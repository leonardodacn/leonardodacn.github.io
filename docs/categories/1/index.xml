<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>1 on haokiu</title>
    <link>https://haokiu.com/categories/1/</link>
    <description>Recent content in 1 on haokiu</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>haokiu.com</copyright>
    <lastBuildDate>Wed, 24 Feb 2021 10:24:56 +0000</lastBuildDate><atom:link href="https://haokiu.com/categories/1/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>java 到底要不要收费</title>
      <link>https://haokiu.com/blog/AWAwA5/</link>
      <pubDate>Wed, 24 Feb 2021 10:24:56 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/AWAwA5/</guid>
      <description>随着JDK 11发布, Oracle同时调整了JDK的授权许可证,里面包含了好几个动作。
首先, Oracle从JDK 11起把以前的商业特性全部开源给OpenJDK,这样OpenJDK 11和OracleJDK 11的代码和功能,在本质上就是完全相同的(官方原文是Essentially Identical)。
然后, Oracle宣布以后将会同时发行两个JDK:一个是以GPLV2+CE协议下由Oracle发行的OpenJDK (本书后面章节称其为Oracle OpenJDK) ,另一个是在新的OTN协议下发行的传统的OracleJDK。
这两个JDK共享绝大部分源码,在功能上是几乎一样的,核心差异是前者可以免费在开发、测试或生产环境中使用，但是只有半年时间的更新支持;后者个人依然可以免费使用，但若在生产环境中商用就必须付费，可以有三年时间的更新支持。
如果说由此能得出&amp;quot;Java要收费&amp;quot;的结论,那是纯属标题党,最多只能说Oracle在迫使商业用户要么不断升级JDK的版本,要么就去购买商业支持。
JDK选择建议 JDK8 分情况 8u211和之后的版本商用需付费，JDK 9/10 免费 JDK 11及以上所有版本商用需付费
免费建议：JDK8 使用 8u202 版本，JDK8 以上版本使用 OpenJDK 或大型机构替代版本Zulu JDK 、Amazon Corretto JDK等
说明 Java 的版本发布周期变更为每六个月一次 ， 每半年发布一个大版本，每个季度发布一个中间特性版本，Java 9 和 Java 10 这两个被称为“功能性的版本”，两者均只提供半年的技术支持，Java 11 不仅提供了长期支持服务，还将作为 Java 平台的参考实现。Oracle 直到2023年9月都会为 Java 11 提供技术支持，而补丁和安全警告等扩展支持将持续到2026年。所以，Java11 必将是下一代长期使用的版本。</description>
    </item>
    
    <item>
      <title>Neovide</title>
      <link>https://haokiu.com/blog/neovide/</link>
      <pubDate>Tue, 16 Feb 2021 13:54:58 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/neovide/</guid>
      <description>neovide 是一个简单的 neovim 用户图像工具，相对于 Neovim 会有一些界面的提升的，但它的功能类似于终端用户界面。
neovide 的官网：https://github.com/Kethku/neovide。
gitbhub上有更多关于它的安装及使用教程。</description>
    </item>
    
    <item>
      <title>1.1 Go1的诺言</title>
      <link>https://haokiu.com/blog/3edad2cabde0428f9098185e6d62c870/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/3edad2cabde0428f9098185e6d62c870/</guid>
      <description>1.1 Go1的诺言 Go语言从2007年开始设计，2009年底正式开源，而第一个正式的版本Go1则是在2012年上半年发布。Go1的语法变迁主要从Go第一个正式版本开始，Go1是Go语言官方对整个社区的承诺：Go1之后的版本将保证源代码层面兼容。
从Go1的发布日志可以发现，Go1对语言和标准库做了严谨的梳理和完善，Go1的重大变化主要集中在语言和标准库部分。其中语言部分最大的变化是将原先的os.Error接口用内置的error接口类型替代、内置函数引入了close函数用于管道的关闭操作。此外，还对加强了init、append内置函数；增强了复合类型字面值的支持；针对Unicode字符增加了rune别名；改善了对map的遍历和删除元素操作；改进了影子返回值的报警提示；复制结构体时涵盖未导出的成员；明确了哪些类型可以进行相等性测试。同时对每个标准库的路径和功能进行详细的设计和完善。
经过多年的发展和普及，大家已经对Go1语言和标准库耳熟能详，对变更的细节就不详细展开了。但正是这次梳理工作才奠定了Go1之后高速发展的十年。</description>
    </item>
    
    <item>
      <title>1.2 Go1到Go1.10</title>
      <link>https://haokiu.com/blog/7ec2e79995ed4c9f8b883cc07c8d78f9/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/7ec2e79995ed4c9f8b883cc07c8d78f9/</guid>
      <description>1.2 Go1到Go1.10 因为Go1承诺，Go1后序的版本都保持了向前兼容的目标。不过在从Go1发展到Go1.10的过程中，语言依然是增加了一些新的特性。本节我们简单回顾Go1到Go1.10的变化。
1.2.1 Go1.2（2013年12月） Go1.2最大的语言变化是切片操作时，可以设置新切片的容量。这个需求在Go1之前就被提出了，但是因为Go1修改工作较大而延期到了Go1.2才被实现。
比如下面的代码：
var a = make([]int, 10) var b = a[i:j:k] 其中b切片是从a切片的第i个元素开始到第j个元素前结束，b切片的容量为k（k指定的容量不能超出a切片的容量）。
为了配合切片语法的变更，reflect包也增加了相应的方法：
func (v Value) SetCap(cap int) func (v Value) Slice3(low, high, max int) Value 其中Value.SetCap只调整切片的容量，和a[::cap]写法效果等价。而Value.Slice3在进行切片操作的同时也指定新切片的容量，和a[low:high:max]写法效果等价。
通过限制子切片的容量，可以将不同子切片进行安全的分割，避免子切片无意越界操作其它切片空间。
1.2.2 Go1.4（2014年12月） Go1.4语言部分对for语法进行了加强。在Go1.3之前for只有下面两种写法：
for i, v := range x { // ... } for i := range x { // ... } for range针对要循环变量类型的不同，产生的循环变量也有差异。在第一种写法中，如果要循环的是数组或切片类型则i和v分别表示索引的下标和元素的值，如果循环的类型是map类型时则i和v分别表示键和值，这种写法不能用于管道类型变量的迭代。而第二种循环也可以用管道变量的迭代，直到管道被关闭时结束。如果用第二种方式循环遍历数组或map，则和for i, _ := range x {}的写法相关相同，相当于忽略的要迭代的值。
但是有时候我们仅仅是要循环几次而并不关心循环变量的值，在Go1.3之前可以这样写：
var times [5][0]int for i := 0; i &amp;lt; len(times); i++ { // ... } for _ = range times { // ... } 前一种方式采用传统的for循环方式遍历，而后一种方式采用for range遍历，但是获取了每次遍历到的值。
在Go1.4中，后一种方式可以省略掉前面的垃圾桶变量，像这样写：
var times [5][0]int for range times { // ... } 其中times对应一个[5][0]int类型的数组，虽然第一维数组有长度，但是数组的元素[0]int大小是0，因此整个数组占用的内存大小依然是0。没有付出额外的内存代价，我们就通过for range方式实现了times次快速迭代。</description>
    </item>
    
    <item>
      <title>1.3 Go1.10过渡到Go2</title>
      <link>https://haokiu.com/blog/2756df043ed74a91bd57f134270e6cbc/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/2756df043ed74a91bd57f134270e6cbc/</guid>
      <description>1.3 Go1.10过渡到Go2 回顾前一节中Go1到Go1.10的语法变化可发现，在Go1之后除了Go1.2的切片语法完善和Go1.9的类型别名很少有重量级的语法特性加入。这是因为Go1.2之后Go语言的语言设计基本是被冻结了，涉及到语言变化的Issue原则上必须通过Russ Cox等核心成员的同意才会被考虑。但是从Go1.10开始，官方终于开始启动Go2.0的语言前期设计工作。首先是官方开始提交模块化的草案，其次是很多呼声较高的语法糖特性开始被考虑逐步加入。可以说Go1.10之后进入了后Go1.0时代，它要在Go2.0到来之前解逐步完善细节问题，从而最终能给轻装上阵开始进入Go2.0开发流程。
1.3.1 Go1.11（2018年8月） 在Go语言的发展史中，2018年注定是一个重要的时间点，因为在2018年8月正式发布了Go1.11。Go1.11语言部分虽然没有变化，但是带来了3个重量级的更新：一是amd64平台完全支持AVX512高性能的指令集；二是Go1.11开始支持模块化的特性；三是Go语言开始WebAssembly平台。这几个个改进将成为后Go1时代最大的亮点。
首先AVX512高性能的指令集可以让Go语言榨干CPU的全部性能，为Go2进军运算密集型应用做好准备（如果对Go汇编语言感兴趣，可以参考作者的《Go语言高级编程》中汇编语言相关的章节）。而模块是管理任何大型工程必备的工具，但是Go语言发布十年来一直缺乏官方的模块化工具。模块化的特性将彻底解决大型Go语言工程的管理问题，至此Go1除了缺少泛型等特性已经近乎完美。最后，WebAssembly作为一个Web汇编语言和虚拟机标准，Go语言可能为Web开发打开一个崭新的领域。
关于模块和WebAssembly都是较大的主题，它们目前都还是作为实验特性，希望在后序版本中逐步完成。在本书将有专门的章节讨论模块和WebAssembly相关的技术。
1.3.2 Go1.12（2019年2月） Go1.12并没有增加新的语言特性，但是官方正式决定在下个Go1.13版本中删除对二进制包的支持。二进制包的是在Go1.7版本作为实验性的特性引入的，一个包可以以类似C语言静态库的方式采用二进制包发布，从而避免公布源代码。在Go语言不支持二进制包特性的时候，社区对这个需求呼声甚高，但是当官方真正支持了之后却根本没有人使用。Go语言官方删除二进制包的决定也是Go的“少即是多”的哲学决定的，而正是这种极度的克制的基因才造就了目前的Go语言成功。
1.3.3 Go1.13（2019年8月） 从Go1.13开始，从Go1.11开始酝酿的诸多决定终于开始逐个生效：首先是模块化将成为默认的特性，彻底告别GOPATH时代；其次是不是太重要的二进制特性将被废除；最后是语言的进化将再次启动，一些细微的语言特性将在Go2到来之前被提前实现。
最有可能被优先实现的特性有：数字支持下划线分割的特性，以便于书写更容易阅读的数字，比如100000000可以写为1_0000_0000；其次Go语言将引入二进制的数字字面值，比如0b00001111是以二进制格式书写的整数。这虽然是很小的语法糖改进，但是标志了Go2语言的开发工作正逐步进入开发计划。</description>
    </item>
    
    <item>
      <title>1.4 Go2诞生</title>
      <link>https://haokiu.com/blog/4f9267cc85a647979aa3803c5c435407/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/4f9267cc85a647979aa3803c5c435407/</guid>
      <description>1.4 Go2诞生 在2018年官方已经发布了Go2的设计草案，其中包含了令人惊喜的泛型和错误等诸多改进，在后Go1时代过去之后将是新兴的Go2时代。需要说明的是，Go2的诞生并不表示Go1被抛弃！如何避免Py3k的笑话正是Go2第一要考虑的问题，因此才会有Go1.11到Go2逐步过段的阶段。而Go语言官方也已经通过博文承诺Go2将保持对Go1软件资产的最大兼容，鉴于Go1诺言被忠实地执行的参考，我们有理由相信Go2会处理好Go1资产的兼容性问题。
大约在2012年前后，作者曾乐观估计Go2将在2020年前后到来，并可能带来大家期盼已久的泛型特性。作者在此预测Go2将在2020年正式进入开发流程，并在2022年前后进入工业生产环境使用，而Go1将在2030年前后逐渐退出历史。为了在Go2正式到来时轻装上阵，我们需要提前把握Go语言的发展动向，而本书正是为此目标准备。</description>
    </item>
    
    <item>
      <title>2.1 Go1的包机制</title>
      <link>https://haokiu.com/blog/e07062bd3a82483893b16c9a014f22dc/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/e07062bd3a82483893b16c9a014f22dc/</guid>
      <description>2.1 Go1的包机制 同⽬录Go源⽂件的集合构成包，而同⽬录下⼦⽬录对应的包的集合构成模块（暂不考虑子模块）。因此，要了解模块之前需要先了解包。
2.1.1 包是最小链接单位 Go语言是一种编译型的语言，链接的最小单位是包，对应go/ast.Package类型，多个包链接为一个可执行程序。在当前的官方实现中，一个包一般对应一个路径目录下的全部的Go语言源文件，而目录的路径包含了表示包的唯一路径名。Go语言的规范中包只是一个抽象的概念，并不要求包一定是以目录的方式展现，在未来包或者是模块也可能以压缩文件的方式展现。
包是Go语言应用编译和链接的基本单位，因此模块最终的目的是为了管理这些包的版本。
2.1.2 包目录布局的演变 在Go语言刚刚开源、还没有GOPATH环境变量之前，Go语言标准库的包全部是放在$(GOROOT)/src目录之下的，比如标准库中的image/png包对应$(GOROOT)/src/image/png目录。而第三方的包也可以放在$(GOROOT)/src目录，这时候Go语言的构建工具是不区分标准库的包和第三方包的。此外第三方或自己的应用对应的包，可以放在$(GOROOT)目录之外的任意目录。
比如可以在任意目录创建一个hello.go文件：
package hello import &amp;#34;fmt&amp;#34; func PrintHello() { fmt.Printf(&amp;#34;Hello, 世界\n&amp;#34;) } 然后在同级的目录创建一个Makefile文件用于管理构建工作：
include $(GOROOT)/src/Make.inc TARG=github.com/chai2010/go2-book/ch2/hello GOFILES=./hello.go include $(GOROOT)/src/Make.pkg 第一个语句包含构建环境，最后的语句表示这是一个包。最重要的TARG变量定义了包的路径，而GOFILES则表示了包由哪些Go文件组成。然后执行make nuke就可以编译生成$(GOROOT)/pkg/github.com/chai2010/go2-book/ch2/hello.a文件。当另一个包要导入hello包时，实际上是从$(GOROOT)/pkg/github.com/chai2010/go2-book/ch2/hello.a文件读取包的信息。
在Go1之前的史前时代，一切包都是手工构建安装的，因此包的版本管理也是手工的方式进行。如果需要使用社区开源的第三方包，需要手工下载代码放到合适的目录正确编译并安装之后才可以使用。
为了将标准库的包和第三方的包分开管理，避免第三方包代码污染$(GOROOT)/src和$(GOROOT)/pkg目录，Go语言引入了GOPATH环境变量。GOPATH环境变量对应的目录用于管理非标准库的包，其中src用户存放Go代码，pkg用于存放编译后的.a文件，bin用于存放编译后的可执行程序。此后直到Go1.10，Go语言所有和包版本管理相关的工作都是基于GOPATH特性展开。
2.1.3 GOPATH特性的扩展 扩展GOPATH的目标都是为了更方便管理包。Go语言的包有三种类型：首先是叶子包，此类包最多依赖标准库，不依赖第三方包；其次是main包表示一个应用，它不能被其它包导入（单元测试除外）；最后是普通的依赖第三方包的非main包。比较特殊的main包同时也是一个叶子包。
叶子包自身很少会遇到版本管理问题，因为不会遇到因为依赖第三方包产生的各种问题，因此叶子包的开发者很少关注版本管理的问题。稍微复杂一点的是main包，main包是包依赖中的根包。main包不担心被其它包依赖，因此它其实是可以通过一个独占的GOPATH来维护所有依赖的第三方包的。最复杂的是既不是main包，也不是普通的叶子包，因为普通包需要管理其依赖的第三方包，同时一般又不能单独管理GOAPTH。在vendor出现之前的版本管理实践中，普通包的版本比较简陋，很多普通包甚至都没有版本管理，只有master一个最新版本。
GOPATH的扩展主要分为横向和纵向两个方向。横向就是同时并列维护多个GOPATH目录，通过手工方式调整其中某些目录来实现目录中包版本切换的目的。纵向扩展一般在管理main包对应的应用程序中使用，通过在包内部创建临时的GOPATH子目录，在GOPATH子目录中包含全部第三方依赖的拷贝来实现外部依赖包版本的管理。
社区中早期出现的Godeps工具就是通过在当前目录下创建Godeps/_workspace子目录来管理维护依赖的第三方包的版本。Godeps的实践成果最终被吸收到来Go语言中，通过vendor机制实现来main包的依赖管理（不是版本管理）。但是最终vendor机制也带来了各种问题（稍后的章节会讨论），最终官方完全重新设计了模块化的特性。
2.1.4 模块化之后的包目录路径 通过vendor机制来实现版本管理的尝试虽然失败了，但是通过横向扩展GOPATH的来维护同一个包的不同版本的思路却在模块中复活了。模块化通过重新组织目录结构，实现了同时管理同一个包的不同版本需求。
比如之前$(GOPATH)/src/github.com/chai2010/pbgo包的1.0.0版本，在模块化之后将对应$(HOME)/go/pkg/mod/github.com/chai2010/pbgo@1.0.0。模块化通过$(HOME)/go/pkg/mod目录管理第三方的依赖包，同时通过pkg@x.y.z的版本后缀来区分同一个包的不同版本。这其实和多个GOPATH并列存放的思路是类似，不过模块化对多版本支持的更加完美。</description>
    </item>
    
    <item>
      <title>2.2 基于vendor的版本管理</title>
      <link>https://haokiu.com/blog/ba3f4751a98a484f995283b9377b90d1/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/ba3f4751a98a484f995283b9377b90d1/</guid>
      <description>2.2 基于vendor的版本管理 2.2.1 vendor的工作机制 2.2.1 vendor的优势 TODO
2.2.1 vendor的问题 </description>
    </item>
    
    <item>
      <title>2.3 模块的设计⽬标</title>
      <link>https://haokiu.com/blog/0ade9d480b954dbc96381d011208c5f1/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/0ade9d480b954dbc96381d011208c5f1/</guid>
      <description>2.3 模块的设计⽬标 2.3.1 模块的概念 2.3.2 不同时间可重现构建 2.3.3 不同环境可重现构建 2.3.4 语义化版本号 2.3.5 最⼩化版本选择 TODO</description>
    </item>
    
    <item>
      <title>2.4 模块快速⼊⻔</title>
      <link>https://haokiu.com/blog/99154ed6163e4a40bcfdc5e7d5956c7d/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/99154ed6163e4a40bcfdc5e7d5956c7d/</guid>
      <description>2.4 模块快速⼊⻔ 2.4.1 快速入门 2.4.2 go get重新⼊⻔ 2.4.3 go.mod⽂件 2.4.4 go.sum⽂件 2.4.5 版本切换 2.4.3 go mod命令 TODO</description>
    </item>
    
    <item>
      <title>2.5 子模块和多版本共存</title>
      <link>https://haokiu.com/blog/c868302e70ab472280a428d5583e15d2/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/c868302e70ab472280a428d5583e15d2/</guid>
      <description>2.5 子模块和多版本共存 2.5.1 子模块 2.5.2 多版本共存 TODO</description>
    </item>
    
    <item>
      <title>2.6 镜像和私有仓库</title>
      <link>https://haokiu.com/blog/3681abb2d5e34af2be2ea2f170c6226f/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/3681abb2d5e34af2be2ea2f170c6226f/</guid>
      <description>2.6 镜像和私有仓库 2.6.1 Fork的仓库 2.6.2 私有仓库 TODO</description>
    </item>
    
    <item>
      <title>2.7 模块化实践中的一些问题</title>
      <link>https://haokiu.com/blog/1fbab86b16734c59b0bff743e512dfb2/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1fbab86b16734c59b0bff743e512dfb2/</guid>
      <description>2.7 模块化实践中的一些问题 2.7.1 和GOPATH不兼容 2.7.2 pkg目录复杂化 TODO</description>
    </item>
    
    <item>
      <title>Go2编程指南</title>
      <link>https://haokiu.com/blog/5c22f69800184d7a8705059ee3773333/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/5c22f69800184d7a8705059ee3773333/</guid>
      <description>Go2编程指南 本书重点讲解Go2新特性，以及Go1教程中较少涉及的特性。本书适合对Go语言有一定基础的用户学习。对于刚学习Go语言的读者，建议先从《Go语言圣经》开始系统学习Go语言的基础知识。如果希望了解Go语言CGO或汇编语言的细节，可以参考《Go语言高级编程》。
作者：柴树杉，Github @chai2010，Twitter @chaishushan 网址：https://github.com/chai2010/go2-book 在线阅读 https://chai2010.cn/go2-book/ 版权声明 Go2编程指南 由 柴树杉 采用 知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议进行许可。
严禁任何商业行为使用或引用该文档的全部或部分内容！
捐助支持 支付宝 微信 前言 TODO</description>
    </item>
    
    <item>
      <title>Go2编程指南</title>
      <link>https://haokiu.com/blog/bk-3/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/bk-3/</guid>
      <description>目录1.1 Go1的诺言1.2 Go1到Go1.101.3 Go1.10过渡到Go21.4 Go2诞生第1章 语法变迁2.1 Go1的包机制2.2 基于vendor的版本管理2.3 模块的设计⽬标2.4 模块快速⼊⻔2.5 子模块和多版本共存2.6 镜像和私有仓库2.7 模块化实践中的一些问题第2章 模块化第3章 错误处理Go2编程指南</description>
    </item>
    
    <item>
      <title>Go2编程指南</title>
      <link>https://haokiu.com/blog/e2e79e399c5b464295e2703c5db5739b/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/e2e79e399c5b464295e2703c5db5739b/</guid>
      <description>Go2编程指南 Go语言QQ群: 102319854, 1055927514 光谷码农课堂: https://study.163.com/provider/480000001914454/index.htm 凹语言(凹读音“Wa”)(The Wa Programming Language): https://github.com/wa-lang/wa 蚂蚁金服招聘云原生方向和编程语言方向岗位(杭州/P7)：云原生方向要求熟悉k8s配套工具，如kubectl、kustomize、kubebuilder，operator；编程语言方向要求对语言对语言解释器（如py/js/lua/wasm等）、工具链、配套SDK有一定兴趣和实践经验。欢迎各位同学咨询或推荐（推荐成功独享全额推荐红包）。联系方式 chaishushan@gmail.com, shushan.css@alibaba-inc.com
本书重点讲解Go2新特性，以及Go1教程中较少涉及的特性。本书适合对Go语言有一定基础的用户学习。对于刚学习Go语言的读者，建议先从《Go语言圣经》开始系统学习Go语言的基础知识。如果希望了解Go语言CGO或汇编语言的细节，可以参考《Go语言高级编程》。如果希望深入学习Go语言语法树结构，可以参考《Go语法树入门——开启自制编程语言和编译器之旅》。
作者：柴树杉，Github @chai2010，Twitter @chaishushan 网址：https://github.com/chai2010/go2-book Star历史：https://starcharts.herokuapp.com/chai2010/go2-book.svg 在线阅读 SUMMARY.md https://chai2010.cn/go2-book/ 网易云课堂·光谷码农课堂 https://study.163.com/provider/480000001914454/index.htm
加入QQ群：102319854 中国最早的Go语言QQ群
关注微信公众号(光谷码农/guanggu-coder) 加入微信群：从公众号底部菜单扫码进群。
相关报告 GIAC: 2018 - Go 语言将要走向何方？(PDF) - 上海·GIAC全球互联网架构大会 2018/11/23 版权声明 Go2编程指南 由 柴树杉 采用 知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议进行许可。
严禁任何商业行为使用或引用该文档的全部或部分内容！
欢迎大家提供建议！</description>
    </item>
    
    <item>
      <title>目录</title>
      <link>https://haokiu.com/blog/1f4511a4eff2422184945a24e32887e2/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1f4511a4eff2422184945a24e32887e2/</guid>
      <description>目录 第1章 语法变迁 1.1 Go1的诺言 1.2 Go1到Go1.10 1.3 Go1.10过渡到Go2 1.4 Go2诞生 第2章 模块化 2.1 Go1的包机制 2.2 基于vendor的版本管理(TODO) 2.3 模块的设计⽬标(TODO) 2.4 模块快速⼊⻔(TODO) 2.5 子模块和多版本共存(TODO) 2.6 镜像和私有仓库(TODO) 2.7 模块化实践中的一些问题(TODO) 第3章 错误处理(TODO) </description>
    </item>
    
    <item>
      <title>第1章 语法变迁</title>
      <link>https://haokiu.com/blog/c3984397f8e5480f81aaaeaf1b82ac23/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/c3984397f8e5480f81aaaeaf1b82ac23/</guid>
      <description>第1章 语法变迁 Go语言语法变化非常少，主要发生在Go1.10之前。Go1.10主要的开发工作在2017年下半年完成，在2018年初正式发布。Go1.10版可以说是Go1和Go2的分水岭，虽然语言本身没有大的变化，但是Go语言官方正式开始准备Go2的前期设计工作。在Go1.10以前，很多关于语言细节修改的建议绝大部分都被冻结了。但是在Go1.10以后，语言改进的工作又重新纳入日程。本章重点回顾Go1.0发布以来，语言发生了哪些细微的变化。</description>
    </item>
    
    <item>
      <title>第2章 模块化</title>
      <link>https://haokiu.com/blog/8ef2da522892434187a81439c5d1dc2d/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/8ef2da522892434187a81439c5d1dc2d/</guid>
      <description>第2章 模块化 模块化也称为包依赖管理，是管理任何大型工程必备的工具。Go语言发布十年来一直缺乏官方的模块化工具。同样在2018年，作为Go语言团队的技术领导人Russ Cox终于出手，重新发明了称为最小版本选择的包依赖管理的规则并提交了提案。模块特性已经被实验性地集成到Go1.11中，并将在后续版本中逐渐转化为正式特性。模块化的特性将彻底解决大型Go语言工程的管理问题，至此Go1除了缺少泛型等特性已经近乎完美。本章讨论模块相关的使用。</description>
    </item>
    
    <item>
      <title>第3章 错误处理</title>
      <link>https://haokiu.com/blog/615b0dd45d2e4323805039e0ffb41808/</link>
      <pubDate>Fri, 22 Jan 2021 15:40:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/615b0dd45d2e4323805039e0ffb41808/</guid>
      <description>第3章 错误处理 </description>
    </item>
    
    <item>
      <title>beego restful path variable</title>
      <link>https://haokiu.com/blog/RNbgLz/</link>
      <pubDate>Fri, 22 Jan 2021 14:52:21 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/RNbgLz/</guid>
      <description>beego的url路径有多个变量的设置和获取方法。
在 router.go 注册 url beego.Router(&amp;#34;/type/:type/?:page&amp;#34;, &amp;amp;controllers.WebController{}, &amp;#34;get:Type&amp;#34;) 获取变量 typeID, err := self.GetInt(&amp;#34;:type&amp;#34;) func (c *Controller) GetInt(key string, def ...int) (int, error) { strv := c.Ctx.Input.Query(key) if len(strv) == 0 &amp;amp;&amp;amp; len(def) &amp;gt; 0 { return def[0], nil } return strconv.Atoi(strv) } </description>
    </item>
    
    <item>
      <title>2020 年好好读一读开源代码吧</title>
      <link>https://haokiu.com/blog/ea1d963411184ea88648b092380ee687/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/ea1d963411184ea88648b092380ee687/</guid>
      <description>2020 年好好读一读开源代码吧 2019 年就这么结束了，2020 年也来临了，虽然我曾对过去 2019 年做了一份总结，但是认真的来说，其实我对自己的 2019 年的收获并不太满意，一个主要的原因是计划好好研读的几个开源项目的源码都没有去做。好在，2020 新的一年，不再像 2019 年创业一般忙碌，终于可以静下心来认真去把这些未完成的计划好好做完。
其实，我一直想找个机会和我的读者，好好讨论一下阅读开源项目源码这个话题的，我这里观点无任何含糊或者模棱两可，我旗帜鲜明的亮出我的观点——想在技术上有所造诣或者想成为某一技术领域的专家的同学一定要认认真真的研读几个开源软件的源码。下面我会具体来展开说下这个问题。
知识付费与阅读源码 大家都知道，时下&amp;quot;知识付费&amp;quot;这个词非常火热，各大平台各个领域都推出了许多基于知识付费的课程，有图文版、语音版和视频版（包括在线实时教育直播）。当然，知识付费是一个好东西。众所周知，互联网信息的特点是信息量大、有用信息少、信息质量良莠不齐，各大平台推出的各种付费课程，精心制作，用心分类和梳理，读者只要花费一定的费用，就能省去大量搜索、查找和遴选信息的时间，直接专注于获得相关知识本身。
在各类知识付费课程中，有一类课程是介绍业界或者大家平常工作中用到的一些开源软件的原理的，进一步说，有的是分析这类软件的源码的，如 nginx、netty、Spring Boot。
我个人觉得，虽然你可以购买一些这样那样的开源软件的教程或者图书（包括电子书）去学习，但一定不要以这些学习材料为主要的学习这些开源软件的方法和途径，有机会的话，或者说如果你要学习的开源软件所使用的开发语言正好是你熟悉或者使用的编程语言，那么你应该尽量多去以阅读这些开源项目的源码本身为主。举个例子，如果你是 C/C++ 后端开发者，那么像 redis、nginx（它们都是使用 C 编写的）这样的开源项目的源码你应该认真的去研读一下；如果你是做 Windows C/C++ 客户端或者一名 QT 客户端开发人员，那么像 MFC、DUILIB、金山卫士等源码，你可以拿来读一读；如果你是 Java 程序员，netty、Spring 等源码是你进阶路上必须迈过去的一关。
为什么建议以阅读相关源码为主，而不是其他相关教程呢？
首先，任何其他相关教程介绍的内容都是基于这个软件的源码实现创作出来的，虽然能帮助你快速理解一些东西，但是不同的教程作者在阅读同样一份代码时的注意点和侧重点不一样，加上如果作者在某些地方有理解偏差的，这种偏差会被引入你所学习的教程或者图书里面，也就是说，你学习的这些东西其实不是第一手的，而是经过别人加工或者理解意译过的，在这个过程中如果别人理解有偏差，那么你或多或少的会受一点影响。所以，为了&amp;quot;不受制于人”，亲自去阅读一些源码时非常有必要的。
其次，如果你按照别人的教程大纲，那么你的学习该软件的开源项目时，可能会受限于别人的视野和侧重点，通俗的说，假设一个开源项目其可以学习和借鉴的内容有 A、B、C、D、E 五个大的点，别人的教程可能只写了 A、B、C、D 四个点，如果你只局限于别人的教程，你就错过 E 这个点了。
这里可以给读者讲一个具体的例子。我最初开始走上工作岗位时做的是 C/C++ 客户端开发，我无意中找到了一份完整的电驴源码，但是开始阅读这份代码比较吃力，于是我就在网上找相关的电驴源码分析教程来看。但是呢，网上的这方面的教程都是关于电驴的网络通信模块和通信协议介绍的，很多做客户端的读者是知道的，做客户端开发很大一部分工作是在开发 UI 界面方面的逻辑和布局，其实电驴源码中关于界面设计逻辑写的也是很精彩的，也非常值得当时的我去借鉴和学习。如果我只按照网上的教程去学习，那么就错过这方面的学习了。也就是同样一份电驴源码，不同的学习者汲取的其源码中的营养成分是不一样的。需要电驴源码的同学可以在公众号后台回复关键字【电驴源码】获取下载链接。
如何去阅读源码呢？ 这应该是很多读者想知道的问题，先讨论几种老生常谈的阅读源码的方式。
第一种方式就是所谓的精读和粗读。很多读者应该听说过这种所谓的阅读源代码的方式，有些人认为有些源码只需要搞清楚其主要结构和流程就可以了，而另外一些源码需要逐行认真去研读其某个或者某几个模块的源码。或者，只阅读自己感兴趣或者需要的模块。
第二种方式，说的是先熟悉代码的整体结构，再去依次搞清楚各个模块的代码细节。
第三种方式是所谓的调试法，通过开源项目的一个或几个典型的流程，去调试跟踪信息流，然后逐步搞清楚整个项目的结构。
以上三种方式都是不错的阅读源码的方式，读者可以根据自己的水平、目的和阶段去使用。但是，我这里想说的并不是这些东西。
我个人觉得，一个技术人员如果想通过源码去提高自己，应该以一种&amp;quot;闲登小阁看新晴&amp;quot;的心境去阅读源码，这也许是在某个节假日的清晨，某个下过雨的午后，某个夜黑人静的深夜。看源码尤其是看高质量源码本来就是一种享受，像品茗。闲暇时间去细细品味一些开源软件的源码，和锻炼身体一样，都是人生中重要不紧急的事情，这类事情做的越多，坚持的越久，越能提高你的人生厚度。虽然阅读源码的最终目的是功利性的，但是阅读源码的心态不建议是功利性的，喜欢做一件事本身的过程，比把这件事做好的目标更快乐。
我从学生时代开始，就喜欢看一些开源软件的源码，当然，从现在的标准来看，看的很多源码都不是&amp;quot;高质量&amp;quot;的，择其善者而从之其不善者而改之，不是吗？有些源码可以学习其架构、结构设计，有些源码则可以学习其细节设计（如变量命名、编码风格等）。
看过的这些源码对我的技术视野影响很大。我上大学的时候，迷恋 Flash 编程，当时非常崇拜 Flash 界的两位前辈——鼠标炸弹（https://mousebomb.org/）和寂寞火山（现在已成币圈有名的大佬），另外还有淘沙网的沙子。多年后再看他们的代码可能质量没有那么高，但是我从他们开源出来的代码中学到了很多东西。举个例子，我喜欢在一些成对结束的花括号后面加上明显的成对结束的注释就是从沙子的代码那里学来的。虽然，现在的 IDE 会清楚的标示出来各个花括号的范围，但是这种注释风格在某些时候大大方便了代码阅读和 review。
//实例 class A { public: void someFunc() { for (int i = 0; i &amp;lt; n; ++i) { for (int j = 0; j &amp;lt; m; ++j) { //some codes... }// end inner-for-loop	}// end outer-for-loop }// end method someFunc }; // end class A 给大家阅读源码的一些建议 很多人阅读源码存在以下不当的习惯或者认知方式：</description>
    </item>
    
    <item>
      <title>C&#43;&#43; 高性能服务器网络框架设计细节</title>
      <link>https://haokiu.com/blog/10dc93cb0ce148d1906354635024bb25/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/10dc93cb0ce148d1906354635024bb25/</guid>
      <description>C++ 高性能服务器网络框架设计细节 这篇文章我们将介绍服务器的开发，并从多个方面探究如何开发一款高性能高并发的服务器程序。需要注意的是一般大型服务器，其复杂程度在于其业务，而不是在于其代码工程的基本框架。大型服务器一般有多个服务组成，可能会支持CDN，或者支持所谓的“分布式”等，这篇文章不会介绍这些东西，因为不管结构多么复杂的服务器，都是由单个服务器组成的。所以这篇文章的侧重点是讨论单个服务程序的结构，而且这里的结构指的也是单个服务器的网络通信层结构，如果你能真正地理解了我所说的，那么在这个基础的结构上面开展任何业务都是可以的，也可以将这种结构扩展成复杂的多个服务器组，例如“分布式”服务。文中的代码示例虽然是以C++为例，但同样适合Java（我本人也是Java开发者），原理都是一样的，只不过Java可能在基本的操作系统网络通信API的基础上用虚拟机包裹了一层接口而已（Java甚至可能基于一些常用的网络通信框架思想提供了一些现成的API，例如NIO）。有鉴于此，这篇文章不讨论那些大而空、泛泛而谈的技术术语，而是讲的是实实在在的能指导读者在实际工作中实践的编码方案或优化已有编码的方法。另外这里讨论的技术同时涉及windows和linux两个平台。
所谓高性能就是服务器能流畅地处理各个客户端的连接并尽量低延迟地应答客户端的请求；所谓高并发，不仅指的是服务器可以同时支持多的客户端连接，而且这些客户端在连接期间内会不断与服务器有数据来往。网络上经常有各种网络库号称单个服务能同时支持百万甚至千万的并发，然后我实际去看了下，结果发现只是能同时支持很多的连接而已。如果一个服务器能单纯地接受ｎ个连接（ｎ可能很大），但是不能有条不紊地处理与这些连接之间的数据来往也没有任何意义，这种服务器框架只是“玩具型”的，对实际生产和应用没有任何意义。
这篇文章将从两个方面来介绍，一个是服务器中的基础的网络通信部件；另外一个是，如何利用这些基础通信部件整合成一个完整的高效的服务器框架。注意：本文以下内容中的客户端是相对概念，指的是连接到当前讨论的服务程序的终端，所以这里的客户端既可能是我们传统意义上的客户端程序，也可能是连接该服务的其他服务器程序。
一、网络通信部件 按上面介绍的思路，我们先从服务程序的网络通信部件开始介绍。
（一）、需要解决的问题 既然是服务器程序肯定会涉及到网络通信部分，那么服务器程序的网络通信模块要解决哪些问题？目前，网络上有很多网络通信框架，如libevent、boost asio、ACE，但都网络通信的常见的技术手段都大同小异，至少要解决以下问题：
如何检测有新客户端连接？ 如何接受客户端连接？ 如何检测客户端是否有数据发来？ 如何收取客户端发来的数据？ 如何检测连接异常？发现连接异常之后，如何处理？ 如何给客户端发送数据？ 如何在给客户端发完数据后关闭连接？ 稍微有点网络基础的人，都能回答上面说的其中几个问题，比如接收客户端连接用socket API的accept函数，收取客户端数据用recv函数，给客户端发送数据用send函数，检测客户端是否有新连接和客户端是否有新数据可以用IO multiplexing技术（IO复用）的select、poll、epoll等socket API。确实是这样的，这些基础的socket API构成了服务器网络通信的地基，不管网络通信框架设计的如何巧妙，都是在这些基础的socket API的基础上构建的。但是如何巧妙地组织这些基础的socket API，才是问题的关键。我们说服务器很高效，支持高并发，实际上只是一个技术实现手段，不管怎样，从软件开发的角度来讲无非就是一个程序而已，所以，只要程序能最大可能地满足“尽量减少等待或者不等待”这一原则就是高效的，也就是说高效不是“忙的忙死，闲的闲死”，而是大家都可以闲着，但是如果有活要干，大家尽量一起干，而不是一部分忙着依次做事情123456789，另外一部分闲在那里无所事事。说的可能有点抽象，下面我们来举一些例子具体来说明一下。 例如：
默认情况下，recv函数如果没有数据的时候，线程就会阻塞在那里； 默认情况下，send函数，如果tcp窗口不是足够大，数据发不出去也会阻塞在那里； connect函数默认连接另外一端的时候，也会阻塞在那里； 又或者是给对端发送一份数据，需要等待对端回答，如果对方一直不应答，当前线程就阻塞在这里。 以上都不是高效服务器的开发思维方式，因为上面的例子都不满足“尽量减少等待”的原则，为什么一定要等待呢？有没用一种方法，这些过程不需要等待，最好是不仅不需要等待，而且这些事情完成之后能通知我。这样在这些本来用于等待的cpu时间片内，我就可以做一些其他的事情。有，也就是我们下文要讨论的IO Multiplexing技术（IO复用技术）。
（二）、几种IO复用机制的比较 目前windows系统支持select、WSAAsyncSelect、WSAEventSelect、完成端口（IOCP），linux系统支持select、poll、epoll。这里我们不具体介绍每个具体的函数的用法，我们来讨论一点深层次的东西，以上列举的API函数可以分为两个层次：
层次一 select和poll 层次二 WSAAsyncSelect、WSAEventSelect、完成端口（IOCP）、epoll 为什么这么分呢？先来介绍第一层次，select和poll函数本质上还是在一定时间内主动去查询socket句柄（可能是一个也可能是多个）上是否有事件，比如可读事件，可写事件或者出错事件，也就是说我们还是需要每隔一段时间内去主动去做这些检测，如果在这段时间内检测出一些事件来，我们这段时间就算没白花，但是倘若这段时间内没有事件呢？我们只能是做无用功了，说白了，还是在浪费时间，因为假如一个服务器有多个连接，在cpu时间片有限的情况下，我们花费了一定的时间检测了一部分socket连接，却发现它们什么事件都没有，而在这段时间内我们却有一些事情需要处理，那我们为什么要花时间去做这个检测呢？把这个时间用在做我们需要做的事情不好吗？所以对于服务器程序来说，要想高效，我们应该尽量避免花费时间主动去查询一些socket是否有事件，而是等这些socket有事件的时候告诉我们去处理。这也就是层次二的各个函数做的事情，它们实际相当于变主动查询是否有事件为当有事件时，系统会告诉我们，此时我们再去处理，也就是“好钢用在刀刃”上了。只不过层次二的函数通知我们的方式是各不相同，比如WSAAsyncSelect是利用windows窗口消息队列的事件机制来通知我们设定的窗口过程函数，IOCP是利用GetQueuedCompletionStatus返回正确的状态，epoll是epoll_wait函数返回而已。
例如，connect函数连接另外一端，如果用于连接socket是非阻塞的，那么connect虽然不能立刻连接完成，但是也是会立刻返回，无需等待，等连接完成之后，WSAAsyncSelect会返回FD_CONNECT事件告诉我们连接成功，epoll会产生EPOLLOUT事件，我们也能知道连接完成。甚至socket有数据可读时，WSAAsyncSelect产生FD_READ事件，epoll产生EPOLLIN事件，等等。所以有了上面的讨论，我们就可以得到网络通信检测可读可写或者出错事件的正确姿势。这是我这里提出的第二个原则：尽量减少做无用功的时间。这个在服务程序资源够用的情况下可能体现不出来什么优势，但是如果有大量的任务要处理，这里就成了性能的一个瓶颈。
（三）、检测网络事件的正确姿势 根据上面的介绍，第一，为了避免无意义的等待时间，第二，不采用主动查询各个socket的事件，而是采用等待操作系统通知我们有事件的状态的策略。我们的socket都要设置成非阻塞的。在此基础上我们回到栏目（一）中提到的七个问题：
如何检测有新客户端连接？
如何接受客户端连接？ 默认accept函数会阻塞在那里，如果epoll检测到侦听socket上有EPOLLIN事件，或者WSAAsyncSelect检测到有FD_ACCEPT事件，那么就表明此时有新连接到来，这个时候调用accept函数，就不会阻塞了。当然产生的新socket你应该也设置成非阻塞的。这样我们就能在新socket上收发数据了。 如何检测客户端是否有数据发来？
如何收取客户端发来的数据？ 同理，我们也应该在socket上有可读事件的时候才去收取数据，这样我们调用recv或者read函数时不用等待，至于一次性收多少数据好呢？我们可以根据自己的需求来决定，甚至你可以在一个循环里面反复recv或者read，对于非阻塞模式的socket，如果没有数据了，recv或者read也会立刻返回，错误码EWOULDBLOCK会表明当前已经没有数据了。示例：
bool CIUSocket::Recv() { int nRet = 0; while(true) { char buff[512]; nRet = ::recv(m_hSocket, buff, 512, 0); if(nRet == SOCKET_ERROR) { if (::WSAGetLastError() == WSAEWOULDBLOCK) break; else return false; } else if(nRet &amp;lt; 1) return false;
m_strRecvBuf.append(buff, nRet); ::Sleep(1); } return true; }
如何检测连接异常？发现连接异常之后，如何处理？ 同样当我们收到异常事件后例如EPOLLERR或关闭事件FD_CLOSE，我们就知道了有异常产生，我们对异常的处理一般就是关闭对应的socket。另外，如果send/recv或者read/write函数对一个socket进行操作时，如果返回0，那说明对端已经关闭了socket，此时这路连接也没必要存在了，我们也可以关闭对应的socket。
如何给客户端发送数据？ 这也是一道常见的网络通信面试题，某一年的腾讯后台开发职位就问到过这样的问题。给客户端发送数据，比收数据要稍微麻烦一点，也是需要讲点技巧的。首先我们不能像注册检测数据可读事件一样一开始就注册检测数据可写事件，因为如果检测可写的话，一般情况下只要对端正常收取数据，我们的socket就都是可写的，如果我们设置监听可写事件，会导致频繁地触发可写事件，但是我们此时并不一定有数据需要发送。所以正确的做法是：如果有数据要发送，则先尝试着去发送，如果发送不了或者只发送出去部分，剩下的我们需要将其缓存起来，然后再设置检测该socket上可写事件，下次可写事件产生时，再继续发送，如果还是不能完全发出去，则继续设置侦听可写事件，如此往复，一直到所有数据都发出去为止。一旦所有数据都发出去以后，我们要移除侦听可写事件，避免无用的可写事件通知。不知道你注意到没有，如果某次只发出去部分数据，剩下的数据应该暂且存起来，这个时候我们就需要一个缓冲区来存放这部分数据，这个缓冲区我们称为“发送缓冲区”。发送缓冲区不仅存放本次没有发完的数据，还用来存放在发送过程中，上层又传来的新的需要发送的数据。为了保证顺序，新的数据应该追加在当前剩下的数据的后面，发送的时候从发送缓冲区的头部开始发送。也就是说先来的先发送，后来的后发送。 如何在给客户端发完数据后关闭连接？ 这个问题比较难处理，因为这里的“发送完”不一定是真正的发送完，我们调用send或者write函数即使成功，也只是向操作系统的协议栈里面成功写入数据，至于能否被发出去、何时被发出去很难判断，发出去对方是否收到就更难判断了。所以，我们目前只能简单地认为send或者write返回我们发出数据的字节数大小，我们就认为“发完数据”了。然后调用close等socket API关闭连接。当然，你也可以调用shutdown函数来实现所谓的“半关闭”。关于关闭连接的话题，我们再单独开一个小的标题来专门讨论一下。
（四）被动关闭连接和主动关闭连接 在实际的应用中，被动关闭连接是由于我们检测到了连接的异常事件，比如EPOLLERR，或者对端关闭连接，send或recv返回0，这个时候这路连接已经没有存在必要的意义了，我们被迫关闭连接。
而主动关闭连接，是我们主动调用close/closesocket来关闭连接。比如客户端给我们发送非法的数据，比如一些网络攻击的尝试性数据包。这个时候出于安全考虑，我们关闭socket连接。</description>
    </item>
    
    <item>
      <title>CppGuide</title>
      <link>https://haokiu.com/blog/bk-1/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/bk-1/</guid>
      <description>Part IC++ 17 结构化绑定pimpl 惯用法C++必知必会的知识点不定参数函数实现var_arg系列的宏你一定要搞明白的C函数调用方式与栈原理利用 cmake 工具生成 Visual Studio 工程文件如何使用 Visual Studio 管理和阅读开源项目代码如何成为一名合格的 C/C++ 开发者？深入理解C/C++中的指针用Visual Studio调试Linux程序详解 C++ 11 中的智能指针Memcached源码阅读序 服务器资源调整Memcached源码阅读一 初始化参数解析Memcached源码阅读二 网络监听的建立Memcached源码分析三 网络连接建立Memcached源码阅读四 内存初始化Memcached源码阅读五 资源初始化Memcached源码阅读六 get过程Memcached源码阅读七 cas属性Memcached源码阅读八 内存池Memcached源码阅读九 连接队列Memcached源码阅读十 Hash表操作Memcached源码阅读十一 LRU操作Memcached源码阅读十二 set操作Memcached源码阅读十三 do_item_alloc操作Memcached源码阅读十四 item结构Memcached阅读十五 Hash表扩容Memcached源码阅读十六 线程交互Memcached源码阅读十七 状态机Memcached源码分析01 TeamTalk介绍02 服务器端的程序的编译与部署03 服务器端的程序架构介绍04 服务器端db_proxy_server源码分析05 服务器端msg_server源码分析06 服务器端login_server源码分析07 服务器端msfs源码分析08 服务器端file_server源码分析09 服务器端route_server源码分析10 开放一个TeamTalk测试服务器地址和几个测试账号11 pc客户端源码分析TeamTalk源码解析Leveldb源码分析16leveldb源码分析leveldb源码分析1leveldb源码分析10leveldb源码分析11leveldb源码分析12leveldb源码分析13leveldb源码分析14leveldb源码分析15leveldb源码分析17leveldb源码分析18leveldb源码分析19leveldb源码分析2leveldb源码分析20leveldb源码分析21leveldb源码分析22leveldb源码分析3leveldb源码分析4leveldb源码分析5leveldb源码分析6leveldb源码分析7leveldb源码分析8leveldb源码分析9libevent源码深度剖析libevent源码深度剖析一libevent源码深度剖析02libevent源码深度剖析03libevent源码深度剖析04libevent源码深度剖析05libevent源码深度剖析06libevent源码深度剖析07libevent源码深度剖析08libevent源码深度剖析09libevent源码深度剖析10libevent源码深度剖析11libevent源码深度剖析12libevent源码深度剖析13作者的故事我是如何年薪五十万的我的 2019后端开发相关的书籍后台开发应该读的书多线程后台C++开发你一定要知道的条件变量整型变量赋值是原子操作吗？从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始从零学习开源项目系列（二） 最后一战概况从零学习开源项目系列（三） CSBattleMgr服务源码研究从零学习开源项目系列（四）LogServer源码探究服务器开发案例实战从零实现一个http服务器从零实现一个邮件收发客户端从零实现一款12306刷票软件从零开发一个WebSocket服务器10 十万在线的WebGame的数据库设计思路11 一种高性能网络游戏服务器架构设计12 经典游戏服务器端架构概述13 游戏跨服架构进化之路1 游戏服务器开发的基本体系与服务器端开发的一些建议2 网络游戏服务器开发框架设计介绍3 游戏后端开发需要掌握的知识4 关于游戏服务端架构的整理5 各类游戏对应的服务端架构6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则7 QQ游戏百万人同时在线服务器架构实现8 大型多人在线游戏服务器架构设计9 百万用户级游戏服务器架构设计游戏开发专题Linux tcpdump 使用介绍Linux 网络故障排查的瑞士军刀程序员必知必会的网络命令从抓包的角度分析connect()函数的连接过程做 Java 或者 C++ 开发都应该知道的 lsof 命令利用 telnet 命令发电子邮件服务器开发中网络数据分析与故障排查经验漫谈程序员的烦心事我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？为什么你的简历没人看程序员如何写简历程序员的薪资与年终奖那些事儿技术面试与HR谈薪资技巧聊一聊程序员如何增加收入谈一谈年终奖Linux C/C++后端开发面试问哪些问题程序员面试题精讲我面试后端开发经理的经历网络通信面试题集锦聊聊如何拿大厂的 offer腾讯后台开发实习生技能要求Linux epoll 模型（含LT 模式和 ET 模式详解）网络编程TCP 协议如何解决粘包、半包问题bind 函数重难点解析connect 函数在阻塞和非阻塞模式下的行为select 函数重难点解析socket 的阻塞模式和非阻塞模式服务器开发通信协议设计介绍服务器端发数据时，如果对端一直不收，怎么办？网络通信中收发数据的正确姿势非阻塞模式下 send 和 recv 函数的返回值职业规划写给那些傻傻想做服务器开发的朋友给工作 4 年迷茫的程序员们的一点建议聊聊技术人员的常见的职业问题2020 年好好读一读开源代码吧自我提升与开源代码C++ 高性能服务器网络框架设计细节高性能服务器框架设计Reactor模式业务数据处理一定要单独开线程吗主线程与工作线程的分工如何设计断线自动重连机制实例：一个服务器程序的架构介绍心跳包机制设计详解日志系统的设计错误码系统的设计高性能服务器架构设计总结</description>
    </item>
    
    <item>
      <title>Reactor模式</title>
      <link>https://haokiu.com/blog/23cb111095cb47f3b6115efccd11086d/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/23cb111095cb47f3b6115efccd11086d/</guid>
      <description>Reactor模式 最近一直在看游双的《高性能Linux服务器编程》一书，下载链接： http://download.csdn.net/detail/analogous_love/9673008
书上是这么介绍Reactor模式的：
按照这个思路，我写个简单的练习：
/** *@desc: 用reactor模式练习服务器程序，main.cpp *@author: zhangyl *@date: 2016.11.23 */ #include &amp;lt;iostream&amp;gt; #include &amp;lt;string.h&amp;gt; #include &amp;lt;sys/types.h&amp;gt; #include &amp;lt;sys/socket.h&amp;gt; #include &amp;lt;netinet/in.h&amp;gt; #include &amp;lt;arpa/inet.h&amp;gt; //for htonl() and htons() #include &amp;lt;unistd.h&amp;gt; #include &amp;lt;fcntl.h&amp;gt; #include &amp;lt;sys/epoll.h&amp;gt; #include &amp;lt;signal.h&amp;gt; //for signal() #include &amp;lt;pthread.h&amp;gt; #include &amp;lt;semaphore.h&amp;gt; #include &amp;lt;list&amp;gt; #include &amp;lt;errno.h&amp;gt; #include &amp;lt;time.h&amp;gt; #include &amp;lt;sstream&amp;gt; #include &amp;lt;iomanip&amp;gt; //for std::setw()/setfill() #include &amp;lt;stdlib.h&amp;gt; #define WORKER_THREAD_NUM 5 #define min(a, b) ((a &amp;lt;= b) ? (a) : (b)) int g_epollfd = 0; bool g_bStop = false; int g_listenfd = 0; pthread_t g_acceptthreadid = 0; pthread_t g_threadid[WORKER_THREAD_NUM] = { 0 }; pthread_cond_t g_acceptcond; pthread_mutex_t g_acceptmutex; pthread_cond_t g_cond /*= PTHREAD_COND_INITIALIZER*/; pthread_mutex_t g_mutex /*= PTHREAD_MUTEX_INITIALIZER*/; pthread_mutex_t g_clientmutex; std::list&amp;lt;int&amp;gt; g_listClients; void prog_exit(int signo) { ::signal(SIGINT, SIG_IGN); //::signal(SIGKILL, SIG_IGN);//该信号不能被阻塞、处理或者忽略 ::signal(SIGTERM, SIG_IGN); std::cout &amp;lt;&amp;lt; &amp;#34;program recv signal &amp;#34; &amp;lt;&amp;lt; signo &amp;lt;&amp;lt; &amp;#34; to exit.</description>
    </item>
    
    <item>
      <title>业务数据处理一定要单独开线程吗</title>
      <link>https://haokiu.com/blog/d7e436585f754029be5279a858049912/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/d7e436585f754029be5279a858049912/</guid>
      <description>业务数据处理一定要单独开线程吗 在 《one thread one loop 思想》一文我们介绍了一个 loop 的主要结构一般如下所示：
while (!m_bQuitFlag) { epoll_or_select_func(); handle_io_events(); handle_other_things(); } 对于一些业务逻辑处理比较简单、不会太耗时的应用来说，handle_io_events() 方法除了收发数据也可以直接用来直接做业务的处理，即其结构如下：
void handle_io_events() { //收发数据 recv_or_send_data(); //解包并处理数据 decode_packages_and_process(); } 其中 recv_or_send_data() 方法中调用 send/recv API 进行实际的网络数据收发。以收数据为例，收完数据存入接收缓冲区后，接下来进行解包处理，然后进行业务处理，例如一个登陆数据包，其业务就是验证登陆的账户密码是否正确、记录其登陆行为等等。从程序函数调用堆栈来看，这些业务处理逻辑其实是直接在网络收发数据线程中处理的。我的意思是：网络线程调用 handle_io_events() 方法，handle_io_events() 方法调用 decode_packages_and_process() 方法，decode_packages_and_process() 方法做具体的业务逻辑处理。
需要注意的是，为了让网络层与业务层脱耦，网络层中通常会提供一些回调函数的接口，这些回调函数我们将其指向具体的业务处理函数。以 libevent 网络库的用法为例：
int main(int argc, char **argv) { struct event_base *base; struct evconnlistener *listener; struct event *signal_event; struct sockaddr_in sin; base = event_base_new(); memset(&amp;amp;sin, 0, sizeof(sin)); sin.sin_family = AF_INET; sin.sin_port = htons(PORT); //listener_cb是我们自定义回调函数 listener = evconnlistener_new_bind(base, listener_cb, (void *)base, LEV_OPT_REUSEABLE|LEV_OPT_CLOSE_ON_FREE, -1, (struct sockaddr*)&amp;amp;sin, sizeof(sin)); if (!listener) { fprintf(stderr, &amp;#34;Could not create a listener!\n&amp;#34;); return 1; } //signal_cb是我们自定义回调函数 signal_event = evsignal_new(base, SIGINT, signal_cb, (void *)base); if (!</description>
    </item>
    
    <item>
      <title>主线程与工作线程的分工</title>
      <link>https://haokiu.com/blog/450c6c7995774bec88a383c0ce41cfdc/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/450c6c7995774bec88a383c0ce41cfdc/</guid>
      <description>主线程与工作线程的分工 服务器端为了能流畅处理多个客户端链接，一般在某个线程A里面accept新的客户端连接并生成新连接的socket fd，然后将这些新连接的socketfd给另外开的数个工作线程B1、B2、B3、B4，这些工作线程处理这些新连接上的网络IO事件（即收发数据），同时，还处理系统中的另外一些事务。这里我们将线程A称为主线程，B1、B2、B3、B4等称为工作线程。工作线程的代码框架一般如下：
while (!m_bQuit) { epoll_or_select_func(); handle_io_events(); handle_other_things(); } 在epoll_or_select_func()中通过select()或者poll/epoll()去检测socket fd上的io事件，若存在这些事件则下一步handle_io_events()来处理这些事件（收发数据），做完之后可能还要做一些系统其他的任务，即调用handle_other_things()。
这样做有三个好处：
线程A只需要处理新连接的到来即可，不用处理网络IO事件。由于网络IO事件处理一般相对比较慢，如果在线程A里面既处理新连接又处理网络IO，则可能由于线程忙于处理IO事件，而无法及时处理客户端的新连接，这是很不好的。
线程A接收的新连接，可以根据一定的负载均衡原则将新的socket fd分配给工作线程。常用的算法，比如round robin，即轮询机制，即，假设不考虑中途有连接断开的情况，一个新连接来了分配给B1，又来一个分配给B2，再来一个分配给B3，再来一个分配给B4。如此反复，也就是说线程A记录了各个工作线程上的socket fd数量，这样可以最大化地来平衡资源，避免一些工作线程“忙死”，另外一些工作线程“闲死”的现象。
即使工作线程不满载的情况下，也可以让工作线程做其他的事情。比如现在有四个工作线程，但只有三个连接。那么线程B4就可以在handle_other_thing()做一些其他事情。
下面讨论一个很重要的效率问题：
在上述while循环里面，epoll_or_selec_func()中的epoll_wait/poll/select等函数一般设置了一个超时时间。如果设置超时时间为0，那么在没有任何网络IO时间和其他任务处理的情况下，这些工作线程实际上会空转，白白地浪费cpu时间片。如果设置的超时时间大于0，在没有网络IO时间的情况，epoll_wait/poll/select仍然要挂起指定时间才能返回，导致handle_other_thing()不能及时执行，影响其他任务不能及时处理，也就是说其他任务一旦产生，其处理起来具有一定的延时性。这样也不好。那如何解决该问题呢？
其实我们想达到的效果是，如果没有网络IO时间和其他任务要处理，那么这些工作线程最好直接挂起而不是空转；如果有其他任务要处理，这些工作线程要立刻能处理这些任务而不是在epoll_wait/poll/selec挂起指定时间后才开始处理这些任务。
我们采取如下方法来解决该问题，以linux为例，不管epoll_fd上有没有文件描述符fd，我们都给它绑定一个默认的fd，这个fd被称为唤醒fd。当我们需要处理其他任务的时候，向这个唤醒fd上随便写入1个字节的，这样这个fd立即就变成可读的了，epoll_wait()/poll()/select()函数立即被唤醒，并返回，接下来马上就能执行handle_other_thing()，其他任务得到处理。反之，没有其他任务也没有网络IO事件时，epoll_or_select_func()就挂在那里什么也不做。
这个唤醒fd，在linux平台上可以通过以下几种方法实现：
管道pipe，创建一个管道，将管道绑定到epoll_fd上。需要时，向管道一端写入一个字节，工作线程立即被唤醒。
linux 2.6新增的eventfd：
int eventfd(unsigned int initval, int flags); 步骤也是一样，将生成的eventfd绑定到epoll_fd上。需要时，向这个eventfd上写入一个字节，工作线程立即被唤醒。
第三种方法最方便。即linux特有的socketpair，socketpair是一对相互连接的socket，相当于服务器端和客户端的两个端点，每一端都可以读写数据。 int socketpair(int domain, int type, int protocol, int sv[2]); 调用这个函数返回的两个socket句柄就是sv[0]，和sv[1]，在一个其中任何一个写入字节，在另外一个收取字节。
将收取的字节的socket绑定到epoll_fd上。需要时，向另外一个写入的socket上写入一个字节，工作线程立即被唤醒。如果是使用socketpair，那么domain参数一定要设置成AFX_UNIX。
由于在windows，select函数只支持检测socket这一种fd，所以Windows上一般只能用方法3的原理。而且需要手动创建两个socket，然后一个连接另外一个，将读取的那一段绑定到select的fd上去。这在写跨两个平台代码时，需要注意的地方。</description>
    </item>
    
    <item>
      <title>写给那些傻傻想做服务器开发的朋友</title>
      <link>https://haokiu.com/blog/7f969a868ee54e84982aa97c89e7cdbd/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/7f969a868ee54e84982aa97c89e7cdbd/</guid>
      <description>写给那些傻傻想做服务器开发的朋友 很久以前看过一篇标题为《写给那些傻傻的，想做服务器开发的应届生》文章，无意中看到知乎上也对这篇文章进行了激烈的讨论。下面谈谈我的看法。
写在前面的话 我在七八年前就看过这篇文章，那个时候我还是一名学生，它深深地影响了我学生时代以及后来的人生轨迹。(所以原文绝对不是首次发表于2015年，我猜想可能是后来的作者2015年修改了原作者的一些内容，并增加了一些自己的东西，让它&amp;quot;与时俱进&amp;quot;)。我学生时代深受这篇文章的影响，以至于我印象中的服务器开发的样子和地位就是这篇文章中所描述的。
我的工作经历 我毕业的时候，一心想做出Windows C/C++客户端开发，当时为了做这个开发放弃了我熟悉的flash编程和web开发，当然薪资也是比较低的。做了几年Windows客户端后，我毅然以一定的代价转到了linux服务器开发。到今天为止，大致做过股票资讯、交易系统、游戏服务器、即时通讯系统和直播类型的服务器，架构的能力也由最初的千人到后来的百万在线。我从不后悔我当初转行服务器开发，甚至很庆幸当初的抉择，然而我可能更喜欢的还是客户端开发。
《写给那些傻傻的，想做服务器开发的应届生》一文中的有些观点，根据我的经历，我不敢赞同，或者说我的感受与之大相径庭。
加班的情况 首先说下加班的情况，不管是大公司还是小公司，由于现在的各种测试、预警机制、监控策略和公司发布流程的不断完善，一个月内经常为各种服务器bug、和应急的情况加班的现状已经大为改善不少，当然偶尔发版或者赶项目加班还是有的，不过一个月的频率也就那么一两次。如果你们团队频繁地为了修正紧急bug、解决服务器稳定性问题，那么你们真要好好考虑你们的方法是不是有问题了。
服务器开发与轮子 其次，服务器开发，不仅仅如文中所说的，利用或者组装各种轮子。一个稳定的服务器架构，必须是建立在设计师良好的基础知识和见多识广的经验基础上，即使是使用现有的轮子，也是对这个轮子足够熟悉的基础上，才能让轮子最大地适用自己的公司的业务。也就是说，服务器核心项目人员虽然不一定要造轮子，但一定要具备造轮子的能力。开源的东西好用是好用，但是要么不出问题，一旦出问题往往很难修改。我们去年做类似“冲顶大会”、“百万英雄”这类直播答题应用，由于这类游戏是从美国HQ刮过来的风，国内各大公司为了迅速抢占市场与用户，都想着要比别人早点做出来上线，所以我们公司当时deadline压得比较紧。我们那个时候，最不想看到的人就是项目经理，天天跟着我们后面催项目的进度。项目进度紧不说，另外还有一个技术挑战，由于节目比较火热，同一个房间里面可能会达到百万人同时在线，而这百万人可能同时都会发弹幕消息。假设某个时刻，房间里面有n个人，某个人发一条消息，其他n-1个人收到，服务器需要推送n-1次。如果n个人同时发消息，那么服务器同一时间就要推送n*n，如果n等于1百万的时候，那么单秒的数据量将非常恐怖，这个是我们需要解决的一个技术难题，解决目标是最少延迟的情况下，弹幕最多的送达率；另外一个难题就是，保证出题和答案不能有太多的延时（小于1秒），并在用户给出答案后，服务器能够迅速统计出答案结果并应答客户端。（没办法，所以此时主持人的作用就发挥了，万一延迟太厉害，主持人可以和观众各种唠嗑，当然这是下下策，如果频繁出现这种情况，领导的脸色肯定也不好看，我们做技术的脸上也没有光彩。）那段时间基本上是周六周日都要加班，甚至连周末都可能要到凌晨才能回去。注意：我把这段经历并没有放在上面的关于服务器开发是否频繁地加班的栏目下，这里我想说明的并不是服务器开发要经常加班，我想说的是，如果你平常只会用轮子，而不注重基础内功的修养，这种场景你是很难应对的，首先是单机服务性能要做到极致，其次是多个服务之间的高效配合。很多人可能觉得这种场景也不难，甚至有的人号称单机服务就能解决，这些都是站着说话不腰疼了。像熊猫tv的“冲顶大会”和西瓜视频的“百万英雄”前几次的答题活动中，也出现了服务中断或者题目延迟厉害，甚至“百万英雄”还出现过一次因技术问题答题活动被迫延期的事故。
技术与产品思维 接着说下，技术和产品方面的，服务器开发与客户端开发的思维方式和理念其实是不一样的，如果说客户端产品是一个产品的脸面，那么服务器端就是产品的灵魂。这里可能比喻有点不恰当，与客户端开发相比，优秀的服务器开发应该尽量在单机服务上的性能做到极致，必须尽量利用少的资源给尽可能多的客户端服务（在资源总量有限的情况下，你为单个客户端服务使用的资源越少，你才可能为越多的客户服务）。而服务器开发必须有条不紊地处理与每个客户端的交互，不能纠结或把资源花费在某一个客户端上。但是客户端不一样，客户端只需要管理好自己的一亩三分地就可以了，而且客户端的大多数逻辑和细节在界面（UI）逻辑上。但是我不赞成文中作者所说的客户端代码比服务器代码少很多，相反，我经历过的项目，都是客户度代码比服务器代码多很多。因为客户端代码往往有大量的界面逻辑，如果服务器端没有UI的话，其核心除了网路通信部分，剩下的就是各种业务逻辑（包括存储逻辑，也就是业务逻辑服务器和客户端都有，但是客户端还有界面逻辑）。而从开发团队的人数配比上来说，一般单个端（比如pc、安卓、ios中的一端）的人数要小于服务器开发人员的数量，因为一般一个高级客户端开发，往往可以一个人搞定一个客户端，但是一般很少有一个高级服务器开发可以单独搞定一套服务开发的。（说的是通常情形，请不要走极端）。服务器开发的核心字眼体现在“服务”上，如何为客户端提供稳定的、高效的服务，这是关键的地方。这里“稳定”也包括容灾容错。大凡有一定规模的用户群体的产品，如果服务器不稳定，那后果将是灾难性的，试想QQ或者微信服务器中断一两个小时，后果会怎样？而客户端更侧重的就是产品的细节、用户的体验，当然尽管有些用户体验可能是由服务器端决定的，但是最终还是由客户端反映出来。我不赞同文章中说，客户端更能积累除了技术以外的其他知识，服务器开发也一样的，不管是客户端还是服务器，只有具有产品思维的开发才是好的开发，而功能的设计与规划服务器端的开发在时间点上一般先于客户端开发的。而具体的功能点，也是需要服务器开发人员与产品人员乃至客户沟通的。
薪资方面 最后说下，薪资方面。一般大于两年且同样的工作年限的服务器开发人员要比客户端开发人员高至少三分之一左右。当然不排除一些非常优秀的客户端开发人员可能不在这个规则内。
结语 总结起来，选择了哪条路就选择了什么样的生活。做服务器开发的可以在高并发、高可用方向进一步努力，而做客户端开发可以在用户体验、设计细节方面下功夫。不管怎样，都是我们想要的生活，那里倾洒了我们的汗水，也收获了我们自己的成就感。</description>
    </item>
    
    <item>
      <title>如何设计断线自动重连机制</title>
      <link>https://haokiu.com/blog/1469709fbebd462cb012819cdfb07156/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1469709fbebd462cb012819cdfb07156/</guid>
      <description>如何设计断线自动重连机制 在有连接依赖关系的服务与服务之间，或客户端与服务器之间，无论是出于方便使用、降低运维成本、提高工作效率（服务与服务之间），还是优化用户体验（客户端与服务器之间）自动重连机制通常都是一个非常重要的功能。
情景一 对于一组服务之间，如果其中一些服务（主动连接方，下文以 A 代称）需要与另外一些服务（被连接方，下文以 B 代称）建立 TCP 长连接，如果 A 没有自动连接 B 的功能，那么在部署或者测试这些服务的时候，必须先启动 B，再启动 A，因为一旦先启动 A，A 此时去尝试连接 B（由于 B 还没有启动）会失败，之后 A 再也不会去连接 B了（即使随后 B 被启动了），从而导致整个系统不能正常工作。这是缺点一。
情景二 即使部署或测试的时候，先启动了 B，再启动 A，A 与 B 之间的连接在运行期间内，可能由于网络波动等原因导致 A 与 B 之间连接断开，之后整个系统也不能再正常工作了。这是缺点二。
情景三 如果我们想升级 B，更新完程序后，重启 B，也必须重启 A。如果这种依赖链比较长（例如 A 连接 B，B 连接 C，C 连接 D，D 连接 E，等等），那么更新某个程序的效率和成本会非常高。这是缺点三。
情景四 对于客户端软件来说，如果因为用户的网络短暂故障导致客户端与服务器失去连接，等网络恢复后，较好的用户体验是客户端能检测到用户网络变化后，自动与服务器重连，以便用户能及时收到最新的消息。
以上四个情景说明了断线自动重连功能的重要性，那如何去设计好的断线重连机制呢？
重连本身的功能开发很简单，其实就是调用 socket 函数 connect 函数，不断去“重试”。这里的“重试”我使用了双引号，是为了说明重试的技巧非常有讲究：
对于服务器端程序，例如 A 连接 B，如果连接不上，整个系统将无法工作，那么我们开发 A 服务时，重连的逻辑可以很简单，即 A 一旦发现与 B 断开了连接，就立即尝试与 B 重新连接，如果连接不上，隔一段时间再重试（一般设置为 3 秒或 5 秒即可），一直到连接成功为止。当然，期间可以不断发送报警邮件或者持续输出错误日志，来引起开发或者运维人员的尽快干预，以便尽早排查和解决连接不上的原因。 对于客户端软件，以上做法也是可以的，但是不是最优的。客户端所处的网络环境比服务器程序所处的网络环境一般要恶劣的多，等间隔的定时去重连，一般作用不大（例如用户拔掉了网线）。因此，对于客户端软件，一般出现断线，会尝试去重连，如果连接不上，会隔个比前一次时间更长的时间间隔去重连，例如这个时间间隔可以是 2 秒、4 秒、8 秒、16秒等等。但是，这样也存在一个问题，随着重连次数的变多，重连的时间间隔会越来越大（当然，你也可以设置一个最大重连时间间隔，之后恢复到之前较小的时间间隔）。如果网络此时已经恢复（例如用户重新插上网线），我们的程序需要等待一个很长的时间间隔（如 16 秒）才能恢复连接，这同样不利于用户体验。一般情况下，如果网络发生波动，我们的程序可以检测网络状态，如果网络状态恢复正常此时应该立即进行一次重连，而不是一成不变地按照设置的时间间隔去重连。 操作系统提供了检测网络状态变化的 API 函数，例如对于 Windows 可以使用 IsNetworkAlive() 函数去检测，对于 Android，网络变化时会发送消息类型是 WifiManager.NETWORK_STATE_CHANGED_ACTION 的广播通知。
另外，还需要注意的是，如果客户端网络断开，一般会在界面某个地方显式地告诉用户当前连接状态，并提醒当前正在进行断线重连，且应该有一个可以让用户放弃断线重连或者立即进行一次断线重连的功能。
综上所述，总结起来，对于服务器程序之间的重连可以设计成等时间间隔的定时重连，对于客户端程序要结合依次放大重连时间间隔、网络状态变化立即重连或用户主动发起重连这三个因素来设计。
不需要重连的情形 不需要重连一般有以下情形：
用户使用客户端主动放弃重连；
因为一些业务上的规定，禁止客户端重连；
举个例子，如果某个系统同一时刻同一个账户只允许登陆一个，某个账户在机器 A 上登陆，此时接着又在机器 B 上登陆，此时 A 将被服务器踢下线，那么此时 A 客户端的逻辑就应该禁止自动重连。</description>
    </item>
    
    <item>
      <title>实例：一个服务器程序的架构介绍</title>
      <link>https://haokiu.com/blog/f6db032966024846bbd5dbc28868bb17/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/f6db032966024846bbd5dbc28868bb17/</guid>
      <description>实例：一个服务器程序的架构介绍 本文将介绍我曾经做过的一个项目的服务器架构和服务器编程的一些重要细节。
一、程序运行环境 操作系统：Centos 7.0
编译器：gcc/g++ 4.8.3、cmake 2.8.11
mysql数据库：5.5.47
项目代码管理工具：Visual Studio 2013
一、程序结构 该程序总共有 17 个线程，其中分为 9 个数据库工作线程 D 和一个日志线程 L，6 个普通工作线程 W，一个主线程 M。（以下会用这些字母来代指这些线程）
（一）、数据库工作线程的用途 9 个数据库工作线程在线程启动之初，与 mysql 建立连接，也就是说每个线程都与 mysql 保持一路连接，共 9 个数据库连接。
每个数据库工作线程同时存在两个任务队列，第一个队列 A 存放需要执行数据库增删查改操作的任务 sqlTask，第二个队列 B 存放 sqlTask 执行完成后的结果。sqlTask 执行完成后立即放入结果队列中，因而结果队列中任务也是一个个的需要执行的任务。大致伪代码如下：
void db_thread_func() { while (!m_bExit) { if (NULL != (pTask = m_sqlTask.Pop())) { //从m_sqlTask中取出的任务先执行完成后，pTask将携带结果数据 pTask-&amp;gt;Execute(); //得到结果后，立刻将该任务放入结果任务队列 m_resultTask.Push(pTask); continue; } sleep(1000); }//end while-loop } 现在的问题来了：
任务队列 A 中的任务从何而来，目前只有消费者，没有生产者，那么生产者是谁？ 任务队列 B 中的任务将去何方，目前只有生产者没有消费者。 这两个问题先放一会儿，等到后面我再来回答。
（二）工作线程和主线程 在介绍主线程和工作线程具体做什么时，我们介绍下服务器编程中常常抽象出来的几个概念（这里以 tcp 连接为例）：
TcpServer 即 Tcp 服务，服务器需要绑定ip地址和端口号，并在该端口号上侦听客户端的连接（往往由一个成员变量 TcpListener 来管理侦听细节）。所以一个 TcpServer 要做的就是这些工作。除此之外，每当有新连接到来时，TcpServer 需要接收新连接，当多个新连接存在时，TcpServer 需要有条不紊地管理这些连接：连接的建立、断开等，即产生和管理下文中说的 TcpConnection 对象。 一个连接对应一个 TcpConnection 对象，TcpConnection 对象管理着这个连接的一些信息：如连接状态、本端和对端的 ip 地址和端口号等。 数据通道对象 Channel，Channel 记录了 socket 的句柄，因而是一个连接上执行数据收发的真正执行者，Channel 对象一般作为 TcpConnection 的成员变量。 TcpSession 对象，是将 Channel 收取的数据进行解包，或者对准备好的数据进行装包，并传给 Channel 发送。 归纳起来：一个 TcpServer 依靠 TcpListener 对新连接的侦听和处理，依靠 TcpConnection 对象对连接上的数据进行管理，TcpConnection 实际依靠 Channel 对数据进行收发，依靠 TcpSession 对数据进行装包和解包。也就是说一个 TcpServer 存在一个 TcpListener，对应多个 TcpConnection，有几个TcpConnection 就有几个 TcpSession，同时也就有几个 Channel。</description>
    </item>
    
    <item>
      <title>心跳包机制设计详解</title>
      <link>https://haokiu.com/blog/82046162d4f74d3b9745ef1e8f8cdf57/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/82046162d4f74d3b9745ef1e8f8cdf57/</guid>
      <description>心跳包机制设计详解 存在下面两种情形：
情形一：一个客户端连接服务器以后，如果长期没有和服务器有数据来往，可能会被防火墙程序关闭连接，有时候我们并不想要被关闭连接。例如，对于一个即时通讯软件，如果服务器没有消息时，我们确实不会和服务器有任何数据交换，但是如果连接被关闭了，有新消息来时，我们再也没法收到了，这就违背了“即时通讯”的设计要求。
情形二：通常情况下，服务器与某个客户端一般不是位于同一个网络，其之间可能经过数个路由器和交换机，如果其中某个必经路由器或者交换器出现了故障，并且一段时间内没有恢复，导致这之间的链路不再畅通，而此时服务器与客户端之间也没有数据进行交换，由于 TCP 连接是状态机，对于这种情况，无论是客户端或者服务器都无法感知与对方的连接是否正常，这类连接我们一般称之为“死链”。
情形一中的应用场景要求必须保持客户端与服务器之间的连接正常，就是我们通常所说的“保活“。如上文所述，当服务器与客户端一定时间内没有有效业务数据来往时，我们只需要给对端发送心跳包即可实现保活。
情形二中的死链，只要我们此时任意一端给对端发送一个数据包即可检测链路是否正常，这类数据包我们也称之为”心跳包”，这种操作我们称之为“心跳检测”。顾名思义，如果一个人没有心跳了，可能已经死亡了；一个连接长时间没有正常数据来往，也没有心跳包来往，就可以认为这个连接已经不存在，为了节约服务器连接资源，我们可以通过关闭 socket，回收连接资源。
根据上面的分析，让我再强调一下，心跳检测一般有两个作用：
保活 检测死链 TCP keepalive 选项 操作系统的 TCP/IP 协议栈其实提供了这个的功能，即 keepalive 选项。在 Linux 操作系统中，我们可以通过代码启用一个 socket 的心跳检测（即每隔一定时间间隔发送一个心跳检测包给对端），代码如下：
//on 是 1 表示打开 keepalive 选项，为 0 表示关闭，0 是默认值 int on = 1; setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, &amp;amp;on, sizeof(on)); 但是，即使开启了这个选项，这个选项默认发送心跳检测数据包的时间间隔是 7200 秒（2 小时），这时间间隔实在是太长了，不具有实用性。
我们可以通过继续设置 keepalive 相关的三个选项来改变这个时间间隔，它们分别是 TCP_KEEPIDLE、TCP_KEEPINTVL 和 TCP_KEEPCNT，示例代码如下：
//发送 keepalive 报文的时间间隔 int val = 7200; setsockopt(fd, IPPROTO_TCP, TCP_KEEPIDLE, &amp;amp;val, sizeof(val)); //两次重试报文的时间间隔 int interval = 75; setsockopt(fd, IPPROTO_TCP, TCP_KEEPINTVL, &amp;amp;interval, sizeof(interval)); int cnt = 9; setsockopt(fd, IPPROTO_TCP, TCP_KEEPCNT, &amp;amp;cnt, sizeof(cnt)); TCP_KEEPIDLE 选项设置了发送 keepalive 报文的时间间隔，发送时如果对端回复 ACK。则本端 TCP 协议栈认为该连接依然存活，继续等 7200 秒后再发送 keepalive 报文；如果对端回复 RESET，说明对端进程已经重启，本端的应用程序应该关闭该连接。
如果对端没有任何回复，则本端做重试，如果重试 9 次（TCP_KEEPCNT 值）（前后重试间隔为 75 秒（TCP_KEEPINTVL 值））仍然不可达，则向应用程序返回 ETIMEOUT（无任何应答）或 EHOST 错误信息。</description>
    </item>
    
    <item>
      <title>日志系统的设计</title>
      <link>https://haokiu.com/blog/1549ab1669fe40dda14c41a84df83415/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1549ab1669fe40dda14c41a84df83415/</guid>
      <description>日志系统的设计 为什么需要日志 实际的软件项目产出都有一个流程，即先开发、测试，再发布生产，由于人的因素，既然是软件产品就不可能百分百没有 bug 或者逻辑错误，对于已经发布到生产的项目，一旦某个时刻产生非预期的结果，我们就需要去定位和排查问题。但是一般正式的生产环境的服务器或者产品是不允许开发人员通过附加调试器去排查问题的，主要有如下可能原因：
在很多互联网企业，开发部门、测试部分和产品运维部门是分工明确的，软件产品一旦发布到生产环境以后，将全部交由运维部门人员去管理和维护，而原来开发此产品的开发人员不再拥有相关的操作程序的权限。 对于已经上了生产环境的服务，其数据和程序稳定性是公司的核心产值所在，一般不敢或不允许被开发人员随意调试或者操作，以免造成损失。 发布到生产环境的服务，一般为了让程序执行效率更高、文件体积更小，都是去掉调试符号后的版本，不方便也不利于调试。 既然我们无法通过调试器去调试，这个时候为了跟踪和回忆当时的程序行为进而定位问题，我们就需要日志系统。
退一步说，即使在开发或者测试环境，我们可以把程序附加到调试器上去调试，但是对于一些特定的程序行为，我们无法通过设置断点，让程序在某个时刻暂停下来进行调试。例如，对于某些网络通信功能，如果暂停时间过长（相对于某些程序逻辑来说），通信的对端可能由于彼端没有在规定时间内响应而断开连接，导致程序逻辑无法进入我们想要的执行流中去；再例如，对于一些高频操作（如心跳包、定时器、界面绘制下的某些高频重复行为），可能在少量次数下无法触发我们想要的行为，而通过断点的暂停方式，我们不得不重复操作几十次、上百次甚至更多，这样排查问题效率是非常低下的。对于这类操作，我们可以通过打印日志，将当时的程序行为上下文现场记录下来，然后从日志系统中找到某次不正常的行为的上下文信息。这也是日志的另外一个作用。
本文将从技术和业务上两个方面来介绍日志系统相关的设计与开发，所谓技术上，就是如何从程序开发的角度设计一款功能强大、性能优越、使用方便的日志系统；而业务上，是指我们在使用日志系统时，应该去记录哪些行为和数据，既简洁、不啰嗦，又方便需要时快速准确地定位到问题。
日志系统的技术上的实现 日志的最初的原型即将程序运行的状态打印出来，对于 C/C++ 这门语言来说，即可以利用 printf、std::cout 等控制台输出函数，将日志信息输出到控制台，这类简单的情形我们不在此过多赘述。
对于商业项目，为了方便排查问题，我们一般不将日志写到控制台，而是输出到文件或者数据库系统。不管哪一种，其思路基本上一致，我们这里以写文件为例来详细介绍。
同步写日志 所谓同步写日志，指的是在输出日志的地方，将日志即时写入到文件中去。根据笔者的经验，这种设计广泛地用于相当多的的客户端软件。笔者曾从事过数年的客户端开发（包括 PC、安卓软件），设计过一些功能复杂的金融客户端产品，在这些系统中采用的就是这种同步写日志的方式。之所以使用这种方式其主要原因就是设计简单，而又不会影响用户使用体验。说到这里读者可能有这样一个疑问：一般的客户端软件，一般存在界面，而界面部分所属的逻辑就是程序的主线程，如果采取这种同步写日志的方式，当写日志时，写文件是磁盘 IO 操作，相比较程序其他部分是 CPU 操作，前者要慢很多，这样势必造成CPU等待，进而导致主线程“卡”在写文件处，进而造成界面卡顿，从而导致用户使用软件的体验不好。读者的这种顾虑确实是存在的。但是，很多时候我们不用担心这种问题，主要有两个原因：
对于客户端程序，即使在主线程（UI 线程）中同步写文件，其单次或者几次磁盘操作累加时间，与人（用户）的可感知时间相比，也是非常小的，也就是说用户根本感觉不到这种同步写文件造成的延迟。当然，这里也给您一个提醒就是，如果在 UI 线程里面写日志，尤其是在一些高频操作中（如 Windows 的界面绘制消息 WM_PAINT 处理逻辑中），一定要控制写日志的长度和次数，否则就会因频繁写文件或一次写入数据过大而对界面造成卡顿。 客户端程序除了 UI 线程，还有其他与界面无关的工作线程，在这些线程中直接写文件，一般不会对用户的体验产生什么影响。 说了这么多，我们给出一个具体的例子。
日志类的 .h 文件
/** *@desc: IULog.h *@author: zhangyl *@date: 2014.12.25 */ #ifndef __LOG_H__ #define __LOG_H__ enum LOG_LEVEL { LOG_LEVEL_INFO, LOG_LEVEL_WARNING, LOG_LEVEL_ERROR }; //注意：如果打印的日志信息中有中文，则格式化字符串要用_T()宏包裹起来， #define LOG_INFO(...) CIULog::Log(LOG_LEVEL_INFO, __FUNCSIG__,__LINE__, __VA_ARGS__) #define LOG_WARNING(...) CIULog::Log(LOG_LEVEL_WARNING, __FUNCSIG__, __LINE__,__VA_ARGS__) #define LOG_ERROR(...) CIULog::Log(LOG_LEVEL_ERROR, __FUNCSIG__,__LINE__, __VA_ARGS__) class CIULog { public: static bool Init(bool bToFile, bool bTruncateLongLog, PCTSTR pszLogFileName); static void Uninit(); static void SetLevel(LOG_LEVEL nLevel); //不输出线程ID号和所在函数签名、行号 static bool Log(long nLevel, PCTSTR pszFmt, .</description>
    </item>
    
    <item>
      <title>给工作 4 年迷茫的程序员们的一点建议</title>
      <link>https://haokiu.com/blog/049d41c798c54956b4c2b094aacec413/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/049d41c798c54956b4c2b094aacec413/</guid>
      <description>给工作 4 年迷茫的程序员们的一点建议 有公众号读者在后台向我提问：
JAVA 程序员，4 年了，迷茫了，希望由前辈可以给指出一个技术路线5年左右程序员必须要掌握的知识技能树?
工作了很久了，对于目前自己的技术程度不满意，但是不知道如何梳理。学习一些技术是不知道是否有用。希望前辈可以指点迷津。不以年限轮英雄，希望可以给出您的见解。修改一次。。。。。。项目设计都是我来做。。。数据库设计也是我来做。。。我的意思是。。感觉目前自己的知识储备不足以支撑我架构以及设计。。求个知识树。。。。
以下是我的回答：
先举两个真实的例子。
例子一： 前两天我在给我们部门做服务器网络故障排查经验分享时，我问了一个问题关于 java.io.DataOutputStream 的问题，如果从一个 socket 输出流中读取数据，如果当前流中没有数据，读方法是否会阻塞。我又问，假如阻塞，会阻塞多久？我们如何避免这个问题。很多人回答不上来，更不用说，Java 中的 AIO、NIO 的使用细节了。
例子二： 我归纳一下，情况大致如下： 有不少朋友通过我的公众号『高性能服务器开发』中的『职业指导』模块找到我，来意大致是：做 java 开发工作了三五年了，月收入不到二万，现在因为人到中年，经济压力比较大; 但是工作上只能做做模块，写写业务代码，所以即使跳槽也不会拿到满意的薪资，所以只好维持现状(但又特别苦闷、迷茫)。
我来说一下我的观点，说的现实一点，题主所谓的迷茫其实因知识能力的不足导致的成就感、收入水平与日益增长的工作年限的矛盾。
越是高薪的职位，其对人的要求也越高。诸如上面的例子，工作有几年的 java 开发者，连 jdk 中基本的输入输出流的细节都搞不清楚，一问到就是各种摇头，然后说各种 java 框架，这样的开发者其实并不合格，因为他们离开了框架就啥也做不了，那么在工作安排上这样的人不天天也业务代码，谁来写呢？(核心的技术框架是不能让他们写的，由于基础水平不扎实，写出来的框架稳定性和性能会不好)。说的悲观一点，这样的开发者公司是从来不缺的，铁打的营盘，流水的兵，走了再招一批罢了，这也就是所谓的千军易得一将难求，我们要努力做将才乃至帅才，而不是小兵。
在面试某些 java 开发者时，我问的比较多的一个问题就是，java 多线程之间的同步技术有哪些，然后不少面试者就病急乱投医了，甚至连 ConcurrentHashMap 都说上了。这也是典型的基础概念模糊不清，ConcurrentHashMap 是一个线程安全性容器，但绝不是一个线程同步技术。
再比如问面试者 java.lang.Object 有哪些常用方法时，不少面试者能说出来的也不多。
我举这些例子并不是为了要教大家具体的 java 知识，而是为了说明基础知识的重要性。如果你的java基础足够好(熟悉 jdk 的常用类，知道常用接口的各种坑和注意事项)，那么开发一个东西时即使不用框架你也能顺畅地写出来。这样的人才具备进一步发展的潜力。退一步说，不管多么复杂的java框架，都是基于jdk那些类库的。你jdk的基础知识都学不好，我不相信那些上层框架你能搞的透彻。
说一千道一万，核心的还是基础知识不扎实的问题。就和刘备当年成就帝业一样，诸葛亮给的策略就是先谋取荆州，再进军西蜀，最后三分天下。同理jdk的基础知识就是你应该要首先谋取的“荆州”，进一步的各种框架、架构设计是你的“蜀地”。基础不牢，想其他的东西都是好高骛远，不切实际。最后日复一日，年复一年，在恨自己生不逢时，领导不是伯乐的嗟叹中蹉跎了岁月。
对于上面这个注重基础的问题上，实际情形中，我遇到三种人。
第一类：意识不到基础知识的重要性，这类人就不提了。
第二类，意识到基础知识的重要性，但是总是在各种理由和借口中麻痹自己，温水煮青蛙把自己“煮死”。很多咨询我的人，也是这种情况，说什么自己工作忙，家庭琐事多。我其实不想多说啥，为失败找借口的人太多，为成功找方法的人太少。你工作五年了，每个月抽一天时间来补一下基础，你现在都不是这样了，这个时间也抽不出来？自我麻痹而已。这类人其实是有想法没啥行动。
第三类，意识到基础的重要性，同时在各种闲暇时间去补充，去积累。这样的人学的最快，最后达到的高度也很高（当然收入也不菲）。
扎实的基础知识 + 见多识广的框架经验，让你在职场上变得无可替代，这才是你的核心竞争力。答案可能有点跑题了，但是我觉得先解决思想上的问题，行动上就容易许多了。
如果你想和我聊聊职业上的困惑，可以在『高性能服务器开发』公众号后台回复关键字『职业指导』，我们可以针对性地聊一聊。</description>
    </item>
    
    <item>
      <title>聊聊技术人员的常见的职业问题</title>
      <link>https://haokiu.com/blog/1908cdb9f5c747b996136e3b3e408b8d/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1908cdb9f5c747b996136e3b3e408b8d/</guid>
      <description>聊聊技术人员的常见的职业问题 由于时间有限，很多读者提出的问题，不能一一解答，因此这篇文章，来系统地就各类型的读者遇到的一些常见职业问题回答一下：
Q1 应届生如何选择自己的第一份工作？
Q2 作为一个程序员，是进入大厂好，还是进入创业公司好？
Q3 我专科（或二本）毕业，学历不行，如何进大厂工作？
Q4 我非科班出身，如何进大厂工作？
Q5 有没有人能分享一下大厂的面经？
A1 答案点 这里 和 这里。
Q6 我工作了几年，技术不行，如何提高？
Q7 我非科班出身，应该看哪些书才能补上计算机专业的基础？
Q8 我想成为一名技术高手，应该如何提高？
Q9 天天写业务代码，如何能有机会做一些底层的设计和开发？
A2 答案点 这里。
Q10 服务器端开发与前端开发有什么差别？哪个发展潜力好一点？哪个薪资高一点？
A3 答案点 这里。
Q11 我想成为一名 C++ 程序员，该如何入门、进阶以及升华？
Q12 C++ 后端开发需要掌握哪些东西？
Q13 C++ 面试应该准备哪些东西？
A4 答案点 这里 和 这里 以及 这里。
Q15 我是一名 Java 程序员，天天增删改查数据库，我如何实质性的提高自己？
Q16 Java 技术栈的所谓的基础在哪里？
A5 答案点 这里。
Q17 程序员真的很难找女朋友吗？
Q18 大厂加班严重，在大厂上班的程序员真的没有女朋友吗？
A6 这是一个忧伤的话题，答案戳 这里 和 这里 以及 **这里****。
Q20 如何通过技术面试来确定面试官的职级？如何确定自己面试职位所对应的职级？
A7 答案看 这里。
Q21 技术面试中，面试官问我薪资，我该不该告诉他？
Q22 技术面试过了，如何和 HR 谈薪水？
Q23 我报了一个薪水之后，HR 爽快的答应了，我是不是报低了？我能不能再找他们提高一点？
A8 答案看 这里。
Q24 年薪五十万的技术岗位做些什么工作？
Q25 做技术岗位如何年薪五十万呢？
Q26 年薪五十万的程序员是不是真的头发很少？
A9 别害怕，答案戳 这里。
Q26 年终奖是如何发的？什么时候发？
Q27 年终奖还没发，我跳槽是不是就没有年终奖了？</description>
    </item>
    
    <item>
      <title>职业规划</title>
      <link>https://haokiu.com/blog/01f6fc4ce7c54057a2379aab6b98843f/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/01f6fc4ce7c54057a2379aab6b98843f/</guid>
      <description>职业规划 给工作 4 年迷茫的程序员们的一点建议
聊聊技术人员的常见的职业问题
写给那些傻傻想做服务器开发的朋友</description>
    </item>
    
    <item>
      <title>自我提升与开源代码</title>
      <link>https://haokiu.com/blog/e50a72b7fb4e47a9904a05621e5b692f/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/e50a72b7fb4e47a9904a05621e5b692f/</guid>
      <description>自我提升与开源代码 2020 年好好读一读开源代码吧 </description>
    </item>
    
    <item>
      <title>错误码系统的设计</title>
      <link>https://haokiu.com/blog/32ba3bce20124dd380cdde0bba6ef5b9/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/32ba3bce20124dd380cdde0bba6ef5b9/</guid>
      <description>错误码系统的设计 本文介绍服务器开发中一组服务中错误码系统的设计理念与实践，如果读者从来没想过或者没接触过这种设计理念，建议认真体会一下这种设计思路的优点。
错误码的作用 读者如果有使用过中国电信的宽带账号上网的经历，如果我们登陆不成功，一般服务器会返回一个错误码，如651、678。然后，我们打中国电信的客服电话，客服会询问我们错误码是多少，通过错误码他们的技术人员就大致知道了错误原因；并且通过错误码，他们就知道到底是电信的服务器问题还是宽带用户自己的设备或者操作问题，如果是用户自己的问题，他们一般会尝试教用户如何操作，而不是冒然就派遣维修人员上门，这样不仅能尽早解决问题同时也节约了人力成本。
再举另外一个例子，我们日常浏览网页，当Web服务器正常返回页面时，状态码一般是200(OK)，而当页面不存在时，错误码一般是404，另外像503等错误都是比较常见的。
通过以上两个例子，读者应该能明白，对于服务器系统来说，设计一套好的错误码是非常有必要的，可以在用户请求出问题时迅速定位并解决问题。具体包括两个方面：
可以迅速定位是用户“输入”问题还是服务器自身的问题。 所谓的用户“输入”问题，是指用户的不当操作，这里的“用户的不当操作”可能是因为客户端软件本身的逻辑错误或漏洞，也可能是使用客户端的人的非法操作，而客户端软件在设计上因为考虑不周而缺乏有效性校验，这两类情形都可能会产生非法的数据，并且直接发给服务器。一个好的服务端系统不能假设客户端的请求数据一定是合法的，必须对传过来的数据做有效性校验。服务器没有义务一定给非法的请求做出应答，因此请求的最终结果是服务器不应答或给客户端不想要的应答。
以上面的例子为例，宽带用户输入了无效的用户名或者密码造成服务器拒绝访问；用户在浏览器中输入了一个无效的网址等。这类错误，都是需要用户自己解决或者用户可以自己解决的。如果错误码可以反映出这类错误，那么在实际服务器运维的过程中，当用户反馈这一类故障时，我们通过服务器内部产生的错误码或者应答给客户端的错误码，准确快速地确定问题原因。如果是用户非法请求造成的，可以让用户自行解决。注意，这里的“用户”，可以代指人，也可以代指使用某个服务器的所有下游服务和客户端。
可以快速定位哪个步骤或哪个服务出了问题。
对于单个服务，假设收到某个“客户端”请求时，需要经历多个步骤才能完成，而这中间任何一个步骤都可能出问题，在不同步骤出错时返回不同的错误码，那么就可以知道是哪个步骤出了问题。
其次，一般稍微复杂一点的系统，都不是单个服务，往往是由一组服务构成。如果将错误码分段，每个服务的错误码都有各自的范围，那么通过错误码，我们也能准确地知道是哪个服务出了问题。
错误码系统设计实践 前面介绍了太多的理论知识，我们来看一个具体的例子。假设如下一个“智能邮件系统”，其结构如下所示：
上图中的服务**“智能邮件坐席站点”和“配置站点”是客户端，”智能邮件操作综合接口“和”邮件配置服务“**是对客户端提供服务的前置服务，这两个前置服务后面还依赖后面的数个服务。由于这里我们要说明的是技术问题，而不是业务问题，所以具体每个服务作何用途这里就不一一介绍了。在这个系统中，当客户端得到前置服务某个不正确应答时，会得到一个错误码，我们按以下规则来设计错误码：
服务名称 正值错误码范围 负值错误码范围 智能邮件综合操作接口 100~199 -100~-199 ES数据同步服务 200~299 -200~-299 邮件配置服务 300~399 -300~-399 邮件基础服务 400~499 -400~-499 我们在设计这套系统时，做如下规定：
所有的正值错误码表示所在服务的上游服务发来的请求不满足业务要求。举个例子，假设某次智能邮件坐席站点客户端得到了一个错误码101，我们可以先确定错误产生的服务器是智能邮件综合操作接口服务；其次，产生该错误的原因是智能邮件坐席站点客户端发送给智能邮件综合操作接口服务的请求不满足要求，通过这个错误码我们甚至可以进一步确定发送的请求哪里不符合要求。如我们可以这样定义： 100 用户名不存在
101 密码无效
102 发送的邮件收件人非法
103 邮件正文含有非法字符
其他从略，此处就不一一列举了。
所有的负值错误码表示程序内部错误。如： -100 数据库操作错误
-101 网络错误
-102 内存分配失败
-103 ES数据同步服务连接不上
其他从略，此处就不一一列举了。
对负值错误码的特殊处理 通过前面的介绍，读者应该能看出正值错误码与负值错误码的区别，即正值错误码一般是由请求服务的客户产生，如果出现这样的错误，应该由客户自己去解决问题；而负值错误码，则一般是服务内部产生的错误。因此，如果是正值错误码，错误码和错误信息一般可以直接返回给客户端；而对于负值错误，我们一般只将错误码返回给客户端，而不带上具体的错误信息，这也是读者在使用很多软件产品时，经常会得到“网络错误”这类万能错误提示。也就是说对于负值错误码的错误信息，我们可以统一显示成“网络错误”或者其他比较友好的错误提示。
这样做的原因有二：
客户端即使拿到这样的错误信息，也不能对排查和解决问题提供任何帮助，因为这些错误是程序内部错误或者bug。 这类错误有可能是企业内部的设计缺陷，直接暴露给客户，除了让客户对企业的技术实力产生质疑以外，没有任何其他正面效应。 而之所以带上错误码，是为了方便内部排查和定位问题。当然，现在的企业服务，内部也有大量监控系统，可能也不会再暴露这样的错误码了。
扩展 上文介绍了利用错误码的分段来定位问题的技术思想，其实不仅仅是错误码可以分段，我们在开发一组服务时，业务类型也可以通过编号来分段，这样通过业务号就能知道归属哪个服务了。
如果读者以前没接触过这种设计思想，希望可以好好的思考和体会一下。</description>
    </item>
    
    <item>
      <title>非阻塞模式下 send 和 recv 函数的返回值</title>
      <link>https://haokiu.com/blog/7050b3d426bf44b29c25c3d30ae77006/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/7050b3d426bf44b29c25c3d30ae77006/</guid>
      <description>非阻塞模式下 send 和 recv 函数的返回值 我们来总结一下 send 和 recv 函数的各种返回值意义：
返回值 n 返回值含义 大于 0 成功发送 n 个字节 0 对端关闭连接 小于 0（ -1） 出错或者被信号中断或者对端 TCP 窗口太小数据发不出去（send）或者当前网卡缓冲区已无数据可收（recv） 我们来逐一介绍下这三种情况：
返回值大于 0
对于 send 和 recv 函数返回值大于 0，表示发送或接收多少字节，需要注意的是，在这种情形下，我们一定要判断下 send 函数的返回值是不是我们期望发送的缓冲区长度，而不是简单判断其返回值大于 0。举个例子：
1int n = send(socket, buf, buf_length, 0)； 2if (n &amp;gt; 0) 3{ 4 printf(&amp;#34;send data successfully\n&amp;#34;); 5} 很多新手会写出上述代码，虽然返回值 n 大于 0，但是实际情形下，由于对端的 TCP 窗口可能因为缺少一部分字节就满了，所以返回值 n 的值可能在 (0, buf_length] 之间，当 0 &amp;lt; n &amp;lt; buf_length 时，虽然此时 send 函数是调用成功了，但是业务上并不算正确，因为有部分数据并没发出去。你可能在一次测试中测不出 n 不等于 buf_length 的情况，但是不代表实际中不存在。所以，建议要么认为返回值 n 等于 buf_length 才认为正确，要么在一个循环中调用 send 函数，如果数据一次性发不完，记录偏移量，下一次从偏移量处接着发，直到全部发送完为止。
1 //推荐的方式一 2 int n = send(socket, buf, buf_length, 0)； 3 if (n == buf_length) 4 { 5 printf(&amp;#34;send data successfully\n&amp;#34;); 6 } 1//推荐的方式二：在一个循环里面根据偏移量发送数据 2bool SendData(const char* buf , int buf_length) 3{ 4 //已发送的字节数目 5 int sent_bytes = 0; 6 int ret = 0; 7 while (true) 8 { 9 ret = send(m_hSocket, buf + sent_bytes, buf_length - sent_bytes, 0); 10 if (nRet == -1) 11 { 12 if (errno == EWOULDBLOCK) 13 { 14 //严谨的做法，这里如果发不出去，应该缓存尚未发出去的数据，后面介绍 15 break; 16 } 17 else if (errno == EINTR) 18 continue; 19 else 20 return false; 21 } 22 else if (nRet == 0) 23 { 24 return false; 25 } 26 27 sent_bytes += ret; 28 if (sent_bytes == buf_length) 29 break; 30 31 //稍稍降低 CPU 的使用率 32 usleep(1); 33 } 34 35 return true; 36} 返回值等于 0</description>
    </item>
    
    <item>
      <title>高性能服务器架构设计总结</title>
      <link>https://haokiu.com/blog/67da065d5a2a4917804acd4875f0f0a8/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/67da065d5a2a4917804acd4875f0f0a8/</guid>
      <description>高性能服务器架构设计总结 系列目录
第01篇 主线程与工作线程的分工
第02篇 Reactor模式
第03篇 一个服务器程序的架构介绍
第04篇 如何将socket设置为非阻塞模式
第05篇 如何编写高性能日志
第06篇 关于网络编程的一些实用技巧和细节
第07篇 开源一款即时通讯软件的源码
第08篇 高性能服务器架构设计总结1
第09篇 高性能服务器架构设计总结2
第10篇 高性能服务器架构设计总结3
第11篇 高性能服务器架构设计总结4
这篇文章算是对这个系列的一个系统性地总结。我们将介绍服务器的开发，并从多个方面探究如何开发一款高性能高并发的服务器程序。
所谓高性能就是服务器能流畅地处理各个客户端的连接并尽量低延迟地应答客户端的请求；所谓高并发，指的是服务器可以同时支持多的客户端连接，且这些客户端在连接期间内会不断与服务器有数据来往。
这篇文章将从两个方面来介绍，一个是服务器的框架，即单个服务器程序的代码组织结构；另外一个是一组服务程序的如何组织与交互，即架构。注意：本文以下内容中的客户端是相对概念，指的是连接到当前讨论的服务程序的终端，所以这里的客户端既可能是我们传统意义上的客户端程序，也可能是连接该服务的其他服务器程序。
一、框架篇 按上面介绍的思路，我们先从单个服务程序的组织结构开始介绍。
（一）、网络通信 既然是服务器程序肯定会涉及到网络通信部分，那么服务器程序的网络通信模块要解决哪些问题？
笔者认为至少要解决以下问题：
如何检测有新客户端连接？ 如何接受客户端连接？ 如何检测客户端是否有数据发来？ 如何收取客户端发来的数据？ 如何检测连接异常？发现连接异常之后，如何处理？ 如何给客户端发送数据？ 如何在给客户端发完数据后关闭连接？ 稍微有点网络基础的人，都能回答上面说的其中几个问题，比如接收客户端连接用socket API的accept函数，收取客户端数据用recv函数，给客户端发送数据用send函数，检测客户端是否有新连接和客户端是否有新数据可以用IO multiplexing技术（IO复用）的select、poll、epoll等socket API。确实是这样的，这些基础的socket API构成了服务器网络通信的地基，不管网络通信框架设计的如何巧妙，都是在这些基础的socket API的基础上构建的。但是如何巧妙地组织这些基础的socket API，才是问题的关键。我们说服务器很高效，支持高并发，实际上只是一个技术实现手段，不管怎样从软件开发的角度来讲无非就是一个程序而已，所以，只要程序能最大可能地满足“尽量减少等待”就是高效。也就是说高效不是“忙的忙死，闲的闲死”，而是大家都可以闲着，但是如果有活要干，大家尽量一起干，而不是一部分忙着依次做事情123456789，另外一部分闲在那里无所事事。说的可能有点抽象，下面我们来举一些例子具体来说明一下。
比如默认recv函数如果没有数据的时候，线程就会阻塞在那里； 默认send函数，如果tcp窗口不是足够大，数据发不出去也会阻塞在那里； connect函数默认连接另外一端的时候，也会阻塞在那里； 又或者是给对端发送一份数据，需要等待对端回答，如果对方一直不应答，当前线程就阻塞在这里。 以上都不是高效服务器的开发思维方式，因为上面的例子都不满足“尽量减少等待”的原则，为什么一定要等待呢？有没用一种方法，这些过程不需要等待，最好是不仅不需要等待，而且这些事情完成之后能通知我。这样在这些本来用于等待的cpu时间片内，我就可以做一些其他的事情。有，也就是我们下文要讨论的IO Multiplexing技术（IO复用技术）。
（二）、几种IO复用机制的比较 目前windows系统支持select、WSAAsyncSelect、WSAEventSelect、完成端口（IOCP），linux系统支持select、poll、epoll。这里我们不具体介绍每个具体的函数的用法，我们来讨论一点深层次的东西，以上列举的API函数可以分为两个层次：
层次一 select和poll 层次二 WSAAsyncSelect、WSAEventSelect、完成端口（IOCP）、epoll 为什么这么分呢？先来介绍第一层次，select和poll函数本质上还是在一定时间内主动去查询socket句柄（可能是一个也可能是多个）上是否有事件，比如可读事件，可写事件或者出错事件，也就是说我们还是需要每隔一段时间内去主动去做这些检测，如果在这段时间内检测出一些事件来，我们这段时间就算没白花，但是倘若这段时间内没有事件呢？我们只能是做无用功了，说白了，还是在浪费时间，因为假如一个服务器有多个连接，在cpu时间片有限的情况下，我们花费了一定的时间检测了一部分socket连接，却发现它们什么事件都没有，而在这段时间内我们却有一些事情需要处理，那我们为什么要花时间去做这个检测呢？把这个时间用在做我们需要做的事情不好吗？所以对于服务器程序来说，要想高效，我们应该尽量避免花费时间主动去查询一些socket是否有事件，而是等这些socket有事件的时候告诉我们去处理。这也就是层次二的各个函数做的事情，它们实际相当于变主动查询是否有事件为当有事件时，系统会告诉我们，此时我们再去处理，也就是“好钢用在刀刃”上了。只不过层次二的函数通知我们的方式是各不相同，比如WSAAsyncSelect是利用windows消息队列的事件机制来通知我们设定的窗口过程函数，IOCP是利用GetQueuedCompletionStatus返回正确的状态，epoll是epoll_wait函数返回而已。
比如connect函数连接另外一端，如果连接socket是异步的，那么connect虽然不能立刻连接完成，但是也是会立刻返回，无需等待，等连接完成之后，WSAAsyncSelect会返回FD_CONNECT事件告诉我们连接成功，epoll会产生EPOLLOUT事件，我们也能知道连接完成。甚至socket有数据可读时，WSAAsyncSelect产生FD_READ事件，epoll产生EPOLLIN事件，等等。
所以有了上面的讨论，我们就可以得到网络通信检测可读可写或者出错事件的正确姿势。这是我这里提出的第二个原则：尽量减少做无用功的时间。这个在服务程序资源够用的情况下可能体现不出来什么优势，但是如果有大量的任务要处理，个人觉得这个可能带来无用。
（三）、检测网络事件的正确姿势 根据上面的介绍，第一，为了避免无意义的等待时间，第二，不采用主动查询各个socket的事件，而是采用等待操作系统通知我们有事件的状态的策略。我们的**socket都要设置成异步的。**在此基础上我们回到栏目（一）中提到的七个问题：
如何检测有新客户端连接？
如何接受客户端连接？
默认accept函数会阻塞在那里，如果epoll检测到侦听socket上有EPOLLIN事件，或者WSAAsyncSelect检测到有FD_ACCEPT事件，那么就表明此时有新连接到来，这个时候调用accept函数，就不会阻塞了。当然产生的新socket你应该也设置成非阻塞的。这样我们就能在新socket上收发数据了。
如何检测客户端是否有数据发来？
如何收取客户端发来的数据？
同理，我们也应该在socket上有可读事件的时候才去收取数据，这样我们调用recv或者read函数时不用等待。
至于一次性收多少数据好呢？
我们可以根据自己的需求来决定，甚至你可以在一个循环里面反复recv或者read，对于非阻塞模式的socket，如果没有数据了，recv或者read也会立刻返回，错误码EWOULDBLOCK会表明当前已经没有数据了。示例：
1bool CIUSocket::Recv() 2{ 3 int nRet = 0; 4 5 while(true) 6 { 7 char buff[512]; 8 nRet = ::recv(m_hSocket, buff, 512, 0); 9 //一旦出现错误就立刻关闭Socket 10 if(nRet == SOCKET_ERROR) 11 { 12 if (::WSAGetLastError() == WSAEWOULDBLOCK) 13 break; 14 else 15 return false; 16 } 17 else if(nRet &amp;lt; 1) 18 return false; 19 20 m_strRecvBuf.</description>
    </item>
    
    <item>
      <title>高性能服务器框架设计</title>
      <link>https://haokiu.com/blog/95e6ea6c39e345bf8177b77fb2d24548/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/95e6ea6c39e345bf8177b77fb2d24548/</guid>
      <description>高性能服务器框架设计 主线程与工作线程的分工
Reactor模式
实例：一个服务器程序的架构介绍
错误码系统的设计
日志系统的设计
如何设计断线自动重连机制
心跳包机制设计详解
业务数据处理一定要单独开线程吗
C++ 高性能服务器网络框架设计细节</description>
    </item>
    
    <item>
      <title>01 TeamTalk介绍</title>
      <link>https://haokiu.com/blog/8c53924ed21041948dff215384cdb81d/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/8c53924ed21041948dff215384cdb81d/</guid>
      <description>01 TeamTalk介绍 TeamTalk是蘑菇街开源的一款企业内部用的即时通讯软件（Enterprise IM），类似腾讯的RTX。网上也有很多的介绍，我这里也有写几遍关于这款产品的“流水账”，一方面对自己这段时间的阅读其代码做个总结，尽量做个既能宏观上从全局来介绍，又不缺少很多有价值的微观细节，另一方面如果对于作为读者的您有些许帮助，那就善莫大焉了。
项目地址github：https://github.com/baloonwj/TeamTalk
如果您打不开github，请移步至百度网盘下载：http://pan.baidu.com/s/1slbJVf3
关于即时通讯软件本身，我相信使用过QQ的都知道是啥。
下载项目解压后目录结构是这样的：
这款即时通讯软件分为服务器端（linux）、pc端、web端、mac端和两个移动端（ios和安卓），源码中使用了大量的开源技术（用项目作者的话说，就是“拿来主义”）。例如通信协议使用了google protobuf，服务器端使用了内存数据库redis，pc端界面库使用的duilib，pc端的日志系统使用的是YAOLOG库、cximage、jsoncpp库等等。在接下来各个端的源码分析中，我们将会深入和细致地介绍。
下一篇我将介绍首先介绍服务器端的程序的编译与部署。</description>
    </item>
    
    <item>
      <title>02 服务器端的程序的编译与部署</title>
      <link>https://haokiu.com/blog/23af895a60264bfe949c3636689d3f83/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/23af895a60264bfe949c3636689d3f83/</guid>
      <description>02 服务器端的程序的编译与部署 这篇我们来介绍下TeamTalk服务器端的编译与部署，部署文档在auto_setup下，这里我们只介绍下服务器程序的编译与部署，不包括管理后台的部署，其部署方法在auto_setup\im_server文件夹，其实按官方介绍只要找一台干净的linux系统运行一下auto_setup\im_server\setup.sh程序就可以了，会自动安装mysql（maridb，mysql被oracle收购后，分为两个分支，继续开源的分支改名叫maridb）、nginx和redis。我们暂且不部署web端，所以不需要安装nginx。我这里是手动安装了mysql和redis。然后启动mysql和redis，并手动建立如下库和表。库名叫teamtalk，需要建立以下这些表：
--后台管理员表 --password 密码,规则md5(md5(passwd)+salt) CREATE TABLE `IMAdmin` ( `id` mediumint(6) unsigned NOT NULL AUTO_INCREMENT, `uname` varchar(40) NOT NULL COMMENT &amp;#39;用户名&amp;#39;, `pwd` char(32) NOT NULL COMMENT &amp;#39;经过md5加密的密码&amp;#39;, `status` tinyint(2) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;用户状态 0 :正常 1:删除 可扩展&amp;#39;, `created` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;创建时间&amp;#39;, `updated` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;更新时间&amp;#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 --存储语音地址 CREATE TABLE `IMAudio` ( `id` int(11) NOT NULL AUTO_INCREMENT, `fromId` int(11) unsigned NOT NULL COMMENT &amp;#39;发送者Id&amp;#39;, `toId` int(11) unsigned NOT NULL COMMENT &amp;#39;接收者Id&amp;#39;, `path` varchar(255) COLLATE utf8mb4_bin DEFAULT &amp;#39;&amp;#39; COMMENT &amp;#39;语音存储的地址&amp;#39;, `size` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;文件大小&amp;#39;, `duration` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;语音时长&amp;#39;, `created` int(11) unsigned NOT NULL COMMENT &amp;#39;创建时间&amp;#39;, PRIMARY KEY (`id`), KEY `idx_fromId_toId` (`fromId`,`toId`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --存储部门信息 CREATE TABLE `IMDepart` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &amp;#39;部门id&amp;#39;, `departName` varchar(64) COLLATE utf8mb4_bin NOT NULL DEFAULT &amp;#39;&amp;#39; COMMENT &amp;#39;部门名称&amp;#39;, `priority` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;显示优先级,相同优先级按拼音顺序排列&amp;#39;, `parentId` int(11) unsigned NOT NULL COMMENT &amp;#39;上级部门id&amp;#39;, `status` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;状态&amp;#39;, `created` int(11) unsigned NOT NULL COMMENT &amp;#39;创建时间&amp;#39;, `updated` int(11) unsigned NOT NULL COMMENT &amp;#39;更新时间&amp;#39;, PRIMARY KEY (`id`), KEY `idx_departName` (`departName`), KEY `idx_priority_status` (`priority`,`status`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --发现配置表 CREATE TABLE `IMDiscovery` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT &amp;#39;id&amp;#39;, `itemName` varchar(64) COLLATE utf8mb4_bin NOT NULL DEFAULT &amp;#39;&amp;#39; COMMENT &amp;#39;名称&amp;#39;, `itemUrl` varchar(64) COLLATE utf8mb4_bin NOT NULL DEFAULT &amp;#39;&amp;#39; COMMENT &amp;#39;URL&amp;#39;, `itemPriority` int(11) unsigned NOT NULL COMMENT &amp;#39;显示优先级&amp;#39;, `status` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;状态&amp;#39;, `created` int(11) unsigned NOT NULL COMMENT &amp;#39;创建时间&amp;#39;, `updated` int(11) unsigned NOT NULL COMMENT &amp;#39;更新时间&amp;#39;, PRIMARY KEY (`id`), KEY `idx_itemName` (`itemName`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --群组表 CREATE TABLE `IMGroup` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(256) COLLATE utf8mb4_bin NOT NULL DEFAULT &amp;#39;&amp;#39; COMMENT &amp;#39;群名称&amp;#39;, `avatar` varchar(256) COLLATE utf8mb4_bin NOT NULL DEFAULT &amp;#39;&amp;#39; COMMENT &amp;#39;群头像&amp;#39;, `creator` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;创建者用户id&amp;#39;, `type` tinyint(3) unsigned NOT NULL DEFAULT &amp;#39;1&amp;#39; COMMENT &amp;#39;群组类型，1-固定;2-临时群&amp;#39;, `userCnt` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;成员人数&amp;#39;, `status` tinyint(3) unsigned NOT NULL DEFAULT &amp;#39;1&amp;#39; COMMENT &amp;#39;是否删除,0-正常，1-删除&amp;#39;, `version` int(11) unsigned NOT NULL DEFAULT &amp;#39;1&amp;#39; COMMENT &amp;#39;群版本号&amp;#39;, `lastChated` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;最后聊天时间&amp;#39;, `created` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;创建时间&amp;#39;, `updated` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;更新时间&amp;#39;, PRIMARY KEY (`id`), KEY `idx_name` (`name`(191)), KEY `idx_creator` (`creator`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin COMMENT=&amp;#39;IM群信息&amp;#39; --群成员表 CREATE TABLE `IMGroupMember` ( `id` int(11) NOT NULL AUTO_INCREMENT, `groupId` int(11) unsigned NOT NULL COMMENT &amp;#39;群Id&amp;#39;, `userId` int(11) unsigned NOT NULL COMMENT &amp;#39;用户id&amp;#39;, `status` tinyint(4) unsigned NOT NULL DEFAULT &amp;#39;1&amp;#39; COMMENT &amp;#39;是否退出群，0-正常，1-已退出&amp;#39;, `created` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;创建时间&amp;#39;, `updated` int(11) unsigned NOT NULL DEFAULT &amp;#39;0&amp;#39; COMMENT &amp;#39;更新时间&amp;#39;, PRIMARY KEY (`id`), KEY `idx_groupId_userId_status` (`groupId`,`userId`,`status`), KEY `idx_userId_status_updated` (`userId`,`status`,`updated`), KEY `idx_groupId_updated` (`groupId`,`updated`) ) ENGINE=InnoDB AUTO_INCREMENT=68 DEFAULT CHARSET=utf8 COMMENT=&amp;#39;用户和群的关系表&amp;#39; --群消息表,x代表第几张表，目前做了分表有8张:0-7.</description>
    </item>
    
    <item>
      <title>03 服务器端的程序架构介绍</title>
      <link>https://haokiu.com/blog/74f8790b79af42ab856a668b8927b38a/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/74f8790b79af42ab856a668b8927b38a/</guid>
      <description>03 服务器端的程序架构介绍 通过上一节的编译与部署，我们会得到TeamTalk服务器端以下部署程序：
db_proxy_server file_server http_msg_server login_server msfs msg_server push_server router_server 这些服务构成的拓扑图如下：
各个服务程序的作用描述如下：
LoginServer (C++): 负载均衡服务器，分配一个负载小的MsgServer给客户端使用 MsgServer (C++): 消息服务器，提供客户端大部分信令处理功能，包括私人聊天、群组聊天等 RouteServer (C++): 路由服务器，为登录在不同MsgServer的用户提供消息转发功能 FileServer (C++): 文件服务器，提供客户端之间得文件传输服务，支持在线以及离线文件传输 MsfsServer (C++): 图片存储服务器，提供头像，图片传输中的图片存储服务 DBProxy (C++): 数据库代理服务器，提供mysql以及redis的访问服务，屏蔽其他服务器与mysql与redis的直接交互 HttpMsgServer(C++) :对外接口服务器，提供对外接口功能。（目前只是框架） PushServer(C++): 消息推送服务器，提供IOS系统消息推送。（IOS消息推送必须走apns） 注意：上图中并没有push_server和http_push_server。如果你不调试ios版本的客户端，可以暂且不启动push_server，另外http_push_server也可以暂不启动。
启动顺序：
一般来说，前端的服务会依赖后端的服务，所以一般先启动后端服务，再启动前端服务。建议按以下顺序启动服务：
1、启动db_proxy。 2、启动route_server，file_server，msfs 3、启动login_server 4、启动msg_server 那么我就按照服务端的启动顺序去讲解服务端的一个流程概述。 第一步:启动db_proxy后，db_proxy会去根据配置文件连接相应的MySQL实例，以及redis实例。 第二步:启动route_server,file_server,msfs后，各个服务端都会开始监听相应的端口。 第三步:启动login_server,login_server就开始监听相应的端口(8080)，等待客户端的连接，而分配一个负载相对较小的msg_server给客户端。 第四步:启动msg_server(端口8000)，msg_server启动后，会去主动连接route_server，login_server，db_proxy_server，会将自己的监听的端口信息注册到login_server去，同时在用户上线，下线的时候会将自己的负载情况汇报给login_server.
各个服务的端口号 (注意：如果出现部署完成后但是服务进程启动有问题或者只有部分服务进程启动了，请查看相应的log日志，请查看相应的log日志，请查看相应的log日志。)
服务 端口 login_server 8080/8008 msg_server 8000 db_proxy_server 10600 route_server 8200 http_msg_server 8400 file_server 8600/8601 服务网络通信框架介绍：
上面介绍的每一个服务都使用了相同的网络通信框架，该通信框架可以单独拿出来做为一个通用的网络通信框架。该网络框架是在一个循环里面不断地检测IO事件，然后对检测到的事件进行处理。流程如下：
使用IO复用技术（linux和windows平台用select、mac平台用kevent）分离网络IO。
对分离出来的网络IO进行操作，分为socket句柄可读、可写和出错三种情况。
当然再加上定时器事件，即检测一个定时器事件列表，如果有定时器到期，则执行该定时器事件。
整个框架的伪码大致如下：
while (running) { //处理定时器事件 _CheckTimer(); //IO multiplexing int n = select(socket集合, ...); //事件处理 **if** (某些socket可读) { pSocket-&amp;gt;OnRead(); } **if** (某些socket可写) { pSocket-&amp;gt;OnWrite(); } **if** (某些socket出错) { pSocket-&amp;gt;OnClose(); } } 处理定时器事件的代码如下：
void CEventDispatch::_CheckTimer() { uint64_t curr_tick = get_tick_count(); list&amp;lt;TimerItem*&amp;gt;::iterator it; for (it = m_timer_list.</description>
    </item>
    
    <item>
      <title>04 服务器端db_proxy_server源码分析</title>
      <link>https://haokiu.com/blog/5481b95ce7c64f8c99c98e3c59d74314/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/5481b95ce7c64f8c99c98e3c59d74314/</guid>
      <description>04 服务器端db_proxy_server源码分析 从这篇文章开始，我将详细地分析TeamTalk服务器端每一个服务的源码和架构设计。
这篇从db_proxy_server开始。db_proxy_server是TeamTalk服务器端最后端的程序，它连接着关系型数据库mysql和nosql内存数据库redis。其位置在整个服务架构中如图所示：
我们从db_proxy_server的main()函数开始，main()函数其实就是做了以下初始化工作，我整理成如下伪码：
int main() { //1. 初始化redis连接 //2. 初始化mysql连接 //3. 启动任务队列，用于处理任务 //4. 启动从mysql同步数据到redis工作 //5. 在端口10600上启动侦听，监听新连接 //6. 主线程进入循环，监听新连接的到来以及出来新连接上的数据收发 } 下面，我们将一一介绍以上步骤。
一、初始化redis连接 CacheManager* pCacheManager = CacheManager::getInstance(); CacheManager* CacheManager::getInstance() { if (!s_cache_manager) { s_cache_manager = new CacheManager(); if (s_cache_manager-&amp;gt;Init()) { delete s_cache_manager; s_cache_manager = NULL; } } return s_cache_manager; } int CacheManager::Init() { CConfigFileReader config_file(&amp;#34;dbproxyserver.conf&amp;#34;); //CacheInstances=unread,group_set,token,sync,group_member char* cache_instances = config_file.GetConfigName(&amp;#34;CacheInstances&amp;#34;); if (!cache_instances) { log(&amp;#34;not configure CacheIntance&amp;#34;); return 1; } char host[64]; char port[64]; char db[64]; char maxconncnt[64]; CStrExplode instances_name(cache_instances, &amp;#39;,&amp;#39;); for (uint32_t i = 0; i &amp;lt; instances_name.GetItemCnt(); i++) { char* pool_name = instances_name.GetItem(i); //printf(&amp;#34;%s&amp;#34;, pool_name); snprintf(host, 64, &amp;#34;%s_host&amp;#34;, pool_name); snprintf(port, 64, &amp;#34;%s_port&amp;#34;, pool_name); snprintf(db, 64, &amp;#34;%s_db&amp;#34;, pool_name); snprintf(maxconncnt, 64, &amp;#34;%s_maxconncnt&amp;#34;, pool_name); char* cache_host = config_file.</description>
    </item>
    
    <item>
      <title>05 服务器端msg_server源码分析</title>
      <link>https://haokiu.com/blog/27deab1b64f24c839058b60bd3826f79/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/27deab1b64f24c839058b60bd3826f79/</guid>
      <description>05 服务器端msg_server源码分析 在分析msg_server的源码之前，我们先简单地回顾一下msg_server在整个服务器系统中的位置和作用：
各个服务程序的作用描述如下：
LoginServer (C++): 负载均衡服务器，分配一个负载小的MsgServer给客户端使用 MsgServer (C++): 消息服务器，提供客户端大部分信令处理功能，包括私人聊天、群组聊天等 RouteServer (C++): 路由服务器，为登录在不同MsgServer的用户提供消息转发功能 FileServer (C++): 文件服务器，提供客户端之间得文件传输服务，支持在线以及离线文件传输 MsfsServer (C++): 图片存储服务器，提供头像，图片传输中的图片存储服务 DBProxy (C++): 数据库代理服务器，提供mysql以及redis的访问服务，屏蔽其他服务器与mysql与redis的直接交互 HttpMsgServer(C++) :对外接口服务器，提供对外接口功能。（目前只是框架） PushServer(C++): 消息推送服务器，提供IOS系统消息推送。（IOS消息推送必须走apns） 从上面的介绍中，我们可以看出TeamTalk是支持分布式部署的一套聊天服务器程序，通过分布式部署可以实现分流和支持高数量的用户同时在线。msg_server是整个服务体系的核心系统，可以部署多个，不同的用户可以登录不同的msg_server。这套体系有如下几大亮点：
login_server可以根据当前各个msg_server上在线用户数量，来决定一个新用户登录到哪个msg_server，从而实现了负载平衡；
route_server可以将登录在不同的msg_server上的用户的聊天消息发给目标用户；
通过单独的一个数据库操作服务器db_proxy_server，避免了msg_server直接操作数据库，将数据库操作的入口封装起来。
在前一篇文章《服务器端db_proxy_server源码分析》中，我介绍了每个服务如何接收连接、读取数据并解包、以及组装数据包发包的操作，这篇文章我将介绍作为客户端，一个服务如何连接另外一个服务。这里msg_server在启动时会同时连接db_proxy_server，login_server，file_server，route_server，push_server。在msg_server服务main函数里面有如下初始化调用：
//连接file_server init_file_serv_conn(file_server_list, file_server_count); //连接db_proxy_server init_db_serv_conn(db_server_list2, db_server_count2, concurrent_db_conn_cnt); //连接login_server init_login_serv_conn(login_server_list, login_server_count, ip_addr1, ip_addr2, listen_port, max_conn_cnt); //连接push_server init_route_serv_conn(route_server_list, route_server_count); //连接push_server init_push_serv_conn(push_server_list, push_server_count); 其中每个连接服务的流程都是一样的。我们这里以第一个连接file_server为例：
void init_file_serv_conn(serv_info_t* server_list, uint32_t server_count) { g_file_server_list = server_list; g_file_server_count = server_count; serv_init&amp;lt;CFileServConn&amp;gt;(g_file_server_list, g_file_server_count); netlib_register_timer(file_server_conn_timer_callback, NULL, 1000); s_file_handler = CFileHandler::getInstance(); } template &amp;lt;class T&amp;gt; void serv_init(serv_info_t* server_list, uint32_t server_count) { for (uint32_t i = 0; i &amp;lt; server_count; i++) { T* pConn = new T(); pConn-&amp;gt;Connect(server_list[i].server_ip.c_str(), server_list[i].server_port, i); server_list[i].</description>
    </item>
    
    <item>
      <title>06 服务器端login_server源码分析</title>
      <link>https://haokiu.com/blog/1866caff3acc4baeb8666ea706d7ba7d/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1866caff3acc4baeb8666ea706d7ba7d/</guid>
      <description>06 服务器端login_server源码分析 login_server从严格意义上来说，是一个登录分流器，所以名字起的有点名不符实。该服务根据已知的msg_server上的在线用户数量来返回告诉一个即将登录的用户登录哪个msg_server比较合适。关于其程序框架的非业务代码我们已经在前面的两篇文章《服务器端db_proxy_server源码分析》和《服务器端msg_server源码分析》中介绍过了。这篇文章主要介绍下其业务代码。
首先，程序初始化的时候，会初始化如下功能：
//1. 在8008端口监听客户端连接 //2. 在8100端口上监听msg_server的连接 //3. 在8080端口上监听客户端http连接 其中连接对象CLoginConn代表着login_server与msg_server之间的连接；而CHttpConn代表着与客户端的http连接。我们先来看CLoginConn对象，上一篇文章中也介绍了其业务代码主要在其HandlePdu()函数中，可以看到这路连接主要处理哪些数据包：
void CLoginConn::HandlePdu(CImPdu* pPdu) { switch (pPdu-&amp;gt;GetCommandId()) { case CID_OTHER_HEARTBEAT: break; case CID_OTHER_MSG_SERV_INFO: _HandleMsgServInfo(pPdu); break; case CID_OTHER_USER_CNT_UPDATE: _HandleUserCntUpdate(pPdu); break; case CID_LOGIN_REQ_MSGSERVER: _HandleMsgServRequest(pPdu); break; default: log(&amp;#34;wrong msg, cmd id=%d &amp;#34;, pPdu-&amp;gt;GetCommandId()); break; } } 命令号CID_OTHER_HEARTBEAT是与msg_server的心跳包。上一篇文章《服务器端msg_server源码分析》中介绍过，msg_server连上login_server后会立刻给login_server发一个数据包，该数据包里面含有该msg_server上的用户数量、最大可容纳的用户数量、自己的ip地址和端口号。
list&amp;lt;user_conn_t&amp;gt; user_conn_list; CImUserManager::GetInstance()-&amp;gt;GetUserConnCnt(&amp;amp;user_conn_list, cur_conn_cnt); char hostname[256] = {0}; gethostname(hostname, 256); IM::Server::IMMsgServInfo msg; msg.set_ip1(g_msg_server_ip_addr1); msg.set_ip2(g_msg_server_ip_addr2); msg.set_port(g_msg_server_port); msg.set_max_conn_cnt(g_max_conn_cnt); msg.set_cur_conn_cnt(cur_conn_cnt); msg.set_host_name(hostname); CImPdu pdu; pdu.SetPBMsg(&amp;amp;msg); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_MSG_SERV_INFO); SendPdu(&amp;amp;pdu); 命令号是CID_OTHER_MSG_SERV_INFO。我们来看下login_server如何处理这个命令的：
void CLoginConn::_HandleMsgServInfo(CImPdu* pPdu) { msg_serv_info_t* pMsgServInfo = new msg_serv_info_t; IM::Server::IMMsgServInfo msg; msg.ParseFromArray(pPdu-&amp;gt;GetBodyData(), pPdu-&amp;gt;GetBodyLength()); pMsgServInfo-&amp;gt;ip_addr1 = msg.ip1(); pMsgServInfo-&amp;gt;ip_addr2 = msg.ip2(); pMsgServInfo-&amp;gt;port = msg.port(); pMsgServInfo-&amp;gt;max_conn_cnt = msg.max_conn_cnt(); pMsgServInfo-&amp;gt;cur_conn_cnt = msg.cur_conn_cnt(); pMsgServInfo-&amp;gt;hostname = msg.host_name(); g_msg_serv_info.</description>
    </item>
    
    <item>
      <title>07 服务器端msfs源码分析</title>
      <link>https://haokiu.com/blog/0055f7fa607b4b2180cd0eb3924eff5c/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/0055f7fa607b4b2180cd0eb3924eff5c/</guid>
      <description>07 服务器端msfs源码分析 这篇文章是对TeamTalk服务程序msfs的源码和架构设计分析。msfs作用是用来接受teamtalk聊天中产生的聊天图片的上传和下载。还是老规矩，把该服务在整个架构中的位置图贴一下吧。
可以看到，msfs仅被客户端连接，客户端以http的方式来上传和下载聊天图片。
可能很多同学对http协议不是很熟悉，或者说一知半解。这里大致介绍一下http协议，http协议其实也是一种应用层协议，建立在tcp/ip层之上，其由包头和包体两部分组成（不一定要有包体），看个例子：
比如当我们用浏览器请求一个网址http://www.hootina.org/index.php，实际是浏览器给特定的服务器发送如下数据包，包头部分如下：
GET /index.php HTTP/1.1\r\n Host: www.hootina.org\r\n Connection: keep-alive\r\n Cache-Control: max-age=0\r\n Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,/;q=0.8\r\n User-Agent: Mozilla/5.0\r\n \r\n 这个包没有包体。
从上面我们可以看出一个http协议大致格式可以描述如下：
GET或Post请求方法 请求的资源路径 http协议版本号\r\n 字段名1：值1\r\n 字段名2：值2\r\n 字段名3：值3\r\n 字段名4：值4\r\n 字段名5：值5\r\n 字段名6：值6\r\n \r\n 也就是是http协议的头部是一行一行的，每一行以\r\n表示该行结束，最后多出一个空行以\r\n结束表示头部的结束。接下来就是包体的大小了（如果有的话，上文的例子没有包体）。一般get方法会将参数放在请求的资源路径后面，像这样
http://wwww.hootina.org/index.php?变量1=值1&amp;amp;变量2=值2&amp;amp;变量3=值3&amp;amp;变量4=值4
网址后面的问号表示参数开始，每一个参数与参数之间用&amp;amp;隔开
还有一种post的请求方法，这种数据就是将数据放在包体里面了，例如：
POST /otn/login/loginAysnSuggest HTTP/1.1\r\n Host: kyfw.12306.cn\r\n Connection: keep-alive\r\n Content-Length: 96\r\n Accept: */*\r\n Origin: https://kyfw.12306.cn\r\n X-Requested-With: XMLHttpRequest\r\n User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.75\r\n Content-Type: application/x-www-form-urlencoded; charset=UTF-8\r\n Referer: https://kyfw.12306.cn/otn/login/init\r\n Accept-Encoding: gzip, deflate, br\r\n Accept-Language: zh-CN,zh;q=0.8\r\n \r\n loginUserDTO.user_name=balloonwj%40qq.com&amp;amp;userDTO.password=xxxxgjqf&amp;amp;randCode=184%2C55%2C37%2C117 上述报文中loginUserDTO.user_name=balloonwj%40qq.com&amp;amp;userDTO.password=2032_scsgjqf&amp;amp;randCode=184%2C55%2C37%2C117 其实包体内容，这个包是我的一个12306买票软件发给12306服务器的报文。这里拿来做个例子。
因为对方收到http报文的时候，如果包体有内容，那么必须告诉对方包体有多大。这个最常用的就是通过包头的Content-Length字段来指定大小。上面的例子中Content-Length等于96，正好就是字符串 loginUserDTO.user_name=balloonwj%40qq.com&amp;amp;userDTO.password=xxxxgjqf&amp;amp;randCode=184%2C55%2C37%2C117 的长度，也就是包体的大小。
还有一种叫做http chunk的编码技术，通过对http包内容进行分块传输。这里就不介绍了（如果你感兴趣，可以私聊我）。
常见的对http协议有如下几个误解：
html文档的头就是http的头 这种认识是错误的，html文档的头部也是http数据包的包体的一部分。正确的http头是长的像上文介绍的那种。
关于http头Connection:keep-alive字段 一端指定了这个字段后，发http包给另外一端。这个选项只是一种建议性的选项，对端不一定必须采纳，对方也可能在实际实现时，将http连接设置为短连接，即不采纳这个字段的建议。
每个字段都是必须的吗？ 不是，大多数字段都不是必须的。但是特定的情况下，某些字段是必须的。比如，通过post发送的数据，就必须设置Content-Length。不然，收包的一端如何知道包体多大。又比如如果你的数据采取了gzip压缩格式，你就必须指定Accept-Encoding: gzip，然对方如何解包你的数据。
好了，http协议就暂且介绍这么多，下面回到正题上来说msfs的源码。
msfs在main函数里面做了如下初始化工作，伪码如下：
//1. 建立一个两个任务队列，分别处理http get请求和post请求 //2. 创建名称为000～255的文件夹，每个文件夹里面会有000～255个子目录，这些目录用于存放聊天图片 //3. 在8700端口上监听客户端连接 //4. 启动程序消息泵 第1点，建立任务队列我们前面系列的文章已经介绍过了。</description>
    </item>
    
    <item>
      <title>08 服务器端file_server源码分析</title>
      <link>https://haokiu.com/blog/c5f5c9828a6f472d9768cffc2f548784/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/c5f5c9828a6f472d9768cffc2f548784/</guid>
      <description>08 服务器端file_server源码分析 这篇文章我们来介绍file_server服务的功能和源码实现。TeamTalk支持离线在线文件和离线文件两种传送文件的方式。单纯地研究file_server的程序结构没多大意义，因为其程序结构和其他几个服务结构基本上一模一样，前面几篇文章已经介绍过了。 我们研究teamtalk的file_server是为了学习和借鉴teamtalk的文件传输功能实现思路，以内化为自己的知识，并加以应用。
所以这篇文章，我们将pc客户端的文件传输功能、msg_server转发消息、file_server处理文件数据三个方面结合起来一起介绍。
下面开始啦。
一、连接状况介绍
fileserver开始并不是和客户端连接的，客户端是按需连接file_server的。但是file_server与msg_server却是长连接。先启动file_server，再启动msg_server。msg_server初始化的时候，会去尝试连接file_server的8601端口。连接成功以后，会给file_server发送一个发包询问file_server侦听客户端连接的ip和端口号信息：
void CFileServConn::OnConfirm() { log(&amp;#34;connect to file server success &amp;#34;); m_bOpen = true; m_connect_time = get_tick_count(); g_file_server_list[m_serv_idx].reconnect_cnt = MIN_RECONNECT_CNT / 2; //连上file_server以后，给file_server发送获取ip地址的数据包 IM::Server::IMFileServerIPReq msg; CImPdu pdu; pdu.SetPBMsg(&amp;amp;msg); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_FILE_SERVER_IP_REQ); SendPdu(&amp;amp;pdu); } file_server收到该数据包后，将自己的侦听客户端连接的ip地址和端口号发包告诉msg_server：
void FileMsgServerConn::_HandleGetServerAddressReq(CImPdu* pPdu) { IM::Server::IMFileServerIPRsp msg; const std::list&amp;lt;IM::BaseDefine::IpAddr&amp;gt;&amp;amp; addrs = ConfigUtil::GetInstance()-&amp;gt;GetAddressList(); for (std::list&amp;lt;IM::BaseDefine::IpAddr&amp;gt;::const_iterator it=addrs.begin(); it!=addrs.end(); ++it) { IM::BaseDefine::IpAddr* addr = msg.add_ip_addr_list(); *addr = *it; log(&amp;#34;Upload file_client_conn addr info, ip=%s, port=%d&amp;#34;, addr-&amp;gt;ip().c_str(), addr-&amp;gt;port()); } SendMessageLite(this, SID_OTHER, CID_OTHER_FILE_SERVER_IP_RSP, pPdu-&amp;gt;GetSeqNum(), &amp;amp;msg); } 得到的信息是file_server侦听的ip地址和端口号，默认配置的端口号是8600。也就是说file_server的8600用于客户端连接，8601端口用于msg_server连接。这样，客户端需要传输文件（注意：不是聊天图片，聊天图片使用另外一个服务msfs进行传输），会先告诉msg_server它需要进行文件传输，msg_server收到消息后告诉客户端，你连file_server来传输文件吧，并把file_server的地址和端口号告诉客户端。客户端这个时候连接file_server进行文件传输。我们来具体看一看这个流程的细节信息：
客户端发包给msg_server说要进行文件发送 然后选择一个文件：
pc客户端发送文件逻辑：
//pc客户端代码(Modules工程SessionLayout.cpp) void SessionLayout::Notify(TNotifyUI&amp;amp; msg) { ... //省略无关代码 else if (msg.pSender == m_pBtnsendfile) //文件传输 { module::UserInfoEntity userInfo; if (!module::getUserListModule()-&amp;gt;getUserInfoBySId(m_sId, userInfo)) { LOG__(ERR, _T(&amp;#34;SendFile can&amp;#39;t find the sid&amp;#34;)); return; } CFileDialog	fileDlg(TRUE, NULL, NULL, OFN_HIDEREADONLY | OFN_FILEMUSTEXIST , _T(&amp;#34;文件|*.</description>
    </item>
    
    <item>
      <title>09 服务器端route_server源码分析</title>
      <link>https://haokiu.com/blog/d337b00514f346dcb055e1a411da83d8/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/d337b00514f346dcb055e1a411da83d8/</guid>
      <description>09 服务器端route_server源码分析 route_server的作用主要是用户不同msg_server之间消息路由，其框架部分和前面的服务类似，没有什么好说的。我们这里重点介绍下它的业务代码，也就是其路由细节：
void CRouteConn::HandlePdu(CImPdu* pPdu) { switch (pPdu-&amp;gt;GetCommandId()) { case CID_OTHER_HEARTBEAT: // do not take any action, heart beat only update m_last_recv_tick break; case CID_OTHER_ONLINE_USER_INFO: _HandleOnlineUserInfo( pPdu ); break; case CID_OTHER_USER_STATUS_UPDATE: _HandleUserStatusUpdate( pPdu ); break; case CID_OTHER_ROLE_SET: _HandleRoleSet( pPdu ); break; case CID_BUDDY_LIST_USERS_STATUS_REQUEST: _HandleUsersStatusRequest( pPdu ); break; case CID_MSG_DATA: case CID_SWITCH_P2P_CMD: case CID_MSG_READ_NOTIFY: case CID_OTHER_SERVER_KICK_USER: case CID_GROUP_CHANGE_MEMBER_NOTIFY: case CID_FILE_NOTIFY: case CID_BUDDY_LIST_REMOVE_SESSION_NOTIFY: _BroadcastMsg(pPdu, this); break; case CID_BUDDY_LIST_SIGN_INFO_CHANGED_NOTIFY: _BroadcastMsg(pPdu); break; default: log(&amp;#34;CRouteConn::HandlePdu, wrong cmd id: %d &amp;#34;, pPdu-&amp;gt;GetCommandId()); break; } } 上面是route_server处理的消息类型，我们逐一来介绍：
CID_OTHER_ONLINE_USER_INFO 这个消息是msg_server连接上route_server后告知route_server自己上面的用户登录情况。route_server处理后，只是简单地记录一下每个msg_server上的用户数量和用户id：
void CRouteConn::_HandleOnlineUserInfo(CImPdu* pPdu) { IM::Server::IMOnlineUserInfo msg; CHECK_PB_PARSE_MSG(msg.ParseFromArray(pPdu-&amp;gt;GetBodyData(), pPdu-&amp;gt;GetBodyLength())); uint32_t user_count = msg.user_stat_list_size(); log(&amp;#34;HandleOnlineUserInfo, user_cnt=%u &amp;#34;, user_count); for (uint32_t i = 0; i &amp;lt; user_count; i++) { IM::BaseDefine::ServerUserStat server_user_stat = msg.</description>
    </item>
    
    <item>
      <title>1 游戏服务器开发的基本体系与服务器端开发的一些建议</title>
      <link>https://haokiu.com/blog/867310d7f5a74f758c1745b3083cfcc8/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/867310d7f5a74f758c1745b3083cfcc8/</guid>
      <description>1 游戏服务器开发的基本体系与服务器端开发的一些建议 近年来，我身边的朋友有很多都从web转向了游戏开发。他们以前都没有做过游戏服务器开发，更谈不上什么经验，而从网上找的例子或游戏方面的知识，又是那么的少，那么的零散。当他们进入游戏公司时，显得一脸茫然。如果是大公司还好点，起码有人带带，能学点经验，但是有些人是直接进入了小公司，甚至这些小公司只有他一个后台。他们一肩扛起了公司的游戏后端的研发，也扛起了公司的成败。他们也非常尽力，他们也想把游戏的后端做好。可是就是因为没什么经验，刚开始时以为做游戏服务器和做web差不多，但是经过一段时间之后，才发现代码太多，太乱了，一看代码都想重构，都是踩着坑往前走。
这里我把一些游戏开发方面的东西整理一下，希望能对那些想做游戏服务器开发的朋友有所帮助。
首先，要明确一点，做游戏服务器开发和做传统的web开发有着本质的区别。游戏服务器开发，如果没有经验，一开始根本没有一个明确清析的目标，不像web那样，有些明确的MVC架构，往往就是为了尽快满足策划的需求，尽快的实现功能，尽快能让游戏跑起来。但是随着功能越来越多，在老代码上面修改的越来越频繁，游戏测试时暴露出来的一堆bug，更让人觉得束手无策，这个时候我们想到了重构，想到了架构的设计。 游戏的构架设计非常重要，好的构架代码清析，责任明确，扩展性强，易调试。这些会为我们的开发省去不少时间。**那要怎么样设计游戏的构架呢？可能每个游戏都不一样，但是本质上还是差不多的。 对于游戏服务器的构架设计，我们首先要了解游戏的服务器构架都有什么组成的？**一款游戏到上线，**需要具备哪些功能？**有些人可能会说，只要让游戏跑起来，访问服务器不出问题不就行了吗？答案是不行的，游戏构架本身代表的是一个体系，它包括：
系统初始化 游戏逻辑 数据库系统 缓存系统 游戏日志 游戏管理工具 公共服务组件 这一系统的东西都是不可少的，它们共同服务于游戏的整个运营过程。我们一点点来介绍各个系统的功能。
一，系统初始化 系统初始化是在没有客户端连接的时候，服务器启动时所需要做的工作。基本上就是配置文件的读取，初始化系统参数。
但是我们必须要考虑的是：
系统初始化需要的参数配置在哪儿，是配置在本地服务器，还是配置在数据库； 服务器启动的时候去数据库取； 配置的修改需不需要重启服务器等。 二，游戏逻辑 游戏逻辑是游戏的核心功能实现，也是整个游戏的服务中心，它被开发的好坏，直接决定了游戏服务器在运行中的性能。那在游戏逻辑的开发中我们要注意些什么呢？ 游戏是一种网络交互比较强的业务，好的底层通信，可以最大化游戏的性能，增加单台服务器处理的同时在线人数，给游戏带来更好的体验，至少不容易出现因为网络层导致的数据交互卡顿的现象。在这里我推荐使用Netty，它是目前最流行的NIO框架，它的用法可以在我之前的文章中查看，这里不再多说了。 有人疑问，代码也需要分层次？这个是当然了，不同的代码，代表了不同的功能实现。现在的开发语言都是面向对象的，如果我们不加思考，不加整理的把功能代码乱堆一起，起始看起来是快速实现了功能，但是到后期，如果要修改需求，或在原来的代码上增加新的需求，那真是被自己打败了。所以代码一定要分层，主要有以下几层：
**协议层，**也叫前后台交互层，它主要负责与前台交互协议的解析和返回数据。在这一层基本上没有什么业务逻辑实现。**与前台交互的数据都在这一层开始，也在这一层终止。**比如你使用了Netty框架，那么Netty的ChannelHandlerContext即Ctx只能出现在这一层，他不能出现到游戏业务逻辑代码的实现中，接收到客户端的请求，在这一层把需要的参数解析出来，再把参数传到业务逻辑方法中，业务逻辑方法处理完后，把要返回给客户端的数据再返回到这一层，在这一层组织数据，返回给客户端，这样就可以把业务逻辑和网络层分离，业务逻辑只关心业务实现，而且也方便对业务逻辑进行单元测试。 业务逻辑层，这里处理真正的游戏逻辑，该计算价格计算价格，该通关的通关，该计时的计时。该保存数据的保存数据。但是这一层不直接操作缓存或数据库，只是处理游戏逻辑计算。因为业务逻辑层是整个游戏事件的处理核心，所以他的处理是否正确直接决定游戏的正确性。所以这一层的代码要尽量使用面向对象的方法去实现。**不要出现重复代码或相似的功能进行复制粘贴，这样修改起来非常不方便，可能是修改了某一处，而忘记了修改另外同样的代码。还要考虑每个方法都是可测试的**，一个方法的行数最好不要超过一百行。另外，可以多看看设计模式的书，它可以帮助我们设计出灵活，整洁的代码。 三，数据库系统 数据库是存储数据库的核心，但是游戏数据在存储到数据库的时候会经过网络和磁盘的IO,它的访问速度相对于内存来说是很慢的。一般来说，每次访问数据库都要和数据库建立连接，访问完成之后，为了节省数据库的连接资源，要再把连接断开。
这样无形中又为服务器增加了开销，在大量的数据访问时，可能会更慢，而游戏又是要求低延时的，这时该怎么办呢？我们想到了数据库连接池，即把访问数据库的连接放到一个地方管理，用完我不断开，用的时候去那拿，用完再放回去。这样不用每次都建立新的连接了。
但是如果要我们自己去实现一套连接池管理组件的话，需要时间不说，对技术的把控也是一个考验，还要再经过测试等等，幸好互联网开源的今天，有一些现成的可以使用，这里推荐Mybatis，即实现了代码与SQL的分离，又有足够的SQL编写的灵活性，是一个不错的选择。
四，缓存系统 游戏中，客户端与服务器的交互是要求低延迟的，延迟越低，用户体验越好。像之前说过的一样，低延迟就是要求服务器处理业务尽量的快，客户端一个请求过来，要在最短的时间内响应结果，最低不得超过500ms，因为加上来回的网络传输耗时，基本上就是600ms-到700ms了，再长玩家就会觉得游戏卡了。
如果直接从数据库中取数据，处理完之后再存回数据库的话，这个性能是跟不上的。在服务器，数据在内存中处理是最快的，所以我们要把一部分常用的数据提前加载到内存中，比如说游戏数据配置表，经常登陆的玩家数据等。这样在处理业务时，就不用走数据库了，直接从内存中取就可以了，速度更快。
游戏中常见的缓存有两种：
直接把数据存储在jvm或服务器内存中 使用第三方的缓存工具，这里推荐Redis，详细的用法可以自己去查询。（本公号内有系列文章，详情见【菜单栏】- 【技术文章】 - 【基础系列】 - 【实战R1，实战R2】） 五，游戏日志 日志是个好东西呀，**一个游戏中更不能少了日志，而且日志一定要记录的详细。**它是玩家在整个游戏中的行为记录，有了这个记录，我们就可以分析玩家的行为，查找游戏的不足，在处理玩家在游戏中的问题时，日志也是一个良好的凭证和快速处理方式。 在游戏中，日志分为：
系统日志，主要记录游戏服务器的系统情况。比如：数据库能否正常连接，服务器是否正常启动，数据是否正常加载； 玩家行为日志，比如玩家发送了什么请求，得到了什么物品，消费了多少货币等等； **统计日志，**这种日志是对游戏中所有玩家某种行为的一种统计，根据这个统计来分析大部分玩家的行为，得出一些共性或不同之处，以方法运营做不同的活动吸引用户消费。 在构架设计中，日志记录一定要做为一种强制行为，因为不强制的话，可能由于某种原因某个功能忘记加日志了，那么当这个功能出问题了，或者运营跟我们要这个功能的一些数据库，就傻眼了。又得加需求，改代码了。日志一定要设计一种良好的格式，日志记录的数据要容易读取，分解。日志行为可以用枚举描述，在功能最后的处理方法里面加上这个枚举做为参数，这样不管谁在调用这个方法时，都要去加参数描述。 俗话说，工欲善其事，必先利其器。**游戏管理工具是对游戏运行中的一系列问题处理的一种工具。**它不仅是给开发人员用，大多数是给运营使用。游戏上线后，我们需要针对线上的问题进行不同的处理。不可能把所有问题都让程序员去处理吧，于是程序员们想到了一个办法，给你们做一个工具，你们爱谁处理谁处理去吧。
六， 游戏管理工具 游戏管理工具是一个不断增涨的系统，因为它很多时候是伴随着游戏中遇到的问题而实现的。
但是根据经验，有一些功能是必须有的，比如：
服务器管理，主要负责服务器的开启，关闭，服务器配置信息，玩家信息查询； 玩家管理，比如踢人，封号； 统计查询，玩家行为日志查询，统计查询，次留率查询，邮件服务，修改玩家数据等。 根据游戏的不同要求，**凡是可以能过工具实现的，都做到游戏管理工具里面。**它是针对所有服务器的管理。
一个好的，全的游戏管理工具，可以提高游戏运营中遇到问题处理的效率，为玩家提供更好的服务。
七，公共组件 公共组件是为游戏运行中提供公共的服务。例如：
充值服务器，我们没必须一个服用一个充值，而且你也不能对外提供多个充值服务器地址，和第三方公司对接，他们绝对不干，这是要疯呀； 还有运营搞活动时的礼包码； 还有注册用户的管理，玩家一个注册账号可以进不同的区等。 这些都是针对所有区服提供的服务，所以要单独做，与游戏逻辑分开，这样方便管理，部署和负载均衡。
还有SDK的登陆验证，现在手游比较多，与渠道对接里要进行验证，这往往是很多http请求，速度慢，所以这个也要拿出来单独做，不要在游戏逻辑中去验证，因为网络IO的访问时间是不可控制的，http是阻塞的请求。
所以，综上来看，一个游戏服务器起码有几个大的功能模块组成：
游戏逻辑工程； 日志处理工程； 充值工程； 游戏管理工具工程； 用户登陆工程； 公共活动工程等。 根据游戏的不同需要，可能还有其它的。所在构架的设计中，一定要考虑到系统的分布式部署，尽量把公共的功能拆出来做，这样可以增强系统的可扩展性。
服务器端开发的一些建议 本文作为游戏服务器端开发的基本大纲，是游戏实践开发中的总结。
第一部分 —— 专业基础，用于指导招聘和实习考核； 第二部分 —— 游戏入门，讲述游戏服务器端开发的基本要点； 第三部分 —— 服务端架构，介绍架构设计中的一些基本原则。 希望能帮到大家！
一、专业基础 1.1网络 1.1.1理解TCP/IP协议 网络传输模型 滑动窗口技术 建立连接的三次握手与断开连接的四次握手 连接建立与断开过程中的各种状态 TCP/IP协议的传输效率 思考：
请解释DOS攻击与DRDOS攻击的基本原理 一个100Byte数据包，精简到50Byte, 其传输效率提高了50% TIMEWAIT状态怎么解释？ 1.1.2掌握常用的网络通信模型 Select Epoll，边缘触发与平台出发点区别与应用 Select与Epoll的区别及应用 1.</description>
    </item>
    
    <item>
      <title>10 十万在线的WebGame的数据库设计思路</title>
      <link>https://haokiu.com/blog/ace809ec27124ecc987bcd4c7eec569f/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/ace809ec27124ecc987bcd4c7eec569f/</guid>
      <description>10 十万在线的WebGame的数据库设计思路 服务器数量预估 在线人数预估： 在项目设计之前，需要先对运营后的服务器人数做一下预估，预计激活人数300w，活跃人数40w，同时在线10w。而服务器的设计极限则在激活人数500w，活跃人数60w，最高同时在线15w。 数据参考：
这里之所以预计这么低的激活人数，是从整个服务器考虑的。《热血三国》是将不同的用户放在不同的服务器里，所以单一服务器的激活人数不会对服务器压力产生太 大影响。而如果将所有玩家统一到一组服务器里，则会导致用户表访问压力过大。偏低的激活人数靠定期清理不活跃账户来实现。
数据库服务器数量估计： 服务器在搭配上，一般分为db服务器和web服务器。在这之前的运营中，通常按照1:1的方式来配置数据库和web服务器，而实际情况可以使1:2的配置比 例。不过在单一世界的设计里，单台db服务器肯定无法满足需求。之前设计过一款策略类webgame，在运营时，每秒sql数为在线人数的1~1.5倍。 不过这个测试数据，是在没有钱全面应用缓存的情况的数据，在新系统里，如果全面应用缓存，并采用类似于Memcache的软件提供数据缓存，这样数据库的访问压力将可以得到极大的缓解，因此我们暂定吧每秒sql数暂定为在线人数的1倍。正常情况下数据库的访问压力应该为 10w sql/秒 极限数据应该为15w sql/秒。 数据库使用ms sqlserver 2008，在这之前的一个策略类webgame项目，对一台CPU为 E5520核的服务器上做压力测试，得到的数据如下：
Sql数 5k CPU 50% 硬盘IO 0.5M(突发3M） 网卡流量 30Mbit/s(100M网卡） 按照上面的分析，在正常情况下，我们需要为整个系统提供20台db。Web服务端按照1:1和db做搭配，也将安排20台，预计3个机柜的服务器。
数据库表结构划分 数据库表设计： 因为要把这么多访问量分担到不同的服务器里，原先的数据库表设计肯定不会合适。初步的想法是根据游戏的逻辑模块，将不同模块的数据库表拆分到各个服务器 里，如果按照上面的服务器预估得到的结论是4~6组服务器，实际上这个方案还是可行的。但如果是20组服务器的话，除非是一台服务器一张数据库表，但这的 设计会造成数据表太分散，在处理事务的时候，会跨多个数据库 策略类webgame一般的主要模块为：建筑物和资源、军事、英雄、物品、帮会、交易、地图。根据这些模块的应用场景，可以将数据库表分为2种类型，一种是属于玩家的数据，另外一种是公共数据。
属于玩家的数据是指玩家个人说拥有的基地、资源、军事单位、物品等数据，它们都是围绕着玩家而产生的。 公共数据则是指由多位玩家共同组合而产生的数据，例如：账户信息、帮会、地图等。 这里划分两种数据的目的是在于他们的数据库表的划分。对于公共数据，则采用单一服务器，单一数据库表处理的方式来处理。例如帮会模块和地图模块就准备分别 用3台服务器来存储各自对应的数据库表。而对于玩家的数据，则根据用户ID采用一定的划分方式，将玩家数据打散到各个服务器里（http://blog.zhaojie.me/2010/03/sharding-by-id-characteristic.html）。
（数据表的结构划分）
用户表和其单表的设计思路： 这里所说的单表是指在逻辑上部队数据库表做拆分，程序在访问时只访问一个数据库。当然这只是逻辑上的单一，根据实际上的访问压力，可以将数据库文件作水平切割分布在不同的文件分区和服务器里。这部分的数据库表设计继续沿用之前的设计方案就可以了。 对于用户信息，帮会信息等数据，实际上插入和更新的频率不会太高，更多的是在查询上，因此这部分的设计重点应该是在缓存上。从以前的资料里得知Memcache服务器每秒可以响应4w次的读请求，用一台Memcache就能处理好用户和帮会信息的缓存处理。
地图模块设计思路 地图模块： 地图在传统策略类webgame里都是以平面的方式展示和存储的。地图的移动都是在这个平面上实现。但一般来说，平面地图的设计容量都会有一个上限，一般来 地图多为400*400，他的人数上限就是16w，实际上服务器容纳3~5w人后，整张地图就会显得很拥挤了。如果要想容纳几百万人在线，平面地图的尺寸 就需要扩容得相当大了，这样玩家从地图中间移动到边缘的时间会相当恐怖，因此平面地图在这里不是很合适。因此，地图不能用平面来构造，必须是立体的方法构 造。在这里我设计了两组方案：
立体平面空间：
如上图所描述的，立体平面空间，就是把多块地图一层层叠加在一起，形成一个立体的空间。这样如果用户不够，再增加一个新的平面就行。游戏的背景可以根据需要 做调整（例如整个世界是被大海隔开的5片大陆组成，在这5片大陆之外，还有其它的超位面空间，这些空间自身是互不相连的，但是可以通过传送阵进行位面传 送）。这样做的好处是，用户容易理解，以往用户的操作习惯不用改变，毕竟都是在平面地图上战斗。只不过要做跨位面的战斗的移动计算上会存在问题（逻辑上的 问题：是否允许跨大陆的远征军） 用户坐标的表示方法：地图层次、x坐标、y坐标
数据库设计方案： 采用了层次结构，只需要增加一个地图层次的字段，这个地图表就能沿用。（参考字段：ID、地图层次、X坐标、y坐标、地图类型、玩家ID、城池ID） 虽然说，加入了一个地图层次的字段能解决地图的表示问题，不过，因为整个游戏世界是单一世界的服务器，当所用地图信息存储到一张表的时候，这数据量就不容小 视。在这之前做webgame项目的时候，整张地图是预先生成好数据库记录的，当有玩家加入游戏的时候，就去修改表里的玩家ID和城池ID。同时因为地图 大小只有400400，整张表也就16w条记录。但如果是要做一个承载500w人的服务器，那地图的尺寸最好是要800800，并且地图的层次为 15~20层，就算最小的15层，按照原先的设计思路，至少需要预先插入960w条记录。 数据量看上去比较夸张，不过对于SqlServer来说也不是处理不了，并且我们还将计划把地图表单独用一台服务器来处理，其压力远小很多。不过也不能不考虑当发生性能瓶颈时的优化处理。优化的方法有两个：
拆分：按照地图层次，把这张表拆分成15~20张表，或者拆分到15~20个数据库里 用疏矩阵存储：地图不预先生成用户的地图信息，而是有玩家加入时才插入数据。这个方案在服务器早期人数比较少时会得到良好的性能效果，但当用户人数达到一定量时，还是避免不了因为记录函数过多而导致而外的开销。 全立体空间：
全立体空间就是取消了平面的坐标显示，用户都是在一个三维的立体地图里战斗。好处是地图不用那么分散，在移动计算让很好处理，存在的问题就是游戏在显示的时候，如何表现地图的三维效果会比较困难。 用户坐标的表示方式：x坐标 y坐标 z坐标
数据库存储方案： 三维空间的数据库表设计结构可以和上面的表一样，而且也只能采用疏矩阵的方式存储，因为做成三维空间后，可表示的位置的记录数更多了。
可移动基地在全立体空间的设想： 早在两年前，看过《超时空要塞F》的时候，就产生了一个想法，就是玩家的基地是可以移动的。玩家的母舰在游戏的过程中，已一定的速度在整个世界里移动。 可以移动体系的设计要点：
用户的基地可移动 用户基地只能拥有一个（武林三国、travian都能建立多个） 空间坐标由x坐标 y坐标 z坐标 组成，并且坐标的值应为小数 同一个坐标里运行多个玩家存在，玩家的航线交叉并不会造成影响（只是为了方便计算减少判断过程） 移动的数据通过后台定时刷新 a)每个短周期(1~60s)在内存里更新坐标 b)每个长周期（10~100个短周期时间）将坐标的数据更新的数据库 攻击舰队移动的时间是按照2个阶段来进行的 a)第一个阶段是从母舰移动到目标坐标的时间 b)第二个阶段，在快到达时（前60分钟），做一个判断，判断攻击舰队的雷达能否搜索到目标的母舰坐标，能则做攻击坐标的新修正，如果不能则继续按照原先的坐标点移动。以上判断将每隔1分钟做一次，直到到达目标坐标点。如果到达目标坐标点仍然无法视为攻击失败，舰队返回 舰队的移动距离和舰队所携带的能量有关，超过移动范围的坐标，舰队是无法出发的。 部队和母舰应该是可以进行空间跳跃实现长距离的移动，不过空间跳跃需要在制定地点消耗大量的能量才能实现。 默认情况下，母舰移动速度为1格（x、y、z坐标）/天。 默认舰队的雷达查询范围为1格 默认母舰的雷达查询范围为3格 玩家数据的数据库设计 数据库的划分: 在游戏里数据交互最频繁的还是玩家的数据，他的访问量是一台服务器所不能解决的，因此我们考虑将这部分数据分担到多台服务器里。分担的方法还是做水平切 割，但这次不使用数据库自身的切割功能，而是在应用逻辑层上对数据库进行切割。根据用户的ID取模后写入对应的服务器里。 服务器1 用户ID % 服务器数量 = 0 服务器2 用户ID % 服务器数量 = 1 …… 预计每台服务器能提供6k~8k的在线用户访问，预计一共需要16台服务器。考虑到服务器的进一步扩容问题，在初期规划时，建议规划为32个数据库，每台服务器可以先放3~5个数据库，等服务器用户人数上来后，再将数据库拆分到不同的服务器里。</description>
    </item>
    
    <item>
      <title>10 开放一个TeamTalk测试服务器地址和几个测试账号</title>
      <link>https://haokiu.com/blog/601f5e2b4c0a4303a540259d9d394d0b/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/601f5e2b4c0a4303a540259d9d394d0b/</guid>
      <description>10 开放一个TeamTalk测试服务器地址和几个测试账号 由于TeamTalk是用于企业内部的即时通讯软件，一般客户端并不提供账号注册功能。如果你仅对TeamTalk的客户端感兴趣，你可以仅仅研究pc端和移动端代码。官方的测试服务器地址已经失效，所以我已经部署了一套TeamTalk服务器，并建立了几个测试账户可以供你使用：
tangseng
sunwukong
zhubajie
shaseng
==================
xiaowang
xiaoming
xiaozhao
xiaoli
==================
以上是账户名，密码随意。我改了下服务器端的代码，密码不进行校验的。你可以填写任意密码。
pc端设置方式：
安卓端设置方式：
关于ios端，目前由于服务器端的push_server没有部署，暂且就不提供了。
我专门把pc端代码和安卓端代码提取出来供大家下载：
pc端：
下载地址：http://download.csdn.net/detail/analogous_love/9851833
开发工具：VS2013
安卓端：
下载地址：http://download.csdn.net/detail/analogous_love/9851845
IDE使用Android-studio java 1.7 gradle 2.2.1
如果测试服务器连接不上，请通过微信 easy_coder 与我联系。</description>
    </item>
    
    <item>
      <title>11 pc客户端源码分析</title>
      <link>https://haokiu.com/blog/ee4c77c4daf64f5f821d76808ec0b8b3/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/ee4c77c4daf64f5f821d76808ec0b8b3/</guid>
      <description>11 pc客户端源码分析 ——写在前面的话
在要不要写这篇文章的纠结中挣扎了好久，就我个人而已，我接触windows编程，已经六七个年头了，尤其是在我读研的三年内，基本心思都是花在学习和研究windows程序上了。我很庆幸我当初学习windows程序走了一条正确的路线：先是学习常用的windows程序原理和基本API，再学习的mfc、wtl等一些常用的框架和类库，同时看了大量windows项目的源码，如金山卫士的开源代码、filezilla、电驴源码等等。个人觉得，基础真的很重要，拿windows开发来说，当你掌握了windows的程序的基本原理，我列一下大致范围：
windows消息机制（消息如何产生、如何发送、如何处理，常见的消息有哪些、消息的优先级、如何自定义消息、窗体消息、常用控件消息）
gdi原理（要熟悉gdi的各种对象，如画笔、画刷、字体、区域、裁剪、位图等，熟悉它们的API，熟悉各种gdi绘图API、当然最好也要熟悉一整套的gdi+的类，gdi与gdi+的区别）
windows进程与线程的概念（进程的概念、如何创建、如何结束、跨进程如何通信；线程的创建与销毁、线程间的同步与资源保护，熟悉windows常用的线程同步对象：临界区、事件、互斥体、信号量等）
windows内存管理（清晰地掌握一个进程地址空间的内存分布、windows堆的创建与管理等）
dll技术（dll的生成、变量的导出、函数的导出、类的导出、如何查看dll导出哪些函数、隐式dll的加载、显示dll的加载、远程dll注入技术等）
PE文件（一个PE文件的结构、有哪些节、如何修改、分别映射到进程地址空间的什么位置等）
windows SEH（结构化异常处理）
windows socket编程
windows读写文件技术（像CreateFile、WriteFile、GetFileSize等这些API应该熟练掌握、内存映射技术）
当然很多必备的技术也不好归类到windows技术下面，比如socket编程，这涉及到很多网络的知识，比如tcp的三次握手，数据的收发等，还有就是各种字符编码的知识、以及之间的相互转换，又比如一系列的CRT函数及其对应的宽字符版本。当然如果你搞windows开发，一定要熟悉开发工具Visual Studio，熟悉其工程项目的大多数属性配置，而且要做到知其然也知其所以然。如果不是不能跨平台，我敢说VS是史上最好最强大的开发工具，没有之一！我已经有好几年年不做windows开发了，目前主要从事linux开发，但windows的很多设计思想真的很好，非常值得借鉴，而且从编码风格来说，虽然看起来有点怪异，但是非常规范和易懂。
有了基础知识，你可以轻松地对工作中的一些问题给出解决方案，也能轻松阅读和使用市面上的那些库，比如，如果你深刻理解windows GDI，你不会在一个群里大喊，duilib某个属性为什么不起作用，你可以直接去阅读它的画法代码，如果是bug你可以改bug，如果只是你使用错误，你可以了解到正确的使用方法。所以基础这个东西，在短时间内，可能让你看不出与其他人的差别，但是从长远来看，它决定着你在技术上走的高度与深度。套用侯捷先生的一句话：勿在浮沙筑高台。
—— 正题
上面简单地介绍了下，我个人学习windows程序设计的一些心得吧。扯的有点远了，让我们回到正题上来，来分析TeamTalk的源码吧。当然这篇文章与前面介绍的不一样，我们不仅介绍程序的正题设计思路，还会介绍一些有意义的细节，比如一些windows开发中常用的一些细节。
一、程序功能 我们来先看下TeamTalk pc客户端包括哪些功能：TeamTalk因为开发的初衷是用于企业内部的即时通讯软件，所以，不提供对外注册的功能，一个员工的加入一般是人事部门在后台管理系统来新增该员工信息。其功能包括登录、聊天、群聊和建讨论组，当然聊天过程中可以发文字、表情、图片和文件，还包括查看聊天记录和简单地查看某个员工的个人信息，业务功能其实不多的。下面是一些功能截图：
二、编译方法与项目工程文件介绍 TeamTalk的pc客户端的下载地址是：https://github.com/baloonwj/TeamTalk 代码包括服务器端代码、pc端、mac端、安卓和IOS端，还有web端所有代码。
pc客户端代码的编译方法很简单：用VS2013打开win-client\solution目录下的teamtalk.sln，编译即可。你的VS版本至少要是VS2013，因为代码中大量使用了C++11的东西，VS2013以下版本是不支持C++11的语法的。当然，如果你是VS2015的话，可以参考这篇文章来进行修改和编译：http://www.07net01.com/linux/2017/01/1795569.html
打开teamtalk.sln之后，总共有10个解决方法，如下图所示：
其中teamtalk是主工程，你应该将它设置成启动工程，编译完成之后就可以调试了。你可以自己配置服务器来连接进行调试，我也可以连接我的测试服务器，具体参见《TeamTalk源码分析（十） —— 开放一个TeamTalk测试服务器地址和几个测试账号》。下面先大致介绍一个各个工程的作用：
Duilib是teamtalk使用的一款开源界面库，该界面库模仿web开发中的布局技术，使用xml文件来布局windows界面，并且在主窗口上绘制所有子控件，也就是所谓的directUI技术；
GifSmiley是程序中用来解析和显示gif格式的图片的库，以支持gif图片的动画效果；
httpclient功能是程序中使用的http请求库，登录前程序会先连接服务器的login_server以获得后续需要登录的msg_server的ip地址和端口号 等信息，这里就是使用的http协议，同时聊天过程中收发的聊天图片与图片服务器msfs也使用http协议来收发这些图片；
libogg是一个语音库，用来解析声音文件的，因为pc客户端可能会收到移动端的语音聊天，相比较传统的*.wav、.mp3、.wma，*.ogg格式的不仅音质高，而且音频文件的体积小，腾讯的QQ游戏英雄杀中的语音也是使用这个格式的。
libspeex是一个音频压缩库；
Modules就是TeamTalk中使用的各种库了，展开来看下你就明白了：
network是teamtalk使用的网络通信的代码，其实teamtalk pc端和服务器端使用的是同一套网络通信库，只不过如果服务器运行在linux下，其核心的IO复用模型是epoll，而pc客户端使用的IO复用模型是select；
speexdec 也是和ogg格式相关的编码和解码器；
teamtalk是主程序入口工程；
utility包含了teamtalk中用到的一些工具类工程，比如sqlite的包装接口、md5工具类等。
除了上面介绍的一些库以外，程序还使用了sqlite库、谷歌protobuf库、日志库yaolog等。关于yaolog可参见http://blog.csdn.net/gemo/article/details/8499692，这个日志库比较有意思的地方是可以单独打印出网络通信中的字节流的二进制形式，推荐一下，效果如下图所示（位于win-client\bin\teamtalk\Debug\log\socket.log文件中）：
三、程序总体框架介绍 整个程序使用了mfc框架来做一个架子，而所有的窗口和对话框都使用的是duilib，关于duilib网上有很多资料，这里不介绍duilib细节的东西了。一个mfc程序框架，使用起来也很简单，就是定义一个类集成mfc的CWinApp类，并改写其InitInstance()方法，mfc内部会替我们做好消息循环的步骤。TeamTalk相关的代码如下：
//位于teamtalk.h中 class CteamtalkApp : public CWinApp { public: CteamtalkApp(); public: virtual BOOL InitInstance(); virtual BOOL ExitInstance(); private: /** * 创建用户目录 * * @return BOOL * @exception there is no any exception to throw. */	BOOL _CreateUsersFolder(); /** * 创建主窗口 * * @return BOOL * @exception there is no any exception to throw.</description>
    </item>
    
    <item>
      <title>11 一种高性能网络游戏服务器架构设计</title>
      <link>https://haokiu.com/blog/8d180ec3ae3e409bac6e8a67811f54bc/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/8d180ec3ae3e409bac6e8a67811f54bc/</guid>
      <description>11 一种高性能网络游戏服务器架构设计 ​ 网络游戏的结构分为客户端与服务器端，客户端采用2D绘制引擎或者3D绘制引擎绘制游戏世界的实时画面，服务器端则负责响应所有客户端的连接请求和游戏逻辑处理，并控制所有客户端的游戏画面绘制。客户端与服务器通过网络数据包交互完成每一步游戏逻辑，由于游戏逻辑是由服务器负责处理的，要保证面对海量用户登录时，游戏具有良好的流畅性和用户体验，优秀的服务器架构起到了关键的作用。
1 服务器架构设计 1.1 服务器架构分类 服务器组的架构一般分为两种：第一种是带网关服务器的服务器架构；第二种是不带网关服务器的服务器架构，这两种方案各有利弊。在给出服务器架构设计之前，先对这两种设计方案进行详细的探讨。 所谓网关服务器，其实是Gate服务器，比如LoginGate、GameGate等。网关服务器的主要职责是将客户端和游戏服务器隔离，客户端程序直接与这些网关服务器通信，并不需要知道具体的游戏服务器内部架构，包括它们的IP、端口、网络通信模型(完成端口或Epoll)等。客户端只与网关服务器相连，通过网关服务器转发数据包间接地与游戏服务器交互。同样地，游戏服务器也不直接和客户端通信，发给客户端的协议都通过网关服务器进行转发。
1.2 服务器架构设计 根据网络游戏的规模和设计的不同，每组服务器中服务器种类和数量是不尽相同的。本文设计出的带网关服务器的服务器组架构如图1所示。
本文将服务器设计成带网关服务器的架构，虽然加大了服务器的设计复杂度，但却带来了以下几点好处： （1）作为网络通信的中转站，负责维护将内网和外网隔离开，使外部无法直接访问内部服务器，保障内网服务器的安全，一定程度上较少外挂的攻击。 （2）网关服务器负责解析数据包、加解密、超时处理和一定逻辑处理，这样可以提前过滤掉错误包和非法数据包。 （3）客户端程序只需建立与网关服务器的连接即可进入游戏，无需与其它游戏服务器同时建立多条连接，节省了客户端和服务器程序的网络资源开销。 （4）在玩家跳服务器时，不需要断开与网关服务器的连接，玩家数据在不同游戏服务器间的切换是内网切换，切换工作瞬间完成，玩家几乎察觉不到，这保证了游戏的流畅性和良好的用户体验。
在享受网关服务器带来上述好处的同时，还需注意以下可能导致负面效果的两个情况：如何避免网关服务器成为高负载情况下的通讯瓶颈问题以及由于网关的单节点故障导致整组服务器无法对外提供服务的问题。上述两个问题可以采用“多网关” 技术加以解决。顾名思义，“多网关” 就是同时存在多个网关服务器，比如一组服务器可以配置三台GameGate。当负载较大时，可以通过增加网关服务器来增加网关的总体通讯流量，当一台网关服务器宕机时，它只会影响连接到本服务器的客户端，其它客户端不会受到任何影响。
从图1的服务器架构图可以看出，一组服务器包括LoginGate、LoginServer、GameGate、GameServer、DBServer和MServer等多种服务器。LoginGate和GameGate就是网关服务器，一般一组服务器会配置3台GameGate，因为稳定性对于网络游戏运营来说是至关重要的，而服务器宕机等突发事件是游戏运营中所面临的潜在风险，配置多台服务器可以有效地降低单个服务器宕机带来的风险。另外，配置多台网关服务器也是进行负载均衡的有效手段之一。下面将对各种服务器的主要功能和彼此之间的数据交互做详细解释。
（1）LoginGate LoginGate主要负责在玩家登录时维护客户端与LoginServer之间的网络连接与通讯，对LoginServer和客户端的通信数据进行加解密、校验。
（2）LoginServer
LoginServer主要功能是验证玩家的账号是否合法，只有通过验证的账号才能登录游戏。从架构图可以看出， DBServer和GameServer会连接LoginServer。玩家登录基本流程是，客户端发送账号和密码到LoginServer验证，如果验证通过，LoginServer会给玩家分配一个SessionKey，LoginServer会把这个SessionKey发送给客户端、DBServer和GameServer，在后续的选择角色以后进入游戏过程中，DBServer和GameServer将验证SessionKey合法性，如果和客户端携带的SessionKey不一致，将无法成功获取到角色或者进入游戏。
（3）GameGate
GameGate(GG)主要负责在用户游戏过程中负责维持GS与客户端之间的网络连接和通讯，对GS和客户端的通信数据进行加解密和校验，对客户端发往GS的用户数据进行解析，过滤错误包，对客户端发来的一些协议作简单的逻辑处理，其中包括游戏逻辑中的一些超时判断。在用户选择角色过程中负责维持DBServer与客户端之间的网络连接和通讯，对DBServer和客户端的通信数据进行加解密和校验，对客户端发往DBServer的用户数据做简单的分析。维持客户端与MServer之间的网络连接与通讯、加解密、数据转发和简单的逻辑处理等。
（4）GameServer
GameServer(GS)主要负责游戏逻辑处理。网络游戏有庞大世界观背景，绚丽激烈的阵营对抗以及完备的装备和技能体系。目前，网络游戏主要包括任务系统、声望系统、玩家PK、宠物系统、摆摊系统、行会系统、排名系统、副本系统、生产系统和宝石系统等。从软件架构角度来看，这些系统可以看着GS的子系统或模块，它们共同处理整个游戏世界逻辑的运算。游戏逻辑包括角色进入与退出游戏、跳GS以及各种逻辑动作(比如行走、跑动、说话和攻击等)。
由于整个游戏世界有许多游戏场景，在该架构中一组服务器有3台GS共同负责游戏逻辑处理，每台游戏服务器负责一部分地图的处理，这样不仅降低了单台服务器的负载，而且降低了GS宕机带来的风险。玩家角色信息里会保持玩家上次退出游戏时的地图编号和所在GS编号，这样玩家再次登录时，会进入到上次退出时的GS。
上面提到过，在验证账号之后，LoginServer会把这个SessionKey 发给GS，当玩家选择角色登录GS时，会把SessionKey一起发给GS，这时GS会验证SessionKey是否与其保存的相一致，不一致的话GS会拒绝玩家进入游戏。MServer的主要负责GS之间的数据转发以及数据广播，另外，一些系统也可以放到MServer上，这样也可以减轻GS的运算压力。
（5）DBServer
DBServer主要的功能是缓存玩家角色数据，保证角色数据能快速的读取和保存。由于角色数据量是比较大的，包括玩家的等级、经验、生命值、魔法值、装备、技能、好友、公会等。如果每次GS获取角色数据都去读数据库，效率必然非常低下，用DBServer缓存角色数据之后，极大地提高了数据请求的响应速度。
LoginServer会在玩家选组时把SessionKey发给DBServer，当玩家发送获取角色信息协议时会带上这个SessionKey，如果跟DBServer保存的SessionKey不一致，则DBServer会认为玩家不是合法用户，获取角色协议将会失败。另外，玩家选取角色正式进入游戏时，GS会给DBServer发送携带SessionKey的获取角色信息协议，这时DBServer同样会验证SessionKey的合法性。总之，只有客户端、DBServer和GS所保存的SessionKey一致，才能保证协议收到成功反馈。
与DBServer通讯的服务器主要有GG，GS和LoginServer，DBServer与GG交互的协议主要包括列角色、创建角色、删除角色、恢复角色等，DBServer与GS交互的协议包括读取角色数据、保存角色数据和跳服务器等，DBServer与LoginServer交互的协议主要是用户登录协议，这时候会给DBServer发送SessionKey。
（6）MServer 每一个组有一台MServer，主要负责维持3台GS之间数据的转发和数据广播。另外一些游戏系统也可能会放到MServer上处理，比如行会系统。
1.3 服务器交互的主要流程 下面给出服务器之间数据通讯的主要流程从这些流程能看出各种服务器之间是如何数据交互和协同工作的。
图2的流程说明了，在选角色过程中，客户端会把携带游戏账号和SessionKey的选角色协议发给GG，GG做一些简单处理之后转发给DBServer，DBServer要验证SessionKey的合法性，验证通过之后，DBServer会从角色信息缓冲区里取出该账户的所有角色信息发给客户端。这个过程在客户端的表现是，当选择好服务器组之后，客户端会直接显示该账号下的所有角色，之后就可以选择角色进入游戏了。
图3的流程说明了，在玩家选角色正式进入游戏时，客户端会把携带游戏账号、角色ID和SessionKey的登录协议发给GG，GG做一些简单处理之后转发给GS。GS会验证SessionKey的合法性，验证通过之后，GS会把验证通过的结果发给客户端，同时GS给DBServer发获取角色数据的协议，这些角色数据是一个玩家所有的游戏数据，包括装备、技能等等。
图4的流程说明了，在玩家游戏过程，客户端把逻辑协议(包括走、说话、跑、使用技能等)发给GG，GG完成加解密和简单逻辑处理之后转发给GS，GS负责这些协议的主要 逻辑处理。
2 总结 网络游戏服务器的架构设计已经成为当前网络游戏研究领域的热点，因为高性能服务器架构设计是一款网络游戏成功的关键。本文从实际应用出发，提出了一种高性能的服务器架构设计解决方案，并且详细探讨了各种服务器的功能，本文的最后给出了几个服务器之间数据通讯的关键流程，以图文并茂的方式解释各个服务器是如何协同工作的。</description>
    </item>
    
    <item>
      <title>12 经典游戏服务器端架构概述</title>
      <link>https://haokiu.com/blog/d7795d37211b43728424c7c4f7469b67/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/d7795d37211b43728424c7c4f7469b67/</guid>
      <description>12 经典游戏服务器端架构概述 架构的分析模型 一. 讨论的背景 ​ 现代电子游戏，基本上都会使用一定的网络功能。从验证正版，到多人交互等等，都需要架设一些专用的服务器，以及编写在服务器上的程序。因此，游戏服务器端软件的架构，本质上也是游戏服务器这个特定领域的软件架构。 ​ 软件架构的分析，可以通过不同的层面入手。比较经典的软件架构描述，包含了以下几种架构： ​ 1.运行时架构——这种架构关心如何解决运行效率问题，通常以程序进程图、数据流图为表达方式。在大多数开发团队的架构设计文档中，都会包含运行时架构，说明这是一种非常重要的设计方面。这种架构也会显著的影响软件代码的开发效率和部署效率。本文主要讨论的是这种架构。 ​ 2.逻辑架构——这种架构关心软件代码之间的关系，主要目的是为了提高软件应对需求变更的便利性。人们往往会以类图、模块图来表达这种架构。这种架构设计在需要长期运营和重用性高的项目中，有至关重要的作用。因为软件的可扩展性和可重用度基本是由这个方面的设计决定的。特别是在游戏领域，需求变更的频繁程度，在多个互联网产业领域里可以说是最高的。本文会涉及一部分这种架构的内容，但不是本文的讨论重点。 ​ 3.物理架构——关心软件如何部署，以机房、服务器、网络设备为主要描述对象。 ​ 4.数据架构——关心软件涉及的数据结构的设计，对于数据分析挖掘，多系统协作有较大的意义。 ​ 5.开发架构——关心软件开发库之间的关系，以及版本管理、开发工具、编译构建的设计，主要为了提高多人协作开发，以及复杂软件库引用的开发效率。现在流行的集成构建系统就是一种开发架构的理论。
二. 游戏服务器架构的要素 ​ 服务器端软件的本质，是一个会长期运行的程序，并且它还要服务于多个不定时，不定地点的网络请求。所以这类软件的特点是要非常关注稳定性和性能。这类程序如果需要多个协作来提高承载能力，则还要关注部署和扩容的便利性；同时，还需要考虑如何实现某种程度容灾需求。由于多进程协同工作，也带来了开发的复杂度，这也是需要关注的问题。 ​ 功能约束，是架构设计决定性因素。一个万能的架构，必定是无能的架构。一个优秀的架构，则是正好把握了对应业务领域的核心功能产生的。游戏领域的功能特征，于服务器端系统来说，非常明显的表现为几个功能的需求： ​ 1.对于游戏数据和玩家数据的存储 ​ 2.对玩家客户端进行数据广播 ​ 把一部分游戏逻辑在服务器上运算，便于游戏更新内容，以及防止外挂。 ​ 针对以上的需求特征，在服务器端软件开发上，我们往往会关注软件对电脑内存和CPU的使用，以求在特定业务代码下，能尽量满足承载量和响应延迟的需求。最基本的做法就是“时空转换”，用各种缓存的方式来开发程序，以求在CPU时间和内存空间上取得合适的平衡。在CPU和内存之上，是另外一个约束因素：网卡。网络带宽直接限制了服务器的处理能力，所以游戏服务器架构也必定要考虑这个因素。 ​ 对于游戏服务器架构设计来说，最重要的是利用游戏产品的需求约束，从而优化出对此特定功能最合适的“时-空”架构。并且最小化对网络带宽的占用。
[图：游戏服务器的分析模型]
三. 核心的三个架构 ​ 基于上述的分析模型，对于游戏服务端架构，最重要的三个部分就是，如何使用CPU、内存、网卡的设计： ​ 1.内存架构：主要决定服务器如何使用内存，以保证尽量少的内存泄漏的可能，以及最大化利用服务器端内存来提高承载量，降低服务延迟。 ​ 2.调度架构：设计如何使用进程、线程、协程这些对于CPU调度的方案。选择同步、异步等不同的编程模型，以提高服务器的稳定性和承载量。同时也要考虑对于开发带来的复杂度问题。现在出现的虚拟化技术，如虚拟机、docker、云服务器等，都为调度架构提供了更多的选择。 ​ 3.通信模式：决定使用何种方式通讯。网络通讯包含有传输层的选择，如TCP/UDP；据表达层的选择，如定义协议；以及应用层的接口设计，如消息队列、事件分发、远程调用等。 ​ 本文的讨论，也主要是集中于对以上三个架构的分析。
四. 游戏服务器模型的进化历程 ​ 最早的游戏服务器是比较简单的，如UO《网络创世纪》的服务端一张3.5寸软盘就能存下。基本上只是一个广播和存储文件的服务器程序。后来由于国内的外挂、盗版流行，各游戏厂商开始以MUD为模型，建立主要运行逻辑在服务器端的架构。这种架构在MMORPG类产品的不断更新中发扬光大，从而出现了以地图、视野等分布要素设计的分布式游戏服务器。而在另外一个领域，休闲游戏，天然的需要集中超高的在线用户，所以全区型架构开始出现。现代的游戏服务器架构，基本上都希望能结合承载量和扩展性的有点来设计，从而形成了更加丰富多样的形态。 ​ 本文的讨论主要是选取这些比较典型的游戏服务器模型，分析其底层各种选择的优点和缺点，希望能探讨出更具广泛性，更高开发效率的服务器模型。
分服模型 一. 模型描述 ​ 分服模型是游戏服务器中最典型，也是历久最悠久的模型。其特征是游戏服务器是一个个单独的世界。每个服务器的帐号是独立的，而且只用同一服务器的帐号才能产生线上交互。在早期服务器的承载量达到上限的时候，游戏开发者就通过架设更多的服务器来解决。这样提供了很多个游戏的“平行世界”，让游戏中的人人之间的比较，产生了更多的空间。所以后来以服务器的开放、合并形成了一套成熟的运营手段。一个技术上的选择最后导致了游戏运营方式的模式，是一个非常有趣的现象。
[图：分服模型]
二. 调度架构 1.单进程游戏服务器 最简单的游戏服务器只有一个进程，是一个单点。这个进程如果退出，则整个游戏世界消失。在此进程中，由于需要处理并发的客户端的数据包，因此产生了多种选择方法：
[图：单进程调度模型]
​ a.同步-动态多线程：每接收一个用户会话，就建立一个线程。这个用户会话往往就是由客户端的TCP连接来代表，这样每次从socket中调用读取或写出数据包的时候，都可以使用阻塞模式，编码直观而简单。有多少个游戏客户端的连接，就有多少个线程。但是这个方案也有很明显的缺点，就是服务器容易产生大量的线程，这对于内存占用不好控制，同时线程切换也会造成CPU的性能损失。更重要的多线程下对同一块数据的读写，需要处理锁的问题，这可能让代码变的非常复杂，造成各种死锁的BUG，影响服务器的稳定性。 ​ b.同步-多线程池：为了节约线程的建立和释放，建立了一个线程池。每个用户会话建立的时候，向线程池申请处理线程的使用。在用户会话结束的时候，线程不退出，而是向线程池“释放”对此线程的使用。线程池能很好的控制线程数量，可以防止用户暴涨下对服务器造成的连接冲击，形成一种排队进入的机制。但是线程池本身的实现比较复杂，而“申请”、“施放”线程的调用规则需要严格遵守，否则会出现线程泄露，耗尽线程池。 ​ c.异步-单线程/协程：在游戏行业中，采用Linux的epoll作为网络API，以期得到高性能，是一个常见的选择。游戏服务器进程中最常见的阻塞调用就是网路IO，因此在采用epoll之后，整个服务器进程就可能变得完全没有阻塞调用，这样只需要一个线程即可。这彻底解决了多线程的锁问题，而且也简化了对于并发编程的难度。但是，“所有调用都不得阻塞”的约束，并不是那么容易遵守的，比如有些数据库的API就是阻塞的；另外单进程单线程只能使用一个CPU，在现在多核多CPU的服务器情况下，不能充分利用CPU资源。异步编程由于是基于“回调”的方式，会导致要定义很多回调函数，并且把一个流程里面的逻辑，分别写在多个不同的回调函数里面，对于代码阅读非常不理。——针对这种编码问题，协程(Coroutine)能较好的帮忙，所以现在比较流行使用异步+协程的组合。不管怎样，异步-单线程模型由于性能好，无需并发思维，依然是现在很多团队的首选。 ​ d.异步-固定多线程：这是基于异步-单线程模型进化出来的一种模型。这种模型一般有三类线程：主线程、IO线程、逻辑线程。这些线程都在内部以全异步的方式运行，而他们之间通过无锁消息队列通信。 2.多进程游戏服务器 ​ 多进程的游戏服务器系统，最早起源于对于性能问题需求。由于单进程架构下，总会存在承载量的极限，越是复杂的游戏，其单进程承载量就越低，因此开发者们一定要突破进程的限制，才能支撑更复杂的游戏。 ​ 一旦走上多进程之路，开发者们还发现了多进程系统的其他一些好处：能够利用上多核CPU能力；利用操作系统的工具能更仔细的监控到运行状态、更容易进行容灾处理。多进程系统比较经典的模型是“三层架构”。 ​ 在多进程架构下，开发者一般倾向于把每个模块的功能，都单独开发成一个进程，然后以使用进程间通信来协调处理完整的逻辑。这种思想是典型的“管道与过滤器”架构模式思想——把每个进程看成是一个过滤器，用户发来的数据包，流经多个过滤器衔接而成的管道，最后被完整的处理完。由于使用了多进程，所以首选使用单进程单线程来构造其中的每个进程。这样对于程序开发来说，结构清晰简单很多，也能获得更高的性能。
[图:经典的三层模型]
​ 尽管有很多好处，但是多进程系统还有一个需要特别注意的问题——数据存储。由于要保证数据的一致性，所以存储进程一般都难以切分成多个进程。就算对关系型数据做分库分表处理，也是非常复杂的，对业务类型有依赖的。而且如果单个逻辑处理进程承载不了，由于其内存中的数据难以分割和同步，开发者很难去平行的扩展某个特定业务逻辑。他们可能会选择把业务逻辑进程做成无状态的，但是这更加加重了存储进程的性能压力，因为每次业务处理都要去存储进程处拉取或写入数据。 ​ 除了数据的问题，多进程也架构也带来了一系列运维和开发上的问题：首先就是整个系统的部署更为复杂了，因为需要对多个不同类型进程进行连接配置，造成大量的配置文件需要管理；其次是由于进程间通讯很多，所以需要定义的协议也数量庞大，在单进程下一个函数调用解决的问题，在多进程下就要定义一套请求、应答的协议，这造成整个源代码规模的数量级的增大；最后是整个系统被肢解为很多个功能短小的代码片段，如果不了解整体结构，是很难理解一个完整的业务流程是如何被处理的，这让代码的阅读和交接成本巨高无比，特别是在游戏领域，由于业务流程变化非常快，几经修改后的系统，几乎没有人能完全掌握其内容。
三. 内存架构 ​ 由于服务器进程需要长期自动化运行，所以内存使用的稳定是首要大事。在服务器进程中，就算一个触发几率很小的内存泄露，都会积累起来变成严重的运营事故。需要注意的是，不管你的线程和进程结构如何，内存架构都是需要的，除非是Erlang这种不使用堆的函数式语言。 1.动态内存 ​ 在需要的时候申请内存来处理问题，是每个程序员入门的时候必然要学会的技能。但是，如何控制内存释放却是一个大问题。在C/C++语言中，对于堆的控制至关重要。有一些开发者会以树状来规划内存使用，就是一般只new/delete一个主要的类型的对象，其他对象都是此对象的成员（或者指针成员），只要这棵树上所有的对象都管理好自己的成员，就不会出现内存漏洞，整个结构也比较清晰简单。
[图:对象树架构]
​ 在Objective C语言中，有所谓autorealse的特性，这种特性实际上是一种引用计数的技术。由于能配合在某个调度模型下，所以使用起来会比较简单。同样的思想，有些开发者会使用一些智能指针，配合自己写的框架，在完整的业务逻辑调用后一次性清理相关内存。
[图:根据业务处理调度管理内存池]
​ 在带虚拟机的语言中，最常见的是JAVA，这个问题一般会简单一些，因为有自动垃圾回收机制。但是，JAVA中的容器类型、以及static变量依然是可能造成内存泄露的原因。加上无规划的使用线程，也有可能造成内存的泄露——有些线程不会退出，而且在不断增加，最后耗尽内存。所以这些问题都要求开发者专门针对static变量以及线程结构做统一设计、严格规范。 2.预分配内存 ​ 动态分配内存在小心谨慎的程序员手上，是能发挥很好的效果的。但是游戏业务往往需要用到的数据结构非常多，变化非常大，这导致了内存管理的风险很高。为了比较彻底的解决内存漏洞的问题，很多团队采用了预先分配内存的结构。在服务器启动的时候分配所有的变量，在运行过程中不调用任何new关键字的代码。 ​ 这样做的好处除了可以有效减少内存漏洞的出现概率，也能降低动态分配内存所消耗的性能。同时由于启动时分配内存，如果硬件资源不够的话，进程就会在启动时失败，而不是像动态分配内存的程序一样，可能在任何一个分配内存的时候崩溃。然而，要获得这些好处，在编码上首先还是要遵循“动态分配架构”中对象树的原则，把一类对象构造为“根”对象，然后用一个内存池来管理这些根对象。而这个内存池能存放的根对象的数目，就是此服务进程的最大承载能力。一切都是在启动的时候决定，非常的稳妥可靠。</description>
    </item>
    
    <item>
      <title>13 游戏跨服架构进化之路</title>
      <link>https://haokiu.com/blog/3a513d0ec4fc47e2b3830ec79beb1572/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/3a513d0ec4fc47e2b3830ec79beb1572/</guid>
      <description>13 游戏跨服架构进化之路 江贵龙，游戏行业从业8年，历任多款游戏项目服务器主程，服务器负责人。 关注游戏服务器架构及优化，监控预警，智能运维，数据统计分析等。
1.背景 ​ 虽然游戏市场竞争激烈，产品格局变动较大,但游戏产业一直处于稳步增长阶段，无论是在端游，页游，手游还是已经初露端倪的H5游戏。可以预见，游戏类型中，MMOARPG游戏仍然会是引领市场的主流趋势，贡献着大部分流水，市场上也仍然在不断涌现精品。研发团队对MMO游戏的探索从来未间断过,从付费模式的改变，到题材多元化，次时代的视觉效果，更成熟的玩法及数值体系，本文主要针对跨服玩法上的探索和实现做一些思考和分析。 ​ 根据2016年《中国游戏产业报告》数据显示，随着游戏人口红利逐渐消失，获取用户的成本居高不下，几年来至少翻了十倍以上，目前平均导量成本页游为10~15元/人，手游在15~20元/人，其中IOS上成本30~50元/人,“洗”用户模式的效果正在变得微弱，用户流失严重。让我们先来看看滚服玩法的局限性，滚服洗量模式下存在着如下的弊端：
2.设计目标 ​ 在上述背景下，一款长留存，低流失的精品游戏就成了平台方，渠道商，研发方追捧的目标，设想一下，如果让所有服务器玩家通过“跨域体系”实现自由畅通交互，在此基础上，玩家可以体验到前所未有的“国战系统”——7×24小时昼夜不停服的国家战争，随时开战；突破单地图承载容量极限的国战对决，带来真正万人国战的刺激体验，形成全区玩家能够互动的游戏社交环境。依托平台运营来打造一款真正意义上摆脱传统游戏运营模式的全新产品，为平台吸纳足够的市场份额，大幅降低流失率。 ​ 我们的蓝图是开创“1=1000”模式，让所有玩家，身处一个服务器却如同同时存在于所有服务器，这种打破服务器屏障的设定，杜绝了游戏出现“被迫滚服”现象出现，玩家不用再担心鬼服人烟稀少，不用担心交易所一无所有，所有的数据共享，让玩家轻松Hold住全世界。 3.进化过程 ​ 项目组那时面临的现状是游戏各种档期计划、宣传推广安排都已经就绪，两个月后该独代项目要在腾讯平台按时上线，开发不能因引入跨服机制而导致所有完成度100%的功能都要去分别去增加跨服的支持，而技术人员在跨服功能开发这块经验的积累上也不充分。 技术小组分析了时下项目的现状，跨服业务需求及现有的框架结构，明确了几点原则： ​ 1.为了实现跨服，游戏代码从底层架构到上层业务逻辑的代码改动成本尽量降低 ​ 2.业务逻辑里尽量少关心或者不用关心是否在本服或者跨服，降低开发人员的跨服功能开发复杂度，提高开发的效率，缩短开发周期。 那么，我们需要解决哪些技术疑点呢？
3.1 客户端直连还是服务器转发 a)如果直连，那么，跨服玩法时客户端要维持两个连接，在跨服里，要模拟玩家登陆，绑定session的过程，游戏服和跨服两边要同时维护两份玩家数据，如何做到数据的同步？跨服要暴露给玩家，需要有公网访问IP和端口。对客户端连接管理来说较复杂。 b)如果通过大区服务器消息转发，那么，服务器之间做RPC通信，连接管理，消息需额外做一步跳转，性能能否满足？跨不跨服，对于客户端来说透明，跨服隐藏在大区之后，更加安全，不需再浪费公网IP和端口。 综合考虑了下，采用了B方案。
3.1.1 RPC框架设计需求 那么，我们需要先准备一套高性能轻量级的RPC框架。 业界有很多典型的RPC框架，比如Motan、Thrift、gRPC、Hessian、Hprose，Wildfly,Dubbo,DubboX，为什么我们还要重复造轮子呢？综合考虑了下，框架要满足以下几点业务需求: 1.该框架要简单、易用、支持高并发的跨服请求； 2.根据现有的游戏服务器框架，会有很多定制化的场景； 3.通过NIO TCP长连接获取服务，但无需跨语言的需求； 4.支持同步请求，异步请求，异步回调CallBack； 5.要有服务发现的功能，要有Failfast能力； 6.具备负载均衡，分组等路由策略； 基于有以上的诉求，结合团队以前的开发经验，于是就决定自主研发。 我们选用的技术栈有 Netty、Apache Commons Pool、Redis等。 框架分为服务提供方(RPC Server)、服务调用方(RPC Client)、注册中心(Registry)三个角色，基于Redis为服务注册中心，通过其Pub/Sub实现服务动态的注册和发现。Server 端会在服务初始化时向Registry 注册声明所提供的服务；Client 向 Registry 订阅到具体提供服务的 Server 列表，根据需要与相关的 Server 建立连接，进行 RPC 服务调用。同时，Client 通过 Registry 感知 Server 的状态变更。三者的交互关系如右图：
图1、RPC框架三者关系
3.1.2 RPC请求的有序性 连接池在设计过程中，比较重要的是要考虑请求的顺序性，也就是先请求的先完成。 如果玩家的跨服请求通过不同的RPC连接并发执行，就有可能单个玩家请求因错序而导致逻辑矛盾，比如玩家移动，见图2：
图2、玩家移动
​ 玩家移动是很频繁的，如果A请求让玩家从位置1移动到位置2，B请求从位置2移动到位置3，有可能B请求先被跨服接收处理，这就会产生逻辑问题。 ​ 那么，如何做到请求的有序性呢？其本质是让同一份数据的访问能串行化，方法就是让同一个玩家的跨服请求通过同一条RPC连接执行，加上逻辑上的有效性验证，如图3所示：
3.1.3 同步RPC实现细节 限于篇幅，这里只讲同步请求的RPC连接池实现。 同步请求的时序图如图4：
上图为进入跨服战场的一次同步请求,场景切换控制器StageControllAction发起进入跨服战场的请求applyChangeByBattlefield(),场景管理器StageControllManager首先要调用登录跨服的RPC请求GameRpcClient.loginCrossServer(LoginCrossServerReq)， ​ 跨服RPC请求的工作流是这样的:
public LoginCrossServerAck loginCrossServer(LoginCrossServerReqreq)throws ServiceException { //从连接池中获取一个连接 RpcClient rpcClient = rpcClientPool.getResource(req.getRoleId()); try { //发起一次同步RPC请求 RpcMsg msg = rpcClient.sendWithReturn(MsgType.RPC_LoginCrossServerReq, req); return JSON.parseObject(msg.getContent(), LoginCrossServerAck.</description>
    </item>
    
    <item>
      <title>2 网络游戏服务器开发框架设计介绍</title>
      <link>https://haokiu.com/blog/288a2c3a9e374a3ebf898cfa184e2921/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/288a2c3a9e374a3ebf898cfa184e2921/</guid>
      <description>2 网络游戏服务器开发框架设计介绍 在开发过程中，会先有一份开发大纲或是一份策划案，但是这些在我的开发中可能不会有，或者即使有，也很有可能是我随性写下来的，但是我会尽可能写好它。
网络通信层，我会放到单独的SOCKET编程中去讲解，这里的主题是游戏的架构设计以及系统模块间的协同工作。
所以，在这里假设所有的网络层都已经开发完毕，具体的网络层开发代码不会再这里出现，因为这需要很多年的开发经验，或者对SOCKET有一定的了解才能够讲述清楚或理解，所以我不想再我还没有足够的把握之前去说这样的问题，主要问题是不想让人说我不专业；另一方面是不希望给没有接触过SOCKET编程或了解不多的人带来误导或困扰。
在开发游戏具体功能前，第一个要做的就是理清系统功能，这里的系统功能并不是具体的游戏功能，而是从软件角度出发的，行业内部称其为分布式服务器开发，讲的是如何构建一个可移植、可分布到不同网络机器独立或依赖运行的应用程序。
本系列开发教程是我个人游戏经历和工作历程的一个沉淀，也是我个人主观的一个未实现版本，在这里，我希望它可以以教程的方式存在，并去按部就班的一步一步实现出来。所有的源码代码都是开源的，我不会有丝毫保留，这样做的目的是方便很多像我一样的游戏狂热者入门无门，另一方面也是希望前辈们可以对我的错误进行指正。下面将具体描述服务器的划分以及功能实现。
此系列开发教程，总共将分为10个模块：它们分别为
LoginGate服务器、 LoginServer服务器、 GameGate服务器、 GameServer服务器、 IMServer服务器、 AIServer服务器、 CenterServer服务器、 BillingServer服务器、 WebServices服务器、 DBServer服务器。 1
LoginGate：登陆网关服务器，将所有的LoginServer服务器地址暴露给最终用户，每个LoginGate服务可以挂接n个LoginServer，将最终用户的所有请求转发给目标LoginServer。当最终用户通过此服务完成登陆后，会与该服务断开连接，断开连接前，服务器会将数据上报给GameGate服务。
2
LoginServer：登陆服务器，仅作于内部服务与LoginGate进行连接，所有的最终用户请求由LoginGate过滤后，转发过来进行处理。与LoginGate的所有通信都是明文，即未加密数据。
3
**GameGate：**游戏网关服务器，与LoginGate协作完成最终用户的登陆过程，每一个服务会连接到唯一一个LoginGate服务上进行注册，LoginGate会将以完成验证登陆的用户信息同步到所有已注册成功的GameGate上，根据注册不同的GameGate类型信息，LoginGate会发生不同的通过认证的最终用户信息。
GameGate挂接n个GameServer服务到自身，此服务将所有注册到自身的GameServer信息发送给最终用户，提供用户选择具体的区或线路进行游戏（区和线路在不同的游戏设定中有不同的定义），在这里区的定义对应的是GameGate，每一个GameGate可以表示物理或逻辑上的多个游戏分区，每个分区由至少一个GameServer组成；
线路定义为GameServer，每一个GameServer代表一条线路，线路之间互相不可见，但是可以通过IMServer进行一些扩展通信，例如公会、好友、聊天等服务可以设置透明通信或隐藏通信。透明通信由IMServer向目标GameServer转发请求，并进行处理；隐藏通信仅在当前GameServer进行处理，不会做跨越性操作。
4
GameServer：游戏服务器，作为内部服务与GameGate协作处理最终用户的请求，这个服务主要处理游戏逻辑，例如战斗。此服务启动后，会根据配置文件的配置信息进行相应的服务注册，该服务启动成功后，会注册到GameGate和IMServer、AIServer服务器，它们分别提供最终用户游戏、交友、公会、聊天和智能体的移动、创建、销毁等服务。作为整个游戏的核心处理服务器，会处理掉大部分的用户交互服务请求，只有在不能处理的情况下，才会请求其它服务协同处理。
5
IMServer：IM通信服务器，全称InstantMessaging（译为即时通讯），ICQ、MSN、QQ等聊天工具都属于此范畴。此服务的作用是提供物理或逻辑不同位置的GameServer上的最终用户通讯的一个媒介，用户成功登陆GameServer时，会将自己的好友、公会信息注册到此服务上，当需要跨GameServer服务时，共IMServer使用。此服务主要提供聊天、交友、交易、公会等社交类行为服务，该服务可以直接或间接的与最终用户进行通信，但最终用户无法直接与该服务进行通信，比如请求操作，所有的用户操作都由GameServer转发，IMServer可以选择性的直接反馈最终用户或通过GameServer反馈。
6
**AIServer：**人工智能服务器，全称Artificial Intelligence（译为人工智能），例如现代服务性机器人（自动吸尘器、智能探测仪、智能防爆装置等）都属于人工智能范畴。这里的人工智能主要体现在游戏中的NPC、MONSTER等有行为表现物体。GameServer启动后会连接到此服务进行注册，并获取所需智能体的信息，以反馈给最终用户，并最终显示在用户应用程序中。该服务主要控制智能体的移动、攻击、创建、销毁等行为，另外包括在战斗中或非战斗状态下的行为，比如游走在街道上的商品小贩；在搜索到攻击目标时，主动或召集附近的战斗单位一起攻击用户，都属于该服务的工作内容。
7
**CenterServer：**中心服务器，用于监控、更新已注册到此服务的状态，比如电信1区（傲视天地）服务器的运行状态等。此服务主要是管理除自身以外的所有服务程序的运行状态，以及时反馈给技术活运维人员。
8
**BillingServer：**计费服务器，用于计算用户在游戏中的消耗、增值；比如XX在游戏中购买了一个双倍经验卡，消耗10金币，或者用户通过网站形式进行充值，都会通过该服务反馈给用户最终结果。
9
**WebServices：**网站服务，主要用于网站与游戏之间的交互。比如XX用户通过网站进行充值服务，充值成功后，通知计费服务以响应用户操作；或通过网站进行游戏激活、礼品领取等，都需要此服务与游戏应用程序进行交互，以体现实时的变化。
10
DBServer：用于全局数据维护，例如更新、查询、插入、删除操作；这些数据包含用户账号、充值、代金卷、点卡、月卡以及游戏中需要用到的角色数据。
服务器整体架构图分布示意图：
LoginGate内部运行示意图：
LoginServer内部运行示意图：
由于其它服务器模块程序的内部图与这两个类似，所以就不在这个上面耽搁太多时间，下一篇将讲述具体的游戏开发，网络库使用的是开源库ACE，下载地址http://download.dre.vanderbilt.edu/previous_versions/ACE-5.8.0.zip。</description>
    </item>
    
    <item>
      <title>3 游戏后端开发需要掌握的知识</title>
      <link>https://haokiu.com/blog/16d1fbc7aa204ddba0ef394895d2c2b6/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/16d1fbc7aa204ddba0ef394895d2c2b6/</guid>
      <description>3 游戏后端开发需要掌握的知识 这篇是从网上找到牛人的博客总结下来的：
实战方面：
（1）两种在知名IT公司使用的游戏服务器架构设计
点击图片可以放大
1
各个服务器的功能以及作用：
**CenterServer服务器管理器：**管理所有的服务器，分配服务器的端口，负责全局的逻辑（管理），对各功能服务器和场景服务器提供服务，保证服务器的合法性 DBserver角色档案缓冲服务器 GameServer逻辑服务器：玩家的实时同步在里面实现 GateServer网关服务器：负责消息转发 **LoginServer登录服务器：**连接账号数据 2
不带负载均衡的和带负载均衡：
相同点：
​ 与带负载均衡大概的架构相同
不同点：
不带负载均衡
Gate Server 和Game Server之间是一对一的关系，每个Game Server能容纳的玩家数量是一定的，正常情况下一个Gate Server的对应一个Game Server实时在线人数能达到3000人，一旦达到峰值，就会找下一个对应的Game Server。
各个Gate Server服务器之间是不通信的
带负载均衡
一个Gate Server的对应多个Game Server
各个GateServer之间可以互相通信，而且还可以随意扩展，通过配置文件可以实现配置
3
服务器的工作过程：
用户从客户端选择游戏服务器列表 登录到Login Server,在登陆的过程中 先去平台服务器进行账号的验证 验证通过后会通知Login Server，然后Login Server会把验证的消息发送 到center Server，请求其中的Gate Server的地址和端口 Center Server会找一个可用的Gate Server信息,发送回LoginServer Login Server会把消息发送给客户端 客户端断开与Login Server的连接，然后与Game Server 连接进入游戏场景中 </description>
    </item>
    
    <item>
      <title>4 关于游戏服务端架构的整理</title>
      <link>https://haokiu.com/blog/a7ec43bdee96498694f118163763c921/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/a7ec43bdee96498694f118163763c921/</guid>
      <description>4 关于游戏服务端架构的整理 一个大型的网落游戏服务器应该包含几个模块：网络通讯，业务逻辑，数据存储，守护监控（不是必须）。其中业务逻辑可能根据具体需要，又划分为好几个子模块。
这里说的模块可以指一个进程，或者一个线程方式存在，本质上就是一些类的封装。
对于服务器的并发性，要么采用单进程多线程，要么采用多进程单线程的方式，说说两种方式的优缺点：
一、单进程多线程的服务器设计模式，只有一个进程，但一个进程包好多个线程： 网络通讯层，业务逻辑，数据存储，分别在独立的线程中，无守护进程。
优点：
数据共享和交换方便，使用全局变量或者单例就可以，数据存储方便。 单进程，服务器框架结构相对简单，编码容易。 缺点：
所有功能只能在单个物理服务器上，不能做成分布式。 不方便监控各个线程状态，容易死锁 一个线程出错，例如内存非法访问，栈空间被破坏，那么服务器进程就退出，所有玩家掉线，影响大。 二、多进程单线程的服务器设计模式，多个进程，每个进程只有一个线程： 网路通讯，业务逻辑，数据存储，守护进程，分别在不同的进程。
优点：
各个进程可以分布在不同的物理服务器上，可以做成分布式的服务器框架，例如可以将数据存储单独放到一个物理服务器上，供几个区的服务器使用。将网络通讯进程独立出来，甚至可以做成导向服务器，实现跨服战。 可以通过守护进程监控其它进程状态，例如有进程死掉，马上重启该进程，或者某个进程cpu使用率接近100%（基本可以判断是某个逻辑死循环了）, 强制kill掉该进程，然后重启。 单个服务器进程异常退出，只要不是网络通讯进程（一般这个都会比较稳定，没什么逻辑），那么就可以及时被守护进程重启，不会造成玩家掉线，只会造成在1-2秒内，某个逻辑功能无法使用，甚至玩家都感觉不到。 服务器通过共享内存进行数据交换，那么如果其中一个服务器死掉，数据还在，可以保护用户数据（当然多线程也可以使用共享内存）。 并发性相对多线程要高点。 缺点：
不方便使用互斥锁，因为进程切换的时间片远远于线程切换，对于一个高并发服务器是无法允许这么高时间片的切换代价的。因此必须设计好服务器的框架，尽量避开使用锁机制，但要保证数据不出错。 多进程编程，在各个进程间会有很多通讯，跨服务器进程的异步消息较多，会让服务器的编码难度加大。 下面先按照一个游戏的功能，将服务器的功能分块框架画出来:
点击图片可放大
以上是一个游戏服务器最基础的功能框架图，接下来要做的就是设计服务器的框架了
1. 早期的MMORPG服务器结构 Client&amp;lt;-&amp;gt;GameServer&amp;lt;-&amp;gt;DB 所有业务数据集中处理
优点:
简单,快速开发
缺点:
所有业务放在一起,系统负担大大增加.一个bug可能导致整个服务器崩溃,造成所有玩家掉线甚至丢失等严重后果。 开服一刹那,所有玩家全部堆积在同一个新手村.-&amp;raquo;&amp;raquo;卡，客户端卡（同屏人数过多渲染/广播风暴） 服务器卡(处理大量同场景消息/广播风暴) 2. 中期-用户分离集群式 GameServe1 Client | DB GameServer2 玩家不断增多-&amp;gt;分线-&amp;gt;程序自动或玩家手动选择进入 **缺点:**运营到后期,随着每条线玩家的减少, 互动大大减少。
3. 中后期 数据分离集群式 按地图划分服务器,当前主流 新手村问题：《天龙八部》提出了较好的解决方案，建立多个平行的新手村地图，一主多副，开服时尽可能多的同时容纳新用户的涌入，高等级玩家从其它地图回新手村只能到达主新手村。
4. 当前主流的网络游戏架构 注：在GateServer和CenterServer之间是有一条TCP连接的。而GameServer和LogServer之间的连接可以是UDP连接。这是有一个大概的图，很多地方需要细化。 **GateServer:**网关服务器,AgentServer、ProxyServer
优点:
作为网络通信的中转站，负责维护将内网和外网隔离开，使外部无法直接访问内部服务器，保障内网服务器的安全，一定程度上较少外挂的攻击。 网关服务器负责解析数据包、加解密、超时处理和一定逻辑处理，这样可以提前过滤掉错误包和非法数据包。 客户端程序只需建立与网关服务器的连接即可进入游戏，无需与其它游戏服务器同时建立多条连接，节省了客户端和服务器程序的网络资源开销。 在玩家跳服务器时，不需要断开与网关服务器的连接，玩家数据在不同游戏服务器间的切换是内网切换，切换工作瞬问完成，玩家几乎察觉不到，这保证了游戏的流畅性和良好的用户体验。 缺点:
网关服务器成为高负载情况下的通讯瓶颈问题 由于网关的单节点故障导致整组服务器无法对外提供服务的问题 解决：
**多网关技术。**顾名思义，“多网关” 就是同时存在多个网关服务器，比如一组服务器可以配置三台GameGme。当负载较大时，可以通过增加网关服务器来增加网关的总体通讯流量，当一台网关服务器宕机时，它只会影响连接到本服务器的客户端，其它客户端不会受到任何影响。 **DCServer:**数据中心服务器。主要的功能是缓存玩家角色数据，保证角色数据能快速的读取和保存 CenterServer:全局服务器/中心服务器,也叫WorldServer. 主要负责维持GameServer之间数据的转发和数据广播。另外一些游戏系统也可能会放到Center上处理，比如好友系统,公会系统。 改进:
将网关服务器细化为LogingateServer和多个GameGateServer.
5. 按业务分离式集群 由于网络游戏存在很多的业务，如聊天，战斗，行走，NPC等，可以将某些业务分到单独的服务器上。这样每个服务器的程序则会精简很多。而且一些大流量业务的分离,可以有效的提高游戏服务器人数上限。
优点：
业务的分离使得每种服务器的程序变的简单，这样可以降低出错的几率。即使出错，也不至于影响到每一个整个游戏的进行,而且通过快速启动另一台备用服务器替换出错的服务器。 业务的分离使得流量得到了分散，进而相应速度回得到提升 。 大部分业务都分离了成了单独的服务器,所以可以动态的添加，从而提高人数上限。 改进： 甚至可以将登陆服务器细化拆分建角色,选择角色服务器
6. 一种简单实用的网络游戏服务器架构 下图中每个方框表示一个独立的进程APP组件，每个服务进程如果发生宕机会影响部分用户，整体服务但不会全部中断。在宕机进程重启后，又可以并入整体，全部服务得以继续。
**gls：**game login server，游戏登录服务器，某种程序上，其不是核心组件，gls调用外部的接口，进行基本的用户名密码认证。此外需要实现很多附属的功能：登录排队 （对开服非常有帮助），GM超级登录通道（GM可以不排队进入游戏），封测期间激活用户控制，限制用户登录，控制客户端版本等。 **db：**实质上是后台sql的大内存缓冲，隔离了数据库操作，比较内存中的数据，只把改变的数据定时批量写入sql。系统的算法，开发稳定性都要求非常高。 **center：**所有组件都要在这里注册，在线玩家的session状态都在这里集中存放，和各组件有心跳连接。所有对外的接口也全部通过这里。 角色入口：玩家登录游戏后的选择角色 **gs：**game server，最核心组件，同一地图，所有游戏逻辑相关的功能，都在这里完成。 **gate：**建立和用户的常链接，主要作sockt转发，屏蔽恶意包，对gs进行保护。协议加密解密功能，一个gate共享多个gs，降低跳转地图连接不上的风险。 **IM，关系，寄售：**表示其它组件，负责对应的跨地图发生全局的游戏逻辑。 7.另一个架构图 1- 这是一条WebService的管道，在用户激活该区帐号，或者修改帐号密码的时候，通过这条通道来插入和更新用户的帐号信息。 2- 这也是一条WebService管道，用来获取和控制用户该该组内的角色信息，以及进行付费商城代币之类的更新操作。 3- 这是一条本地的TCP/IP连接，这条连接主要用来进行服务器组在登陆服务器的注册，以及登陆服务器验证帐户后，向用户服务器注册帐户登陆信息，以及进行对已经登陆的帐户角色信息进行操作（比如踢掉当前登陆的角色），还有服务器组的信息更新（当前在线玩家数量等）。 4- 这也是一条本地TCP/IP连接，这条连接用来对连接到GameServer的客户端进行验证，以及获取角色数据信息，还有传回GameServer上角色的数据信息改变。 5- 这条连接也是一条本地的TCP/IP连接，它用来进行公共信息服务器和数个游戏服务器间的交互，用来交换一些游戏世界级的信息（比如公会信息，跨服组队信息，跨服聊天频道等）。 6- 这里的两条连接，想表达的意思是，UserServer和GameServer的Agent是可以互换使用的，也就是玩家进入组内之后，就不需要再切换 Agent。如果不怕乱套，也可以把登陆服务器的Agent也算上，这样用户整个过程里就不需要再更换Agent，减少重复连接的次数，也提高了稳定性。 （毕竟连接次数少了，也降低了连不上服务器的出现几率） 在这个架构里面，**GameServer实际上是一个游戏逻辑的综合体，**里面可以再去扩展成几个不同的逻辑服务器，通过PublicServer进行公共数据交换。</description>
    </item>
    
    <item>
      <title>5 各类游戏对应的服务端架构</title>
      <link>https://haokiu.com/blog/47a72212e86d4b6a8fe0516f8ff1cf65/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/47a72212e86d4b6a8fe0516f8ff1cf65/</guid>
      <description>5 各类游戏对应的服务端架构 类型一：卡牌、跑酷等弱交互服务端 卡牌跑酷类因为交互弱，玩家和玩家之间不需要实时面对面PK，打一下对方的离线数据，计算下排行榜，买卖下道具即可，所以实现往往使用简单的 HTTP服务器：
登录时可以使用非对称加密（RSA, DH），服务器根据客户端uid，当前时间戳还有服务端私钥，计算哈希得到的加密 key 并发送给客户端。之后双方都用 HTTP通信，并用那个key进行RC4加密。客户端收到key和时间戳后保存在内存，用于之后通信，服务端不需要保存 key，因为每次都可以根据客户端传上来的 uid 和 时间戳 以及服务端自己的私钥计算得到。**用模仿 TLS的行为，**来保证多次 HTTP请求间的客户端身份，并通过时间戳保证同一人两次登录密钥不同。 每局开始时，访问一下，请求一下关卡数据，玩完了又提交一下，验算一下是否合法，获得什么奖励，数据库用单台 MySQL或者 MongoDB即可，后端的 Redis做缓存（可选）。
如果要实现通知，那么让客户端定时15秒轮询一下服务器，如果有消息就取下来，如果没消息可以逐步放长轮询时间，比如30秒；如果有消息，就缩短轮询时间到10秒，5秒，即便两人聊天，延迟也能自适应。 此类服务器用来实现一款三国类策略或者卡牌及酷跑的游戏已经绰绰有余，这类游戏因为逻辑简单，玩家之间交互不强，使用 HTTP来开发的话，开发速度快，调试只需要一个浏览器就可以把逻辑调试清楚了。
类型2：第一代游戏服务器 1978 1978年，英国著名的财经学校University of Essex的学生 Roy Trubshaw编写了世界上第一个MUD程序《MUD1》，在University of Essex于1980年接入 ARPANET之后加入了不少外部的玩家，甚至包括国外的玩家。《MUD1》程序的源代码在 ARPANET共享之后出现了众多的改编版本，至此MUD才在全世界广泛流行起来。不断完善的 MUD1的基础上产生了开源的 MudOS（1991），成为众多网游的鼻祖：
MUDOS采用 C语言开发，因为玩家和玩家之间有比较强的交互（聊天，交易，PK），MUDOS使用单线程无阻塞套接字来服务所有玩家，所有玩家的请求都发到同一个线程去处****理，主线程每隔1秒钟更新一次所有对象（网络收发，更新对象状态机，处理超时，刷新地图，刷新NPC）。 游戏世界采用房间的形式组织起来，每个房间有东南西北四个方向可以移动到下一个房间，由于欧美最早的网游都是地牢迷宫形式的，因此场景的基本单位被称为 “房间”。
MUDOS使用一门称为LPC的脚本语言来描述整个世界（包括房间拓扑，配置，NPC，以及各种剧情）。游戏里面的高级玩家（巫师），可以不断的通过修改脚本来为游戏添加房间以及增加剧情。早年 MUD1上线时只有17个房间，Roy Trubshaw毕业以后交给他的师弟 Richard Battle，在 Richard Battle手上，不断的添加各种玩法到一百多个房间，终于将 MUD发扬光大。 用户使用 Telnet之类的客户端用 Tcp协议连接到 MUDOS上，使用纯文字进行游戏，每条指令用回车进行分割。比如 1995年国内第一款 MUD游戏《侠客行》，你敲入*：”go east”，*游戏就会提示你：“*后花园 - 这里是归云庄的后花园，种满了花草，几个庄丁正在浇花。此地乃是含羞草生长之地。这里唯一的出口是 north。这里有：花待 阿牧（A mu），还有二位庄丁（Zhuang Ding）”，然后你继续用文字操作，查看阿牧的信息：“look a mu”，*系统提示：“*花待 阿牧（A mu）他是陆乘风的弟子，受命在此看管含羞草。他看起来三十多岁，生得眉清目秀，端正大方，一表人才。他的武艺看上去【不是很高】，出手似乎【极轻】”。*然后你可以选择击败他获得含羞草，但是你吃了含羞草却又可能会中毒死亡。在早期网上资源贫乏的时候，这样的游戏有很强的代入感。 用户数据保存在文件中，每个用户登录时，从文本文件里把用户的数据全部加载进来，操作全部在内存里面进行，无需马上刷回磁盘。用户退出了，或者每隔5分钟检查到数据改动了，都会保存到磁盘。这样的系统在当时每台服务器承载个4000人同时游戏，不是特别大的问题。从1991年的 MUDOS发布后，全球各地都在为他改进，扩充，退出新版本，随着 Windows图形机能的增强。1997游戏《UO》在 MUDOS的基础上为角色增加的x,y坐标，为每个房间增加了地图，并且为每个角色增加了动画，形成了第一代的图形网络游戏。 因为游戏内容基本可以通过 LPC脚本进行定制，所以MUDOS也成为名副其实的第一款服务端引擎，引擎一次性开发出来，然后制作不同游戏内容。后续国内的《万王之王》等游戏，很多都是跟《UO》一样，直接在 MUDOS上进行二次开发，加入房间的地图还有角色的坐标等要素，该架构一直为国内的第一代 MMORPG提供了稳固的支持，直到 2003年，还有游戏基于 MUDOS开发。 虽然后面图形化增加了很多东西，但是这些MMORPG后端的本质还是 MUDOS。
随着游戏内容的越来越复杂，架构变得越来越吃不消了，各种负载问题慢慢浮上水面，于是有了我们的第二代游戏服务器。
类型3：第二代游戏服务器 2003 2000年后，网游已经脱离最初的文字MUD，进入全面图形化年代。最先承受不住的其实是很多小文件，用户上下线，频繁的读取写入用户数据，导致负载越来越大。随着在线人数的增加和游戏数据的增加，服务器变得不抗重负。同时早期 EXT磁盘分区比较脆弱，稍微停电，容易发生大面积数据丢失。因此第一步就是拆分文件存储到数据库去。
此时游戏服务端已经脱离陈旧的 MUDOS体系，各个公司在参考 MUDOS结构的情况下，开始自己用 C再重新开发自己的游戏服务端。并且脚本也抛弃了 LPC，采用扩展性更好的 Python或者 Lua来代替。由于主逻辑使用单线程模型，随着游戏内容的增加，传统单服务器的结构进一步成为瓶颈。于是有人开始拆分游戏世界，变为下面的模型：
游戏服务器压力拆分后得以缓解，但是两台游戏服务器同时访问数据库，大量重复访问，大量数据交换，使得数据库成为下一个瓶颈。于是形成了数据库前端代理（DB Proxy），游戏服务器不直接访问数据库而是访问代理，再有代理访问数据库，同时提供内存级别的cache。早年 MySQL4之前没有提供存储过程，这个前端代理一般和 MySQL跑在同一台上，它转化游戏服务器发过来的高级数据操作指令，拆分成具体的数据库操作，一定程度上代替了存储过程：
但是这样的结构并没有持续太长时间，因为玩家切换场景经常要切换连接，中间的状态容易错乱。而且游戏服务器多了以后，相互之间数据交互又会变得比较麻烦，于是人们拆分了网络功能，独立出一个网关服务 Gate（有的地方叫 Session，有的地方叫 LinkSvr之类的，名字不同而已）：
把网络功能单独提取出来，让用户统一去连接一个网关服务器，再有网关服务器转发数据到后端游戏服务器。而游戏服务器之间数据交换也统一连接到网管进行交换。这样类型的服务器基本能稳定的为玩家提供游戏服务，一台网关服务1-2万人，后面的游戏服务器每台服务5k-1w，依游戏类型和复杂度不同而已，图中隐藏了很多不重要的服务器，如登录和管理。这是目前应用最广的一个模型，到今天仍然很多新项目会才用这样的结构来搭建。 人都是有惯性的，按照先前的经验，似乎把 MUDOS拆分的越开性能越好。于是大家继续想，网关可以拆分呀；基础服务如聊天交易可以拆分呀；还可以提供web接口，数据库可以拆分呀，于是有了下面的模型：</description>
    </item>
    
    <item>
      <title>6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则</title>
      <link>https://haokiu.com/blog/84414d52b22b4cdaa7a7cf4beb0e1585/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/84414d52b22b4cdaa7a7cf4beb0e1585/</guid>
      <description>6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则 腾讯QQGame游戏同时在线的玩家数量极其庞大，为了方便组织玩家组队游戏，腾讯设置了大量游戏室（房间），玩家可以选择进入属意的房间，并在此房间内找到可以加入的游戏组（牌桌、棋盘等）。玩家选择进入某个房间时，必须确保此房间当前人数未满（通常上限为400），否则进入步骤将会失败。玩家在登入QQGame后，会从服务器端获取某类游戏下所有房间的当前人数数据，玩家可以据此找到未满的房间以便进入。
如上篇所述的原因，如果待进入房间的人数接近上限时，玩家的进入请求可能失败，这是因为服务器在收到此进入请求之前可能有若干其他玩家也请求进入这个房间，造成房间人数达到上限。
这一问题是无法通过上篇所述调整协作分配的方法来解决的，这是因为：要进入的房间是由玩家来指定的，无法在服务器端完成此项工作，游戏软件必须将服务器端所维护的所有房间人数数据复制到玩家的客户端，并让玩家在界面上看到这些数据，以便进行选择。
这样，上篇所述的客户端与服务器端协作分配原则（谁掌握数据，谁干活），还得加上一些限制条件，并让位于另一个所谓&amp;quot;用户驱动客户端行为&amp;quot;原则&amp;ndash;如果某个功能的执行是由用户来推动的，则这个功能的实现应当放在客户端（或者至少由客户端来控制整个协作），并且客户端必须持有此功能所依赖相关数据的副本，这个副本应当尽量与服务器端的源保持同步。
图一&amp;quot;进入房间&amp;quot;失败示意
QQGame还存在一个明显的不足，就是：玩家如果在游戏一段时间后，离开了某个房间，并且想进入其它房间，这时QQGame并不会刷新所有房间的当前人数，造成玩家据此信息所选的待进入房间往往实际上人数已满，使得进入步骤失败。笔者碰到的最糟情形是重复3、4次以上，才最后成功进入另外某个房间。此缺陷其实质是完全放弃了客户端数据副本与服务器端的源保持同步的原则。
实际上，QQGame的开发者有非常充分的理由来为此缺陷的存在进行辩护：QQGame同时在线的用户数超过百万甚至千万数量级，如果所有客户端要实时（所谓实时，就玩家的体验容忍度而言，可以定为不超过1秒的延迟）地从服务器端获取更新数据，那么最终只有一个结果&amp;ndash;系统彻底崩溃。
设想一下每秒千万次请求的吞吐量，以普通服务器每秒上百个请求的处理能力（这个数据是根据服务请求处理过程可能涉及到I/O操作来估值的，纯内存处理的情形可能提高若干数量级），需要成千上万台服务器组成集群方能承受（高可用性挑战）；而随着玩家不断地进入或退出游戏房间，相关数据一直在快速变化中，
正向来看，假设有一台中心服务器持有这些数据，那么需要让成千上万台服务器与中心保持这些动态数据的实时同步（数据一致性挑战）； 相对应的，逆向来看，玩家进入房间等请求被分配给不同的服务器来处理，一旦玩家进入房间成功则对应服务器内的相关数据被改变，那么假定中的中心服务器就需要实时汇集所有工作服务器内发生的数据变动（数据完整性挑战）。 同时处理上万台服务器的数据同步，这需要什么样的中心服务器呢？即使有这样的超级服务器存在，那么Internet网较大的（而且不稳定的）网络通讯延迟又怎么解决呢？
对于软件缺陷而言，可以在不同的层面来加以解决&amp;ndash;从设计、到需求、甚至是直接在业务层面来解决（例如，08年北京奥运会网上购票系统，为了解决订票请求拥塞而至系统崩溃的缺陷，最后放弃了原先&amp;quot;先到先得&amp;quot;的购票业务流程，改为：用户先向系统发订票申请，系统只是记录下来而不进行处理，而到了空闲时，在后台随机抽选幸运者，为他们一一完成订票业务）。当然解决方案所处的层面越高，可能就越让人不满意。
就上述进入房间可能遭遇失败的缺陷而言，最简便的解决方案就是：在需求层面调整系统的操作方式，即**增加一个类似上篇所述&amp;quot;自动快速加入游戏&amp;quot;的功能&amp;ndash;&amp;ldquo;自动进入房间&amp;quot;功能。**系统在服务器端为玩家找到一个人数较多又未满的房间，并尝试进入（注意，软件需求是由用户的操作目标所驱动的，玩家在此的目标就是尽快加入一个满意的游戏组，因此由系统来替代玩家选择目标房间同样符合相关目标）。而为了方便玩家手工选择要进入的房间，则应当增加一个&amp;quot;刷新当前各房间人数&amp;quot;的功能。另外，**还可以调整房间的组织模式，**例如以地域为单位来划分房间，像深圳（长城宽带）区房间1、四川（电信）房间3、北美区房间1等，在深圳上网的玩家将被系统引导而优先进入深圳区的房间。
不管怎样，解决软件缺陷的王道还是在设计层面。要解决上述缺陷，架构设计师就必须同时面对高可用、数据一致性、完整性等方面的严峻挑战。
在思考相关解决方案时，我们将应用若干与高性能服务器集群架构设计相关的一些重要原则。首先是&amp;quot;分而治之&amp;quot;原则，即将大量客户端发出的服务请求进行适当的划分（例如，所有从深圳长城宽带上网的玩家所发出的服务请求分为一组），分别分配给不同的服务器（例如，将前述服务请求分组分配给放置于深圳数据中心的服务器）来加以处理。对于QQGame千万级的并发服务请求数而言，采用Scale Up向上扩展，即升级单个服务器处理能力的方式基本上不予考虑（没有常规的主机能处理每秒上千万的请求）。唯一可行的，只有Scale Out向外扩展，即利用大量服务器集群做负载均衡的方式，这实质上就是&amp;quot;分而治之&amp;quot;原则的具体应用。
图二 分而治之&amp;quot;下的QQGame游戏服务集群部署
然而，要应用&amp;quot;分而治之&amp;quot;原则进行Scale Out向外扩展，还依赖于其它的条件。如果各服务器在处理被分配的服务请求时，其行为与其它服务器的行为结果产生交叉（循环）依赖，换句话讲就是共享了某些数据（例如，服务器A处理客户端a发来的进入房间#n请求，而同时，服务器B也在处理客户端b发来的进入房间#n请求，此时服务器A与B的行为存在循环依赖&amp;ndash;因为两者要同时访问房间#n的数据，这一共享数据会造成两者间的循环依赖），则各服务器之间必须确保这些共享数据的一致完整性，否则就可能发生逻辑错误（例如，假定房间#n的人数差一个就满了，服务器A与B在独自处理的情况下，将同时让客户端a与b的进入请求成功，于是房间#n的最终人数将超出上限）。
而要做到此点，各服务器的处理进程之间就必须保持同步（实际上就是排队按先后顺序访问共享数据，例如：服务器A先处理，让客户端a进入房间成功，此时房间#n满员；此后服务器B更新到房间#n满的数据，于是客户端b的进入请求处理结果失败），这样，原来将海量请求做负载均衡的意图就彻底失败了，多台服务器的并发处理能力在此与一台实质上并没有区别。
由此，我们导出了另外一个所谓&amp;quot;处理自治&amp;rdquo;（或称&amp;quot;行为独立&amp;quot;）的原则，即所有参与负载均衡的服务器，其处理对应服务请求的行为应当不循环依赖于其它服务器，换句话讲，就是各服务器的行为相对独立（**注意：**在这里，非循环依赖是允许的，下文中我们来分析为什么）。
由此可见，简单的负载均衡策略对于QQGame而言是解决不了问题的。我们必须找到一种途径，使得在使用大量服务器进行&amp;quot;分而治之&amp;quot;的同时，同时有确保各个服务器&amp;quot;处理自治&amp;quot;。此间的关键就在于&amp;quot;分而治之&amp;quot;的&amp;quot;分&amp;quot;字上。前述将某个地域网段内上网的玩家所发出的服务请求分到一组，并分配给同一服务器的做法，其目的不外乎是尽可能地减少网络通讯延迟带来的负面影响。但它不能满足&amp;quot;处理自治&amp;quot;的要求，为了确保自治，应当让同一台服务器所处理的请求本身是&amp;quot;自治&amp;quot;（准确的说法是&amp;quot;自闭包&amp;quot;Closure）的。同一台服务器所处理的所有请求组成一个服务请求集合，这个集合如果与其它任何与其无交集的（请求）集合（包含此集合的父集合除外）不循环依赖，则此服务请求集合是&amp;quot;自闭包&amp;quot;的，而处理此请求集合的服务器，其&amp;quot;行为独立&amp;quot;。
我们可以将针对同一房间的进入请求划分到同一服务请求分组，这些请求相互之间当然是存在循环依赖的，但与其它分组中的请求却不存在循环依赖（本房间内人数的变化不会影响到其它房间），而将它们都分配给同一服务器（不妨命名为&amp;quot;房间管理服务器&amp;quot;，简称&amp;quot;房间服务器&amp;quot;）后，那个服务器将是&amp;quot;处理自治&amp;quot;的。
图三 满足&amp;quot;处理自治&amp;quot;条件的QQ游戏区域&amp;quot;房间管理&amp;quot;服务部署
那么接下来要解决的问题，就是玩家所关注的某个游戏区内，所有房间当前人数数据的实时更新问题。其解决途径与上述的方法类似，我们还是**将所有获取同一区内房间数据的服务请求归为一组，并交给同一服务器处理。**与上文所述场景不同的是，这个服务器需要实时汇集本区内所有房间服务器的房间人数数据。我们可以让每个房间服务器一旦发生数据变更时，就向此服务器（不妨命名为&amp;quot;游戏区域管理服务器&amp;quot;，简称&amp;quot;区服务器&amp;quot;）推送一个变更数据记录，而推送的数据只需包含房间Id和所有进入的玩家Id（房间服务器还包含其它细节数据，例如牌桌占位数据）便可。
另外，由于一个区内的玩家数可能是上十万数量级，一个服务器根本承担不了此种负荷，那么**怎么解决这一矛盾呢？**如果深入分析，我们会发现，更新区内房间数据的请求是一种数据只读类请求，它不会对服务器状态造成变更影响，因此这些请求相互间不存在依赖关系；这样，我们可以将它们再任意划分为更小的分组，而同时这些分组仍然保持&amp;quot;自闭包&amp;quot;特性，然后分配给不同的区服务器。多台区服务器来负责同一区的数据更新请求，负载瓶颈被解决。
当然，此前，还需将这些区服务器分为1台主区服务器和n台从属区服务器；主区服务器负责汇集本区内所有房间服务器的房间人数数据，从属区服务器则从主区服务器实时同步区房间数据副本。
更好的做法，则是如『图五』所示，由房间服务器来充当从属区服务器的角色，玩家进入某个房间后，在玩家进入另外一个房间之前，其客户端都将从此房间对应的房间服务器来更新区内房间数据。要注意的是，图中房间服务器的数据更新利用了所谓的&amp;quot;分布式对象缓存服务&amp;quot;。
玩家进入某个房间后，还要加入某个游戏组才能玩游戏。上篇所述的方案，是让第一个加入某个牌桌的用户，其主机自动充当本牌桌的游戏服务器；而其它玩家要加入此牌桌，其加入请求应当发往第一个加入的用户主机；此后开始游戏，其对弈过程将由第一个加入用户的主机来主导执行。
那么此途径是否同样也符合上述的前两个设计原则呢？游戏在执行的过程中，根据输赢结果，玩家要加分或减分，同时还要记录胜负场数。这些数据必须被持久化（比如在数据库中保存下来），因此游戏服务器（『图六』中的设计，是由4个部署于QQ客户端的&amp;quot;升级&amp;quot;游戏前台逻辑执行服务，加上1个&amp;quot;升级&amp;quot;游戏后台逻辑执行服务，共同组成一个牌桌的&amp;quot;升级&amp;quot;游戏服务）在处理相关游戏执行请求时，将依赖于玩家游戏账户数据服务（『图六』中的所谓&amp;quot;QQGame会话服务&amp;quot;）；
不过这种依赖是非循环的，即玩家游戏账户数据服务器的行为反过来并不依赖于游戏服务器。上文中曾提到，&amp;ldquo;处理自治&amp;quot;原则中非循环依赖是允许的。这里游戏服务器在处理游戏收盘请求时，要调用玩家游戏账户数据服务器来更新相关数据；因为不同玩家的游戏账户数据是相互独立的，此游戏服务器在调用游戏账户数据服务器时，逻辑上不受其它游戏服务器调用游戏账户数据服务器的影响，不存在同步等待问题；所以，游戏服务器在此能够达成负载均衡的意图。 点击图片可以放大
图****四 存在&amp;quot;非循环依赖&amp;quot;的QQ游戏客户端P2P服务与交互逻辑部署
不过，在上述场景中，虽然不存在同步依赖，但是性****能依赖还是存在的，游戏账户数据服务器的处理性能不够时，会造成游戏服务器长时间等待。为此，我们**可以应用分布式数据库表水平分割的技术，**将QQ玩家用户以其登记的行政区来加以分组，并部署于对应区域的数据库中（例如，深圳的玩家数据都在深圳的游戏账户数据库中）。
点击图片可以放大
图五 满足&amp;quot;自闭包&amp;quot;条件的QQ分布式数据库（集群）部署
实际上，我们由此还可以推论出一个数据库表水平分割的原则&amp;ndash;任何数据库表水平分割的方式，必须确保同一数据库实例中的数据记录是&amp;quot;自闭包&amp;quot;的，即不同数据库实例中的数据记录相互间不存在循环依赖。
总之，初步满足QQGame之苛刻性能要求的分布式架构现在已经是初具雏形了，但仍然有很多涉及性能方面的细节问题有待解决。例如，Internet网络通讯延迟的问题、服务器之间协作产生的性能瓶颈问题等等。笔者将在下篇中继续深入探讨这些话题。</description>
    </item>
    
    <item>
      <title>7 QQ游戏百万人同时在线服务器架构实现</title>
      <link>https://haokiu.com/blog/64368e0e78ea4a568fff21e1511c0f43/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/64368e0e78ea4a568fff21e1511c0f43/</guid>
      <description>7 QQ游戏百万人同时在线服务器架构实现 QQ游戏于前几日终于突破了百万人同时在线的关口，向着更为远大的目标迈进，这让其它众多传统的棋牌休闲游戏平台黯然失色，相比之下，联众似乎已经根本不是QQ的对手，因为QQ除了这100万的游戏在线人数外，它还拥有3亿多的注册量（当然很多是重复注册的）以及QQ聊天软件900万的同时在线率，我们已经可以预见未来由QQ构建起来的强大棋牌休闲游戏帝国。
服务器程序，其可承受的同时连接数目是有理论峰值的，在实际应用中，能达到一万人的同时连接并能保证正常的数据交换已经是很不容易了，通常这个值都在2000到5000之间，据说QQ的单台服务器同时连接数目也就是在这个值这间。
如果要实现2000到5000用户的单服务器同时在线，是不难的。在windows下，比较成熟的技术是采用IOCP&amp;mdash;完成端口。只要运用得当，一个完成端口服务器是完全可以达到2K到5K的同时在线量的。但，5K这样的数值离百万这样的数值实在相差太大了，所以，百万人的同时在线是单台服务器肯定无法实现的。
要实现百万人同时在线，首先要实现一个比较完善的完成端口服务器模型，这个模型要求至少可以承载2K到5K的同时在线率（当然，如果你MONEY多，你也可以只开发出最多允许100人在线的服务器）。在构建好了基本的完成端口服务器之后，就是有关服务器组的架构设计了。之所以说这是一个服务器组，是因为它绝不仅仅只是一台服务器，也绝不仅仅是只有一种类型的服务器。
简单地说，实现百万人同时在线的服务器模型应该是：登陆服务器＋大厅服务器＋房间服务器。当然，也可以是其它的模型，但其基本的思想是一样的。下面，我将逐一介绍这三类服务器的各自作用。
/ 1 /
**登陆服务器：**一般情况下，我们会向玩家开放若干个公开的登陆服务器，就如QQ登陆时让你选择的从哪个QQ游戏服务器登陆一样，QQ登陆时让玩家选择的六个服务器入口实际上就是登陆服务器。登陆服务器主要完成负载平衡的作用。详细点说就是，在登陆服务器的背后，有N个大厅服务器，登陆服务器只是用于为当前的客户端连接选择其下一步应该连接到哪个大厅服务器，当登陆服务器为当前的客户端连接选择了一个合适的大厅服务器后，客户端开始根据登陆服务器提供的信息连接到相应的大厅上去，同时客户端断开与登陆服务器的连接，为其他玩家客户端连接登陆服务器腾出套接字资源。
在设计登陆服务器时，至少应该有以下功能：N个大厅服务器的每一个大厅服务器都要与所有的登陆服务器保持连接，并实时地把本大厅服务器当前的同时在线人数通知给各个登陆服务器，这其中包括：用户进入时的同时在线人数增加信息以及用户退出时的同时在线人数减少信息。这里的各个大厅服务器同时在线人数信息就是登陆服务器为客户端选择某个大厅让其登陆的依据。举例来说，玩家A通过登陆服务器1连接到登陆服务器，登陆服务器开始为当前玩家在众多的大厅服务器中根据哪一个大厅服务器人数比较少来选择一个大厅，同时把这个大厅的连接IP和端口发给客户端，客户端收到这个IP和端口信息后，根据这个信息连接到此大厅，同时，客户端断开与登陆服务器之间的连接，这便是用户登陆过程中，在登陆服务器这一块的处理流程。
/ 2 /
大厅服务器：是普通玩家看不到的服务器，它的连接IP和端口信息是登陆服务器通知给客户端的。也就是说，在QQ游戏的本地文件中，具体的大厅服务器连接IP和端口信息是没有保存的。大厅服务器的主要作用是向玩家发送游戏房间列表信息。
这些信息包括：
每个游戏房间的类型 名称 在线人数 连接地址以及其它如游戏帮助文件URL的信息 从****界面上看的话，大厅服务器就是我们输入用户名和密码并校验通过后进入的游戏房间列表界面。
大厅服务器，主要有以下功能：
一是向当前玩家广播各个游戏房间在线人数信息； 二是提供游戏的版本以及下载地址信息； 三是提供各个游戏房间服务器的连接IP和端口信息； 四是提供游戏帮助的URL信息； 五是提供其它游戏辅助功能。 但在这众多的功能中，有一点是最为核心的，即：**为玩家提供进入具体的游戏房间的通道，让玩家顺利进入其欲进入的游戏房间。**玩家根据各个游戏房间在线人数，判定自己进入哪一个房间，然后双击服务器列表中的某个游戏房间后玩家开始进入游戏房间服务器。
/ 3 /
游戏房间服务器：具体地说就是如“斗地主1”，“斗地主2”这样的游戏房间。游戏房间服务器才是具体的负责执行游戏相关逻辑的服务器。这样的游戏逻辑分为两大类：
第一类是通用的游戏房间逻辑，如：进入房间，离开房间，进入桌子，离开桌子以及在房间内说话等； 第二类是游戏桌子逻辑，这个就是各种不同类型游戏的主要区别之处了，比如斗地主中的叫地主或不叫地主的逻辑等，当然，游戏桌子逻辑里也包括有通用的各个游戏里都存在的游戏逻辑，比如在桌子内说话等。 总之，游戏房间服务器才是真正负责执行游戏具体逻辑的服务器。
这里提到的三类服务器，均采用的是完成端口模型，每个服务器最多连接数目是5000人，但是，我在游戏房间服务器上作了逻辑层的限定，最多只允许300人同时在线。其他两个服务器仍然允许最多5000人的同时在线。
如果按照这样的结构来设计，那么要实现百万人的同时在线就应该是这样：
首先是大厅，1000000/5000＝200。也就是说，至少要200台大厅服务器，但通常情况下，考虑到实际使用时服务器的处理能力和负载情况，应该至少准备250台左右的大厅服务器程序。 另外，**具体的各种类型的游戏房间服务器需要多少，**就要根据当前玩各种类型游戏的玩家数目分别计算了，比如斗地主最多是十万人同时在线，每台服务器最多允许300人同时在线，那么需要的斗地主服务器数目就应该不少于：100000/300=333，准备得充分一点，就要准备350台斗地主服务器。 除正常的玩家连接外，还要考虑到：对于登陆服务器，会有250台大厅服务器连接到每个登陆服务器上，这是始终都要保持的连接； 而对于大厅服务器而言，如果仅仅有斗地主这一类的服务器，就要有350多个连接与各个大厅服务器始终保持着。所以从这一点看，结构在某些方面还存在着需要改进的地方，但核心思想是：尽快地提供用户登陆的速度，尽可能方便地让玩家进入游戏中。</description>
    </item>
    
    <item>
      <title>8 大型多人在线游戏服务器架构设计</title>
      <link>https://haokiu.com/blog/5b23fbec804b470cb12e3c20af54d1d0/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/5b23fbec804b470cb12e3c20af54d1d0/</guid>
      <description>8 大型多人在线游戏服务器架构设计 由于大型多人在线游戏服务器理论上需要支持无限多的玩家，所以对服务器端是一个非常大的考验。服务器必须是安全的，可维护性高的，可伸缩性高的，可负载均衡的，支持高并发请求的。面对这些需求，我们在设计服务器的时候就需要慎重考虑，特别是架构的设计，如果前期设计不好，最后面临的很可能是重构。
一款游戏服务器的架构都是慢慢从小变大的，不可能一下子就上来一个完善的服务器构架，目前流行的说法是游戏先上线，再扩展。所以说我们在做架构的时候，一定要把底层的基础组件做好，方便以后扩展，但是刚开始的时候留出一些接口，并不实现它，将来游戏业务的发展，再慢慢扩展。当然，如果前期设计的不好，后期业务扩展了，但架构没办法扩展，只能加班加点搞了。
面对庞大的数据量我们想到的唯一个解决方案就是分而治之，即采用分布式的方式去解决它。把紧凑独立的功能单独拿出来做。分担到不同的物理服务器上面去运行。而且做到可以动态扩展。这就需要我们考虑好模块的划分，尽量要业务独立，关联性低。
前期，由于游戏需要尽快上线，开发周期短，我们需要把服务尽快的跑起来，这个时候的目标应该是尽快完成测试版本开发，单台服务器支持的人数可以稍微低一些，但是当人数暴涨时，我们可以能过多开几组服务来支持新增涨的用户量，即可以平衡扩展就可以了。到后期我们再把具体的模块单独拿出来支持，比如前期逻辑服务器上包括:活动，关卡，背包，技能，好友管理等。后期我们可以把好友，背包管理或其它的单独做一个服务进程，部署在不同的物理服务器上面。我们先按分区的服务进行设计，后面在部署的时候可以部署为世界服务器，下面是一个前期的架构图，下面我们从每个服务器的功能说起：
1，登陆管理服务 负责用户的登陆验证，如果有注册功能的话，也可以放在这里。一般手机游戏直接走sdk验证。网页游戏和客户端游戏会有注册功能，也可以叫用户管理服务。
1.1 用户登陆验证 负责接收客户端的用户登陆请求，验证账号的合法性，是否在黑名单（被封号的用户），是否在白名单（一般是测试账号，服务未开启时也可以进入）。如果是sdk登陆，此服务向第三方服务发起回调请求。
1.2 登陆安全加密 使用加密的传输协议，见通信协议部分。
1.3 是否在白名单内 白名单是给内部测试人员使用的，在服务器未开启的状态下，白名单的用户可以提前进入游戏进行游戏测试。
1.4 判断是否在黑名单 黑名单的用户是禁止登陆的，一般这是一些被封号的用户，拒绝登陆。
1.5 登陆验证 服务器使用私钥解密密码，进行验证，如果是sdk登陆，则直接向第三方服务发起回调。
1.6 登陆令牌（token）生成 当用户登陆验证成功之后，服务器端需要生成一个登陆令牌token,这个token具有时效性，当用户客户端拿到这个token之后，如果在一定时间内没有登陆游戏成功，那么这个token将失败，用户需要重新申请token,token存储在登陆服务这，向外提供用户是否已登陆的接口，其它服务器想验证如果是否登陆，就拿那个服务收到的token来此验证。
1.7 显示用户角色信息 当用户登陆成功之后，显示最近登陆的角色信息。
2，显示公告 用户登陆成功之后，请求公告服务器，获取最新的公告，公告服务先根据token和Userid验证用户是否已登陆，公告有可能根据渠道的不同，显示不同的公告。所以 公告一定是要可以根据渠道编辑的。
3，选区服务 当用户登陆成功之后，请求服务器分区列表服务器，显示当前所有的大区列表。
3.1 验证用户是否已登陆 向登陆服务器请求验证是否已登陆。
3.2 大区列表显示 大区列表信息中只显示大区id和大区名称。这样做是为了安全考虑，不一次性把大区对应的网关ip和端口暴露出来，也可以减少网络的传输量。
3.3 用户点击选择某个大区，客户端拿到大区id再向选区服务请求获取此大区对应的网关ip地址和端口。根据负载算法计算得出。
3.4 网关的选择 选区服务会维护一份网关的配置列表。一个大区对应一到多个网关，当配置有多个网关时，需要定时检测各个网关是否连接正常，如果发现有网关连接不上，需要把大区对应的网关信息设置为无效，不再参与网关的分配，并发出报警。 一般对于网关的选择，可以使用用户id求余法加虚网关节点法。这样在网关节点数量固定的情况下，一个用户总是会被分配到同一个网关上面。但是如果只是使用求余法的话，可能会造成用户分布不均衡，这里可以通过增加网关的虚拟节点（其它就是增加某个网关的权重，让用户多来一些到这个网关上面），这个可以参考哈稀一致性算法。包括后面说到的一个网关对应多个逻辑服务器，也可以使用同样的方法。这部分可以抽象出来一个模块使用。
3.5 选区服务对内要提供修改服务器状态的接口，比如维护中…
4，登陆网关 4.1 建立连接 收到客户端的建立连接请求之后，记录此channel和对应的连接建立时间。并设置如果在一定时间内未收到登陆请求，则断开连接。返回给客户端登陆超时。
4.2 登陆请求 收到登陆请求后，移除记录的channelid信息，向登陆服务器验证用户是否已登陆过,并向外广播用户角色登陆成功的消息。
4.3 登陆成功后，接收网关的其它的消息
4.4 客户端消息合法性验证 在向逻辑服务器转发消息之前验证消息的合法性，具体验证方法见协议安全验 证。
4.5 将客户端消息转发送到对应的逻辑服务器。
5 通信协议 5.1协议序列化和返回序列化 可以直接使用protobuf，直接对协议进行序列化和反序列化。
5.2协议组成 5.2.1 包头构成 包总长度，加密字符串长度，加密字符串内容，userId,playerId,版本号，内包内容。 5.2.2 包体组成 请求的逻辑信息，是protobuf后对应的二进制数据。
包总长度 加密内容 UserId playerId 请求序列id 版本号 内包内容 Int 64 Long Long Long int varchar 4 64 8 8 8 4 变长 5.3 协议内容加密 如果协议明文传输的话，被篡改的风险就非常大，所以我们要对传输协议进行加密传输，由于协议内容大小不固定，为了保证效率，采用对称加密算法，首先客户端使用AES的公钥对消息内容加密（上表中userid之后的信息），客户端把加密后的报文发送到服务器端。AES的公钥在用户第一次连接时获取。
5.4 协议完整性验证 尽管我们对消息做了加密，但也不是万无一失的，为了进一步确保消息没有被篡改，我们需要对消息的完整性进行检测，使用数字摘要的方式，首先客户端对userid及之后的协议信息进行AES加密，加密之后取它的md5值，md5值用于验证数据的完整性。这个md5值会被传送到服务器，如果协议信息被修改了，那个md5就会不同。</description>
    </item>
    
    <item>
      <title>9 百万用户级游戏服务器架构设计</title>
      <link>https://haokiu.com/blog/db5f58a948804f718159e858bf744da9/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/db5f58a948804f718159e858bf744da9/</guid>
      <description>9 百万用户级游戏服务器架构设计 服务器结构探讨 &amp;ndash; 最简单的结构 所谓服务器结构，也就是如何将服务器各部分合理地安排，以实现最初的功能需求。所以，结构本无所谓正确与错误；当然，优秀的结构更有助于系统的搭建，对系统的可扩展性及可维护性也有更大的帮助。
好的结构不是一蹴而就的，而且每个设计者心中的那把尺都不相同，所以这个优秀结构的定义也就没有定论。在这里，我们不打算对现有游戏结构做评价，而是试着从头开始搭建一个我们需要的MMOG结构。
对于一个最简单的游戏服务器来说，它只需要能够接受来自客户端的连接请求，然后处理客户端在游戏世界中的移动及交互，也即游戏逻辑处理即可。如果我们把这两项功能集成到一个服务进程中，则最终的结构很简单：
嗯，太简单了点，这样也敢叫服务器结构？好吧，现在我们来往里面稍稍加点东西，让它看起来更像是服务器结构一些。
一般来说，我们在接入游戏服务器的时候都会要提供一个帐号和密码，验证通过后才能进入。关于为什么要提供用户名和密码才能进入的问题我们这里不打算做过多讨论，云风曾对此也提出过类似的疑问，并给出了只用一个标识串就能进入的设想，有兴趣的可以去看看他们的讨论。但不管是采用何种方式进入，照目前看来我们的服务器起码得提供一个帐号验证的功能。
我们把观察点先集中在一个大区内。在大多数情况下，一个大区内都会有多组游戏服，也就是多个游戏世界可供选择。简单点来实现，我们完全可以抛弃这个大区的概念，认为一个大区也就是放在同一个机房的多台服务器组，各服务器组间没有什么关系。这样，我们可为每组服务器单独配备一台登录服。最后的结构图应该像这样：
该结构下的玩家操作流程为，先选择大区，再选择大区下的某台服务器，即某个游戏世界，点击进入后开始帐号验证过程，验证成功则进入了该游戏世界。但是，如果玩家想要切换游戏世界，他只能先退出当前游戏世界，然后进入新的游戏世界重新进行帐号验证。
早期的游戏大都采用的是这种结构，有些游戏在实现时采用了一些技术手段使得在切换游戏服时不需要再次验证帐号，但整体结构还是未做改变。
该结构存在一个服务器资源配置的问题。因为登录服处理的逻辑相对来说比较简单，就是将玩家提交的帐号和密码送到数据库进行验证，和生成会话密钥发送给游戏服和客户端，操作完成后连接就会立即断开，而且玩家在以后的游戏过程中不会再与登录服打任何交道。这样处理短连接的过程使得系统在大多数情况下都是比较空闲的，但是在某些时候，由于请求比较密集，比如开新服的时候，登录服的负载又会比较大，甚至会处理不过来。
另外在实际的游戏运营中，有些游戏世界很火爆，而有些游戏世界却非常冷清，甚至没有多少人玩的情况也是很常见的。所以，我们能否更合理地配置登录服资源，使得整个大区内的登录服可以共享就成了下一步改进的目标。
服务器结构探讨 &amp;ndash; 登录服的负载均衡 回想一下我们在玩wow时的操作流程：运行wow.exe进入游戏后，首先就会要求我们输入用户名和密码进行验证，验证成功后才会出来游戏世界列表，之后是排队进入游戏世界，开始游戏…
可以看到跟前面的描述有个很明显的不同，那就是要先验证帐号再选择游戏世界。这种结构也就使得登录服不是固定配备给个游戏世界，而是全区共有的。
我们可以试着从实际需求的角度来考虑一下这个问题。正如我们之前所描述过的那样，登录服在大多数情况下都是比较空闲的，也许我们的一个拥有20个游戏世界的大区仅仅使用10台或更少的登录服即可满足需求。而当在开新区的时候，或许要配备40台登录服才能应付那如潮水般涌入的玩家登录请求。所以，登录服在设计上应该能满足这种动态增删的需求，我们可以在任何时候为大区增加或减少登录服的部署。
当然，在这里也不会存在要求添加太多登录服的情况。还是拿开新区的情况来说，即使新增加登录服满足了玩家登录的请求，游戏世界服的承载能力依然有限，玩家一样只能在排队系统中等待，或者是进入到游戏世界中导致大家都卡。
另外，当我们在增加或移除登录服的时候不应该需要对游戏世界服有所改动，也不会要求重启世界服，当然也不应该要求客户端有什么更新或者修改，一切都是在背后自动完成。
最后，有关数据持久化的问题也在这里考虑一下。一般来说，使用现有的商业数据库系统比自己手工技术先进要明智得多。我们需要持久化的数据有玩家的帐号及密码，玩家创建的角色相关信息，另外还有一些游戏世界全局共有数据也需要持久化。
好了，需求已经提出来了，现在来考虑如何将其实现。
对于负载均衡来说，已有了成熟的解决方案。一般最常用，也最简单部署的应该是基于DNS的负载均衡系统了，其通过在DNS中为一个域名配置多个IP地址来实现。最新的DNS服务已实现了根据服务器系统状态来实现的动态负载均衡，也就是实现了真正意义上的负载均衡，这样也就有效地解决了当某台登录服当机后，DNS服务器不能立即做出反应的问题。当然，如果找不到这样的解决方案，自己从头打造一个也并不难。而且，通过DNS来实现的负载均衡已经包含了所做的修改对登录服及客户端的透明。
而对于数据库的应用，在这种结构下，登录服及游戏世界服都会需要连接数据库。从数据库服务器的部署上来说，可以将帐号和角色数据都放在一个中心数据库中，也可分为两个不同的库分别来处理，基到从物理上分到两台不同的服务器上去也行。
但是对于不同的游戏世界来说，其角色及游戏内数据都是互相独立的，所以一般情况下也就为每个游戏世界单独配备一台数据库服务器，以减轻数据库的压力。所以，整体的服务器结构应该是一个大区有一台帐号数据库服务器，所有的登录服都连接到这里。而每个游戏世界都有自己的游戏数据库服务器，只允许本游戏世界内的服务器连接。
最后，我们的服务器结构就像这样：
这里既然讨论到了大区及帐号数据库，所以顺带也说一下关于激活大区的概念。wow中一共有八个大区，我们想要进入某个大区游戏之前，必须到官网上激活这个区，这是为什么呢？
一般来说，在各个大区帐号数据库之上还有一个总的帐号数据库，我们可以称它为中心数据库。比如我们在官网上注册了一个帐号，这时帐号数据是只保存在中心数据库上的。而当我们要到一区去创建角色开始游戏的时候，在一区的帐号数据库中并没有我们的帐号数据，所以，我们必须先到官网上做一次激活操作。这个激活的过程也就是从中心库上把我们的帐号数据拷贝到所要到的大区帐号数据库中。
服务器结构探讨 &amp;ndash; 简单的世界服实现 讨论了这么久我们一直都还没有进入游戏世界服务器内部，现在就让我们来窥探一下里面的结构吧。
对于现在大多数MMORPG来说，游戏服务器要处理的基本逻辑有移动、聊天、技能、物品、任务和生物等，另外还有地图管理与消息广播来对其他高级功能做支撑。如纵队、好友、公会、战场和副本等，这些都是通过基本逻辑功能组合或扩展而成。
在所有这些基础逻辑中，与我们要讨论的服务器结构关系最紧密的当属地图管理方式。决定了地图的管理方式也就决定了我们的服务器结构，我们仍然先从最简单的实现方式开始说起。
回想一下我们曾战斗过无数个夜晚的暗黑破坏神，整个暗黑的世界被分为了若干个独立的小地图，当我们在地图间穿越时，一般都要经过一个叫做传送门的装置。世界中有些地图间虽然在地理上是直接相连的，但我们发现其游戏内部的逻辑却是完全隔离的。可以这样认为，一块地图就是一个独立的数据处理单元。
既然如此，我们就把每块地图都当作是一台独立的服务器，他提供了在这块地图上游戏时的所有逻辑功能，至于内部结构如何划分我们暂不理会，先把他当作一个黑盒子吧。
当两个人合作做一件事时，我们可以以对等的关系相互协商着来做，而且一般也都不会有什么问题。当人数增加到三个时，我们对等的合作关系可能会有些复杂，因为我们每个人都同时要与另两个人合作协商。正如俗语所说的那样，三个和尚可能会碰到没水喝的情况。当人数继续增加，情况就变得不那么简单了，我们得需要一个管理者来对我们的工作进行分工、协调。游戏的地图服务器之间也是这么回事。
一般来说，我们的游戏世界不可能会只有一块或者两块小地图，那顺理成章的，也就需要一个地图管理者。先称它为游戏世界的中心服务器吧，毕竟是管理者嘛，大家都以它为中心。
中心服务器主要维护一张地图ID到地图服务器地址的映射表。当我们要进入某张地图时，会从中心服上取得该地图的IP和port告诉客户端，客户端主动去连接，这样进入他想要去的游戏地图。在整个游戏过程中，客户端始终只会与一台地图服务器保持连接，当要切换地图的时候，在获取到新地图的地址后，会先与当前地图断开连接，再进入新的地图，这样保证玩家数据在服务器上只有一份。
我们来看看结构图是怎样的：
很简单，不是吗。但是简单并不表示功能上会有什么损失，简单也更不能表示游戏不能赚钱。早期不少游戏也确实采用的就是这种简单结构。
服务器结构探讨 &amp;ndash; 继续世界服 都已经看出来了，这种每切换一次地图就要重新连接服务器的方式实在是不够优雅，而且在实际游戏运营中也发现，地图切换导致的卡号，复制装备等问题非常多，这里完全就是一个事故多发地段，如何避免这种频繁的连接操作呢？
最直接的方法就是把那个图倒转过来就行了。客户端只需要连接到中心服上，所有到地图服务器的数据都由中心服来转发。很完美的解决方案，不是吗？
这种结构在实际的部署中也遇到了一些挑战。对于一般的MMORPG服务器来说，单台服务器的承载量平均在2000左右，如果你的服务器很不幸地只能带1000人，没关系，不少游戏都是如此；如果你的服务器上跑了3000多玩家依然比较流畅，那你可以自豪地告诉你的策划，多设计些大量消耗服务器资源的玩法吧，比如大型国战、公会战争等。
2000人，似乎我们的策划朋友们不大愿意接受这个数字。我们将地图服务器分开来原来也是想将负载分开，以多带些客户端，现在要所有的连接都从中心服上转发，那连接数又遇到单台服务器的可最大承载量的瓶颈了。
这里有必要再解释下这个数字。我知道，有人一定会说，才带2000人，那是你水平不行，我随便写个TCP服务器都可带个五六千连接。问题恰恰在于你是随便写的，而MMORPG的服务器是复杂设计的。如果一个演示socket API用的echo服务器就能满足MMOG服务器的需求，那写服务器该是件多么惬意的事啊。
但我们所遇到的事实是，服务器收到一个移动包后，要向周围所有人广播，而不是echo服务器那样简单的回应；服务器在收到一个连接断开通知时要向很多人通知玩家退出事件，并将该玩家的资料写入数据库，而不是echo服务器那样什么都不需要做；服务器在收到一个物品使用请求包后要做一系列的逻辑判断以检查玩家有没有作弊；服务器上还启动着很多定时器用来更新游戏世界的各种状态……
其实这么一比较，我们也看出资源消耗的所在了：服务器上大量的复杂的逻辑处理。再回过头来看看我们想要实现的结构，我们既想要有一个唯一的入口，使得客户端不用频繁改变连接，又希望这个唯一入口的负载不会太大，以致于接受不了多少连接。
仔细看一看这个需求，我们想要的仅仅只是一台管理连接的服务器，并不打算让他承担太多的游戏逻辑。既然如此，那五六千个连接也还有满足我们的要求。至少在现在来说，一个游戏世界内，也就是一组服务器内同时有五六千个在线的玩家还是件让人很兴奋的事。事实上，在大多数游戏的大部分时间里，这个数字也是很让人眼红的。
什么？你说梦幻、魔兽还有史先生的那个什么征途远不止这么点人了！噢，我说的是大多数，是大多数，不包括那些明星。你知道大陆现在有多少游戏在运营吗？或许你又该说，我们不该在一开始就把自己的目标定的太低！好吧，我们还是先不谈这个。
继续我们的结构讨论。一般来说，我们把这台负责连接管理的服务器称为网关服务器，因为内部的数据都要通过这个网关才能出去，不过从这台服务器提供的功能来看，称其为反向代理服务器可能更合适。我们也不在这个名字上纠缠了，就按大家通用的叫法，还是称他为网关服务器吧。
网关之后的结构我们依然可以采用之前描述的方案，只是，似乎并没有必要为每一个地图都开一个独立的监听端口了。我们可以试着对地图进行一些划分，由一个Master Server来管理一些更小的Zone Server，玩家通过网关连接到Master Server上，而实际与地图有关的逻辑是分派给更小的Zone Server去处理。
最后的结构看起来大概是这样的：
服务器结构探讨 &amp;ndash; 最终的结构 如果我们就此打住，可能马上就会有人要嗤之以鼻了，就这点古董级的技术也敢出来现。好吧，我们还是把之前留下的问题拿出来解决掉吧。
一般来说，当某一部分能力达不到我们的要求时，最简单的解决方法就是在此多投入一点资源。既然想要更多的连接数，那就再加一台网关服务器吧。新增加了网关服后需要在大区服上做相应的支持，或者再简单点，有一台主要的网关服，当其负载较高时，主动将新到达的连接重定向到其他网关服上。
而对于游戏服来说，有一台还是多台网关服是没有什么区别的。每个代表客户端玩家的对象内部都保留一个代表其连接的对象，消息广播时要求每个玩家对象使用自己的连接对象发送数据即可，至于连接是在什么地方，那是完全透明的。当然，这只是一种简单的实现，也是普通使用的一种方案，如果后期想对消息广播做一些优化的话，那可能才需要多考虑一下。
既然说到了优化，我们也稍稍考虑一下现在结构下可能采用的优化方案。
首先是当前的Zone Server要做的事情太多了，以至于他都处理不了多少连接。这其中最消耗系统资源的当属生物的AI处理了，尤其是那些复杂的寻路算法，所以我们可以考虑把这部分AI逻辑独立出来，由一台单独的AI服务器来承担。
然后，我们可以试着把一些与地图数据无关的公共逻辑放到Master Server上去实现，这样Zone Server上只保留了与地图数据紧密相关的逻辑，如生物管理，玩家移动和状态更新等。
还有聊天处理逻辑，这部分与游戏逻辑没有任何关联，我们也完全可以将其独立出来，放到一台单独的聊天服务器上去实现。
最后是数据库了，为了减轻数据库的压力，提高数据请求的响应速度，我们可以在数据库之前建立一个数据库缓存服务器，将一些常用数据缓存在此，服务器与数据库的通信都要通过这台服务器进行代理。缓存的数据会定时的写入到后台数据库中。
好了，做完这些优化我们的服务器结构大体也就定的差不多了，暂且也不再继续深入，更细化的内容等到各个部分实现的时候再探讨。
好比我们去看一场晚会， 舞台上演员们按着预定的节目单有序地上演着，但这就是整场晚会的全部吗？显然不止，在幕后还有太多太多的人在忙碌着，甚至在晚会前和晚会后都有。我们的游戏服务器也如此。
在之前描述的部分就如同舞台上的演员，是我们能直接看到的，幕后的工作人员我们也来认识一下。
现实中有警察来维护秩序，游戏中也如此，这就是我们常说的GM。GM可以采用跟普通玩家一样的拉入方式来进入游戏，当然权限会比普通玩家高一些，也可以提供一台GM服务器专门用来处理GM命令，这样可以有更高的安全性，GM服一般接在中心服务器上。
在以时间收费的游戏中，我们还需要一台计费的服务器，这台服务器一般接在网关服务器上，注册玩家登录和退出事件以记录玩家的游戏时间。
任何为用户提供服务的地方都会有日志记录，游戏服务器当然也不例外。从记录玩家登录的时间，地址，机器信息到游戏过程中的每一项操作都可以作为日志记录下来，以备查错及数据挖掘用。至于搜集玩家机器资料所涉及到的法律问题不是我们该考虑的。
差不多就这么多了吧，接下来我们会按照这个大致的结构来详细讨论各部分的实现。
服务器结构探讨 —— 一点杂谈 再强调一下，服务器结构本无所谓好坏，只有是否适合自己。我们在前面探讨了一些在现在的游戏中见到过的结构，并尽我所知地分析了各自存在的一些问题和可以做的一些改进，希望其中没有谬误，如果能给大家也带来些启发那自然更好。
突然发现自己一旦罗嗦起来还真是没完没了。接下来先说说我在开发中遇到过的一些困惑和一基础问题探讨吧，这些问题可能有人与我一样，也曾遇到过，或者正在被困扰中，而所要探讨的这些基础问题向来也是争论比较多的，我们也不评价其中的好与坏，只做简单的描述。
首先是服务器操作系统，linux与windows之争随处可见，其实在大多数情况下这不是我们所能决定的，似乎各大公司也基本都有了自己的传统，如网易的freebsd，腾讯的linux等。如果真有权利去选择的话，选自己最熟悉的吧。
决定了OS也就基本上确定了网络IO模型，windows上的IOCP和linux下的epool，或者直接使用现有的网络框架，如ACE和asio等，其他还有些商业的网络库在国内的使用好像没有见到，不符合中国国情嘛。:)
然后是网络协议的选择，以前的选择大多倾向于UDP，为了可靠传输一般自己都会在上面实现一层封装，而现在更普通的是直接采用本身就很可靠的TCP，或者TCP与UDP的混用。早期选择UDP的主要原因还是带宽限制，现在宽带普通的情况下TCP比UDP多出来的一点点开销与开发的便利性相比已经不算什么了。当然，如果已有了成熟的可靠UDP库，那也可以继续使用着。
还有消息包格式的定义，这个曾在云风的blog上展开过激烈的争论。消息包格式定义包括三段，包长、消息码和包体，争论的焦点在于应该是消息码在前还是包长在前，我们也把这个当作是信仰问题吧，有兴趣的去云风的blog上看看，论论。
另外早期有些游戏的包格式定义是以特殊字符作分隔的，这样一个好处是其中某个包出现错误后我们的游戏还能继续。但实际上，我觉得这是完全没有必要的，真要出现这样的错误，直接断开这个客户端的连接可能更安全。而且，以特殊字符做分隔的消息包定义还加大了一点点网络数据量。
最后是一个纯技术问题，有关socket连接数的最大限制。开始学习网络编程的时候我犯过这样的错误，以为port的定义为unsigned short，所以想当然的认为服务器的最大连接数为65535，这会是一个硬性的限制。而实际上，一个socket描述符在windows上的定义是unsigned int，因此要有限制那也是四十多亿，放心好了。
在服务器上port是监听用的，想象这样一种情况，web server在80端口上监听，当一个连接到来时，系统会为这个连接分配一个socket句柄，同时与其在80端口上进行通讯；当另一个连接到来时，服务器仍然在80端口与之通信，只是分配的socket句柄不一样。这个socket句柄才是描述每个连接的唯一标识。按windows网络编程第二版上的说法，这个上限值配置影响。</description>
    </item>
    
    <item>
      <title>bind 函数重难点解析</title>
      <link>https://haokiu.com/blog/48af9bced29e4786944b5661c4155665/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/48af9bced29e4786944b5661c4155665/</guid>
      <description>bind 函数重难点解析 bind 函数如何选择绑定地址 bind 函数的基本用法如下：
struct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); bindaddr.sin_port = htons(3000); if (bind(listenfd, (struct sockaddr *)&amp;amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout &amp;lt;&amp;lt; &amp;#34;bind listen socket error.&amp;#34; &amp;lt;&amp;lt; std::endl; return -1; } 其中 bind 的地址我们使用了一个宏叫 INADDR_ANY ，关于这个宏的解释如下：
If an application does not care what local address is assigned, specify the constant value INADDR_ANY for an IPv4 local address or the constant value in6addr_any for an IPv6 local address in the sa_data member of the name parameter. This allows the underlying service provider to use any appropriate network address, potentially simplifying application programming in the presence of multihomed hosts (that is, hosts that have more than one network interface and address).</description>
    </item>
    
    <item>
      <title>C&#43;&#43; 17 结构化绑定</title>
      <link>https://haokiu.com/blog/b08571a528324d72b376f4ccb2a6dad3/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/b08571a528324d72b376f4ccb2a6dad3/</guid>
      <description>C++ 17 结构化绑定 stl 的 map 容器很多读者应该都很熟悉，map 容器提供了一个 insert 方法，我们用该方法向 map 中插入元素，但是应该很少有人记得 insert 方法的返回值是什么类型，让我们来看一下 C++98/03 提供的 insert 方法的签名：
std::pair&amp;lt;iterator,bool&amp;gt; insert( const value_type&amp;amp; value ); 这里我们仅关心其返回值，这个返回值是一个 std::pair 类型，由于 map 中的元素的 key 不允许重复，所以如果 insert 方法调用成功，T1 是被成功插入到 map 中的元素的迭代器，T2 的类型为 bool，此时其值为 true（表示插入成功）；如果 insert 由于 key 重复，T1 是造成 insert 插入失败、已经存在于 map 中的元素的迭代器，此时 T2 的值为 false（表示插入失败）。
在 C++98/03 标准中我们可以使用 std::pair 的 first 和 second 属性来分别引用 T1 和 T2 的值。如下面的我们熟悉的代码所示：
#include &amp;lt;iostream&amp;gt; #include &amp;lt;string&amp;gt; #include &amp;lt;map&amp;gt; int main() { std::map&amp;lt;std::string, int&amp;gt; cities; cities[&amp;#34;beijing&amp;#34;] = 0; cities[&amp;#34;shanghai&amp;#34;] = 1; cities[&amp;#34;shenzhen&amp;#34;] = 2; cities[&amp;#34;guangzhou&amp;#34;] = 3; //for (const auto&amp;amp; [key, value] : m) //{ // std::cout &amp;lt;&amp;lt; key &amp;lt;&amp;lt; &amp;#34;: &amp;#34; &amp;lt;&amp;lt; value &amp;lt;&amp;lt; std::endl; //} //这一行在 C++11 之前写法实在太麻烦了， //std::pair&amp;lt;std::map&amp;lt;std::string, int&amp;gt;::iterator, int&amp;gt; insertResult = cities.</description>
    </item>
    
    <item>
      <title>C&#43;&#43;必知必会的知识点</title>
      <link>https://haokiu.com/blog/6176f55c32444820a0055fadcf89273c/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/6176f55c32444820a0055fadcf89273c/</guid>
      <description>C++必知必会的知识点 如何成为一名合格的C/C++开发者？
不定参数函数实现var_arg系列的宏
你一定要搞明白的C函数调用方式与栈原理
深入理解C/C++中的指针
详解C++11中的智能指针
C++17结构化绑定
C++必须掌握的pimpl惯用法
用Visual Studio调试Linux程序
如何使用Visual Studio管理和阅读开源项目代码
利用cmake工具生成Visual Studio工程文件</description>
    </item>
    
    <item>
      <title>connect 函数在阻塞和非阻塞模式下的行为</title>
      <link>https://haokiu.com/blog/f82abb8bce8a4c85b9b8c665cb9fe48d/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/f82abb8bce8a4c85b9b8c665cb9fe48d/</guid>
      <description>connect 函数在阻塞和非阻塞模式下的行为 在 socket 是阻塞模式下 connect 函数会一直到有明确的结果才会返回（或连接成功或连接失败），如果服务器地址“较远”，连接速度比较慢，connect 函数在连接过程中可能会导致程序阻塞在 connect 函数处好一会儿（如两三秒之久），虽然这一般也不会对依赖于网络通信的程序造成什么影响，但在实际项目中，我们一般倾向使用所谓的异步的 connect 技术，或者叫非阻塞的 connect。这个流程一般有如下步骤：
1. 创建socket，并将 socket 设置成非阻塞模式； 2. 调用 connect 函数，此时无论 connect 函数是否连接成功会立即返回；如果返回-1并不表示连接出错，如果此时错误码是EINPROGRESS 3. 接着调用 select 函数，在指定的时间内判断该 socket 是否可写，如果可写说明连接成功，反之则认为连接失败。 按上述流程编写代码如下：
/** * 异步的connect写法，nonblocking_connect.cpp * zhangyl 2018.12.17 */ #include &amp;lt;sys/types.h&amp;gt; #include &amp;lt;sys/socket.h&amp;gt; #include &amp;lt;arpa/inet.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; #include &amp;lt;iostream&amp;gt; #include &amp;lt;string.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;fcntl.h&amp;gt; #include &amp;lt;errno.h&amp;gt; #define SERVER_ADDRESS &amp;#34;127.0.0.1&amp;#34; #define SERVER_PORT 3000 #define SEND_DATA &amp;#34;helloworld&amp;#34; int main(int argc, char* argv[]) { //1.创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout &amp;lt;&amp;lt; &amp;#34;create client socket error.&amp;#34; &amp;lt;&amp;lt; std::endl; return -1; } //连接成功以后，我们再将 clientfd 设置成非阻塞模式， //不能在创建时就设置，这样会影响到 connect 函数的行为 int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(clientfd, F_SETFL, newSocketFlag) == -1) { close(clientfd); std::cout &amp;lt;&amp;lt; &amp;#34;set socket to nonblock error.</description>
    </item>
    
    <item>
      <title>leveldb源码分析</title>
      <link>https://haokiu.com/blog/c898014e5b304df0bade6b12d638467a/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/c898014e5b304df0bade6b12d638467a/</guid>
      <description>leveldb源码分析 leveldb源码分析1
leveldb源码分析2
leveldb源码分析3
leveldb源码分析4
leveldb源码分析5
leveldb源码分析6
leveldb源码分析7
leveldb源码分析8
leveldb源码分析9
leveldb源码分析10
leveldb源码分析11
leveldb源码分析12
leveldb源码分析13
leveldb源码分析14
leveldb源码分析15
leveldb源码分析16
leveldb源码分析17
leveldb源码分析18
leveldb源码分析19
leveldb源码分析20
leveldb源码分析21
leveldb源码分析22</description>
    </item>
    
    <item>
      <title>leveldb源码分析1</title>
      <link>https://haokiu.com/blog/1776ae3c50104b7ea0c90cf31322958a/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1776ae3c50104b7ea0c90cf31322958a/</guid>
      <description>leveldb源码分析1 本系列《leveldb源码分析》共有22篇文章，这是第一篇。
leveldb，除去测试部分，代码不超过1.5w行。这是一个单机k/v存储系统，决定看完它，并把源码分析完整的写下来，还是会很有帮助的。我比较厌烦太复杂的东西，而Leveldb的逻辑很清晰，代码不多、风格很好，功能就不用讲了，正合我的胃口。 BTW，分析Leveldb也参考了网上一些朋友写的分析blog，如【巴山独钓】。
leveldb源码分析 2012年1月21号开始研究下leveldb的代码，Google两位大牛开发的单机KV存储系统，涉及到了skip list、内存KV table、LRU cache管理、table文件存储、operation log系统等。先从边边角角的小角色开始扫。
不得不说，Google大牛的代码风格太好了，读起来很舒服，不像有些开源项目，很快就看不下去了。
开始之前先来看看Leveldb的基本框架，几大关键组件，如图1-1所示。
图1-1
leveldb是一种基于operation log的文件系统，是Log-Structured-Merge Tree的典型实现。LSM源自Ousterhout和Rosenblum在1991年发表的经典论文&amp;laquo;The Design and Implementation of a Log-Structured File System &amp;raquo;。
由于采用了op log，它就可以把随机的磁盘写操作，变成了对op log的append操作，因此提高了IO效率，最新的数据则存储在内存memtable中。
当op log文件大小超过限定值时，就定时做check point。Leveldb会生成新的Log文件和Memtable，后台调度会将Immutable Memtable的数据导出到磁盘，形成一个新的SSTable文件。SSTable就是由内存中的数据不断导出并进行Compaction操作后形成的，而且SSTable的所有文件是一种层级结构，第一层为Level 0，第二层为Level 1，依次类推，层级逐渐增高，这也是为何称之为LevelDb的原因。
1. 一些约定 先说下代码中的一些约定：
1.1 字节序 Leveldb对于数字的存储是little-endian的，在把int32或者int64转换为char*的函数中，是按照先低位再高位的顺序存放的，也就是little-endian的。
1.2 VarInt 把一个int32或者int64格式化到字符串中，除了上面说的little-endian字节序外，大部分还是变长存储的，也就是VarInt。对于VarInt，每byte的有效存储是7bit的，用最高的8bit位来表示是否结束，如果是1就表示后面还有一个byte的数字，否则表示结束。直接见Encode和Decode函数。
在操作log中使用的是Fixed存储格式。
1.3 字符比较 是基于unsigned char的，而非char。
2. 基本数据结构 别看是基本数据结构，有些也不是那么简单的，像LRU Cache管理和Skip list那都算是leveldb的核心数据结构。
2.1 Slice Leveldb中的基本数据结构：
包括length和一个指向外部字节数组的指针。 和string一样，允许字符串中包含’\0’。 提供一些基本接口，可以把const char和string转换为Slice；把Slice转换为string，取得数据指针const char。
2.2 Status Leveldb 中的返回状态，将错误号和错误信息封装成Status类，统一进行处理。并定义了几种具体的返回状态，如成功或者文件不存在等。
为了节省空间Status并没有用std::string来存储错误信息，而是将返回码(code), 错误信息message及长度打包存储于一个字符串数组中。
成功状态OK 是NULL state_，否则state_ 是一个包含如下信息的数组:
state_[0..3] == 消息message长度 state_[4] == 消息code state_[5..] ==消息message 2.3 Arena Leveldb的简单的内存池，它所作的工作十分简单，申请内存时，将申请到的内存块放入std::vector blocks_中，在Arena的生命周期结束后，统一释放掉所有申请到的内存，内部结构如图2.3-1所示。
Arena主要提供了两个申请函数：其中一个直接分配内存，另一个可以申请对齐的内存空间。
Arena没有直接调用delete/free函数，而是由Arena的析构函数统一释放所有的内存。
应该说这是和leveldb特定的应用场景相关的，比如一个memtable使用一个Arena，当memtable被释放时，由Arena统一释放其内存。
2.4 Skip list **Skip list(跳跃表）是一种可以代替平衡树的数据结构。**Skip lists应用概率保证平衡，平衡树采用严格的旋转（比如平衡二叉树有左旋右旋）来保证平衡，因此Skip list比较容易实现，而且相比平衡树有着较高的运行效率。
从概率上保持数据结构的平衡比显式的保持数据结构平衡要简单的多。对于大多数应用，用skip list要比用树更自然，算法也会相对简单。由于skip list比较简单，实现起来会比较容易，虽然和平衡树有着相同的时间复杂度(O(logn))，但是skip list的常数项相对小很多。skip list在空间上也比较节省。一个节点平均只需要1.333个指针（甚至更少），并且不需要存储保持平衡的变量。
如图2.4-1所示。
在Leveldb中，skip list是实现memtable的核心数据结构，memtable的KV数据都存储在skip list中。</description>
    </item>
    
    <item>
      <title>leveldb源码分析10</title>
      <link>https://haokiu.com/blog/603a94de7932474cbf7478a2d7b94ebf/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/603a94de7932474cbf7478a2d7b94ebf/</guid>
      <description>leveldb源码分析10 本系列《leveldb源码分析》共有22篇文章，这是第十篇
6.SSTable之四 6.6 遍历Table 6.6.1 遍历接口 Table导出了一个返回Iterator的接口，通过Iterator对象，调用者就可以遍历Table的内容，它简单的返回了一个TwoLevelIterator对象。见函数实现：
Iterator* NewIterator(const ReadOptions&amp;amp;options) const; { return NewTwoLevelIterator(rep_-&amp;gt;index_block-&amp;gt;NewIterator(rep_-&amp;gt;options.comparator), &amp;amp;Table::BlockReader,const_cast&amp;lt;Table*&amp;gt;(this), options); } // 函数NewTwoLevelIterator创建了一个TwoLevelIterator对象： Iterator* NewTwoLevelIterator(Iterator* index_iter,BlockFunction block_function, void* arg, constReadOptions&amp;amp; options) { return newTwoLevelIterator(index_iter, block_function, arg, options); } 这里有一个函数指针BlockFunction，类型为：
typedef Iterator* (*BlockFunction)(void*, const ReadOptions&amp;amp;, constSlice&amp;amp;); 为什么叫TwoLevelIterator呢，下面就来看看。
6.6.2 TwoLevelIterator 它也是Iterator的子类，之所以叫two level应该是不仅可以迭代其中存储的对象，它还接受了一个函数BlockFunction，可以遍历存储的对象，可见它是专门为Table定制的。 我们已经知道各种Block的存储格式都是相同的，但是各自block data存储的k/v又互不相同，于是我们就需要一个途径，能够在使用同一个方式遍历不同的block时，又能解析这些k/v。这就是BlockFunction，它又返回了一个针对block data的Iterator。Block和block data存储的k/v对的key是统一的。 先来看类的主要成员变量：
BlockFunction block_function_; // block操作函数 void* arg_; // BlockFunction的自定义参数 const ReadOptions options_; // BlockFunction的read option参数 Status status_; // 当前状态 IteratorWrapper index_iter_; // 遍历block的迭代器 IteratorWrapper data_iter_; // May be NULL-遍历block data的迭代器 // 如果data_iter_ != NULL，data_block_handle_保存的是传递给 // block_function_的index value，以用来创建data_iter_ std::string data_block_handle_; 下面分析一下对于Iterator几个接口的实现。
S1 对于其Key和Value接口都是返回的data_iter_对应的key和value： virtual bool Valid() const { return data_iter_.Valid(); } virtual Slice key() const { assert(Valid()); return data_iter_.</description>
    </item>
    
    <item>
      <title>leveldb源码分析11</title>
      <link>https://haokiu.com/blog/0159e326ba0e4917878529ee1ae3af48/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/0159e326ba0e4917878529ee1ae3af48/</guid>
      <description>leveldb源码分析11 本系列《leveldb源码分析》共有22篇文章，这是第十一篇
7.TableCache 这章的内容比较简单，篇幅也不长。
7.1 TableCache简介 TableCache缓存的是Table对象，每个DB一个，它内部使用一个LRUCache缓存所有的table对象，实际上其内容是文件编号{file number, TableAndFile}*。TableAndFile是一个拥有2个变量的结构体：RandomAccessFile和Table；
TableCache类的主要成员变量有：
Env* const env_; // 用来操作文件 const std::string dbname_; // db名 Cache* cache_; // LRUCache 三个函数接口，其中的参数**@file_number是文件编号，@file_size**是文件大小：
void Evict(uint64_tfile_number); // 该函数用以清除指定文件所有cache的entry， //函数实现很简单，就是根据file number清除cache对象。 EncodeFixed64(buf,file_number); cache_-&amp;gt;Erase(Slice(buf, sizeof(buf))); Iterator* NewIterator(constReadOptions&amp;amp; options, uint64_t file_number, uint64_t file_size, Table**tableptr = NULL); //该函数为指定的file返回一个iterator(对应的文件长度必须是&amp;#34;file_size&amp;#34;字节). //如果tableptr不是NULL，那么tableptr保存的是底层的Table指针。 //返回的tableptr是cache拥有的，不能被删除，生命周期同返回的iterator Status Get(constReadOptions&amp;amp; options, uint64_t file_number,uint64_t file_size, const Slice&amp;amp; k,void* arg, void(*handle_result)(void*, const Slice&amp;amp;, const Slice&amp;amp;)); // 这是一个查找函数，如果在指定文件中seek 到internal key &amp;#34;k&amp;#34; 找到一个entry， //就调用 (*handle_result)(arg,found_key, found_value). 7.2 TableCache::Get() 先来看看**Get接口，**只有几行代码：
Cache::Handle* handle = NULL; Status s =FindTable(file_number, file_size, &amp;amp;handle); if (s.ok()) { Table* t =reinterpret_cast&amp;lt;TableAndFile*&amp;gt;(cache_-&amp;gt;Value(handle))-&amp;gt;table; s = t-&amp;gt;InternalGet(options,k, arg, saver); cache_-&amp;gt;Release(handle); } return s; 首先根据file_number找到Table的cache对象，如果找到了就调用Table::InternalGet，对查找结果的处理在调用者传入的saver回调函数中。 Cache在Lookup找到cache对象后，如果不再使用需要调用Release减引用计数。这个见Cache的接口说明。</description>
    </item>
    
    <item>
      <title>leveldb源码分析12</title>
      <link>https://haokiu.com/blog/cd6a8ad07c9f4c479a1e88591f05cd70/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/cd6a8ad07c9f4c479a1e88591f05cd70/</guid>
      <description>leveldb源码分析12 本系列《leveldb源码分析》共有22篇文章，这是第十二篇
8.FilterPolicy&amp;amp;Bloom之1 8.1 FilterPolicy 因名知意，FilterPolicy是用于key过滤的，可以快速的排除不存在的key。前面介绍Table的时候，在Table::InternalGet函数中有过一面之缘。 FilterPolicy有3个接口：
virtual const char* Name() const = 0; // 返回filter的名字 virtual void CreateFilter(const Slice* keys, int n, std::string* dst)const = 0; virtual bool KeyMayMatch(const Slice&amp;amp; key, const Slice&amp;amp; filter)const = 0; CreateFilter接口，它根据指定的参数创建过滤器，并将结果append到dst中，注意：不能修改dst的原始内容，只做append。 参数@keys[0,n-1]包含依据用户提供的comparator排序的key列表&amp;ndash;可重复，并把根据这些key创建的filter追加到@*dst中。 KeyMayMatch，参数@filter包含了调用CreateFilter函数append的数据，如果key在传递函数CreateFilter的key列表中，则必须返回true。
注意：它不需要精确，也就是即使key不在前面传递的key列表中，也可以返回true，但是如果key在列表中，就必须返回true。 涉及到的类如图8.1-1所示。
8.2InternalFilterPolicy 这是一个简单的FilterPolicy的wrapper，以方便的把FilterPolicy应用在InternalKey上，InternalKey是Leveldb内部使用的key，这些前面都讲过。它所做的就是从InternalKey拆分得到user key，然后在user key上做FilterPolicy的操作。 它有一个成员：
constFilterPolicy* const user_policy_; 其Name()返回的是user_policy_-&amp;gt;Name()；
bool InternalFilterPolicy::KeyMayMatch(const Slice&amp;amp; key, constSlice&amp;amp; f) const { returnuser_policy_-&amp;gt;KeyMayMatch(ExtractUserKey(key), f); } void InternalFilterPolicy::CreateFilter(const Slice* keys, int n,std::string* dst) const { Slice* mkey =const_cast&amp;lt;Slice*&amp;gt;(keys); for (int i = 0; i &amp;lt; n; i++)mkey[i] = ExtractUserKey(keys[i]); user_policy_-&amp;gt;CreateFilter(keys, n, dst); } 8.3 BloomFilter 8.3.1 基本理论 Bloom Filter实际上是一种hash算法，数学之美系列有专门介绍。它是由巴顿.布隆于一九七零年提出的，它实际上是一个很长的二进制向量和一系列随机映射函数。 Bloom Filter将元素映射到一个长度为m的bit向量上的一个bit，当这个bit是1时，就表示这个元素在集合内。使用hash的缺点就是元素很多时可能有冲突，为了减少误判，就使用k个hash函数计算出k个bit，只要有一个bit为0，就说明元素肯定不在集合内。下面的图8.3-1是一个示意图。
在leveldb的实现中，Name()返回&amp;quot;leveldb.BuiltinBloomFilter&amp;quot;，因此metaindex block** 中的key就是”filter.leveldb.BuiltinBloomFilter”。Leveldb使用了double hashing来模拟多个hash函数，当然这里不是用来解决冲突的。 和线性再探测（linearprobing）一样，Double hashing从一个hash值开始，重复向前迭代，直到解决冲突或者搜索完hash表。不同的是，double hashing使用的是另外一个hash函数，而不是固定的步长。 给定两个独立的hash函数h1和h2，对于hash表T和值k，第i次迭代计算出的位置就是：h(i, k) = (h1(k) + i*h2(k)) mod |T|。 对此，Leveldb选择的hash函数是：</description>
    </item>
    
    <item>
      <title>leveldb源码分析13</title>
      <link>https://haokiu.com/blog/f110bd8130344cbf801fc30d4d7a7ce9/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/f110bd8130344cbf801fc30d4d7a7ce9/</guid>
      <description>leveldb源码分析13 本系列《leveldb源码分析》共有22篇文章，这是第十三篇
8.FilterPolicy&amp;amp;Bloom之二 8.5 构建FilterBlock 8.5.1 FilterBlockBuilder 了解了filter机制，现在来看看filter block的构建，这就是类FilterBlockBuilder。它为指定的table构建所有的filter，结果是一个string字符串，并作为一个block存放在table中。它有三个函数接口：
// 开始构建新的filter block，TableBuilder在构造函数和Flush中调用 void StartBlock(uint64_tblock_offset); // 添加key，TableBuilder每次向data block中加入key时调用 void AddKey(const Slice&amp;amp;key); // 结束构建，TableBuilder在结束对table的构建时调用 Slice Finish(); FilterBlockBuilder的构建顺序必须满足如下范式：(StartBlock AddKey*)* Finish，显然这和前面讲过的BlockBuilder有所不同。 其成员变量有：
const FilterPolicy* policy_; // filter类型，构造函数参数指定 std::string keys_; //Flattened key contents std::vector&amp;lt;size_t&amp;gt; start_; // 各key在keys_中的位置 std::string result_; // 当前计算出的filter data std::vector&amp;lt;uint32_t&amp;gt;filter_offsets_; // 各个filter在result_中的位置 std::vector&amp;lt;Slice&amp;gt; tmp_keys_;// policy_-&amp;gt;CreateFilter()参数 前面说过base是2KB，这对应两个常量kFilterBase =11, kFilterBase =(1&amp;lt;&amp;lt;kFilterBaseLg)；其实从后面的实现来看tmp_keys_完全不必作为成员变量，直接作为函数GenerateFilter()的栈变量就可以。下面就分别分析三个函数接口。
8.5.2 FilterBlockBuilder::StartBlock() 它根据参数block_offset计算出filter index，然后循环调用GenerateFilter生产新的Filter。
uint64_t filter_index =(block_offset / kFilterBase); assert(filter_index &amp;gt;=filter_offsets_.size()); while (filter_index &amp;gt;filter_offsets_.size()) GenerateFilter(); 我们来到GenerateFilter这个函数，看看它的逻辑。
//S1 如果filter中key个数为0，则直接压入result_.size()并返回 const size_t num_keys =start_.size(); if (num_keys == 0) { // there are no keys for this filter filter_offsets_.push_back(result_.size()); //result_.size()应该是0 return; } //S2 从key创建临时key list，根据key的序列字符串kyes_和各key在keys_ //中的开始位置start_依次提取出key。 start_.</description>
    </item>
    
    <item>
      <title>leveldb源码分析14</title>
      <link>https://haokiu.com/blog/5a5f7db3f4fc4684a0c7ddb21dd6ea40/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/5a5f7db3f4fc4684a0c7ddb21dd6ea40/</guid>
      <description>leveldb源码分析14 本系列《leveldb源码分析》共有22篇文章，这是第十四篇
9 LevelDB框架之1
到此为止，基本上Leveldb的主要功能组件都已经分析完了，下面就是把它们组合在一起，形成一个高性能的k/v存储系统。这就是leveldb::DB类。 这里先看一下LevelDB的导出接口和涉及的类，后面将依次以接口分析的方式展开。 而实际上leveldb::DB只是一个接口类，真正的实现和框架类是DBImpl这个类，正是它集合了上面的各种组件。 此外，还有Leveldb对版本的控制，执行版本控制的是Version和VersionSet类。 在leveldb的源码中，DBImpl和VersionSet是两个庞然大物，体量基本算是最大的。对于这两个类的分析，也会分散在打开、销毁和快照等等这些功能中，很难在一个地方集中分析。 作者在文档impl.html中描述了leveldb的实现，其中包括文件组织、compaction和recovery等等。下面的9.1和9.2基本都是翻译子impl.html文档。 在进入框架代码之前，先来了解下leveldb的文件组织和管理。
9.1 DB文件管理 9.1.1 文件类型
对于一个数据库Level包含如下的6种文件:
1/[0-9]+.log：db操作日志 这就是前面分析过的操作日志，log文件包含了最新的db更新，每个更新都以append的方式追加到文件结尾。当log文件达到预定大小时（缺省大约4MB），leveldb就把它转换为一个有序表（如下-2），并创建一个新的log文件。 当前的log文件在内存中的存在形式就是memtable，每次read操作都会访问memtable，以保证read读取到的是最新的数据。
2/[0-9]+.sst：db的sstable文件 这两个就是前面分析过的静态sstable文件，sstable存储了以key排序的元素。每个元素或者是key对应的value，或者是key的删除标记（删除标记可以掩盖更老sstable文件中过期的value）。 Leveldb把sstable文件通过level的方式组织起来，从log文件中生成的sstable被放在level 0。当level 0的sstable文件个数超过设置（当前为4个）时，leveldb就把所有的level 0文件，以及有重合的level 1文件merge起来，组织成一个新的level 1文件（每个level 1文件大小为2MB）。 Level 0的SSTable文件（后缀为.sst）和Level&amp;gt;1的文件相比有特殊性：这个层级内的.sst文件，两个文件可能存在key重叠。对于Level&amp;gt;0，同层sstable文件的key不会重叠。考虑level&amp;gt;0，level中的文件的总大小超过10^level MB时（如level=1是10MB，level=2是100MB），那么level中的一个文件，以及所有level+1中和它有重叠的文件，会被merge到level+1层的一系列新文件。Merge操作的作用是将更新从低一级level迁移到最高级，只使用批量读写（最小化seek操作，提高效率）。
3/MANIFEST-[0-9]+：DB元信息文件 它记录的是leveldb的元信息，比如DB使用的Comparator名，以及各SSTable文件的管理信息：如Level层数、文件名、最小key和最大key等等。
4/CURRENT：记录当前正在使用的Manifest文件 它的内容就是当前的manifest文件名；因为在LevleDb的运行过程中，随着Compaction的进行，新的SSTable文件被产生，老的文件被废弃。并生成新的Manifest文件来记载sstable的变动，而CURRENT则用来记录我们关心的Manifest文件。 当db被重新打开时，leveldb总是生产一个新的manifest文件。Manifest文件使用log的格式，对服务状态的改变（新加或删除的文件）都会追加到该log中。 上面的log文件、sst文件、清单文件，末尾都带着序列号，其序号都是单调递增的（随着next_file_number从1开始递增），以保证不和之前的文件名重复。
5/log：系统的运行日志，记录系统的运行信息或者错误日志。 6/dbtmp：临时数据库文件，repair时临时生成的。 这里就涉及到几个关键的number计数器，log文件编号，下一个文件（sstable、log和manifest）编号，sequence。 所有正在使用的文件编号，包括log、sstable和manifest都应该小于下一个文件编号计数器。 9.1.2 Level 0
当操作log超过一定大小时（缺省是1MB），执行如下操作：
S1 创建新的memtable和log文件，并重导向新的更新到新memtable和log中； S2 在后台： S2.1 将前一个memtable的内容dump到sstable文件； S2.2 丢弃前一个memtable； S2.3 删除旧的log文件和memtable S2.4 把创建的sstable文件放到level 0
9.2 Compaction 当level L的总文件大小查过限制时，我们就在后台执行compaction操作。Compaction操作从level L中选择一个文件f，以及选择中所有和f有重叠的文件。如果某个level (L+1)的文件ff只是和f部分重合，compaction依然选择ff的完整内容作为输入，在compaction后f和ff都会被丢弃。 另外：因为level 0有些特殊（同层文件可能有重合），从level 0到level 1的compaction就需要特殊对待：level 0的compaction可能会选择多个level 0文件，如果它们之间有重叠。 Compaction将选择的文件内容merge起来，并生成到一系列的level (L+1)文件中，如果输出文件超过设置（2MB），就切换到新的。当输出文件的key范围太大以至于和超过10个level (L+2)文件有重合时，也会切换。后一个规则确保了level (L+1)的文件不会和过多的level (L+2)文件有重合，其后的level (L+1) compaction不会选择过多的level (L+2)文件。 老的文件会被丢弃，新创建的文件将加入到server状态中。 Compaction操作在key空间中循环执行，详细讲一点就是，对于每个level，我们记录上次compaction的ending key。Level的下一次compaction将选择ending key之后的第一个文件（如果这样的文件不存在，将会跳到key空间的开始）。 Compaction会忽略被写覆盖的值，如果更高一层的level没有文件的范围包含了这个key，key的删除标记也会被忽略。
9.2.1 时间
Level 0的compaction最多从level 0读取4个1MB的文件，以及所有的level 1文件（10MB），也就是我们将读取14MB，并写入14BM。 Level &amp;gt; 0的compaction，从level L选择一个2MB的文件，最坏情况下，将会和levelL+1的12个文件有重合（10：level L+1的总文件大小是level L的10倍；边界的2：level L的文件范围通常不会和level L+1的文件对齐）。因此Compaction将会读26MB，写26MB。对于100MB/s的磁盘IO来讲，compaction将最坏需要0.5秒。 如果磁盘IO更低，比如10MB/s，那么compaction就需要更长的时间5秒。如果user以10MB/s的速度写入，我们可能生成很多level 0文件（50个来装载5*10MB的数据）。这将会严重影响读取效率，因为需要merge更多的文件。
解决方法1：为了降低该问题，我们可能想增加log切换的阈值，缺点就是，log文件越大，对应的memtable文件就越大，这需要更多的内存。 解决方法2：当level 0文件太多时，人工降低写入速度。 解决方法3：降低merge的开销，如把level 0文件都无压缩的存放在cache中。</description>
    </item>
    
    <item>
      <title>leveldb源码分析15</title>
      <link>https://haokiu.com/blog/bd56540c7f464f2e8e9392c3903b27f5/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/bd56540c7f464f2e8e9392c3903b27f5/</guid>
      <description>leveldb源码分析15 本系列《leveldb源码分析》共有22篇文章，这是第十五篇
9 LevelDB框架之2
9.4 版本控制 当执行一次compaction后，Leveldb将在当前版本基础上创建一个新版本，当前版本就变成了历史版本。还有，如果你创建了一个Iterator，那么该Iterator所依附的版本将不会被leveldb删除。 在leveldb中，Version就代表了一个版本，它包括当前磁盘及内存中的所有文件信息。在所有的version中，只有一个是CURRENT。 VersionSet是所有Version的集合，这是个version的管理机构。 前面讲过的VersionEdit记录了Version之间的变化，相当于delta增量，表示又增加了多少文件，删除了文件。也就是说：Version0 + VersionEdit &amp;ndash;&amp;gt; Version1。 每次文件有变动时，leveldb就把变动记录到一个VersionEdit变量中，然后通过VersionEdit把变动应用到current version上，并把current version的快照，也就是db元信息保存到MANIFEST文件中。 另外，MANIFEST文件组织是以VersionEdit的形式写入的，它本身是一个log文件格式，采用log::Writer/Reader的方式读写，一个VersionEdit就是一条log record。
9.4.1 VersionSet
和DBImpl一样，下面就初识一下Version和VersionSet。 先来看看Version的成员：
std::vector&amp;lt;FileMetaData*&amp;gt;files_[config::kNumLevels]; // sstable文件列表 // Next fileto compact based on seek stats. 下一个要compact的文件 FileMetaData* file_to_compact_; int file_to_compact_level_; // 下一个应该compact的level和compaction分数. // 分数 &amp;lt; 1 说明compaction并不紧迫. 这些字段在Finalize()中初始化 double compaction_score_; int compaction_level_; 可见一个Version就是一个sstable文件集合，以及它管理的compact状态。Version通过Version* prev和*next指针构成了一个Version双向循环链表，表头指针则在VersionSet中（初始都指向自己）。 下面是VersionSet的成员。可见它除了通过Version管理所有的sstable文件外，还关心manifest文件信息，以及控制log文件等编号。
//=== 第一组，直接来自于DBImple，构造函数传入 Env* const env_; // 操作系统封装 const std::string dbname_; const Options* const options_; TableCache* const table_cache_; // table cache const InternalKeyComparatoricmp_; //=== 第二组，db元信息相关 uint64_t next_file_number_; // log文件编号 uint64_t manifest_file_number_; // manifest文件编号 uint64_t last_sequence_; uint64_t log_number_; // log编号 uint64_t prev_log_number_; // 0 or backingstore for memtable being compacted //=== 第三组，menifest文件相关 WritableFile* descriptor_file_; log::Writer* descriptor_log_; //=== 第四组，版本管理 Version dummy_versions_; // versions双向链表head.</description>
    </item>
    
    <item>
      <title>Leveldb源码分析16</title>
      <link>https://haokiu.com/blog/383f27c1087943b39b255aa993d7b9ac/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/383f27c1087943b39b255aa993d7b9ac/</guid>
      <description>Leveldb源码分析16 本系列《leveldb源码分析》共有22篇文章，这是第十六篇
10.Version分析之一 先来分析leveldb对单版本的sstable文件管理，主要集中在Version类中。前面的10.4节已经说明了Version类的功能和成员，这里分析其函数接口和代码实现。 Version不会修改其管理的sstable文件，只有读取操作。
10.1 Version接口 先来看看Version类的接口函数，接下来再一一分析。
// 追加一系列iterator到 @*iters中， //将在merge到一起时生成该Version的内容 // 要求: Version已经保存了(见VersionSet::SaveTo) void AddIterators(constReadOptions&amp;amp;, std::vector&amp;lt;Iterator*&amp;gt;* iters); // 给定@key查找value，如果找到保存在@*val并返回OK。 // 否则返回non-OK，设置@ *stats. // 要求：没有hold lock struct GetStats { FileMetaData* seek_file; int seek_file_level; }; Status Get(constReadOptions&amp;amp;, const LookupKey&amp;amp; key, std::string* val,GetStats* stats); // 把@stats加入到当前状态中，如果需要触发新的compaction返回true // 要求：hold lock bool UpdateStats(constGetStats&amp;amp; stats); void GetOverlappingInputs(intlevel, const InternalKey*begin, // NULL 指在所有key之前 const InternalKey* end, // NULL指在所有key之后 std::vector&amp;lt;FileMetaData*&amp;gt;* inputs); // 如果指定level中的某些文件和[*smallest_user_key,*largest_user_key] //有重合就返回true。 // @smallest_user_key==NULL表示比DB中所有key都小的key. // @largest_user_key==NULL表示比DB中所有key都大的key. bool OverlapInLevel(int level,const Slice*smallest_user_key, const Slice* largest_user_key); // 返回我们应该在哪个level上放置新的memtable compaction， // 该compaction覆盖了范围[smallest_user_key,largest_user_key]. int PickLevelForMemTableOutput(const Slice&amp;amp; smallest_user_key, const Slice&amp;amp; largest_user_key); // 指定level的sstable个数 int NumFiles(int level) const {return files_[level].size(); 10.2 Version::AddIterators() 该函数最终在DB::NewIterators()接口中被调用，调用层次为： DBImpl::NewIterator()-&amp;gt;DBImpl::NewInternalIterator()-&amp;gt;Version::AddIterators()。 函数功能是为该Version中的所有sstable都创建一个Two Level Iterator，以遍历sstable的内容。</description>
    </item>
    
    <item>
      <title>leveldb源码分析17</title>
      <link>https://haokiu.com/blog/0d1705067c1d403889b748a57e0b3af5/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/0d1705067c1d403889b748a57e0b3af5/</guid>
      <description>leveldb源码分析17 本系列《leveldb源码分析》共有22篇文章，这是第十七篇
10 Version分析之2
10.5 Version::UpdateStats() 当Get操作直接搜寻memtable没有命中时，就需要调用Version::Get()函数从磁盘load数据文件并查找。如果此次Get不止seek了一个文件，就记录第一个文件到stat并返回。其后leveldb就会调用UpdateStats(stat)。 Stat表明在指定key range查找key时，都要先seek此文件，才能在后续的sstable文件中找到key。 该函数是将stat记录的sstable文件的allowed_seeks减1，减到0就执行compaction。也就是说如果文件被seek的次数超过了限制，表明读取效率已经很低，需要执行compaction了。所以说allowed_seeks是对compaction流程的有一个优化。 函数声明：boolVersion::UpdateStats(const GetStats&amp;amp; stats) 函数逻辑很简单：
FileMetaData* f =stats.seek_file; if (f != NULL) { f-&amp;gt;allowed_seeks--; if (f-&amp;gt;allowed_seeks &amp;lt;=0 &amp;amp;&amp;amp; file_to_compact_ == NULL) { file_to_compact_ = f; file_to_compact_level_ =stats.seek_file_level; return true; } } return false; 变量allowed_seeks的值在sstable文件加入到version时确定，也就是后面将遇到的VersionSet::Builder::Apply()函数。
10.6 Version::GetOverlappingInputs() 它在指定level中找出和**[begin, end]**有重合的sstable文件，函数声明为：
void Version::GetOverlappingInputs(int level, const InternalKey* begin, constInternalKey* end, std::vector&amp;lt;FileMetaData*&amp;gt;* inputs); 要注意的是，对于level0，由于文件可能有重合，其处理具有特殊性。当在level 0中找到有sstable文件和**[begin, end]**重合时，会相应的将begin/end扩展到文件的min key/max key，然后重新开始搜索。 了解了功能，下面分析函数实现代码，逻辑还是很直观的。 S1 首先根据参数初始化查找变量。
inputs-&amp;gt;clear(); Slice user_begin, user_end; if (begin != NULL) user_begin =begin-&amp;gt;user_key(); if (end != NULL) user_end = end-&amp;gt;user_key(); const Comparator* user_cmp =vset_-&amp;gt;icmp_.user_comparator(); S2 遍历该层的sstable文件，比较sstable的**{minkey,max key}和传入的[begin, end]**，如果有重合就记录文件到@inputs中，需要对level 0做特殊处理。
for (size_t i = 0; i &amp;lt;files_[level].size(); ) { FileMetaData* f =files_[level][i++]; const Slice file_start =f-&amp;gt;smallest.</description>
    </item>
    
    <item>
      <title>leveldb源码分析18</title>
      <link>https://haokiu.com/blog/9276872cee384cebb6d1c912acedf0a2/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/9276872cee384cebb6d1c912acedf0a2/</guid>
      <description>leveldb源码分析18 本系列《leveldb源码分析》共有22篇文章，这是第十八篇
11 VersionSet分析之1 Version之后就是VersionSet，它并不是Version的简单集合，还肩负了不少的处理逻辑。这里的分析不涉及到compaction相关的部分，这部分会单独分析。包括log等各种编号计数器，compaction点的管理等等。
11.1 VersionSet接口 1 首先是构造函数，VersionSet会使用到TableCache，这个是调用者传入的。TableCache用于Get k/v操作。
VersionSet(const std::string&amp;amp; dbname, const Options* options, TableCache*table_cache, const InternalKeyComparator*); VersionSet的构造函数很简单，除了根据参数初始化，还有两个地方值得注意： N1 next_file_number_从2开始； N2 创建新的Version并加入到Version链表中，并设置CURRENT=新创建version； 其它的数字初始化为0，指针初始化为NULL。 2 恢复函数，从磁盘恢复最后保存的元信息
Status Recover(); 3 标记指定的文件编号已经被使用了
void MarkFileNumberUsed(uint64_t number); 逻辑很简单，就是根据编号更新文件编号计数器：
if (next_file_number_ &amp;lt;= number) next_file_number_ = number + 1; 4 在current version上应用指定的VersionEdit，生成新的MANIFEST信息，保存到磁盘上，并用作current version。 要求：没有其它线程并发调用；要用于mu；
Status LogAndApply(VersionEdit* edit, port::Mutex* mu)EXCLUSIVE_LOCKS_REQUIRED(mu); 5 对于@v中的@key，返回db中的大概位置
uint64_t ApproximateOffsetOf(Version* v, const InternalKey&amp;amp; key); 6 其它一些简单接口，信息获取或者设置，如下：
//返回current version Version* current() const { return current_; } // 当前的MANIFEST文件号 uint64_t ManifestFileNumber() const { return manifest_file_number_; } // 分配并返回新的文件编号 uint64_t NewFileNumber() { return next_file_number_++; } // 返回当前log文件编号 uint64_t LogNumber() const { return log_number_; } // 返回正在compact的log文件编号，如果没有返回0 uint64_t PrevLogNumber() const { return prev_log_number_; } // 获取、设置last sequence，set时不能后退 uint64_t LastSequence() const { return last_sequence_; } void SetLastSequence(uint64_t s) { assert(s &amp;gt;=last_sequence_); last_sequence_ = s; } // 返回指定level中所有sstable文件大小的和 int64_t NumLevelBytes(int level) const; // 返回指定level的文件个数 int NumLevelFiles(int level) const; // 重用@file_number，限制很严格：@file_number必须是最后分配的那个 // 要求: @file_number是NewFileNumber()返回的.</description>
    </item>
    
    <item>
      <title>leveldb源码分析19</title>
      <link>https://haokiu.com/blog/2d765b7b763343038b1df047545b2017/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/2d765b7b763343038b1df047545b2017/</guid>
      <description>leveldb源码分析19 本系列《leveldb源码分析》共有22篇文章，这是第十九篇
11.VersionSet分析之2 11.4 LogAndApply() 函数声明：
Status LogAndApply(VersionEdit*edit, port::Mutex* mu) 前面接口小节中讲过其功能：在currentversion上应用指定的VersionEdit，生成新的MANIFEST信息，保存到磁盘上，并用作current version，故为Log And Apply。 参数edit也会被函数修改。
11.4.1 函数流程 下面就来具体分析函数代码。 S1 为edit设置log number等4个计数器。
if (edit-&amp;gt;has_log_number_) { assert(edit-&amp;gt;log_number_ &amp;gt;= log_number_); assert(edit-&amp;gt;log_number_ &amp;lt; next_file_number_); } else edit-&amp;gt;SetLogNumber(log_number_); if (!edit-&amp;gt;has_prev_log_number_) edit-&amp;gt;SetPrevLogNumber(prev_log_number_); edit-&amp;gt;SetNextFile(next_file_number_); edit-&amp;gt;SetLastSequence(last_sequence_); 要保证edit自己的log number是比较大的那个，否则就是致命错误。保证edit的log number小于next file number，否则就是致命错误-见9.1小节。
S2 创建一个新的Version v，并把新的edit变动保存到v中。
Version* v = new Version(this); { Builder builder(this, current_); builder.Apply(edit); builder.SaveTo(v); } Finalize(v); //如前分析，只是为v计算执行compaction的最佳level S3 如果MANIFEST文件指针不存在，就创建并初始化一个新的MANIFEST文件。这只会发生在第一次打开数据库时。这个MANIFEST文件保存了current version的快照。
std::string new_manifest_file; Status s; if (descriptor_log_ == NULL) { // 这里不需要unlock *mu因为我们只会在第一次调用LogAndApply时 // 才走到这里(打开数据库时). assert(descriptor_file_ == NULL); // 文件指针和log::Writer都应该是NULL new_manifest_file = DescriptorFileName(dbname_, manifest_file_number_); edit-&amp;gt;SetNextFile(next_file_number_); s = env_-&amp;gt;NewWritableFile(new_manifest_file, &amp;amp;descriptor_file_); if (s.ok()) { descriptor_log_ = new log::Writer(descriptor_file_); s = WriteSnapshot(descriptor_log_); // 写入快照 } } S4 向MANIFEST写入一条新的log，记录current version的信息。在文件写操作时unlock锁，写入完成后，再重新lock，以防止浪费在长时间的IO操作上。</description>
    </item>
    
    <item>
      <title>leveldb源码分析2</title>
      <link>https://haokiu.com/blog/c955baadcc824d20acb455e1078a257c/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/c955baadcc824d20acb455e1078a257c/</guid>
      <description>leveldb源码分析2 本系列《leveldb源码分析》共有22篇文章，这是第二篇。
3.Int Coding 轻松一刻，前面约定中讲过Leveldb使用了很多VarInt型编码，典型的如后面将涉及到的各种key。其中的编码、解码函数分为VarInt和FixedInt两种。int32和int64操作都是类似的。
3.1 Decode 首先是FixedInt编码，直接上代码，很简单明了。
void EncodeFixed32(char* buf, uint32_t value) { if (port::kLittleEndian) { memcpy(buf, &amp;amp;value,sizeof(value)); } else { buf[0] = value &amp;amp; 0xff; buf[1] = (value &amp;gt;&amp;gt; 8)&amp;amp; 0xff; buf[2] = (value &amp;gt;&amp;gt; 16)&amp;amp; 0xff; buf[3] = (value &amp;gt;&amp;gt; 24)&amp;amp; 0xff; } } 下面是VarInt编码，int32和int64格式，代码如下，有效位是7bit的，因此把uint32按7bit分割，对unsigned char赋值时，超出0xFF会自动截断，因此直接*(ptr++) = v|B即可，不需要再把(v|B)与0xFF作&amp;amp;操作。
char* EncodeVarint32(char* dst, uint32_t v) { unsigned char* ptr =reinterpret_cast&amp;lt;unsigned char*&amp;gt;(dst); static const int B = 128; if (v &amp;lt; (1&amp;lt;&amp;lt;7)) { *(ptr++) = v; } else if (v &amp;lt; (1&amp;lt;&amp;lt;14)){ *(ptr++) = v | B; *(ptr++) = v&amp;gt;&amp;gt;7; } else if (v &amp;lt; (1&amp;lt;&amp;lt;21)){ *(ptr++) = v | B; *(ptr++) = (v&amp;gt;&amp;gt;7) | B; *(ptr++) = v&amp;gt;&amp;gt;14; } else if (v &amp;lt; (1&amp;lt;&amp;lt;28)){ *(ptr++) = v | B; *(ptr++) = (v&amp;gt;&amp;gt;7) | B; *(ptr++) = (v&amp;gt;&amp;gt;14) | B; *(ptr++) = v&amp;gt;&amp;gt;21; } else { *(ptr++) = v | B; *(ptr++) = (v&amp;gt;&amp;gt;7) | B; *(ptr++) = (v&amp;gt;&amp;gt;14) | B; *(ptr++) = (v&amp;gt;&amp;gt;21) | B; *(ptr++) = v&amp;gt;&amp;gt;28; } return reinterpret_cast&amp;lt;char*&amp;gt;(ptr); } // 对于uint64，直接循环 char* EncodeVarint64(char* dst, uint64_t v) { static const int B = 128; unsigned char* ptr =reinterpret_cast&amp;lt;unsigned char*&amp;gt;(dst); while (v &amp;gt;= B) { *(ptr++) = (v &amp;amp; (B-1)) |B; v &amp;gt;&amp;gt;= 7; } *(ptr++) =static_cast&amp;lt;unsigned char&amp;gt;(v); returnreinterpret_cast&amp;lt;char*&amp;gt;(ptr); } 3.</description>
    </item>
    
    <item>
      <title>leveldb源码分析20</title>
      <link>https://haokiu.com/blog/0da12c5829764cdc8a508c0a05e99a3e/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/0da12c5829764cdc8a508c0a05e99a3e/</guid>
      <description>leveldb源码分析20 本系列《leveldb源码分析》共有22篇文章，这是第二十篇 12 DB的打开 先分析LevelDB是如何打开db的，万物始于创建。在打开流程中有几个辅助函数：DBImpl()，DBImpl::Recover, DBImpl::DeleteObsoleteFiles, DBImpl::RecoverLogFile, DBImpl::MaybeScheduleCompaction。
12.1 DB::Open() 打开一个db，进行PUT、GET操作，就是前面的静态函数DB::Open的工作。如果操作成功，它就返回一个db指针。前面说过DB就是一个接口类，其具体实现在DBImp类中，这是一个DB的子类。 函数声明为：
Status DB::Open(const Options&amp;amp; options, const std::string&amp;amp;dbname, DB** dbptr); 分解来看，Open()函数主要有以下5个执行步骤。 S1 创建DBImpl对象，其后进入**DBImpl::Recover()函数执行S2和S3。 S2 从已存在的db文件恢复db数据，根据CURRENT记录的MANIFEST文件读取db元信息；这通过调用VersionSet::Recover()完成。 S3 然后过滤出那些最近的更新log，前一个版本可能新加了这些log，但并没有记录在MANIFEST中。然后依次根据时间顺序，调用DBImpl::RecoverLogFile()从旧到新回放这些操作log。回放log时可能会修改db元信息，比如dump了新的level 0文件，因此它将返回一个VersionEdit对象，记录db元信息的变动。 S4 如果DBImpl::Recover()返回成功，就执行VersionSet::LogAndApply()**应用VersionEdit，并保存当前的DB信息到新的MANIFEST文件中。 S5 最后删除一些过期文件，并检查是否需要执行compaction，如果需要，就启动后台线程执行。 下面就来具体分析Open函数的代码，在Open函数中涉及到上面的3个流程。 S1 首先创建DBImpl对象，锁定并试图做Recover操作。Recover操作用来处理创建flag，比如存在就返回失败等等，尝试从已存在的sstable文件恢复db。并返回db元信息的变动信息，一个VersionEdit对象。
1DBImpl* impl = newDBImpl(options, dbname); 2impl-&amp;gt;mutex_.Lock(); // 锁db 3VersionEdit edit; 4Status s =impl-&amp;gt;Recover(&amp;amp;edit); // 处理flag&amp;amp;恢复：create_if_missing,error_if_exists S2 如果Recover返回成功，则调用VersionSet取得新的log文件编号——实际上是在当前基础上+1，准备新的log文件。如果log文件创建成功，则根据log文件创建log::Writer。然后执行VersionSet::LogAndApply，根据edit记录的增量变动生成新的current version，并写入MANIFEST文件。
函数NewFileNumber(){returnnext_file_number_++;}，直接返回next_file_number_。
1uint64_t new_log_number = impl-&amp;gt;versions_-&amp;gt;NewFileNumber(); 2WritableFile* lfile; 3s = options.env-&amp;gt;NewWritableFile(LogFileName(dbname, new_log_number), &amp;amp;lfile); 4if (s.ok()) { 5 edit.SetLogNumber(new_log_number); 6 impl-&amp;gt;logfile_ = lfile; 7 impl-&amp;gt;logfile_number_ = new_log_number; 8 impl-&amp;gt;log_ = newlog::Writer(lfile); 9 s = impl-&amp;gt;versions_-&amp;gt;LogAndApply(&amp;amp;edit, &amp;amp;impl-&amp;gt;mutex_); 10} S3 如果VersionSet::LogAndApply返回成功，则删除过期文件，检查是否需要执行compaction，最终返回创建的DBImpl对象。
1if (s.ok()) { 2 impl-&amp;gt;DeleteObsoleteFiles(); 3 impl-&amp;gt;MaybeScheduleCompaction(); 4} 5impl-&amp;gt;mutex_.Unlock(); 6if (s.</description>
    </item>
    
    <item>
      <title>leveldb源码分析21</title>
      <link>https://haokiu.com/blog/1d4ede18ded04a569baee5550226fa6f/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1d4ede18ded04a569baee5550226fa6f/</guid>
      <description>leveldb源码分析21 本系列《leveldb源码分析》共有22篇文章，这是第二十一篇
14 DB的查询与遍历之1 分析完如何打开和关闭db，本章就继续分析如何从db中根据key查询value，以及遍历整个db。
14.1 Get() 函数声明：StatusGet(const ReadOptions&amp;amp; options, const Slice&amp;amp; key, std::string* value) 从DB中查询key 对应的value，参数@options指定读取操作的选项，典型的如snapshot号，从指定的快照中读取。快照本质上就是一个sequence号，后面将单独在快照一章中分析。 下面就来分析下函数逻辑：
// S1 锁mutex，防止并发，如果指定option则尝试获取snapshot；然后增加MemTable的引用值。 MutexLock l(&amp;amp;mutex_); SequenceNumber snapshot; if (options.snapshot != NULL) snapshot = reinterpret_cast&amp;lt;const SnapshotImpl*&amp;gt;(options.snapshot)-&amp;gt;number_; else snapshot = versions_-&amp;gt;LastSequence(); // 取当前版本的最后Sequence MemTable *mem = mem_, *imm = imm_; Version* current = versions_-&amp;gt;current(); mem-&amp;gt;Ref(); if (imm != NULL) imm-&amp;gt;Ref(); current-&amp;gt;Ref(); // S2 从sstable文件和MemTable中读取时，释放锁mutex；之后再次锁mutex。 bool have_stat_update = false; Version::GetStats stats; { mutex_.Unlock(); // 先从memtable中查询，再从immutable memtable中查询 LookupKey lkey(key, snapshot); if (mem-&amp;gt;Get(lkey, value, &amp;amp;s)) { } else if (imm != NULL &amp;amp;&amp;amp; imm-&amp;gt;Get(lkey, value, &amp;amp;s)) { } else { // 需要从sstable文件中查询 s = current-&amp;gt;Get(options, lkey, value, &amp;amp;stats); have_stat_update = true; // 记录之，用于compaction } mutex_.</description>
    </item>
    
    <item>
      <title>leveldb源码分析22</title>
      <link>https://haokiu.com/blog/08d56462861f4df7b247921ba14a88e2/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/08d56462861f4df7b247921ba14a88e2/</guid>
      <description>leveldb源码分析22 本系列《leveldb源码分析》共有22篇文章，这是第二十二篇
14 DB的查询与遍历之2 14.4 DBIter Leveldb数据库的MemTable和sstable文件的存储格式都是**(user key, seq, type) =&amp;gt; uservalue**。DBIter把同一个userkey在DB中的多条记录合并为一条，综合考虑了userkey的序号、删除标记、和写覆盖等等因素。 从前面函数NewIterator的代码还能看到，DBIter内部使用了MergingIterator，在调用MergingItertor的系列seek函数后，DBIter还要处理key的删除标记。否则，遍历时会把已删除的key列举出来。 DBIter还定义了两个移动方向，默认是kForward： 1） kForward，向前移动，代码保证此时DBIter的内部迭代器刚好定位在this-&amp;gt;key(),this-&amp;gt;value()这条记录上； 2） kReverse，向后移动，代码保证此时DBIter的内部迭代器刚好定位在所有key=this-&amp;gt;key()的entry之前。 其成员变量savedkey和saved value保存的是KReverse方向移动时的k/v对，每次seek系调用之后，其值都会跟随iter_而改变。 DBIter的代码开始读来感觉有些绕，主要就是它要处理删除标记，而且其底层的MergingIterator，对于同一个key会有多个不同sequence的entry。导致其Next/Prev操作比较复杂，要考虑到上一次移动的影响，跳过删除标记和重复的key。 DBIter必须导出Iterator定义的几个接口，下面就拖出来挨个分析。
14.4.1 Get系接口 首先是几个简单接口，获取key、value和status的：
//kForward直接取iter_-&amp;gt;value()，否则取saved value virtual Slice value() const { assert(valid_); return (direction_ == kForward) ? iter_-&amp;gt;value() : saved_value_; } virtual Status status() const { if (status_.ok()) returniter_-&amp;gt;status(); return status_; } 14.4.2 辅助函数 在分析seek系函数之前，先来理解两个重要的辅助函数：FindNextUserEntry和FindPrevUserEntry的功能和逻辑。其功能就是循环跳过下一个/前一个delete的记录，直到遇到kValueType的记录。 先来看看，函数声明为： void DBIter::FindNextUserEntry(bool skipping, std::string* skip) 参数@skipping表明是否要跳过sequence更小的entry； 参数@skip临时存储空间，保存seek时要跳过的key； 在进入FindNextUserEntry时，iter_刚好定位在this-&amp;gt;key(), this-&amp;gt;value()这条记录上。下面来看函数实现：
virtual Slice key() const { //kForward直接取iter_-&amp;gt;key()，否则取saved key assert(valid_); return (direction_ == kForward) ? ExtractUserKey(iter_-&amp;gt;key()) : saved_key_; } // 循环直到找到合适的entry，direction必须是kForward assert(iter_-&amp;gt;Valid()); assert(direction_ == kForward); do { ParsedInternalKey ikey; // 确保iter_-&amp;gt;key()的sequence &amp;lt;= 遍历指定的sequence if (ParseKey(&amp;amp;ikey) &amp;amp;&amp;amp; ikey.</description>
    </item>
    
    <item>
      <title>leveldb源码分析3</title>
      <link>https://haokiu.com/blog/34fc58749a224c92be698a0d9cd27b99/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/34fc58749a224c92be698a0d9cd27b99/</guid>
      <description>leveldb源码分析3 本系列《leveldb源码分析》共有22篇文章，这是第三篇。
4. Memtable之一 Memtable是leveldb很重要的一块，leveldb的核心之一。我们肯定关注KV数据在Memtable中是如何组织的，秘密在Skip list中。
4.1 用途 在Leveldb中，所有内存中的KV数据都存储在Memtable中，物理disk则存储在SSTable中。在系统运行过程中，如果Memtable中的数据占用内存到达指定值(Options.write_buffer_size)，则Leveldb就自动将Memtable转换为Memtable，并自动生成新的Memtable，也就是Copy-On-Write机制了。
Immutable Memtable则被新的线程Dump到磁盘中，Dump结束则该Immutable Memtable就可以释放了。因名知意，Immutable Memtable是只读的。
所以可见，最新的数据都是存储在Memtable中的，Immutable Memtable和物理SSTable则是某个时点的数据。
为了防止系统down机导致内存数据Memtable或者Immutable Memtable丢失，leveldb自然也依赖于log机制来保证可靠性了。
Memtable提供了写入KV记录，删除以及读取KV记录的接口，但是事实上**Memtable并不执行真正的删除操作,**删除某个Key的Value在Memtable内是作为插入一条记录实施的，但是会打上一个Key的删除标记，真正的删除操作在后面的 Compaction过程中，lazy delete。
4.2 核心是Skip list 另外，Memtable中的KV对是根据Key排序的，leveldb在插入等操作时保证key的有序性。想想，前面看到的Skip list不正是合适的人选吗，因此Memtable的核心数据结构是一个Skip list，Memtable只是一个接口类。当然随之而来的一个问题就是Skip list是如何组织KV数据对的，在后面分析Memtable的插入、查询接口时我们将会看到答案。
4.3 接口说明 先来看看Memtable的接口：
void Ref() { ++refs_; } void Unref(); Iterator* NewIterator(); void Add(SequenceNumber seq, ValueType type, const Slice&amp;amp; key, const Slice&amp;amp; value); bool Get(const LookupKey&amp;amp; key, std::string* value, Status* s); 首先Memtable是基于引用计数的机制，如果引用计数为0，则在Unref中删除自己，Ref和Unref就是干这个的。
NewIterator是返回一个迭代器，可以遍历访问table的内部数据，很好的设计思想，这种方式隐藏了table的内部实现。外部调用者必须保证使用Iterator访问Memtable的时候该Memtable是live的。 Add和Get是添加和获取记录的接口，没有Delete，还记得前面说过，memtable的delete实际上是插入一条type为kTypeDeletion的记录。 4.4 类图 先来看看Memtable相关的整体类层次吧，并不复杂，还是相当清晰的。见图4.4-1。
4.5 Key结构 Memtable是一个KV存储结构，那么这个key肯定是个重点了，在分析接口实现之前，有必要仔细分析一下Memtable对key的使用。
这里面有5个key的概念，可能会让人混淆，下面就来一个一个的分析。
4.5.1 InternalKey &amp;amp; ParsedInternalKey &amp;amp; User Key InternalKey是一个复合概念，是有几个部分组合成的一个key，ParsedInternalKey就是对InternalKey分拆后的结果，先来看看ParsedInternalKey的成员，这是一个struct：
Slice user_key; SequenceNumber sequence; ValueType type; 也就是说InternalKey是由User key + SequenceNumber + ValueType组合而成的，顺便先分析下几个Key相关的函数，它们是了解Internal Key和User Key的关键。
首先是InternalKey和ParsedInternalKey相互转换的两个函数，如下。
bool ParseInternalKey (const Slice&amp;amp; internal_key, ParsedInternalKey* result); void AppendInternalKey (std::string* result, const ParsedInternalKey&amp;amp; key); 函数实现很简单，就是字符串的拼接与把字符串按字节拆分，代码略过。根据实现，容易得到InternalKey的格式为：</description>
    </item>
    
    <item>
      <title>leveldb源码分析4</title>
      <link>https://haokiu.com/blog/f4dfd0e7e33240c9807a11402d34ddb3/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/f4dfd0e7e33240c9807a11402d34ddb3/</guid>
      <description>leveldb源码分析4 本系列《leveldb源码分析》共有22篇文章，这是第四篇
4.Memtable之2 4.6 Comparator 弄清楚了key，接下来就要看看key的使用了，先从Comparator开始分析。首先Comparator是一个抽象类，导出了几个接口。
其中**Name()和Compare()**接口都很明了，另外的两个Find xxx接口都有什么功能呢，直接看程序注释：
//Advanced functions: these are used to reduce the space requirements //for internal data structures like index blocks. // 这两个函数：用于减少像index blocks这样的内部数据结构占用的空间 // 其中的*start和*key参数都是IN OUT的。 //If *start &amp;lt; limit, changes *start to a short string in [start,limit). //Simple comparator implementations may return with *start unchanged, //i.e., an implementation of this method that does nothing is correct. // 这个函数的作用就是：如果*start &amp;lt; limit，就在[startlimit,)中找到一个 // 短字符串，并赋给*start返回 // 简单的comparator实现可能不改变*start，这也是正确的 virtual void FindShortestSeparator(std::string* start, const Slice&amp;amp; limit) const = 0; //Changes *key to a short string &amp;gt;= *key. //Simple comparator implementations may return with *key unchanged, //i.e., an implementation of this method that does nothing is correct.</description>
    </item>
    
    <item>
      <title>leveldb源码分析5</title>
      <link>https://haokiu.com/blog/81982087975a4f49913e723952169670/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/81982087975a4f49913e723952169670/</guid>
      <description>leveldb源码分析5 本系列《leveldb源码分析》共有22篇文章，这是第五篇。
5.操作Log 1 分析完KV在内存中的存储，接下来就是操作日志。所有的写操作都必须先成功的append到操作日志中，然后再更新内存memtable。这样做有两点：
可以将随机的写IO变成append，极大的提高写磁盘速度； 防止在节点down机导致内存数据丢失，造成数据丢失，这对系统来说是个灾难。 在各种高效的存储系统中，这已经是口水技术了。
5.1 格式 在源码下的文档doc/log_format.txt中，作者详细描述了log格式：
The log file contents are a sequence of 32KB blocks. The only exception is that the tail of thefile may contain a partial block. Each block consists of a sequence of records: block:= record* trailer? record := checksum: uint32 // crc32c of type and data[] ; little-endian length: uint16 // little-endian type: uint8 // One of FULL,FIRST, MIDDLE, LAST data: uint8[length] A record never starts within the last six bytes of a block (since it won&amp;rsquo;tfit). Any leftover bytes here form thetrailer, which must consist entirely of zero bytes and must be skipped byreaders.</description>
    </item>
    
    <item>
      <title>leveldb源码分析6</title>
      <link>https://haokiu.com/blog/3e005b6becda44edaa67dc81f32d5499/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/3e005b6becda44edaa67dc81f32d5499/</guid>
      <description>leveldb源码分析6 本系列《leveldb源码分析》共有22篇文章，这是第六篇。
5. 操作Log 2 5.3 读日志 日志读取显然比写入要复杂，要检查checksum，检查是否有损坏等等，处理各种错误。
5.3.1 类层次 Reader主要用到了两个接口，一个是汇报错误的Reporter，另一个是log文件读取类SequentialFile。
Reporter的接口只有一个：
void Corruption(size_t bytes,const Status&amp;amp; status); SequentialFile有两个接口：
Status Read(size_t n, Slice* result, char* scratch); Status Skip(uint64_t n); 说明下，Read接口有一个result参数传递结果就行了，为何还有一个scratch呢，这个就和Slice相关了。它的字符串指针是传入的外部char*指针，自己并不负责内存的管理与分配。因此Read接口需要调用者提供一个字符串指针，实际存放字符串的地方。
Reader类有几个成员变量，需要注意：
bool eof_; // 上次Read()返回长度&amp;lt; kBlockSize，暗示到了文件结尾EOF uint64_t last_record_offset_; // 函数ReadRecord返回的上一个record的偏移 uint64_t end_of_buffer_offset_;// 当前的读取偏移 uint64_t const initial_offset_;// 偏移，从哪里开始读取第一条record Slice buffer_; // 读取的内容 5.3.2日志读取流程 Reader只有一个接口，那就是ReadRecord，下面来分析下这个函数。
S1 根据initial offset跳转到调用者指定的位置，开始读取日志文件。跳转就是直接调用SequentialFile的Seek接口。 另外，需要先调整调用者传入的initialoffset参数，调整和跳转逻辑在SkipToInitialBlock函数中。
if (last_record_offset_ &amp;lt;initial_offset_) { // 当前偏移 &amp;lt; 指定的偏移，需要Seek if (!SkipToInitialBlock()) return false; } 下面的代码是SkipToInitialBlock函数调整read offset的逻辑：
// 计算在block内的偏移位置，并圆整到开始读取block的起始位置 size_t offset_in_block =initial_offset_ % kBlockSize; uint64_t block_start_location =initial_offset_ - offset_in_block; // 如果偏移在最后的6byte里，肯定不是一条完整的记录，跳到下一个block if (offset_in_block &amp;gt;kBlockSize - 6) { offset_in_block = 0; block_start_location +=kBlockSize; } end_of_buffer_offset_ =block_start_location; // 设置读取偏移 if (block_start_location &amp;gt; 0) file_-&amp;gt;Skip(block_start_location); // 跳转 首先计算出在block内的偏移位置，然后圆整到要读取block的起始位置。开始读取日志的时候都要保证读取的是完整的block，这就是调整的目的。</description>
    </item>
    
    <item>
      <title>leveldb源码分析7</title>
      <link>https://haokiu.com/blog/b3a81cdfb8624332bd1f184097675b32/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/b3a81cdfb8624332bd1f184097675b32/</guid>
      <description>leveldb源码分析7 本系列《leveldb源码分析》共有22篇文章，这是第七篇。
6. SSTable之一 SSTable是Leveldb的核心之一，是表数据最终在磁盘上的物理存储。也是体量比较大的模块。
6.1 SSTable的文件组织 作者在文档doc/table_format.txt中描述了表的逻辑结构，如图6.1-1所示。逻辑上可分为两大块，数据存储区Data Block，以及各种Meta信息。
文件中的k/v对是有序存储的，并且被划分到连续排列的Data Block里面，这些Data Block从文件头开始顺序存储，Data Block的存储格式代码在block_builder.cc中；
紧跟在Data Block之后的是Meta Block，其格式代码也在block_builder.cc中；Meta Block存储的是Filter信息，比如Bloom过滤器，用于快速定位key是否在data block中。
MetaIndex Block是对Meta Block的索引，它只有一条记录，key是meta index的名字（也就是Filter的名字），value为指向meta index的BlockHandle；BlockHandle是一个结构体，成员offset_是Block在文件中的偏移，成员size_是block的大小；
Index block是对Data Block的索引，对于其中的每个记录，其key &amp;gt;=Data Block最后一条记录的key，同时&amp;lt;其后Data Block的第一条记录的key；value是指向data index的BlockHandle；
Footer，文件的最后，大小固定，其格式如图6.1-2所示。
成员metaindex_handle指出了meta index block的起始位置和大小； 成员index_handle指出了index block的起始地址和大小； 这两个字段都是BlockHandle对象，可以理解为索引的索引，通过Footer可以直接定位到metaindex和index block。再后面是一个填充区和魔数（0xdb4775248b80fb57）。
6.2 Block存储格式 6.2.1 Block的逻辑存储 Data Block是具体的k/v数据对存储区域，此外还有存储meta的metaIndex Block，存储data block索引信息的Index Block等等，他们都是以Block的方式存储的。来看看Block是如何组织的。每个Block有三部分构成：block data, type, crc32，如图6.2-1所示。
类型type指明使用的是哪种压缩方式，当前支持none和snappy压缩。
虽然block有好几种，但是Block Data都是有序的k/v对，因此写入、读取BlockData的接口都是统一的，对于Block Data的管理也都是相同的。
对Block的写入、读取将在创建、读取sstable时分析，知道了格式之后，其读取写入代码都是很直观的。
由于sstable对数据的存储格式都是Block，因此在分析sstable的读取和写入逻辑之前，我们先来分析下Leveldb对Block Data的管理。
Leveldb对Block Data的管理是读写分离的，读取后的遍历查询操作由Block类实现，BlockData的构建则由BlockBuilder类实现。
6.2.2 重启点-restartpoint BlockBuilder对key的存储是前缀压缩的，对于有序的字符串来讲，这能极大的减少存储空间。但是却增加了查找的时间复杂度，为了兼顾查找效率，每隔K个key，leveldb就不使用前缀压缩，而是存储整个key，这就是重启点（restartpoint）。
在构建Block时，有参数Options::block_restart_interval定每隔几个key就直接存储一个重启点key。
Block在结尾记录所有重启点的偏移，可以二分查找指定的key。Value直接存储在key的后面，无压缩。
对于一个k/v对，其在block中的存储格式为：
共享前缀长度 shared_bytes: varint32
前缀之后的字符串长度 unshared_bytes: varint32
值的长度 value_length: varint32
前缀之后的字符串 key_delta: char[unshared_bytes]
值 value: char[value_length]
对于重启点，shared_bytes= 0
Block的结尾段格式是：
&amp;gt; restarts: uint32[num_restarts]
&amp;gt; num_restarts: uint32 // 重启点个数
**元素restarts[i]**存储的是block的第i个重启点的偏移。很明显第一个k/v对，总是第一个重启点，也就是restarts[0] = 0;
图6.2-2给出了block的存储示意图。
总体来看Block可分为k/v存储区和后面的重启点存储区两部分，其中k/v的存储格式如前面所讲，可看做4部分：
前缀压缩的key长度信息 + value长度 + key前缀之后的字符串+ value</description>
    </item>
    
    <item>
      <title>leveldb源码分析8</title>
      <link>https://haokiu.com/blog/8554dc1843294f5fa7955b748c61710f/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/8554dc1843294f5fa7955b748c61710f/</guid>
      <description>leveldb源码分析8 本系列《leveldb源码分析》共有22篇文章，这是第八篇
6 SSTable之2 6.4 创建sstable文件 了解了sstable文件的存储格式，以及Data Block的组织，下面就可以分析如何创建sstable文件了。相关代码在table_builder.h/.cc以及block_builder.h/.cc（构建Block）中。
6.4.1 TableBuilder类 构建sstable文件的类是TableBuilder，该类提供了几个有限的方法可以用来添加k/v对，Flush到文件中等等，它依赖于BlockBuilder来构建Block。
TableBuilder的几个接口说明下：
void Add(const Slice&amp;amp; key, const Slice&amp;amp; value)，向当前正在构建的表添加新的{key, value}对，要求根据Option指定的Comparator，key必须位于所有前面添加的key之后； void Flush()，将当前缓存的k/v全部flush到文件中，一个高级方法，大部分的client不需要直接调用该方法； void Finish()，结束表的构建，该方法被调用后，将不再会使用传入的WritableFile； void Abandon()，结束表的构建，并丢弃当前缓存的内容，该方法被调用后，将不再会使用传入的WritableFile；【只是设置closed为true，无其他操作】 一旦**Finish()/Abandon()**方法被调用，将不能再次执行Flush或者Add操作。 下面来看看涉及到的类，如图6.3-1所示。 图6.3-1
其中WritableFile和op log一样，使用的都是内存映射文件。Options是一些调用者可设置的选项。
TableBuilder只有一个成员变量Rep* rep_，实际上Rep结构体的成员就是TableBuilder所有的成员变量；这样做的目的，可能是为了隐藏其内部细节。Rep的定义也是在.cc文件中，对外是透明的。
简单解释下成员的含义：
Options options; // data block的选项 Options index_block_options; // index block的选项 WritableFile* file; // sstable文件 uint64_t offset; // 要写入data block在sstable文件中的偏移，初始0 Status status; //当前状态-初始ok BlockBuilder data_block; //当前操作的data block BlockBuilder index_block; // sstable的index block std::string last_key; //当前data block最后的k/v对的key int64_t num_entries; //当前data block的个数，初始0 bool closed; //调用了Finish() or Abandon()，初始false FilterBlockBuilder*filter_block; //根据filter数据快速定位key是否在block中 bool pending_index_entry; //见下面的Add函数，初始false BlockHandle pending_handle; //添加到index block的data block的信息 std::string compressed_output;//压缩后的data block，临时存储，写入后即被清空 Filter block是存储的过滤器信息，它会存储{key, 对应data block在sstable的偏移值}，不一定是完全精确的，以快速定位给定key是否在data block中。
下面分析如何向sstable中添加k/v对，创建并持久化sstable。其它函数都比较简单，略过。另外对于Abandon，简单设置closed=true即返回。
6.4.2 添加k/v对 这是通过方法**Add(constSlice&amp;amp; key, const Slice&amp;amp; value)**完成的，没有返回值。下面分析下函数的逻辑：</description>
    </item>
    
    <item>
      <title>leveldb源码分析9</title>
      <link>https://haokiu.com/blog/899ada7f72f249e6938aef7f300eaf1a/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/899ada7f72f249e6938aef7f300eaf1a/</guid>
      <description>leveldb源码分析9 本系列《leveldb源码分析》共有22篇文章，这是第九篇
6 SSTable之3 6.5 读取sstable文件 6.5.1 类层次 Sstable文件的读取逻辑在类Table中，其中涉及到的类还是比较多的，如图6.5-1所示。
Table类导出的函数只有3个，先从这三个导出函数开始分析。其中涉及到的类（包括上图中为画出的）都会一一遇到，然后再一一拆解。
本节分析sstable的打开逻辑，后面再分析key的查找与数据遍历。
6.5.2 Table::Open() 打开一个sstable文件，函数声明为：
static Status Open(const Options&amp;amp; options, RandomAccessFile* file, uint64_tfile_size, Table** table); 这是Table类的一个静态函数，如果操作成功，指针*table指向新打开的表，否则返回错误。
要打开的文件和大小分别由参数file和file_size指定；option是一些选项；
下面就分析下函数逻辑：
*1* S1 首先从文件的结尾读取Footer，并Decode到Footer对象中，如果文件长度小于Footer的长度，则报错。Footer的decode很简单，就是根据前面的Footer结构，解析并判断magic number是否正确，解析出meta index和index block的偏移和长度。 *table = NULL; if (size &amp;lt;Footer::kEncodedLength) { // 文件太短 returnStatus::InvalidArgument(&amp;#34;file is too short to be an sstable&amp;#34;); } charfooter_space[Footer::kEncodedLength]; // Footer大小是固定的 Slice footer_input; Status s = file-&amp;gt;Read(size -Footer::kEncodedLength, Footer::kEncodedLength, &amp;amp;footer_input, footer_space); if (!s.ok()) return s; Footer footer; s =footer.DecodeFrom(&amp;amp;footer_input); if (!s.ok()) return s; S2 解析出了Footer，我们就可以读取index block和meta index了，首先读取index block。 BlockContents contents; Block* index_block = NULL; if (s.ok()) { s = ReadBlock(file, ReadOptions(),footer.index_handle(), &amp;amp;contents); if (s.ok()) { index_block = newBlock(contents); } } 这是通过调用ReadBlock完成的，下面会分析这个函数。</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析</title>
      <link>https://haokiu.com/blog/5d2f8fa20fdc4018a34afe19f8c23987/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/5d2f8fa20fdc4018a34afe19f8c23987/</guid>
      <description>libevent源码深度剖析 libevent源码深度剖析01
libevent源码深度剖析02
libevent源码深度剖析03
libevent源码深度剖析04
libevent源码深度剖析05
libevent源码深度剖析06
libevent源码深度剖析07
libevent源码深度剖析08
libevent源码深度剖析09
libevent源码深度剖析10
libevent源码深度剖析11
libevent源码深度剖析12
libevent源码深度剖析13</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析02</title>
      <link>https://haokiu.com/blog/d62a9a215b334817945e5814d92a423a/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/d62a9a215b334817945e5814d92a423a/</guid>
      <description>libevent源码深度剖析02 Reactor模式
前面讲到，整个libevent本身就是一个Reactor，因此本节将专门对Reactor模式进行必要的介绍，并列出libevnet中的几个重要组件和Reactor的对应关系，在后面的章节中可能还会提到本节介绍的基本概念。
1. Reactor的事件处理机制 首先来回想一下普通函数调用的机制：程序调用某函数?函数执行，程序等待?函数将结果和控制权返回给程序?程序继续处理。
Reactor释义**“反应堆”，是一种事件驱动机制。和普通函数调用的不同之处在于：应用程序不是主动的调用某个API完成处理，而是恰恰相反，Reactor逆置了事件处理流程，应用程序需要提供相应的接口并注册到Reactor上，如果相应的时间发生，Reactor将主动调用应用程序注册的接口，这些接口又称为“回调函数”**。使用libevent也是想libevent框架注册相应的事件和回调函数；当这些事件发生时，libevent会调用这些回调函数处理相应的事件（I/O读写、定时和信号）。
用“好莱坞原则”来形容Reactor再合适不过了：不要打电话给我们，我们会打电话通知你。
举个例子：你去应聘某xx公司，面试结束后。
“普通函数调用机制”公司HR比较懒，不会记你的联系方式，那怎么办呢，你只能面试完后自己打电话去问结果；有没有被录取啊，还是被据了；
“Reactor”公司HR就记下了你的联系方式，结果出来后会主动打电话通知你：有没有被录取啊，还是被据了；你不用自己打电话去问结果，事实上也不能，你没有HR的留联系方式。
2. Reactor模式的优点 Reactor模式是编写高性能网络服务器的必备技术之一，它具有如下的优点
1）响应快，不必为单个同步时间所阻塞，虽然Reactor本身依然是同步的；
2）编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销； 3）可扩展性，可以方便的通过增加Reactor实例个数来充分利用CPU资源； 4）可复用性，reactor框架本身与具体事件处理逻辑无关，具有很高的复用性；
3. Reactor模式框架 使用Reactor模型，必备的几个组件：事件源、Reactor框架、多路复用机制和事件处理程序，先来看看Reactor模型的整体框架，接下来再对每个组件做逐一说明。
1） 事件源 Linux上是文件描述符，Windows上就是Socket或者Handle了，这里统一称为“句柄集”；程序在指定的句柄上注册关心的事件，比如I/O事件。
2） event demultiplexer——事件多路分发机制 由操作系统提供的I/O多路复用机制，比如select和epoll。 程序首先将其关心的句柄（事件源）及其事件注册到event demultiplexer上； 当有事件到达时，event demultiplexer会发出通知“在已经注册的句柄集中，一个或多个句柄的事件已经就绪”； 程序收到通知后，就可以在非阻塞的情况下对事件进行处理了。 对应到libevent中，依然是select、poll、epoll等，但是libevent使用结构体eventop进行了封装，以统一的接口来支持这些I/O多路复用机制，达到了对外隐藏底层系统机制的目的。
3） Reactor——反应器 Reactor，是事件管理的接口，内部使用event demultiplexer注册、注销事件；并运行事件循环，当有事件进入“就绪”状态时，调用注册事件的回调函数处理事件。 对应到libevent中，就是event_base结构体。 一个典型的Reactor声明方式：
class Reactor{ public: int register_handler(Event_Handler *pHandler, int event); int remove_handler(Event_Handler *pHandler, int event); void handle_events(timeval *ptv); // ... }; 4） Event Handler——事件处理程序
事件处理程序提供了一组接口，每个接口对应了一种类型的事件，供Reactor在相应的事件发生时调用，执行相应的事件处理。通常它会绑定一个有效的句柄。 对应到libevent中，就是event结构体。 下面是两种典型的Event Handler类声明方式，二者互有优缺点。
class Event_Handler{ public: virtual void handle_read() = 0; virtual void handle_write() = 0; virtual void handle_timeout() = 0; virtual void handle_close() = 0; virtual HANDLE get_handle() = 0; // ... }; class Event_Handler{ public: // events maybe read/write/timeout/close .</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析03</title>
      <link>https://haokiu.com/blog/88dcf812d9464727bdfa54410657cfaa/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/88dcf812d9464727bdfa54410657cfaa/</guid>
      <description>libevent源码深度剖析03 libevent基本使用场景和事件流程 1. 前言 学习源代码该从哪里入手？我觉得从程序的基本使用场景和代码的整体处理流程入手是个不错的方法，至少从个人的经验上讲，用此方法分析libevent是比较有效的。
2. 基本应用场景 基本应用场景也是使用libevnet的基本流程，下面来考虑一个最简单的场景，使用livevent设置定时器，应用程序只需要执行下面几个简单的步骤即可。 1）首先初始化libevent库，并保存返回的指针
struct event_base* base = event_init(); 实际上这一步相当于初始化一个Reactor实例；在初始化libevent后，就可以注册事件了。
2）初始化事件event，设置回调函数和关注的事件
evtimer_set(&amp;amp;ev, timer_cb, NULL); 事实上这等价于调用 event_set(&amp;amp;ev, -1, 0, timer_cb, NULL); event_set的函数原型是：
void event_set(struct event *ev, int fd, short event, void (*cb)(int, short, void *), void *arg) ev：执行要初始化的event对象； fd：该event绑定的“句柄”，对于信号事件，它就是关注的信号； event：在该fd上关注的事件类型，它可以是EV_READ, EV_WRITE, EV_SIGNAL； cb：这是一个函数指针，当fd上的事件event发生时，调用该函数执行处理，它有三个参数，调用时由event_base负责传入，按顺序，实际上就是event_set时的fd, event和arg； arg：传递给cb函数指针的参数； 由于定时事件不需要fd，并且定时事件是根据添加时**（event_add）的超时值设定的，因此这里event也不需要设置。 这一步相当于初始化一个event handler**，在libevent中事件类型保存在event结构体中。 注意：libevent并不会管理event事件集合，这需要应用程序自行管理；
3）设置event从属的event_base
event_base_set(base, &amp;amp;ev); 这一步相当于指明event要注册到哪个event_base实例上；
4）是正式的添加事件的时候了
event_add(&amp;amp;ev, timeout); 基本信息都已设置完成，只要简单的调用**event_add()函数即可完成，其中timeout是定时值； 这一步相当于调用Reactor::register_handler()**函数注册事件。
5）程序进入无限循环，等待就绪事件并执行事件处理
event_base_dispatch(base); 3. 实例代码 上面例子的程序代码如下所示
struct event ev; struct timeval tv; void time_cb(int fd, short event, void *argc){ printf(&amp;#34;timer wakeup/n&amp;#34;); event_add(&amp;amp;ev, &amp;amp;tv); // reschedule timer } int main(){ struct event_base *base = event_init(); tv.tv_sec = 10; // 10s period tv.</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析04</title>
      <link>https://haokiu.com/blog/7fd5744edc6741c18b5cb6187e662e40/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/7fd5744edc6741c18b5cb6187e662e40/</guid>
      <description>libevent源码深度剖析04 1. 前言 详细分析源代码之前，如果能对其代码文件的基本结构有个大概的认识和分类，对于代码的分析将是大有裨益的。本节内容不多，我想并不是说它不重要！
2. 源代码组织结构 Libevent的源代码虽然都在一层文件夹下面，但是其代码分类还是相当清晰的，主要可分为头文件、内部使用的头文件、辅助功能函数、日志、libevent框架、对系统I/O多路复用机制的封装、信号管理、定时事件管理、缓冲区管理、基本数据结构和基于libevent的两个实用库等几个部分，有些部分可能就是一个源文件。 源代码中的test部分就不在我们关注的范畴了。 1）头文件 主要就是event.h：事件宏定义、接口函数声明，主要结构体event的声明； 2）内部头文件 xxx-internal.h：内部数据结构和函数，对外不可见，以达到信息隐藏的目的； 3）libevent框架 event.c：event整体框架的代码实现； 4）对系统I/O多路复用机制的封装 epoll.c：对epoll的封装； select.c：对select的封装； devpoll.c：对dev/poll的封装; kqueue.c：对kqueue的封装； 5）定时事件管理 min-heap.h：其实就是一个以时间作为key的小根堆结构； 6）信号管理 signal.c：对信号事件的处理； 7）辅助功能函数 evutil.h 和evutil.c：一些辅助功能函数，包括创建socket pair和一些时间操作函数：加、减和比较等。 8）日志 log.h和log.c：log日志函数 9）缓冲区管理 evbuffer.c和buffer.c：libevent对缓冲区的封装； 10）基本数据结构 compat/sys下的两个源文件：queue.h是libevent基本数据结构的实现，包括链表，双向链表，队列等；_libevent_time.h：一些用于时间操作的结构体定义、函数和宏定义； 11）实用网络库 http和evdns：是基于libevent实现的http服务器和异步dns查询库；
3. 小结 本节介绍了libevent的组织和分类，下面将会详细介绍libevent的核心部分event结构。</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析05</title>
      <link>https://haokiu.com/blog/1f6a82cdb17742a49514907b604e44c1/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1f6a82cdb17742a49514907b604e44c1/</guid>
      <description>libevent源码深度剖析05 libevent的核心：事件event
对事件处理流程有了高层的认识后，本节将详细介绍libevent的核心结构event，以及libevent对event的管理**。**
1. libevent的核心-event libevent是基于**事件驱动（event-driven）**的，从名字也可以看到event是整个库的核心。event就是Reactor框架中的事件处理程序组件；它提供了函数接口，供Reactor在事件发生时调用，以执行相应的事件处理，通常它会绑定一个有效的句柄。
首先给出event结构体的声明，它位于event.h文件中：
struct event { TAILQ_ENTRY (event) ev_next; TAILQ_ENTRY (event) ev_active_next; TAILQ_ENTRY (event) ev_signal_next; unsigned int min_heap_idx; /* for managing timeouts */ struct event_base *ev_base; int ev_fd; short ev_events; short ev_ncalls; short *ev_pncalls; /* Allows deletes in callback */ struct timeval ev_timeout; int ev_pri; /* smaller numbers are higher priority */ void (*ev_callback)(int, short, void *arg); void *ev_arg; int ev_res; /* result passed to event callback */ int ev_flags; }; ev_events：event关注的事件类型，它可以是以下3种类型：
I/O事件： EV_WRITE和EV_READ 定时事件：EV_TIMEOUT 信号： EV_SIGNAL 辅助选项：EV_PERSIST，表明是一个永久事件 Libevent中的定义为：
#define EV_TIMEOUT 0x01 #define EV_READ 0x02 #define EV_WRITE 0x04 #define EV_SIGNAL 0x08 #define EV_PERSIST 0x10 /* Persistant event */ 可以看出事件类型可以使用“|”运算符进行组合，需要说明的是，信号和I/O事件不能同时设置；</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析06</title>
      <link>https://haokiu.com/blog/fc115cade0c049a8ab14e737a22b37fe/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/fc115cade0c049a8ab14e737a22b37fe/</guid>
      <description>libevent源码深度剖析06 初见事件处理框架
前面已经对libevent的事件处理框架和event结构体做了描述，现在是时候剖析libevent对事件的详细处理流程了，本节将分析libevent的事件处理框架event_base和libevent注册、删除事件的具体流程，可结合前一节libevent对event的管理。
1. 事件处理框架-event_base 回想Reactor模式的几个基本组件，本节讲解的部分对应于Reactor框架组件。在libevent中，这就表现为event_base结构体，结构体声明如下，它位于event-internal.h文件中：
struct event_base { const struct eventop *evsel; void *evbase;　int event_count; /* counts number of total events */ int event_count_active; /* counts number of active events */ int event_gotterm; /* Set to terminate loop */ int event_break; /* Set to terminate loop immediately */ /* active event management */ struct event_list **activequeues; int nactivequeues; /* signal handling info */ struct evsignal_info sig; struct event_list eventqueue; struct timeval event_tv; struct min_heap timeheap; struct timeval tv_cache; }; 下面详细解释一下结构体中各字段的含义。
evsel和evbase这两个字段的设置可能会让人有些迷惑，这里你可以把evsel和evbase看作是类和静态函数的关系，比如添加事件时的调用行为：evsel-&amp;gt;add(evbase, ev)，实际执行操作的是evbase；这相当于class::add(instance, ev)，instance就是class的一个对象实例。 evsel指向了全局变量static const struct eventop *eventops[]中的一个； 前面也说过，libevent将系统提供的I/O demultiplex机制统一封装成了eventop结构；因此eventops[]包含了select、poll、kequeue和epoll等等其中的若干个全局实例对象。 evbase实际上是一个eventop实例对象； 先来看看eventop结构体，它的成员是一系列的函数指针, 在event-internal.h文件中：
struct eventop { const char *name; void *(*init)(struct event_base *); // 初始化 int (*add)(void *, struct event *); // 注册事件 int (*del)(void *, struct event *); // 删除事件 int (*dispatch)(struct event_base *, void *, struct timeval *); // 事件分发 void (*dealloc)(struct event_base *, void *); // 注销，释放资源 /* set if we need to reinitialize the event base */ int need_reinit; }; 也就是说，在libevent中，每种I/O demultiplex机制的实现都必须提供这五个函数接口，来完成自身的初始化、销毁释放；对事件的注册、注销和分发。 比如对于epoll，libevent实现了5个对应的接口函数，并在初始化时并将eventop的5个函数指针指向这5个函数，那么程序就可以使用epoll作为I/O demultiplex机制了，这个在后面会再次提到。</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析07</title>
      <link>https://haokiu.com/blog/1fa932a07dd84e9fbdde728e110c098f/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1fa932a07dd84e9fbdde728e110c098f/</guid>
      <description>libevent源码深度剖析07 事件主循环
现在我们已经初步了解了libevent的Reactor组件——event_base和事件管理框架，接下来就是libevent事件处理的中心部分——事件主循环，根据系统提供的事件多路分发机制执行事件循环，对已注册的就绪事件，调用注册事件的回调函数来处理事件。
1. 阶段性的胜利 libevent将I/O事件、定时器和信号事件处理很好的结合到了一起，本节也会介绍libevent是如何做到这一点的。 在看完本节的内容后，读者应该会对Libevent的基本框架：事件管理和主循环有比较清晰的认识了，并能够把libevent的事件控制流程清晰的串通起来，剩下的就是一些细节的内容了。
2. 事件处理主循环 libevent的事件主循环主要是通过**event_base_loop ()**函数完成的，其主要操作如下面的流程图所示，event_base_loop所作的就是持续执行下面的循环。 清楚了event_base_loop所作的主要操作，就可以对比源代码看个究竟了，代码结构还是相当清晰的。
int event_base_loop(struct event_base *base, int flags){ const struct eventop *evsel = base-&amp;gt;evsel; void *evbase = base-&amp;gt;evbase; struct timeval tv; struct timeval *tv_p; int res, done; // 清空时间缓存 base-&amp;gt;tv_cache.tv_sec = 0; // evsignal_base是全局变量，在处理signal时，用于指名signal所属的event_base实例 if (base-&amp;gt;sig.ev_signal_added) evsignal_base = base; done = 0; while (!done) { // 事件主循环 // 查看是否需要跳出循环，程序可以调用event_loopexit_cb()设置event_gotterm标记 // 调用event_base_loopbreak()设置event_break标记 if (base-&amp;gt;event_gotterm) { base-&amp;gt;event_gotterm = 0; break; } if (base-&amp;gt;event_break) { base-&amp;gt;event_break = 0; break; } // 校正系统时间，如果系统使用的是非MONOTONIC时间，用户可能会向后调整了系统时间 // 在timeout_correct函数里，比较last wait time和当前时间，如果当前时间&amp;lt; last wait time // 表明时间有问题，这是需要更新timer_heap中所有定时事件的超时时间。 timeout_correct(base, &amp;amp;tv); // 根据timer heap中事件的最小超时时间，计算系统I/O demultiplexer的最大等待时间 tv_p = &amp;amp;tv; if (!base-&amp;gt;event_count_active &amp;amp;&amp;amp; !</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析08</title>
      <link>https://haokiu.com/blog/4a5e0c5a568b4187b207ec0ada2dbdfb/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/4a5e0c5a568b4187b207ec0ada2dbdfb/</guid>
      <description>libevent源码深度剖析08 集成信号处理
现在我们已经了解了libevent的基本框架：事件管理框架和事件主循环。上节提到了libevent中I/O事件和Signal以及Timer事件的集成，这一节将分析如何将Signal集成到事件主循环的框架中。
1. 集成策略——使用socket pair 前一节已经做了足够多的介绍了，基本方法就是采用“消息机制”。在libevent中这是通过socket pair完成的，下面就来详细分析一下。 Socket pair就是一个socket对，包含两个socket，一个读socket，一个写socket。工作方式如下图所示：
创建一个socket pair并不是复杂的操作，可以参见下面的流程图，清晰起见，其中忽略了一些错误处理和检查。
Libevent提供了辅助函数evutil_socketpair()来创建一个socket pair，可以结合上面的创建流程来分析该函数。
2. 集成到事件主循环——通知event_base Socket pair创建好了，可是libevent的事件主循环还是不知道Signal是否发生了啊，看来我们还差了最后一步，那就是：为socket pair的读socket在libevent的event_base实例上注册一个persist的读事件。 这样当向写socket写入数据时，读socket就会得到通知，触发读事件，从而event_base就能相应的得到通知了。 前面提到过，Libevent会在事件主循环中检查标记，来确定是否有触发的signal，如果标记被设置就处理这些signal，这段代码在各个具体的I/O机制中，以Epoll为例，在**epoll_dispatch()**函数中，代码片段如下：
res = epoll_wait(epollop-&amp;gt;epfd, events, epollop-&amp;gt;nevents, timeout); if (res == -1) { if (errno != EINTR) { event_warn(&amp;#34;epoll_wait&amp;#34;); return (-1); } evsignal_process(base);// 处理signal事件 return (0); } else if (base-&amp;gt;sig.evsignal_caught) { evsignal_process(base);// 处理signal事件 } 完整的处理框架如下所示：
注1：libevent中，初始化阶段并不注册读socket的读事件，而是在注册信号阶段才会测试并注册； 注2：libevent中，检查I/O事件是在各系统I/O机制的**dispatch()函数中完成的，该dispatch()函数在event_base_loop()**函数中被调用；
3. evsignal_info结构体 libevent中Signal事件的管理是通过结构体evsignal_info完成的，结构体位于evsignal.h文件中，定义如下：
struct evsignal_info { struct event ev_signal; int ev_signal_pair[2]; int ev_signal_added; volatile sig_atomic_t evsignal_caught; struct event_list evsigevents[NSIG]; sig_atomic_t evsigcaught[NSIG]; #ifdef HAVE_SIGACTION struct sigaction **sh_old; #else ev_sighandler_t **sh_old; #endif int sh_old_max; }; 下面详细介绍一下个字段的含义和作用： 1）ev_signal， 为socket pair的读socket向event_base注册读事件时使用的event结构体； 2）ev_signal_pair，socket pair对，作用见第一节的介绍； 3）ev_signal_added，记录ev_signal事件是否已经注册了； 4）evsignal_caught，是否有信号发生的标记；是volatile类型，因为它会在另外的线程中被修改； 5）evsigvents[NSIG]，数组，evsigevents[signo]表示注册到信号signo的事件链表； 6）evsigcaught[NSIG]，具体记录每个信号触发的次数，evsigcaught[signo]是记录信号signo被触发的次数； 7）sh_old记录了原来的signal处理函数指针，当信号signo注册的event被清空时，需要重新设置其处理函数； evsignal_info的初始化包括，创建socket pair，设置ev_signal事件（但并没有注册，而是等到有信号注册时才检查并注册），并将所有标记置零，初始化信号的注册事件链表指针等。</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析09</title>
      <link>https://haokiu.com/blog/e65e0c91ca7e45ad9ad3081edbd423f8/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/e65e0c91ca7e45ad9ad3081edbd423f8/</guid>
      <description>libevent源码深度剖析09 集成定时器事件
现在再来详细分析libevent中I/O事件和Timer事件的集成，与Signal相比，Timer事件的集成会直观和简单很多。Libevent对堆的调整操作做了一些优化，本节还会描述这些优化方法。
1. 集成到事件主循环 因为系统的I/O机制像select()和epoll_wait()都允许程序制定一个最大等待时间（也称为最大超时时间）timeout，即使没有I/O事件发生，它们也保证能在timeout时间内返回。 那么根据所有Timer事件的最小超时时间来设置系统I/O的timeout时间；当系统I/O返回时，再激活所有就绪的Timer事件就可以了，这样就能将Timer事件完美的融合到系统的I/O机制中了。 具体的代码在源文件event.c的**event_base_loop()**中，现在就对比代码来看看这一处理方法：
if (!base-&amp;gt;event_count_active &amp;amp;&amp;amp; !(flags &amp;amp; EVLOOP_NONBLOCK)) { // 根据Timer事件计算evsel-&amp;gt;dispatch的最大等待时间 timeout_next(base, &amp;amp;tv_p); } else { // 如果还有活动事件，就不要等待，让evsel-&amp;gt;dispatch立即返回 evutil_timerclear(&amp;amp;tv); } // ... // 调用select() or epoll_wait() 等待就绪I/O事件 res = evsel-&amp;gt;dispatch(base, evbase, tv_p); // ... // 处理超时事件，将超时事件插入到激活链表中 timeout_process(base); **timeout_next()**函数根据堆中具有最小超时值的事件和当前时间来计算等待时间，下面看看代码：
1static int timeout_next(struct event_base *base, struct timeval **tv_p){ 2 struct timeval now; 3 struct event *ev; 4 struct timeval *tv = *tv_p; 5 // 堆的首元素具有最小的超时值 6 if ((ev = min_heap_top(&amp;amp;base-&amp;gt;timeheap)) == NULL) { 7 // 如果没有定时事件，将等待时间设置为NULL,表示一直阻塞直到有I/O事件发生 8 *tv_p = NULL; 9 return (0); 10 } 11 // 取得当前时间 12 gettime(base, &amp;amp;now); 13 // 如果超时时间&amp;lt;=当前值，不能等待，需要立即返回 14 if (evutil_timercmp(&amp;amp;ev-&amp;gt;ev_timeout, &amp;amp;now, &amp;lt;=)) { 15 evutil_timerclear(tv); 16 return (0); 17 } 18 // 计算等待的时间=当前时间-最小的超时时间 19 evutil_timersub(&amp;amp;ev-&amp;gt;ev_timeout, &amp;amp;now, tv); 20 return (0); 21} 2.</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析10</title>
      <link>https://haokiu.com/blog/f567712a9375435692b3217e444f19e5/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/f567712a9375435692b3217e444f19e5/</guid>
      <description>libevent源码深度剖析10 支持I/O多路复用技术
libevent的核心是事件驱动、同步非阻塞，为了达到这一目标，必须采用系统提供的I/O多路复用技术，而这些在Windows、Linux、Unix等不同平台上却各有不同，如何能提供优雅而统一的支持方式，是首要关键的问题，这其实不难，本节就来分析一下。
1. 统一的关键 libevent支持多种I/O多路复用技术的关键就在于结构体eventop，这个结构体前面也曾提到过，它的成员是一系列的函数指针, 定义在event-internal.h文件中：
struct eventop { const char *name; void *(*init)(struct event_base *); // 初始化 int (*add)(void *, struct event *); // 注册事件 int (*del)(void *, struct event *); // 删除事件 int (*dispatch)(struct event_base *, void *, struct timeval *); // 事件分发 void (*dealloc)(struct event_base *, void *); // 注销，释放资源 /* set if we need to reinitialize the event base */ int need_reinit; }; 在libevent中，每种I/O demultiplex机制的实现都必须提供这五个函数接口，来完成自身的初始化、销毁释放；对事件的注册、注销和分发。 比如对于epoll，libevent实现了5个对应的接口函数，并在初始化时并将eventop的5个函数指针指向这5个函数，那么程序就可以使用epoll作为I/O demultiplex机制了。
2. 设置I/O demultiplex机制 libevent把所有支持的I/O demultiplex机制存储在一个全局静态数组eventops中，并在初始化时选择使用何种机制，数组内容根据优先级顺序声明如下：
/* In order of preference */ static const struct eventop *eventops[] = { #ifdef HAVE_EVENT_PORTS &amp;amp;evportops, #endif #ifdef HAVE_WORKING_KQUEUE &amp;amp;kqops, #endif #ifdef HAVE_EPOLL &amp;amp;epollops, #endif #ifdef HAVE_DEVPOLL &amp;amp;devpollops, #endif #ifdef HAVE_POLL &amp;amp;pollops, #endif #ifdef HAVE_SELECT &amp;amp;selectops, #endif #ifdef WIN32 &amp;amp;win32ops, #endif NULL }; 然后libevent根据系统配置和编译选项决定使用哪一种I/O demultiplex机制，这段代码在函数**event_base_new()**中：</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析11</title>
      <link>https://haokiu.com/blog/136973dd819b459bac605bcb1a25571c/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/136973dd819b459bac605bcb1a25571c/</guid>
      <description>libevent源码深度剖析11 时间管理
为了支持定时器，libevent必须和系统时间打交道，这一部分的内容也比较简单，主要涉及到时间的加减辅助函数、时间缓存、时间校正和定时器堆的时间值调整等。下面就结合源代码来分析一下。
1. 初始化检测 libevent在初始化时会检测系统时间的类型，通过调用函数**d****etect_monotonic()完成，它通过调用clock_gettime()**来检测系统是否支持monotonic时钟类型：
static void detect_monotonic(void){ #if defined(HAVE_CLOCK_GETTIME) &amp;amp;&amp;amp; defined(CLOCK_MONOTONIC) struct timespec ts; if (clock_gettime(CLOCK_MONOTONIC, &amp;amp;ts) == 0) use_monotonic = 1; // 系统支持monotonic时间 #endif } Monotonic时间指示的是系统从boot后到现在所经过的时间，如果系统支持Monotonic时间就将全局变量use_monotonic设置为1，设置use_monotonic到底有什么用，这个在后面说到时间校正时就能看出来了。
2. 时间缓存 结构体event_base中的tv_cache，用来记录时间缓存。这个还要从函数**gettime()**说起，先来看看该函数的代码：
static int gettime(struct event_base *base, struct timeval *tp){ // 如果tv_cache时间缓存已设置，就直接使用 if (base-&amp;gt;tv_cache.tv_sec) { *tp = base-&amp;gt;tv_cache; return (0); } // 如果支持monotonic，就用clock_gettime获取monotonic时间 #if defined(HAVE_CLOCK_GETTIME) &amp;amp;&amp;amp; defined(CLOCK_MONOTONIC) if (use_monotonic) { struct timespec ts; if (clock_gettime(CLOCK_MONOTONIC, &amp;amp;ts) == -1) return (-1); tp-&amp;gt;tv_sec = ts.tv_sec; tp-&amp;gt;tv_usec = ts.tv_nsec / 1000; return (0); } #endif // 否则只能取得系统当前时间 return (evutil_gettimeofday(tp, NULL)); } 如果tv_cache已经设置，那么就直接使用缓存的时间；否则需要再次执行系统调用获取系统时间。 函数**evutil_gettimeofday()用来获取当前系统时间，在Linux下其实就是系统调用gettimeofday()；Windows没有提供函数gettimeofday，而是通过调用_ftime()**来完成的。 在每次系统事件循环中，时间缓存tv_cache将会被相应的清空和设置，再次来看看下面event_base_loop的主要代码逻辑：
int event_base_loop(struct event_base *base, int flags){ // 清空时间缓存 base-&amp;gt;tv_cache.tv_sec = 0; while(!</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析12</title>
      <link>https://haokiu.com/blog/1f455bc4e89944fe8fb0ca8f3bbcdc1b/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1f455bc4e89944fe8fb0ca8f3bbcdc1b/</guid>
      <description>libevent源码深度剖析12 让libevent支持多线程
libevent本身不是多线程安全的，在多核的时代，如何能充分利用CPU的能力呢，这一节来说说如何在多线程环境中使用libevent，跟源代码并没有太大的关系，纯粹是使用上的技巧。
1. 错误使用示例 在多核的CPU上只使用一个线程始终是对不起CPU的处理能力啊，那好吧，那就多创建几个线程，比如下面的简单服务器场景。 1 主线程创建工作线程1； 2 接着主线程监听在端口上，等待新的连接； 3 在线程1中执行event事件循环，等待事件到来； 4 新连接到来，主线程调用libevent接口event_add将新连接注册到libevent上； … … 上面的逻辑看起来没什么错误，在很多服务器设计中都可能用到主线程和工作线程的模式…. 可是就在线程1注册事件时，主线程很可能也在操作事件，比如删除，修改，通过libevent的源代码也能看到，没有同步保护机制，问题麻烦了，看起来不能这样做啊，难道只能使用单线程不成！？
2. 支持多线程的几种模式 libevent并不是线程安全的，但这不代表libevent不支持多线程模式，其实方法在前面已经将signal事件处理时就接触到了，那就是消息通知机制。 一句话，“你发消息通知我，然后再由我在合适的时间来处理”； 说到这就再多说几句，再打个比方，把你自己比作一个工作线程，而你的头是主线程，你有一个消息信箱来接收别人发给你的消息，当时头有个新任务要指派给你。
2.1 暴力抢占 那么第一节中使用的多线程方法相当下面的流程： 1 当时你正在做事，比如在写文档； 2 你的头找到了一个任务，要指派给你，比如帮他搞个PPT，哈； 3 头命令你马上搞PPT，你这是不得不停止手头的工作，把PPT搞定了再接着写文档； …
2.2 纯粹的消息通知机制 那么基于纯粹的消息通知机制的多线程方式就像下面这样： 1 当时你正在写文档； 2 你的头找到了一个任务，要指派给你，帮他搞个PPT； 3 头发个消息到你信箱，有个PPT要帮他搞定，这时你并不鸟他； 4 你写好文档，接着检查消息发现头有个PPT要你搞定，你开始搞PPT； … 第一种的好处是消息可以立即得到处理，但是很方法很粗暴，你必须立即处理这个消息，所以你必须处理好切换问题，省得把文档上的内容不小心写到PPT里。在操作系统的进程通信中，消息队列（消息信箱）都是操作系统维护的，你不必关心。 第二种的优点是通过消息通知，切换问题省心了，不过消息是不能立即处理的（基于消息通知机制，这个总是难免的），而且所有的内容都通过消息发送，比如PPT的格式、内容等等信息，这无疑增加了通信开销。
2.3 消息通知+同步层 有个折中机制可以减少消息通信的开销，就是提取一个同步层，还拿上面的例子来说，你把工作安排都存放在一个工作队列中，而且你能够保证“任何人把新任务扔到这个队列”，“自己取出当前第一个任务”等这些操作都能够保证不会把队列搞乱（其实就是个加锁的队列容器）。 再来看看处理过程和上面有什么不同： 1 当时你正在写文档； 2 你的头找到了一个任务，要指派给你，帮他搞个PPT； 2 头有个PPT要你搞定，他把任务push到你的工作队列中，包括了PPT的格式、内容等信息； 3 头发个消息（一个字节）到你信箱，有个PPT要帮他搞定，这时你并不鸟他； 4 你写好文档，发现有新消息（这预示着有新任务来了），检查工作队列知道头有个PPT要你搞定，你开始搞PPT； … 工作队列其实就是一个加锁的容器（队列、链表等等），这个很容易实现实现；而消息通知仅需要一个字节，具体的任务都push到了在工作队列中，因此想比2.2减少了不少通信开销。 多线程编程有很多陷阱，线程间资源的同步互斥不是一两句能说得清的，而且出现bug很难跟踪调试；这也有很多的经验和教训，因此如果让我选择，在绝大多数情况下都会选择机制3作为实现多线程的方法。
3. 例子——memcached Memcached中的网络部分就是基于libevent完成的，其中的多线程模型就是典型的消息通知+同步层机制。下面的图足够说明其多线程模型了，其中有详细的文字说明。
注：该图的具体出处忘记了，感谢原作者。
4. 小节 本节更是libevent的使用方面的技巧，讨论了一下如何让libevent支持多线程，以及几种支持多线程的机制，和memcached使用libevent的多线程模型。</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析13</title>
      <link>https://haokiu.com/blog/b05b12b227ee4ce494fe99d9116d6a23/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/b05b12b227ee4ce494fe99d9116d6a23/</guid>
      <description>libevent源码深度剖析13 libevent信号处理注意点
前面讲到了 libevent 实现多线程的方法，然而在多线程的环境中注册信号事件，还是有一些情况需要小心处理，那就是不能在多个 libevent 实例上注册信号事件。依然冠名追加到 libevent 系列。
以 2 个线程为例，做简单的场景分析。
1 首先是创建并初始化线程 1 的 libevent 实例 base1 ，线程 1 的 libevent 实例 base2 ；
2 在 base1 上注册 SIGALRM 信号；在 base2 上注册 SIGINT 信号；
3 假设当前 base1 和 base2 上都没有注册其他的事件；
4 线程 1 和 2 都进入 event_base_loop 事件循环：
5 假设线程 1 先进入 event_base_loop ，并设置 evsignal_base = base1 ；并等待；
6 接着线程 2 也进入 event_base_loop ，并设置 evsignal_base = base2 ；并等待；
于是 evsignal_base 就指向了 base2 ；
7 信号 ALARM 触发，调用服务例程：
static void evsignal_handler(int sig){ ... evsignal_base-&amp;gt;sig.evsigcaught[sig]++; evsignal_base-&amp;gt;sig.evsignal_caught = 1; /* Wake up our notification mechanism */ send(evsignal_base-&amp;gt;sig.ev_signal_pair[0], &amp;#34;a&amp;#34;, 1, 0); ... } 于是 base2 得到通知 ALARM 信号发生了，而实际上 ALARM 是注册在 base1 上的， base2 上的 ALARM 注册 event 是空的，于是处理函数将不能得到调用；因此在 libevent 中，如果需要处理信号，只能将信号注册到一个 libevent 实例上。</description>
    </item>
    
    <item>
      <title>libevent源码深度剖析一</title>
      <link>https://haokiu.com/blog/8aa77e3ff7e54bdb8899e32f75300864/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/8aa77e3ff7e54bdb8899e32f75300864/</guid>
      <description>libevent源码深度剖析一 1. 前言 libevent是一个轻量级的开源高性能网络库，使用者众多，研究者更甚，相关文章也不少。写这一系列文章的用意在于，一则分享心得；二则对libevent代码和设计思想做系统的、更深层次的分析，写出来，也可供后来者参考。
附带一句：libevent是用c语言编写的（大牛们都偏爱c语言哪），而且几乎是无处不函数指针，学习其源代码也需要相当的c语言基础。
2. Libevent简介 上来当然要先夸奖啦，libevent 有几个显著的亮点： 事件驱动（event-driven），高性能; 轻量级，专注于网络，不如ACE那么臃肿庞大； 源代码相当精炼、易读； 跨平台，支持Windows、Linux、BSD和Mac Os； 支持多种I/O多路复用技术， epoll、poll、dev/poll、select和kqueue等； 支持I/O，定时器和信号等事件； 注册事件优先级；
libevent已经被广泛的应用，作为底层的网络库；比如memcached、Vomit、Nylon、Netchat等等。 libevent当前的最新稳定版是1.4.13；这也是本文参照的版本。
3. 学习的好处 学习libevent有助于提升程序设计功力，除了网络程序设计方面外，libevent的代码里有很多有用的设计技巧和基础数据结构，比如信息隐藏、函数指针、c语言的多态支持、链表和堆等等，都有助于提升自身的程序功力。 程序设计不止要了解框架，很多细节之处恰恰也是事关整个系统成败的关键。只对libevent本身的框架大概了解，那或许仅仅是一知半解，不深入代码分析，就难以了解其设计的精巧之处，也就难以为自己所用。
事实上libevent本身就是一个典型的Reactor模型，理解Reactor模式是理解libevent的基石；因此下一节将介绍典型的事件驱动设计模式——Reactor模式。
参考资料： libevent官方地址: http://monkey.org/~provos/libevent/</description>
    </item>
    
    <item>
      <title>Linux C/C&#43;&#43;后端开发面试问哪些问题</title>
      <link>https://haokiu.com/blog/8570010b5d82422da83500ab481816be/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/8570010b5d82422da83500ab481816be/</guid>
      <description>Linux C/C++后端开发面试问哪些问题 今天我的技术群（想加技术群的可以加我微信 easy_coder）里面一名叫“成都-go-戒炸鸡”的群友提出了他最近面试的一些面试题，面试题内容个人觉得非常典型、也非常有代表性和针对性，故拿出来与大家分享一下，也感谢他的分享。成都-go-戒炸鸡说：
“今天面试，我没答出来的有redis持久化机制，redis销毁方式机制，mq实现原理，c++虚函数，hash冲突的解决，memcached一致性哈希，socket函数select的缺陷，epoll模型，同步互斥，异步非阻塞，回调的概念，innodb索引原理，单向图最短路径，动态规划算法。”
为了避免问题有歧义，面试题略有修改。
思路分析 从面试题的内容可以看出，这是一个后台开发的职位。
除了关于 c++ 虚函数这个问题以外，其他的大多数问题都与哪种编程语言关系不大，大多数是原理性和基础性的问题，少数是工作经验问题，笔者试着给大家分析。
语言基础 C++ 虚函数这是面试初、中级 C ++ 职位一个概率95%以上的面试题。一般有以下几种问法：
在有继承关系的父子类中，构建和析构一个子类对象时，父子构造函数和析构函数的执行顺序分别是怎样的？ 在有继承关系的类体系中，父类的构造函数和析构函数一定要申明为 virtual 吗？如果不申明为 virtual 会怎样？ 什么是 C++ 多态？C++ 多态的实现原理是什么？ 什么是虚函数？虚函数的实现原理是什么？ 什么是虚表？虚表的内存结构布局如何？虚表的第一项（或第二项）是什么？ 菱形继承（类D同时继承B和C，B和C又继承自A）体系下，虚表在各个类中的布局如何？如果类B和类C同时有一个成员变了m，m如何在D对象的内存地址上分布的？是否会相互覆盖？ 算法与数据结构基础 说到算法和数据结构，对于社招人士和对于应届生一般是不一样的，对于大的互联网公司和一般的小的企业也是不一样的。下面根据我当面试官面试别人和找工作被别人面试经验来谈一谈。
先说考察的内容，除了一些特殊的岗位，常见的算法和数据结构面试问题有如下：
排序（常考的排序按频率考排序为：快速排序 &amp;gt; 冒泡排序 &amp;gt; 归并排序 &amp;gt; 桶排序） 一般对于对算法基础有要求的公司，如果你是应届生或者工作经验在一至三年内，以上算法如果写不出来，给面试官的影响会非常不好，甚至直接被 pass 掉。对于工作三年以上的社会人士，如果写不出来，但是能分析出其算法复杂度、最好和最坏的情况下的复杂度，说出算法大致原理，在多数面试官面前也可以过的。注意，如果你是学生，写不出来或者写的不对，基本上面试过不了。
二分查找
二分查找的算法尽量要求写出来。当然，大多数面试官并不会直接问你二分查找，而是结合具体的场景，例如如何求一个数的平方根，这个时候你要能想到是二分查找。我在2017年年底，面试agora时，面试官问了一个问题：如何从所有很多的ip地址中快速找个某个ip地址。
链表
无论是应届生还是工作年限不长的社会人士，琏表常见的操作一定要熟练写出来，如链表的查找、定位、反转、连接等等。还有一些经典的问题也经常被问到，如两个链表如何判断有环（我在2017年面试饿了么二面、上海黄金交易所一面被问过）。链表的问题一般不难，但是链表的问题存在非常多的“坑”，如很多人不注意边界检查、空链表、返回一个链表的函数应该返回链表的头指针等等。
队列与栈
对于应届生来说一般这一类问的比较少，但是对于社会人士尤其是中高级岗位开发，会结合相关的问题问的比较多，例如让面试者利用队列写一个多线程下的生产者和消费者程序，全面考察的多线程的资源同步与竞态问题（下文介绍多线程面试题时详细地介绍）。
栈一般对于基础要求高的面试，会结合函数调用实现来问。即函数如何实现的，包括函数的调用的几种常见调用方式、参数的入栈顺序、内存栈在地址从高向低扩展、栈帧指针和栈顶指针的位置、函数内局部变量在栈中的内存分布、函数调用结束后，调用者和被调用者谁和如何清理栈等等。某年面试京东一基础部门，面试官让写从0加到100这样一个求和算法，然后写其汇编代码。
哈希表
哈希表是考察最多的数据结构之一。常见的问题有哈希冲突的检测、让面试者写一个哈希插入函数等等。基本上一场面试下来不考察红黑树基本上就会问哈希表，而且问题可浅可深。我印象比较深刻的是，当年面试百度广告推荐部门时，二面问的一些关于哈希表的问题。当时面试官时先问的链表，接着问的哈希冲突的解决方案，后来让写一个哈希插入算法，这里需要注意的是，你的算法中插入的元素一定要是通用元素，所以对于 C++ 或者 Java 语言，一定要使用模板这一类参数作为哈希插入算法的对象。然后，就是哈希表中多个元素冲突时，某个位置的元素使用链表往后穿成一串的方案。最终考察 linux 下 malloc（下面的ptmalloc） 函数在频繁调用造成的内存碎片问题，以及开源方案解决方案 tcmalloc 和 jemalloc。总体下来，面试官是一步步引导你深入。（有兴趣的读者可以自行搜索，网上有很多相关资料）
树
面试高频的树是红黑树，也有一部分是B树（B+树）。
红黑树一般的问的深浅不一，大多数面试官只要能说出红黑树的概念、左旋右旋的方式、分析出查找和插入的平均算法复杂度和最好最坏时的算法复杂度，并不要写面试者写出具体代码实现。一般 C++ 面试问 stl 的map，java 面试问 TreeMap 基本上就等于开始问你红黑树了，要有心里准备。笔者曾经面试爱奇艺被问过红黑树。
B树一般不会直接问，问的最多的形式是通过问 MySQL 索引实现原理（数据库知识点将在下文中讨论）。笔者面试腾讯看点部门二面被问到过。
图
图的问题就我个人面试从来没遇到过，不过据我某位哥哥所说，他在进三星电子之前有一道面试题就是深度优先和广度优先问题。
其他的一些算法
如A*寻路、霍夫曼编码也偶尔会在某一个领域的公司的面试中被问到，如宝开（《植物大战僵尸》的母公司， 在上海人民广场附近有分公司）。
编码基本功 还有一类面试题不好分类，笔者姑且将其当作是考察编码基本功，这类问题既可以考察算法也可以考察你写代码基本素养，这些素养不仅包括编码风格、计算机英语水平、调试能力等，还包括你对细节的掌握和易错点理解，如有意识地对边界条件的检查和非法值的过滤。请读者看以下的代码执行结果是什么？（笔者2011年去北京中关村的鼎普面试的问题）
for(char i = 0; i &amp;lt; 256; ++i) { printf(&amp;#34;%d\n&amp;#34;, i); } 下面再列举几个常见的编码题：
实现一个 memmov 函数
这个题目考查点在于 memmov 函数与 memcpy 函数的区别，这两者对于源地址与目标地址内存有重叠的这一情况的处理方式是不一样的。</description>
    </item>
    
    <item>
      <title>Linux epoll 模型（含LT 模式和 ET 模式详解）</title>
      <link>https://haokiu.com/blog/e4e0126749ad480399c46665753f03e4/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/e4e0126749ad480399c46665753f03e4/</guid>
      <description>Linux epoll 模型（含LT 模式和 ET 模式详解） 综合 select 和 poll 的一些优缺点，Linux 从内核 2.6 版本开始引入了更高效的 epoll 模型，本节我们来详细介绍 epoll 模型。
要想使用 epoll 模型，必须先需要创建一个 epollfd，这需要使用 epoll_create 函数去创建：
#include &amp;lt;sys/epoll.h&amp;gt; int epoll_create(int size); 参数 size 从 Linux 2.6.8 以后就不再使用，但是必须设置一个大于 0 的值。epoll_create 函数调用成功返回一个非负值的 epollfd，调用失败返回 -1。
有了 epollfd 之后，我们需要将我们需要检测事件的其他 fd 绑定到这个 epollfd 上，或者修改一个已经绑定上去的 fd 的事件类型，或者在不需要时将 fd 从 epollfd 上解绑，这都可以使用 epoll_ctl 函数：
int epoll_ctl(int epfd, int op, int fd, struct epoll_event* event); 参数说明：
参数 epfd 即上文提到的 epollfd；
参数 op，操作类型，取值有 EPOLL_CTL_ADD、EPOLL_CTL_MOD 和 EPOLL_CTL_DEL，分别表示向 epollfd 上添加、修改和移除一个其他 fd，当取值是 EPOLL_CTL_DEL，第四个参数 event 忽略不计，可以设置为 NULL；
参数 fd，即需要被操作的 fd；
参数 event，这是一个 epoll_event 结构体的地址，epoll_event 结构体定义如下：
struct epoll_event { uint32_t events; /* 需要检测的 fd 事件，取值与 poll 函数一样 */ epoll_data_t data; /* 用户自定义数据 */ }; epoll_event 结构体的 data 字段的类型是 epoll_data_t，我们可以利用这个字段设置一个自己的自定义数据，它本质上是一个 Union 对象，在 64 位操作系统中其大小是 8 字节，其定义如下：</description>
    </item>
    
    <item>
      <title>Linux tcpdump 使用介绍</title>
      <link>https://haokiu.com/blog/6eecf1781f7d4e1691c367ebf702d4d2/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/6eecf1781f7d4e1691c367ebf702d4d2/</guid>
      <description>Linux tcpdump 使用介绍 tcpdump 是 Linux 系统提供一个非常强大的抓包工具，熟练使用它，对我们排查网络问题非常有用。如果你的机器上还没有安装，可以使用如下命令安装：
yum install tcpdump 如果要使用 tcpdump 命令必须具有 sudo 权限。
tcpdump 常用的选项有：
-i 指定要捕获的目标网卡名，网卡名可以使用前面章节中介绍的 ifconfig 命令获得；如果要抓所有网卡的上的包，可以使用 any 关键字。
## 抓取网卡ens33上的包 tcpdump -i ens33 ## 抓取所有网卡上的包 tcpdump -i any -X 以 ASCII 和十六进制的形式输出捕获的数据包内容，减去链路层的包头信息；-XX 以 ASCII 和十六进制的形式输出捕获的数据包内容，包括链路层的包头信息。
-n 不要将 ip 地址显示成别名的形式；-nn 不要将 ip 地址和端口以别名的形式显示。
-S 以绝对值显示包的 ISN 号（包序列号），默认以上一包的偏移量显示。
-vv 抓包的信息详细地显示；-vvv 抓包的信息更详细地显示。
-w 将抓取的包的原始信息（不解析，也不输出）写入文件中，后跟文件名：
tcpdump -i any -w filename -r 从利用 -w 选项保存的包文件中读取数据包信息。
除了可以使用选项以外，tcpdump 还支持各种数据包过滤的表达式，常见的形式如下：
## 仅显示经过端口 8888 上的数据包（包括tcp:8888和udp:8888） tcpdump -i any &amp;#39;port 8888&amp;#39; ## 仅显示经过端口是 tcp:8888 上的数据包 tcpdump -i any &amp;#39;tcp port 8888&amp;#39; ## 仅显示从源端口是 tcp:8888 的数据包 tcpdump -i any &amp;#39;tcp src port 8888&amp;#39; ## 仅显示源端口是 tcp:8888 或目标端口是 udp:9999 的包 tcpdump -i any &amp;#39;tcp src port 8888 or udp dst port 9999&amp;#39; ## 仅显示地址是127.</description>
    </item>
    
    <item>
      <title>Linux 网络故障排查的瑞士军刀</title>
      <link>https://haokiu.com/blog/501d5d7dacf24f4098180740dba82434/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/501d5d7dacf24f4098180740dba82434/</guid>
      <description>Linux 网络故障排查的瑞士军刀 nc 即 netcat 命令，这个工具在排查网络故障时非常有用，功能非常强大，因而被业绩称为网络界的“瑞士军刀”，请读者务必掌握。默认系统是没有这个命令的，你需要安装一下，安装方法：
yum install nc nc 命令常见的用法是模拟一个服务器程序被其他客户端连接，或者模拟一个客户端连接其他服务器，连接之后就可以进行数据收发。我们来逐一介绍一下：
模拟一个服务器程序
使用 -l 选项（单词 listen 的第一个字母）在某个 ip 地址和端口号上开启一个侦听服务，以便让其他客户端连接。通常为了显示更详细的信息，会带上 -v 选项。
示例如下：
[root@iZ238vnojlyZ ~]# nc -v -l 127.0.0.1 6000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on 127.0.0.1:6000 这样就在 6000 端口开启了一个侦听服务器，我们可以通过 127.0.0.1:6000 去连接上去；如果你的机器可以被外网访问，你可以使用 0.0.0.0 这样的侦听地址，示例：
[root@iZ238vnojlyZ ~]# nc -v -l 0.0.0.0 6000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on 0.0.0.0:6000 模拟一个客户端程序
用 nc 命令模拟一个客户端程序时，我们不需要使用 -l 选项，直接写上 ip 地址（或域名，nc 命令可以自动解析域名）和端口号即可，示例如下：
## 连接百度 web 服务器 [root@iZ238vnojlyZ ~]# nc -v www.baidu.com 80 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 115.239.211.112:80. 输出提示我们成功连接上百度 Web 服务器。
我们知道客户端连接服务器一般都是操作系统随机分配一个可用的端口号连接到服务器上去，使用 nc 命令作为客户端时可以使用 -p 选项指定使用哪个端口号连接服务器，例如，我们希望通过本地 5555 端口连接百度的 Web 服务器，可以这么输入：</description>
    </item>
    
    <item>
      <title>Memcached源码分析</title>
      <link>https://haokiu.com/blog/d10283bf526c437a9e64e40d5afa25c4/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/d10283bf526c437a9e64e40d5afa25c4/</guid>
      <description>Memcached源码分析 00 服务器资源调整
01 初始化参数解析
02 网络监听的建立
03 网络连接建立
04 内存初始化
05 资源初始化
06 get过程
07 cas属性
08 内存池
09 连接队列
10 Hash表操作
12 set操作
13 do_item_alloc操作
14 item结构
15 Hash表扩容
16 线程交互
17 状态机
​</description>
    </item>
    
    <item>
      <title>Memcached源码分析三 网络连接建立</title>
      <link>https://haokiu.com/blog/2a422d9fa3fe4cddbcbef326866d8943/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/2a422d9fa3fe4cddbcbef326866d8943/</guid>
      <description>Memcached源码分析三 网络连接建立 接着上一篇继续分析，上一篇请参考 《Memcached源码阅读之网络监听的建立》，这篇主要分析TCP的连接建立（从前面的代码分析可以看出，这个过程是由主线程驱动的），UDP没有连接建立的过程，所以之间进行连接分发，我们后续分析，现在直接上代码进行讲解。
conn *conn_new(const int sfd, enum conn_states init_state, const int event_flags, const int read_buffer_size, enum network_transport transport, struct event_base *base) { conn *c = conn_from_freelist(); //获取一个空闲连接，conn是Memcached内部对网络连接的一个封装 //如果没有空闲的连接 if (NULL == c) { if (!(c = (conn *)calloc(1, sizeof(conn))))//申请空间 { fprintf(stderr, &amp;#34;calloc()\n&amp;#34;); return NULL; }MEMCACHED_CONN_CREATE(c); //进行一些初始化 c-&amp;gt;rbuf = c-&amp;gt;wbuf = 0; c-&amp;gt;ilist = 0; c-&amp;gt;suffixlist = 0; c-&amp;gt;iov = 0; c-&amp;gt;msglist = 0; c-&amp;gt;hdrbuf = 0; c-&amp;gt;rsize = read_buffer_size; c-&amp;gt;wsize = DATA_BUFFER_SIZE; c-&amp;gt;isize = ITEM_LIST_INITIAL; c-&amp;gt;suffixsize = SUFFIX_LIST_INITIAL; c-&amp;gt;iovsize = IOV_LIST_INITIAL; c-&amp;gt;msgsize = MSG_LIST_INITIAL; c-&amp;gt;hdrsize = 0; //每个conn都自带读入和输出缓冲区，在进行网络收发数据时，特别方便 c-&amp;gt;rbuf = (char *)malloc((size_t)c-&amp;gt;rsize); c-&amp;gt;wbuf = (char *)malloc((size_t)c-&amp;gt;wsize); c-&amp;gt;ilist = (item **)malloc(sizeof(item *) * c-&amp;gt;isize); c-&amp;gt;suffixlist = (char **)malloc(sizeof(char *) * c-&amp;gt;suffixsize); c-&amp;gt;iov = (struct iovec *) malloc(sizeof(struct iovec) * c-&amp;gt;iovsize); c-&amp;gt;msglist = (struct msghdr *) malloc( sizeof(struct msghdr) * c-&amp;gt;msgsize); if (c-&amp;gt;rbuf == 0 || c-&amp;gt;wbuf == 0 || c-&amp;gt;ilist == 0 || c-&amp;gt;iov == 0 || c-&amp;gt;msglist == 0 || c-&amp;gt;suffixlist == 0) { conn_free(c); fprintf(stderr, &amp;#34;malloc()\n&amp;#34;); return NULL; } STATS_LOCK(); //统计变量更新 stats.</description>
    </item>
    
    <item>
      <title>Memcached源码阅读一 初始化参数解析</title>
      <link>https://haokiu.com/blog/778cf564240e4d19ad39e0e271d66b3d/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/778cf564240e4d19ad39e0e271d66b3d/</guid>
      <description>Memcached源码阅读一 初始化参数解析 Memcached启动时，有很多配置参数可以选择，这些配置参数严重影响着Memcached的使用，下面分析下这些参数的意义，开源软件版本之间差异比较大，我这次分析是基于1.4.15进行分析的，大家学习时记得核对版本。
&amp;#34;a:&amp;#34; //unix socket的权限位信息，unix socket的权限位信息和普通文件的权限位信息一样 &amp;#34;p:&amp;#34; //memcached监听的TCP端口值，默认是11211 &amp;#34;s:&amp;#34; //unix socket监听的socket文件路径 &amp;#34;U:&amp;#34; //memcached监听的UDP端口值，默认是11211 &amp;#34;m:&amp;#34; //memcached使用的最大内存值，默认是64M &amp;#34;M&amp;#34; //当memcached的内存使用完时，不进行LRU淘汰数据，直接返回错误，该选项就是关闭LRU &amp;#34;c:&amp;#34; //memcached的最大连接数,如果不指定，按系统的最大值进行 &amp;#34;k&amp;#34; //是否锁定memcached所持有的内存，如果锁定了内存，其他业务持有的内存就会减小 &amp;#34;hi&amp;#34; //帮助信息 &amp;#34;r&amp;#34; //core文件的大小，如果不指定，按系统的最大值进行 &amp;#34;v&amp;#34; //调试信息 &amp;#34;d&amp;#34; //设定以daemon方式运行 &amp;#34;l:&amp;#34; //绑定的ip信息，如果服务器有多个ip，可以在多个ip上面启动多个Memcached实例，注意：这个不是可接收的IP地址 &amp;#34;u:&amp;#34; //memcached运行的用户，如果以root启动，需要指定用户，否则程序错误，退出。 &amp;#34;P:&amp;#34; //memcached以daemon方式运行时，保存pid的文件路径信息 &amp;#34;f:&amp;#34; //内存的扩容因子，这个关系到Memcached内部初始化空间时的一个变化，后面详细说明 &amp;#34;n:&amp;#34; //chunk的最小大小(byte)，后续的增长都是该值*factor来进行增长的 &amp;#34;t:&amp;#34; //内部worker线程的个数，默认是4个，最大值推荐不超过64个 &amp;#34;D:&amp;#34; //内部数据存储时的分割符 &amp;#34;L&amp;#34; //指定内存页的大小，默认内存页大小为4K，页最大不超过2M，调大页的大小，可有效减小页表的大小,提高内存访问的效率 &amp;#34;R:&amp;#34; //单个worker的最大请求个数 &amp;#34;C&amp;#34; //禁用业务的cas,即compare and set &amp;#34;b:&amp;#34; //listen操作缓存连接个数 &amp;#34;B:&amp;#34; //memcached内部使用的协议，支持二进制协议和文本协议，早期只有文本协议，二进制协议是后续加上的 &amp;#34;I:&amp;#34; //单个item的最大值，默认是1M,可以修改，修改的最小值为1k,最大值不能超过128M &amp;#34;S&amp;#34; //打开sasl安全协议 &amp;#34;o:&amp;#34; /** *有四个参数项可以设置: *maxconns_fast(如果连接数超过最大连接数，立即关闭新的连接) *hashpower(hash表的大小的指数值，是按1&amp;lt;&amp;lt;hashpower来创建hash表的，默认的hashpower为16，配置值建议不超过64) *slab_reassign（是否调整/平衡各个slab所占的内存） *slab_automove（是否自动移动各个slab，如果该选项打开，会有专门的线程来进行slab的调整） */ Memcached内部是通过settings来抽象上面的这些初始化参数。
struct settings { size_t maxbytes; int maxconns; int port; int udpport; char* inter; int verbose; rel_time_t oldest_live; /* ignore existing items older than this */ int evict_to_free; char* socketpath; /* path to unix socket if using local socket */ int access; /* access mask (a la chmod) for unix domain socket */ double factor; /* chunk size growth factor */ int chunk_size; int num_threads; /* number of worker (without dispatcher) libevent threads to run */ int num_threads_per_udp; /* number of worker threads serving each udp socket */ char prefix_delimiter; /* character that marks a key prefix (for stats) */ int detail_enabled; /* nonzero if we&amp;#39;re collecting detailed stats */ int reqs_per_event; /* Maximum number of io to process on each io-event.</description>
    </item>
    
    <item>
      <title>Memcached源码阅读七 cas属性</title>
      <link>https://haokiu.com/blog/4d2fa7e9284a4e7fb742bdda30d20da6/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/4d2fa7e9284a4e7fb742bdda30d20da6/</guid>
      <description>Memcached源码阅读七 cas属性 cas即compare and set或者compare and swap,是实现乐观锁的一种技术，乐观锁是相对悲观锁来说的，所谓悲观锁是在数据处理过程中，完全锁定，这种能完全保证数据的一致性，但在多线程情况下，并发性能差，通常是使用各种锁技术实现；而乐观锁是通过版本号机制来实现数据一致性，过程中会使用CPU提供的原子操作指令，乐观锁能提高系统的并发性能，Memcached使用cas是保证数据的一致性，不是严格为了实现锁。
Memcached是多客户端应用，在多个客户端修改同一个数据时，会出现相互覆盖的情况，在这种情况下，使用cas版本号验证，可以有效的保证数据的一致性，Memcached默认是打开cas属性的，每次存储数据时，都会生成其cas值并和item一起存储，后续的get操作会返回系统生成的cas值，在执行set等操作时，需要将cas值传入，下面我们看看Memcached内部是如何实现cas的，关于如何使用Mecached的CAS协议，请参考文章：Memcached的CAS协议（链接：http://langyu.iteye.com/blog/680052）。
//为新的item生成cas值 uint64_t get_cas_id(void) { static uint64_t cas_id = 0; return ++cas_id; } //这段代码是store_item的代码片段，这里是执行cas存储时执行的判断逻辑， else if (ITEM_get_cas(it) == ITEM_get_cas(old_it))//cas值一致 { pthread_mutex_lock(&amp;amp;c-&amp;gt;thread-&amp;gt;stats.mutex); c-&amp;gt;thread-&amp;gt;stats.slab_stats[old_it-&amp;gt;slabs_clsid].cas_hits++; pthread_mutex_unlock(&amp;amp;c-&amp;gt;thread-&amp;gt;stats.mutex); item_replace(old_it, it, hv);//执行存储逻辑 stored = STORED; } //cas值不一致，不进行实际的存储 else { pthread_mutex_lock(&amp;amp;c-&amp;gt;thread-&amp;gt;stats.mutex); c-&amp;gt;thread-&amp;gt;stats.slab_stats[old_it-&amp;gt;slabs_clsid].cas_badval++; //更新统计信息 pthread_mutex_unlock(&amp;amp;c-&amp;gt;thread-&amp;gt;stats.mutex); if (settings.verbose &amp;gt; 1) { //打印错误日志 fprintf(stderr, &amp;#34;CAS: failure: expected %llu, got %llu\n&amp;#34;, (unsigned long long) ITEM_get_cas(old_it), (unsigned long long) ITEM_get_cas(it)); } stored = EXISTS; } </description>
    </item>
    
    <item>
      <title>Memcached源码阅读九 连接队列</title>
      <link>https://haokiu.com/blog/596315b99d2f40dba9c9ea13e975bd9d/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/596315b99d2f40dba9c9ea13e975bd9d/</guid>
      <description>Memcached源码阅读九 连接队列 Memcached中Master线程和Worker线程之间通信连接信息时，是通过连接队列来通信的，即Master线程投递一个消息到Worker线程的连接队列中，Worker线程从连接队列中读取链接信息来执行连接操作，下面我们简单分析下Memcached的连接队列结构。
typedef struct conn_queue_item CQ_ITEM;//每个连接信息的封装 struct conn_queue_item { int sfd;//accept之后的描述符 enum conn_states init_state;//连接的初始状态 int event_flags;//libevent标志 int read_buffer_size;//读取数据缓冲区大小 enum network_transport transport;//内部通信所用的协议 CQ_ITEM *next;//用于实现链表的指针 }; typedef struct conn_queue CQ;//连接队列的封装 struct conn_queue { CQ_ITEM *head;//头指针，注意这里是单链表，不是双向链表 CQ_ITEM *tail;//尾部指针， pthread_mutex_t lock;//锁 pthread_cond_t cond;//条件变量 }; //连接队列初始化 static void cq_init(CQ *cq) { pthread_mutex_init(&amp;amp;cq-&amp;gt;lock, NULL);//初始化锁 pthread_cond_init(&amp;amp;cq-&amp;gt;cond, NULL);//初始化条件变量 cq-&amp;gt;head = NULL; cq-&amp;gt;tail = NULL; } //获取一个连接 static CQ_ITEM *cq_pop(CQ *cq) { CQ_ITEM *item; pthread_mutex_lock(&amp;amp;cq-&amp;gt;lock);//执行加锁操作 item = cq-&amp;gt;head; //获得头部指针指向的数据 if (NULL != item) { //更新头指针信息 cq-&amp;gt;head = item-&amp;gt;next; //这里为空的话，则尾指针也为空，链表此时为空 if (NULL == cq-&amp;gt;head) cq-&amp;gt;tail = NULL; } //释放锁操作 pthread_mutex_unlock(&amp;amp;cq-&amp;gt;lock); return item; } //添加一个连接信息 static void cq_push(CQ *cq, CQ_ITEM *item) { item-&amp;gt;next = NULL; pthread_mutex_lock(&amp;amp;cq-&amp;gt;lock);//执行加锁操作 //如果链表目前是空的 if (NULL == cq-&amp;gt;tail) //则头指针指向该结点 cq-&amp;gt;head = item; else cq-&amp;gt;tail-&amp;gt;next = item;//添加到尾部 cq-&amp;gt;tail = item; //尾部指针后移 pthread_cond_signal(&amp;amp;cq-&amp;gt;cond); //唤醒条件变量，如果有阻塞在该条件变量的线程，则会唤醒该线程 pthread_mutex_unlock(&amp;amp;cq-&amp;gt;lock); } //创建连接队列 static CQ_ITEM *cqi_new(void) { CQ_ITEM *item = NULL; pthread_mutex_lock(&amp;amp;cqi_freelist_lock); //加锁，保持数据同步 if (cqi_freelist) { //更新空闲链表信息 item = cqi_freelist; cqi_freelist = item-&amp;gt;next; } pthread_mutex_unlock(&amp;amp;cqi_freelist_lock); //如果空闲链表没有多余的链接 if (NULL == item) { int i; //初始化64个空闲连接信息 item = malloc(sizeof(CQ_ITEM) * ITEMS_PER_ALLOC); if (NULL == item) return NULL; //将空闲的连接信息进行链接 for (i = 2; i &amp;lt; ITEMS_PER_ALLOC; i++) item[i - 1].</description>
    </item>
    
    <item>
      <title>Memcached源码阅读二 网络监听的建立</title>
      <link>https://haokiu.com/blog/9a03435a987949d28e30905f7a0c839b/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/9a03435a987949d28e30905f7a0c839b/</guid>
      <description>Memcached源码阅读二 网络监听的建立 Memcahced是一个服务器程序，所以需要建立网络监听来接受其他客户端机器的连接，下面分析下其过程，这次分析是基于Memcached 1.4.15版本分析的。
// 如果socketpath为空，则表示使用的TCP / UDP, 不是使用unix socket //如果socketpath为空，则表示使用的TCP/UDP,不是使用unix socket if (settings.socketpath == NULL) { //可以从环境变量读取端口文件所在的文件路径 const char *portnumber_filename = getenv(&amp;#34;MEMCACHED_PORT_FILENAME&amp;#34;); char temp_portnumber_filename[PATH_MAX]; FILE *portnumber_file = NULL; //如果端口文件不为空，则打开 if (portnumber_filename != NULL) { snprintf(temp_portnumber_filename, sizeof(temp_portnumber_filename), &amp;#34;%s.lck&amp;#34;, portnumber_filename); portnumber_file = fopen(temp_portnumber_filename, &amp;#34;a&amp;#34;); if (portnumber_file == NULL) { fprintf(stderr, &amp;#34;Failed to open \&amp;#34;%s\&amp;#34;: %s\n&amp;#34;, temp_portnumber_filename, strerror(errno)); } } //settings.port表示Memcached采用的是TCP协议，创建TCP Socket，监听并且绑定 errno = 0; if (settings.port &amp;amp;&amp;amp; server_sockets(settings.port, tcp_transport, portnumber_file)) { vperror(&amp;#34;failed to listen on TCP port %d&amp;#34;, settings.port); exit(EX_OSERR); } //settings.udpport表示Memcached采用的是UDP协议，创建UDP Socket，监听并且绑定 errno = 0; if (settings.udpport &amp;amp;&amp;amp; server_sockets(settings.udpport, udp_transport, portnumber_file)) { vperror(&amp;#34;failed to listen on UDP port %d&amp;#34;, settings.udpport); exit(EX_OSERR); } //端口文件不为空 if (portnumber_file) { fclose(portnumber_file);//关闭文件 rename(temp_portnumber_filename, portnumber_filename);//重命名端口文件 } } //TCP和UDP使用的是同一个接口来创建监听和绑定 static int server_sockets(int port, enum network_transport transport, FILE *portnumber_file) { //settings.</description>
    </item>
    
    <item>
      <title>Memcached源码阅读五 资源初始化</title>
      <link>https://haokiu.com/blog/f56b1e30eede4a21b7fd293a33a1e47a/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/f56b1e30eede4a21b7fd293a33a1e47a/</guid>
      <description>Memcached源码阅读五 资源初始化 Memcached内部有hash表，各种统计信息，工作线程，网络，连接，内存结构等，在memcached启动时(执行main函数)，会对这些资源进行初始化的，网络和内存的初始化操作放到后续分析，这次分析hash表，统计信息，工作线程，网络连接的初始化过程。
1 hash表的初始化
//hash表的初始化，传入的参数是启动时传入的 assoc_init(settings.hashpower_init); //hashsize的实现 #define hashsize(n) ((ub4)1&amp;lt;&amp;lt;(n)) //主hash表结构定义，在hash表扩容时，会有次hash表，所以有主次hash表区分，该结构是指针的指针，也即相当于数组指针 static item** primary_hashtable = 0; void assoc_init(const int hashtable_init) { if (hashtable_init) { //如果设置了初始化参数，则按设置的参数进行初始化 hashpower = hashtable_init; } //hashpower的默认值为16,如果未设置新值，则按默认值进行初始化 primary_hashtable = calloc(hashsize(hashpower), sizeof(void *)); if (! primary_hashtable) { fprintf(stderr, &amp;#34;Failed to init hashtable.\n&amp;#34;); exit(EXIT_FAILURE); } STATS_LOCK();//全局统计信息加锁，保证数据同步 stats.hash_power_level = hashpower; stats.hash_bytes = hashsize(hashpower) * sizeof(void *); STATS_UNLOCK(); } 2 统计信息的初始化
Memcached内部有很多全局的统计信息，用于实时获取各个资源的使用情况，后面将会看到，所有对统计信息的更新都需要加锁，而这些信息的更新是和Memcached的操作次数同数量级的，所以，在一定程度来说，这些统计信息对性能有影响。
stats结构是对统计信息的一个抽象，各个字段都比较好理解，不做解释。
struct stats { pthread_mutex_t mutex; unsigned int curr_items; unsigned int total_items; uint64_t curr_bytes; unsigned int curr_conns; unsigned int total_conns; uint64_t rejected_conns; unsigned int reserved_fds; unsigned int conn_structs; uint64_t get_cmds; uint64_t set_cmds; uint64_t touch_cmds; uint64_t get_hits; uint64_t get_misses; uint64_t touch_hits; uint64_t touch_misses; uint64_t evictions; uint64_t reclaimed; time_t started; /* when the process was started */ bool accepting_conns; /* whether we are currently accepting */ uint64_t listen_disabled_num; unsigned int hash_power_level; /* Better hope it&amp;#39;s not over 9000 */ uint64_t hash_bytes; /* size used for hash tables */ bool hash_is_expanding; /* If the hash table is being expanded */ uint64_t expired_unfetched; /* items reclaimed but never touched */ uint64_t evicted_unfetched; /* items evicted but never touched */ bool slab_reassign_running; /* slab reassign in progress */ uint64_t slabs_moved; /* times slabs were moved around */ }; 统计信息的初始化也就是对stats变量的一个初始化。</description>
    </item>
    
    <item>
      <title>Memcached源码阅读八 内存池</title>
      <link>https://haokiu.com/blog/63c41390d91c4392a0d3cc433c49a4ac/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/63c41390d91c4392a0d3cc433c49a4ac/</guid>
      <description>Memcached源码阅读八 内存池 Memcached内部维护了一个内存池来减少频繁的malloc和free，在该内存池的基础上面实现了slab内存管理，下面简单介绍下内存池的实现，大家在实现类似结构时，可以做个参考。
static void *mem_base = NULL;//mem_base指向新申请的内存空间，指向整个内存空间的头部 static void *mem_current = NULL;//指向已经分配过的空间，且指向已经分配了空间的尾部 static size_t mem_avail = 0;//剩余空间大小 //部分初始化操作 mem_limit = limit;//初始容量 mem_base = malloc(mem_limit);//申请内存空间 if (mem_base != NULL) //如果不为空 { mem_current = mem_base; //当前还没分配，所以其指向为整个空间 mem_avail = mem_limit; //可用空间为满 } else { fprintf(stderr, &amp;#34;Warning: Failed to allocate requested memory in&amp;#34; &amp;#34; one large chunk.\nWill allocate in smaller chunks\n&amp;#34;); } //分配空间的过程，分配size大小的空间 static void *memory_allocate(size_t size) { void *ret; //如果未初始化 if (mem_base == NULL) { ret = malloc(size); } else { ret = mem_current; if (size &amp;gt; mem_avail) { return NULL; } //执行对齐操作 if (size % CHUNK_ALIGN_BYTES) { size += CHUNK_ALIGN_BYTES - (size % CHUNK_ALIGN_BYTES); } mem_current = ((char*)mem_current) + size; if (size &amp;lt; mem_avail) { mem_avail -= size; } else { mem_avail = 0; } } return ret; } </description>
    </item>
    
    <item>
      <title>Memcached源码阅读六 get过程</title>
      <link>https://haokiu.com/blog/9dbcb2b8ef6b4cdbab38c3845d520ef0/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/9dbcb2b8ef6b4cdbab38c3845d520ef0/</guid>
      <description>Memcached源码阅读六 get过程 我们在前面分析过，Memcached从网络读取完数据，解析数据，如果是get操作，则执行get操作，下面我们分析下get操作的流程。
//根据key信息和key的长度信息读取数据 item *item_get(const char *key, const size_t nkey) { item *it; uint32_t hv; hv = hash(key, nkey, 0);//获得分段锁信息，如果未进行扩容，则item的hash表是多个hash桶共用同一个锁，即是分段的锁 item_lock(hv);//执行分段加锁 it = do_item_get(key, nkey, hv);//执行get操作 item_unlock(hv);//释放锁 return it; } //执行分段加锁 void item_lock(uint32_t hv) { uint8_t *lock_type = pthread_getspecific(item_lock_type_key); if (likely(*lock_type == ITEM_LOCK_GRANULAR)) { mutex_lock(&amp;amp;item_locks[(hv &amp;amp; hashmask(hashpower)) % item_lock_count]);//执行分段加锁 } else {//如果在扩容过程中 mutex_lock(&amp;amp;item_global_lock); } } //执行分段解锁 void item_unlock(uint32_t hv) { uint8_t *lock_type = pthread_getspecific(item_lock_type_key); if (likely(*lock_type == ITEM_LOCK_GRANULAR)) { mutex_unlock(&amp;amp;item_locks[(hv &amp;amp; hashmask(hashpower)) % item_lock_count]);//释放分段锁 } else {//如果在扩容过程中 mutex_unlock(&amp;amp;item_global_lock); } } //执行读取操作 item *do_item_get(const char *key, const size_t nkey, const uint32_t hv) { item *it = assoc_find(key, nkey, hv);//从Hash表中获取相应的结构 if (it !</description>
    </item>
    
    <item>
      <title>Memcached源码阅读十 Hash表操作</title>
      <link>https://haokiu.com/blog/857ca75e1a154abc91281759ea864d5c/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/857ca75e1a154abc91281759ea864d5c/</guid>
      <description>Memcached源码阅读十 Hash表操作 Memcached的Hash表用来提高数据访问性能，通过链接法来解决Hash冲突，当Hash表中数据多余Hash表容量的1.5倍时，Hash表就会扩容，Memcached的Hash表操作没什么特别的，我们这里简单介绍下Memcached里面的Hash表操作。
//hash表插入元素 int assoc_insert(item *it, const uint32_t hv) { unsigned int oldbucket; //如果已经开始扩容，且扩容的桶编号大于目前的item所在桶的编号 if (expanding &amp;amp;&amp;amp; (oldbucket = (hv &amp;amp; hashmask(hashpower - 1))) &amp;gt;= expand_bucket) { //这里是类似单链表的，按单链表的操作进行插入 it-&amp;gt;h_next = old_hashtable[oldbucket]; old_hashtable[oldbucket] = it; } else { //已经扩容，则按新的Hash规则进行路由 it-&amp;gt;h_next = primary_hashtable[hv &amp;amp; hashmask(hashpower)]; //这里在新的Hash表中执行单链表插入 primary_hashtable[hv &amp;amp; hashmask(hashpower)] = it; } hash_items++;//元素个数+1 if (! expanding &amp;amp;&amp;amp; hash_items &amp;gt; (hashsize(hashpower) * 3) / 2) { //开始扩容 assoc_start_expand();//唤醒扩容条件变量 } MEMCACHED_ASSOC_INSERT(ITEM_key(it), it-&amp;gt;nkey, hash_items); return 1; } //hash表删除元素 void assoc_delete(const char *key, const size_t nkey, const uint32_t hv) { item **before = _hashitem_before(key, nkey, hv); //获得item对应的桶的前一个元素 if (*before) { item *nxt; hash_items--;//元素个数-1 MEMCACHED_ASSOC_DELETE(key, nkey, hash_items); nxt = (*before)-&amp;gt;h_next;//执行单链表的删除操作 (*before)-&amp;gt;h_next = 0; *before = nxt; return; } assert(*before !</description>
    </item>
    
    <item>
      <title>Memcached源码阅读十一 LRU操作</title>
      <link>https://haokiu.com/blog/1e01253c10f9435e84a4106aa149ab68/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/1e01253c10f9435e84a4106aa149ab68/</guid>
      <description>Memcached源码阅读十一 LRU操作 LRU是最近最少使用的简称，该技术经常用来实现cache数据更新，Memcached使用LRU技术来淘汰老的数据，Memcached默认是启用LRU操作的，在这种情况下所有的set操作都会成功，如果Memcached的内存池已经使用完，则会淘汰老数据来存放新数据，如果关闭了Memcached的LRU，则当Memcached没有多余的内存空间时，Memcached之间返回错误，下面我们分析下LRU的相关操作。
里面再附一张Memcached的内存结构图，从图中可以看到LRU队列保持这已经分配出去的item的结构（图中指针为单链表，这里画的有误，其实是双向链表），同时每个slabclass由两个指针来维护该表，即heads和tails指针，分别指向最老的数据和最新的数据，这样便于LRU链表的操作。
//每个slabclass各有一个指针 static item *heads[LARGEST_ID]; static item *tails[LARGEST_ID]; //将item加入到对应classid的LRU链的head，这里是item加入到LRU链表中 static void item_link_q(item *it) { /* item is the new head */ item **head, **tail; assert(it-&amp;gt;slabs_clsid &amp;lt; LARGEST_ID); assert((it-&amp;gt;it_flags &amp;amp; ITEM_SLABBED) == 0); head = &amp;amp;heads[it-&amp;gt;slabs_clsid]; tail = &amp;amp;tails[it-&amp;gt;slabs_clsid]; assert(it != *head); assert((*head &amp;amp;&amp;amp; *tail) || (*head == 0 &amp;amp;&amp;amp; *tail == 0)); it-&amp;gt;prev = 0; it-&amp;gt;next = *head; if (it-&amp;gt;next) it-&amp;gt;next-&amp;gt;prev = it;//执行插入数据操作 *head = it; if (*tail == 0) *tail = it; sizes[it-&amp;gt;slabs_clsid]++; return; } //将item从对应classid的LRU链上移除，这里是item从LRU链表中删除 static void item_unlink_q(item *it) { item **head, **tail; assert(it-&amp;gt;slabs_clsid &amp;lt; LARGEST_ID); head = &amp;amp;heads[it-&amp;gt;slabs_clsid]; tail = &amp;amp;tails[it-&amp;gt;slabs_clsid]; if (*head == it) { assert(it-&amp;gt;prev == 0); *head = it-&amp;gt;next; } if (*tail == it) { assert(it-&amp;gt;next == 0); *tail = it-&amp;gt;prev; } assert(it-&amp;gt;next !</description>
    </item>
    
    <item>
      <title>Memcached源码阅读十七 状态机</title>
      <link>https://haokiu.com/blog/4547681a8a0d42759accab81b61267ab/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/4547681a8a0d42759accab81b61267ab/</guid>
      <description>Memcached源码阅读十七 状态机 按我们之前的描述，Master线程建立连接之后，分发给Worker线程，而Worker线程处理业务逻辑时，会进入状态机，状态机按不同的状态处理业务逻辑，我们在分析连接分发时，已经看到了Master线程进入状态机时在有新连接建立的时候，后续的状态都是业务逻辑的状态，其处理流程如下图所示：
共有10个状态（代码中的状态不止这些，有些没什么用，此处就没展现），状态listenning状态是Master建立连接的过程，我们已经分析过了，我们接下来分不同的文章分析其余的9中状态。
enum conn_states { conn_listening, //监听状态 conn_new_cmd, //为新连接做一些准备 conn_waiting, //等待读取一个数据包 conn_read, //读取网络数据 conn_parse_cmd, //解析缓冲区的数据 conn_write, //简单的回复数据 conn_nread, //读取固定数据的网络数据 conn_swallow, //处理不需要的写缓冲区的数据 conn_closing, //关闭连接 conn_mwrite, //顺序的写多个item数据 conn_max_state //最大状态，做断言使用 }; 这篇文件先分析conn_new_cmd和conn_wating状态，子线程最初进入的状态就是conn_new_cmd状态，这个状态主要是做一些清理。
case conn_new_cmd: //全局变量，记录每个libevent实例处理的事件，通过初始启动参数配置 --nreqs; //还可以处理请求 if (nreqs &amp;gt;= 0) { //整理缓冲区 reset_cmd_handler(c); } //拒绝请求 else { pthread_mutex_lock(&amp;amp;c-&amp;gt;thread-&amp;gt;stats.mutex); c-&amp;gt;thread-&amp;gt;stats.conn_yields++;//更新统计数据 pthread_mutex_unlock(&amp;amp;c-&amp;gt;thread-&amp;gt;stats.mutex); //如果缓冲区有数据，则需要处理 if (c-&amp;gt;rbytes &amp;gt; 0) { //更新libevent状态 if (!update_event(c, EV_WRITE | EV_PERSIST)) { if (settings.verbose &amp;gt; 0) fprintf(stderr, &amp;#34;Couldn&amp;#39;t update event\n&amp;#34;); conn_set_state(c, conn_closing);//关闭连接 } } stop = true; } break; //整理缓冲区 static void reset_cmd_handler(conn *c) { c-&amp;gt;cmd = -1; c-&amp;gt;substate = bin_no_state; //还有item if (c-&amp;gt;item != NULL) { //删除item，本篇不分析其实现，后续分析 item_remove(c-&amp;gt;item); c-&amp;gt;item = NULL; } //整理缓冲区 conn_shrink(c); //缓冲区还有数据 if (c-&amp;gt;rbytes &amp;gt; 0) { //更新状态 conn_set_state(c, conn_parse_cmd); } //如果没有数据 else { //进入等待状态，状态机没有数据要处理，就进入这个状态 conn_set_state(c, conn_waiting); } } //缩小缓冲区 static void conn_shrink(conn *c) { assert(c !</description>
    </item>
    
    <item>
      <title>Memcached源码阅读十三 do_item_alloc操作</title>
      <link>https://haokiu.com/blog/50d829bedab44857aaf08cfd61e6c952/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/50d829bedab44857aaf08cfd61e6c952/</guid>
      <description>Memcached源码阅读十三 do_item_alloc操作 前面我们分析了Memcached的set操作，其set操作在经过所有的数据有效性检查之后，如果需要存储item，则会执行item的实际存储操作，我们下面分析下其过程。
//执行item的存储操作,该操作会将item挂载到LRU表和slabcalss中 item *do_item_alloc(char *key, const size_t nkey, const int flags, const rel_time_t exptime, const int nbytes, const uint32_t cur_hv) { uint8_t nsuffix; item *it = NULL; char suffix[40]; //计算item的总大小(空间) size_t ntotal = item_make_header(nkey + 1, flags, nbytes, suffix, &amp;amp;nsuffix); //如果使用了cas if (settings.use_cas) { //增加cas的空间 ntotal += sizeof(uint64_t); } unsigned int id = slabs_clsid(ntotal); //那大小选择合适的slab if (id == 0) return 0; //执行LRU锁 mutex_lock(&amp;amp;cache_lock); //存储时，会尝试从LRU中选择合适的空间的空间 int tries = 5; //如果LRU中尝试5次还没合适的空间，则执行申请空间的操作 int tried_alloc = 0; item *search; void *hold_lock = NULL; //初始化时选择的过期时间 rel_time_t oldest_live = settings.oldest_live; search = tails[id];//第id个LRU表的尾部 for (; tries &amp;gt; 0 &amp;amp;&amp;amp; search != NULL; tries--, search=search-&amp;gt;prev) { uint32_t hv = hash(ITEM_key(search), search-&amp;gt;nkey, 0);//获取分段锁 //尝试执行锁操作，这里执行的乐观锁 if (hv !</description>
    </item>
    
    <item>
      <title>Memcached源码阅读十二 set操作</title>
      <link>https://haokiu.com/blog/a795d0b698914f3898a0896633cd92ad/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/a795d0b698914f3898a0896633cd92ad/</guid>
      <description>Memcached源码阅读十二 set操作 之前分析了Memcached的get操作，下面分析set操作的流程。
//存储item enum store_item_type store_item(item *item, int comm, conn* c) { enum store_item_type ret; uint32_t hv; hv = hash(ITEM_key(item), item-&amp;gt;nkey, 0);//获取Hash表的分段锁 item_lock(hv);//执行数据同步 ret = do_store_item(item, comm, c, hv);//存储item item_unlock(hv); return ret; } //存储item enum store_item_type do_store_item(item *it, int comm, conn *c,const uint32_t hv) { char *key = ITEM_key(it);//读取item对应的key item *old_it = do_item_get(key, it-&amp;gt;nkey, hv); //读取相应的item,如果没有相关的数据,old_it为NULL enum store_item_type stored = NOT_STORED;//item状态标记 item *new_it = NULL; int flags; //如果old_it不为NULL,且操作为add操作 if (old_it != NULL &amp;amp;&amp;amp; comm == NREAD_ADD) { do_item_update(old_it);//更新数据 } //old_it为空，且操作为REPLACE，则什么都不做 else if (!old_it &amp;amp;&amp;amp; (comm == NREAD_REPLACE || comm == NREAD_APPEND || comm == NREAD_PREPEND)) { //memcached的Replace操作是替换已有的数据，如果没有相关数据，则不做任何操作 } //以cas方式读取 else if (comm == NREAD_CAS) { if (old_it == NULL) //为空 { // LRU expired stored = NOT_FOUND;//修改状态 pthread_mutex_lock(&amp;amp;c-&amp;gt;thread-&amp;gt;stats.</description>
    </item>
    
    <item>
      <title>Memcached源码阅读十六 线程交互</title>
      <link>https://haokiu.com/blog/314f7e41e35f43db9facbca467726a7a/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/314f7e41e35f43db9facbca467726a7a/</guid>
      <description>Memcached源码阅读十六 线程交互 Memcached按之前的分析可以知道，其是典型的Master-Worker线程模型，这种模型很典型，其工作模型是Master绑定端口，监听网络连接，接受网络连接之后，通过线程间通信来唤醒Worker线程，Worker线程已经连接的描述符执行读写操作，这种模型简化了整个通信模型，下面分析下这个过程。
case conn_listening: addrlen = sizeof(addr); //Master线程(main)进入状态机之后执行accept操作，这个操作也是非阻塞的。 if ((sfd = accept(c-&amp;gt;sfd, (struct sockaddr *) &amp;amp;addr, &amp;amp;addrlen)) == -1) { //非阻塞模型，这个错误码继续等待 if (errno == EAGAIN || errno == EWOULDBLOCK) { stop = true; } //连接超载 else if (errno == EMFILE) { if (settings.verbose &amp;gt; 0) fprintf(stderr, &amp;#34;Too many open connections\n&amp;#34;); accept_new_conns(false); stop = true; } else { perror(&amp;#34;accept()&amp;#34;); stop = true; } break; } //已经accept成功，将accept之后的描述符设置为非阻塞的 if ((flags = fcntl(sfd, F_GETFL, 0)) &amp;lt; 0 || fcntl(sfd, F_SETFL, flags | O_NONBLOCK) &amp;lt; 0) { perror(&amp;#34;setting O_NONBLOCK&amp;#34;); close(sfd); break; } //判断是否超过最大连接数 if (settings.maxconns_fast &amp;amp;&amp;amp; stats.curr_conns + stats.reserved_fd &amp;gt;= settings.maxconns - 1) { str = &amp;#34;ERROR Too many open connections\r\n&amp;#34;; res = write(sfd, str, strlen(str)); close(sfd); STATS_LOCK(); stats.</description>
    </item>
    
    <item>
      <title>Memcached源码阅读十四 item结构</title>
      <link>https://haokiu.com/blog/3fee4e4314af42ee9fa58cda4aa0b839/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/3fee4e4314af42ee9fa58cda4aa0b839/</guid>
      <description>Memcached源码阅读十四 item结构 item是Memcached中抽象实际数据的结构，我们分析下item的一些特性，便于后续Memcached的其他特性分析。
typedef struct _stritem { struct _stritem *next;//item在slab中存储时，是以双链表的形式存储的,next即后向指针 struct _stritem *prev;//prev为前向指针 struct _stritem *h_next;//Hash桶中元素的链接指针 rel_time_t time;//最近访问时间 rel_time_t exptime;//过期时间 int nbytes;//数据大小 unsigned short refcount;//引用次数 uint8_t nsuffix;//不清楚什么意思? uint8_t it_flags;//不清楚什么意思? uint8_t slabs_clsid;//标记item属于哪个slabclass下 uint8_t nkey;//key的长度 union { uint64_t cas; char end; } data[];//真实的数据信息 } item; 其结构图如下所示：
Item由两部分组成，item的属性信息和item的数据部分，属性信息解释如上，数据部分包括cas，key和真实的value信息，item在内存中的存储形式如下：
这个图画出了部分结构，还有Hash表的结构没有画出。
这里大概介绍了item的一些信息，后面我们会分析item插入Hash表等信息。</description>
    </item>
    
    <item>
      <title>Memcached源码阅读四 内存初始化</title>
      <link>https://haokiu.com/blog/c82fe349df914fb8943e4aa3231c9cad/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/c82fe349df914fb8943e4aa3231c9cad/</guid>
      <description>Memcached源码阅读四 内存初始化 Memcached作为内存cache服务器，内存高效管理是其最重要的任务之一，Memcached使用SLAB管理其内存，SLAB内存管理直观的解释就是分配一块大的内存，之后按不同的块（48byte, 64byte, … 1M）等切分这些内存，存储业务数据时，按需选择合适的内存空间存储数据。
Memcached首次默认分配64M的内存，之后所有的数据都是在这64M空间进行存储，在Memcached启动之后，不会对这些内存执行释放操作，这些内存只有到Memcached进程退出之后会被系统回收，下面分析下Memcached的内存初始化过程。
//内存初始化，settings.maxbytes是Memcached初始启动参数指定的内存值大小,settings.factor是内存增长因子 slabs_init(settings.maxbytes, settings.factor, preallocate); #define POWER_SMALLEST 1 //最小slab编号 #define POWER_LARGEST 200 //首次初始化200个slab //实现内存池管理相关的静态全局变量 static size_t mem_limit = 0;//总的内存大小 static size_t mem_malloced = 0;//初始化内存的大小，这个貌似没什么用 static void *mem_base = NULL;//指向总的内存的首地址 static void *mem_current = NULL;//当前分配到的内存地址 static size_t mem_avail = 0;//当前可用的内存大小 static slabclass_t slabclass[MAX_NUMBER_OF_SLAB_CLASSES];//定义slab结合，总共200个 void slabs_init(const size_t limit, const double factor, const bool prealloc) { int i = POWER_SMALLEST - 1; //size表示申请空间的大小，其值由配置的chunk_size和单个item的大小来指定 unsigned int size = sizeof(item) + settings.chunk_size; mem_limit = limit;//mem_limit是全局变量 if (prealloc) { //支持预分配 mem_base = malloc(mem_limit);//申请地址，mem_base指向申请的地址 if (mem_base != NULL) { //mem_current指向当前地址 mem_current = mem_base; //可用内存大小为mem_limit mem_avail = mem_limit; } else { //支持预分配失败 fprintf(stderr, &amp;#34;Warning: Failed to allocate requested memory in&amp;#34; &amp;#34; one large chunk.</description>
    </item>
    
    <item>
      <title>Memcached源码阅读序 服务器资源调整</title>
      <link>https://haokiu.com/blog/8f65d01cc42d4c8782d95eed02dd4eb5/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/8f65d01cc42d4c8782d95eed02dd4eb5/</guid>
      <description>Memcached源码阅读序 服务器资源调整 本篇作为Memcached源码分析的开篇，这次阅读的源码版本为: 1.4.15，开源软件各个版本之间差异比较大，同学们学习时，记得核对版本。
memcached的main函数位于memcached.c文件中，从main函数启动之后，会初始化一些资源和申请一些服务器资源，如下面所示：
1 Core文件大小和进程打开文件个数限制的调整。
if (maxcore != 0) { struct rlimit rlim_new; //获取当前Core文件大小的配置值 if (getrlimit(RLIMIT_CORE, &amp;amp;rlim) == 0) { //变量初始化为无限制 rlim_new.rlim_cur = rlim_new.rlim_max = RLIM_INFINITY; if (setrlimit(RLIMIT_CORE, &amp;amp;rlim_new) != 0)//如果设置失败 { //变量初始化为当前值的最大值 rlim_new.rlim_cur = rlim_new.rlim_max = rlim.rlim_max; (void) setrlimit(RLIMIT_CORE, &amp;amp;rlim_new);//重新进行设置 } } //再次确认Core文件允许的大小，如果当前的Core文件的大小为0，则不允许Core文件产生，和maxcore!=0不符，程序结束 if ((getrlimit(RLIMIT_CORE, &amp;amp;rlim) != 0) || rlim.rlim_cur == 0) { fprintf(stderr, &amp;#34;failed to ensure corefile creation\n&amp;#34;); exit(EX_OSERR); } } //读取进程允许打开的文件数信息，读取失败，程序退出 if (getrlimit(RLIMIT_NOFILE, &amp;amp;rlim) != 0) { fprintf(stderr, &amp;#34;failed to getrlimit number of files\n&amp;#34;); exit(EX_OSERR); } else { //按memcached启动时的指定的最大连接数进行设置 rlim.rlim_cur = settings.maxconns; rlim.rlim_max = settings.maxconns; if (setrlimit(RLIMIT_NOFILE, &amp;amp;rlim) != 0) { fprintf(stderr, &amp;#34;failed to set rlimit for open files.</description>
    </item>
    
    <item>
      <title>Memcached阅读十五 Hash表扩容</title>
      <link>https://haokiu.com/blog/3ba1e9453dcc49edb8ee1597bb133cdd/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/3ba1e9453dcc49edb8ee1597bb133cdd/</guid>
      <description>Memcached阅读十五 Hash表扩容 Hash表是Memcached里面最重要的结构之一，其采用链接法来处理Hash冲突，当Hash表中的项太多时，也就是Hash冲突比较高的时候，Hash表的遍历就脱变成单链表，此时为了提供Hash的性能，Hash表需要扩容，Memcached的扩容条件是当表中元素个数超过Hash容量的1.5倍时就进行扩容，扩容过程由独立的线程来完成，扩容过程中会采用2个Hash表，将老表中的数据通过Hash算法映射到新表中，每次移动的桶的数目可以配置，默认是每次移动老表中的1个桶。
//hash表中增加元素 int assoc_insert(item *it, const uint32_t hv) { unsigned int oldbucket; //如果已经进行扩容且目前进行扩容还没到需要插入元素的桶，则将元素添加到旧桶中 if (expanding &amp;amp;&amp;amp;(oldbucket = (hv &amp;amp; hashmask(hashpower - 1))) &amp;gt;= expand_bucket) { //添加元素 it-&amp;gt;h_next = old_hashtable[oldbucket]; old_hashtable[oldbucket] = it; } else { //如果没扩容，或者扩容已经到了新的桶中，则添加元素到新表中 it-&amp;gt;h_next = primary_hashtable[hv &amp;amp; hashmask(hashpower)];//添加元素 primary_hashtable[hv &amp;amp; hashmask(hashpower)] = it; } hash_items++;//元素数目+1 //还没开始扩容，且表中元素个数已经超过Hash表容量的1.5倍 if (! expanding &amp;amp;&amp;amp; hash_items &amp;gt; (hashsize(hashpower) * 3) / 2) { //唤醒扩容线程 assoc_start_expand(); } MEMCACHED_ASSOC_INSERT(ITEM_key(it), it-&amp;gt;nkey, hash_items); return 1; } //唤醒扩容线程 static void assoc_start_expand(void) { if (started_expanding) return; started_expanding = true; //唤醒信号量 pthread_cond_signal(&amp;amp;maintenance_cond); } //启动扩容线程，扩容线程在main函数中会启动，启动运行一遍之后会阻塞在条件变量maintenance_cond上面，插入元素超过规定，唤醒条件变量 static void *assoc_maintenance_thread(void *arg) { //do_run_maintenance_thread的值为1，即该线程持续运行 while (do_run_maintenance_thread) { int ii = 0; item_lock_global();//加Hash表的全局锁 mutex_lock(&amp;amp;cache_lock);//加cache_lock锁 //执行扩容时，每次按hash_bulk_move个桶来扩容 for (ii = 0; ii &amp;lt; hash_bulk_move &amp;amp;&amp;amp; expanding; ++ii) { item *it, *next; int bucket; //老表每次移动一个桶中的一个元素 for (it = old_hashtable[expand_bucket]; NULL !</description>
    </item>
    
    <item>
      <title>Part I</title>
      <link>https://haokiu.com/blog/184a1ba071384d75b2da68fa7be54511/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/184a1ba071384d75b2da68fa7be54511/</guid>
      <description>此仓库是公众号【高性能服务器开发】文章汇总，如需下载全部文章，可以在公众号回复关键字“文章下载”即可得到下载链接。分享和转发文章时请保留作者信息，部分文章来源于网络，侵权请联系删除。
我也专门建立了读者交流群，想加群的读者可以加我微信easy_coder
在线阅读站点1：https://balloonwj.github.io/cpp-guide-web/
在线阅读站点2: http://balloonwj.gitee.io/cpp-guide-web/
备份站点：http://101.37.25.166/blog/
如需下载该站点源码用于自己搭建站点，可以在【高性能服务器开发】微信公众号后台回复关键字“站点下载”即可得到下载链接。
Part I C++必知必会的知识点
如何成为一名合格的C/C++开发者？ 不定参数函数实现var_arg系列的宏 你一定要搞明白的C函数调用方式与栈原理 深入理解C/C++中的指针 详解C++11中的智能指针 C++17结构化绑定 C++必须掌握的pimpl惯用法 用Visual Studio调试Linux程序 如何使用Visual Studio管理和阅读开源项目代码 利用cmake工具生成Visual Studio工程文件 多线程
后台C++开发你一定要知道的条件变量 整型变量赋值是原子操作吗？ 网络编程
bind 函数重难点解析 connect 函数在阻塞和非阻塞模式下的行为 select 函数重难点解析 Linux epoll 模型（含LT 模式和 ET 模式详解） socket 的阻塞模式和非阻塞模式 非阻塞模式下 send 和 recv 函数的返回值 服务器开发通信协议设计介绍 TCP 协议如何解决粘包、半包问题 网络通信中收发数据的正确姿势 服务器端发数据时，如果对端一直不收，怎么办？ 程序员必知必会的网络命令
利用telnet命令发电子邮件 做Java或者C++开发都应该知道的lsof命令 Linux网络故障排查的瑞士军刀nc命令 Linux tcpdump使用详解 从抓包的角度分析connect函数的连接过程 服务器开发中网络数据分析与故障排查经验漫谈 Part II 高性能服务器框架设计
主线程与工作线程的分工 Reactor模式 实例：一个服务器程序的架构介绍 错误码系统的设计 日志系统的设计 如何设计断线自动重连机制 心跳包机制设计详解 业务数据处理一定要单独开线程吗 C++ 高性能服务器网络框架设计细节 服务器开发案例实战
从零实现一个http服务器 从零实现一款12306刷票软件 从零实现一个邮件收发客户端 从零开发一个WebSocket服务器 从零学习开源项目系列（一）从一款多人联机实时对战游戏开始 从零学习开源项目系列（二）最后一战概况 从零学习开源项目系列（三） CSBattleMgr服务源码研究 从零学习开源项目系列（四）LogServer源码探究 Part III TeamTalk IM源码分析
01 TeamTalk介绍 02 服务器端的程序的编译与部署 03 服务器端的程序架构介绍 04 服务器端db_proxy_server源码分析 05 服务器端msg_server源码分析 06 服务器端login_server源码分析 07 服务器端msfs源码分析 08 服务器端file_server源码分析 09 服务器端route_server源码分析 10 开放一个TeamTalk测试服务器地址和几个测试账号 11 pc客户端源码分析 libevent源码深度剖析</description>
    </item>
    
    <item>
      <title>pimpl 惯用法</title>
      <link>https://haokiu.com/blog/4a2f5d00bb404b68a468bd72dfe357f8/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/4a2f5d00bb404b68a468bd72dfe357f8/</guid>
      <description>pimpl 惯用法 现在这里有一个名为 CSocketClient 的网络通信类，定义如下：
/** * 网络通信的基础类, SocketClient.h * zhangyl 2017.07.11 */ class CSocketClient { public: CSocketClient(); ~CSocketClient(); public: void SetProxyWnd(HWND hProxyWnd); bool Init(CNetProxy* pNetProxy); bool Uninit(); int Register(const char* pszUser, const char* pszPassword); void GuestLogin(); BOOL IsClosed(); BOOL	Connect(int timeout = 3); void AddData(int cmd, const std::string&amp;amp; strBuffer); void AddData(int cmd, const char* pszBuff, int nBuffLen); void Close(); BOOL ConnectServer(int timeout = 3); BOOL SendLoginMsg(); BOOL RecvLoginMsg(int&amp;amp; nRet); BOOL Login(int&amp;amp; nRet); private: void LoadConfig(); static UINT CALLBACK SendDataThreadProc(LPVOID lpParam); static UINT CALLBACK RecvDataThreadProc(LPVOID lpParam); bool Send(); bool Recv(); bool CheckReceivedData(); void SendHeartbeatPackage(); private: SOCKET m_hSocket; short m_nPort; char m_szServer[64]; long m_nLastDataTime; //最近一次收发数据的时间 long m_nHeartbeatInterval; //心跳包时间间隔，单位秒 CRITICAL_SECTION m_csLastDataTime; //保护m_nLastDataTime的互斥体 HANDLE m_hSendDataThread; //发送数据线程 HANDLE m_hRecvDataThread; //接收数据线程 std::string m_strSendBuf; std::string m_strRecvBuf; HANDLE m_hExitEvent; bool m_bConnected; CRITICAL_SECTION m_csSendBuf; HANDLE m_hSemaphoreSendBuf; HWND m_hProxyWnd; CNetProxy* m_pNetProxy; int m_nReconnectTimeInterval; //重连时间间隔 time_t m_nLastReconnectTime; //上次重连时刻 CFlowStatistics* m_pFlowStatistics; }; 这段代码来源于笔者实际项目中开发的一个股票客户端的软件。</description>
    </item>
    
    <item>
      <title>select 函数重难点解析</title>
      <link>https://haokiu.com/blog/2369cd70c2354e9c844815c14f31134c/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/2369cd70c2354e9c844815c14f31134c/</guid>
      <description>select 函数重难点解析 select 函数是网络通信编程中非常常用的一个函数，因此应该熟练掌握它。虽然它是 BSD 标准之一的 Socket 函数之一，但在 Linux 和 Windows 平台，其行为表现还是有点区别的。我们先来看一下 Linux 平台上的 select 函数。
Linux 平台下的 select 函数 select 函数的作用是检测一组 socket 中某个或某几个是否有“事件”，这里的“**事件”**一般分为如下三类：
可读事件，一般意味着可以调用 recv 或 read 函数从该 socket 上读取数据；如果该 socket 是侦听 socket（即调用了 bind 函数绑定过 ip 地址和端口号，并调用了 listen 启动侦听的 socket），可读意味着此时可以有新的客户端连接到来，此时可调用 accept 函数接受新连接。 可写事件，一般意味着此时调用 send 或 write 函数可以将数据“发出去”。 异常事件，某个 socket 出现异常。 函数签名如下：
int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); 参数说明：
参数 nfds， Linux 下 socket 也称 fd，这个参数的值设置成所有需要使用 select 函数监听的 fd 中最大 fd 值加 1。
参数 readfds，需要监听可读事件的 fd 集合。
参数 writefds，需要监听可写事件的 fd 集合。
参数 exceptfds，需要监听异常事件 fd 集合。
readfds、writefds 和 exceptfds 类型都是 fd_set，这是一个结构体信息，其定义位于 /usr/include/sys/select.h 中：
/* The fd_set member is required to be an array of longs.</description>
    </item>
    
    <item>
      <title>socket 的阻塞模式和非阻塞模式</title>
      <link>https://haokiu.com/blog/7a9421787c4a4e7482e4f3ea6234c7ac/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/7a9421787c4a4e7482e4f3ea6234c7ac/</guid>
      <description>socket 的阻塞模式和非阻塞模式 对 socket 在阻塞和非阻塞模式下的各个函数的行为差别深入的理解是掌握网络编程的基本要求之一，是重点也是难点。
阻塞和非阻塞模式下，我们常讨论的具有不同行为表现的 socket 函数一般有如下几个，见下表：
connect accept send (Linux 平台上对 socket 进行操作时也包括 write 函数，下文中对 send 函数的讨论也适用于 write 函数) recv (Linux 平台上对 socket 进行操作时也包括 read 函数，下文中对 recv 函数的讨论也适用于 read 函数) 限于文章篇幅，本文只讨论 send 和recv函数，connect 和 accept 函数我们将在该系列的后面文章中讨论。在正式讨论之前，我们先解释一下阻塞模式和非阻塞模式的概念。所谓阻塞模式，就当某个函数“执行成功的条件”当前不能满足时，该函数会阻塞当前执行线程，程序执行流在超时时间到达或“执行成功的条件”满足后恢复继续执行。而非阻塞模式恰恰相反，即使某个函数的“执行成功的条件”不当前不能满足，该函数也不会阻塞当前执行线程，而是立即返回，继续运行执行程序流。如果读者不太明白这两个定义也没关系，后面我们会以具体的示例来讲解这两种模式的区别。
如何将 socket 设置成非阻塞模式 无论是 Windows 还是 Linux 平台，默认创建的 socket 都是阻塞模式的。
在 Linux 平台上，我们可以使用 fcntl() 函数或 ioctl() 函数给创建的 socket 增加 O_NONBLOCK 标志来将 socket 设置成非阻塞模式。示例代码如下：
int oldSocketFlag = fcntl(sockfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; fcntl(sockfd, F_SETFL, newSocketFlag); ioctl() 函数 与 fcntl() 函数使用方式基本一致，这里就不再给出示例代码了。
当然，Linux 下的 socket() 创建函数也可以直接在创建时将 socket 设置为非阻塞模式，socket() 函数的签名如下：
int socket(int domain, int type, int protocol); 给 type 参数增加一个 SOCK_NONBLOCK 标志即可，例如：</description>
    </item>
    
    <item>
      <title>TCP 协议如何解决粘包、半包问题</title>
      <link>https://haokiu.com/blog/7b86f55ffdcd4434a17beb9dbf7b9527/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/7b86f55ffdcd4434a17beb9dbf7b9527/</guid>
      <description>TCP 协议如何解决粘包、半包问题 一 TCP 协议是流式协议 很多读者从接触网络知识以来，应该听说过这句话：TCP 协议是流式协议。那么这句话到底是什么意思呢？所谓流式协议，即协议的内容是像流水一样的字节流，内容与内容之间没有明确的分界标志，需要我们人为地去给这些协议划分边界。
举个例子，A 与 B 进行 TCP 通信，A 先后给 B 发送了一个 100 字节和 200 字节的数据包，那么 B 是如何收到呢？B 可能先收到 100 字节，再收到 200 字节；也可能先收到 50 字节，再收到 250 字节；或者先收到 100 字节，再收到 100 字节，再收到 200 字节；或者先收到 20 字节，再收到 20 字节，再收到 60 字节，再收到 100 字节，再收到 50 字节，再收到 50 字节……
不知道读者看出规律没有？规律就是 A 一共给 B 发送了 300 字节，B 可能以一次或者多次任意形式的总数为 300 字节收到。假设 A 给 B 发送的 100 字节和 200 字节分别都是一个数据包，对于发送端 A 来说，这个是可以区分的，但是对于 B 来说，如果不人为规定多长为一个数据包，B 每次是不知道应该把收到的数据中多少字节作为一个有效的数据包的。而规定每次把多少数据当成一个包就是协议格式规范的内容之一。
经常会有新手写出类似下面这样的代码：
发送端：
//...省略创建socket，建立连接等部分不相关的逻辑... char buf[] = &amp;#34;the quick brown fox jumps over a lazy dog.&amp;#34;; int n = send(socket, buf, strlen(buf), 0); //...省略出错处理逻辑... 接收端：
//省略创建socket，建立连接等部分不相关的逻辑... char recvBuf[50] = { 0 }; int n = recv(socket, recvBuf, 50, 0); //省略出错处理逻辑.</description>
    </item>
    
    <item>
      <title>TeamTalk源码解析</title>
      <link>https://haokiu.com/blog/0da28a69a69242919c3333dc8e970a8f/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/0da28a69a69242919c3333dc8e970a8f/</guid>
      <description>TeamTalk源码解析 01 TeamTalk介绍
02 服务器端的程序的编译与部署
03 服务器端的程序架构介绍
04 服务器端db_proxy_server源码分析
05 服务器端msg_server源码分析
06 服务器端login_server源码分析
07 服务器端msfs源码分析
08 服务器端file_server源码分析
09 服务器端route_server源码分析
10 开放一个TeamTalk测试服务器地址和几个测试账号
11 pc客户端源码分析</description>
    </item>
    
    <item>
      <title>不定参数函数实现var_arg系列的宏</title>
      <link>https://haokiu.com/blog/e3f33300987a43d08044b27dbbc5e9ec/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/e3f33300987a43d08044b27dbbc5e9ec/</guid>
      <description>不定参数函数实现var_arg系列的宏 电驴的源码日志模块有一个叫 DebugLogError 函数，其签名如下：
//代码位于easyMule-master/src/WorkLayer/Log.h 55行 void DebugLogError(LPCTSTR pszLine, ...); 电驴的源码可以在公众号【 高性能服务器开发 】后台回复“获取电驴源码”即可获取。
这个函数的申明在 Log.h 头文件中，是一个全局函数，其实现代码在 Log.cpp 文件中：
//代码位于easyMule-master/src/WorkLayer/Log.cpp 111行 void DebugLogError(LPCTSTR pszFmt, ...) { va_list argp; va_start(argp, pszFmt); LogV(LOG_DEBUG | LOG_ERROR, pszFmt, argp); va_end(argp); } 这个函数是一个具有不定参数的函数（也就是参数个数不确定），比如调用这个函数我们可以传入一个参数，也可以传入二个或者三个参数等等：
DebugLogError(L&amp;#34;我喜欢你!&amp;#34;); DebugLogError(L&amp;#34;我喜欢你!&amp;#34;, L&amp;#34;你喜欢谁？&amp;#34;); DebugLogError(L&amp;#34;我喜欢你!&amp;#34;, L&amp;#34;你喜欢谁？&amp;#34;, L&amp;#34;萧雨萌!&amp;#34;); 与此类似， C 语言中最熟悉的函数 printf() 和 scanf() 就是能传入不定参数的函数的例子，可是你知道如何编写这样具有不定参数的函数么？
你可以通过这段代码学习到编写方法，奥秘就在DebugLogError()中使用的几个你从来没见过的宏，让我们欢迎它们：
va_list va_start va_end 这几个宏是C函数库提供的，位于头文件stdarg.h中。下面我们利用这几个宏自定义一个ShowLove()函数：
#include &amp;lt;stdio.h&amp;gt; #include &amp;lt;tchar.h&amp;gt; #include &amp;lt;stdarg.h&amp;gt; #include &amp;lt;locale.h&amp;gt; int ShowLove(wchar_t* szFirstSentence, ...) { //用来统计可变参数数量 int num = 0; //第一步： //申明一个va_list类型对象ap，用于对参数进行遍历 va_list ap; //第二步： //使用va_start对变量进行初始化 //这里需要注意的是: //在传统C语言中，va_start把ap中内部指针设置为传递给函数参数的【第一个实参】； //而在标准的C中，va_start接受一个额外参数，也就是最后一个【固定参数】的名称， //并把ap中的内部指针设置为传递给函数的第一个【可变参数】. //所以你在VC++ 6.0和VS2008等高版本的编译器中使用va_start需要注意区别 //这里使用标准C va_start(ap, szFirstSentence); //第三步： //使用va_arg宏返回实参列表中的下一个参数值，并把ap的内部指针推向下一个参数（如果有的话） //必须指定下一个参数的类型。 //在调用va_start之后第一次调用va_arg将返回第一个可变参数的值 wprintf(szFirstSentence); wchar_t* p = 0; while(p = va_arg(ap, wchar_t*)) { wprintf(L&amp;#34;%s&amp;#34;, p); num ++; } //第四步： //待所有可变参数都读取完毕以后，调用va_end宏对ap和va_list做必要的清理工作 va_end(ap); return num; } int main(int argc, char* argv[]) { setlocale(LC_ALL, &amp;#34;&amp;#34;); int z = ShowLoveL&amp;#34;我喜欢你！\n&amp;#34;); int y = ShowLove(L&amp;#34;我喜欢你！&amp;#34;, L&amp;#34;你喜欢谁？\n&amp;#34;); int l = ShowLove(L&amp;#34;我喜欢你！&amp;#34;, L&amp;#34;你喜欢谁？&amp;#34;, L&amp;#34;萧雨萌！\n&amp;#34;); printf(&amp;#34;可变参数个数依次是：%d\t%d\t%d\n&amp;#34;, z, y, l); return 0; } 上述代码的运行结果是：</description>
    </item>
    
    <item>
      <title>为什么你的简历没人看</title>
      <link>https://haokiu.com/blog/15d5370937664a8d84891f5e983b87f4/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/15d5370937664a8d84891f5e983b87f4/</guid>
      <description>为什么你的简历没人看 程序员如何写简历 </description>
    </item>
    
    <item>
      <title>从抓包的角度分析connect()函数的连接过程</title>
      <link>https://haokiu.com/blog/f3b5fbeb80e645c9b5bd3d1feea7b387/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/f3b5fbeb80e645c9b5bd3d1feea7b387/</guid>
      <description>从抓包的角度分析connect()函数的连接过程 这篇文章主要是从tcp连接建立的角度来分析客户端程序如何利用connect函数和服务端程序建立tcp连接的，了解connect函数在建立连接的过程中底层协议栈做了哪些事情。
tcp三次握手 在正式介绍connect函数时，我们先来看一下tcp三次握手的过程，下面这个实验是客户端通过telnet远程登录服务端的例子，telnet协议是基于tcp协议，我们可以通过wireshark抓包工具看到客户端和服务端之间三次握手的过程，12.1.1.1是客户端的ip地址，12.1.1.2是服务端的ip地址。
下面是我们通过wireshark抓取到的tcp三次握手的数据包：
我们看到客户端远程登录服务端时，首先发送了一个SYN报文，其中目标端口为23（远程登录telnet协议使用23端口），初始序号seq = 0，并设置自己的窗口rwnd = 4128（rwnd是一个对端通告的接收窗口，用于流量控制）。
然后服务端回复了一个SYN + ACK报文，初始序号seq = 0，ack = 1（在前一个包的seq基础上加1），同时也设置自己的窗口rwnd = 4128。
然后客户端收到服务端的SYN + ACK报文时，回复了一个ACK报文，表示确认建立tcp连接，序号为seq = 1， ack = 1*（在前一个包的seq基础上加1）*， 设置窗口rwnd = 4128，此时客户端和服务端之间已经建立tcp连接。
connect函数 前面我们在介绍tcp三次握手的时候说过，客户端在跟服务端建立tcp连接时，通常是由客户端主动向目标服务端发起tcp连接建立请求，服务端被动接受tcp连接请求；同时服务端也会发起tcp连接建立请求，表示服务端希望和客户端建立连接，然后客户端会接受连接并发送一个确认，这样双方就已经建立好连接，可以开始通信。
这里说明一下：可能有的小伙伴会感到疑惑，为啥服务端也要跟客户端建立连接呢？其实这跟tcp采用全双工通信的方式有关。对于全双工通信，简单来说就是两端可以同时收发数据，如下图所示：
我们再回到正题，那么在网络编程中，肯定也有对应的函数做到跟上面一样的事情，没错，就是connect（连接）。顾名思义，connect函数就是用于客户端程序和服务端程序建立tcp连接的。
一般来说，客户端使用connect函数跟服务端建立连接，肯定要指定一个ip地址和端口号（相当于客户端的身份标识），要不然服务端都不知道你是谁？凭什么跟你建立连接。同时还得指明服务端的ip地址和端口号，也就是说，你要跟谁建立连接。
connect函数原型：
int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数说明： sockfd：客户端的套接字文件描述符 addr：要连接的套接字地址，这是一个传入参数，指定了要连接的套接字地址信息（例如IP地址和端口号） addrlen：是一个传入参数，参数addr的大小，即sizeof(addr)
返回值说明：连接建立成功返回0，失败返回-1并设置errno
connect函数在建立tcp连接的过程中用到了一个非常重要的队列，那就是未决连接队列，这个队列用来管理tcp的连接，包括已完成三次握手的tcp连接和未完成三次握手的tcp连接，下面我们就来详细介绍一下未决连接队列。
未决连接队列 未决连接队列是指服务器接收到客户端的连接请求，但是尚未被处理（也就是未被accept，后面会说）的连接，可以理解为未决连接队列是一个容器，这个容器存储着这些尚未被处理的链接。
当一个客户端进程使用 connect 函数发起请求后，服务器进程就会收到连接请求，然后检查未决连接队列是否有空位，如果未决队列满了，就会拒绝连接，那么客户端调用的connect 函数返回失败。
如果未决连接队列有空位，就将该连接加入未决连接队列。当 connect 函数成功返回后，表明tcp的“三次握手”连接已完成，此时accept函数获取到一个客户端连接并返回。
在上图中，在未决连接队列中又分为2个队列：
未完成队列（未决队列）：即客户端已经发出SYN报文并到达服务器，但是在tcp三次握手连接完成之前，这些套接字处于SYN_RCVD状态，服务器会将这些套接字加入到未完成队列。
已完成队列：即刚刚完成tcp三次握手的tcp连接，这些套接字处于ESTABLISHED状态，服务器会将这些套接字加入到已完成队列。
我们来看一下连接建立的具体过程，如图所示：
服务端首先调用listen函数监听客户端的连接请求，然后调用accept函数阻塞等待取出未决连接队列中的客户端连接，如果未决连接队列一直为空，这意味着没有客户端和服务器建立连接，那么accept就会一直阻塞。
当客户端一调用connect函数发起连接时，如果完成tcp三次握手，那么accept函数会取出一个客户端连接（注意：是已经建立好的连接）然后立即返回。
上面就是客户端和服务端在网络中的状态变迁的具体过程，前面我们在学习tcp三次握手的过程中还知道，服务端和客户端在建立连接的时候会设置自己的一个接收缓冲区窗口rwnd的大小。
服务端在发送SYN + ACK数据报文时会设置并告知对方自己的接收缓冲区窗口大小，客户端在发送ACK数据报文时也会设置并告知对方自己的接收缓冲区窗口大小。
注意，accept函数调用成功，返回的是一个已经完成tcp三次握手的客户端连接。如果在三次握手的过程中(最后一步)，服务端没有接收到客户端的ACK，则说明三次握手还没有建立完成，accept函数依然会阻塞。
关于tcp三次握手连接建立的几种状态：SYN_SENT，SYN_RCVD，ESTABLISHED。 SYN_SENT：当客户端调用connect函数向服务端发送SYN包时，客户端就会进入 SYN_SENT状态，并且还会等待服务器发送第二个SYN + ACK包，因此SYN_SENT状态就是表示客户端已经发送SYN包。
SYN_RCVD：当服务端接收到客户端发送的SYN包并确认时，服务端就会进入 SYN_RCVD状态，这是tcp三次握手建立的一个很短暂的中间状态，一般很难看到， SYN_RCVD状态表示服务端已经确认收到客户端发送的SYN包。
ESTABLISHED：该状态表示tcp三次握手连接建立完成。
对于这两个队列需要注意几点注意：
1. 未完成队列和已完成队列的总和不超过listen函数的backlog参数的大小。listen函数的签名如下：
int listen(int sockfd, int backlog); 2. 一旦该连接的tcp三次握手完成，就会从未完成队列加入到已完成队列中
3. 如果未决连接队列已满，当又接收到一个客户端SYN时，服务端的tcp将会忽略该SYN，也就是不会理客户端的SYN，但是服务端并不会发送RST报文，原因是：客户端tcp可以重传SYN，并期望在超时前未决连接队列找到空位与服务端建立连接，这当然是我们所希望看到的。如果服务端直接发送一个RST的话，那么客户端的connect函数将会立即返回一个错误，而不会让tcp有机会重传SYN，显然我们也并不希望这样做。
但是不排除有些linux实现在未决连接队列满时，的确会发送RST。但是这种做法是不正确的，因此我们最好忽略这种情况，处理这种额外情况的代码也会降低客户端程序的健壮性。
connect函数出错情况 由于connect函数是在建立tcp连接成功或失败才返回，返回成功的情况本文上面已经介绍过了。这里我们介绍connect函数返回失败的几种情况： 第一种 当客户端发送了SYN报文后，没有收到确认则返回ETIMEDOUT错误，值得注意的是，失败一次并不会马上返回ETIMEDOUT错误。即当你调用了connect函数，客户端发送了一个SYN报文，没有收到确认就等6s后再发一个SYN报文，还没有收到就等24s再发一个（不同的linux系统设置的时间可能有所不同，这里以BSD系统为主）。这个时间是累加的，如果总共等了75s后还是没收到确认，那么客户端将返回ETIMEDOUT错误。
对于linux系统，改变这个系统上限值也比较容易，由于需要改变系统配置参数，你需要root权限。 相关的命令是sysctl net.ipv4.tcp_syn_retries(针对于ipv4)。 在设置该值时还是要比较保守的，因为每次syn包重试的间隔都会增大(比如BSD类的系统实现中间隔会以2到3倍增加)，所有tcp_syn_retries的一个微小变化对connect超时时间的影响都非常大，不过扩大这个值也不会有什么坏处，因为你代码中设置的超时值都能够生效。但是如果代码中没有设置connect的超时值，那么connect就会阻塞很久，你发现对端机器down掉的间隔就更长。 作者建议设置这个值到6或者7，最多8。6对应的connect超时为45s，7对应90s，8对应190s。</description>
    </item>
    
    <item>
      <title>从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始</title>
      <link>https://haokiu.com/blog/416ada8e33704bdcadd3202dd2413740/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/416ada8e33704bdcadd3202dd2413740/</guid>
      <description>从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始 写在前面的话
经常有学生或者初学者问我如何去阅读和学习一个开源软件的代码，也有不少朋友在工作岗位时面对前同事留下的项目，由于文档不完善、代码注释少、工程数量大，而无从下手。本文将来通过一个多人联机实时对战游戏——最后一战，来解答以上问题。
其实，我以上问题在我是一个学生时，我也同样因此而困惑，但是后来，我发现，对于文档缺失、注释缺失的项目，需要自己摸索，虽然是挑战，同时也是机遇——一个不错的学习机会。因为至少有代码，正如侯捷大师所说的的，“源码面前，了无秘密”，所以我们应该**“read the fucking code”**。
所以，这个系列的文章，我们分析“最后一战”这个游戏源码时，我们不会按照传统的思路：先介绍总结的程序结构，再介绍各个模块的细节，因为，当我们面对一套陌生的源码时，尤其是在文档缺失的情况下，我们根本无法开始就掌握这个项目的总体结构，我们只能从零开始一个个模块的对代码进行阅读和调试，所以我们这个系列的文章也按这个思路来分析，以真实的案例来教会新手一步步读懂一个开源项目的代码。
我们先来看下这个游戏的内容吧，下面给出游戏画面的部分截图：
这是一款类似于王者荣耀、dota之类的5v5实时RPG竞技游戏。
客户端的逻辑比较简单，主要是一些游戏特效和动画（基于Unity 3D），所以这里我们主要分析游戏的服务器端源码。
先介绍一下推荐的源码的运行和开发环境（我的配置）：
Windows 7
Visual Studio 2010
服务器端有非常多的模块，这里先截一张主要模块的项目图示：
从下一篇文章开始，我们将介绍如何学习这样的源码。
欢迎阅读下一篇**《从零学习开源项目系列（二） 最后一战概况》**。
源码下载方法：
微信搜索公众号**『高性能服务器开发』(中文名：高性能服务器开发)，关注公众号后，在公众号中回复『英雄联盟』**，即可得到下载链接。（喷子和代码贩子请远离！）</description>
    </item>
    
    <item>
      <title>从零学习开源项目系列（三） CSBattleMgr服务源码研究</title>
      <link>https://haokiu.com/blog/86a8b9de9c914f8ab93a3d36b455838b/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/86a8b9de9c914f8ab93a3d36b455838b/</guid>
      <description>从零学习开源项目系列（三） CSBattleMgr服务源码研究 服务器项目工程如下图所示：
如上图所示，这篇文章我们将介绍CSBattleMgr的情况，但是我们不会去研究这个服务器的特别细节的东西（这些细节我们将在后面的文章中介绍）。阅读一个未知的项目源码如果我们开始就纠结于各种细节，那么我们最终会陷入“横看成岭侧成峰，远近高低各不同”的尴尬境界，浪费时间不说，可能收获也是事倍功半。所以，尽管我们不熟悉这套代码，我们还是尽量先从整体来把握，先大致了解各个服务的功能，细节部分回头再针对性地去研究。
这个系列的第二篇文章《从零学习开源项目系列（二） 最后一战概况》中我们介绍了，这套游戏的服务需要使用redis和mysql，我们先看下mysql是否准备好了（mysql服务启动起来，数据库建表数据存在，具体细节请参考第二篇文章）。打开Windows的cmd程序，输入以下指令连接mysql：
mysql -uroot -p123321 连接成功以后，如下图所示：
然后我们输入以下指令，查看我们需要的数据库是否创建成功：
show databases; 这些都是基本的sql语句，如果您不熟悉的话，可能需要专门学习一下。
数据库创建成功后如下图所示：
至于数据库中的表是否创建成功，我们这里先不关注，后面我们实际用到哪张数据表，我们再去研究。
mysql没问题了，接下来我们要启动一下redis，通过第二篇文章我们知道redis需要启动两次，也就是一共两个redis进程，我们游戏服务中分别称为redis-server和redis-login-server（它们的配置文件信息不一样），我们可以在Server\Bin\x64\Release目录下手动cmd命令行执行下列语句：
start /min &amp;#34;redis-server&amp;#34; &amp;#34;redis-server.exe&amp;#34; redis.conf start /min &amp;#34;redis-Logicserver&amp;#34; &amp;#34;redis-server.exe&amp;#34; redis-logic.conf 但是这样比较麻烦，我将这两句拷贝出来，放入一个叫start-redis.bat文件中了，每次启动只要执行一下这个bat文件就可以：
redis和redis-logic服务启动后如下图所示：
我们常见的redis服务都是linux下的源码，微软公司对redis源码进行了改造，出了一个Windows版本，稍微有点不尽人意（例如：Windows下没有完全与linux的fork()相匹配的API，所以只能用CreateProcess()去替代）。关于windows版本的redis源码官方下载地址为：https://github.com/MicrosoftArchive/redis/releases。
在启动好了mysql和redis后，我们现在正式来看一下CSBattleMgr这个服务。读者不禁可能要问，那么多服务，你怎么知道要先看这个服务呢？我们上一篇文章中也说过，我们再start.bat文件中发现除了redis以外，这是第三个需要启动的服务，所以我们先研究它（start.bat我们可以认为是源码作者为我们留下的部署步骤“文档”）：
我们打开CSBattleMgr服务main.cpp文件，找到入口main函数，内容如下：
int main(){ DbgLib::CDebugFx::SetExceptionHandler(true); DbgLib::CDebugFx::SetExceptionCallback(ExceptionCallback, NULL); GetCSKernelInstance(); GetCSUserMgrInstance(); GetBattleMgrInstance(); GetCSKernelInstance()-&amp;gt;Initialize(); GetBattleMgrInstance()-&amp;gt;Initialize(); GetCSUserMgrInstance()-&amp;gt;Initialize(); GetCSKernelInstance()-&amp;gt;Start(); mysql_library_init(0, NULL, NULL); GetCSKernelInstance()-&amp;gt;MainLoop(); } 通过调试，我们发下这个函数大致做了以下任务：
//1. 设置程序异常处理函数 //2. 初始化一系列单例对象 //3. 初始化mysql //4. 进入一个被称作“主循环”的无限循环 步骤1设置程序异常处理函数没有好介绍的，我们看一下步骤2初始化一系列单例对象，总共初始化了三个类的对象CCSKernel、CCSUserMgr和CCSBattleMgr。单例模式本身没啥好介绍的，但是有人要提单例模式的线程安全性，所以出现很多通过加锁的单例模式代码，我个人觉得没必要；认为要加锁的朋友可能认为单例对象如果在第一次初始化时同时被多个线程调用就会有问题，我觉得加锁带来的开销还不如像上面的代码一样，在整个程序初始化初期获取一下单例对象，让单例对象生成出来，后面即使多个线程获取这个单例对象也都是读操作，无需加锁。以GetCSKernelInstance();为例：
CCSKernel* GetCSKernelInstance(){ return &amp;amp;CCSKernel::GetInstance(); } CCSKernel&amp;amp; CCSKernel::GetInstance(){ if (NULL == pInstance){ pInstance = new CCSKernel; } return *pInstance; } GetCSKernelInstance()-&amp;gt;Initialize()的初始化动作其实是加载各种配置信息和事先设置一系列的回调函数和定时器：
INT32 CCSKernel::Initialize() { //JJIAZ加载配置的时候 不要随便调整顺序 CCSCfgMgr::getInstance().Initalize(); INT32 n32Init = LoadCfg(); if (eNormal != n32Init) { ELOG(LOG_ERROR,&amp;#34; loadCfg()............failed!&amp;#34;); return n32Init; } if(m_sCSKernelCfg.un32MaxSSNum &amp;gt; 0 ) { m_psSSNetInfoList = new SSSNetInfo[m_sCSKernelCfg.</description>
    </item>
    
    <item>
      <title>从零学习开源项目系列（二） 最后一战概况</title>
      <link>https://haokiu.com/blog/92d9492b21aa444d81eb4f31c1bfabb1/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/92d9492b21aa444d81eb4f31c1bfabb1/</guid>
      <description>从零学习开源项目系列（二） 最后一战概况 这份代码我也是无意中来自一个朋友，据他说也是来源于互联网，服务器端代码原来是Linux版本的，但被厉害的大神修改成可以在Windows上运行。（如果不小心侵犯了您的版权，请联系我删除）。好在，这份代码中使用的大多数方法和接口都是可以跨Windows和Linux两个平台的，所以Linux开发下的朋友请不要感到不适，我们学习这份代码更多的不是纠结细节而是学习思路和原理。
游戏主solution文件用Visual Studio打开后如下图所示：
这里总共有10个工程项目，模块比较多。**我们应该从何处入手呢？**我们先看下源码目录：
我们进入Server目录，发现如下一个文件：
我们打开看一下内容：
cd Bin\x64\Release start.bat 这个代码进入Bin\x64\Release目录，执行另外一个start.bat，我们进入这个目录去看下这个文件内容：
taskkill /f /t /im redis-server.exe taskkill /f /t /im CSBattleMgr.exe taskkill /f /t /im SSBattleMgr.exe taskkill /f /t /im GSConsole.exe taskkill /f /t /im BalanceServer.exe taskkill /f /t /im LoginServer.exe taskkill /f /t /im GSKernel.exe taskkill /f /t /im RobotConsole.exe taskkill /f /t /im LogServer.exe ping -n 1 127.0&amp;gt;nul start /min &amp;#34;redis-server&amp;#34; &amp;#34;redis-server.exe&amp;#34; redis.conf ping -n 1 127.0&amp;gt;nul start /min &amp;#34;redis-Logicserver&amp;#34; &amp;#34;redis-server.exe&amp;#34; redis-logic.conf ping -n 1 127.0&amp;gt;nul echo &amp;#34;start CSBattleMgr.exe&amp;#34; start /min &amp;#34;CSBattleMgr&amp;#34; &amp;#34;CSBattleMgr.exe&amp;#34; ping -n 1 127.0&amp;gt;nul echo &amp;#34;start SSBattleMgr.exe&amp;#34; start /min &amp;#34;SSBattleMgr&amp;#34; &amp;#34;SSBattleMgr.exe&amp;#34; ping -n 1 127.</description>
    </item>
    
    <item>
      <title>从零学习开源项目系列（四）LogServer源码探究</title>
      <link>https://haokiu.com/blog/fea618d6d104410cb5df6bc54d9529f2/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/fea618d6d104410cb5df6bc54d9529f2/</guid>
      <description>从零学习开源项目系列（四）LogServer源码探究 这是从零学习开源项目的第四篇，上一篇是《从零学习开源项目系列（三） CSBattleMgr服务源码研究》，这篇文章我们一起来学习LogServer，中文意思可能是“日志服务器”。那么这个日志服务器到底做了哪些工作呢？
我们在Visual Studio中将LogServer设置为启动项，然后按F5将LogServer启动起来，启动成功后显示如下图：
从上图中，我们可以到大致做了三件事：
1. 创建一个侦听端口（端口号1234） 2. 连接mysql数据库 3. 初始化日志处理程序 我们来验证一下这三件事的细节。我们再Visual Studio中将程序中断（【调试】菜单-【全部中断】，快捷键Ctrl + Alt + Break）。然后在线程窗口查看这个程序所有的线程，如下图所示：
所有用红色旗帜标记的线程都是用户线程，我们可以查看这些线程的调用堆栈。我们从最上面的主线程开始：
切换到main函数，我们可以看出这里是一个循环：
int main() { auto res = CLogHandler::GetInstance().Init(); if (res) { while(true) { INetSessionMgr::GetInstance()-&amp;gt;Update(); Sleep(1); } } return 0; } 这里一个是初始化动作，一个循环中Update动作，它们具体做了些什么，我们先不管，我们先看其他线程做了什么，再回过头来看这里的代码。
我们接着看下一个线程的内容：
从调用堆栈来看，这是一个使用boost::thread启动的线程，这个线程函数代码如下：
void Active::Run() { if (m_BeginInThreadCallback){ m_BeginInThreadCallback(); } while (true){ Consume(); } } 我们先看下这个线程函数做了什么，主要是m_BeginInThreadCallback和**Consume()函数，看下Consume()**函数：
void Active::Consume(){ boost::mutex::scoped_lock lock(m_IOMutex); while(m_Queue.empty()){ m_ConditionVar.wait(lock); } m_SwapQueue.swap(m_Queue); lock.unlock(); while(!m_SwapQueue.empty()){ Buffer* pBuffer = m_SwapQueue.front(); m_SwapQueue.pop(); m_Callback(pBuffer); --m_PendingWorkNum; if (pBuffer){ m_pBufferPool.ReleaseObejct(pBuffer); } } } 这段代码很好理解，先使用条件变量挂起当前线程，条件变量触发后，如果消费者和生产者共有队列m_Queue中有数据，将公用的队列m_Queue临时倒换到本地的一个局部队列m_SwapQueue中，然后挨个处理队列m_SwapQueue中的数据。
这个线程在哪里创建的呢？通过搜索线程函数，我们找到如下代码：
void Active::Start(){ bool ifHvTimer = !m_ThreadTimer.IsEmpty(); if (ifHvTimer){ m_Thread = boost::thread(&amp;amp;Active::RunWithUpdate, this); } else{ m_Thread = boost::thread(&amp;amp;Active::Run, this); } m_ThreadID = get_native_thread_id(m_Thread); char sThreadName[30]; sprintf(sThreadName, &amp;#34;%s-%d&amp;#34;, &amp;#34;Actor-Run&amp;#34;, GetActorID()); _SetThreadName(m_ThreadID, sThreadName); } 在上面这个函数中添加断点，重启下程序，很快会触发断点，我们看下断点触发时的调用堆栈：</description>
    </item>
    
    <item>
      <title>从零实现一个http服务器</title>
      <link>https://haokiu.com/blog/2ec66b5605c8455e833f06d2a23fff09/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/2ec66b5605c8455e833f06d2a23fff09/</guid>
      <description>从零实现一个http服务器 我始终觉得，天生的出身很重要，但后天的努力更加重要，所以如今的很多“科班”往往不如后天努力的“非科班”。所以，我们需要重新给“专业”和“专家”下一个定义：所谓专业，就是别人不搞你搞，这就是你的“专业”；你和别人同时搞，你比别人搞的好，就是“专家”。
说到http协议和http请求，很多人都知道，但是他们真的“知道”吗？我面试过很多求职者，一说到http协议，他们能滔滔不绝，然后我问他http协议的具体格式是啥样子的？很多人不清楚，不清楚就不清楚吧，他甚至能将http协议的头扯到html文档头部。当我问http GET和POST请求的时候，GET请求是什么形式一般人都可以答出来，但是POST请求的数据放在哪里，服务器如何识别和解析这些POST数据，很多人又说不清道不明了。当说到http服务器时，很多人离开了apache、Nginx这样现成的http server之外，自己实现一个http服务器无从下手，如果实际应用场景有需要使用到一些简单http请求时，使用apache、Nginx这样重量级的http服务器程序实在劳师动众，你可以尝试自己实现一个简单的。
上面提到的问题，如果您不能清晰地回答出来，可以阅读一下这篇文章，这篇文章在不仅介绍http的格式，同时带领大家从零实现一个简单的http服务器程序。
一、项目背景 最近很多朋友希望我的flamingo服务器支持http协议，我自己也想做一个微信小程序，小程序通过http协议连接通过我的flamingo服务器进行聊天。flamingo是一个开源的即时通讯软件，目前除了服务器端，还有pc端、android端，后面会支持更多的终端。关于flamingo的介绍您可以参考这里: https://github.com/baloonwj/flamingo，更新日志：https://github.com/baloonwj/flamingo/issues/1。下面是flamingo的部分截图：
二、http协议介绍 1. http协议是应用层协议，一般建立在tcp协议的基础之上（当然你的实现非要基于udp也是可以的），也就是说http协议的数据收发是通过tcp协议的。
2. http协议也分为head和body两部分，但是我们一般说的html中的和标记不是http协议的头和身体，它们都是http协议的body部分。
那么http协议的头到底长啥样子呢？我们来介绍一下http协议吧。
http协议的格式如下：
GET或POST 请求的url路径（一般是去掉域名的路径） HTTP协议版本号\r\n字段1名: 字段1值\r\n字段2名: 字段2值\r\n…字段n名 : 字段n值\r\n\r\nhttp协议包体内容 也就是说http协议由两部分组成：包头和包体，包头与包体之间使用一个\r\n分割，由于http协议包头的每一行都是以**\r\n结束，所以http协议包头一般以\r\n\r\n**结束。
举个例子，比如我们在浏览器中请求http://www.hootina.org/index_2013.php这个网址，这是一个典型的GET方法，浏览器组装的http数据包格式如下：
GET /index_2013.php HTTP/1.1\r\nHost: www.hootina.org\r\nConnection: keep-alive\r\nUpgrade-Insecure-Requests: 1\r\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nAccept-Language: zh-CN,zh;q=0.9,en;q=0.8\r\n\r\n 上面这个请求只有包头没有包体，http协议的包体不是必须的，也就是说GET请求一般没有包体。
如果GET请求带参数，那么一般是附加在请求的url后面，参数与参数之间使用&amp;amp;分割，例如请求http://www.hootina.org/index_2013.php?param1=value1&amp;amp;param2=value2&amp;amp;param3=value3，我们看下这个请求组装的的http协议包格式：
GET /index_2013.php?param1=value1&amp;amp;param2=value2&amp;amp;param3=value3 HTTP/1.1\r\nHost: www.hootina.org\r\nConnection: keep-alive\r\nUpgrade-Insecure-Requests: 1\r\nUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36\r\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\r\nAccept-Encoding: gzip, deflate\r\nAccept-Language: zh-CN,zh;q=0.9,en;q=0.8\r\n\r\n 对比一下，你现在知道http协议的GET参数放在协议包的什么位置了吧。
那么POST的数据放在什么位置呢？我们再12306网站https://kyfw.12306.cn/otn/login/init中登陆输入用户名和密码：
然后发现浏览器以POST方式组装了http协议包发送了我们的用户名、密码和其他一些信息，组装的包格式如下：
POST /passport/web/login HTTP/1.1\r\nHost: kyfw.</description>
    </item>
    
    <item>
      <title>从零实现一个邮件收发客户端</title>
      <link>https://haokiu.com/blog/e1e38f7ff0e941c8ad6e51923070551d/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/e1e38f7ff0e941c8ad6e51923070551d/</guid>
      <description>从零实现一个邮件收发客户端 与邮件收发有关的协议有 POP3、SMPT 和 IMAP 等。
POP3
POP3全称是 Post Office Protocol 3 ，即邮局协议的第 3 个版本，它规定怎样将个人计算机连接到 Internet 的邮件服务器和下载电子邮件的电子协议，它是因特网电子邮件的第一个离线协议标准，POP3 允许用户从服务器上把邮件存储到本地主机（即自己的计算机）上，同时删除保存在邮件服务器上的邮件，而 POP3 服务器则是遵循 POP3 协议的接收邮件服务器，用来接收电子邮件的。
SMTP
SMTP 的全称是 Simple Mail Transfer Protocol，即简单邮件传输协议。它是一组用于从源地址到目的地址传输邮件的规范，它帮助每台计算机在发送或中转邮件时找到下一个目的地。SMTP 服务器就是遵循 SMTP 协议的发送邮件服务器。SMTP 需要认证，简单地说就是要求必须在提供了账户名和密码之后才可以登录 SMTP 服务器，这就使得那些垃圾邮件的散播者无可乘之机，使用户避免受到垃圾邮件的侵扰。
IMAP
IMAP全称是 Internet Mail Access Protocol，即交互式邮件存取协议，它是跟 POP3 类似邮件访问标准协议之一。不同的是，开启了 IMAP 后，在电子邮件客户端收取的邮件仍然保留在服务器上，同时在客户端上的操作都会反馈到服务器上，如：删除邮件，标记已读等，服务器上的邮件也会做相应的动作。所以无论从浏览器登录邮箱或者客户端软件登录邮箱，看到的邮件以及状态都是一致的。而 POP3 对邮件的操作只会在本地邮件客户端起作用。
读者如果需要自己编写相关的邮件收发客户端，需要登录对应的邮件服务器开启相应的 POP3/SMTP/IMAP 服务。以 163 邮箱为例：
请登录 163 邮箱(http://mail.163.com/)，点击页面正上方的“设置”，再点击左侧上“POP3/SMTP/IMAP”，其中“开启 SMTP 服务”是系统默认勾选开启的。读者可勾选图中另两个选项，点击确定，即可开启成功。不勾选图中两个选项，点击确定，可关闭成功。
网易163免费邮箱相关服务器信息：
163免费邮客户端设置的POP3、SMTP、IMAP地址
POP3、SMTP、IMAP 协议就是我们前面介绍的以指定字符（串）为包的结束标志的协议典型例子。我们来以 SMTP 协议和 POP3 协议为例来讲解一下。
SMTP 协议 先来介绍 SMTP 协议吧，SMTP 全称是 Simple Mail Transfer Protocol，即简单邮件传输协议，该协议用于发送邮件。
SMTP 协议的格式：
关键字 自定义内容\r\n “自定义内容”根据“关键字”的类型是否设置，对于使用 SMTP 作为客户端的一方常用的“关键字“如下所示：
//连接上邮件服务器之后登录服务器之前向服务器发送的问候信息 HELO 自定义问候语\r\n //请求登录邮件服务器 AUTH LOGIN\r\n base64形式的用户名\r\n base64形式的密码\r\n //设置发件人邮箱地址 MAIL FROM:发件人地址\r\n //设置收件人地址，每次发送可设置一个收件人地址，如果有多个收件地址，要分别设置对应次数 rcpt to:收件人地址\r\n //发送邮件正文开始标志 DATA\r\n //发送邮件正文，注意邮件正文以.\r\n结束 邮件正文\r\n.\r\n //登出服务器 QUIT\r\n 使用 SMTP 作为邮件服务器的一方常用的“关键字“是定义的各种应答码，应答码后面可以带上自己的信息，然后以\r\n作为结束，格式如下：</description>
    </item>
    
    <item>
      <title>从零实现一款12306刷票软件</title>
      <link>https://haokiu.com/blog/42f423476e5d4262bcb032f3cf4c40d3/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/42f423476e5d4262bcb032f3cf4c40d3/</guid>
      <description>从零实现一款12306刷票软件 写在前面的话
每年逢年过节，一票难求读者肯定不陌生。这篇文章，我们带领读者从零实现一款12306刷票软件，其核心原理是通过发送http请求模拟登录12306网站的购票的过程，最后买到票。
关于http请求的格式和如何组装http数据包给服务器发送请求，我们在上一篇文章《从零实现一个http服务器》中已经详细介绍过了，如果还不明白的朋友可以去那篇文章看下。
郑重申明一下：这里介绍的技术仅供用于学习，不可用于恶意攻击12306服务器，请勿滥用本文介绍的技术。对12306服务器造成的任何损失，后果自负。
当然，由于12306服务器用户量巨大，为了防止黄牛和其他一些非法攻击者，12306的很多url和在购票过程中各个步骤的协议细节经常发生变化。所以，本文中介绍的一些具体的url，可能在你看到本文时已经失效。但是这并没有关系，只要你掌握了本文中介绍的分析方法，您就可以灵活地修改您的代码，以适应最新的12306服务器的要求。
举个例子，如12306的查票接口目前的url是：
https://kyfw.12306.cn/otn/leftTicket/query 可能过几天就变成了
https://kyfw.12306.cn/otn/leftTicket/queryX 再过几天又可能变成
https://kyfw.12306.cn/otn/leftTicket/queryY 然后一个星期后又可能变成
https://kyfw.12306.cn/otn/leftTicket/queryZ 这些笔者都见过。所以，重在原理的学习，掌握了原理，不管12306的相关url变成什么样，都可以以不变应万变。哎，12306在与黄牛的斗争中越走越远啊T_T
本文将使用以下工具来分析12306购票的过程，然后使用C++语言，模拟相关的过程，最终购票。
Chrome浏览器（其他的浏览器也可以，都有类似的界面，如Chrome，装了httpwatch的IE浏览器等） 一个可以登录12306网址并且可以购票的12306账号 Visual Studio（版本随意，我这里用的是VS 2013） 一、查票与站点信息接口
之所以先分析这个接口，是因为查票不需要用户登录的，相对来说最简单。我们在Chrome浏览器中打开12306余票查询页面，网址是：https://kyfw.12306.cn/otn/leftTicket/init，如下图所示：
然后在页面中右键菜单中选择【检查】菜单，打开后，选择【网络】选项卡。如下图所示：
打开后页面变成二分窗口了，左侧是正常的网页页面，右侧是浏览器自带的控制台，当我们在左侧页面中进行操作后，右侧会显示我们浏览器发送的各种http请求和应答。我们这里随便查一个票吧，如查2018年5月20日从上海到北京的票，点击12306网页中【查询】按钮后，我们发现右侧是这样的：
通过图中列表的type值是xhr，我们可以得出这是一个ajax请求（ajax是一种浏览器原生支持的异步技术，具体细节请读者自行搜索）。我们选择这个请求，你能看到这个请求的细节——请求和响应结果：
在reponse中，我们可以看到我们的这个http的去除http头的响应结果（包体，可能是解压缩或者解码后的）：
这是一个json格式，我们找个json格式化工具，把这个json格式化后贴出来给大家看一下，其实您后面会发现12306的http请求结果中与购票相关的数据基本上都是json格式。这里的json如下：
{ &amp;#34;validateMessagesShowId&amp;#34;: &amp;#34;_validatorMessage&amp;#34;, &amp;#34;status&amp;#34;: true, &amp;#34;httpstatus&amp;#34;: 200, &amp;#34;data&amp;#34;: { &amp;#34;result&amp;#34;: [&amp;#34;null|23:00-06:00系统维护时间|5l0000G10270|G102|AOH|VNP|AOH|VNP|06:26|12:29|06:03|IS_TIME_NOT_BUY|RLVVIt093U2EZuy2NE+VQyRloXyqTzFp6YyNk6J52QcHEA01|20180520|3|HZ|01|11|1|0|||||||||||1|有|13||O090M0|O9M|0&amp;#34;,(内容太长，这里省略) &amp;#34;], &amp;#34;flag&amp;#34;: &amp;#34;1&amp;#34;, &amp;#34;map&amp;#34;: { &amp;#34;AOH&amp;#34;: &amp;#34;上海虹桥&amp;#34;, &amp;#34;BJP&amp;#34;: &amp;#34;北京&amp;#34;, &amp;#34;VNP&amp;#34;: &amp;#34;北京南&amp;#34;, &amp;#34;SHH&amp;#34;: &amp;#34;上海&amp;#34; } }, &amp;#34;messages&amp;#34;: [], &amp;#34;validateMessages&amp;#34;: {} } 其中含有的余票信息在result节点中，这是一个数组。每个节点以|分割，我们可以格式化后显示在自己的界面上：
我这里做的界面比较简陋，读者如果有兴趣可以做更精美的界面。我们列下这个请求发送的http数据包和应答包：
请求包：
GET /otn/leftTicket/query?leftTicketDTO.train_date=2018-05-20&amp;amp;leftTicketDTO.from_station=SHH&amp;amp;leftTicketDTO.to_station=BJP&amp;amp;purpose_codes=ADULT HTTP/1.1 Host: kyfw.12306.cn Connection: keep-alive Cache-Control: no-cache Accept: */* X-Requested-With: XMLHttpRequest If-Modified-Since: 0 User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36 Referer: https://kyfw.12306.cn/otn/leftTicket/init Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cookie: RAIL_EXPIRATION=1526978933395; RAIL_DEVICEID=WKxIYg-q1zjIPVu7VjulZ9PqEGvW2gUB9LvoM1Vx8fa7l3SUwnO_BVSatbTq506c6VYNOaxAiRaUcGFTMjCz9cPayEIc9vJ0pHaXdSqDlujJP8YrIoXbpAAs60l99z8bEtnHgAJzxLzKiv2nka5nmLY_BMNur8b8; _jc_save_fromStation=%u4E0A%u6D77%2CSHH; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_fromDate=2018-05-20; _jc_save_toDate=2018-05-19; _jc_save_wfdc_flag=dc 应答包：</description>
    </item>
    
    <item>
      <title>从零开发一个WebSocket服务器</title>
      <link>https://haokiu.com/blog/f8c9189db8404c76867e71440f136a2c/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/f8c9189db8404c76867e71440f136a2c/</guid>
      <description>从零开发一个WebSocket服务器 WebSocket 协议是为了解决 http 协议的无状态、短连接（通常是）和服务端无法主动给客户端推送数据等问题而开发的新型协议，其通信基础也是基于 TCP。由于较旧的浏览器可能不支持 WebSocket 协议，所以使用 WebSocket 协议的通信双方在进行 TCP 三次握手之后，还要再额外地进行一次握手，这一次的握手通信双方的报文格式是基于 HTTP 协议改造的。
WebSocket 握手过程 TCP 三次握手的过程我们就不在这里赘述了，任何一本网络通信书籍上都有详细的介绍。我们这里来介绍一下 WebSocket 通信最后一次的握手过程。
握手开始后，一方给另外一方发送一个 http 协议格式的报文，这个报文格式大致如下：
GET /realtime HTTP/1.1\r\n Host: 127.0.0.1:9989\r\n Connection: Upgrade\r\n Pragma: no-cache\r\n Cache-Control: no-cache\r\n User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64)\r\n Upgrade: websocket\r\n Origin: http://xyz.com\r\n Sec-WebSocket-Version: 13\r\n Accept-Encoding: gzip, deflate, br\r\n Accept-Language: zh-CN,zh;q=0.9,en;q=0.8\r\n Sec-WebSocket-Key: IqcAWodjyPDJuhGgZwkpKg==\r\n Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits\r\n \r\n 对这个格式有如下要求：
握手必须是一个有效的 HTTP 请求； 请求的方法必须为 GET，且 HTTP 版本必须是 1.1； 请求必须包含 Host 字段信息； 请求必须包含 Upgrade字段信息，值必须为 websocket； 请求必须包含 Connection 字段信息，值必须为 Upgrade； 请求必须包含 Sec-WebSocket-Key 字段，该字段值是客户端的标识编码成 base64 格式； 请求必须包含 Sec-WebSocket-Version 字段信息，值必须为 13； 请求必须包含 Origin 字段； 请求可能包含 Sec-WebSocket-Protocol 字段，规定子协议； 请求可能包含 Sec-WebSocket-Extensions字段规定协议扩展； 请求可能包含其他字段，如 cookie 等。 对端收到该数据包后如果支持 WebSocket 协议，会回复一个 http 格式的应答，这个应答报文的格式大致如下：</description>
    </item>
    
    <item>
      <title>作者的故事</title>
      <link>https://haokiu.com/blog/745f468dc9234e4f95ac9d848e64fa0b/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/745f468dc9234e4f95ac9d848e64fa0b/</guid>
      <description>作者的故事 我的 2019
我是如何年薪五十万的</description>
    </item>
    
    <item>
      <title>你一定要搞明白的C函数调用方式与栈原理</title>
      <link>https://haokiu.com/blog/2d2976c6ad824a1b9e2c44ffad106432/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/2d2976c6ad824a1b9e2c44ffad106432/</guid>
      <description>你一定要搞明白的C函数调用方式与栈原理 写在前面的话
这绝对不是标题党。而是C/C++开发中你必须要掌握的基础知识，也是高级技术岗位面试中高频题。我真的真的真的希望无论是学生还是广大C/C++开发者，都该掌握此文中介绍的知识。
正文
这篇blog试图讲明当一个c函数被调用时，一个**栈帧(stack frame)**是如何被建立，又如何被消除的。这些细节跟操作系统平台及编译器的实现有关，下面的描述是针对运行在Intel奔腾芯片上Linux的gcc编译器而言。c语言的标准并没有描述实现的方式，所以，不同的编译器，处理器，操作系统都可能有自己的建立栈帧的方式。
一个典型的栈帧 图1是一个典型的栈帧，图中，栈顶在上，地址空间往下增长。 这是如下一个函数调用时的栈的内容：
int foo(int arg1, int arg2, int arg3); 并且，foo有两个局部的int变量（4个字节）。在这个简化的场景中，main调用foo，而程序的控制仍在foo中。这里，main是调用者（caller），foo是被调用者（callee）。 ESP被foo使用来指示栈顶。EBP相当于一个“基准指针”。从main传递到foo的参数以及foo本身的局部变量都可以通过这个基准指针为参考，加上偏移量找到。 由于被调用者允许使用EAX，ECX和EDX寄存器，所以如果调用者希望保存这些寄存器的值，就必须在调用子函数之前显式地把他们保存在栈中。另一方面，如果除了上面提到的几个寄存器，被调用者还想使用别的寄存器，比如EBX，ESI和EDI，那么，被调用者就必须在栈中保存这些被额外使用的寄存器，并在调用返回前回复他们。也就是说，如果被调用者只使用约定的EAX，ECX和EDX寄存器，他们由调用者负责保存并回复，但如果被调用这还额外使用了别的寄存器，则必须有他们自己保存并回复这些寄存器的值。 传递给foo的参数被压到栈中，最后一个参数先进栈，所以第一个参数是位于栈顶的。foo中声明的局部变量以及函数执行过程中需要用到的一些临时变量也都存在栈中。 小于等于4个字节的返回值会被保存到EAX中，如果大于4字节，小于8字节，那么EDX也会被用来保存返回值。如果返回值占用的空间还要大，那么调用者会向被调用者传递一个额外的参数，这个额外的参数指向将要保存返回值的地址。用C语言来说，就是函数调用：
x = foo(a, b, c); 被转化为：
foo(&amp;amp;x, a, b, c); 注意，这仅仅在返回值占用大于8个字节时才发生。有的编译器不用EDX保存返回值，所以当返回值大于4个字节时，就用这种转换。 当然，并不是所有函数调用都直接赋值给一个变量，还可能是直接参与到某个表达式的计算中，如：
m = foo(a, b, c) + foo(d, e, f); 有或者作为另外的函数的参数， 如：
fooo(foo(a, b, c), 3); 这些情况下，foo的返回值会被保存在一个临时变量中参加后续的运算，所以，foo(a, b, c)还是可以被转化成foo(&amp;amp;tmp, a, b, c)。
让我们一步步地看一下在c函数调用过程中，一个栈帧是如何建立及消除的。
函数调用前调用者的动作 在我们的例子中，调用者是main，它准备调用函数foo。在函数调用前，main正在用ESP和EBP寄存器指示它自己的栈帧。
首先，main把EAX，ECX和EDX压栈。这是一个可选的步骤，只在这三个寄存器内容需要保留的时候执行此步骤。 接着，main把传递给foo的参数一一进栈，最后的参数最先进栈。例如，我们的函数调用是：
a = foo(12, 15, 18); 相应的汇编语言指令是：
push dword 18 push dword 15 push dword 12 最后，main用call指令调用子函数：
call foo 当call指令执行的时候，EIP指令指针寄存器的内容被压入栈中。因为EIP寄存器是指向main中的下一条指令，所以现在返回地址就在栈顶了。在call指令执行完之后，下一个执行周期将从名为foo的标记处开始。 图2展示了call指令完成后栈的内容。图2及后续图中的粗线指示了函数调用前栈顶的位置。我们将会看到，当整个函数调用过程结束后，栈顶又回到了这个位置。
被调用者在函数调用后的动作 当函数foo，也就是被调用者取得程序的控制权，它必须做3件事：建立它自己的栈帧，为局部变量分配空间，最后，如果需要，保存寄存器EBX，ESI和EDI的值。 首先foo必须建立它自己的栈帧。EBP寄存器现在正指向main的栈帧中的某个位置，这个值必须被保留，因此，EBP进栈。然后ESP的内容赋值给了EBP。这使得函数的参数可以通过对EBP附加一个偏移量得到，而栈寄存器ESP便可以空出来做其他事情。如此一来，几乎所有的c函数都由如下两个指令开始：
push ebp mov ebp, esp 此时的栈入图3所示。在这个场景中，第一个参数的地址是EBP加8，因为main的EBP和返回地址各在栈中占了4个字节。
​
下一步，foo必须为它的局部变量分配空间，同时，也必须为它可能用到的一些临时变量分配空间。比如，foo中的一些C语句可能包括复杂的表达式，其子表达式的中间值就必须得有地方存放。这些存放中间值的地方同城被称为临时的，因为他们可以为下一个复杂表达式所复用。为说明方便，我们假设我们的foo中有两个int类型（每个4字节）的局部变量，需要额外的12字节的临时存储空间。简单地把栈指针减去20便为这20个字节分配了空间：
sub esp, 20 现在，局部变量和临时存储都可以通过基准指针EBP加偏移量找到了。 最后，如果foo用到EBX，ESI和EDI寄存器，则它f必须在栈里保存它们。结果，现在的栈如图4所示。
​
foo的函数体现在可以执行了。这其中也许有进栈、出栈的动作，栈指针ESP也会上下移动，但EBP是保持不变的。这意味着我们可以一直用[EBP+8]找到第一个参数，而不管在函数中有多少进出栈的动作。 函数foo的执行也许还会调用别的函数，甚至递归地调用foo本身。然而，只要EBP寄存器在这些子调用返回时被恢复，就可以继续用EBP加上偏移量的方式访问实际参数，局部变量和临时存储。
被调用者返回前的动作 在把程序控制权返还给调用者前，被调用者foo必须先把返回值保存在EAX寄存器中。我们前面已经讨论过，当返回值占用多于4个或8个字节时，接收返回值的变量地址会作为一个额外的指针参数被传到函数中，而函数本身就不需要返回值了。这种情况下，被调用者直接通过内存拷贝把返回值直接拷贝到接收地址，从而省去了一次通过栈的中转拷贝。 其次，foo必须恢复EBX，ESI和EDI寄存器的值。如果这些寄存器被修改，正如我们前面所说，我们会在foo执行开始时把它们的原始值压入栈中。如果ESP寄存器指向如图4所示的正确位置，寄存器的原始值就可以出栈并恢复。可见，在foo函数的执行过程中正确地跟踪ESP是多么的重要————也就是说，进栈和出栈操作的次数必须保持平衡。 这两步之后，我们不再需要foo的局部变量和临时存储了，我们可以通过下面的指令消除栈帧：</description>
    </item>
    
    <item>
      <title>做 Java 或者 C&#43;&#43; 开发都应该知道的 lsof 命令</title>
      <link>https://haokiu.com/blog/a21d8fb5077b4bdfacf0cd5f4583f1cc/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/a21d8fb5077b4bdfacf0cd5f4583f1cc/</guid>
      <description>做 Java 或者 C++ 开发都应该知道的 lsof 命令 lsof 命令是 Linux 系统的扩展工具，它的含义是 list opened filedesciptor （列出已经打开的文件描述符），在 Linux 系统中，所有的与资源句柄相关的东西都可以统一抽象成文件描述符（filedescriptor，简称 fd）。一个文件句柄是一个 fd，一个 socket 对象也可以称之为 fd 等等。
默认情况下，系统是不存在这个命令的，你需要安装一下，使用如下命令安装：
yum install lsof 我们来看一下这个命令的使用效果：
COMMAND PID TID USER FD TYPE DEVICE SIZE/OFF NODE NAME systemd 1 root cwd DIR 202,1 4096 2 / nscd 453 469 nscd 8u netlink 0t0 11017 ROUTE nscd 453 470 nscd cwd DIR 202,1 4096 2 / nscd 453 470 nscd rtd DIR 202,1 4096 2 / nscd 453 470 nscd txt REG 202,1 180272 146455 /usr/sbin/nscd nscd 453 470 nscd mem REG 202,1 217032 401548 /var/db/nscd/hosts nscd 453 470 nscd mem REG 202,1 90664 132818 /usr/lib64/libz.</description>
    </item>
    
    <item>
      <title>利用 cmake 工具生成 Visual Studio 工程文件</title>
      <link>https://haokiu.com/blog/cf3a65cd7c2a40d1a4dbfd708c471c01/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/cf3a65cd7c2a40d1a4dbfd708c471c01/</guid>
      <description>利用 cmake 工具生成 Visual Studio 工程文件 对于习惯了 Visual Studio 强大的管理项目、编码和调试功能的读者来说，在 Linux 下使用 gcc/g++ 编译、使用 gdb 调试是一件何其痛苦的事情，对于大多数的开源 C/C++ 项目，如果我们不在意 Windows 和 Linux 在一些底层 API 接口上的使用差别，想熟悉该项目的执行脉络和原理，在 Windows 上使用 Visual Studio 调试该项目也未尝不可。凡是可以使用 CMake 工具编译的 Linux 程序（即提供了 CMakeLists.txt 文件），我们同样也可以利用 CMake 工具生成 Windows 上的 Visual Studio 工程文件。
这里我们以著名的开源网络库 libuv 为例。
从 libuv 的官方地址提供的下载链接：https://dist.libuv.org/dist/ 下载最新的 libuv 的源码得到文件 libuv-v1.31.0.tar.gz（笔者写作此书时，libuv 最新版本是 1.31.0），解压该文件。作者的机器上我将代码解压至 *F:\mycode\libuv-v1.31.0* ，解压后的目录中确实存在一个 CMakeLists.txt 文件，如下图所示：
启动 Windows 上的 CMake 图形化工具（cmake-gui），按下图进行设置：
设置完成之后，点击界面上的Configure 按钮，会提示 vsprojects 目录不存在，提示是否创建，我们点击 Yes 进行创建。
如果您的机器上安装了多个版本的Visual Studio，接下来会弹窗对话框让我们选择要生成的工程文件对应的 Visual Studio 版本号。读者可以根据自己的实际情况按需选择。我这里选择 Visual Studio 2019。
点击 Finish 按钮后开始启动 CMake 的检测和配置工作。等待一会儿，CMake 底部的输出框中提示 “Configuring Done” 表示配置工作已经完成。
接下来点击 Generate 按钮即可生成所选版本的 Visual Studio 工程文件，生成的文件位于 vsprojects 目录。
我们可以在界面上点击按钮 Open Project 按钮直接打开工程文件，也可以找到对应目录下的 libuv.sln 打开。</description>
    </item>
    
    <item>
      <title>利用 telnet 命令发电子邮件</title>
      <link>https://haokiu.com/blog/966ed73cc54b4cf5bdae1e1e5adba616/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/966ed73cc54b4cf5bdae1e1e5adba616/</guid>
      <description>利用 telnet 命令发电子邮件 telnet 命令是我们最常用的网络调试命令之一。如果你的机器上还没有安装 telnet 命令，可以使用如下命令安装一下：
yum install telnet 如果一个服务程序对外开启了侦听服务，我们都可以使用 telnet ip port 来连接上去，例如：
[root@localhost ~]# telnet 120.55.94.78 8888 Trying 120.55.94.78... Connected to 120.55.94.78. Escape character is &amp;#39;^]&amp;#39;. 如果不指定端口号，telnet 会使用默认 23 号端口。
反过来说，可以通过 telnet 命令去检测指定 ip 地址和端口号的侦听服务是否存在。知道这点很重要，我们可以利用这个去检测一个服务是否可以正常连接。举个例子，比如某次从某处得到一个代码下载地址，这是一个 svn 地址：svn://120.55.94.78/mycode/mybook。为了检测这个 svn 服务是否还能正常对外服务，我们可以先用 ping 命令去检测一下到达这个 ip：120.55.94.78 的网络是否畅通：
[root@localhost ~]# ping 120.55.94.78 PING 120.55.94.78 (120.55.94.78) 56(84) bytes of data. 64 bytes from 120.55.94.78: icmp_seq=1 ttl=128 time=15.3 ms 64 bytes from 120.55.94.78: icmp_seq=2 ttl=128 time=14.3 ms 64 bytes from 120.55.94.78: icmp_seq=3 ttl=128 time=16.4 ms 64 bytes from 120.55.94.78: icmp_seq=4 ttl=128 time=16.1 ms 64 bytes from 120.55.94.78: icmp_seq=5 ttl=128 time=15.5 ms ^C --- 120.55.94.78 ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 4007ms rtt min/avg/max/mdev = 14.</description>
    </item>
    
    <item>
      <title>后台C&#43;&#43;开发你一定要知道的条件变量</title>
      <link>https://haokiu.com/blog/3418f291fe18455999e74a1f1dbad72a/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/3418f291fe18455999e74a1f1dbad72a/</guid>
      <description>后台C++开发你一定要知道的条件变量 今天因为工作需要，需要帮同事用C语言（不是C++）写一个生产者消费者的任务队列工具库，考虑到不能使用任何第三库和C++的任何特性，所以我将任务队列做成一个链表，生产者在队列尾部加入任务，消费者在队列头部取出任务。很快就写好了，代码如下：
/*** 线程池工具, ctrip_thread_pool.h* zhangyl 2018.03.23*/#ifndef __CTRIP_THREAD_POOL_H__#define __CTRIP_THREAD_POOL_H__#include &amp;lt;pthread.h&amp;gt;#ifndef NULL#define NULL 0#endif#define PUBLIC PUBLIC struct ctrip_task{struct ctrip_task* pNext;int value;};struct ctrip_thread_info{//线程退出标志int thread_running;int thread_num;int tasknum;struct ctrip_task* tasks;pthread_t* threadid;pthread_mutex_t mutex;pthread_cond_t cond;};/* 初始化线程池线程数目* @param thread_num 线程数目, 默认为8个*/PUBLIC void ctrip_init_thread_pool(int thread_num);/* 销毁线程池*/PUBLIC void ctrip_destroy_thread_pool();/**向任务池中增加一个任务* @param t 需要增加的任务*/PUBLIC void ctrip_thread_pool_add_task(struct ctrip_task* t);/**从任务池中取出一个任务* @return 返回得到的任务*/struct ctrip_task* ctrip_thread_pool_retrieve_task();/**执行任务池中的任务* @param t 需要执行的任务*/PUBLIC void ctrip_thread_pool_do_task(struct ctrip_task* t);/**线程函数* @param thread_param 线程参数*/void* ctrip_thread_routine(void* thread_param);#endif //!</description>
    </item>
    
    <item>
      <title>后台开发应该读的书</title>
      <link>https://haokiu.com/blog/b46f16d0f9f8415e94eb76455deea0f0/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/b46f16d0f9f8415e94eb76455deea0f0/</guid>
      <description>后台开发应该读的书 根据我的经验来谈一谈，先介绍一下我的情况，坐标上海，后台开发（也带团队了），某知名互联网公司。
目前主流的有C++和JAVA，C++我的经验稍微多一点。我就说说我关于C++方面的学习经验。如果您是学生，临近毕业，没有那么多时间读许多书，可以按下面列举的重要程度来参考。
首先，我觉得你应该好好准备算法和数据结构，做到常见的算法和数据结构知识点都能非常熟悉，这样的话你毕业求职的时候可以轻松拿一些大厂（BAT等）的offer。我本人非科班出身，一毕业之后各种摸爬滚打。一毕业去大厂个人觉得有两个好处，第一，你的收入会比一般的的小公司高很多，小公司招人要求相对低一些，薪资给的也少很多，它们是实实在在招能干本职工作活儿的人。第二，你的起点也会比一般进入小厂的同学高。我这里并不是歧视小厂，只是说一种普遍的情况。我本人也是从小厂一路过来的。这里我是强调算法和数据结构的重要性。尤其是应届生求职，更应该去好好准备一下这个，因为这个东西是原理性的基础。企业在面试应届生时不会过分要求项目经验和各种操作系统原理、网络通信原理之类的东西，而唯一能考察一个人的基本功的就是这个了。我是社招进大厂，基本上算法和数据结构这类问题问的比项目经验本身要多许多。但是社招又不太一样，因为除了要准备算法和数据结构以外，还得准备有项目经验、了解操作系统原理、熟悉网络通信、了解数据库、熟悉要求的各种开源框架和技术等等，实在太多了，即使再怎么准备也不一定能一举拿下。相反，应届生基本上只要好好准备算法和数据结构的东西，大学其他专业课学的不是太差，这基本上就是进大厂的捷径。图书方面，你可以使用你们计算机专业的相关教材，也可以使用《数据结构与算法分析:C语言描述》《算法导论》这一类严谨的教材，当然，平心而论我是不敢推荐《算法导论》的，因为这一本书实在是太大部头了，没有好的数学知识，真的很难啃。如果想看一下比较幽默轻松类的书，可以看看程杰的《大话数据结构》。
其次，如果你学有余力，可以看看操作系统原理方面的书籍，当然也可以使用你们的教材，我这里推荐一本我看过的吧，Tanenbaum.A.S《现代操作系统》，Tanenbaum是荷兰人，也是Linux之父Linus Torvalds操作系统方面的启蒙老师。当然，我的建议是这种书毕竟流于理论知识，也不一定要看完，但**一定将一些基础概念，如进程线程内存模式等基础概念看懂理解。**你如果还有时间强烈推荐看看俞甲子的《程序员的自我修养:链接、装载与库》，这本书同时涉及到了Windows和linux两个操作系统平台，用各种辅助工具剖析了程序从源码到二进制文件再到装载到进程地址空间里面的各个细节，甚至连进程地址空间中的堆结构、栈结构也分析得清清楚楚，同时也分析了C Runtime（CRT）、glibc这样的操作系统接口库的原理和执行逻辑，是一本实实在在难得的帮你实战操作系统原理的一本好书。我特别喜欢这个书中序言的一段话：
“CPU体系结构、汇编、C语言（包括C++）和操作系统，永远都是编程大师们的护身法宝，就如同少林寺的《易筋经》，是最为上乘的武功；学会了《易筋经》，你将无所不能，任你创造武功；学会了编程“易筋经”，大师们可以任意开发操作系统、编译器，甚至是开发一种新的程序设计语言！”
再次，你学这些东西是为了将来实践并有产出的，而落实这个产出的东西就是编程语言，如果是入门，我首推C/C++。你只有熟练使用一门编程语言，你才能将你的想法变成现实。注意这里我把C和C++放在一起，但是严格意义上说，C和C++还是有点区别的，但是除了语法上的一些细节差异，基本上可以认为是相通的。个人觉得C语言是所有想成为高手最应该使用的入门语言，不要和我说现在很火的python、go这类语言，“玄都观里桃千树，尽是刘郎去后栽”。我这里也推荐一本C语言方面的图书吧，有兴趣的可以参考一下：《C语言程序设计:现代方法》。至于谭浩强的书就不要提了，还有就是大部头的《C++ Primer》，它虽然是一本好书，但实在是太大部头了。语法层面的东西学会很快，stl库的东西需要实战，也不是翻这类字典一样的书就能很好地掌握的。当然，如果你想掌握好C++，《深度探索C++对象模型》是一定要看的。C++实际编码技巧还有另外一本非常好的书，介绍了常见的C++编码技巧《提高C++性能的编程技术》，建议C++开发的把书中说的技巧全部掌握。
接着说，我们再说说网络方面的，首先网络基础方面的书籍，我就没啥推荐了，现在很多计算机学院也开始使用《计算机网络:自顶向下方法》这本不错的教材，如果没有看过的可以看下。当然还是那句话你一定要看懂而不是看完。比如三次握手和四次挥手的细节，你一定要很清楚。然后你就可以找一本网络编程的实战书来看下，如果你没有使用任何socket api编程的经验，你可以看看韩国人尹圣雨写的这本《TCP/IP网络编程》，这本书从基础的socket api介绍到比较高级的io复用技术，有非常详细和生动的例子。如果你是初级水平，强烈建议看看这本书。网络编程的细节需要注意的地方实在太多了，这本书上都有介绍。很多人尤其是一些学生，写了一些可以相互聊天的小程序就觉得自己熟悉网络通信了，但是这类程序拿到互联网上或者离开局域网，不是连接出错，就是数据总是收发不全。我当年也是这么过来的，看看这本书，你就能明白许多网络故障的原因。等你有了一定的网络编程以后（熟练使用常见socket API），你可以看看游双的《Linux高性能服务器编程》，这本书给没有基础的人或者基础不扎实的人的感觉是，尤其是书的前三章，这书怎么这么垃圾，又把网络理论书上面的东西搬过来凑字数，但是如果你有基础再按照书上的步骤在机器上实践一遍，你会发现，真是一本难得的、良心的书，桃李不言下自成蹊吧。如果你掌握了这本说上说的这些知识，你再看陈硕老师的《Linux多线程服务端编程》或者去看像libevent这样的开源网络库，你会进一步的得到提升。这也是我学习网络编程的一些经验和经历吧。注意这里有必要提一下：像UNP、APUE、还有《TCP/IP详解》这一类书，如果你将来不是专门做网络方面的工作或研究，其实是非常不建议抱着他们看的，因为部头太大，其次太多理论和Unix的东西，花的时间产出投入比很低的。
接着说，以上说的都是一些基础的东西。其实不管是什么开发，后台开发也不例外，你都是需要基于特定的操作系统的，这里不提Windows系统，单单拿linux操作系统来说，既然你选择做这个方面的开发，你需要熟悉这个操作系统平台提供的一些常用的API函数，网络通信方面上文已经说过，除了网络通信还有如操作文件、操作内存、字符串操作、进程线程系列、线程同步系列（如互斥体、条件变量、信号量）、管道等常用的各种API接口函数。这里的意思是，不是要你背诵记忆每一个接口函数的签名，而是你要知道何时该用哪个接口，如何用，有什么注意事项。我入门的时候看的是Robert Love的《Linux系统编程》，熟悉这个人的应该知道，google的工程师，他还有另外一本非常有名的书《Linux内核设计与实现》。
最后，我强调一下，如果你是快毕业的学生，面临着找工作的压力，应该以算法和数据结构为主。如果你是大一大二或研一这个阶段的学生，我上面推荐的书，你还是可以考虑好好咀嚼一下。标准是看懂而不是看完。
再补充一些我觉得要成为高手应该要掌握的东西，先说汇编。虽然第三代第四代语言越来越多，硬件性能越来越好。但是如果你熟练掌握汇编，你就比其他人多很多优势，你会能透彻地知道你写的每一行C/C++代码背后的机器指令的效率。无论是做安全工程还是自己技术提升上都是非常不错的。这里推荐一本王爽老师的《汇编语言(第3版)》，这本书不厚，语言通俗易懂，你也不用刻意去记忆，基本上当小说书看一下就能很快看完了。汇编实战类图书还有另外一本《老&amp;quot;码&amp;quot;识途:从机器码到框架的系统观逆向修炼之路》。我个人是非常喜欢这本书的。当年读这本书的时候，真的有一种“笑看妻子愁何在？漫卷诗书喜欲狂”的感觉。尽管那个时候连女朋友都没有——！
另外补充一些我学生时代看过的书吧，我本人是熟悉Windows和linux两个平台的开发，这也归功于我学生时代看过的一些经典书籍，可能有点跑题了，如果不介意，我可以和你说说：
《Windows程序设计》第五版（第六版以后，这个不再是用Windows Native API写C程序了，而是转到C#平台上了），这本书是中国第一代程序的windows启蒙书籍，你所看到的大多数桌面软件，如QQ，的开发者可能都是通过阅读这本书启蒙起来的。 《Windows核心编程》，这本书搞Windows开发的一定都知道这本书的分量。 《linux内核情景分析》毛德操老师的书，非常的实在，另外他写了一套关于Windows源码分析的书，这本书是基于开源的“Windows”ReactOS，书名叫《Windows内核情景分析》。 《编译系统透视：图解编译原理》，编译原理方面的实践书。 《编程之美》，关于面试的，主要是一些算法和逻辑思维题实战。 《重构：改善既有代码设计》，没有实际写代码经验不推荐看。 《程序员的修炼之道——从小工到专家》这本书特别推荐学生看一下，能大幅度地提高你实际编码的技巧和编码风格。 《代码整洁之道》同上 《大话设计模式》 《Windows PE文件权威指南》 《Java编程思想》 《Effective C++》系列 《80x86汇编语言程序设计教程》 总的来看，我学生时代主要是侧重基础知识来读书的。本科四年、硕士三年，多谢这些书帮助我成长，记得大学毕业的时候，我光读书笔记就有满满十个笔记本。
工作以后，也读了像redis、netty、分布式这一类书。但是那都是工作需要吧。由于我扎实的基础，当然也可能是因为运气成分吧吧，所以得到一些注重扎实的技术基础公司的青睐，给了目前这个阶段看起来还不错的薪资（当然可能还有人比我更厉害，那我这里就贻笑大方了，所以请不喜勿喷）。同时非常感谢我一路上遇到的公司和同事给我的技术上和生活上的帮助。薪资本身不能说明一个人是否成功，我码这么多字，**希望广大的开发者注重基础，勿在浮沙筑高台。尤其是学生，你有大把读书的机会，一定要珍惜大学时光。毕竟工作以后，尤其是毕业后，面临着工作、家庭等各种问题，你可能再也没有心思和完整的时间去学习和提升了。**所以前期的积累很重要，毕竟选择技术这条路，提高技术是升职加薪改善生活水平最直接的方法。最后用我学生时代看到一个技术前辈写的一首诗来结束吧：
仗鼠红尘已是癫，
有网平步上青天。
游星戏斗弄日月，
醉卧云端笑人间。
七载寻梦像扑火，
九州谁共我疯癫？
以上是我的经历，我也曾迷惘和无助过。也有很多朋友找到我，希望我做一些经验分享和职业规划指导，有需要的小伙伴可以加我微信 easy_coder。</description>
    </item>
    
    <item>
      <title>后端开发相关的书籍</title>
      <link>https://haokiu.com/blog/624d2104f4a54c50940f5de425c06ab0/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/624d2104f4a54c50940f5de425c06ab0/</guid>
      <description>后端开发相关的书籍 后台开发应该读的书 </description>
    </item>
    
    <item>
      <title>多线程</title>
      <link>https://haokiu.com/blog/dd345ae60ca14a61866fcc2f232aed74/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/dd345ae60ca14a61866fcc2f232aed74/</guid>
      <description>多线程 后台C++开发你一定要知道的条件变量
整型变量赋值是原子操作吗？</description>
    </item>
    
    <item>
      <title>如何使用 Visual Studio 管理和阅读开源项目代码</title>
      <link>https://haokiu.com/blog/9a2768ae509d48689a05cf010b262b09/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/9a2768ae509d48689a05cf010b262b09/</guid>
      <description>如何使用 Visual Studio 管理和阅读开源项目代码 对于 Linux C/C++ 项目，虽然我们在 Linux 系统中使用 gdb 去调试，但是通常情况下对于 C/C++ 项目笔者一般习惯使用 Visual Studio 去做项目管理，Visual Studio 提供了强大的 C/C++ 项目开发和管理能力。这里以 redis 源码为例，介绍一下如何将这种开源项目整体添加到 Visual Studio 的解决方案中去。
启动 Visual Studio 新建一个空的 Win32 控制台程序。(工程建好后，关闭该工程防止接下来的步骤中文件占用导致的无法移动。) \2. 这样会在 redis 源码目录下会根据你设置的名称生成一个文件夹（这里是 redis-4.0.1），将该文件夹中所有文件拷贝到 redis 源码根目录，然后删掉生成的这个文件夹。
\3. 再次用 Visual Studio 打开 redis-4.0.1.sln 文件，然后在解决方案资源管理器视图中点击显示所有文件按钮并保持该按钮选中。（如果找不到解决方案资源管理器视图，可以在【视图】菜单中打开，快捷键 Ctrl + Alt + L。）
\4. 然后选中所有需要添加到解决方案中的文件，右键选择菜单【包括在项目中】即可，如果文件比较多，Visual Studio 可能需要一会儿才能完成，为了减少等待时间，读者也可以一批一批的添加。
5.接着选择【文件】菜单【全部保存】菜单项保存即可（快捷键 Ctrl + Shift + S ）。
最终效果如下图所示：
这样我们就能利用 Visual Studio 强大的功能管理和阅读我们的源码了。
这里要提醒一下读者：C/C++ 开源项目中一般会使用各种宏去条件编译一些代码，实际生成的二进制文件中不一定包含这些代码，所以在 Visual Studio 中看到某段代码的行号与实际在 gdb 中调试的代码行号不一定相同，在给某一行代码设置断点时请以 gdb 中 list 命令看到的代码行号为准。</description>
    </item>
    
    <item>
      <title>如何成为一名合格的 C/C&#43;&#43; 开发者？</title>
      <link>https://haokiu.com/blog/79cb378b756e457cbcb3a3c669a8e4c0/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/79cb378b756e457cbcb3a3c669a8e4c0/</guid>
      <description>如何成为一名合格的 C/C++ 开发者？ 写在前面的话 在大多数开发或者准开发人员的认识中，C/C++ 是一门非常难的编程语言，很多人知道它的强大，但因为认为“难”造成的恐惧让很多人放弃。
笔者从学生时代开始接触 C/C++，工作以后先后担任过 C++ 客户端和服务器的开发经理并带队开发，至今已经有十多年了。虽然时至今日哪种编程语言对我来说已经不再重要（我目前主要从事 Java 开发），但 C/C++ 仍然是笔者最喜欢的编程语言。在我看来，C/C++ 一旦学成，其妙无穷，就像武侠小说中的“九阳神功”一样，有了这个基础，您可以快速学习任何语言和编程技术。
C/C++ 的当前应用领域 需要注意的是本文不细分 C与 C++ 的区别，通常情况下，C++ 可以看成是 C 的一个超集，在古典时期，可以认为 C++ 就是 C with classes。虽然如今的 C++ 从功能层面上来看，离 C 越来越远了；但是从语法层面来上来看，大多数 C++ 语法还是与 C 基本一致的——所谓 C++ 的面向对象特性，如果细究 C++ 类方法的具体语法还是 C 的过程式语法。当然，面向对象是一种思想，语言本身对其支持的程度固然重要，能否熟练使用更要看开发者的水平。
C 语言目前主要用于像操作系统一类偏底层的应用开发，包括像 Windows/Linux 这样的大型商业操作系统，以及嵌入式操作系统、嵌入式设备上的应用。还有一些开源的软件，也会选择 C 开发，这些系统主要优先考虑程序执行效率和生成的可执行文件的体积（C 代码生成的可执行文件体积相对更小），当然还有一些是历史技术选型问题，这类软件像 Redis、libevent、Nginx，目前像国内的电信服务商所使用的电话呼叫系统，一般也是基于一款叫 FreeSWITCH 的开源 C 程序做的二次开发（项目地址：https://freeswitch.com/ ）。
C++ 面向对象的语法与 C 相比较起来，在将高级语言翻译成机器二进制码的时候，C++ 编译器在背后偷偷地做了大量工作，生成了大量的额外机器码，而这种机器码相对于 C 来说不是必须的。例如，对于一个 C++ 类的实例方法，编译器在生成这个方法的机器码时，会将函数的第一个参数设置成对象的 this 指针地址，以此来实现对象与函数的绑定。正因为如此，许多开发者会优化和调整编译器生成的汇编代码。
我们再来说说 C++。C++ 的应用领域目前有三大类，第一类就是我们目前见到的各种桌面应用软件，尤其 Windows 桌面软件，如 QQ、安全类杀毒类软件（如金山的安全卫士，已开源，其代码地址：http://code.ijinshan.com/source/source.html ）、各种浏览器等；另外就是一些基础软件和高级语言的运行时环境，如大型数据库软件、Java 虚拟机、C# 的 CLR、Python 编译器和运行时环境等；第三类就是一些业务型应用软件的后台，像游戏的服务器后台，如魔兽世界的服务器（代码地址：https://github.com/azerothcore/azerothcore-wotlk ）和一些企业内部的应用系统。笔者曾在某交易所从事后台开发，其交易系统和行情系统就是基于 C++ 开发的。
C++ 与操作系统平台 从上面的介绍可以看出，与 Java、Python 等语言相比，C/C++ 语言是离操作系统最近的一种高级语言，因此其执行效率也比较高。但是有得必有失，因为如此，C/C++ 这门语言存在如下特点。
**C/C++ 整套的语法不具备“功能完备性”，单纯地使用这门语言本身提供的功能无法创建任何有意义的程序，必须借助操作系统的 API 接口函数来达到相应的功能。**当然，随着 C++ 语言标准和版本的不断更新升级，这种现状正在改变；而像 Java、Python 这类语言，其自带的 SDK 提供了各种操作系统的功能。
举个例子，C/C++ 语言本身不具备网络通信功能，必须使用操作系统提供的网络通信函数（如 Socket 系列函数）；而对于 Java 来说，其 JDK 自带的 java.</description>
    </item>
    
    <item>
      <title>我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？</title>
      <link>https://haokiu.com/blog/5b6afa35b0644098b8b4d0c853f20358/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/5b6afa35b0644098b8b4d0c853f20358/</guid>
      <description>我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？ 以下内容来自于一名群友的求助，经当事人同意首发于『高性能服务器开发』公众号，文字略有改动，未经许可，不得转载。
（以下文中的“我”乃当事人本人，非文章作者。）
群主，您好。我是一名上海一名 C++ 客户端开发，最近遇到了点私人问题，请群主帮我参考一下。以下是我的问题：
我是一名程序员，很爱我的女友，谈婚论嫁时，女友要求我用两年的工资作为彩礼，我该不该答应？
（一）
我老家是湖北黄石的，大学就读于武汉某学校，2018 年 7 月毕业，辗转来到上海。由于学历不太好，加上大学荒废了四年，在上海找了近一个月工作之后，终于 2018 年 7 月底上海找了一份 做 PC 客户端开发的工作，使用 C++ 语言。公司是做金融系统平台定制的，主要业务是股票交易系统，为此招了很多数据分析师，女孩子比较多。我就在这家公司认识了我现在的女朋友，她也是一名数据分析师，她是江苏人，也是在武汉上的学，大学毕业时在券商实习做过柜台，所以业务比较熟悉。平常她需要和我们这些开发进行对接，一来二去我们就熟悉了。有一次无意中一起下班，发现我们顺路，后来我们就经常一起加班下班，我向她请教业务问题，她和我了解系统实现逻辑。
后来一段时间，我发现她每天早上来的很晚，而且总是眼睛红红的或者像是没休息好的样子。于是，我趁着下班的机会，问她怎么了，可是她总是说没事。终于有一天晚上我们一起下班回家的日子，她告诉我原因了：她前男友那段时间总是打电话找她，请求复合，她已经和前男友分手快一年了，她前男友回了老家，她来到了上海。现在她男朋友生了病，据她描述应该病的不轻，她拒绝了他的复合要求，但是她心里觉得很过意不去，对于一个病人这样做是不是太残忍了。但是，她又不想复合，虽然她的前男友平常对她很好，但前男友是个喜怒无常且无任何人生规划的人，还有一点点家庭暴力倾向。（画外音：小方群主看到这里惊呆了，好狗血的剧情。。。）
后来，某天晚上在公司附近的公园的草坪上我不断的安慰她，让她想开一点，既然分手了，又有顾忌，就不要再想前一段感情了，建议她向前看。
又过了几天，她说她想通了，这次决定放下。那天晚上，我去了她租的房子。之前，她每次只允许我走到她小区门口，从不允许我进去，调侃我说我“图谋不轨”。那天晚上，我真是感到受宠若惊，聊的比较晚。后来不知道因为什么事情，她又说起了她的前男友如何可怜，我当时很生气，抓起我的书包就准备走。她突然一把抱住我，并且强吻了我。我当时就木头了，单身二十三年，女孩子手都没摸过，更不用说和女孩子接吻了。那感觉，当时脑子就不清醒了。然后，她反问我：XXX，你是不是想追我？我当时小心翼翼地回答是。她说让她考虑一下，然后就让我先回去了。
我一宿未眠，不知道她如何想的。第二天一大早就去了公司，可是一上午都没看到她来公司，我给她发微信打电话也没人回。终于，下午她终于来公司了，而且看起来精神状态不错。她神秘兮兮的和我说晚上一起吃饭。
晚上我们一起在公司的楼下食堂吃饭，她说她和她前男友好好的聊了一下，把事情说清楚了。她不会再想她的前男友，并且接受我的追求。那天，当她告诉我她愿意接受我的时候，我非常的开心。
（二）
接下来的日子，应该是我人生中最开心的一段日子了。我发现，我们对文学都很感兴趣，我们一起聊《红楼梦》《雷雨》《巴黎圣母院》《飘》《百年孤独》《海上钢琴师》等一些国内外的经典著作和电影，她和我聊她之前在深圳和小伙伴们的趣事，还有一些我从未听过的文学作品，她的学识令我佩服。
那段时候，下班以后，我俩骑着共享单车在华师和同济大学的校园里漫游，有时候手拉手在河边散步，无话不谈，真的佩服她的文学素养和对世界的认识。而且让我惊喜的是，她有一手好厨艺，我琢磨着和她自小的家庭环境有关系吧。周末她烧饭时，从来不让我洗碗，而且一个人全包了从买菜到炒菜煮饭、饭后洗碗、打扫的全过程。我们一起玩王者荣耀和英雄联盟，她对这两个游戏也很感兴趣。
周末有的时候我们会一起去南京路步行街逛街、看看电影，我觉得她是个非常独立的人，她每次买东西都不会让我付钱，而且我之前断断续续借给她五六千块钱，在一次闹矛盾后也一分不少的还给我了。当然后来，我们又和好了。
在交往中，我知道了她的家庭状况。家在苏北农村，父母务农。家里有一个哥哥，高中没读完就辍学了。父母比较对哥哥比较宠爱，从小对她管不多，她经常和家里吵架。她从小的愿望就是将来离开家。所以她一个人去武汉上学，毕业后一个人去深圳，干了一年来到上海。但是，她的哥哥从小对他很好，她很感激。唉，这个&amp;quot;好&amp;quot;字，埋下了我后来的悲剧。
在一个周五的晚上，我们去了一家很有特色的古风饭店吃了顿饭，我们一起喝了点店里的招牌酒水——女儿红。她貌似喝醉了，脸红扑扑的，回来的路上，她一边挽着我的手一边给我唱王菲的情歌。那天星光下，她穿着一套白色的裙子，像个仙子一样美丽。那天，我也很开心，心里想：她的独立自强以及读了那么多书，具有一种一般女孩不具有的知性美，还有她的勤劳质朴，在现在的女大学生中实在太少了，这应该是我理想中的对象吧。
顺理成章，那天晚上，我们在她的租的房子里面发生了关系，我很意外的是，她竟然还是个chu。我问她后不后悔，她意味深长的问我，你知道女儿红这酒名的来历吗？我说不知道。她说，古时候，穷人家的父亲会在女儿出生的那一天，把一坛白酒用红色的布包好藏在地窖里，等女儿长大出嫁那一天会拿出来，送给出嫁的女儿和女婿。所以，她不后悔，并安慰我她爱我，这是迟早的事情。那天我暗暗下定决心，一定一辈子对她好。
（三）
后来，有了第一次以后，我就经常在她那里过夜了，只不过我们隐藏的很好，公司没人知道我们的关系，我因为工作表现好，工资从六千涨到一万。后来，闲聊时，她和我说她哥哥对她的好，她虽然恨她的父母，但是她觉得她的哥哥挺可怜的，她想嫁给我，但希望我给她家 20 万的彩礼，她哥哥也可以拿着这笔钱娶老婆，她哥哥比她大五岁，她父母很着急，由于她哥哥学历不高没什么文化，又没啥手艺，生活过的很一般，年纪比较大了，家庭状况也不好，所以还没找到老婆，所以她父母压着她希望她在她哥哥的经济上照顾，她想着从小哥哥就照顾她，所以希望能帮哥哥一把。我当时听了这个话，不知道如何回答。20 万的彩礼对我来说，有点多，差不多相当于我现在快两年多的工资收入。我也是农村家庭，父母辛辛苦苦供我上大学。现在毕业了，父母年纪也大了，还有三万多的助学贷款没还完。
我带她回了趟老家，父母很满意，非常开心。在家里催婚的状况下，我尝试着和她沟通过很多次，能不能彩礼钱少一点，结婚本身也要花钱的，她似乎并不想让步。我不敢告诉我的父母，不想让他们本来很开心的心情泼一盆冷水。我很爱她，但是她的这个条件我确实有点为难。甚至有时候，我在想，本来好好的一场可以开花结果的恋爱，怎么感觉有种卖女儿的感觉？
另外还有件事，让我一直耿耿于怀，群主你不要笑（画外音：群主尽量忍住）。有次和她 XXOO 的时候，正在做的时候，她说她哥真的需要一个老婆，我有这方面的生理需求，她哥哥也有的。所以，她希望我能答应她的请求，她想和我过一辈子，但是希望我能理解下她，同意她的要求。我当时听了这话，像吃了苍蝇，立马没兴趣 XO 了。
这个月，她提出来双方父母见个面，希望我们可以定下来，可是我现在很纠结：我不想和她分手，我爱她，而且她的第一次给了我，但是我又不能满足她的彩礼要求。我不敢想这些事，现在上班也没心思。群主作为过来人和各位读者，能给我点建议吗？</description>
    </item>
    
    <item>
      <title>我是如何年薪五十万的</title>
      <link>https://haokiu.com/blog/7a566da932f2481388ca678c2dc2c1ac/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/7a566da932f2481388ca678c2dc2c1ac/</guid>
      <description>我是如何年薪五十万的 以下经历希望对广大程序员同行有点启发。
1
我姓方，码农一枚，14 年硕士毕业于某 211 学校，哎，这里就不提母校了。人到中年，还没混出什么名堂，就不给学校丢脸了。经常很多人问我现在的收入多少，这个嘛，男人的收入就和女人的身高一样是个秘密。不过，今天姑且聊一聊这个话题。
2
我的第一家公司做 Windows C/C++ 开发，第二家公司做 Linux C++ 开发，第三家公司是某大型互联网公司，以 C++ 技术专家的加入，同时从事 C++ 和 Java 开发。我大学学的非计算机专业，非科班出身的劣势就是参加大厂的校招时，筛选简历那一关直接给你 pass 掉了，这也是我毕业时未通过校招去大厂的原因之一。之所以走到今天靠的是自己的兴趣加上一些运气，当然也离不开很多人的帮助。大学时早年自学 Web ，熟悉 html 5 标准前的各类前端开发技术和 PS 等软件，后痴迷 Flash 编程，做过很多 Flash 动画自娱自乐，2011 年大学毕业时先后在上海一家开发 Flash 整站和一家做网页游戏公司任 Flash 程序员，第一家公司实习工资 1500，第二家公司正式员工月薪 3000。许多年后，我和第二家公司的 Flash 主程再聚首时，他告诉我其实我当时作为一名应届生 3000 的工资并不低，当时他作为项目负责人工资也才 8000。当然，据他说，经过这么多年后，在经历了几次创业失败后他也回归于平淡，在张江一家做游戏的公司安安心心地上班。
3
我的大学后半段时间，真的非常痴迷于 Flash，那个时候觉得 Flash 就是整个人生的意义，并为此写过很多轻狂的话，像什么“你 flash一下子，我爱你一辈子，真像个傻子”、“让我们高举 Flash 伟大旗帜，紧密地团结在以 Adobe 为核心的富媒体公司周围，紧随乔纳森．盖伊的脚步，不舍昼夜的编程，把我国的 RIA 事业全面推向现代化！” 那个时候，坐五个小时的火车来上海，就为去上海书城买一本全英文版的《Flash 编程精髓》，甚至为了一份 flash 开发的工作差点儿放弃读研究生。时过境迁，八年后的今天，浏览器原生支持很多以前仅能通过 flash 实现的技术和效果，Adobe 公司宣布不再更新 flash，各个浏览器逐步禁用乃至不再支持 flash。真是让人唏嘘不已啊。
大四正式离校的前一天晚上在逛蓝色理想站点时，发现有人在一篇帖子上推荐《Windows 程序设计》（第五版）这本书，看了下目录，果断购买，听说过这本书的读者应该知道，这本书一百多块钱，老厚了。这本书可谓是改变我整个人生轨迹的一本书吧，这本书介绍了 Windows 操作系统上程序运行的原理，直接利用操作系统提供的 API 进行编程。愈看这本书，我愈喜欢，它介绍了很多操作系统层面的原理，从前很多在 flash 平台不明白的东西一下子变得清晰起来，从前很多 flash 平台提供的类库不知道该如何使用一下子明白了为什么要那么设计了，后面又陆陆续续地看了《Windows 核心编程》等书。整个人更意识到对底层原理和计算机基础科学的掌握的重要性。于是等到硕士毕业时，我可以去一些公家单位从事地质相关的工作，去互联网业务做前端开发（也包括 flash 开发），但是我还是很倔强啊，薪资高低和工作地点并不是我考虑的因为，我就要做 Windows C++ 开发。当年非 flash 不嫁，如今却非要嫁给另外一个人。哎，人这辈子啊，真的可能会爱上很多人，工作、兴趣亦如是。
4
让我们来复盘一下这段经历，整个学生生涯，大学期间学的是 web 开发和 flash 编程，硕士期间学的是 Windows C++，并针对性地补充很多计算机科学的基础知识，也看了不少“闲杂知识”，如汇编、逆向、安全工程等等，当然都是自学。人的经历是有限的，自学的太多其他东西，很可能让你的专业课就变得一塌糊涂。我也是这样，所以，我特别理解 CSDN 上那位叫 moreWindows 的前辈在读研期间的痛苦，好几次想辍学去做开发。但是，作为过来人，我也想劝来者：如果你有机会读研一定去读个研究生，哪怕是自费或者非全日制的，你现在不明白，会有明白的一天，我们大多数人都不是命运的幸运儿，所以有时候学历还是有点用的。
前期学习 Web 开发技术，让我对 html、javascript、CSS 等非常熟悉，而且我读了非常多的 web 方面的经典书籍，也熟悉 web 标准，那个时候讲究的是三层分离（即表现层、样式层和行为层要分离），加上后来又学习了 web 后端开发技术（主要是 php），我的水平具备开发一个商业的 web 整站的水平。这段经历，让我熟悉了很多计算机和软件开发的一些基础理论和设计原则，如 URL、相对路径等概念。</description>
    </item>
    
    <item>
      <title>我的 2019</title>
      <link>https://haokiu.com/blog/fce122b624fd44a88df285c221d765b8/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/fce122b624fd44a88df285c221d765b8/</guid>
      <description>我的 2019 2019 年就这么悄无声息的过去了，我并不是一个喜欢缅怀过去的人，很多人喜欢回忆过去经历的困难，但就我倒是认为如果过去的苦难不能对将来生活质量或者人生经验有帮助，那这些苦难其实相当于白挨了。
从学生时代开始，每年在年末时都会总结一下过去的一年，给自己复盘，总结一下过去一年的得失。成年人的生活没有谁是容易的，而成年人的工作和交往大多数都是逐利的，只是有些是直接的，有些是间接的。当然，这也无可厚非，大家的目的虽然功利却也高尚，都希望给自己和家人或者爱的人提供更好的生活质量。
工作 先来说说我的工作吧。我是一名地地道道的程序员。我于 2018 年 12 月底从携程旅行网离职，应朋友邀请一起合伙创业，投资人是一知名大佬，创业的项目是基于区块链的期货交易系统，项目从 2018 年年底开始启动，从零开始开发，于 2019 年 8 月份正式全球上线，8 月后开始优化和重构部分框架。
整个交易系统分为场上系统和场下系统，场上系统是交易系统的核心系统，一共有多个服务，从功能上有下单服务、清算服务、撮合服务、条件单服务、K 线服务和行情推送服务，场下系统为交易非核心系统，包括指数服务、管理系统等。使用的开发语言是 Java 和 C++，行情服务使用的是 C++，其他所有服务使用的是 Java，另外我们的客户端有 Web 端和手机端（安卓和 ios）。服务与服务之间使用 Kafka 作为消息中间件，数据存储和查询使用 mysql 和 ElasticSearch。交易核心系统开发要求比较高，无论是对性能还是代码的质量的要求比较高，交易系统非核心部分，例如管理系统，由于只是给内部运营团队使用，要求不高做的相对来说粗糙一些，其技术原理也比较简单（各种对数据库进行增删改查的 RESTFUL 接口），但由于功能比较多，工作量也比较大。除了这些技术栈外，还用到了 zookeeper、consul、Prometheus 等。
互联网时代市场动态和风口转瞬即逝，因此我们需要尽快把产品做出来。从立项之初，我们自己公司技术人员加上我一共有 3 位，另外一位是邀请我的朋友，还有一位是我从携程&amp;quot;忽悠”过来的一位玩的比较好的同事。为了加快开发进度，加上起初我们对部分业务不是很熟悉或者经验不足，我们花了大约四百万在上海找了一个专门做交易系统的外包团队，外包团队负责主要开发，我们负责 review 代码和把控整体开发进度。原来外包团队承诺我们的是，项目可以在五月份完成，但是由于外包团队本身的质量问题导致后来我们不得不强力干预，甚至完全自己接手。由于外包团队中开发人员的素养问题以及外包团队的 leader 的管理和待遇问题，导致我们直到五月初还看不到一个可以走通基本流程的产品。于是后来我们的策略做了调整，与外包团队所在的公司进行了沟通，吸纳了外包团队中部分还不错的开发人员，对于无法达到我们要求的开发人员停止合作，最终我接手了条件单、撮合服务、K 线服务、行情推送服务等 4 个核心服务的开发，其中行情推送服务使用的是 C++，目前的人员配置中了，只有我同时拥有 C++ 和 Java 技术栈，因此只能我来接手行情推送服务。
其实从我们与外包团队的合作的刚开始的两个月后，我们就觉得行情服务外包团队在预定的工期内无法完成，因此在那个时候我就被安排开始接手这个服务的开发，起初他们给我的一套程序是他们根据之前做过的一个股票服务的行情代码精简来的一个空架子，加上他们的代码有大量我们不需要的无用功能，加上其通信协议与我们的业务并不完全契合，在我花了一周时间熟悉后，我一边在原来的老的上面开发，另外有自己重新设计了一套，经过大家的试用后完全采用了我新的设计。由于 C++ 是我的技术专长，在行情服务基本开发完毕后，八月份上线后到目前没有出现任何问题，所以基本未做过任何的修改。这样为我腾出大量的时间去集中精力去开发和优化条件单、撮合和 K 线服务。
先来说撮合服务吧。在大多数交易系统中，撮合服务是非常核心的一轮。所谓撮合，即根据一定的交易规则（常见的规则是时间优先、价格优先），将用户的报单进行成交，产生成交等相关信息，如果不能成交，则成为市场上的挂单。最初负责这个服务的外包同事，哎，但是由于其工作态度和代码素养问题，写出来的代码真的是&amp;quot;惨不忍睹&amp;quot;。我们与外包团队约定的要求是，撮合服务必须至少达到每秒可以处理 3000 ～ 5000 笔报单的性能。但是其交付后我们测试发现，每秒三百到五百的速度都达不到。但是这个事情的结果在我们整个公司，包括 CEO 都引起来非常大的恐慌。项目上线在即，如果按这个速度，我们的系统注定是个失败的产品。于是后来，CEO 给外包团队的领导施压，强行把这么同事给&amp;quot;撵走&amp;quot;了，并由我来接手，当然压力也落在我的身上，我记得我最初接手的那几周内，CEO 每天跑我工位上来问我撮合现在最新的进展怎样，有时候一天可能会跑两次。我在阅读其撮合代码的过程中，发现这个代码的质量非常差。当然造成撮合效率如此之低有两个主要原因：一是他使用的一个链表去存储所有用户的报单，这样的话，改单或者撤单，寻找某个订单时需要遍历这个链表，当订单数量多的时候，这个过程会很慢。哎，数据结构和算法不用心学的开发人员，真是贻害无穷啊。二是他往 Kafka 中写数据时使用了 Future 接口的 get 方法，熟悉 Java 的同学可能知道，这个是需要等待的，也就是说每往 Kafka 发一次数据都要等待结果返回。这种同步的做法，让整个撮合系统对报单的吞吐量变得很低。于是，在全公司上下尤其是 CEO 的&amp;quot;密切&amp;quot;注视下，我花了大概三个月时间基本重写了撮合服务的所有业务逻辑，而这个外包同事已经做这个做了半年了。
剩下的是条件单服务，所谓条件单就是用户发起的、根据一定规则（例如某个价格指数达到一定值时）才会产生的报单。这个服务也是上文中开发撮合服务的外包同事做的，条件单和撮合服务存在同样的问题，我也重写了全部的业务逻辑，但是由于时间来不及，18 年 8 月份我们上线时由于还没重构完成，我们第一次没有上线这个功能，第一次上线后的一周后我们上线了这个功能。
剩下的就是不太重要的 K 线服务了，K 线服务本身业务并不复杂，但是数据量非常大，原来是外包团队的另外一位同事开发的。原来我们的注意力并没有在这个上面有特别多的关注，主要是其比较简单。但是某天公司的产品同事，在群里发了几张关于我们生产环境的 K 线服务的图，结果某些大周期的 K 线数据竟然和小周期的 K 线数据竟然对不上，我当时真的是无语了。于是我又被安排维护 K 线服务，K 线服务的代码质量其实还是不错的，只不过一些核心的算法竟然不对，例如计算从某天到某天之间有多少小时，这都能算错，而且如果自己稍微验证一下就很容易发现问题。
上面说的四个服务，除了行情推送服务由于早期就使用我开发的版本因此对我来说，很轻松，大家也很放心，但是撮合、条件单和 K 线这三个服务让我承受了很大的压力。我没预料到的是，一个外包团队的某些开发人员开发水平能不靠谱到如此程度，而且还是工作多年的程序员。好在一切都过来了，项目也成功上线了。后来，我们陆续招聘了前端开发人员、测试团队、补齐了自己的产品团队和运营团队，后来我们又招了客服团队。
由于项目任务比较多，我们采用的是 996 模式，但是在 2018 年上半年，我基本上在晚上 12 点之前是没回去过的。当然，我并不认为工作时间与实际的产出会成正比，在团队扩大的过程中也暴露了很多的问题，有我自己的，也有 CEO 和团队其他一些负责人的。有的时候，我其实挺想和 CEO 说让大家每周多休息一天，但是看到当前的现状，我最终还是没开口。</description>
    </item>
    
    <item>
      <title>我面试后端开发经理的经历</title>
      <link>https://haokiu.com/blog/b9e6c063ac4a43aca14c01cc45b2f8fa/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/b9e6c063ac4a43aca14c01cc45b2f8fa/</guid>
      <description>我面试后端开发经理的经历 我去年12月份从上一家公司离职，一直到今年3月份，基本上都在面试中度过来的。
先交代下背景：坐标上海，做技术开发，我本人面试的职位是linux服务器开发，最倾向的职位是服务器开发主程或技术经理。我本人也是上几家公司的面试官，因为接下来几年面临着成家，技术上也到了瓶颈期，虽然拿了不少offer，但是想综合比对一下，于是就参加了很多的面试。我先后去了如下一些公司：腾讯、百度、饿了么、爱奇艺、360、携程网、京东、华为、bilibili、上海黄金交易所、东方财富网、zilliz、掌门集团(做无线万能钥匙的那一家)、喜马拉雅听书、峰果网络、华尔街新闻、万得财经、汇正财经、逗屋网络、朝阳永续，还有数家小规模的公司或创业公司吧。
为了避免引起不必要的纠纷，下面我就不说具体的公司名称了。技术面试的细节我尽量写的详细一点，希望对大家有参考价值，技术面试大致有三种情形：
经验分享 一、以百度、爱奇艺等为代表的，以数据结构和算法为主。
首先是简单地了解下你之前的工作经历和项目经验，然后就是算法和数据结构题目，具体涉及到以下内容：
01
快速排序
快速排序（包括算法步骤、平均算法复杂度、最好和最坏的情形），有人说校招要把算法写出来，我是社招，所以描述一下算法步骤即可。
02
二分查找算法
写二分查找算法，这个尽管是社招，但是一般也不难，所以要求面试者写出来。但是很多公司，比如不会直接让你写算法，而是结合一个具体场景来提问，然后让你自己联想到二分查找，比如求一个数的平方根。
03
链表
链表，常见的面试题有写一个链表中删除一个节点的算法、单链表倒转、两个链表找相交的部分，这个一般必须得完全无误的情况下写出来。
04
自己实现一些基础的函数
自己实现一些基础的函数，例如strcpy / memcpy / memmov / atoi，同样的道理，这些必须完全无误且高效地写出来，比如你的实现中会动态分配堆内存，那么这道题目就算答错。
第3点和第4点的门道一般在于考察你的代码风格、对边界条件的处理，比如判断指针是否为空，千万不要故意不考虑这种情形，即使你知道也不行，只要你不写，一般面试官就认为你的思路不周详，容错率低；再比如，单链表的倒转，最后的返回值肯定是倒转后的链表头结点，这样才能引用一个链表，这些都是面试官想考虑的重点。
05
哈希表
哈希表，对哈希表的细节要求很高，比如哈希表的冲突检测、哈希函数常用实现、算法复杂度；比如百度二面就让我写一个哈希表插入元素算法，元素类型是任意类型。
06
AVL树和B树的概念、细节
AVL树和B树的概念、细节，比如会问mysql数据库的索引的实现原理，基本上就等于问你B树了。
07
红黑树
红黑树，这个基本上必问的一个数据结构，包括红黑树的概念、平均算法复杂度、最好最坏情况下的算法复杂度、、左右旋转、颜色变换。面试官常见的算法套路有：你熟悉C++的stl吗？你说熟悉，ok，stl的map用过吧？用过，ok，那map是如何实现的？红黑树，ok，那什么是红黑树？这样提问红黑树就开始了。Java的也类似。
二、以饿了么、bilibli、喜马拉雅、360、携程等为代表的，兼顾算法数据结构和其他开发技术。
算法和数据结构部分上文提过了，下面提一下其他技术，大致包括以下东西：
01
基础的C++问题
以C++语言为例（不是C++开发的朋友可以跳过这一点），第一类是基础的C++问题，常见的有C++的继承体系中virtual关键字的作用（如继承关系中析构函数为什么要申明成virtual函数，如果不申明为virtual会有什么影响)、在涉及到父子类时构造与析构函数的执行顺序、多重继承时类的成员列表在地址空间的排列；static关键字的作用，static_cast / reinterpret_cast / dynamic_cast等几个转换符的使用场景;问的最多的就是虚表的布局，尤其是菱形继承(B和C继承A，D继承B和C)时每个对象的空间结构分布，比如问D有几份虚表，D中B和C的成员空间排布。
另外，如果你应聘的职位使用C++开发，很多公司会问你一些C++11的东西（或者问boost库，基本上都一样），这个你用过就用过，没有用过就说没用过不要装X，常见的C++11需要掌握的一些技术库我也列举一下吧（JAVA及其他语言的读者可以忽略）：
auto关键字、for-each循环、右值及移动构造函数 + std::forward + std::move + stl容器新增的emplace_back()方法、std::thread库、std::chrono库、智能指针系列（std::shared_ptr/std::unique_ptr/std::weak_ptr）(智能指针的实现原理一定要知道，最好是自己实现过)、线程库std::thread+线程同步技术库std::mutex/std::condition_variable/std::lock_guard等、lamda表达式（JAVA中现在也常常考察lamda表达式的作用）、std::bind/std::function库、其他的就是一些关键字的用法(override、final、delete)，还有就是一些细节如可以像JAVA一样在类成员变量定义处给出初始化值。
02
网络通信问题
网络通信问题，比如协议栈的层级关系，三次握手和四次挥手的【细节】，注意我说的是细节，比如CLOSE_WAIT和TIME_WAIT状态（bilibili问了这样一个问题，你可以感受一下：A与B建立了正常连接后，从未相互发过数据，这个时候B突然机器重启，问A此时的tcp状态处于什么状态？如何消除服务器程序中的这个状态？
万得问过流量拥塞和控制机制、腾讯问过tcp和ip包头常见有哪些字段），阻塞和非阻塞socket在send、recv函数上的行为表现，异步connect函数的写法，select函数的用法，epoll与select的区别，基本上只要问到epoll，必问epoll的水平模式和边缘模式的区别；一些socket选项的用法，nagle / keepalive / linger等选项的区别；tcp / udp的区别和适用场景；通信协议如何设计避免粘包；http协议的get和post方法的区别（问的比较深的会让你画出http协议的格式，参照这篇文章中关于http协议格式的讲解：http://blog.csdn.net/analogous_love/article/details/72540130）；windows用户可能会问到完成端口模型(IOCP)，网络通信方面的问题，我专门开了一个知乎live系统地总结了一下，有兴趣的朋友可以看这里：https://www.zhihu.com/lives/922110858308485120 和 这里：https://www.zhihu.com/lives/902113324999778304。
总之，网络通信问题能搞的多清楚就可以搞的多清楚，最起码把tcp应用层的各种socket API的用法细节搞清楚。
03
操作系统原理性的东西
比如linux下elf文件的节结构，映射到进程地址空间后，分别对应哪些段，相关的问题还有，全局变量、静态存储在进程地址空间的哪里；堆和栈的区别，栈的结构，栈的细节一点要搞的特别清楚，因为一些对技术要求比较高的公司会问的比较深入，例如京东的一面是让我先写一个从1加到100的求和函数，然后让我写出这个函数的汇编代码（JAVA开发的同学可能会让你试着去写一点JVM的指令），如果你对栈的结构（如函数参数入栈顺序、函数局部变量在栈中的布局、栈帧指针和栈顶指针的位置）不熟悉的话，这题目就无法答对了；栈的问题，可能会以常见的函数调用方式来提问，常见的函数调用有如下__cdecl/__stdcall/__thiscall/__fastcall的区别，比如像printf这样具有不定参数的函数为什么不能使用__stdcall；还有就是进程和线程的联系与区别，问的最多的就是线程之间的一些同步技术，如互斥体、信号量、条件变量等(Windows上还有事件、临界区等)，这些东西你必须熟悉到具体的API函数使用的层面上来，从另外一个角度来说，这是咱们实际工作中编码最常用的东西，如果你连这个都不能熟练使用，那么你肯定不是一个合格的开发者；这类问题还可以引申为什么是死锁、如何避免死锁；进程之间通信的常用技术也需要掌握，常用的通信方式（linux下）有共享内存、匿名和具名管道、socket、消息队列等等，管道和socket是两个必须深入掌握的考察点（与上面网络通信有点重复）；linux系统下可能还会问什么是daemon进程，如何产生daemo进程，什么是僵尸进程，僵尸进程如何产生和消除（bilibili问过）。
CAS机制（饿了么二面问过）。
04
使用过的开源技术
第四类就是一个使用过的开源技术，比如代表nosql技术的redis；网络库libevent等等；数据库如mysql的一些东西。这个一般不做硬性要求，但是这里必须强调的就是redis，熟练使用redis甚至研究过redis源码，现在一般是做后台开发的技术标配或者说不可缺少的部分，基于redis的面试题既可以聊算法与数据结构，也可以聊网络框架等等一类东西。我面试的公司中基本上百分之九十以上都问到了redis，只是深浅不一而已，比如喜马拉雅问了redis的数据存储结构、rehash；bilibili问了redis的事务与集群。
三、只问一些做过的业务或者项目经验。
这类公司他们招人其实对技术要求不高（资深及主管级开发除外），只要你过往的项目与当前应聘职位匹配，可以过来直接上手干活就可以了，当然薪资也就不会给很多。比如游戏公司会关心你是否有某某类型的游戏开发经验、股票类公司会关心你是否有过证券或者交易系统的开发经验等。我的经验就是这类公司，能去的话可以去，不能去的话就当积累面试经验。业务开发哪里都能找到，真正的重视技术的公司，应该是广大做技术尤其是初中级开发的朋友应该值得关心的事情。
不靠谱型公司。 我遇到的大致有四类：
01
装X忽悠型
第一类：装X忽悠型
面试过程冗长繁琐，比如号称每一百份简历中才发一个面试邀请，号称每一百个面试者发一个offer，号称硅谷风格，我面试的有一家公司就是这个样子，先是一轮长长的电话面试，然后是五轮技术面试，前三轮是刷leetcode上原题，然后后几轮面试，面试官从基本的操作系统的中断、GDT、LDT、分表分页机制问到上层高并发海量数据的架构，说的不好听，真是从外太空聊到内子宫，最后问具体职位做什么时，要么遮遮掩掩要么原型毕露；或者讨论薪资时，要么面露难色要么各种画饼，但是实际就给不了多少薪水的。
02
佛性公司
第二类：佛性公司
面试下来，全程面试官面带微笑，问你的问题你回答的面试官也很赞同，但最后你就没通过，我猜测要么公司不是很缺人，想观望一下是否有合适的人才；要么招聘信息上开的薪资给不到。
03
老奶奶裹脚布型公司
第三类：老奶奶裹脚布型公司
其特点是面试周期长，往往第一轮面试通知你过了，让你回去等上十天半个月后，给你打电话通知你来第二轮面试，面试要求穿正装，带好各种证件，面试前必须先查验你的身份证、学历证学位证，甚至是四六级考试证等等，麻烦至极，即使你一路过关斩将过了终面，薪资也给不了多少。大家都是要养家糊口的，都是忙着找工作，谁有时间和你耗上十天半个月呢？
04
不尊重人类型公司
第四类：不尊重人类型公司
我这里说的不尊重人，不是指的是面试过程中对你人身攻击，而是不根据你的工作年限和经验随意安排面试官，举个例子，比如你工作十年，你去面试一个技术总监的职位，对方公司安排一个工作不满两年的部门职员作为面试官，这个面试官如果是走过场可以理解，但是非要和你纠结一个如二进制位移、现代编译器要不要在子类析构函数前加virtual关键字这些技术细节就没必要了。还有一类就是故意问一些刁钻的问题，或者全场都心不在焉、玩手机、漫不经心的面试官，比如问你tcp协议头有多少个字段，每个字段是干啥的。遇到这一类面试官我的经验就是要么婉拒，要么直接怼回去。
注意细节 下面再说下面试中需要注意的一些细节：
01
把目光放长远一点
第一，如果你的工作年限不长，尤其是渴望在技术方面有一定的造诣，那么你首先考虑的应该是新的单位是否能有利于你技术上的成长，而不是两份同样的工作，薪资上的上下相差的三五千、五六千。如果想转行的同学（比如从客户端转服务器，从C++转JAVA），不要因为薪资突然变低而拒绝这种阵痛，要把目光放长远一点。
02
可能最终会因为薪资达不到不被录取</description>
    </item>
    
    <item>
      <title>技术面试与HR谈薪资技巧</title>
      <link>https://haokiu.com/blog/d949dd8f005d45c7b6c71ea9a87a0712/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/d949dd8f005d45c7b6c71ea9a87a0712/</guid>
      <description>技术面试与HR谈薪资技巧 作为“生在红旗下，长在春风里”的“四有新人”（现在90后00后还有知道这个词的吗？^_^），张小方同志从毕业至今，与各路HR、HRD斗智斗勇，再加上自己的不懈努力，历尽千辛万苦终于将毕业时的1500每月的薪资提高了二十几倍。本文就和大家唠唠这些年风里来雨里去无数次铩羽而归、兢兢业业、如履薄冰、诚惶诚恐、夜不能寐、枕戈待旦、惴惴不安、临盆一脚，最终守得云开见月明的谈薪经历。当然，本文说的主要是技术面试中谈薪的经历，主要针对的是一些社会人士求职，当然一些通用的原则同样适用于应届生求职。
面试官的级别 一般技术面试的模式是 n + 1 或者是 1 + n + 1，什么意思呢？其中 n 指的是你见到的不同级别的面试官的个数，1 指的你见到的hr。
两种模式 模式一：一般技术面试有两种情形，你进入公司以后，会让你填写一些个人资料，如果有笔试题，也会做一些笔试题，接着HR会先找你简单地聊几句了解一下你的情况，然后通知技术面试官过来面试，如果一轮或者多轮技术面试后，面试官觉得你还不错，HR会接着详细地了解一下你的情况，如之前做什么工作的、是否已经离职、是否成家有小孩，当然最最关键的是询问你期望的薪资。这就是所谓的“1 + n + 1”模式，即开始由HR面试，中间是技术面试，最后还是HR面试。
模式二： 在登记个人信息和笔试（如果有的话）完以后，直接就是技术面试，技术面试结束后如果面试官觉得你还不错，HR会接着进行人事面试。这就是所谓的“n + 1”模式，即开始是技术面试，最后由HR面试。
当然，可能在你去公司现场面试之前，会有一些电话或者远程视频的面试的形式，这类基本上也属于技术面试的范畴。这里就不再赘述了。
面试官的级别和面试轮次 一般公司的的级别是按如下方式划分的：普通员工上面是部门经理（或技术主管），部分经理（或技术主管）上面是总监（即所谓的大领导）（规模小的公司或者扁平化的公司上面就是CTO、副总或者CEO了，因此到这一层就没有了），总监（大领导）上面一般是公司的CTO、副总或者老板了。
如果是应聘初、中级的岗位，第一轮面试官一般是你的职位所在的部门的经理。一般经理觉得没问题，接着就是HR面试了，也就是说就这么两类人来面试你。
如果你面试的是高级、资深岗位，第一轮面试官是所在部门的经理，只要面试表现不是太差，经理会让总监来继续第二轮面试你。如果总监觉得也没有问题，接着就是HR面试了。
如果你面试的是经理或开发主管的职位，第一轮面试一般是相关部门与你职级差不多的部门经理来面试你，注意这一轮大多数一般只是简单地聊一聊（走过场），然后由上一级总监（大领导）来进行第二轮面试（这轮面试很关键），如果这一轮面试也OK的话，会由大领导的上一级，如公司CTO或副总甚至CEO进行第三轮面试甚至第四轮面试。如果以上都没问题，接着就是HR或HRD的人事面试了。
注意，我这里面试的轮次是按职级划分的，而不是按次数划分的。实际上在大多数公司，会由搭配交叉部门的其他同事来面试。举个例子，例如你求职的是高级开发，除了部门经理 A1 和大领导 B 会面试你，部门经理 A1 或者大领导 B 可能会邀请其他部门的某个同事C或者领导A2来面试你，这里的职级按从低到高依次是C &amp;lt; A1 = A2 &amp;lt; B。也就是说，面试官 C 和 A1、A2 这种级别的面试官可能会出现多位。
人事面试 说完了技术面试官的职级和面试次数，再来说说人事面试，一般人事面试是最后一轮面试。你需要注意的是——HR 一般没有决策权，也就是说 HR 没有权利决定你最终的去留，她们只是转达用人部门的意见。当然，也不排除有少数强势的 HR 或 HRD，大多数的HR都没有一票否决权。所以，如果HR和你详谈时，也说明你前面的面试结果不是太差。这个时候，你要做的就是尽量在公司可接受的范围内达到自己利益最大化就可以了。
在我看来，大多数HR虽然看起来美丽大方，但是都是“妖精”，尤其是一些阅人无数的资深HR，那简直是“职场白骨精”（调侃一下，没有恶意，请各位HR勿怪）。
首先，由于她们有自己的绩效考核，即最短时间、最低的成本招到最合适的人才。据我所知，举个例子，比如一个计划最高可以用25K招到的人，现在某个HR用20K就招到了，那节省下来的5K就会算作HR的绩效，所以这也是HR为什么会找你谈工资的目的了，其核心目的其实就是为了压工资。减少人力资源成本是负责招聘的HR的一项重要职责。
其次，由于大多数HR没有否决权，只是忠实地转达用人部门的意见。所以你问她的一些问题，大多数情况下是得不到任何实质性的答案的，一般都是些场面上的官话。所以，你也不用问诸如“面试成绩如何”、“面试官对你的影响如何”、“什么时候给面试结果”之类的傻傻的问题。
当然，HR与你谈论很多问题，其实是通过交流中了解你这个人的性格、反应能力、情商、经历和资历等信息，以最大化地为公司招到一个合适的人，排除一些人事隐患。比如，HR一般会问男同胞是否有女朋友、是否结婚、老家是哪里的等等，这些不是说HR要查你的户口（这个从身份证信息上就能看出来），而是看你这个人未来几年是否稳定，一般成家就意味着责任感，而不是要刺探你的婚姻状况。
当然读者最关心的可能就是如何谈薪资。这里单独来开一节来详细讨论下这个问题。
谈薪的基本要点与脱坑技巧 谈薪是一个与HR斗智斗勇的过程，在谈薪的过程中有很多坑。一般HR会问你期望的薪资，然后就你的报价（请原谅我用这个词，谈好薪确实就等于把自己卖了 - -！）进行讨价还价，当然不和你讨价还价的HR也有，一般有两种：第一种，你的报价实在太高，已经远远超过公司的预算，HR觉得没有谈下去的必要；第二种，天使。第二种，我反正是从来没遇到过。除了总监及以上职位，一般你求职的JD上都会有一个薪资范围，你报价时可以参考一下这个。其次就是，除非你能力特别优秀，面试效果特别好，否则 IT 行业一般的涨薪最大幅度是你前一份工作的百分之三十，也就是说如果你前一份工作月薪是20K，那么你这份工作你最多可以报价27K。
一般与HR谈薪的过程中，即要展示自己对求职的职位有很大的兴趣，但又不要暴露自己想尽快找到工作的想法，尤其是在你手头上没有offer 、且已经离职的情况下，这样会让自己很被动，你迫切需要一份工作，而现在又无多余的选择，这样HR就会使劲压制你的薪资。
HR与你谈论薪资经常有如下套路：
HR: 您期望的薪资是多少？你: 25K。 OK，你已经被HR成功套路。这个时候你的最高价就是25K了，然后HR会顺着这个价往下砍，所以你最终的薪资一般都会低于25K。等你接到offer，你的心里肯定充满了各种“悔恨”：其实当时报价26、27甚至28、29也是可以的。
正确的回答可以这样，并且还能够反套路一下HR：
HR: 您期望的薪资是多少？你: 就我的面试表现，贵公司最高可以给多少薪水？ 哈哈，如果经验不够老道的HR可能就真会说出一个报价（如25K）来，然后，你就可以很开心地顺着这个价慢慢地往上谈了。所以这种情况下，你最终的薪资肯定是大于25K的。当然，经验老道的HR会给你一句很官方的套话：
HR: 您期望的薪资是多少？你: 就我的面试表现，贵公司最高可以给多少薪水？HR: 这个暂且没法确定，要结合您几轮面试结果和用人部门的意见来综合评定。 如果HR这么回答你，我的建议是这样的：
虽然薪资很重要，但是我个人觉得这不是最重要的。我有以下建议：
如果你觉得你技术面试效果很好，可以报一个高一点的薪资，这样如果HR想要你，会找你商量的。 如果你觉得技术面试效果一般，但是你比较想进这家公司，可以报一个折中的薪资。 如果你觉得面试效果很好，但是你不想进这家公司，你可以适当“漫天要价”一下。 如果你觉得面试效果不好，但是你想进这家公司，你可以开一个稍微低一点的工资。 需要注意的是，面试求职是一个双向选择的过程。面试应该做到不卑不亢，千万不要因为面试结果不好，就低声下气地乞求工作，每个人的工作经历和经验都是不一样的，技术面试不好，知道自己的短板针对性地补缺补差就行，而不是在人事关系上动歪脑筋。当然也不要盲目自信，把自己的无知当理所当然，谦虚一点。笔者曾经面试Intel时，因为单词“cache”的读音和面试官争论了很久，面试官读“cash”，我坚持认为读“cake”，这里就闹了一个笑话。
除了和HR谈薪有陷阱，和技术面试官谈薪也一般存在一些陷阱。大多数公司都要求总监级别以下的面试官不得询问面试者期望薪资，但是也不排除一些面试官的个人好奇心，”无意中“向面试者询问该问题。除了级别高的领导，一般面试官是无权询问薪资的，此时面试者就要留心了。如果被问到，可以委婉地回答一下，如可以说：现在还不确定，会按招聘信息的薪资范围和结合自己的面试结果来提出一个期望薪资。如果实在绕不过去这个问题，可以把薪资说的低一点（口头上只是说说而已），实际薪资还是由高层领导决定并最终和HR谈的。原因是因为，在信息不对称的情况下，如果你报的薪资过高，超过当前面试官的薪资，很可能引起当前面试官的不愉快，造成对自己非技术上的差评，造成失去入职该公司的机会。
谈薪资还有一个坑，你一定要搞清楚公司的薪资构成，就是尽量把月薪或者基础薪资谈高一点。说说我之前的两段经历：
经历一：我之前有份工作，HR和我谈的时候，说是月薪14K。但是我实际进去以后，发现14K分为基础工资和绩效工资，这其中6K是基本工资，剩下的8K是绩效工资，而每个月会有一个绩效系数，系数范围是从0.8～1.5，也就是说当你某个月绩效系数是1时，你拿到完整的8K；如果你系数是0.8时，你只能拿到6400，也就是辛辛苦苦干了一个月实际拿到手的只有6000 + 6400 = 12400，平白无故地少了1600。而公司对外宣称你的月薪是14K，还有就是基本上绩效系数在1以上的都没有。</description>
    </item>
    
    <item>
      <title>拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？</title>
      <link>https://haokiu.com/blog/40c71c6aa54540abb1c141d82ca0cd49/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/40c71c6aa54540abb1c141d82ca0cd49/</guid>
      <description>拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？ 网友提问：
拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？
面试的时候双方都感觉还可以，一面后hr开始压价，比预期低了3K，我拒绝。
然后邀请我去复试，跟经理交流后，觉得我可以，然而hr又压价，比预期低了1K，我拒绝，因为我对他们提出的期望薪资是我的最低底线。
然而过去不到1小时，hr说可以给到我期望薪资，并发了offer，但是试用期6个月打8折这个条件我不是很满意，而且offer居然没说明具体薪资组成部分，感觉他们很没诚意，然后思前想后决定发邮件拒绝了。
然而过去三天后，接到他们副总的电话，询问我拒绝原因，说自己公司管理制度如何如何人性化，还说条件可以再谈，非常诚恳也非常谦逊，感觉不好意思拒绝。然后我说自己再考虑考虑。随后hr再次电话来谈条件，说试用期不打折，并把薪资组成部分说的很详细，邀请我加入。
我犹豫了，现在有点纠结，手里还有另一家offer，待遇差不多，但是这家录用我很爽快，感觉我合适就直接发offer了，并说清楚了具体待遇。但是考虑这家公司目前规模和发展趋势不是符合自己预期的，所以也在犹豫中。
反正个人感觉第一家公司想要我但是却各种理由为难我，被我拒绝后又放低标准极力邀请我，这是不是一个坑啊，这么着急招人估计这个岗位肯定是个大坑啊。
现在很纠结，跳槽需要慎重考虑啊，真怕自己跳入一个更大的坑爬不出来。
小方老师建议：
先说结论：现在拿到offer的话，如果比较纠结就都不去，哪怕一家公司都去不了。再找就是了。
说两段我的经验吧，第一段，几年前，在A公司和B公司之间两家公司的offer纠结，A公司离我住的地方太远不想去，B公司感觉氛围不太喜欢，最后在各种纠结中去了B公司，没干三个月受不了离职了。
某年年底找工作时，有个猎头，给我推荐了一个公司，我开始不太想去，因为这家公司我并不了解，所以我和猎头说，除非月薪可以给到30k，否则我不想去，后来猎头反复和对方公司沟通，最终满足了我的要求，但是，猎头说由于对方公司有一定的涨薪限制，所以不能给到月薪30k，但是由于我要求的是30k*13薪，对方公司换了种方式，给26k*15薪，这样一年下来也是39万。我开始是很不愿意这种所谓的变通方法，于是猎头就和他的领导那段时间反复做我的思想工作。我当时也非常纠结要不要去，因为相对于我当前的薪资确实翻了一番，但是我隐约觉得当初面试我的面试官(也就是我进去后我的直系领导)是个&amp;quot;不好相处&amp;quot;的人。后来猎头又反复和我说，面试我的面试官是和乐于传道受业解惑的和蔼可亲的技术大神最终在各种纠结中我还是去入职了。但是没过多久，我就干的很不开心。那个领导的代码风格稀烂，例如写C++代码，没有任何注释文档，甚至所有的实现文件都写在*.h文件中;其次，与人交流非常没耐心，下面的同事问他问题说不到三句可能就不耐烦，所以隔壁组的同事也都不太喜欢他，但是由于这个项目一直是他一个人做也没商业化，所以公司也没多管他。等到他带团队，与其他同事打交道时就暴露各种问题了。更让人受不了的是，他经常在项目要发版本时修改代码，也不通知其他同事，直到我们发现不对劲，排查很久发现问题，他才说。最让我们受不了的是，有次周六周日加了两天班，周六晚上到夜里十二点，周日到凌晨三点，他还冲团队成员发火。所以那天夜里，我四点钟半到家，直接给CTO写了封投诉他的信。
后来的情况不用说了，我当初面试的时顾虑都一一应验了，和我一起来的几个同事，年后都陆续离职了。
我想说的是，不管是薪资还是公司面试的时候面试官和人事的种种举动，如果你有顾虑或者觉得不适合你，千万不要为了钱本身就去了。
小方老师联系方式：微信 easy_coder。</description>
    </item>
    
    <item>
      <title>整型变量赋值是原子操作吗？</title>
      <link>https://haokiu.com/blog/c5ae7c2ab16046b2b12deffde01da947/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/c5ae7c2ab16046b2b12deffde01da947/</guid>
      <description>整型变量赋值是原子操作吗？ 整型变量赋值操作不是原子操作 那么为什么整型变量的操作不是原子性的呢？常见的整型变量操作有如下几种情况：
给整型变量赋值一个确定的值，如
int a = 1; 这条指令操作一般是原子的，因为对应着一条计算机指令，cpu将立即数1搬运到变量a的内存地址中即可，汇编指令如下：
mov dword ptr [a], 2 然后这确是最不常见的情形，由于现代编译器一般有优化策略，如果变量a的值在编译期间就可以计算出来（例如这里的例子中a的值就是1），那么a这个变量本身在正式版本的软件中（release版）就很有可能被编译器优化掉，使用a的地方，直接使用常量1来代替。所以实际的执行指令中，这样的指令存在的可能性比较低。
变量自身增加或者减去一个值，如
a ++; 从C/C++语法的级别来看，这是一条语句，是原子的；但是从实际执行的二进制指令来看，也不是原子的，其一般对应三条指令，首先将变量a对应的内存值搬运到某个寄存器（如eax）中，然后将该寄存器中的值自增1，再将该寄存器中的值搬运回a的内存中：
mov eax, dword ptr [a] inc eax mov dword ptr [a], eax 现在假设a的值是0，有两个线程，每个线程对变量a的值递增1，我们预想的结果应该是2，可实际运行的结果可能是1！是不是很奇怪？分析如下：
int a = 0; //线程1 void thread_func1() { a ++; } //线程2 void thread_func2() { a ++; } 我们预想的结果是线程1和线程2的三条指令各自执行，最终a的值为2，但是由于操作系统线程调度的不确定性，线程1执行完指令①和②后，eax寄存器中的值为1，此时操作系统切换到线程2执行，执行指令③④⑤，此时eax的值变为1；接着操作系统切回线程1继续执行，执行指令⑦，得到a的最终结果1。
把一个变量的值赋值给另外一个变量，或者把一个表达式的值赋值给另外一个变量，如
int a = b; 从C/C++语法的级别来看，这是也是一条语句，是原子的；但是从实际执行的二进制指令来看，由于现代计算机CPU架构体系的限制，数据不可以直接从内存搬运到另外一块内存，必须借助寄存器中断，这条语句一般对应两条计算机指令，即将变量b的值搬运到某个寄存器（如eax）中，再从该寄存器搬运到变量a的内存地址：
mov eax, dword ptr [b] mov dword ptr [a], eax 既然是两条指令，那么多个线程在执行这两条指令时，某个线程可能会在第一条指令执行完毕后被剥夺CPU时间片，切换到另外一个线程而产生不确定的情况。这和上一种情况类似，就不再详细分析了。
说点题外话，网上很多人强调某些特殊的整型数值类型（如bool类型）的操作是原子的，这是由于，某些CPU生产商开始有意识地从硬件平台保证这一类操作的原子性，但这并不是每一种类型的CPU架构都支持，在这一事实成为标准之前，我们在多线程操作整型时还是老老实实使用下文介绍的原子操作或线程同步技术来对这些数据类型进行保护。</description>
    </item>
    
    <item>
      <title>服务器开发中网络数据分析与故障排查经验漫谈</title>
      <link>https://haokiu.com/blog/b7d459605e1d4d46adba41bdb0c66b78/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/b7d459605e1d4d46adba41bdb0c66b78/</guid>
      <description>服务器开发中网络数据分析与故障排查经验漫谈 ​
一、 操作系统提供的网络接口
为了能更好的排查网络通信问题，我们需要熟悉操作系统提供的以下网络接口函数，列表如下：
接口函数名称 接口函数描述 接口函数签名 socket 创建套接字 int socket(int domain, int type, int protocol); connect 连接一个服务器地址 int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); send 发送数据 ssize_t send(int sockfd, const void *buf, size_t len, int flags); recv 收取数据 ssize_t recv(int sockfd, void *buf, size_t len, int flags); accept 接收连接 int accept4(int sockfd, struct sockaddr *addr, socklen_t *addrlen, int flags); shutdown 关闭收发链路 int shutdown(int sockfd, int how); close 关闭套接字 int close(int fd); setsockopt 设置套接字选项 int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); 注意：这里以bekeley提供的标准为例，不包括特定操作系统上特有的接口函数（如Windows平台的WSASend，linux的accept4），也不包括实际与网络数据来往不相关的函数（如select、linux的epoll），这里只讨论与tcp相关的接口函数，像与udp相关的函数sendto/recvfrom等函数与此类似。
下面讨论一下以上函数的一些使用注意事项：
1 以上函数如果调用出错后，返回值均为-1；但是返回值是-1，不一定代表出错，这还得根据对应的套接字模式（阻塞与非阻塞模式）。
2 默认使用的socket函数创建的套接字是阻塞模式的，可以调用相关接口函数将其设置为非阻塞模式（Windows平台可以使用ioctlsocket函数，linux平台可以使用fcntl函数，具体设置方法可以参考这里。）。阻塞模式和非阻塞模式的套接字，对服务器的连接服务器和网络数据的收发行为影响很大。详情如下：
阻塞模式下，connect函数如果不能立刻连上服务器，会导致执行流阻塞在那里一会儿，直到connect连接成功或失败或网络超时；而非阻塞模式下，无论是否连接成功connect将立即返回，此时如果未连接成功，返回值将是-1，错误码是EINPROGRESS，表示连接操作仍然在进行中。Linux平台后续可以通过使用select/poll等函数检测该socket是否可写来判断连接是否成功。
阻塞套接字模式下，send函数如果由于对端tcp窗口太小，不足以将全部数据发送出去，将阻塞执行流，直到出错或超时或者全部发送出去为止；同理recv函数如果当前协议栈系统缓冲区中无数据可读，也会阻塞执行流，直到出错或者超时或者读取到数据。send和recv函数的超时时间可以参考下文关于常用socket选项的介绍。
非阻塞套接字模式下，如果由于对端tcp窗口太小，不足以将数据发出去，它将立刻返回，不会阻塞执行流，此时返回值为-1，错误码是EAGAIN或EWOULDBLOCK，表示当前数据发不出去，希望你下次再试。但是返回值如果是-1，也可能是真正的出错了，也可能得到错误码EINTR，表示被linux信号中断了，这点需要注意一下。recv函数与send函数情形一样。
3 send函数虽然名称叫“send”，但是其并不是将数据发送到网络上去，只是将数据从应用层缓冲区中拷贝到协议栈内核缓冲区中，具体什么时候发送到网络上去，与协议栈本身行为有关系（socket选项nagle算法与这个有关系，下文介绍常见套接字选项时会介绍），这点需要特别注意，所以即使send函数返回一个大于0的值n，也不能表明已经有n个字节发送到网络上去了。同样的道理，recv函数也不是从网络上收取数据，只是从协议栈内核缓冲区拷贝数据至应用层缓冲区，并不是真正地从网络上收数据，所以，调用recv时，操作系统的协议栈已经将数据从网络上收到自己的内核缓冲区中了，recv仅仅是一次数据拷贝操作而已。</description>
    </item>
    
    <item>
      <title>服务器开发案例实战</title>
      <link>https://haokiu.com/blog/5d978400ccba478eaaa6a166b4ffba8d/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/5d978400ccba478eaaa6a166b4ffba8d/</guid>
      <description>服务器开发案例实战 从零实现一个http服务器
从零实现一款12306刷票软件
从零实现一个邮件收发客户端
从零开发一个WebSocket服务器
从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始
从零学习开源项目系列（二） 最后一战概况
从零学习开源项目系列（三） CSBattleMgr服务源码研究
从零学习开源项目系列（四）LogServer源码探究</description>
    </item>
    
    <item>
      <title>服务器开发通信协议设计介绍</title>
      <link>https://haokiu.com/blog/27166845330344e4bf4f9a385e69fc94/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/27166845330344e4bf4f9a385e69fc94/</guid>
      <description>服务器开发通信协议设计介绍 一、选择TCP还是UDP协议 由于我们的即时通讯软件的用户存在用户状态问题，即用户登录成功以后可以在他的好友列表中看到哪些好友在线，所以客户端和服务器需要保持长连接状态。另外即时通讯软件一般要求信息准确、有序、完整地到达对端，而这也是TCP协议的特点之一。综合这两个所以这里我们选择TCP协议，而不是UDP协议。
二、协议的结构 由于TCP协议是流式协议，所谓流式协议即通讯的内容是无边界的字节流：如A给B连续发送了三个数据包，每个包的大小都是100个字节，那么B可能会一次性收到300个字节；也可能先收到100个字节，再收到200个字节；也可能先收到100个字节，再收到50个字节，再收到150个字节；或者先收到50个字节，再收到50个字节，再收到50个字节，最后收到150个字节。也就是说，B可能以任何组合形式收到这300个字节。即像水流一样无明确的边界。为了能让对端知道如何给包分界，目前一般有三种做法：
以固定大小字节数目来分界，上文所说的就是属于这种类型，如每个包100个字节，对端每收齐100个字节，就当成一个包来解析； 以特定符号来分界，如每个包都以特定的字符来结尾（如\n），当在字节流中读取到该字符时，则表明上一个包到此为止。 固定包头+包体结构，这种结构中一般包头部分是一个固定字节长度的结构，并且包头中会有一个特定的字段指定包体的大小。这是目前各种网络应用用的最多的一种包格式。 上面三种分包方式各有优缺点，方法1和方法2简单易操作，但是缺点也很明显，就是很不灵活，如方法一当包数据不足指定长度，只能使用占位符如0来凑，比较浪费；方法2中包中不能有包界定符，否则就会引起歧义，也就是要求包内容中不能有某些特殊符号。而方法3虽然解决了方法1和方法2的缺点，但是操作起来就比较麻烦。我们的即时通讯协议就采用第三种分包方式。所以我们的协议包的包头看起来像这样：
struct package_header { int32_t bodysize; }; 一个应用中，有许多的应用数据，拿我们这里的即时通讯来说，有注册、登录、获取好友列表、好友消息等各种各样的协议数据包，而每个包因为业务内容不一样可能数据内容也不一样，所以各个包可能看起来像下面这样：
struct package_header { int32_t bodysize; }; //登录数据包 struct register_package { package_header header; //命令号 int32_t cmd; //注册用户名 char username[16]; //注册密码 char password[16]; //注册昵称 char nickname[16]; //注册手机号 char mobileno[16]; }; //登录数据包 struct login_package { package_header header; //命令号 int32_t cmd; //登录用户名 char username[16]; //密码 char password[16]; //客户端类型 int32_t clienttype; //上线类型，如在线、隐身、忙碌、离开等 int32_t onlinetype; }; //获取好友列表 struct getfriend_package { package_header header; //命令号 int32_t cmd; }; //聊天内容 struct chat_package { package_header header; //命令号 int32_t cmd; //发送人userid int32_t senderid; //接收人userid int32_t targetid; //消息内容 char chatcontent[8192]; }; 看到没有？由于每一个业务的内容不一样，定义的结构体也不一样。如果业务比较多的话，我们需要定义各种各样的这种结构体，这简直是一场噩梦。那么有没有什么方法可以避免这个问题呢？有，我受jdk中的流对象的WriteInt32、WriteByte、WriteInt64、WriteString，这样的接口的启发，也发明了一套这样的协议，而且这套协议基本上是通用协议，可用于任何场景。我们的包还是分为包头和包体两部分，包头和上文所说的一样，包体是一个不固定大小的二进制流，其长度由包头中的指定包体长度的字段决定。
struct package_protocol { int32_t bodysize; //注意：C/C++语法不能这么定义结构体， //这里只是为了说明含义的伪代码 //bodycontent即为一个不固定大小的二进制流 char binarystream[bodysize]; }; 接下来的核心部分就是如何操作这个二进制流，我们将流分为二进制读和二进制写两种流，下面给出接口定义：</description>
    </item>
    
    <item>
      <title>服务器端发数据时，如果对端一直不收，怎么办？</title>
      <link>https://haokiu.com/blog/bb7da7e0bc524808b2a072fb43da3a8e/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/bb7da7e0bc524808b2a072fb43da3a8e/</guid>
      <description>服务器端发数据时，如果对端一直不收，怎么办？ 这类问题一般出现在跨部门尤其是与外部开发人员合作的时候。假设现在有这样一种情况，我们的服务器提供对外的服务，指定好了协议，然后对外提供服务，客户端由外部人员去开发，由于存在太多的不确定性，如果我们在给对端（客户端）发送数据时，对端因为一些问题（可能是逻辑 bug 或者其他的一些问题）一直不从 socket 系统缓冲区中收取数据，而服务器端可能定期产生一些数据需要发送给客户端，再发了一段时间后，由于 TCP 窗口太小，导致数据发送不出去，这样待发送的数据会在服务器端对应的连接的发送缓冲区中积压，如果我们不做任何处理，很快系统就会因为缓冲区过大内存耗尽，导致服务被系统杀死。
对于这种情况，我们一般建议从以下几个方面来增加一些防御措施：
设置每路发送连接的发送缓冲区大小上限（如 2 M，或者小于这个值），当某路连接上的数据发送不出去的时候，即将数据存入发送缓冲区时，先判断一下缓冲区最大剩余空间，如果剩余空间已经小于我们要放入的数据大小，也就是说缓冲区中数据大小会超过了我们规定的上限，则认为该连接出现了问题，关闭该路连接并回收相应的资源（如清空缓冲区、回收套接字资源等）。示例代码如下：
//outputBuffer_为发送缓冲区对象 size_t remainingLen = outputBuffer_.remainingBytes(); //如果加入到缓冲区中的数据长度超出了发送缓冲区最大剩余量 if (remainingLen &amp;lt; dataToAppend.length()) { forceClose() return } outputBuffer_.append(static_cast&amp;lt;const char*&amp;gt;(dataToAppend.c_str()), dataToAppend.length()); 还有另外一种场景，当有一部分数据已经积压在发送缓冲区了，此后服务器端未产生新的待发送的数据，此时如果不做任何处理，发送缓冲区的数据会一直积压，但是发送缓冲区的数据容量也不会超过上限。如果不做任何处理的话，该数据会一直在缓冲区中积压，白白浪费系统资源。对于这种情况一般我们会设置一个定时器，每隔一段时间（如 3 秒）去检查一下各路连接的发送缓冲区中是否还有数据未发送出去，也就是说如果一个连接超过一定时间内还存在未发送出去的数据，我们也认为该连接出现了问题，我们可以关闭该路连接并回收相应的资源（如清空缓冲区、回收套接字资源等）。示例代码如下：
//每3秒检测一次 const int SESSION_CHECK_INTERVAL = 3000; SetTimer(SESSION_CHECK_TIMER_ID, SESSION_CHECK_INTERVAL); void CSessionManager::OnTimer() { for (auto iter = m_mapSession.begin(); iter != m_mapSession.end(); ++iter) { if (!CheckSession(iter-&amp;gt;value)) { //关闭session，回收相关的资源 iter-&amp;gt;value-&amp;gt;ForceClose(); iter = m_mapSession.erase(iter); } } } void CSessionManager::CheckSession(CSession* pSession) { if (!pSession-&amp;gt;GetConnection().OutputBuffer.IsEmpty()) return false; return true; } 上述代码，每隔 3 秒检测所有的 Session 的对应的 Connection 对象，如果发现发送缓冲区非空，说明该连接中发送缓冲区中数据已经驻留 3 秒了，将该连接关闭并清理资源。</description>
    </item>
    
    <item>
      <title>深入理解C/C&#43;&#43;中的指针</title>
      <link>https://haokiu.com/blog/ec8d1fd1cfc24923bdb71accca3fc1e4/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/ec8d1fd1cfc24923bdb71accca3fc1e4/</guid>
      <description>深入理解C/C++中的指针 C和C++中最强大的功能莫过于指针了（pointer），但是对于大多数人尤其是新手来说，指针是一个最容易出错、也最难掌握的概念了。本文将从指针的方方面面来讲述指针的概念和用法，希望对大家有所帮助。
内存模型 为了更好地理解指针，让我们来看一下计算机的内存模型。
内存分为物理内存和虚拟内存，物理内存对应计算机中的内存条，虚拟内存是操作系统内存管理系统假象出来的。由于这些不是我们本文的重点，下面不做区分。有不清楚这些概念的同学，可以给我留言或者在线询问。
在不考虑cpu缓存的情况下，计算机运行程序本质上就是对内存中的数据的操作，通俗地来说，就是将内存条某些部分的数据搬进搬出或者搬来搬去，其中“搬进搬出”是指将内存中的二进制数据搬入cpu寄存器及运算器中进行相应的加减运算或者将寄存器中的数据搬回内存单元中，而“搬来搬去”是指将内存中的数据由这个位置搬到另外一个位置（当然，一般不是直接搬，而是借助寄存器作为中间存储区）。如下图所示：
计算机为了方便管理内存，将内存的每个单元用一个数字编号，如下图所以：
图中所示，是一个大小为128个字节的内存空间，其中每一个空格代表一个字节，所以内存编号是0~127。
对于一个32位的操作系统来说，内存空间中每一个字节的编号是一个32位二进制数，所以内存编号从0000 0000 0000 0000 0000 0000 0000 0000至1111 1111 1111 1111 1111 1111 1111 1111，转换成16进制也就是0x00000000至0xFFFFFFFF，由于是从0开始的，所以化成10机制就是从0至2的32次方减1；对于64位操作系统，内存编号也就是从64个0至64个1。
大家需要注意的是，从上面两个图我们可以发现，我们一般将编号小的内存单元画在上面，编号大的画在下面，也就是说从上至下，内存编号越来越大。
指针与指针变量 指针的本意就是内存地址，我们可以通俗地理解成内存编号，既然计算机通过编号来操作内存单元，这就造就了指针的高效率。
那么什么是指针变量呢？指针变量可通俗地理解成存储指针的变量，也就是存储内存地址（内存编号）的变量。首先指针变量和整型变量、字符型变量以及其他数据类型的变量一样都是变量类型；但是，反过来，我们不应该按这样的方式来分类，即：整型指针变量、字符型指针变量、浮点型指针变量等等。为什么不推荐这样的分类方法呢？首先，指针变量就是一个数据类型，指针数据类型，这种数据类型首先是一个变量数据类型，那么它的大小是多少呢？很多同学理所当然地认为整型指针变量和一个字符指针变量的大小是不一样的，这种认识是错的。指针变量也是一个变量，它是一个用来存储其他变量的内存地址的，更准确地说，指针变量时用来存储其他变量的内存首地址的，因为不同的数据类型所占的内存大小不一样。举个例子，在32位机器上，假如a是int型变量，pa是指向a的指针变量，b是一个double型变量，pb是指向b的指针变量，那么a在内存中占四个字节，b在内存中占8个字节，假如a在内存中分布是从0x11111110~0x11111113，而b在内存中分布是0x11112221至0x11112228，那么指针变量pa中存储的内容是0x11111110，而pb中存储就是0x11112221，看到了吧，也就是说，pa和pb中存储的都是地址，而且都是32位的二进制地址；再者，因为存储这样的地址需要4个字节，所以无论是int型指针变量pa或者是double型指针变量pb，它们所占的内存大小都是四个字节，从这点来说，不管什么类型的指针都是一样的，所以不论按整型指针变量、字符型指针变量、浮点型指针变量等等来区分指针变量。总结起来，指针变量和int、float、char等类型一样同属变量类型，指针变量类型占四个字节（32位机器下），存储的是32位的内存地址。下面的代码证明这一点：
上面介绍的是指针变量的一个方面，指针变量还有另外一层含义：在C/C++中星号（*）被定义成取内容符号，虽然所有指针变量占的内存大小和存储的内存地址大小都是一样的，但是由于存储的只是数据的内存首地址，所以指针变量存储的内存地址所指向的数据类型决定着如何解析这个首地址，也就是说对于int型指针变量，我们需要从该指针变量存储的（首）地址开始向后一直搜索4个字节的内存空间，以图中的变量a为例就是从0x12ff60~0x12ff63，对于变量b就是0x12ff44~0x12ff4b。所以从这个意义来上讲，当我们使用*pa，必须先知道pa是一个整型的指针，这里强调“整型”，而a的值1也就存储在从0x12ff60~0x12ff63这四个字节里面，当我们使用*pb，必须先知道pb是一个double型指针，这里强调&amp;quot;double&amp;quot;,也就是说值2.0000存储在0x12ff44~0x12ff4b这八个字节里面。因此，我们对指针变量进行算术运算，比如pa + 2,pb + +之类的操作，是以数据类型大小为单位的，也就是说pa + 2,相当于0x12ff60 + sizeof(int) * 2 = 0x12ff60 + 4 * 2 = 0x12ff68,不是0x12ff60 + 2哦；而pb - -相当于0x12ff44 + sizeof(double) * 1 = 0x12ff44 + 8 * 1 = 0x12ff4c。理解这一点很重要。 同理&amp;amp;a + 2和&amp;amp;b - 1也是一样（注意由于&amp;amp;b是一个指针常量，所以写成&amp;amp;b - -是错误的）。
指针变量和指针常量 指针变量首先是一个变量，由于指针变量存储了某个变量的内存首地址，我们通常认为**”指针变量指向了该变量“，但是在这个时刻指针变量pa指向变量a，下个时候可能不存储变量a的首地址，而是存储变量c的首地址，那么我们可以认为这个时候，pa不再指向a，而是指向c。请别嫌我啰嗦，为了帮助你理解，我是故意说得这么细的，后面我们讨论高级主题的时候，当你觉得迷糊，请回来反复咀嚼一下这段话。也就是说指针变量是一个变量，它的值可以变动**的。
相反，指针常量可通俗地理解为存储固定的内存单元地址编号的”量“，它一旦存储了某个内存地址以后，不可再改存储其他的内存地址了。所以指针常量是坚韧，因为它”咬定青山不放松“；说是”痴情“，因为它”曾经沧海难为水“。我这里讲的指针常量对应的是const关键字定义的量，而不是指针字面量。像&amp;amp;a, &amp;amp;b, &amp;amp;a + 2等是指针字面量，而const int *p = &amp;amp;a;中的p才算是真正的指针常量，指针常量一般用在函数的参数中，表示该函数不可改变实参的内容。来看一个例子吧：
上面的函数由于修改了一个常指针（多数情况下等同指针常量），因而会编译出错：error C3892: “x”: 不能给常量赋值。
指针变量与数组 记得多年以前，我在学生会给电子技术部和地理信息系统专业的同学进行C语言培训时，这是一个最让他们头疼和感到一头雾水的话题，尤其是指针变量与二维数组的结合，我永远忘不了胡永月那一脸迷惑与无助的表情。今天我这里给大家深入地分析一下。先看一个例子：
如果你能得出下面这样的结果，说明你已经基本上对数组与指针的概念理解清楚了：
通过上图，我们可以知道*(a + 1) = 2, *(ptr - 1) = 5。
且不说很多同学根本得不到这样的结果，他们看到int ptr = (int)(&amp;amp;a+1);这样的语句就已经懵了，首先，我们知道C语言中规定数组名表示这个数组的首地址，而这里竟然出现了&amp;amp;a这样的符号，本来a就是一个指针常量了，这里对&amp;amp;a再次取地址难道不是非法操作吗？哈哈，当你有这样的疑问的时候，说明你对二维数组相关知识理解不深入。我这里先给你补充下知识点吧：</description>
    </item>
    
    <item>
      <title>游戏开发专题</title>
      <link>https://haokiu.com/blog/c1e71fdf335346f5aadad6e1d1dc3e55/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/c1e71fdf335346f5aadad6e1d1dc3e55/</guid>
      <description>游戏开发专题 1 游戏服务器开发的基本体系与服务器端开发的一些建议
2 网络游戏服务器开发框架设计介绍
3 游戏后端开发需要掌握的知识
4 关于游戏服务端架构的整理
5 各类游戏对应的服务端架构
6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则
7 QQ游戏百万人同时在线服务器架构实现
8 大型多人在线游戏服务器架构设计
9 百万用户级游戏服务器架构设计
10 十万在线的WebGame的数据库设计思路
11 一种高性能网络游戏服务器架构设计
12 经典游戏服务器端架构概述
13 游戏跨服架构进化之路</description>
    </item>
    
    <item>
      <title>用Visual Studio调试Linux程序</title>
      <link>https://haokiu.com/blog/f64c601f237d4cac97445aa4b0e07369/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/f64c601f237d4cac97445aa4b0e07369/</guid>
      <description>用Visual Studio调试Linux程序 用Visual Studio调试Linux程序？你真的没看错，这个是真的，不是标题党。当然如果你说VS2015及以上版本自带的Linux调试插件，那就算了。这些自带的插件调试一个有简单的main函数程序还凑合，稍微复杂点的程序，根本无法编译调试。
而本文介绍的主角是VS的另外一款插件Visual GDB，让我们欢迎主角登场，下面是正文。
使用Visual Studio+VisualGDB调试远程Linux程序 需要工具：
Visual Studio 2013或以上版本（以下简称VS） VisualGDB（一款VS插件，官网为：http://visualgdb.com/） 含有调试符号的Linux程序文件（该程序文件为调试目标） Visual Assistant（番茄助手，另外一款VS插件） 在VS上安装完VisualGDB插件以后，有如下几种方式来对远程Linux机器上的程序进行调试：
**方法一、**如果该程序已经启动，则可以使用VS菜单【Debug】-&amp;gt;【Attach to Process&amp;hellip;】。 这种方法有个缺点是，不能从开始启动的main函数处添加断点，自始至终地调试程序，查看完整程序运行脉络，所以下面推荐方法二。
方法二、利用VS启动远程Linux机器上一个Linux程序文件进行调试。选择VS菜单【Debug】 -&amp;gt;【Quick Debugwith GDB】。 需要注意的地方，已经在上图中标红框。这里简单地解释一下：
如果你安装了交叉编译环境Target可以选择MinGW/Cygwin，否则就选择远程Linux系统。这里如果不存在一个ssh连接，则需要创建一个。
Debugged program是需要设置的被调试程序的路径，位于远程Linux机器上。
Arguments是该调试程序需要设置的命令行参数，如果被调试程序不需要命令行参数可以不设置。
Working directory是被调试程序运行的工作目录。
另外建议勾选上Initial breakpoint in main，这样启动调试时，程序就会停在程序入口处。
这样，我们就可以利用VS强大的功能去查看程序的各种状态了，常用的面板，如【内存】【线程】【观察】【堆栈】【GDB Session】【断点】等窗口位于VS 菜单【Debug】-&amp;gt;【Windows】菜单下，注意，有些窗口只有在调试状态下才可见。这里有两个值得强调一下的功能是：
GDB Session****窗口，在这个窗口里面可以像原来直接使用gdb调试一样输入gdb指令来进行调试。 SSH console****窗口，这个窗口类似一个远程操作Linux系统的应用程序如xshell、SecureCRT。 现在还剩下一个问题，就是我们虽然在调试时可视化地远程查看一个Linux进程的状态信息，但很多类型的定义和什么却无法看到。解决这个问题的方法就是你可以先在VS里面建立一个工程，导入你要调试的程序的源代码目录。然后利用方法一或者方法二去启动调试程序。这个时候你想查看某个类型的定义或什么只要利用Visual Assit的查看源码功能即可，快捷键是Alt + G。
需要注意的时：同时安装了Visual Assist和VisualGDB后，后者也会提供一个go按钮去查找源码定义，但这个功能远不如Visual Assist按钮好用，我们可以禁用掉它来使用Visual Assist的Go功能。禁用方法，打开菜单：【Tools】-&amp;gt;【Option&amp;hellip;】:
然后重启VS即可。
到这里，既可以查看源码，也可以调试程序了。
VisualGDB 下载地址：
链接：https://share.weiyun.com/57aGHLM 密码：kj9ahs</description>
    </item>
    
    <item>
      <title>程序员如何写简历</title>
      <link>https://haokiu.com/blog/9c853d8576774df7ad52d79d740d95f1/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/9c853d8576774df7ad52d79d740d95f1/</guid>
      <description>程序员如何写简历 笔者工作多年后面试了很多公司，例如 2018 年年初横扫各大互联网公司，也作为面试官面试了很多人，看过不少的简历。现在疫情快过去了，很多小伙伴开始准备简历看新机会了，但是不少小伙伴遇到以下两种情况：
投了很多公司，邀请面试的寥寥无几； 面试的时候被面试官问的哑口无言。 造成以上原因很大一部分是因为简历的问题，本文将结合自身的面试和被面试的经历和大家聊一聊简历怎么写。我们先来分析一些简历素材。
简历一 这是一位毕业生的简历，大家看下这个简历存在什么问题？
分析：
简历中写了自己做的一个项目，项目描述中将该项目描述成 RPC、分布式网络框架，试问从项目描述来看，哪里体现出该项目使用了 RPC 框架和分布式？且不说没用到，就算用了，一般按大多数应届生的经验水平是很难在面试时经得住面试官在分布式等问题上的追问的，这非常容易给自己面试挖坑，一般校招或者对应届生的项目要求并不会太高，但是自己在简历中写上这些“分布式”、“RPC”等高大上的术语，如果实际并未掌握，只能是给自己埋雷。
另外，求职者的项目是一个网络通信库，但是通信协议不是自己的（Protobuf），网络库也是别人的（Muduo），那这个项目有自己的东西吗？一般作为面试官对应届生没有多少项目经验是可以理解的，但是如果把别人的东西拿来自己加个壳，并写在简历中，这就没多大意义了。如果该同学尝试自己设计了一种通信协议，哪怕最终实现的不是很好，面试官也可能非常喜欢，因为融入了自己的创作和思考；退一步说，用 protobuf 也是可以的，如果面试时能说得清楚 protobuf 的序列化和反序列化的原理和该库的结构，也是 OK 的。
面试结果：
该同学在面试时因这个项目被面试官死怼，铩羽而归。
简历二 分析：
这个简历我第一眼看到之后，我猜想应该很少有 HR 或者猎头联系该同学面试吧，后来和当事人确认下，果不其然。该简历的问题有以下几点：
简历中列举的技术栈非常多，如 Linux 、Shell、Python、C++、Golang、Django、Flask、Bootstrap、JQuery&amp;hellip;&amp;hellip;面试者真的掌握了这么多技术吗？另外，求职目标写的是“后端开发”，虽然 HR 可能不知道 Bootstrap、vue 等是前端技术，但技术面试官不知道吗？你一个求职后端职位的，你写许多前端技术干嘛？体现自己全栈吗？按作者的年龄和工作经历，很多技术只是了解或者使用过，并不一定掌握，且不说面试容易被问到而答不出来，最主要的是这份简历让人一看就觉得求职者没有自己专精的领域。说白了，啥可能都知道，但啥都没掌握好。所以大多数公司看到这样一份简历直接就 pass 掉了。 求职目标写的是“后端开发”，位置不够显眼，其次求职目标后端开发一词描述太泛，这位同学本意是求职 C++ 后台开发，但是这样一写，php、Java、golang、python 等不算后端开发吗？所以建议把求职的职位稍微缩小点范围。 面试结果：
基本无面试邀请。
简历三 分析
同学醒醒，你已经毕业工作三年了，还把毕业的硕士论文贴到简历中。。。。。。问题是，你这个毕业论文中还有 “ demo” 字样，可能你的毕业论文获过奖，但是大多数 HR 和 面试官都看不懂里面的行业术语，但是一定能看懂 “demo” 这个词，demo 给大家的感觉好像高大上不起来吧。。。。。。 这位同学作为一个非科班（动物科学）转计算机行业的人，已经成功入行三年了，为啥还要把自己本科的专业放在这么明显的位置，是强调自己转行不易、很努力吗？- -! 如果你不是科班出身，或者不是名牌大学（清华、北大、复旦、武大等）毕业，尤其是毕业几年了，就不要把学历和毕业院校放在这么显眼的位置吧，可以放在“兴趣爱好”之前。 求职意向也是一样的问题； 技术专长描述的也不好，一般我们看用人单位的招聘信息，也都是先写通用技术后写专业领域的技术，所以通用技术指的是算法数据结构、操作系统原理、网络编程等等；专业的技术，指的是 C++、Java、golang、python 等语言、各种框架、开源软件等。 另外，如果长得不是特别帅的话，就不建议放自己的照片了。。。。。。 简历四 分析
这个简历看完我是真的醉了。
大哥，我知道你没有拿得出手的项目经历和技术，可是你求职的是开发岗位，你也不至于把饲养猪的经历写进简历吧，虽然有些大厂自己给员工养猪吃，但是程序开发和养猪毕竟是两码事吧。。。。。。
简历五 分析
这份简历的项目描述也得太详细了，尤其是业务部分，感觉像项目招标书或者项目售前方案。。如果你求职的是技术开发类岗位，且你求职的下家公司与你简历中的项目不是同一个类型，那就把项目业务内容写得简略点，描述项目经历时多写一些技术内容。。。。。。说实话这份简历适合去应聘项目经理，尤其是公路局的项目经理。。。。。。
简历六 分析
这是一位大哥的简历，大哥已经工作十三年了，请读者看看这个项目经历描述是否有 13 年的水平？这项目描述实在太细了，首先可能把之前公司的商业技术机密全部泄露了。。。。。其次，和上面的简历六一样，多写点技术内容少写点业务内容不行吗，简历六可以应聘项目经理，这份简历可以应聘产品经理。。。。。。需求写的太细了，你确定是要找后端开发吗。。。。。。
简历七 分析
人常说，一份文案的整洁程度可以反映一个人的细致程度。这份简历存在两个问题：
个人技能这一块分类很混乱，例如“掌握 C++ 应用，理解底层原理,部分 c11 特性”中底层原理和 C++ 应用有什么关系，完全可以分开写嘛，另外 C++11已经目前已经被广泛使用，如果你不熟悉就不要写，写熟悉部分是熟悉多少？是告诉面试官自己这方面掌握的不好吗？原本面试时面试官可能不会问，看到这个可能说不定忍不住问几个 C++11 的东西；“多线程，同步，ipc通信等”中的“同步”难道不是针对多线程讲的吗？“熟悉设计模式、策略模式、单例模式、工厂模式”中策略模式、单例模式、工厂模式难道不是设计模式的一种吗？为何和设计模式一起用顿号并列起来？ 简历中标点符号一会儿中文的逗号，一会儿英文的逗号，像 C++、Linux 这样的专用名词一会儿首字母大写，一会儿小写，导致整个排版脏乱不堪。 总结 成功的方法都差不多，错误的情形千奇百怪。因文章篇幅，就不贴更多的简历了，看完上面七份简历，你是否也有类似的情形呢？下面给大家总结一下投递简历注意事项和如何写技术简历。
**一、**投递简历时，如果投递到企业或者 HR 的邮箱，一定要在邮件主题中写清楚来意，一般是【XXX 求职或者应聘 XXX 职位】，例如【张小方应聘后端 C++ 开发岗位】，不然邮件很容易被忽略或者被邮件垃圾过滤系统所过滤，简历根本到不了 HR 或者面试官手里；简历附件的文件名尽量写清楚附件的内容，如 【XXX 求职 XXX 岗位】.</description>
    </item>
    
    <item>
      <title>程序员必知必会的网络命令</title>
      <link>https://haokiu.com/blog/2137687badbe411cac56094071bcc338/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/2137687badbe411cac56094071bcc338/</guid>
      <description>程序员必知必会的网络命令 利用telnet命令发电子邮件
做Java或者C++开发都应该知道的lsof命令
Linux网络故障排查的瑞士军刀nc命令
Linux tcpdump使用详解
从抓包的角度分析connect函数的连接过程
服务器开发中网络数据分析与故障排查经验漫谈</description>
    </item>
    
    <item>
      <title>程序员的烦心事</title>
      <link>https://haokiu.com/blog/e11a027d307841d9b515ac4b1670037c/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/e11a027d307841d9b515ac4b1670037c/</guid>
      <description>程序员的烦心事 拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？
我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？</description>
    </item>
    
    <item>
      <title>程序员的薪资与年终奖那些事儿</title>
      <link>https://haokiu.com/blog/18d3e73501ef4be092520d6f5991517f/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/18d3e73501ef4be092520d6f5991517f/</guid>
      <description>程序员的薪资与年终奖那些事儿 技术面试与HR谈薪资技巧
聊一聊程序员如何增加收入
谈一谈年终奖</description>
    </item>
    
    <item>
      <title>程序员面试题精讲</title>
      <link>https://haokiu.com/blog/c092595334ac4b29914e418b3aae0648/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/c092595334ac4b29914e418b3aae0648/</guid>
      <description>程序员面试题精讲 腾讯后台开发实习生技能要求
聊聊如何拿大厂的 offer
网络通信题目集锦
我面试后端开发经理的经历
Linux C/C++后端开发面试问哪些问题</description>
    </item>
    
    <item>
      <title>网络编程</title>
      <link>https://haokiu.com/blog/6e60982d515240e4b34e2f0e22647f58/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/6e60982d515240e4b34e2f0e22647f58/</guid>
      <description>网络编程 bind 函数重难点解析
connect 函数在阻塞和非阻塞模式下的行为
select 函数重难点解析
Linux epoll 模型（含LT 模式和 ET 模式详解）
socket 的阻塞模式和非阻塞模式
非阻塞模式下 send 和 recv 函数的返回值
服务器开发通信协议设计介绍
TCP 协议如何解决粘包、半包问题
网络通信中收发数据的正确姿势
服务器端发数据时，如果对端一直不收，怎么办？</description>
    </item>
    
    <item>
      <title>网络通信中收发数据的正确姿势</title>
      <link>https://haokiu.com/blog/ec34cfea56f74c0d9a622ef5cbc4f812/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/ec34cfea56f74c0d9a622ef5cbc4f812/</guid>
      <description>网络通信中收发数据的正确姿势 在网络通信中，我们可能既要通过 socket 去发送数据也要通过 socket 来收取数据。那么一般的网络通信框架是如何收发数据的呢？注意，这里讨论的范围是基于各种 IO 复用函数（select、poll、epoll 等）来判断 socket 读写来收发数据，其他情形比较简单，这里就不提了。
我们这里以服务器端为例。服务器端接受客户端连接后，产生一个与客户端连接对应的 socket（Linux 下也叫 fd，为了叙述方便，以后称之为 clientfd），我们可以通过这个 clientfd 收取从客户端发来的数据，也可以通过这个 clientfd 将数据发往客户端。但是收与发在操作流程上是有明显的区别的。
收数据的正确姿势 对于收数据，当接受连接成功得到 clientfd 后，我们会将该 clientfd 绑定到相应的 IO 复用函数上并监听其可读事件。不同的 IO 复用函数可读事件标志不一样，例如对于 poll 模型，可读标志是 POLLIN，对于 epoll 模型，可读事件标志是 EPOLLIN。当可读事件触发后，我们调用 recv 函数从 clientfd 上收取数据（这里不考虑出错的情况），根据不同的网络模式我们可能会收取部分，或一次性收完。收取到的数据我们会放入接收缓冲区内，然后做解包操作。这就是收数据的全部“姿势”。对于使用 epoll 的 LT 模式（水平触发模式），我们每次可以只收取部分数据；但是对于 ET 模式（边缘触发模式），我们必须将本次收到的数据全部收完。
ET 模式收完的标志是 recv 或者 read 函数的返回值是 -1，错误码是 EWOULDBLOCK，针对 Windows 和 Linux 下区别，前面章节已经详细地说过了。
这就是读数据的全部姿势。流程图如下：
发数据的正确姿势 对于发数据，除了 epoll 模型的 ET 模式外，epoll 的 LT 模式或者其他 IO 复用函数，我们通常都不会去注册监听该 clientfd 的可写事件。这是因为，只要对端正常收数据，一般不会出现 TCP 窗口太小导致 send 或 write 函数无法写的问题。因此大多数情况下，clientfd 都是可写的，如果注册了可写事件，会导致一直触发可写事件，而此时不一定有数据需要发送。故而，如果有数据要发送一般都是调用 send 或者 write 函数直接发送，如果发送过程中， send 函数返回 -1，并且错误码是 EWOULDBLOCK 表明由于 TCP 窗口太小数据已经无法写入时，而仍然还剩下部分数据未发送，此时我们才注册监听可写事件，并将剩余的服务存入自定义的发送缓冲区中，等可写事件触发后再接着将发送缓冲区中剩余的数据发送出去，如果仍然有部分数据不能发出去，继续注册可写事件，当已经无数据需要发送时应该立即移除对可写事件的监听。这是目前主流网络库的做法。
流程图如下：
上述逻辑示例如下：
直接尝试发送消息处理逻辑：
/** *@param data 待发送的数据 *@param len 待发送数据长度 */ void TcpConnection::sendMessage(const void* data, size_t len) { int32_t nwrote = 0; size_t remaining = len; bool faultError = false; if (state_ == kDisconnected) { LOGW(&amp;#34;disconnected, give up writing&amp;#34;); return; } // 当前未监听可写事件，且发送缓冲区中没有遗留数据 if (!</description>
    </item>
    
    <item>
      <title>网络通信面试题集锦</title>
      <link>https://haokiu.com/blog/eb4b0ccb7b2942b989b3655d832bb0e0/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/eb4b0ccb7b2942b989b3655d832bb0e0/</guid>
      <description>网络通信面试题集锦 TCP/IP协议栈层次结构
TCP三次握手需要知道的细节点
TCP四次挥手需要知道的细节点(CLOSE_WAIT、TIME_WAIT、MSL)
TCP与UDP的区别与适用场景
linux常见网络模型详解(select、poll与epoll)
epoll_event结构中的epoll_data_t的fd与ptr的使用场景
Windows常见的网络模型详解(select、WSAEventSelect、WSAAsyncSelect)
Windows上的完成端口模型(IOCP)
异步的connect函数如何编写
select函数可以检测网络异常吗？
epoll的水平模式和边缘模式
如何将socket设置成非阻塞的(创建时设置与创建完成后设置)，非阻塞socket与阻塞的socket在收发数据上的区别
send/recv(read/write)返回值大于0、等于0、小于0的区别
如何编写正确的收数据代码与发数据代码
发送数据缓冲区与接收数据缓冲区如何设计
socket选项SO_SNDTIMEO和SO_RCVTIMEO
socket选项TCP_NODELAY
socket选项SO_REUSEADDR和SO_REUSEPORT（Windows平台与linux平台的区别）
socket选项SO_LINGER
shutdown与优雅关闭
socket选项SO_KEEPALIVE
关于错误码EINTR
如何解决tcp粘包问题
信号SIGPIPE与EPIPE错误码
gethostbyname阻塞与错误码获取问题
心跳包的设计技巧（保活心跳包与业务心跳包）
断线重连机制如何设计
如何检测对端已经关闭
如何清除无效的死链（端与端之间的线路故障）
定时器的不同实现及优缺点
http协议的具体格式
http head、get与post方法的细节
http代理、socks4代理与socks5代理如何编码实现
ping
telnet
关于以上问题的答案，有兴趣可以参考我的知乎live：https://www.zhihu.com/lives/922110858308485120
或者如果你有任何不明白的地方，可以加我微信 easy_coder 交流。</description>
    </item>
    
    <item>
      <title>聊一聊程序员如何增加收入</title>
      <link>https://haokiu.com/blog/cbd700214d4e4bc691c5f33f6e905343/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/cbd700214d4e4bc691c5f33f6e905343/</guid>
      <description>聊一聊程序员如何增加收入 亲爱的读者朋友，你好。我是高性能服务器开发公众号的作者，范蠡。一些老的读者应该知道，我有个同名 QQ 群叫高性能服务器开发（研究）群，目前两个群加在一起，也快五千人了吧。很多群友不止一次的想了解我的收入情况，粗略的算了一下，今年一年到目前为止，大概有一百万。然而，这种程度的收入在上海这样的城市，依旧是买不起房，解决不了生活的大问题，比上不足比下有余吧。
咱公众号的大多数读者应该都是从事程序开发或者相关的，你或许在北京上海深圳，或许在南京武汉广州，或许在郑州合肥，或许在其他一些二线三线城市。大多数程序员其实是单纯而又朴实的，晚上可能在骂老板抠门、产品经理SB，但明天早上依然会早起去挤地铁，认真写每一行代码，因为高堂明镜悲白发，朝如青丝暮成雪，一天天老去的父母，需要我们赡养；&amp;ldquo;笑看妻子愁何在，漫卷诗书喜欲狂”，一天天长大的孩子，需要我们去养育。哪个程序员曾经不是不为五斗米而折腰的男子，如今却不得过着李白洗尿布一样的生活？所以，尽管有时候我们有千万种不愿意，但还是不得说这言不由衷的话，做着自己不想做的事情——因为我们缺钱。
今天，我们就和大家讨论一下程序员如何提高收入，当然，由于个人经历经验有限，难免是一家之言，文中内容仅供参考，欢迎温和地提出意见和建议。
程序员们的主要收入来源 这个标题其实不言自明的，程序员们，当然对于大多数上班族，工作是收入的主要来源。看到群里很多学生讨论 offer 薪资的时候，动辄就月薪 30 k 甚至如 45 k以及更高的，虽然不排除确实存在这一类的 SP 或者 SSP offer。但是大多数人会是这类高收入者或者幸运儿吗？月薪 30 k 意味着什么？意味着在一个小城市两口之家半年多的生活费，意味着在中国广大农村一家两三年的生活成本。老板都不是傻子，你能干多少活才会给你多少钱，那么 30 k 需要干多少活呢？其他的城市我不熟悉，以我所在的上海为例吧，对于一般学校毕业的应届毕业生月薪 5 k 起步，硕士会稍微高上 3～5 k，工作两年月薪在 12k～16k 之间，工作四五年月薪在 20 k ～26 k 之间，达到 30 k 及以上，一般需要工作七八年以上。如果较短工作年限，需要达到较高收入水平的，都是技术非常好或者能力特别强的。我工作三多年时，在一家做公司做音视频实时通讯技术，月薪 26 k。但是工作内容和工作量就很大，当时负责 pc 、安卓、iOS、mac 四个端的 C++ sdk 开发和维护，同时负责这几个端的 Java sdk 开发，每天需要处理多家客户使用这些 sdk 报的各种问题。每天晚上九点下班，被项目经理看到，她会说，你今天下班真早啊。我印象深刻的是，那一年春节，从年二十五到正月初六每天早上九点，我需要准时参加公司的项目会议，汇报项目状况和进度，每天二十四小时要随时响应。
我们大多人毕业学校一般、学历也一般，而且也不是特别努力，本身存在&amp;quot;先天不足”。高中或者大学不努力，毕业后本来起点就比名校或者努力的同学差上一截，这一截可能不是 0.1 到 0.11 的距离，可能是 0.1 到 10 的距离。哈佛大学有句校训是这样写的：今天不走，明天要跑。这句话是很有道理的，你从前不努力的阿喀琉斯之踵，可能在短期内对你没多少影响，但是有一天生活的压力，会逼着你补救之，补救的日子里你会觉得异常辛苦。例如人到中年，上有老小，加班加点为了那点微薄的薪资，在行业或者公司不景气时，被公司无情的降薪或者裁员。然后偷偷地抹掉眼泪，整理简历，为下一份微不足道的薪水继续努力。
中国有句老话叫，失之东隅，收之桑榆。意思是说，如果你失去了早上的朝阳，那么你一定要及时抓住晚上的夕阳，它是你最后弥补的机会。既然工资是主要收入来源，那么提高职场竞争力是加薪升职的唯一途径。而对于程序员来说就是提高技术能力和开阔视野。不管你是什么原因入了此行，既然选择了这一行，凑合或者破罐子破摔在这一行是行不通的，互联网行业的特点就是变化迅速，你需要不断学习去适应新的变化。你可能并不喜欢这份职业，这就如同一场婚姻一样，你可能对你的对象不满意，但是大多数人都没有推倒重来（离婚）的勇气和资本。如果你不尝试去与你这个不满意的爱人去培养感情，你的心情只会更加恶心，生活只会更糟。所以，从现在努力，好好培养对技术的热情还来得及，这就是所谓的先结婚再恋爱。不要盲目相信网上所谓程序员 35 岁危机，真正的技术大神是不会有啥危机的。我个人的经历告诉我，30 岁之前的每个月工资多几千块少几千块，对后来的生活真的没多大影响。对于开发人员来说，影响你后期收入却是人到中年的技术实力。我自做公众号以来，因为我的号（高性能服务器开发）是以技术为主，也认识了许许多多的技术号主，但是很多号的号主其实并不是做技术的，因为我本人是个技术痴迷者，所以我对那些技术实力一般的号主都不怎么感冒，反之我会主动约一些技术实力非常好的号主线下见面。在我的了解中，这些坚持做好技术的号主，工资收入都不低，年薪基本都在 50 W+，甚至有到 150 W。当然，技术实力好的，还有许多其他的优势，例如不用担心被裁员、不用担心找不到好工作，而且可能利用自己的技术去轻松地赚一些钱（下文会详细介绍）。
说了这么多，我建议亲爱的读者，你，如果是从事开发的，那么一定要热爱技术，并努力把它学好，因为它是你吃饭的家伙。吃饭的家伙都不重视，那还能指望你有多大的提高？虽然一些人从技术成功转型了，也赚了不少钱，但是这些都是个例，不具有普适性，你觉得你会成为那个幸运的个例吗？
有读者可能会问，那如何学好技术呢？我个人觉得是肯对自己投资。很多人会愿意为自己一趟旅游、一顿大餐花许多钱，却为自己买本书、买个课程、报个学习班的几十或几百块钱而纠结半天。消费行为分为投资型消费和纯消费型消费，工作的早些年，你一定要肯为自己多一些投资型消费。例如，我月薪不过万的时候，我会为见一个技术前辈一面，从上海跑到北京，转好几次车；会在得到 App 上花 1500 块钱约某个技术大神去咖啡店聊上两个小时。很多高人或行业前辈，我们在现实生活中可能永远都没机会与他们接触，但是现在的知识付费平台，给我们提供了很多机会。或许高人前辈的一句话，一个建议或者思路就能让你受益无穷。这样的例子自古有之，我这里就不举例了。
**要对自己负责，学习和提高是自己的事情。**我发现现在很多的人，出了社会之后还是学生时代被老师教的思维。学校里面老师教你是因为你交了并不便宜的学费给学校，学校给老师发工资和补助。但是到了社会上，大家都很忙，别人凭什么要给你无偿提供帮助或者解决问题；别人提供了一份学习资料，你自己没保存，过几天别人删掉了，你又腆着脸让别人再分享一次；别人给你解决问题，你却说你不方便，让别人等一会儿。或者是你觉得工作太忙、孩子吵得太凶没时间学习等等。这些都是理由和借口，都没把自己的学习和提高当自己的事情。
提高技术，先解决思想上的问题，再解决行动上的问题，这样就容易的多了。其实现实生活中大多数人都不努力，或者貌似很努力，所以你只要稍微真努力一点，你就能超过 90% 的人了。不信你可以试一试。两年前加入高性能服务器开发群的，并认真听我的建议付诸行动的群友，现在年薪都 50 W 了吧。
程序员的副业 程序员有哪些副业？很多人说去接外包，但是我并不建议你去接各种外包，尤其是那些需求不是很明确或者金额达到上千的外包项目。由于外包项目一般很难有明确的需求，尤其是和非技术出身的甲方人员对接时，很多功能的界限和定义都是不明确的，例如为一个即时通讯软件做一个&amp;quot;发送消息功能”，这个&amp;quot;发送消息功能&amp;quot;可多可少，可轻可重。发文字发表情比较简单，发图片就不容易做了，而发语音视频尤其是发实时的语音和视频的工作的量是需要一个专门的专业团队至少花上好几个月的。需求不明确的结果就导致容易出现反复沟通和返工，这会耗费你大量的时间和精力，必然会影响你正常的工作和生活，尤其是对于本职工作本来就忙碌的程序员们来说。而最后可能因为甲方的不满意，必然导致不会按期按量付款。当然，现在很多外包平台正在改善这一状况，如码云、开源中国社区、程序员客栈，不过还是存在不少问题。
除了外包，我们再来聊一聊知识付费，知识付费主要是程序员给各大知识付费站点或平台录制或者写作技术教程。文字系列的知识付费课程，国内做的比较好的有极客时间、GitChat 和 掘金社区。由于商业的运作，很多课程的标题和内容比较容易吸引用户购买，当然内容质量也是有保证的。如果你在某些技术方面有积累或者独到之处，可以尝试在这些平台上写一些专栏课程。但是，很多人看到别人的专栏动辄几千甚至上万的购买量，加上定价都在两位数，觉得作者一定通过课程赚到一笔不少的收入。其实也未必，一般的课程在开售前都有一定的基础数量，比如某个课程可能还没开始出售，就有 100 的购买量，这类纯粹是为了吸引用户去购买的。另外，很多课程都会被平台拿去做一些商业活动，如打折优惠、会员免费学习等等，通过这个形式购买的收入，平台会拿去不少一部分，分到每个作者的并不多。最后，剩下的的终于结算给作者了，平台又会为作者缴纳不少的个人所得税（纳税光荣！纳税光荣！纳税光荣！），最后到作者这里就剩下十之三四了。
视频型的知识付费平台，以慕课网和网易云课堂为例，当然由于平台对你录制的课程有一定的质量要求，你需要花费不少时间和精力去撰写课程教案和 PPT，提前练习，保证录制的视频讲解流畅、技术娴熟、知识专业。这类对一般的程序员属于比较重量级的副业了，有一定的难度。
再来说语音型的知识付费平台，例如得到、知乎 live。这里以知乎 live 为例，在知乎举办一场 live，为了保证质量，平台需要你进行资格认证，例如你说你在某某大公司任职，那需要你提交在该公司的工牌、身份证件或者劳动合同；你说你是某方面的专家，你需要有那一方面的相关证书，另外需要缴纳 500 块钱的保证金，这个用途是，如果你不能按期按质举办你的 live，那么这个保证金将不会退还给你。知乎 live 是我比较喜欢的一种形式，主要是比较省事，举办一次，每个月都会一点收入（同样需要缴税），我在知乎上举办过三场开发方面的 live，一年多时间，所有收入加起来大概有一万块钱左右。如果你在大城市生活和工作，可能觉得这没多少钱（我就是），但是如果你在像郑州、合肥这样的二三线城市做 IT，由于这类城市程序员的收入本身就不高，一万块钱绝对至少抵得上一两个月的收入，可以让生活负担小一点。所以建议在这类城市工作的读者可以尝试一下。</description>
    </item>
    
    <item>
      <title>聊聊如何拿大厂的 offer</title>
      <link>https://haokiu.com/blog/61401d1e68344e7b94c634f9b00cdbe4/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/61401d1e68344e7b94c634f9b00cdbe4/</guid>
      <description>聊聊如何拿大厂的 offer 为什么要进大厂 许多读者，尤其是一些学生朋友在找我聊职业规划和职场困惑时，我给的建议就是，如果你是应届生或者工作年限较短（五年以下），那一定要找个机会去大厂工作几年。
无论是出于所谓的“镀镀金”的心理，还是想去大厂挑战大业务量、接触高并发、提高技术、开阔视野，都是非常值得的。
虽然很多大厂都加班，但是作为工薪阶层的一员，哪里不加班呢？再者大厂的各项规章制度和福利待遇都比较完善，你可以见识到很多成熟的系统和优秀的做法和理念。
就福利待遇来说，大厂给的薪资待遇比一般的小公司给的要高上一截。就算你从大厂离职，你也可以很容易的涨薪去另外一家大厂。这些都是小公司的没有的优势（我这里并不是说小公司不好）。
由于刚毕业的时候，没有能够进大厂，导致起点和平台都比同时间进大厂的同学低许多。虽然最终通过自己的努力，从刚毕业时的月薪 5 千到现在的年薪 50 W+。
这期间我走了很多弯路和吃了很多苦头。以工资收入来说，未进大厂的，可能在社会上摸爬滚打好多年才勉强达到月薪 2~3 万，而进大厂可能工作一两年就够了，甚至有些大厂开出的 SSP 直接就有三五十万。
因此，如果你一毕业就进入了大厂，那么你的第一份工作的收入、起点和视野就会比同龄人高很多。这也是我苦口婆心地劝毕业生们在毕业前夕的那段日子里面咬咬牙，努力去拿个大厂的 Offer 的原因。
进入大厂的难点在哪里 虽然大厂很好，但是进大厂对个人资质、个人素养和技术水平都有一定的要求，并不是每个人都有机会的。这里说的个人资质，如学历和毕业院校的层次。
一般大厂都只接收本科及本科以上的学历，对于本科以下的学历的应届生一般都不会考虑。而且会优先选择学校层次还不错的毕业生。
也就是说对于应届生，学校和学历成了硬性要求。即使你的能力再强，HR 筛选简历时就已经把你给 pass 掉了，你根本没有面试的机会。
高考已经没考好了，这个已经成为既成事实了。那对于学历和学校不好的人，还有机会补救吗？
有的，通过社招。
也就是说，你可以先工作几年，再尝试去大厂面试。因为社招更多的是看重的是你的技术水平、工作经验等，对学历要求没那么高了。
如何进入大厂 无论是应届生还是工作几年的人，一般都需要通过技术面试才能进入大厂。
那么大厂技术面试一般会哪些问题呢？除了少部分相关的技术外，重头戏都是算法与数据结构。
说到算法和数据结构这门学科，很多人尤其是已经工作了几年的社会人士，用范玮琪的一句歌词来形容，那真是“那一些是非题，总让人伤透脑筋”。
大家常学常忘，但为了面试，尤其是大厂面试，所以不得不学。
很多人对算法和数据结构这门课，甚至存在这样一个误解：实际工作中根本用不到算法，只有面试才会用到。产生这种错觉的原理，莫外乎此人技术不够资深、水平不够好，无缘参与核心开发而已。
学好算法和数据结构，无论对从技术水平长远的发展来说，还是对个人逻辑思维锻炼都是大有裨益的。
国内的大厂面试，基本上大多数问题都是各种算法和数据结构题，而国外的大厂，像 Google、Facebook、微软等等，基本上百分之百是算法和数据结构题目。
很多应届毕业生横扫各大大厂 Offer，很大一部分原因是因为算法和数据结构掌握的好，当然薪资也非常可观。社会人士虽然在面试大厂时对相关的项目有一定的工作经验，没有像应届生要求那么高，但是最基础最常用的算法和数据结构还是要熟悉的。
说了这么多，那么大厂面试到底要求哪些算法和数据结构知识？我根据我面试的经验，给大家整理了一个清单：
**排序（常考的排序按频率排序为：**快速排序 &amp;gt; 冒泡排序 &amp;gt; 归并排序 &amp;gt; 桶排序）
一般对于对算法基础有要求的公司，如果你是应届生或者工作经验在一至三年内，以上算法如果写不出来，给面试官的印象会非常不好，甚至直接被 pass 掉。
对于工作三年以上的社会人士，如果写不出来，但是能分析出其算法平均、最好和最坏的情况下的复杂度，说出算法大致原理，在多数面试官面前也可以过的。注意，如果你是学生，写不出来或者写的不对，基本上面试就过不了。
二分查找
二分查找的算法尽量要求写出来。当然，大多数面试官并不会直接问你二分查找，而是结合具体的场景，例如如何求一个数的平方根，这个时候你要能想到是二分查找。
我在 2017 年年底，面试 agora 时，面试官问了一个问题：如何从所有很多的 ip 地址中快速找个某个 ip 地址。
链表
无论是应届生还是工作年限不长的社会人士，琏表常见的操作一定要熟练写出来，如链表的查找、定位、反转、连接等等。还有一些经典的问题也经常被问到，如两个链表如何判断有环（我在 2017 年面试饿了么二面、上海黄金交易所一面被问过）。
链表的问题一般不难，但是链表的问题存在非常多的“坑”，如很多人不注意边界检查、空链表、返回一个链表的函数应该返回链表的头指针等等。
队列与栈
对于应届生来说一般这一类问的比较少，但是对于社会人士尤其是中高级岗位开发，会结合相关的问题问的比较多，例如让面试者利用队列写一个多线程下的生产者和消费者程序，全面考察的多线程的资源同步与竞态问题（下文介绍多线程面试题时详细地介绍）。
栈一般对于基础要求高的面试，会结合函数调用实现来问。即函数如何实现的，包括函数的调用的几种常见调用方式、参数的入栈顺序、内存栈在地址从高向低扩展、栈帧指针和栈顶指针的位置、函数内局部变量在栈中的内存分布、函数调用结束后，调用者和被调用者谁和如何清理栈等等
某年面试京东一基础部门，面试官让写从 0 加到 100 这样一个求和算法，然后写其汇编代码。
哈希表
哈希表是考察最多的数据结构之一。常见的问题有哈希冲突的检测、让面试者写一个哈希插入函数等等。基本上一场面试下来不考察红黑树基本上就会问哈希表，而且问题可浅可深。
我印象比较深刻的是，当年面试百度广告推荐部门时，二面问的一些关于哈希表的问题。
当时面试官时先问的链表，接着问的哈希冲突的解决方案，后来让写一个哈希插入算法，这里需要注意的是，你的算法中插入的元素一定要是通用元素，所以对于 C++ 或者 Java 语言，一定要使用模板这一类参数作为哈希插入算法的对象。
然后，就是哈希表中多个元素冲突时，某个位置的元素使用链表往后穿成一串的方案。
最终考察 Linux 下 malloc（下面的 ptmalloc） 函数在频繁调用造成的内存碎片问题，以及开源方案解决方案 tcmalloc 和 jemalloc。
总体下来，面试官是一步步引导你深入。（有兴趣的读者可以自行搜索，网上有很多相关资料）
树 面试高频的树是红黑树，也有一部分是 B 树（B+ 树）。</description>
    </item>
    
    <item>
      <title>腾讯后台开发实习生技能要求</title>
      <link>https://haokiu.com/blog/5f118ee0e1be49a8a754072ecb9b441a/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/5f118ee0e1be49a8a754072ecb9b441a/</guid>
      <description>腾讯后台开发实习生技能要求 如题，应届生除了要良好地掌握算法和数据结构以外，以下一些技能点列表希望对大家有帮助，有兴趣的朋友可以参考这个针对性地补缺补差。文章列出的技能点有的要求熟悉，有的了解即可，注意技能点前面的修饰词。如果没有明确给出“熟悉”“了解”等字眼，要求均为熟悉。
一、操作系统方面 多线程相关与线程之间同步技术 熟练使用（但不局限于）以下linux API
linux下的线程创建、等待、获取线程id
int pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); int pthread_join(pthread_t thread, void **retval); pthread_t pthread_self(void); 常见线程之间的同步技术（何时该用那种技术）
互斥体
int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *mutexattr); int pthread_mutex_destroy(pthread_mutex_t *mutex); int pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); 信号量
int sem_init(sem_t *sem, int pshared, unsigned int value); int sem_destroy(sem_t *sem); int sem_wait(sem_t *sem); int sem_post(sem_t *sem); int sem_getvalue(sem_t *sem, int *valp); 条件变量
int pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr); int pthread_cond_destroy(pthread_cond_t *cond); int pthread_cond_signal(pthread_cond_t *cond); int pthread_cond_broadcast(pthread_cond_t *cond); int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex); int pthread_cond_timedwait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex, const struct timespec *restrict abstime); 读写/自旋锁</description>
    </item>
    
    <item>
      <title>详解 C&#43;&#43; 11 中的智能指针</title>
      <link>https://haokiu.com/blog/913fb3f31d024baf871726b2f22cdfde/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/913fb3f31d024baf871726b2f22cdfde/</guid>
      <description>详解 C++ 11 中的智能指针 C/C++ 语言最为人所诟病的特性之一就是存在内存泄露问题，因此后来的大多数语言都提供了内置内存分配与释放功能，有的甚至干脆对语言的使用者屏蔽了内存指针这一概念。这里不置贬褒，手动分配内存与手动释放内存有利也有弊，自动分配内存和自动释放内存亦如此，这是两种不同的设计哲学。有人认为，内存如此重要的东西怎么能放心交给用户去管理呢？而另外一些人则认为，内存如此重要的东西怎么能放心交给系统去管理呢？在 C/C++ 语言中，内存泄露的问题一直困扰着广大的开发者，因此各类库和工具的一直在努力尝试各种方法去检测和避免内存泄露，如 boost，智能指针技术应运而生。
C++ 98/03 的尝试——std::auto_ptr 在 2019 年讨论 std::auto_ptr 不免有点让人怀疑是不是有点过时了，确实如此，随着 C++11 标准的出现（最新标准是 C++20），std::auto_ptr 已经被彻底废弃了，取而代之是 std::unique_ptr。然而，我之所以还向你介绍一下 std::auto_ptr 的用法以及它的设计不足之处是想让你了解 C++ 语言中智能指针的发展过程，一项技术如果我们了解它过去的样子和发展的轨迹，我们就能更好地掌握它，不是吗？
std::auto_ptr 的基本用法如下代码所示：
#include &amp;lt;memory&amp;gt; int main() { //初始化方式1 std::auto_ptr&amp;lt;int&amp;gt; sp1(new int(8)); //初始化方式2 std::auto_ptr&amp;lt;int&amp;gt; sp2; sp2.reset(new int(8)); return 0; } 智能指针对象 sp1 和 sp2 均持有一个在堆上分配 int 对象，其值均是 8，这两块堆内存均可以在 sp1 和 sp2 释放时得到释放。这是 std::auto_ptr 的基本用法。
sp 是 smart pointer（智能指针）的简写。
std::auto_ptr 真正让人容易误用的地方是其不常用的复制语义，即当复制一个 std::auto_ptr 对象时（拷贝复制或 operator = 复制），原对象所持有的堆内存对象也会转移给复制出来的对象。示例代码如下：
#include &amp;lt;iostream&amp;gt; #include &amp;lt;memory&amp;gt; int main() { //测试拷贝构造 std::auto_ptr&amp;lt;int&amp;gt; sp1(new int(8)); std::auto_ptr&amp;lt;int&amp;gt; sp2(sp1); if (sp1.get() != NULL) { std::cout &amp;lt;&amp;lt; &amp;#34;sp1 is not empty.&amp;#34; &amp;lt;&amp;lt; std::endl; } else { std::cout &amp;lt;&amp;lt; &amp;#34;sp1 is empty.</description>
    </item>
    
    <item>
      <title>谈一谈年终奖</title>
      <link>https://haokiu.com/blog/0f72f7a83bbb4b4fb76a05dc63f5480c/</link>
      <pubDate>Mon, 11 Jan 2021 09:20:42 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/0f72f7a83bbb4b4fb76a05dc63f5480c/</guid>
      <description>谈一谈年终奖 转眼 2019 年就快过完了，对于广大程序员读者来说，重要的事情除了关心能不能买到回老家的车票以外，剩下的事情应该就属年终奖了。
对于 IT 行业来说，所谓年终奖其实就是公司在当年的月底基于你工资的数额发一定的比例的奖金，这也是很多企业的 HR 和猎头向求职者“许诺”的待遇之一。关于年终奖，一般是求职者在应聘时和 HR 谈好，再结合所在的公司的规定在年终兑现给求职者。但是，城市的套路太深了，本文就和大家讨论一下关于年终奖的那些坑，希望对读者朋友有一定启发意义。
年终奖的计算套路 先来说通用规则吧。IT 行业默认的不成文的规定，大多数公司，对于普通员工的年终奖一般是月底多发一个月工资，也就是所谓的 13 薪，这个基本上是保底的。对于从事开发的小伙伴来说，这个规则适用于初中高级，对于技术专家或者开发经理及以上级别一般保底工资会大于 13 薪，常见的是 14 ~ 16 薪不等，总结起来，就是所谓 12 + n，n 的可能取值是 1 ~ 5，它们就是所谓的年终奖，这是大多数公司的通用做法。但是在这些规定的基础之上不同的公司也有一些特殊的规定，常见的有如下几种形式：
年终奖的数量是 n 个月的月薪，但是要根据员工在当年在公司实际工作的天数来定，也就是说员工实际拿到的年终奖数目是 年终奖数目 = 月薪 * n * （员工当年实际工作的天数 / 365）
举个例子，员工小明在某公司当年工作半年，其月薪是 20k， 当时和 HR 谈好是 2 个月年终奖（n = 2），那么小明当年拿到的年终奖是数额是：20000 * 2 * 0.5 = 20000。
ok，有读者看到这里可能美滋滋，他可能会想，今年 12 月 1 日入职现在的公司，按这个规则年终奖是 2 个月，那么我今年的年终奖可以拿到 20000 * 2 * （1 / 12） = 3333，3333 元也不少啦，过年回家给长辈或者小朋友包个红包，或者给女朋友买几件衣服也是戳戳有余的啦。我只能说，这位读者想多了。因为某些公司还有第 2 条规定。
计算年终奖系数时虽然按员工当年实际工作的天数 / 365，但是如果员工当年实际工作的天数小于某个数值（例如 2 个月），则系数为 0。也就是说，很多 12 月份入职该公司的小伙伴在当年大概率是没有年终奖的。
除了上述两个规定外，企业对于年终奖还有一个比较常见的规定，就是年终奖绩效正态分布制。啥意思呢？举个例子，我在求职某大型旅游互联网公司时，HR 告诉我待遇是 16 薪，于是我就相信了。等到当年年底的时候发现，果然是 16 薪啊，但是每个员工都需要进行绩效考评，绩效分为 ABCD 四个等级，A 最优，D 最差，且 ABCD 四个等级的比例是 20%、30%、30%、20%，也就是说一个部门 10 个人，实际上只有 2 个人能拿到 16 薪，剩下的依次是 15 薪、14 薪和 13 薪。到此时，我也只能无奈的接受现实。</description>
    </item>
    
    <item>
      <title>golang 数组与切片的区别</title>
      <link>https://haokiu.com/blog/gnNp9N/</link>
      <pubDate>Thu, 19 Nov 2020 17:09:23 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/gnNp9N/</guid>
      <description>golang 的数组与切片有两大区别：
初始化：数组需要明确指定大小，切片不需要 函数传递：数组是值传递，切片是地址传递 初始化 数组 a := [...]int{1,2,3} a := [3]int{1,2,3} 切片 a:= []int{1,2,3} a := make([]int, 5) a := make([]int, 5, 10) slice的数据结构： go源码slice的数据结构定义：
type slice struct { array unsafe.Pointer len int cap int } slice 有三个字段：
指向真实 array 地址的指针 ptr slice 的长度 len 容量 cap 特性 通过例子说明 slice 和 array 的一些特性。
函数传递 数组需要明确指定大小，切片不需要。数组是值传递，切片是地址传递
a := [...]int{1, 2, 3, 4, 5, 6} fmt.Println(&amp;#34;star deal array, orginal data is:&amp;#34;) fmt.Println(a) aMaxIndex := len(a) - 1 fmt.Printf(&amp;#34;aMaxIndex:%d\r&amp;#34;, aMaxIndex) for i, e := range a { if i == aMaxIndex { a[0] += e fmt.Printf(&amp;#34;index is 0, val is :%d\r&amp;#34;, a[0]) } else { a[i+1] += e fmt.</description>
    </item>
    
    <item>
      <title>go 匿名结构体 数组 示例</title>
      <link>https://haokiu.com/blog/XVVOUE/</link>
      <pubDate>Mon, 09 Nov 2020 10:54:29 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/XVVOUE/</guid>
      <description>在用 vscode 生成测试用例的时候，生成了测试的匿名数组，没怎么用过，这里展示了 go 匿名结构体数组示例
import &amp;#34;testing&amp;#34; func TestGetRandomString(t *testing.T) { type args struct { lens int } tests := []struct { name string args args want string }{ { name: &amp;#34;test&amp;#34;, args: args{ lens: 6, }, want: &amp;#34;hi&amp;#34;, }, { name: &amp;#34;test&amp;#34;, args: args{ lens: 6, }, want: &amp;#34;hi&amp;#34;, }, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := GetRandomString(tt.args.lens); got != tt.want { t.Logf(&amp;#34;GetRandomString() = %v, want %v&amp;#34;, got, tt.want) } }) } } 需要注意的是各个结构体后面有个逗号。</description>
    </item>
    
    <item>
      <title>curl https 地址报异常</title>
      <link>https://haokiu.com/blog/KsbUyb/</link>
      <pubDate>Fri, 23 Oct 2020 15:03:17 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/KsbUyb/</guid>
      <description>用 acme.sh 生产了 Let&amp;rsquo;s Encrypt 的https 证书，在浏览器访问没有问题，但在服务器访问出现下面的异常：
curl: (60) SSL certificate problem: unable to get local issuer certificate More details here: https://curl.haxx.se/docs/sslcerts.html curl failed to verify the legitimacy of the server and therefore could not establish a secure connection to it. To learn more about this situation and how to fix it, please visit the web page mentioned above. 网站用了beego，用 acme.sh 生成的证书。配置：
EnableHTTPS = true HTTPSPort = 443 HTTPSCertFile = &amp;#34;/home/blog/cert/cert.pem&amp;#34; HTTPSKeyFile = &amp;#34;/home/blog/cert/key.pem&amp;#34; 要将 cert.pem 替换为：fullchain.pem
EnableHTTPS = true HTTPSPort = 443 HTTPSCertFile = &amp;#34;/home/blog/cert/fullchain.pem&amp;#34; HTTPSKeyFile = &amp;#34;/home/blog/cert/key.pem&amp;#34; </description>
    </item>
    
    <item>
      <title>beego 让http请求跳转到 https</title>
      <link>https://haokiu.com/blog/ZSf4yF/</link>
      <pubDate>Tue, 13 Oct 2020 16:33:55 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/ZSf4yF/</guid>
      <description>如果beego配置了https，那么可以让 让http请求跳转到 https，怎样配置 beego 的https，可以参考beego 通过acms.sh 使用 https
//siteUrl 是网站地址，比如:https://haokiu.com if &amp;#34;HTTP/1.1&amp;#34; == self.Ctx.Request.Proto &amp;amp;&amp;amp; siteUrl != &amp;#34;&amp;#34; &amp;amp;&amp;amp; strings.HasPrefix(siteUrl, &amp;#34;https&amp;#34;) { //如果支持https，则所有http请求跳转到https self.redirect(siteUrl + self.Ctx.Request.URL.Path) } </description>
    </item>
    
    <item>
      <title>beego 通过acme.sh 使用 https</title>
      <link>https://haokiu.com/blog/qP3u4V/</link>
      <pubDate>Tue, 13 Oct 2020 15:20:09 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/qP3u4V/</guid>
      <description>beego 通过 acme.sh 使用 https
安装acms.sh curl https://get.acme.sh | sh 生成证书 如果使用的是 beego 框架，需添加可访问的静态文件目录：
//acme.sh 自动验证网站目录，不使用https可以忽略 beego.SetStaticPath(&amp;#34;/.well-known&amp;#34;, &amp;#34;.well-known&amp;#34;) acme.sh --issue -d haokiu.com -d www.haokiu.com --webroot /usr/local/pixiublog/ 设置pixiublog开机启动 1. 编写开机启动脚本 vim /usr/lib/systemd/system/pixiublog.service
[Unit] Description=The pixiublog Process Manager After=syslog.target network.target [Service] Type=forking ExecStart=sh /usr/local/pixiublog/start.sh ExecReload=/bin/kill -USR2 $MAINPID ExecStop=/bin/kill -SIGINT $MAINPID [Install] WantedBy=multi-user.target 2. 设置开机启动 systemctl enable pixiublog 安装证书 acme.sh --install-cert -d haokiu.com \ --cert-file /home/blog/cert/cert.pem \ --key-file /home/blog/cert/key.pem \ --fullchain-file /home/blog/cert/fullchain.pem \ --reloadcmd &amp;#34;systemctl restart pixiublog&amp;#34; beego app.conf 配置 EnableHTTPS = true HTTPSPort = 443 HTTPSCertFile = &amp;#34;/home/blog/cert/fullchain.pem&amp;#34; HTTPSKeyFile = &amp;#34;/home/blog/cert/key.pem&amp;#34; 参考 acme.sh 使用</description>
    </item>
    
    <item>
      <title>acme.sh 方便管理 letsencrypt </title>
      <link>https://haokiu.com/blog/6D0DBH/</link>
      <pubDate>Mon, 12 Oct 2020 18:01:57 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/6D0DBH/</guid>
      <description>acme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书。这个脚本可以非常方便的管理 letsencrypt 的证书，省去很多繁琐操作。有了这个脚本就可以方便地给网站使用 https 了
主要步骤:
安装 acme.sh 生成证书 copy 证书到 nginx/apache 或者其他服务 更新证书 更新 acme.sh 出错怎么办, 如何调试 下面详细介绍.
1. 安装 acme.sh 安装很简单, 一个命令:
curl https://get.acme.sh | sh 普通用户和 root 用户都可以安装使用. 安装过程进行了以下几步:
把 acme.sh 安装到你的 home 目录下: ~/.acme.sh/ 并创建 一个 bash 的 alias, 方便你的使用: alias acme.sh=~/.acme.sh/acme.sh
2). 自动为你创建 cronjob, 每天 0:00 点自动检测所有的证书, 如果快过期了, 需要更新, 则会自动更新证书.
更高级的安装选项请参考: https://github.com/Neilpang/acme.sh/wiki/How-to-install
安装过程不会污染已有的系统任何功能和文件, 所有的修改都限制在安装目录中: ~/.acme.sh/
2. 生成证书 acme.sh 实现了 acme 协议支持的所有验证协议. 一般有两种方式验证: http 和 dns 验证.
1. http 方式需要在你的网站根目录下放置一个文件, 来验证你的域名所有权,完成验证. 然后就可以生成证书了. acme.sh --issue -d mydomain.com -d www.mydomain.com --webroot /home/wwwroot/mydomain.com/ 只需要指定域名, 并指定域名所在的网站根目录. acme.sh 会全自动的生成验证文件, 并放到网站的根目录, 然后自动完成验证. 最后会聪明的删除验证文件. 整个过程没有任何副作用.
如果你用的 apache服务器, acme.</description>
    </item>
    
    <item>
      <title>go ... 作用</title>
      <link>https://haokiu.com/blog/hiUuGO/</link>
      <pubDate>Mon, 12 Oct 2020 17:12:09 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/hiUuGO/</guid>
      <description>… 是go的一种语法糖。
作用 用于函数有多个不定参数的情况，可以接受多个不确定数量的参数 打散slice进行传递 例子 一、接受多个不确定数量的参数 func println(args ...string) { //可以接受任意个string参数 for _, v:= range args{ fmt.Println(v) } } func main(){ var strss= []string{ &amp;#34;qwr&amp;#34;, &amp;#34;234&amp;#34;, &amp;#34;yui&amp;#34;, &amp;#34;cvbc&amp;#34;, } println(strss...) //切片被打散传入 } 结果：
qwr 234 yui cvbc 二、打散slice进行传递 var strss= []string{ &amp;#34;qwr&amp;#34;, &amp;#34;234&amp;#34;, &amp;#34;yui&amp;#34;, } var strss2= []string{ &amp;#34;qqq&amp;#34;, &amp;#34;aaa&amp;#34;, &amp;#34;zzz&amp;#34;, &amp;#34;zzz&amp;#34;, } strss=append(strss,strss2...) //strss2的元素被打散一个个append进strss fmt.Println(strss) 结果：
[qwr 234 yui qqq aaa zzz zzz] 最后 如果没有’…’，面对上面的情况，无疑会增加代码量。</description>
    </item>
    
    <item>
      <title>golang 常用函数</title>
      <link>https://haokiu.com/blog/XtwuYL/</link>
      <pubDate>Sat, 10 Oct 2020 10:23:10 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/XtwuYL/</guid>
      <description>1. 获取当前时间 时间戳(秒)：time.Now().Unix 日期：time.Now().Format(&amp;#34;2006-01-02 15:04:05&amp;#34;) 注意：参数必须是 2006-01-02 15:04:05 而不能是自定义的年月日时间 2. 字符串与int转换 i,_ := strconv.Atoi(&amp;#34;3&amp;#34;) a := strconv.Itoa(32) 3.结构体json序列化 chatMsg := &amp;amp;ChatMsg{} err := json.Unmarshal([]byte(msg), chatMsg) //json转结构体 buf, _ := json.Marshal(chatMsg) //结构体转json return string(buf) 4.删除切片元素 mySlice := make([]int, 5) //创建一个初始元素个数为5的数组切片，元素初始值为0 mySlice = append(mySlice[:i], mySlice[i+1:]...) //删除下标为i的元素 mySlice = append(mySlice[:0], mySlice[1:]...) //删除第1个元素 5. url encode/decode encodeUrl:= url.QueryEscape(urltest) decodeUrl,err := url.QueryUnescape(encodeUrl) 6. base64编码 encodeString := base64.StdEncoding.EncodeToString(input) decodeBytes, err := base64.StdEncoding.DecodeString(encodeString) 7. 获取字符串长度 tips := &amp;#34;忍者&amp;#34; len := len(tips) //len=6 len := utf8.RuneCountInString(tips) //len=2 8. SubString func SubString(str string, start int32, end int32) string { result := []rune(str) length := int32(len(result)) if start &amp;lt; 0 || start &amp;gt; length { return str } if end &amp;lt; 0 || end &amp;gt; length { return str } return string(result[start:end]) } result = SubString(result, 0, int32(len([]rune(result)))-1)//注意end参数的取值 9.</description>
    </item>
    
    <item>
      <title>mybatis 增加自定义拦截器</title>
      <link>https://haokiu.com/blog/bGqNiH/</link>
      <pubDate>Sun, 27 Sep 2020 10:59:03 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/bGqNiH/</guid>
      <description>MyBatis 提供的强大机制，使用插件是非常简单的，只需实现 Interceptor 接口，并指定想要拦截的方法签名即可。
拦截器 import java.text.DateFormat; import java.util.Date; import java.util.List; import java.util.Locale; import java.util.Properties; import org.apache.ibatis.executor.Executor; import org.apache.ibatis.mapping.BoundSql; import org.apache.ibatis.mapping.MappedStatement; import org.apache.ibatis.mapping.ParameterMapping; import org.apache.ibatis.plugin.Interceptor; import org.apache.ibatis.plugin.Intercepts; import org.apache.ibatis.plugin.Invocation; import org.apache.ibatis.plugin.Plugin; import org.apache.ibatis.plugin.Signature; import org.apache.ibatis.reflection.MetaObject; import org.apache.ibatis.session.Configuration; import org.apache.ibatis.session.ResultHandler; import org.apache.ibatis.session.RowBounds; import org.apache.ibatis.type.TypeHandlerRegistry; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Intercepts({ @Signature(type = Executor.class, method = &amp;#34;update&amp;#34;, args = { MappedStatement.class, Object.class }), @Signature(type = Executor.class, method = &amp;#34;query&amp;#34;, args = { MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class }) }) public class MybatisInterceptor implements Interceptor { private static final Logger log = LoggerFactory.getLogger(MybatisInterceptor.class); @Override public Object intercept(Invocation invocation) throws Throwable { MappedStatement mappedStatement = (MappedStatement) invocation.</description>
    </item>
    
    <item>
      <title>搜索引擎 及 elastic search </title>
      <link>https://haokiu.com/blog/oaXyUa/</link>
      <pubDate>Wed, 23 Sep 2020 14:29:39 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/oaXyUa/</guid>
      <description>搜索引擎是对数据的检索，所以我们先从生活中的数据说起。我们生活中的数据总体分为两种：
结构化数据 非结构化数据 **结构化数据：**也称作行数据，是由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。指具有固定格式或有限长度的数据，如数据库，元数据等。
**非结构化数据：**又可称为全文数据，不定长或无固定格式，不适于由数据库二维表来表现，包括所有格式的办公文档、XML、HTML、Word 文档，邮件，各类报表、图片和咅频、视频信息等。
**说明：**如果要更细致的区分的话，XML、HTML 可划分为半结构化数据。因为它们也具有自己特定的标签格式，所以既可以根据需要按结构化数据来处理，也可抽取出纯文本按非结构化数据来处理。
根据两种数据分类，搜索也相应的分为两种：
结构化数据搜索 非结构化数据搜索 **对于结构化数据，**因为它们具有特定的结构，所以我们一般都是可以通过关系型数据库（MySQL，Oracle 等）的二维表（Table）的方式存储和搜索，也可以建立索引。
对于非结构化数据，也即对全文数据的搜索主要有两种方法：
顺序扫描 全文检索 **顺序扫描：**通过文字名称也可了解到它的大概搜索方式，即按照顺序扫描的方式查询特定的关键字。
例如给你一张报纸，让你找到该报纸中“平安”的文字在哪些地方出现过。你肯定需要从头到尾把报纸阅读扫描一遍然后标记出关键字在哪些版块出现过以及它的出现位置。
这种方式无疑是最耗时的最低效的，如果报纸排版字体小，而且版块较多甚至有多份报纸，等你扫描完你的眼睛也差不多了。
**全文搜索：**对非结构化数据顺序扫描很慢，我们是否可以进行优化？把我们的非结构化数据想办法弄得有一定结构不就行了吗？
将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。
这种方式就构成了全文检索的基本思路。这部分从非结构化数据中提取出的然后重新组织的信息，我们称之为索引。
这种方式的主要工作量在前期索引的创建，但是对于后期搜索却是快速高效的。
先说说 Lucene
通过对生活中数据的类型作了一个简短了解之后，我们知道关系型数据库的 SQL 检索是处理不了这种非结构化数据的。
这种非结构化数据的处理需要依赖全文搜索，而目前市场上开放源代码的最好全文检索引擎工具包就属于 Apache 的 Lucene了。
但是 Lucene 只是一个工具包，它不是一个完整的全文检索引擎。Lucene 的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。
目前以 Lucene 为基础建立的开源可用全文搜索引擎主要是 Solr 和 Elasticsearch。
Solr 和 Elasticsearch 都是比较成熟的全文搜索引擎，能完成的功能和性能也基本一样。
但是 ES 本身就具有分布式的特性和易安装使用的特点，而 Solr 的分布式需要借助第三方来实现，例如通过使用 ZooKeeper 来达到分布式协调管理。
不管是 Solr 还是 Elasticsearch 底层都是依赖于 Lucene，而 Lucene 能实现全文搜索主要是因为它实现了倒排索引的查询结构。
如何理解倒排索引呢？假如现有三份数据文档，文档的内容如下分别是：
Java is the best programming language. PHP is the best programming language. Javascript is the best programming language. 为了创建倒排索引，我们通过分词器将每个文档的内容域拆分成单独的词（我们称它为词条或 Term），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。
结果如下所示：
Term Doc_1 Doc_2 Doc_3 ------------------------------------- Java | X | | is | X | X | X the | X | X | X best | X | X | X programming | x | X | X language | X | X | X PHP | | X | Javascript | | | X ------------------------------------- 这种结构由文档中所有不重复词的列表构成，对于其中每个词都有一个文档列表与之关联。</description>
    </item>
    
    <item>
      <title>https 原理简介</title>
      <link>https://haokiu.com/blog/3TSsuC/</link>
      <pubDate>Wed, 23 Sep 2020 13:48:39 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/3TSsuC/</guid>
      <description>HTTPS 的整个通信过程可以分为两大阶段：证书验证和数据传输阶段，数据传输阶段又可以分为非对称加密和对称加密两个阶段。具体流程按图中的序号讲解。
客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。
采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书，证书是需要申请的，并由专门的数字证书认证机构(CA)通过非常严格的审核之后颁发的电子证书 (当然了是要钱的，安全级别越高价格越贵)。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。
服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。Chrome 浏览器点击地址栏的锁标志再点击证书就可以看到证书详细信息。
客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。
客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。
服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。
服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。
双方使用对称加密愉快地传输所有数据。</description>
    </item>
    
    <item>
      <title>golang 计算文件和字符串的 md5 值</title>
      <link>https://haokiu.com/blog/dpoeTs/</link>
      <pubDate>Sat, 19 Sep 2020 11:10:59 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/dpoeTs/</guid>
      <description>go MD5 所需要的包在”crypto/md5”包中，需要先实例化一个MD5对象，然后在此基础上调用sum方法即可
文件的MD5 md5 := md5.New() io.Copy(md5,file) MD5Str := hex.EncodeToString(md5.Sum(nil)) 上面的代码实现了计算了文件MD5，其中file是multipart.File类型的，也可以是其他的已打开的其他文件类型。 当然也可以不使用io.copy，而是直接使用sum函数来计算：
md5 := md5.New() MD5Str := hex.EncodeToString(md5.Sum(file)) 这样是直接调用了sum函数来计算文件的值可能要比io.copy稍微慢一些。
字符串的MD5 有时候需要将已知的一段字符串加密，其实和文件加密大概是类似的，只需要调用write方法将字符串写入hash中：
md5 := md5.New() md5.Write([]byte(&amp;#34;hello,world!&amp;#34;)) MD5Str := hex.EncodeToString(md5.Sum(nil)) </description>
    </item>
    
    <item>
      <title>S3协议</title>
      <link>https://haokiu.com/blog/d0DCeH/</link>
      <pubDate>Fri, 18 Sep 2020 15:17:51 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/d0DCeH/</guid>
      <description>S3是Simple Storage Service的缩写，即简单存储服务。亚马逊的名词缩写也都遵循这个习惯，例如Elastic Compute Cloud缩写为EC2等等。
S3说的玄乎一点可以叫云存储，通俗一点就是大网盘。其概念类似于分布式文家系统，同Google的GFS应该在一个层面。
目前的阿里的oss，腾讯的cos，七牛云存储都兼容aws的S3，所以要更换这些服务商之间提供的云存储非常容易，只需要简单的修改Access Key, Secrect Key等就行。
S3的定义如下 Amazon S3 is a web service that enables you to store data in the cloud. You can then download the data or use the data with other AWS services, such as Amazon Elastic Cloud Computer (EC2).
看来除了做网盘只用，S3存储的数据还可以被其他的亚马逊高层服务直接引用，这一点比国内的简单的网盘提供商高不少，亚马逊大网盘是其整体Solution中的有机组成部分。
基本概念 1. bucket – 类比于文件系统的目录 A bucket is a Container for objects stored in Amazon S3. Every object is contained in a bucket. For example, if the object named photos/puppy.jpg is stored in the johnsmith bucket, then it is addressable using the URL http://johnsmith.s3.amazonaws.com/photos/puppy.jpg
似乎目录不能嵌套，也就是不能有子目录，官方的说法是起到namespace的作用，是访问控制的基本单位，其实丫还是个目录。
2. Object – 类比文件系统的文件 对象中带有对象名名，对象属性，对象本身最大5G，其实也还是个文件。
目前object有Versioning的属性（即对象不同历史版本的cache概念），这个是文件系统不具备的，在早期看到的S3资料中没有这一概念，应该是演进的结果，其面对的应该是有版本控制的需求的用户。
3. Keys – 类比文件名 key的样式也是URL，记住亚马逊的服务都是使用Web Service或REST方式访问的。</description>
    </item>
    
    <item>
      <title>golang 判断目录或文件是否存在</title>
      <link>https://haokiu.com/blog/Cd6WaZ/</link>
      <pubDate>Thu, 17 Sep 2020 15:05:46 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/Cd6WaZ/</guid>
      <description>golang 判断目录或文件是否存在：
func Exist(path string) bool { _, err := os.Stat(path) return err == nil || os.IsExist(err) } </description>
    </item>
    
    <item>
      <title>beego bee 工具使用简介</title>
      <link>https://haokiu.com/blog/xVaucl/</link>
      <pubDate>Wed, 16 Sep 2020 16:06:47 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/xVaucl/</guid>
      <description>bee 工具是一个为了协助快速开发 beego 项目而创建的项目，通过 bee 您可以很容易的进行 beego 项目的创建、热编译、开发、测试、和部署。
bee 工具的安装 您可以通过如下的方式安装 bee 工具：
go get github.com/beego/bee 安装完之后，bee 可执行文件默认存放在 $GOPATH/bin 里面，所以您需要把 $GOPATH/bin 添加到您的环境变量中，才可以进行下一步。
如何添加环境变量，请自行搜索 如果你本机设置了 GOBIN，那么上面的命令就会安装到 GOBIN 下，请添加 GOBIN 到你的环境变量中
bee 工具命令详解 我们在命令行输入 bee，可以看到如下的信息：
Bee is a Fast and Flexible tool for managing your Beego Web Application. Usage: bee command [arguments] The commands are: version show the bee &amp;amp; beego version migrate run database migrations api create an api application base on beego framework bale packs non-Go files to Go source files new create an application base on beego framework run run the app which can hot compile pack compress an beego project fix Fixes your application by making it compatible with newer versions of Beego dlv Start a debugging session using Delve dockerize Generates a Dockerfile for your Beego application generate Source code generator hprose Creates an RPC application based on Hprose and Beego frameworks pack Compresses a Beego application into a single file rs Run customized scripts run Run the application by starting a local development server server serving static content over HTTP on port Use bee help [command] for more information about a command.</description>
    </item>
    
    <item>
      <title>beego 日志配置</title>
      <link>https://haokiu.com/blog/gq7FUH/</link>
      <pubDate>Wed, 16 Sep 2020 16:03:29 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/gq7FUH/</guid>
      <description>beego logs 的设计思路来自于 database/sql，目前支持的引擎有 file、console、net、smtp，可以通过如下方式进行安装：
go get github.com/astaxie/beego/logs 如何使用 通用方式 首先引入包：
import ( &amp;#34;github.com/astaxie/beego/logs&amp;#34; ) 然后添加输出引擎（log 支持同时输出到多个引擎），这里我们以 console 为例，第一个参数是引擎名（包括：console、file、conn、smtp、es、multifile）
logs.SetLogger(&amp;#34;console&amp;#34;) 添加输出引擎也支持第二个参数,用来表示配置信息，详细的配置请看下面介绍：
logs.SetLogger(logs.AdapterFile,`{&amp;#34;filename&amp;#34;:&amp;#34;project.log&amp;#34;,&amp;#34;level&amp;#34;:7,&amp;#34;maxlines&amp;#34;:0,&amp;#34;maxsize&amp;#34;:0,&amp;#34;daily&amp;#34;:true,&amp;#34;maxdays&amp;#34;:10,&amp;#34;color&amp;#34;:true}`) 然后我们就可以在我们的逻辑中开始任意的使用了：
package main import ( &amp;#34;github.com/astaxie/beego/logs&amp;#34; ) func main() { //an official log.Logger l := logs.GetLogger() l.Println(&amp;#34;this is a message of http&amp;#34;) //an official log.Logger with prefix ORM logs.GetLogger(&amp;#34;ORM&amp;#34;).Println(&amp;#34;this is a message of orm&amp;#34;) logs.Debug(&amp;#34;my book is bought in the year of &amp;#34;, 2016) logs.Info(&amp;#34;this %s cat is %v years old&amp;#34;, &amp;#34;yellow&amp;#34;, 3) logs.Warn(&amp;#34;json is a type of kv like&amp;#34;, map[string]int{&amp;#34;key&amp;#34;: 2016}) logs.Error(1024, &amp;#34;is a very&amp;#34;, &amp;#34;good game&amp;#34;) logs.Critical(&amp;#34;oh,crash&amp;#34;) } 多个实例 一般推荐使用通用方式进行日志，但依然支持单独声明来使用独立的日志
package main import ( &amp;#34;github.com/astaxie/beego/logs&amp;#34; ) func main() { log := logs.</description>
    </item>
    
    <item>
      <title>beego 日志处理</title>
      <link>https://haokiu.com/blog/YAotkP/</link>
      <pubDate>Wed, 16 Sep 2020 10:17:20 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/YAotkP/</guid>
      <description>beego 的日志处理是基于 logs 模块搭建的，内置了一个变量 BeeLogger，默认已经是 logs.BeeLogger 类型，初始化了 console，也就是默认输出到 console。
使用入门 一般在程序中我们使用如下的方式进行输出：
beego.Emergency(&amp;#34;this is emergency&amp;#34;) beego.Alert(&amp;#34;this is alert&amp;#34;) beego.Critical(&amp;#34;this is critical&amp;#34;) beego.Error(&amp;#34;this is error&amp;#34;) beego.Warning(&amp;#34;this is warning&amp;#34;) beego.Notice(&amp;#34;this is notice&amp;#34;) beego.Informational(&amp;#34;this is informational&amp;#34;) beego.Debug(&amp;#34;this is debug&amp;#34;) 设置输出 我们的程序往往期望把信息输出到 log 中，现在设置输出到文件很方便，如下所示：
beego.SetLogger(&amp;#34;file&amp;#34;, `{&amp;#34;filename&amp;#34;:&amp;#34;logs/test.log&amp;#34;}`) 更多详细的日志配置请查看 beego 日志配置
这个默认情况就会同时输出到两个地方，一个 console，一个 file，如果只想输出到文件，就需要调用删除操作：
beego.BeeLogger.DelLogger(&amp;#34;console&amp;#34;) 设置级别 日志的级别如上所示的代码这样分为八个级别：
LevelEmergency LevelAlert LevelCritical LevelError LevelWarning LevelNotice LevelInformational LevelDebug 级别依次降低，默认全部打印，但是一般我们在部署环境，可以通过设置级别设置日志级别：
beego.SetLevel(beego.LevelInformational) 输出文件名和行号 日志默认不输出调用的文件名和文件行号,如果你期望输出调用的文件名和文件行号,可以如下设置
beego.SetLogFuncCall(true) 开启传入参数 true, 关闭传入参数 false, 默认是关闭的.
完整示例 func internalCalculationFunc(x, y int) (result int, err error) { beego.Debug(&amp;#34;calculating z. x:&amp;#34;, x, &amp;#34; y:&amp;#34;, y) z := y switch { case x == 3: beego.Debug(&amp;#34;x == 3&amp;#34;) panic(&amp;#34;Failure.&amp;#34;) case y == 1: beego.</description>
    </item>
    
    <item>
      <title>计算机 数组</title>
      <link>https://haokiu.com/blog/OOuDn6/</link>
      <pubDate>Mon, 14 Sep 2020 14:46:37 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/OOuDn6/</guid>
      <description>这篇博客对数组的理解很深入，特别转发，原文地址：https://jiang-hao.com/articles/2020/backend-data-struct-array.html
定义 数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。
这个定义里有几个关键词，理解了这几个关键词，我想你就能彻底掌握数组的概念了。
首先是线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。
而与它相对立的概念是非线性表，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。
第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“随机访问”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。
随机访问 我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10]来举例。在下面这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。
我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：
a[i]_address=base_address+i∗data_type_sizea[i]_address=base_address+i∗data_type_size
其中 data_type_size 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。
这里要特别纠正一个“错误”。在面试的时候，常常会问数组和链表的区别，很多人都回答说，“链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)”。
实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。
低效的“插入”和“删除” 前面概念部分我们提到，数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效。现在我们就来详细说一下，究竟为什么会导致低效？又有哪些改进方法呢？
插入操作 设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。
如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。
如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。
为了更好地理解，我们举一个例子。假设数组 a[10]中存储了如下 5 个元素：a，b，c，d，e。
我们现在需要将元素 x 插入到第 3 个位置。我们只需要将 c 放入到 a[5]，将 a[2]赋值为 x 即可。最后，数组中的元素如下： a，b，x，d，e，c。
利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。这个处理思想在快排中也会用到。
删除操作 跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。
和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。
实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？
我们继续来看例子。数组 a[10]中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。</description>
    </item>
    
    <item>
      <title>golang interface</title>
      <link>https://haokiu.com/blog/BmxATZ/</link>
      <pubDate>Thu, 10 Sep 2020 09:38:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/BmxATZ/</guid>
      <description>interface Go语言里面设计最精妙的应该算interface，它让面向对象，内容组织实现非常的方便，当你看完这一章，你就会被interface的巧妙设计所折服。
什么是interface 简单的说，interface是一组method签名的组合，我们通过interface来定义对象的一组行为。
我们前面一章最后一个例子中Student和Employee都能SayHi，虽然他们的内部实现不一样，但是那不重要，重要的是他们都能say hi
让我们来继续做更多的扩展，Student和Employee实现另一个方法Sing，然后Student实现方法BorrowMoney而Employee实现SpendSalary。
这样Student实现了三个方法：SayHi、Sing、BorrowMoney；而Employee实现了SayHi、Sing、SpendSalary。
上面这些方法的组合称为interface(被对象Student和Employee实现)。例如Student和Employee都实现了interface：SayHi和Sing，也就是这两个对象是该interface类型。而Employee没有实现这个interface：SayHi、Sing和BorrowMoney，因为Employee没有实现BorrowMoney这个方法。
interface类型 interface类型定义了一组方法，如果某个对象实现了某个接口的所有方法，则此对象就实现了此接口。详细的语法参考下面这个例子
type Human struct { name string age int phone string } type Student struct { Human //匿名字段Human school string loan float32 } type Employee struct { Human //匿名字段Human company string money float32 } //Human对象实现Sayhi方法 func (h *Human) SayHi() { fmt.Printf(&amp;#34;Hi, I am %s you can call me on %s\n&amp;#34;, h.name, h.phone) } // Human对象实现Sing方法 func (h *Human) Sing(lyrics string) { fmt.Println(&amp;#34;La la, la la la, la la la la la...&amp;#34;, lyrics) } //Human对象实现Guzzle方法 func (h *Human) Guzzle(beerStein string) { fmt.Println(&amp;#34;Guzzle Guzzle Guzzle...&amp;#34;, beerStein) } // Employee重载Human的Sayhi方法 func (e *Employee) SayHi() { fmt.</description>
    </item>
    
    <item>
      <title>beego 的日志级别</title>
      <link>https://haokiu.com/blog/RAhBfF/</link>
      <pubDate>Wed, 09 Sep 2020 11:10:43 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/RAhBfF/</guid>
      <description>看 beego 的源码，beego 的日志分为7个级别：
const ( LevelEmergency = iota LevelAlert LevelCritical LevelError LevelWarning LevelNotice LevelInformational LevelDebug ) 转换为
LevelEmergency = 0 LevelAlert = 1 LevelCritical = 2 LevelError = 3 LevelWarning = 4 LevelNotice = 5 LevelInformational = 6 LevelDebug = 7 </description>
    </item>
    
    <item>
      <title>23中设计模式简介</title>
      <link>https://haokiu.com/blog/nG4mC7/</link>
      <pubDate>Tue, 08 Sep 2020 10:00:24 +0000</pubDate>
      
      <guid>https://haokiu.com/blog/nG4mC7/</guid>
      <description>设计模式主要分为三大类： 创建型模式 创建型模式关注对象的创建过程
工厂模式（Factory Method） 抽象工厂模式 单例模式 建造者模式 原型模式 结构型模式 结构型模式关注对象和类的组织
适配器模式 桥接模式 装饰模式 组合模式 外观模式 享元模式 代理模式 行为型模式 行为型模式关注系统中对象之间的相互交互，研究系统在运行时对象之间相互通信和协作，进一步明确对象的职责
模板方法模式 命令模式 迭代器模式 观察者模式 中介者模式 备忘录模式 解释器模式 状态模式 策略模式 职责链模式 访问者模式 详细说明 创建型模式 创建型模式关注对象的创建过程
1．抽象工厂模式
为一个产品族提供了统一的创建接口。当需要这个产品族的某一系列的时候，可以从抽象工厂中选出相应的系列创建一个具体的工厂类。
2．建造者模式
将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。
3．工厂方法模式
定义一个接口用于创建对象，但是让子类决定初始化哪个类。工厂方法把一个类的初始化下放到子类。
4．原型模式
用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。
5．单例模式
确保一个类只有一个实例，并提供对该实例的全局访问。
5．多例模式
确保一个类只有命名的实例，并提供对这些实例的全局访问。
对象池模式
通过回收利用对象避免获取和释放资源所需的昂贵成本。
惰性初始模式
推迟对象的创建、数据的计算等需要耗费较多资源的操作，只有在第一次访问的时候才执行。
资源获取为初始化
通过绑定到合适对象的生命周期来确保资源被适当地释放。
结构型模式 结构型模式关注对象和类的组织
6．适配器模式
将某个类的接口转换成客户端期望的另一个接口表示。适配器模式可以消除由于接口不匹配所造成的类兼容性问题。
7．桥接模式
将一个抽象与实现解耦，以便两者可以独立的变化。
8．组合模式
把多个对象组成树状结构来表示局部与整体，这样用户可以一样的对待单个对象和对象的组合。
9．装饰模式
向某个对象动态地添加更多的功能。修饰模式是除类继承外另一种扩展功能的方法。
10．外观模式
为子系统中的一组接口提供一个一致的界面， 外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。
11．享元
通过共享以便有效的支持大量小颗粒对象。
12．代理
为其他对象提供一个代理以控制对这个对象的访问。
行为型模式 行为型模式关注系统中对象之间的相互交互，研究系统在运行时对象之间相互通信和协作，进一步明确对象的职责
13．职责链
为解除请求的发送者和接收者之间耦合，而使多个对象都有机会处理这个请求。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它。
14．命令
将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化；对请求排队或记录请求日志，以及支持可取消的操作。
15．解释器
给定一个语言, 定义它的文法的一种表示，并定义一个解释器, 该解释器使用该表示来解释语言中的句子。
16．迭代器
提供一种方法顺序访问一个聚合对象中各个元素, 而又不需暴露该对象的内部表示。
17．中介者
包装了一系列对象相互作用的方式，使得这些对象不必相互明显作用，从而使它们可以松散偶合。当某些对象之间的作用发生改变时，不会立即影响其他的一些对象之间的作用，保证这些作用可以彼此独立的变化。
18．备忘录
备忘录对象是一个用来存储另外一个对象内部状态的快照的对象。备忘录模式的用意是在不破坏封装的条件下，将一个对象的状态捉住，并外部化，存储起来，从而可以在将来合适的时候把这个对象还原到存储起来的状态。
19．观察者模式
在对象间定义一个一对多的联系性，由此当一个对象改变了状态，所有其他相关的对象会被通知并且自动刷新。
20．状态
让一个对象在其内部状态改变的时候，其行为也随之改变。状态模式需要对每一个系统可能取得的状态创立一个状态类的子类。当系统的状态变化时，系统便改变所选的子类。
21．策略
定义一个算法的系列，将其各个分装，并且使他们有交互性。策略模式使得算法在用户使用的时候能独立的改变。
22．模板方法
模板方法模式准备一个抽象类，将部分逻辑以具体方法及具体构造子类的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。先构建一个顶级逻辑框架，而将逻辑的细节留给具体的子类去实现。
23．访问者
封装一些施加于某种数据结构元素之上的操作。一旦这些操作需要修改，接受这个操作的数据结构可以保持不变。访问者模式适用于数据结构相对未定的系统，它把数据结构和作用于结构上的操作之间的耦合解脱开，使得操作集合可以相对自由的演化。</description>
    </item>
    
  </channel>
</rss>
