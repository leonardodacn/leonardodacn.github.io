<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>DataX HdfsWriter 插件文档 | haokiu</title>
<meta name="keywords" content="datax">
<meta name="description" content="DataX HdfsWriter 插件文档 1 快速介绍 HdfsWriter提供向HDFS文件系统指定路径中写入TEXTFile文件和ORCFile文件,文件内容可与hive中表关联。
2 功能与限制 (1)、目前HdfsWriter仅支持textfile和orcfile两种格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表; (2)、由于HDFS是文件系统，不存在schema的概念，因此不支持对部分列写入; (3)、目前仅支持与以下Hive数据类型： 数值型：TINYINT,SMALLINT,INT,BIGINT,FLOAT,DOUBLE 字符串类型：STRING,VARCHAR,CHAR 布尔类型：BOOLEAN 时间类型：DATE,TIMESTAMP 目前不支持：decimal、binary、arrays、maps、structs、union类型; (4)、对于Hive分区表目前仅支持一次写入单个分区; (5)、对于textfile需用户保证写入hdfs文件的分隔符与在Hive上创建表时的分隔符一致,从而实现写入hdfs数据与Hive表字段关联; (6)、HdfsWriter实现过程是：首先根据用户指定的path，创建一个hdfs文件系统上不存在的临时目录，创建规则：path_随机；然后将读取的文件写入这个临时目录；全部写入后再将这个临时目录下的文件移动到用户指定目录（在创建文件时保证文件名不重复）; 最后删除临时目录。如果在中间过程发生网络中断等情况造成无法与hdfs建立连接，需要用户手动删除已经写入的文件和临时目录。 (7)、目前插件中Hive版本为1.1.1，Hadoop版本为2.7.1（Apache［为适配JDK1.7］,在Hadoop 2.5.0, Hadoop 2.6.0 和Hive 1.2.0测试环境中写入正常；其它版本需后期进一步测试； (8)、目前HdfsWriter支持Kerberos认证（注意：如果用户需要进行kerberos认证，那么用户使用的Hadoop集群版本需要和hdfsreader的Hadoop版本保持一致，如果高于hdfsreader的Hadoop版本，不保证kerberos认证有效） 3 功能说明 3.1 配置样例 { &#34;setting&#34;: {}, &#34;job&#34;: { &#34;setting&#34;: { &#34;speed&#34;: { &#34;channel&#34;: 2 } }, &#34;content&#34;: [ { &#34;reader&#34;: { &#34;name&#34;: &#34;txtfilereader&#34;, &#34;parameter&#34;: { &#34;path&#34;: [&#34;/Users/shf/workplace/txtWorkplace/job/dataorcfull.txt&#34;], &#34;encoding&#34;: &#34;UTF-8&#34;, &#34;column&#34;: [ { &#34;index&#34;: 0, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 1, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 2, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 3, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 4, &#34;type&#34;: &#34;DOUBLE&#34; }, { &#34;index&#34;: 5, &#34;type&#34;: &#34;DOUBLE&#34; }, { &#34;index&#34;: 6, &#34;type&#34;: &#34;STRING&#34; }, { &#34;index&#34;: 7, &#34;type&#34;: &#34;STRING&#34; }, { &#34;index&#34;: 8, &#34;type&#34;: &#34;STRING&#34; }, { &#34;index&#34;: 9, &#34;type&#34;: &#34;BOOLEAN&#34; }, { &#34;index&#34;: 10, &#34;type&#34;: &#34;date&#34; }, { &#34;index&#34;: 11, &#34;type&#34;: &#34;date&#34; } ], &#34;fieldDelimiter&#34;: &#34;\t&#34; } }, &#34;writer&#34;: { &#34;name&#34;: &#34;hdfswriter&#34;, &#34;parameter&#34;: { &#34;defaultFS&#34;: &#34;hdfs://xxx:port&#34;, &#34;fileType&#34;: &#34;orc&#34;, &#34;path&#34;: &#34;/user/hive/warehouse/writerorc.">
<meta name="author" content="">
<link rel="canonical" href="https://haokiu.com/dd5ebd2f221f4913ae09f61f3877725e/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css" integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U&#43;6hYRq/Ez/nm5vg=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://haokiu.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://haokiu.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://haokiu.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://haokiu.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://haokiu.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="DataX HdfsWriter 插件文档" />
<meta property="og:description" content="DataX HdfsWriter 插件文档 1 快速介绍 HdfsWriter提供向HDFS文件系统指定路径中写入TEXTFile文件和ORCFile文件,文件内容可与hive中表关联。
2 功能与限制 (1)、目前HdfsWriter仅支持textfile和orcfile两种格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表; (2)、由于HDFS是文件系统，不存在schema的概念，因此不支持对部分列写入; (3)、目前仅支持与以下Hive数据类型： 数值型：TINYINT,SMALLINT,INT,BIGINT,FLOAT,DOUBLE 字符串类型：STRING,VARCHAR,CHAR 布尔类型：BOOLEAN 时间类型：DATE,TIMESTAMP 目前不支持：decimal、binary、arrays、maps、structs、union类型; (4)、对于Hive分区表目前仅支持一次写入单个分区; (5)、对于textfile需用户保证写入hdfs文件的分隔符与在Hive上创建表时的分隔符一致,从而实现写入hdfs数据与Hive表字段关联; (6)、HdfsWriter实现过程是：首先根据用户指定的path，创建一个hdfs文件系统上不存在的临时目录，创建规则：path_随机；然后将读取的文件写入这个临时目录；全部写入后再将这个临时目录下的文件移动到用户指定目录（在创建文件时保证文件名不重复）; 最后删除临时目录。如果在中间过程发生网络中断等情况造成无法与hdfs建立连接，需要用户手动删除已经写入的文件和临时目录。 (7)、目前插件中Hive版本为1.1.1，Hadoop版本为2.7.1（Apache［为适配JDK1.7］,在Hadoop 2.5.0, Hadoop 2.6.0 和Hive 1.2.0测试环境中写入正常；其它版本需后期进一步测试； (8)、目前HdfsWriter支持Kerberos认证（注意：如果用户需要进行kerberos认证，那么用户使用的Hadoop集群版本需要和hdfsreader的Hadoop版本保持一致，如果高于hdfsreader的Hadoop版本，不保证kerberos认证有效） 3 功能说明 3.1 配置样例 { &#34;setting&#34;: {}, &#34;job&#34;: { &#34;setting&#34;: { &#34;speed&#34;: { &#34;channel&#34;: 2 } }, &#34;content&#34;: [ { &#34;reader&#34;: { &#34;name&#34;: &#34;txtfilereader&#34;, &#34;parameter&#34;: { &#34;path&#34;: [&#34;/Users/shf/workplace/txtWorkplace/job/dataorcfull.txt&#34;], &#34;encoding&#34;: &#34;UTF-8&#34;, &#34;column&#34;: [ { &#34;index&#34;: 0, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 1, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 2, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 3, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 4, &#34;type&#34;: &#34;DOUBLE&#34; }, { &#34;index&#34;: 5, &#34;type&#34;: &#34;DOUBLE&#34; }, { &#34;index&#34;: 6, &#34;type&#34;: &#34;STRING&#34; }, { &#34;index&#34;: 7, &#34;type&#34;: &#34;STRING&#34; }, { &#34;index&#34;: 8, &#34;type&#34;: &#34;STRING&#34; }, { &#34;index&#34;: 9, &#34;type&#34;: &#34;BOOLEAN&#34; }, { &#34;index&#34;: 10, &#34;type&#34;: &#34;date&#34; }, { &#34;index&#34;: 11, &#34;type&#34;: &#34;date&#34; } ], &#34;fieldDelimiter&#34;: &#34;\t&#34; } }, &#34;writer&#34;: { &#34;name&#34;: &#34;hdfswriter&#34;, &#34;parameter&#34;: { &#34;defaultFS&#34;: &#34;hdfs://xxx:port&#34;, &#34;fileType&#34;: &#34;orc&#34;, &#34;path&#34;: &#34;/user/hive/warehouse/writerorc." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://haokiu.com/dd5ebd2f221f4913ae09f61f3877725e/" /><meta property="article:section" content="4" />
<meta property="article:published_time" content="2021-02-02T17:45:01+00:00" />
<meta property="article:modified_time" content="2021-02-02T17:45:01+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="DataX HdfsWriter 插件文档"/>
<meta name="twitter:description" content="DataX HdfsWriter 插件文档 1 快速介绍 HdfsWriter提供向HDFS文件系统指定路径中写入TEXTFile文件和ORCFile文件,文件内容可与hive中表关联。
2 功能与限制 (1)、目前HdfsWriter仅支持textfile和orcfile两种格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表; (2)、由于HDFS是文件系统，不存在schema的概念，因此不支持对部分列写入; (3)、目前仅支持与以下Hive数据类型： 数值型：TINYINT,SMALLINT,INT,BIGINT,FLOAT,DOUBLE 字符串类型：STRING,VARCHAR,CHAR 布尔类型：BOOLEAN 时间类型：DATE,TIMESTAMP 目前不支持：decimal、binary、arrays、maps、structs、union类型; (4)、对于Hive分区表目前仅支持一次写入单个分区; (5)、对于textfile需用户保证写入hdfs文件的分隔符与在Hive上创建表时的分隔符一致,从而实现写入hdfs数据与Hive表字段关联; (6)、HdfsWriter实现过程是：首先根据用户指定的path，创建一个hdfs文件系统上不存在的临时目录，创建规则：path_随机；然后将读取的文件写入这个临时目录；全部写入后再将这个临时目录下的文件移动到用户指定目录（在创建文件时保证文件名不重复）; 最后删除临时目录。如果在中间过程发生网络中断等情况造成无法与hdfs建立连接，需要用户手动删除已经写入的文件和临时目录。 (7)、目前插件中Hive版本为1.1.1，Hadoop版本为2.7.1（Apache［为适配JDK1.7］,在Hadoop 2.5.0, Hadoop 2.6.0 和Hive 1.2.0测试环境中写入正常；其它版本需后期进一步测试； (8)、目前HdfsWriter支持Kerberos认证（注意：如果用户需要进行kerberos认证，那么用户使用的Hadoop集群版本需要和hdfsreader的Hadoop版本保持一致，如果高于hdfsreader的Hadoop版本，不保证kerberos认证有效） 3 功能说明 3.1 配置样例 { &#34;setting&#34;: {}, &#34;job&#34;: { &#34;setting&#34;: { &#34;speed&#34;: { &#34;channel&#34;: 2 } }, &#34;content&#34;: [ { &#34;reader&#34;: { &#34;name&#34;: &#34;txtfilereader&#34;, &#34;parameter&#34;: { &#34;path&#34;: [&#34;/Users/shf/workplace/txtWorkplace/job/dataorcfull.txt&#34;], &#34;encoding&#34;: &#34;UTF-8&#34;, &#34;column&#34;: [ { &#34;index&#34;: 0, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 1, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 2, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 3, &#34;type&#34;: &#34;long&#34; }, { &#34;index&#34;: 4, &#34;type&#34;: &#34;DOUBLE&#34; }, { &#34;index&#34;: 5, &#34;type&#34;: &#34;DOUBLE&#34; }, { &#34;index&#34;: 6, &#34;type&#34;: &#34;STRING&#34; }, { &#34;index&#34;: 7, &#34;type&#34;: &#34;STRING&#34; }, { &#34;index&#34;: 8, &#34;type&#34;: &#34;STRING&#34; }, { &#34;index&#34;: 9, &#34;type&#34;: &#34;BOOLEAN&#34; }, { &#34;index&#34;: 10, &#34;type&#34;: &#34;date&#34; }, { &#34;index&#34;: 11, &#34;type&#34;: &#34;date&#34; } ], &#34;fieldDelimiter&#34;: &#34;\t&#34; } }, &#34;writer&#34;: { &#34;name&#34;: &#34;hdfswriter&#34;, &#34;parameter&#34;: { &#34;defaultFS&#34;: &#34;hdfs://xxx:port&#34;, &#34;fileType&#34;: &#34;orc&#34;, &#34;path&#34;: &#34;/user/hive/warehouse/writerorc."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "4s",
      "item": "https://haokiu.com/4/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "DataX HdfsWriter 插件文档",
      "item": "https://haokiu.com/dd5ebd2f221f4913ae09f61f3877725e/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "DataX HdfsWriter 插件文档",
  "name": "DataX HdfsWriter 插件文档",
  "description": "DataX HdfsWriter 插件文档 1 快速介绍 HdfsWriter提供向HDFS文件系统指定路径中写入TEXTFile文件和ORCFile文件,文件内容可与hive中表关联。\n2 功能与限制 (1)、目前HdfsWriter仅支持textfile和orcfile两种格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表; (2)、由于HDFS是文件系统，不存在schema的概念，因此不支持对部分列写入; (3)、目前仅支持与以下Hive数据类型： 数值型：TINYINT,SMALLINT,INT,BIGINT,FLOAT,DOUBLE 字符串类型：STRING,VARCHAR,CHAR 布尔类型：BOOLEAN 时间类型：DATE,TIMESTAMP 目前不支持：decimal、binary、arrays、maps、structs、union类型; (4)、对于Hive分区表目前仅支持一次写入单个分区; (5)、对于textfile需用户保证写入hdfs文件的分隔符与在Hive上创建表时的分隔符一致,从而实现写入hdfs数据与Hive表字段关联; (6)、HdfsWriter实现过程是：首先根据用户指定的path，创建一个hdfs文件系统上不存在的临时目录，创建规则：path_随机；然后将读取的文件写入这个临时目录；全部写入后再将这个临时目录下的文件移动到用户指定目录（在创建文件时保证文件名不重复）; 最后删除临时目录。如果在中间过程发生网络中断等情况造成无法与hdfs建立连接，需要用户手动删除已经写入的文件和临时目录。 (7)、目前插件中Hive版本为1.1.1，Hadoop版本为2.7.1（Apache［为适配JDK1.7］,在Hadoop 2.5.0, Hadoop 2.6.0 和Hive 1.2.0测试环境中写入正常；其它版本需后期进一步测试； (8)、目前HdfsWriter支持Kerberos认证（注意：如果用户需要进行kerberos认证，那么用户使用的Hadoop集群版本需要和hdfsreader的Hadoop版本保持一致，如果高于hdfsreader的Hadoop版本，不保证kerberos认证有效） 3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: [\u0026#34;/Users/shf/workplace/txtWorkplace/job/dataorcfull.txt\u0026#34;], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;DOUBLE\u0026#34; }, { \u0026#34;index\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;DOUBLE\u0026#34; }, { \u0026#34;index\u0026#34;: 6, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, { \u0026#34;index\u0026#34;: 7, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, { \u0026#34;index\u0026#34;: 8, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, { \u0026#34;index\u0026#34;: 9, \u0026#34;type\u0026#34;: \u0026#34;BOOLEAN\u0026#34; }, { \u0026#34;index\u0026#34;: 10, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;index\u0026#34;: 11, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;\\t\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hdfswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;defaultFS\u0026#34;: \u0026#34;hdfs://xxx:port\u0026#34;, \u0026#34;fileType\u0026#34;: \u0026#34;orc\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/user/hive/warehouse/writerorc.",
  "keywords": [
    "datax"
  ],
  "articleBody": "DataX HdfsWriter 插件文档 1 快速介绍 HdfsWriter提供向HDFS文件系统指定路径中写入TEXTFile文件和ORCFile文件,文件内容可与hive中表关联。\n2 功能与限制 (1)、目前HdfsWriter仅支持textfile和orcfile两种格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表; (2)、由于HDFS是文件系统，不存在schema的概念，因此不支持对部分列写入; (3)、目前仅支持与以下Hive数据类型： 数值型：TINYINT,SMALLINT,INT,BIGINT,FLOAT,DOUBLE 字符串类型：STRING,VARCHAR,CHAR 布尔类型：BOOLEAN 时间类型：DATE,TIMESTAMP 目前不支持：decimal、binary、arrays、maps、structs、union类型; (4)、对于Hive分区表目前仅支持一次写入单个分区; (5)、对于textfile需用户保证写入hdfs文件的分隔符与在Hive上创建表时的分隔符一致,从而实现写入hdfs数据与Hive表字段关联; (6)、HdfsWriter实现过程是：首先根据用户指定的path，创建一个hdfs文件系统上不存在的临时目录，创建规则：path_随机；然后将读取的文件写入这个临时目录；全部写入后再将这个临时目录下的文件移动到用户指定目录（在创建文件时保证文件名不重复）; 最后删除临时目录。如果在中间过程发生网络中断等情况造成无法与hdfs建立连接，需要用户手动删除已经写入的文件和临时目录。 (7)、目前插件中Hive版本为1.1.1，Hadoop版本为2.7.1（Apache［为适配JDK1.7］,在Hadoop 2.5.0, Hadoop 2.6.0 和Hive 1.2.0测试环境中写入正常；其它版本需后期进一步测试； (8)、目前HdfsWriter支持Kerberos认证（注意：如果用户需要进行kerberos认证，那么用户使用的Hadoop集群版本需要和hdfsreader的Hadoop版本保持一致，如果高于hdfsreader的Hadoop版本，不保证kerberos认证有效） 3 功能说明 3.1 配置样例 { \"setting\": {}, \"job\": { \"setting\": { \"speed\": { \"channel\": 2 } }, \"content\": [ { \"reader\": { \"name\": \"txtfilereader\", \"parameter\": { \"path\": [\"/Users/shf/workplace/txtWorkplace/job/dataorcfull.txt\"], \"encoding\": \"UTF-8\", \"column\": [ { \"index\": 0, \"type\": \"long\" }, { \"index\": 1, \"type\": \"long\" }, { \"index\": 2, \"type\": \"long\" }, { \"index\": 3, \"type\": \"long\" }, { \"index\": 4, \"type\": \"DOUBLE\" }, { \"index\": 5, \"type\": \"DOUBLE\" }, { \"index\": 6, \"type\": \"STRING\" }, { \"index\": 7, \"type\": \"STRING\" }, { \"index\": 8, \"type\": \"STRING\" }, { \"index\": 9, \"type\": \"BOOLEAN\" }, { \"index\": 10, \"type\": \"date\" }, { \"index\": 11, \"type\": \"date\" } ], \"fieldDelimiter\": \"\\t\" } }, \"writer\": { \"name\": \"hdfswriter\", \"parameter\": { \"defaultFS\": \"hdfs://xxx:port\", \"fileType\": \"orc\", \"path\": \"/user/hive/warehouse/writerorc.db/orcfull\", \"fileName\": \"xxxx\", \"column\": [ { \"name\": \"col1\", \"type\": \"TINYINT\" }, { \"name\": \"col2\", \"type\": \"SMALLINT\" }, { \"name\": \"col3\", \"type\": \"INT\" }, { \"name\": \"col4\", \"type\": \"BIGINT\" }, { \"name\": \"col5\", \"type\": \"FLOAT\" }, { \"name\": \"col6\", \"type\": \"DOUBLE\" }, { \"name\": \"col7\", \"type\": \"STRING\" }, { \"name\": \"col8\", \"type\": \"VARCHAR\" }, { \"name\": \"col9\", \"type\": \"CHAR\" }, { \"name\": \"col10\", \"type\": \"BOOLEAN\" }, { \"name\": \"col11\", \"type\": \"date\" }, { \"name\": \"col12\", \"type\": \"TIMESTAMP\" } ], \"writeMode\": \"append\", \"fieldDelimiter\": \"\\t\", \"compress\":\"NONE\" } } } ] } } 3.2 参数说明 defaultFS\n描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000\n必选：是 默认值：无 fileType\n描述：文件的类型，目前只支持用户配置为\"text\"或\"orc\"。 text表示textfile文件格式\norc表示orcfile文件格式\n必选：是 默认值：无 path\n描述：存储到Hadoop hdfs文件系统的路径信息，HdfsWriter会根据并发配置在Path目录下写入多个文件。为与hive表关联，请填写hive表在hdfs上的存储路径。例：Hive上设置的数据仓库的存储路径为：/user/hive/warehouse/ ，已建立数据库：test，表：hello；则对应的存储路径为：/user/hive/warehouse/test.db/hello 必选：是 默认值：无 fileName\n描述：HdfsWriter写入时的文件名，实际执行时会在该文件名后添加随机的后缀作为每个线程写入实际文件名。 必选：是 默认值：无 column\n描述：写入数据的字段，不支持对部分列写入。为与hive中表关联，需要指定表中所有字段名和字段类型，其中：name指定字段名，type指定字段类型。 用户可以指定Column字段信息，配置如下：\n\"column\": [ { \"name\": \"userName\", \"type\": \"string\" }, { \"name\": \"age\", \"type\": \"long\" } ] 必选：是 默认值：无 writeMode\n描述：hdfswriter写入前数据清理处理模式： append，写入前不做任何处理，DataX hdfswriter直接使用filename写入，并保证文件名不冲突。 nonConflict，如果目录下有fileName前缀的文件，直接报错。 必选：是 默认值：无 fieldDelimiter\n描述：hdfswriter写入时的字段分隔符,需要用户保证与创建的Hive表的字段分隔符一致，否则无法在Hive表中查到数据 必选：是 默认值：无 compress\n描述：hdfs文件压缩类型，默认不填写意味着没有压缩。其中：text类型文件支持压缩类型有gzip、bzip2;orc类型文件支持的压缩类型有NONE、SNAPPY（需要用户安装SnappyCodec）。 必选：否 默认值：无压缩 hadoopConfig\n描述：hadoopConfig里可以配置与Hadoop相关的一些高级参数，比如HA的配置。\n\"hadoopConfig\":{ \"dfs.nameservices\": \"testDfs\", \"dfs.ha.namenodes.testDfs\": \"namenode1,namenode2\", \"dfs.namenode.rpc-address.aliDfs.namenode1\": \"\", \"dfs.namenode.rpc-address.aliDfs.namenode2\": \"\", \"dfs.client.failover.proxy.provider.testDfs\": \"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\" } 必选：否 默认值：无 encoding\n描述：写文件的编码配置。\n必选：否 默认值：utf-8，慎重修改 haveKerberos\n描述：是否有Kerberos认证，默认false\n例如如果用户配置true，则配置项kerberosKeytabFilePath，kerberosPrincipal为必填。\n必选：haveKerberos 为true必选 默认值：false kerberosKeytabFilePath\n描述：Kerberos认证 keytab文件路径，绝对路径\n必选：否 默认值：无 kerberosPrincipal\n描述：Kerberos认证Principal名，如xxxx/hadoopclient@xxx.xxx 必选：haveKerberos 为true必选 默认值：无 3.3 类型转换 目前 HdfsWriter 支持大部分 Hive 类型，请注意检查你的类型。\n下面列出 HdfsWriter 针对 Hive 数据类型转换列表:\nDataX 内部类型 HIVE 数据类型 Long TINYINT,SMALLINT,INT,BIGINT Double FLOAT,DOUBLE String STRING,VARCHAR,CHAR Boolean BOOLEAN Date DATE,TIMESTAMP 4 配置步骤 步骤一、在Hive中创建数据库、表 Hive数据库在HDFS上存储配置,在hive安装目录下 conf/hive-site.xml文件中配置，默认值为：/user/hive/warehouse 如下所示： hive.metastore.warehouse.dir /user/hive/warehouse location of default database for the warehouse Hive建库／建表语法 参考 Hive操作手册\n例： （1）建立存储为textfile文件类型的表\ncreate database IF NOT EXISTS hdfswriter; use hdfswriter; create table text_table( col1 TINYINT, col2 SMALLINT, col3 INT, col4 BIGINT, col5 FLOAT, col6 DOUBLE, col7 STRING, col8 VARCHAR(10), col9 CHAR(10), col10 BOOLEAN, col11 date, col12 TIMESTAMP ) row format delimited fields terminated by \"\\t\" STORED AS TEXTFILE; text_table在hdfs上存储路径为：/user/hive/warehouse/hdfswriter.db/text_table/\n（2）建立存储为orcfile文件类型的表\ncreate database IF NOT EXISTS hdfswriter; use hdfswriter; create table orc_table( col1 TINYINT, col2 SMALLINT, col3 INT, col4 BIGINT, col5 FLOAT, col6 DOUBLE, col7 STRING, col8 VARCHAR(10), col9 CHAR(10), col10 BOOLEAN, col11 date, col12 TIMESTAMP ) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t' STORED AS ORC; orc_table在hdfs上存储路径为：/user/hive/warehouse/hdfswriter.db/orc_table/\n步骤二、根据步骤一的配置信息配置HdfsWriter作业 5 约束限制 略\n6 FAQ 略\n",
  "wordCount" : "480",
  "inLanguage": "en",
  "datePublished": "2021-02-02T17:45:01Z",
  "dateModified": "2021-02-02T17:45:01Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://haokiu.com/dd5ebd2f221f4913ae09f61f3877725e/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "haokiu",
    "logo": {
      "@type": "ImageObject",
      "url": "https://haokiu.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://haokiu.com/" accesskey="h" title="haokiu (Alt + H)">haokiu</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://haokiu.com/" title="haokiu">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://haokiu.com/1/" title="1s">
                    <span>后端</span>
                </a>
            </li>
            <li>
                <a href="https://haokiu.com/2/" title="2s">
                    <span>前端</span>
                </a>
            </li>
            <li>
                <a href="https://haokiu.com/3/" title="3s">
                    <span>区块链</span>
                </a>
            </li>
            <li>
                <a href="https://haokiu.com/4/" title="4s">
                    <span>大数据</span>
                </a>
            </li>
            <li>
                <a href="https://haokiu.com/5/" title="5s">
                    <span>linux</span>
                </a>
            </li>
            <li>
                <a href="https://haokiu.com/6/" title="6s">
                    <span>其他</span>
                </a>
            </li>
            <li>
                <a href="https://haokiu.com/tags/" title="Tags">
                    <span>tags</span>
                </a>
            </li>
            <li>
                <a href="https://haokiu.com/categories/" title="Categories">
                    <span>categories</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://haokiu.com/">Home</a>&nbsp;»&nbsp;<a href="https://haokiu.com/4/">4s</a></div>
    <h1 class="post-title">
      DataX HdfsWriter 插件文档
    </h1>
    <div class="post-meta"><span title='2021-02-02 17:45:01 +0000 UTC'>February 2, 2021</span>

</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#datax-hdfswriter-%e6%8f%92%e4%bb%b6%e6%96%87%e6%a1%a3" aria-label="DataX HdfsWriter 插件文档">DataX HdfsWriter 插件文档</a><ul>
                        
                <li>
                    <a href="#1-%e5%bf%ab%e9%80%9f%e4%bb%8b%e7%bb%8d" aria-label="1 快速介绍">1 快速介绍</a></li>
                <li>
                    <a href="#2-%e5%8a%9f%e8%83%bd%e4%b8%8e%e9%99%90%e5%88%b6" aria-label="2 功能与限制">2 功能与限制</a></li>
                <li>
                    <a href="#3-%e5%8a%9f%e8%83%bd%e8%af%b4%e6%98%8e" aria-label="3 功能说明">3 功能说明</a><ul>
                        
                <li>
                    <a href="#31-%e9%85%8d%e7%bd%ae%e6%a0%b7%e4%be%8b" aria-label="3.1 配置样例">3.1 配置样例</a></li>
                <li>
                    <a href="#32-%e5%8f%82%e6%95%b0%e8%af%b4%e6%98%8e" aria-label="3.2 参数说明">3.2 参数说明</a></li>
                <li>
                    <a href="#33-%e7%b1%bb%e5%9e%8b%e8%bd%ac%e6%8d%a2" aria-label="3.3 类型转换">3.3 类型转换</a></li></ul>
                </li>
                <li>
                    <a href="#4-%e9%85%8d%e7%bd%ae%e6%ad%a5%e9%aa%a4" aria-label="4 配置步骤">4 配置步骤</a></li>
                <li>
                    <a href="#5-%e7%ba%a6%e6%9d%9f%e9%99%90%e5%88%b6" aria-label="5 约束限制">5 约束限制</a></li>
                <li>
                    <a href="#6-faq" aria-label="6 FAQ">6 FAQ</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="datax-hdfswriter-插件文档">DataX HdfsWriter 插件文档</h1>
<hr>
<h2 id="1-快速介绍">1 快速介绍</h2>
<p>HdfsWriter提供向HDFS文件系统指定路径中写入TEXTFile文件和ORCFile文件,文件内容可与hive中表关联。</p>
<h2 id="2-功能与限制">2 功能与限制</h2>
<ul>
<li>(1)、目前HdfsWriter仅支持textfile和orcfile两种格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表;</li>
<li>(2)、由于HDFS是文件系统，不存在schema的概念，因此不支持对部分列写入;</li>
<li>(3)、目前仅支持与以下Hive数据类型：
数值型：TINYINT,SMALLINT,INT,BIGINT,FLOAT,DOUBLE
字符串类型：STRING,VARCHAR,CHAR
布尔类型：BOOLEAN
时间类型：DATE,TIMESTAMP
<strong>目前不支持：decimal、binary、arrays、maps、structs、union类型</strong>;</li>
<li>(4)、对于Hive分区表目前仅支持一次写入单个分区;</li>
<li>(5)、对于textfile需用户保证写入hdfs文件的分隔符<strong>与在Hive上创建表时的分隔符一致</strong>,从而实现写入hdfs数据与Hive表字段关联;</li>
<li>(6)、HdfsWriter实现过程是：首先根据用户指定的path，创建一个hdfs文件系统上不存在的临时目录，创建规则：path_随机；然后将读取的文件写入这个临时目录；全部写入后再将这个临时目录下的文件移动到用户指定目录（在创建文件时保证文件名不重复）; 最后删除临时目录。如果在中间过程发生网络中断等情况造成无法与hdfs建立连接，需要用户手动删除已经写入的文件和临时目录。</li>
<li>(7)、目前插件中Hive版本为1.1.1，Hadoop版本为2.7.1（Apache［为适配JDK1.7］,在Hadoop 2.5.0, Hadoop 2.6.0 和Hive 1.2.0测试环境中写入正常；其它版本需后期进一步测试；</li>
<li>(8)、目前HdfsWriter支持Kerberos认证（注意：如果用户需要进行kerberos认证，那么用户使用的Hadoop集群版本需要和hdfsreader的Hadoop版本保持一致，如果高于hdfsreader的Hadoop版本，不保证kerberos认证有效）</li>
</ul>
<h2 id="3-功能说明">3 功能说明</h2>
<h3 id="31-配置样例">3.1 配置样例</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;setting&#34;</span>: {},
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&#34;job&#34;</span>: {
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;setting&#34;</span>: {
</span></span><span style="display:flex;"><span>            <span style="color:#f92672">&#34;speed&#34;</span>: {
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">&#34;channel&#34;</span>: <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        },
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;content&#34;</span>: [
</span></span><span style="display:flex;"><span>            {
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">&#34;reader&#34;</span>: {
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;txtfilereader&#34;</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">&#34;parameter&#34;</span>: {
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;path&#34;</span>: [<span style="color:#e6db74">&#34;/Users/shf/workplace/txtWorkplace/job/dataorcfull.txt&#34;</span>],
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;encoding&#34;</span>: <span style="color:#e6db74">&#34;UTF-8&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;column&#34;</span>: [
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">0</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;long&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">1</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;long&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">2</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;long&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">3</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;long&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">4</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;DOUBLE&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">5</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;DOUBLE&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">6</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;STRING&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">7</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;STRING&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">8</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;STRING&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">9</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;BOOLEAN&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;date&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;index&#34;</span>: <span style="color:#ae81ff">11</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;date&#34;</span>
</span></span><span style="display:flex;"><span>                            }
</span></span><span style="display:flex;"><span>                        ],
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;fieldDelimiter&#34;</span>: <span style="color:#e6db74">&#34;\t&#34;</span>
</span></span><span style="display:flex;"><span>                    }
</span></span><span style="display:flex;"><span>                },
</span></span><span style="display:flex;"><span>                <span style="color:#f92672">&#34;writer&#34;</span>: {
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;hdfswriter&#34;</span>,
</span></span><span style="display:flex;"><span>                    <span style="color:#f92672">&#34;parameter&#34;</span>: {
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;defaultFS&#34;</span>: <span style="color:#e6db74">&#34;hdfs://xxx:port&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;fileType&#34;</span>: <span style="color:#e6db74">&#34;orc&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;path&#34;</span>: <span style="color:#e6db74">&#34;/user/hive/warehouse/writerorc.db/orcfull&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;fileName&#34;</span>: <span style="color:#e6db74">&#34;xxxx&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;column&#34;</span>: [
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col1&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;TINYINT&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col2&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;SMALLINT&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col3&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;INT&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col4&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;BIGINT&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col5&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;FLOAT&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col6&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;DOUBLE&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col7&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;STRING&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col8&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;VARCHAR&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col9&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;CHAR&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col10&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;BOOLEAN&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col11&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;date&#34;</span>
</span></span><span style="display:flex;"><span>                            },
</span></span><span style="display:flex;"><span>                            {
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;col12&#34;</span>,
</span></span><span style="display:flex;"><span>                                <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;TIMESTAMP&#34;</span>
</span></span><span style="display:flex;"><span>                            }
</span></span><span style="display:flex;"><span>                        ],
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;writeMode&#34;</span>: <span style="color:#e6db74">&#34;append&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;fieldDelimiter&#34;</span>: <span style="color:#e6db74">&#34;\t&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;compress&#34;</span>:<span style="color:#e6db74">&#34;NONE&#34;</span>
</span></span><span style="display:flex;"><span>                    }
</span></span><span style="display:flex;"><span>                }
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>        ]
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h3 id="32-参数说明">3.2 参数说明</h3>
<ul>
<li>
<p><strong>defaultFS</strong></p>
<ul>
<li>
<p>描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000<!-- raw HTML omitted --></p>
</li>
<li>
<p>必选：是 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>fileType</strong></p>
<ul>
<li>
<p>描述：文件的类型，目前只支持用户配置为&quot;text&quot;或&quot;orc&quot;。 <!-- raw HTML omitted --></p>
<p>text表示textfile文件格式</p>
<p>orc表示orcfile文件格式</p>
</li>
<li>
<p>必选：是 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>path</strong></p>
<ul>
<li>
<p>描述：存储到Hadoop hdfs文件系统的路径信息，HdfsWriter会根据并发配置在Path目录下写入多个文件。为与hive表关联，请填写hive表在hdfs上的存储路径。例：Hive上设置的数据仓库的存储路径为：/user/hive/warehouse/ ，已建立数据库：test，表：hello；则对应的存储路径为：/user/hive/warehouse/test.db/hello  <!-- raw HTML omitted --></p>
</li>
<li>
<p>必选：是 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>fileName</strong></p>
<ul>
<li>
<p>描述：HdfsWriter写入时的文件名，实际执行时会在该文件名后添加随机的后缀作为每个线程写入实际文件名。 <!-- raw HTML omitted --></p>
</li>
<li>
<p>必选：是 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>column</strong></p>
<ul>
<li>
<p>描述：写入数据的字段，不支持对部分列写入。为与hive中表关联，需要指定表中所有字段名和字段类型，其中：name指定字段名，type指定字段类型。 <!-- raw HTML omitted --></p>
<p>用户可以指定Column字段信息，配置如下：</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span><span style="color:#e6db74">&#34;column&#34;</span><span style="color:#960050;background-color:#1e0010">:</span>
</span></span><span style="display:flex;"><span>         [
</span></span><span style="display:flex;"><span>                    {
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;userName&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;string&#34;</span>
</span></span><span style="display:flex;"><span>                    },
</span></span><span style="display:flex;"><span>                    {
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;name&#34;</span>: <span style="color:#e6db74">&#34;age&#34;</span>,
</span></span><span style="display:flex;"><span>                        <span style="color:#f92672">&#34;type&#34;</span>: <span style="color:#e6db74">&#34;long&#34;</span>
</span></span><span style="display:flex;"><span>                    }
</span></span><span style="display:flex;"><span>         ]
</span></span></code></pre></div></li>
<li>
<p>必选：是 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>writeMode</strong></p>
<ul>
<li>
<p>描述：hdfswriter写入前数据清理处理模式： <!-- raw HTML omitted --></p>
<ul>
<li>append，写入前不做任何处理，DataX hdfswriter直接使用filename写入，并保证文件名不冲突。</li>
<li>nonConflict，如果目录下有fileName前缀的文件，直接报错。</li>
</ul>
</li>
<li>
<p>必选：是 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>fieldDelimiter</strong></p>
<ul>
<li>
<p>描述：hdfswriter写入时的字段分隔符,<strong>需要用户保证与创建的Hive表的字段分隔符一致，否则无法在Hive表中查到数据</strong> <!-- raw HTML omitted --></p>
</li>
<li>
<p>必选：是 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>compress</strong></p>
<ul>
<li>
<p>描述：hdfs文件压缩类型，默认不填写意味着没有压缩。其中：text类型文件支持压缩类型有gzip、bzip2;orc类型文件支持的压缩类型有NONE、SNAPPY（需要用户安装SnappyCodec）。 <!-- raw HTML omitted --></p>
</li>
<li>
<p>必选：否 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无压缩 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>hadoopConfig</strong></p>
<ul>
<li>
<p>描述：hadoopConfig里可以配置与Hadoop相关的一些高级参数，比如HA的配置。<!-- raw HTML omitted --></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span><span style="color:#e6db74">&#34;hadoopConfig&#34;</span><span style="color:#960050;background-color:#1e0010">:</span>{
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;dfs.nameservices&#34;</span>: <span style="color:#e6db74">&#34;testDfs&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;dfs.ha.namenodes.testDfs&#34;</span>: <span style="color:#e6db74">&#34;namenode1,namenode2&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;dfs.namenode.rpc-address.aliDfs.namenode1&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;dfs.namenode.rpc-address.aliDfs.namenode2&#34;</span>: <span style="color:#e6db74">&#34;&#34;</span>,
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">&#34;dfs.client.failover.proxy.provider.testDfs&#34;</span>: <span style="color:#e6db74">&#34;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&#34;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div></li>
<li>
<p>必选：否 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>encoding</strong></p>
<ul>
<li>
<p>描述：写文件的编码配置。<!-- raw HTML omitted --></p>
</li>
<li>
<p>必选：否 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：utf-8，<strong>慎重修改</strong> <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>haveKerberos</strong></p>
<ul>
<li>
<p>描述：是否有Kerberos认证，默认false<!-- raw HTML omitted --></p>
<p>例如如果用户配置true，则配置项kerberosKeytabFilePath，kerberosPrincipal为必填。</p>
</li>
<li>
<p>必选：haveKerberos 为true必选 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：false <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>kerberosKeytabFilePath</strong></p>
<ul>
<li>
<p>描述：Kerberos认证 keytab文件路径，绝对路径<!-- raw HTML omitted --></p>
</li>
<li>
<p>必选：否 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
<li>
<p><strong>kerberosPrincipal</strong></p>
<ul>
<li>
<p>描述：Kerberos认证Principal名，如xxxx/hadoopclient@xxx.xxx <!-- raw HTML omitted --></p>
</li>
<li>
<p>必选：haveKerberos 为true必选 <!-- raw HTML omitted --></p>
</li>
<li>
<p>默认值：无 <!-- raw HTML omitted --></p>
</li>
</ul>
</li>
</ul>
<h3 id="33-类型转换">3.3 类型转换</h3>
<p>目前 HdfsWriter 支持大部分 Hive 类型，请注意检查你的类型。</p>
<p>下面列出 HdfsWriter 针对 Hive 数据类型转换列表:</p>
<table>
<thead>
<tr>
<th>DataX 内部类型</th>
<th>HIVE 数据类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>Long</td>
<td>TINYINT,SMALLINT,INT,BIGINT</td>
</tr>
<tr>
<td>Double</td>
<td>FLOAT,DOUBLE</td>
</tr>
<tr>
<td>String</td>
<td>STRING,VARCHAR,CHAR</td>
</tr>
<tr>
<td>Boolean</td>
<td>BOOLEAN</td>
</tr>
<tr>
<td>Date</td>
<td>DATE,TIMESTAMP</td>
</tr>
</tbody>
</table>
<h2 id="4-配置步骤">4 配置步骤</h2>
<ul>
<li>步骤一、在Hive中创建数据库、表
Hive数据库在HDFS上存储配置,在hive安装目录下 conf/hive-site.xml文件中配置，默认值为：/user/hive/warehouse
如下所示：</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-xml" data-lang="xml"><span style="display:flex;"><span><span style="color:#f92672">&lt;property&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;name&gt;</span>hive.metastore.warehouse.dir<span style="color:#f92672">&lt;/name&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;value&gt;</span>/user/hive/warehouse<span style="color:#f92672">&lt;/value&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">&lt;description&gt;</span>location of default database for the warehouse<span style="color:#f92672">&lt;/description&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&lt;/property&gt;</span>
</span></span></code></pre></div><p>Hive建库／建表语法 参考 <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual">Hive操作手册</a></p>
<p>例：
（1）建立存储为textfile文件类型的表</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">create</span> <span style="color:#960050;background-color:#1e0010">database</span> <span style="color:#960050;background-color:#1e0010">IF</span> <span style="color:#960050;background-color:#1e0010">NOT</span> <span style="color:#960050;background-color:#1e0010">EXISTS</span> <span style="color:#960050;background-color:#1e0010">hdfswriter;</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">use</span> <span style="color:#960050;background-color:#1e0010">hdfswriter;</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">create</span> <span style="color:#960050;background-color:#1e0010">table</span> <span style="color:#960050;background-color:#1e0010">text_table(</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">1</span>  <span style="color:#960050;background-color:#1e0010">TINYINT,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">2</span>  <span style="color:#960050;background-color:#1e0010">SMALLINT,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">3</span>  <span style="color:#960050;background-color:#1e0010">INT,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">4</span>  <span style="color:#960050;background-color:#1e0010">BIGINT,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">5</span>  <span style="color:#960050;background-color:#1e0010">FLOAT,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">6</span>  <span style="color:#960050;background-color:#1e0010">DOUBLE,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">7</span>  <span style="color:#960050;background-color:#1e0010">STRING,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">8</span>  <span style="color:#960050;background-color:#1e0010">VARCHAR(</span><span style="color:#ae81ff">10</span><span style="color:#960050;background-color:#1e0010">),</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">9</span>  <span style="color:#960050;background-color:#1e0010">CHAR(</span><span style="color:#ae81ff">10</span><span style="color:#960050;background-color:#1e0010">),</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">10</span>  <span style="color:#960050;background-color:#1e0010">BOOLEAN,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">11</span> <span style="color:#960050;background-color:#1e0010">date,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">12</span> <span style="color:#960050;background-color:#1e0010">TIMESTAMP</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">)</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">row</span> <span style="color:#960050;background-color:#1e0010">format</span> <span style="color:#960050;background-color:#1e0010">delimited</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">fields</span> <span style="color:#960050;background-color:#1e0010">terminated</span> <span style="color:#960050;background-color:#1e0010">by</span> <span style="color:#e6db74">&#34;\t&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">STORED</span> <span style="color:#960050;background-color:#1e0010">AS</span> <span style="color:#960050;background-color:#1e0010">TEXTFILE;</span>
</span></span></code></pre></div><p>text_table在hdfs上存储路径为：/user/hive/warehouse/hdfswriter.db/text_table/</p>
<p>（2）建立存储为orcfile文件类型的表</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-json" data-lang="json"><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">create</span> <span style="color:#960050;background-color:#1e0010">database</span> <span style="color:#960050;background-color:#1e0010">IF</span> <span style="color:#960050;background-color:#1e0010">NOT</span> <span style="color:#960050;background-color:#1e0010">EXISTS</span> <span style="color:#960050;background-color:#1e0010">hdfswriter;</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">use</span> <span style="color:#960050;background-color:#1e0010">hdfswriter;</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">create</span> <span style="color:#960050;background-color:#1e0010">table</span> <span style="color:#960050;background-color:#1e0010">orc_table(</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">1</span>  <span style="color:#960050;background-color:#1e0010">TINYINT,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">2</span>  <span style="color:#960050;background-color:#1e0010">SMALLINT,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">3</span>  <span style="color:#960050;background-color:#1e0010">INT,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">4</span>  <span style="color:#960050;background-color:#1e0010">BIGINT,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">5</span>  <span style="color:#960050;background-color:#1e0010">FLOAT,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">6</span>  <span style="color:#960050;background-color:#1e0010">DOUBLE,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">7</span>  <span style="color:#960050;background-color:#1e0010">STRING,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">8</span>  <span style="color:#960050;background-color:#1e0010">VARCHAR(</span><span style="color:#ae81ff">10</span><span style="color:#960050;background-color:#1e0010">),</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">9</span>  <span style="color:#960050;background-color:#1e0010">CHAR(</span><span style="color:#ae81ff">10</span><span style="color:#960050;background-color:#1e0010">),</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">10</span>  <span style="color:#960050;background-color:#1e0010">BOOLEAN,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">11</span> <span style="color:#960050;background-color:#1e0010">date,</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">col</span><span style="color:#ae81ff">12</span> <span style="color:#960050;background-color:#1e0010">TIMESTAMP</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">)</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">ROW</span> <span style="color:#960050;background-color:#1e0010">FORMAT</span> <span style="color:#960050;background-color:#1e0010">DELIMITED</span> <span style="color:#960050;background-color:#1e0010">FIELDS</span> <span style="color:#960050;background-color:#1e0010">TERMINATED</span> <span style="color:#960050;background-color:#1e0010">BY</span> <span style="color:#960050;background-color:#1e0010">&#39;\t&#39;</span>
</span></span><span style="display:flex;"><span><span style="color:#960050;background-color:#1e0010">STORED</span> <span style="color:#960050;background-color:#1e0010">AS</span> <span style="color:#960050;background-color:#1e0010">ORC;</span>
</span></span></code></pre></div><p>orc_table在hdfs上存储路径为：/user/hive/warehouse/hdfswriter.db/orc_table/</p>
<ul>
<li>步骤二、根据步骤一的配置信息配置HdfsWriter作业</li>
</ul>
<h2 id="5-约束限制">5 约束限制</h2>
<p>略</p>
<h2 id="6-faq">6 FAQ</h2>
<p>略</p>

  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://haokiu.com/tags/datax/">datax</a></li>
    </ul>

  </footer>
</article>
    </main>
    
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
