[{"content":"Gate.io芝麻开门创立于2013年，是全球真实交易量TOP10的数字资产交易平台。\n作为全球首家提供100%保证金审计证明的交易所，Gate.io在全球多个国家进行合法注册，向全球数千万用户提供安全可靠、真实透明的数字资产交易服务。\n使用下面的链接注册，可以获得平台的奖励\nhttps://www.gate.io/ref/XgBMB1A/haokiu?ref_type?=102\n","permalink":"https://haokiu.com/blog/gateio/","summary":"Gate.io芝麻开门创立于2013年，是全球真实交易量TOP10的数字资产交易平台。\n作为全球首家提供100%保证金审计证明的交易所，Gate.io在全球多个国家进行合法注册，向全球数千万用户提供安全可靠、真实透明的数字资产交易服务。\n使用下面的链接注册，可以获得平台的奖励\nhttps://www.gate.io/ref/XgBMB1A/haokiu?ref_type?=102","title":"数字货币交易所-gateio"},{"content":"The enkrypt invite code is FC433A\nMint tickets with Enkrypt every day, invite friends to earn more tickets.\nMore tickets — more chances to win!\nShare your code with friends and get +1 ticket for every friend’s mint.\nCode FC433A\naddress：https://raffle.enkrypt.com\n","permalink":"https://haokiu.com/blog/wgJnpu/","summary":"The enkrypt invite code is FC433A\nMint tickets with Enkrypt every day, invite friends to earn more tickets.\nMore tickets — more chances to win!\nShare your code with friends and get +1 ticket for every friend’s mint.\nCode FC433A\naddress：https://raffle.enkrypt.com","title":"enkrypt invite code FC433A"},{"content":"googo 可以让你更好的浏览外文网站，比如meta、youtube，google等。 它之前的网址是googo.in，现在已经不用访问。是一款非常好用的科学上网工具，使用简单。\n使用这个链接可以获取优惠：https://cn.googo.us/#/register?code=lbVOQjeS\n或者使用这个邀请码：lbVOQjeS\n","permalink":"https://haokiu.com/blog/googo/","summary":"googo 可以让你更好的浏览外文网站，比如meta、youtube，google等。 它之前的网址是googo.in，现在已经不用访问。是一款非常好用的科学上网工具，使用简单。\n使用这个链接可以获取优惠：https://cn.googo.us/#/register?code=lbVOQjeS\n或者使用这个邀请码：lbVOQjeS","title":"googo 邀请码 lbVOQjeS"},{"content":"第一章 并发编程的挑战第2章 InnoDB存储引擎第1章 Java的I/O演进之路第1章 Spring框架的由来第2章 Tomcat总体架构三、Paxos的工程实践序第1章 概述第6章 深入分析ClassLoader工作机制第8章 虚拟机字节码执行系统\n","permalink":"https://haokiu.com/blog/bk-5/","summary":"第一章 并发编程的挑战第2章 InnoDB存储引擎第1章 Java的I/O演进之路第1章 Spring框架的由来第2章 Tomcat总体架构三、Paxos的工程实践序第1章 概述第6章 深入分析ClassLoader工作机制第8章 虚拟机字节码执行系统","title":"Hobert读书笔记"},{"content":"2.2.3 Paxos算法详解 假设有一组可以提出提案的进程集合，那么对于一个一致性算法来说需要保证以下几点：\n在这些被提出的提案中，只有一个会被选定。\n如果没有填被提出，那么就不会有被选定的提案。\n当一个填被选定后，进程应该可以获取被选定的提案信息。\n对于一致性来说，安全性（Safety）需求如下：\n只有被提出的提案才能被选定。 只有一个值被选定。 如果某么进程认为某个提案被选定了，那么这个提案必须是真的被选定的那个。 提案的选定\n大多数。\n推导过程\nP1：一个Accptor必须批准它收到的第一个提案\nP1a：一个Acceptor只要尚未响应过任何编号大于Mn的Prepare请求，那么它就可以接收这个编号为Mn的提案。（优化：可以忽略已批准过的提案的Prepare请求）\nP2：如果编号为M0，Value值为V0的提案（即[M0,V0]）被选定了，那么所有比编号M0更高的，且被选定的提案，其Value值必须为V0。\nP2a：如果编号为M0，Value值为V0的提案（即[M0,V0]）被选定了，那么所有比编号M0更高的，且被Acceptor批准的提案，其Value值必须为V0。\nP2b：如果一个提案[M0,V0]被选定后，那么之后任何Proposer产生的编号更高的提案，其Value值都为V0。\nP2c：对于任意的Mn和Vn，如果提案[Mn,Vn]被提出，那么肯定存在一个由半数以上的Acceptor组成的集合S，满足以下两个条件中的任意一个：\nS中不存在任何批准过编号小于Mn的提案的Acceptor。 选取S中所有Acceptor批准的编号小于Mn的提案，其中编号最大的那个提案其Value值是Vn。 推导过程为第二数学归纳法。略\nProposer生成提案\n对于Proposer，获取被通过的提案比预测可能会被通过的提案简单。\nProposer选择一个新的提案编号Mn，然后向某个Acceptor集合的成员发送请求，要求该集合中的Acceptor做出如下回应。 像Proposer承诺，保证不再批准任何编号小于Mn的提案。 如果Acceptor已经批准过任何提案，那么其就向Proposer反馈当前该Acceptor已经批准的编号小于Mn但为最大编号的那个提案的值。 如果Proposer收到了来自半数以上的Acceptor的响应结果，那么它就可以产生编号为Mn、Value值为Vn的提案，这里的Vn是所有响应中编号最大的提案Value值。当然还存在一种情况，就是半数以上的Acceptor都没有批准过任何提案，即响应中不包含任何的提案，那么此时Vn值就可以由Proposer任意选择。 Acceptor批准提案\n一个Acceptor可能会收到来自Proposer的两种请求，分别是Prepare请求和Accept请求，分别相应如下：\nPrepare请求：Acceptor可以在任何时候响应一个Prepare请求。 Accept请求：在不违背Accept现有承诺的前提下，可以任意响应Accept请求。 算法陈述\n阶段一：\nProposer发送提案编号Mn； Acceptor根据约束接收提案，如果接收过返回接收最大值Vn； 阶段二：\n如果Proposer收到大多数A的响应，发送[Mn,Vn]； Acceptor根据约束接收提案； 提案的获取\n通知全部Learner\n选取主Learner\n将主Learner改为Learner集合\n通过选取主Proposer保证算法的活性\n三、Paxos的工程实践 3.1 Chubby 一个分布式锁服务。解决分布式协作，元数据存储，Master选举等一系列与分布式锁服务相关的问题。\n底层为Paxos算法。\n3.1.1 概述 ","permalink":"https://haokiu.com/blog/3426588a7834499f8a9a1b7e46817c0c/","summary":"2.2.3 Paxos算法详解 假设有一组可以提出提案的进程集合，那么对于一个一致性算法来说需要保证以下几点：\n在这些被提出的提案中，只有一个会被选定。\n如果没有填被提出，那么就不会有被选定的提案。\n当一个填被选定后，进程应该可以获取被选定的提案信息。\n对于一致性来说，安全性（Safety）需求如下：\n只有被提出的提案才能被选定。 只有一个值被选定。 如果某么进程认为某个提案被选定了，那么这个提案必须是真的被选定的那个。 提案的选定\n大多数。\n推导过程\nP1：一个Accptor必须批准它收到的第一个提案\nP1a：一个Acceptor只要尚未响应过任何编号大于Mn的Prepare请求，那么它就可以接收这个编号为Mn的提案。（优化：可以忽略已批准过的提案的Prepare请求）\nP2：如果编号为M0，Value值为V0的提案（即[M0,V0]）被选定了，那么所有比编号M0更高的，且被选定的提案，其Value值必须为V0。\nP2a：如果编号为M0，Value值为V0的提案（即[M0,V0]）被选定了，那么所有比编号M0更高的，且被Acceptor批准的提案，其Value值必须为V0。\nP2b：如果一个提案[M0,V0]被选定后，那么之后任何Proposer产生的编号更高的提案，其Value值都为V0。\nP2c：对于任意的Mn和Vn，如果提案[Mn,Vn]被提出，那么肯定存在一个由半数以上的Acceptor组成的集合S，满足以下两个条件中的任意一个：\nS中不存在任何批准过编号小于Mn的提案的Acceptor。 选取S中所有Acceptor批准的编号小于Mn的提案，其中编号最大的那个提案其Value值是Vn。 推导过程为第二数学归纳法。略\nProposer生成提案\n对于Proposer，获取被通过的提案比预测可能会被通过的提案简单。\nProposer选择一个新的提案编号Mn，然后向某个Acceptor集合的成员发送请求，要求该集合中的Acceptor做出如下回应。 像Proposer承诺，保证不再批准任何编号小于Mn的提案。 如果Acceptor已经批准过任何提案，那么其就向Proposer反馈当前该Acceptor已经批准的编号小于Mn但为最大编号的那个提案的值。 如果Proposer收到了来自半数以上的Acceptor的响应结果，那么它就可以产生编号为Mn、Value值为Vn的提案，这里的Vn是所有响应中编号最大的提案Value值。当然还存在一种情况，就是半数以上的Acceptor都没有批准过任何提案，即响应中不包含任何的提案，那么此时Vn值就可以由Proposer任意选择。 Acceptor批准提案\n一个Acceptor可能会收到来自Proposer的两种请求，分别是Prepare请求和Accept请求，分别相应如下：\nPrepare请求：Acceptor可以在任何时候响应一个Prepare请求。 Accept请求：在不违背Accept现有承诺的前提下，可以任意响应Accept请求。 算法陈述\n阶段一：\nProposer发送提案编号Mn； Acceptor根据约束接收提案，如果接收过返回接收最大值Vn； 阶段二：\n如果Proposer收到大多数A的响应，发送[Mn,Vn]； Acceptor根据约束接收提案； 提案的获取\n通知全部Learner\n选取主Learner\n将主Learner改为Learner集合\n通过选取主Proposer保证算法的活性\n三、Paxos的工程实践 3.1 Chubby 一个分布式锁服务。解决分布式协作，元数据存储，Master选举等一系列与分布式锁服务相关的问题。\n底层为Paxos算法。\n3.1.1 概述 ","title":"三、Paxos的工程实践"},{"content":"序 大、快、多样性只是表象，大数据的真正价值在于生命性和生态性。（活数据）\n第1 章 总述 如果不能对数据进行有序、有结构地分类组织和存储，如果不能有效利用并发掘它，继而产生价值，那么它同时也成为一场“灾难”。无需、无结构的数据犹如堆积如山的垃圾，给企业带来的是有令人咋舌的高额成本。\n要求：\n如何建设高效的数据模型和体系，是数据易用，避免重复建设和数据不一致性； 如何提供高效易用的数据开发工具； 如何做好数据质量保障； 如何有效管理和控制日益增长的存储和计算消耗； 如何保证数据服务的稳定，保证其性能； 如何设计有效的数据产品高效赋能于外部客户和内部员工 数据采集层 日志采集体系方案包括两大体系：Aplus.JS是Web端日志采集技术方案；UserTrack是App端日记采集技术方案。\n在采集技术基础上面向各个场景的埋点规范。\n在传输方面采用TimeTunel（TT）,它既包括数据库的增量数据传输，也包括日志数据的传输；既支持实时流式计算，也知乎此各种时间窗口的批量计算。\n也通过数据同步工具（DataX和同步中心，其中同步中心是给予DataX易用性封装的）直连异构数据库（备库）来抽取各种时间窗口的数据。\n数据计算层 数据只有被整合和计算,才能被用于洞察商业规律,挖掘潜在信息，从而实现大数据价值,达到赋能于商业和创造价值的目的。\n阿里巴巴的数据计算层包括两大体系:数据存储及计算云平台（离线计算平台MaxCompute和实时计算平台StreamCompute）和数据整合及管理体系（内部称之为“ OneData ”） 。\nMaxCompute是阿里巴巴自主研发的离线大数据平台。\nStreamCompute是阿里巴巴自主研发的流式大数据平台。\nOneData是数据整合及管理的方法体系和工具。\n借助此体系，构建了数据公共层。\n从数据计算频率角度来看，阿里数据仓库可以分为离线数据仓库（传统的数据仓库概念）和实时数据仓库（典型应用：双11实时数据）。\n阿里数据仓库的数据加工链路也是遵循业界的分层理念，包括：\n操作数据层（Operational Data Store，ODS）; 明细数据层（Data WareHouse Detail，DWD）； 应用数据层（Application Data Store，ADS）。 通过数据仓库不同层次之间的加工过程实现从数据资产向信息资产的转化，并且对整个过程进行有效的元数据管理及数据质量处理。\n元数据模型整合及应用是一个重要的组成部分，主要包含：\n数据源元数据 数据仓库元数据 数据链路元数据 工具类元数据 数据质量类元数据 元数据应用主要面向数据发现、数据管理等，如用于存储、计算和成本管理。\n数据服务层 当数据已被整合和计算好之后，需要提供给产品和应用进行数据消费。\n针对不同的需求，数据服务层的数据源架构在多种数据库之上，如Mysql和HBase。\n数据服务层主要考虑性能、稳定性、扩展性。\nOneService（数据服务平台）一数据仓库整合计算好的数据作为数据源，对外通过接口的方式提供数据服务，主要提供简单数据查询服务、复杂数据查询服务（用户识别、用户画像等）和实时数据推送服务。\n数据应用层 第1篇 数据技术篇 第2章 日志采集 第2篇 数据模型篇 第8章 大数据领域建模综述 8.1 为什么需要数据建模 如何将数据进行有序、有结构地分类组织和存储？\n数据模型就是数据组织和存储方法，它强调从业务、数据存取和使用角度合理存储数据。有了适合业务和基础数据存储环境的模型，那么大数据就能获得以下好处：\n性能：良好的数据模型能帮助我们快速查询所需要的数据，减少数据的I/O吞吐。 成本：良好的数据模型能极大地减少不必要的数据冗余，也能实现计算结果复用，极大地降低大数据系统中的存储和计算成本。 效率：良好的数据模型能极大地改善用户使用数据的体验，提高使用数据的效率。 质量：良好的数据模型能改善数据统计口径的不一致性，减少数据计算错误的可能性。 8.2 关系行数据库系统和数据仓库 大数据领域仍然使用关系型数据库，使用关系理论描述数据之间的关系，只是基于其数据存储的特点关系数据模型的范式上有了不同的选择。\n8.3 从OLTP和OLAP系统特别看模型方法论的选择 OLTP系统通常面向的主要数据操作是随即读写，主要采用满足3NF的实体关系模型存储数据，从而在事务处理中解决数据的冗余和一致性问题；而OLAP系统面向的主要数据操作时批量读写，事物处理中的一致性不是OLAP所关注的，其主要关注数据的集合，以及在一次性的复杂大数据查询和处理中的性能，因此它需要采用一些不同的数据建模方法。\n8.4 典型的数据仓库建模方法论 8.4.1 ER模型 数据仓库中的3NF和OLPT系统中的3NF的却别在于，它是站在企业角度面向主题的抽象，而不是针对某个具体业务流程的实体对象关系的抽象。其具有以下几个特点：\n需要全面了解企业业务和数据； 事实周期非常长； 对建模人员的能力要求非常高。 采用ER模型建设数据仓库魔性的出发点是整合数据将个系统中的数据以整个企业角度按主题进项相似性组合和合并，并进行一致性处理，为数据分析决策服务，但是并不能直接用于分析决策。\n其建模步骤分为三个阶段：\n高层模型：一个高度抽象的模型，描述主要的主题以及主题间的关系，用语描述企业的业务总体概况。 中层模型：在高层模型的基础上，细化主题的数据项。 物理模型（也叫底层模型）：在中层模型的基础上，考虑物理存储，同时基于性能和平台特点进行物理属性的设计，也可能作一些表的合并、分区的设计等。 实践典型：金融业务FS-LDM。\n8.4.2 维度模型 是数据仓库工程领域最流行的数据仓库建模的经典。\n维度建模从分析决策的需求出发构建模型，为分析需求服务，因此它重点关注用户如何更快速地完成需求分析，同时具有较好的大规模复杂查询的响应性能。其典型的代表是星形模型，以及在一些特殊场景下使用的雪花模型。其设计分为一下几个步骤：\n选择需要进行分析决策的业务过程。业务过程可以是单个业务事件，比如交易的支付、退款等；也可以时某个时间的状态，比如当前的账户余额等；还可以是一系列相关业务时间组成的业务流程，具体需要看我们分析的是某些事件发生情况，还是当前状态，或是事件流转效率； 选择粒度。在事件分析中，我们要预判所有分析需要细分的程度，从而决定选择的粒度。粒度是维度的一个组合； 识别维表。选择好粒度之后，就需要细雨此粒度设计维表，包括维度属性，用于分析时进行分组和筛选； 选择事实。确定分析需要衡量的指标。 8.4.3 Data Vault模型 ER模型的衍生。其设计的出发点也是为了实现数据的整合，但不能直接用于数据分析决策。\n8.4.4 Anchor模型 对Data Vault模型做了进一步规范化处理。\n8.5 阿里巴巴数据模型实践综述 第一个阶段：完全应用驱动的时代，构建在Oracle上，数据完全一满足报表需求为目的，将数据以与源结构相同的方式同步不到Oracle（ODS层），数据工程师基于ODS数据进行统计，基本没有系统化的模型方法体系，完全基于对Oracle数据库特性的利用进行数据存储和加工，部分采用一些维度建模的缓慢变化维方式进行历史数据处理。这时候的数据架构只有两层，即ODS+DSS。\n第二个阶段：随着业务发展，数据量增加，性能成为一个较大的问题，因此引入了当时MPP架构体系的Greenplum，同时进行数据架构优化希望通过模型技术改变开发模型，消除一些冗余，提升数据的一致性。开始尝试将工程领域比较流行的ER模型+维度模型方式，构建出一个四成的模型架构，即ODL（数据操作层）+BDL（基础数据层）+IDL（接口数据层）+ADL（应用数据层）。ODL和源系统保持一致；BDL希望以引入ER模型，加强市局的整合，构建一致的基础数据模型；IDL基于维度模型方法构建集市层；ADL完成应用的个性化和基于展现需求的数据组装。遇到的困难与挑战：构建ER模型（业务发展迅速，人员快速变化、业务知识功底的不够全面）。\n在不太成熟、快速变化的业务面前，构建ER模型的风险非常大，不太适合去构建ER模型。\n第三个阶段：业务继续发展，Hadoop为代表的分布式存储计算平台也在快速发展，阿里巴巴自主研发的分布式计算平台MaxCompute。选择了以Kimball的维度建模为核心理念的模型方法论，同时对其进行了一定的升级和扩展，构建了阿里巴巴集团的公共层模型数据架构体系。\n数据公共层建设的目的是着力解决数据存储和计算的共享问题。\n阿里巴巴数据公共层建设的指导方法是一套同意话的集团数据整合及管理的方法体系（内部成为OneData），其包括一致性的指标定义体系、模型设计方法体系及配套工具。\n第9章 阿里巴巴数据整合及管理体系 面对爆炸式增长的数据，如何建设高效的数据模型和体系，对这些数据进行有序和有结构地分类组织和存储，避免重复建设和数据不一致性，保证数据的规范性，一直时大数据系统建设不断追求的方向。\n9.1 概述 从业务架构设计到模型设计，从数据研发到数据服务，做到数据可管理、可追溯、可规避重复建设。\n9.1.1 定位及价值 建设统一的、规范化的数据介入层（ODS）和数据中间层（DWD和DWS），通过数据服务和数据产品，完成服务于阿里巴巴的数据系统建设，即数据公共层建设。提供标准化的（Standard）、共享的（Shared）、数据服务（Service）能力，将数据互通成本，释放计算、存储、人力等资源，以消除业务和技术之痛。\n9.1.2 体系架构 业务板块：由于阿里巴巴集团业务生态庞大、所以根据业务的属性划分出几个相对独立的业务板块，业务板块之间的指标或业务重叠性较小，如点上业务板块涵盖淘系、B2B系和AliExpress系等。\n规范定义：阿里数据业务庞大，结合行业的数据仓库建设经验和阿里数据自身特点，设计出的一套数据规范命名体系，规范定义将会被用在模型设计中。\n模型设计：以维度建模理论为基础，给予维度建模总线架构，构建一致性的维度和事实（进行规范定义）。同时，在落地标模型时，给予阿里自身业务特点，设计出一套表规范命名体系。\n9.2 规范定义 规范定义指以维度建模作为理论基础，构建总线矩阵，划分和定义数据域、业务过程、维度、度量/原子指标、修饰类型、修饰词、时间周期、派生指标。\n9.2.1 名词术语 名词术语 解释 数据域 指面向业务分析，将业务过程或者维度进行抽象的集合。其中，业务过程可以概括为一个个不可拆分的行为事件，在业务过程之下，可以定义指标；维度是指度量的环境，如买家下单时间，买家是维度。为保障整个体系的生命力，数据域是需要抽象提炼的，并且长期维护和更新的，但不轻易变动。在划分数据域时，既能涵盖当前所有的业务需求，又能在新业务进入时无影响地被包含进已有的数据域中和扩展新的数据域。 业务过程 指企业的业务活动事件，如下单、支付、退款都是业务过程。请注意，业务过程是一个不可拆分的行为事件，通俗地讲，业务过程就是企业活动中的事件。 时间周期 用来明确数据统计的时间范围或者时间点，如最近30天、自然周、截至当日等。 修饰类型 是对修饰词的一种抽象划分。修饰类型从术语某个业务域，如日志域的访问终端类型涵盖无线端、PC端等修饰词 修饰词 指除了统计维度以外指标的业务场景限定抽象。修饰词隶属于一种修饰类型，如在日志域的访问终端类型下，有修饰词PC端、无线端等 度量/原子指标 原子指标和度量含义相同，基于某一业务事件行为下的度量，是业务定义中不可再拆分的指标，具有明确业务含义的名词，如支付金额 维度 维度是度量的环境，用来反映业务的一类属性，这类属性的集合构成一个维度，也可称之为实体对象。维度属于一个数据域，如地理纬度（其中包括国家、地区、省以及城市等级别的内容）、时间维度（其中包括年、季、月、周、日等级别的内容） 维度属性 维度属性隶属于一个维度，如地理维度里面的国家名称、国家ID、省份名称等都属于维度属性 派生指标 派生指标=一个原子指标+多个修饰词（可选）+时间周期。可以理解为对原子指标业务统计范围的圈定。如原子指标：支付金额，最近1天海外买家支付金额则为派生指标（最近1天为时间周期，海外为修饰词，买家作为维度，而不作为修饰词） 9.2.2 指标体系 本文在讲述指标时，会涵盖其组成体系（原子指标、派生指标、修饰类型、修饰词、时间周期），将它们作为一个整体来解读。\n基本原则\n（1）组成体系之间的关系\n派生指标有原子指标、时间周期修饰词、若干其他修饰词组合得到 原子指标、修饰类型及修饰词，直接归属在业务过程下，其中修饰词继承修饰类型的数据域。 派生指标可以选择多个修饰词，修饰词之间的关系为“或”或者“且”，有具体的派生指标语义定义决定 派生指标唯一归属一个原子指标，继承原子指标的数据域，与修饰词的数据域无关。 一般而言，事务型指标和存量型指标智慧为一定味道一个业务过程，如果遇到同时有两个行为发生、需要多个修饰词、生成一个派生指标的情况，则选择时间靠后的行为创建原子指标，选择时间靠前的行为创建修饰词。\n原子指标有确定的英文字段名、数据类型和算法说明；派生指标要继承原子指标的英文名，数据类型和算法要求。 （2） 命名约定\n命名所用术语。指标命名，尽量使用英文简写，其次是英文，当指标英文名太长时，可考虑用汉语拼音首字母命名。如中国制造，用zgzc。在OneData工具中维护着常用的名词属于，以用来进行命名。 业务过程。英文名：用英文或英文的缩写或者中文拼音简写；中文名：具体的业务过程中文即可。 关于存量型指标对应的业务过程的约定：实体对象英文名+_stock。如在线会员数、一星会员数等，其对应的业务过程为mbr_stock；在线商品数、商品SKU种类小于5的商品书，其对应的业务过程为itm+stock。\n原子指标。英文名：动作+度量；中文名：动作+度量。原子指标必须挂靠在某个业务过程下。 修饰词。只有时间周期才会有英文名，且长度为2位，加上“_”位3位，例如_1d。其他修饰词无英文名。 派生指标。英文名+原子指标英文名+时间周期修饰词（3位）+序号（4位，例如_001）；中文名：时间周期修饰词+[其他修饰词]+原子指标。 为了控制派生指标的英文名称过长，在英文名的理解和规范上做了取舍，所有修饰词的含义都含入了序号中。序号是跟觉原子指标+派生指标自增的。\n（3）算法\n原子指标、修饰词、派生指标的算法说明必须让各种使用人员看得明白，包括：\n算法该书——算法对应的用户容易理解的阐述。 举例——通过具体例子帮助理解指标算法。 SQL算法说明——对于派生指标给出SQL的写法或者伪代码。 操作细则\n（1）派生指标的种类\n分为三类：事物型指标、存量型指标和复合型指标。按照其特性不同，有些必须新建原子指标，有些可以在其他类型原子指标的基础上增加修饰词形成派生指标。\n事物型指标：指对业务活动进行衡量的指标。（例如新发商品数，重发商品数等）需要维护原子指标及修饰词，在此基础上创建派生指标。 存量型指标：只对对实体对象某些状态（商品、会员）的统计。（例如商品总数、注册会员总数），需要维护原子指标及修饰词，再次基础上创建派生指标，对应的时间周期一般位“历史截止至当前某个时间”。 复合型指标：是在事物型指标和存量型指标的基础上复合而成的。例如浏览UV-下单买家数转化率，有些需要创建新原子指标，有些则可以在事物型或存量型原子指标的基础上增加修饰词得到派生指标。 （2）复合型指标的规则\n比率型：创建原子指标。\n比例型：创建原子指标，如百分比、占比。\n变化量型：不创建原子指标，增加修饰词，在此基础上创建派生指标。\n变化率型：创建原子指标。\n统计型（均值、分位数等）：不创建原子指标，增加修饰词，在此基础上创建派生指标；在修饰类型“统计方法”下增加修饰词，如人均、日均、行业平均、商品平均等。\n排名型：创建原子指标，一般为top_xxx_xxx或者rank组合，创建派生指标时选择对应的修饰词：\n统计方法 排名名次 排名范围 根据什么排序 对象集合型：主要是指数据产品和应用需要展现数据时，将一些对象那个以k-v对的方式存储在一个字段，方便前端展现。创建原子指标，一般为xx串；创建派生指标时选择对应的修饰词如下：\n统计方法（如排序、升序）。 排名名次（如TOP10）。 排名范围（如行业、行业）。 其他规则 （1）上下层级派生指标同时存在时\n如最近1天支付金额和最近1天PC端支付金额，建议使用前者，把PC端作为维度属性存放在物理表中体现。\n（2）父子关系原子指标存在时\n当父子关系原子指标存在时，派生指标使用原子指标创建派生指标。如PV，IPV（商品详情页PV），当统计商品详情也PV时，优先选择子原子指标。\n9.3 模型设计 9.3.1 指导理论 遵循维度建模思想。数据模型的维度设计主要以维度建模理论为基础，基于维度数据模型总线架构，构建一致性的维度和事实。\n9.3.2 模型层次 三层：数据操作层ODS、公共维度模型层CDM、应用数据层ADS，其中公共维度模型层包括明细数据层DWD和汇总数据层DWS。\n操作数据层ODS：把操作系统数据几乎无处理地存放在数据仓库系统中。\n同步：结构化数据增量或全量同步到MaxCompute。 结构化：非结构化（日志）结构化处理并存储到MaxCompute。 累积历史、清洗：根据数据业务需求及稽核和审计要求保存历史数据、清洗数据。 公共维度模型层CDM：存放明细事实数据、维表数据及公共指标汇总数据，其中明细事实数据、维表数据一般根据ODS层数据加工生成；公共指标汇总数据一般根据维表数据和明细事实数据加工生成。\nCDM层又细分为DWD层和DWS层，采用维度模型方法作为理论基础，更多地采用一些维度退化受大，将唯独退化至事实表中，减少事实表和维表的关联，提高明细数据表的易用性；同时在汇总数据层，加强指标的维度退化，采用更多的宽表化手段构建公共指标数据层，提升公共指标的复用性，减少重复加工。其主要功能如下：\n组合相关和相似数据：采用明细宽表，复用关联计算，减少数据扫描。 公共指标统一加工：基于OneData体系构建命名规范、口径一致和算法统一的统计指标，为上层数据产品、应用和服务提供公共指标；建立逻辑汇总宽表。 建立一致性维度：建立一致的数据分析维表，降低数据计算口径、算法不统一的风险。 应用数据层ADS：存放数据产品个性化的统计指标数据，根据CDM层和ODS层加工生成。\n个性化指标加工：不公用性、复杂性（指数型、比值型、排名型指标）。 基于应用的数据组装：大宽表集市、横表转纵表、趋势指标串。 数据调用服务优先使用公共维度模型层（CDM）数据，当公共层没有数据时，需评估是否需要创建公共层数据，当不需要建设公用的公共层时，方可直接使用操作数据层ODS数据。应用数据层ADS作为产品特有的个性化数据一般部队外提供数据服务，但是ADS作为被服务方也需要遵守这个约定。\n9.3.3 基本原则 高内聚低耦合 核心模型和扩展模型分离 公共处理逻辑下沉及单一 成本与性能平衡 数据可回滚 一致性 命名清晰、可理解 9.4 模型实施 9.4.1 业界常用的模型实施过程 Kimball模型实施过程 （1）高层模型\n（2）详细模型\n（3）模型审查、再设计和验证\n（4）提交ETL设计和开发\nInmon模型实施过程\n其他模型实践过程\n业务建模，生成业务模型，主要解决业务层面的分解和程序化。 领域建模，生成领域模型，主要是对业务模型进行抽象处理，生成领域概念模型。 逻辑建模，生成逻辑模型，主要是将领域模型的概念实体以及实体之间的关系数据库层次的逻辑化。 物理建模，生成模型逻辑，主要解决逻辑模型针对不同关系数据库的物理化以及性能等一些具体的技术问题。 9.4.2 OneData实施过程 指导方针 首先，在建设大数据数据仓库时，要进行充分的业务调研和需求分析。\n其次，进行数据总体架构设计，主要是跟觉数据域对数据进行划分，按照维度建模理论，构建总线矩阵、抽象出业务过程和维度。\n再次，对报表需求进行抽象整理出相关指标体系。\n最后，就是代码研发和运维。\n实施工作流 （1）数据调研\n业务调研 一般各个业务领域独资建设数据仓库，业务领域内的业务线由于业务相似、业务相关性较大，进行统一集中建设。\n需求调研 与BI，运营商讨数据诉求（大部分为报表需求）。\n对报表系统中现有的报表进行研究分析。\n（2）架构设计\n数据域划分 数据域面向业务分析，将业务过程或者维度进行抽象的集合。\n业务过程可以概括为一个个不可拆分的行为事件。\n为保障整个体系的生命力，数据域需要抽象提炼，并且长期维护和更新，但不轻易变动。\n构建总线矩阵 明确每个数据域下有哪些业务过程。\n业务过程与哪些维度相关，并定义每个数据域下的业务过程和维度。\n（3）规范定义\n定义指标体系、修饰词、时间周期和派生指标。\n（4）模型设计\n包括维度和属性的规范定义，维表、明细事实表和汇总事实表的模型设计。\n（5）总结\n该实施过程是一个高度迭代和动态的过程，一般采用螺旋式实施方法。在总体架构设计完成之后，开始根据数据域进行迭代式模型设计和评审。在架构设计、规范定义和模型设计等模型实施过程中，都会引入评审机制,以确保模型实施过程的正确性。\n第10章 维度设计 10.1 维度设计基础 10.1.1 维度的基本概念 维度是维度建模的基础和灵魂。再维度建模中，将度量称为“事实”，将环境描述为“维度”，维度是用于分析事实所需要的多样环境。\n维度所包含的表示维度的列，称为维度属性。维度属性是查询约束条件、分组和报表标签生成的基本来源，是数据易用性的关键。维度的作用一般是查询约束、分类汇总以及排序等。\n获取维度或维度属性：\n在报表中获取 和业务人员的交谈中发现维度或维度属性 维度使用主键标识其唯一性，主见也是确保与之相连的任何事实表之间存在引用完整性的基础。\n主键有两种：代理键和自然键。\n10.1.2 维度的基本设计方法 维度的设计过程就是确定维度属性的过程。数据仓库的能力直接与维度属性的质量和深度成正比。\n淘宝商品的维度设计：\n选择维度或新建维度。必须保证维度的唯一性。\n确定主维表。此处一般是ODS表，直接与业务系统同步。\n确定相关维表。根据对业务的树立，确定哪些表和主维表存在关联关系，并选择其中的某些表用于生成维度属性。\n确定维度属性。先从主维表中选择维度属性或生成新的维度属性，然后从相关维表中选择维度属性或生成心的维度属性。\n确定维度属性的几点提示：\n（1）尽可能生成丰富的维度属性\n（2）尽可能多地给出包括一些富有意义的文字性描述。\n（3）区分数字型属性和事实。需要参考字段的具体用途。\n（4）尽量沉淀出通用的维度属性。\n10.1.3 维度的层次机构 维度中的一些描述属性以层次方式或一对多的方式相互关联，可以被理解为包含连续主从关系的属性层次。\n层次的最底层代表维度中描述最低级别的详细信息，最高层代表最高级别的概要信息。\n在属性的层次结构中进行钻取是数据钻取的方法之一。\n10.1.4 规范化和反规范化 当属性层次被实例化为一系列维度，而不是单一的维度时，被称为雪花模式。\n维度的属性层次合并到单个维度中的操作称为反规范化。分析系统的主要目的是用于数据分析和统计，如何更方便用户进行统计分析决定了分析系统的优劣。采用雪花模式，用户在统计分析的过程中需要大量的关联操作，使用复杂度高，同时查询性能很差；而采用反规范化处理，则方便、易用且性能好。\n采用雪花模式，除了可以节约一部分存储外，对于OLAP系统来说没有其他效用。\n10.1.5 一致性维度和交叉探查 迭代式的构建数据仓库存在的问题：单独构建会形成独立性数据即使，导致严重的不一致性。\n通过构建企业范围内一致性维度和事实来构建总线架构。\n数据仓库总线架构的重要基石之一就是一致性维度。将不同数据域的商品的事实合并在一起进行数据探查，如计算转化率等，成为交叉探查。\n如果不同数据域的计算过程使用的维度不一致，就会导致交叉探查存在问题。当存在重复的维度，但维度属性或维度属性的值不一枝时，会导致交叉探查无法进行或交叉探查结果错误。基本可以划分为维度格式和内容不一致两种类型。\n维度一致性的几种表现形式：\n共享维表。 一致性上卷，其中一个维度的维度属性是另一个维度的维度属性的子集，且两个维度的公共维度属性结构和内容相同。 交叉出行，两个维度具有部分相同的维度属性。 10.2 维度设计高级主题 10.2.1 维度整合 数据仓库是一个面向主题的、继承的、非易失的且随时间变化的数据集合，用来支持管理人员的决策。\n不同数据来源之前的具体差异：\n应用在编码、命名习惯、度量单位等方面会存在很大的差异。 应用出于性能和扩展性的考虑，或者随技术架构的演变，以及业务的发展，采用不同的屋里实现。 数据集成的具体体现：\n命名规范的统一。表明、字段名 字段类型的统一。相同和相似字段的字段类型统一。 公共代码及代码值的统一。 业务含义相同的表的统一。高内聚、低耦合，主要有以下几种集成方式： 采用主从表的设计方式，主表放基本信息，从表放从属信息。 直接合并，共有信息和个性信息都放在同一个表中。 不合并，因为源表的表结构及主键等差异很大。 表级别的整合：\n垂直整合，即不同的来源表包含相同的数据集，只是存储的信息不同。 水平整合，及不同的来源表包含不同的数据集，不同子集之间无交叉，也可以存在部分交叉。交叉或者超自然键 10.2.2 水平拆分 维度通常可以按照类别或类型进行细分。\n设计维度的两种方案：\n将维度的不同分类实例化为不同的属性，同时在主维度中保存公共属性 维护单一维度，包含所有可能的属性 设计维度的三个原则：\n扩展性。高内聚、低耦合 效能。在性能和存储成本方面取得平衡。 易用性。可理解度高则易用性低。 对维度进行水平拆分是的两个依据：\n维度的不同分类的属性差异情况。 业务的关联程度。 10.2.3 垂直拆分 维度属性的来源表产出的时间不同。维度属性使用频率不同。有的维度属性经常变化。\n基于扩展性、产出时间、易用性等方面的考虑，设计主从维度。主维表存放稳定、产出时间早、热度高的属性。\n10.2.4 历史归档 归档策略：\n同前台归档策略，在数仓中实现前台归档算法。适用于前台逻辑简单 同前台归档策略，但采用数据库变更日志的方式。不需要关注前台归档策略，简单易行 数仓自定义归档策略。原则是比前台应用晚归档，少归档。 如果技术条件允许，能够解析数据库binlog日志，建议使用归档策略2，规避前台归档算法。\n10.3 维度变化 10.3.1 缓慢变化维 反映历史变化，如何处理维度变化？\n缓慢变化维：维度的属性并不是静态的，会随着时间发生缓慢变化。与数据增长较为快速的事实表相比，维度变化相对缓慢。\n处理缓慢变化维的三种方式：\n重写维度值。不保留历史数据，始终最新 插入新的维度行。保留历史数据 添加维度列。 10.3.2 快照维度 每天保留一份全量快照数据。\n优点：\n简单而有效，开发和维护成本低。 使用方便，理解性好。 弊端：极大的存储浪费。\n10.3.3 极限存储 透明化：底层的数据还是历史拉链数据，但是上层做一个试图或者hook，吧对极限存储前的表转换成对极限存储表的查询。\n分月做历史拉链表。\n极限存储压缩了全量存储的成本，同时对下游用户透明。\n局限性：产出效率较低，对于变化频率高的数据并不能达到节约成本的效果。\n实际生产中的格外处理：\n在极限存储前做一个全量存储表，保留最近一段时间的全量分区数据。 对于部分变化频率频繁的字段需要过滤。 10.3.4 微型模型 通过将一些属性移到全新的维表中，可以解决维度的过度增长导致极限存储效果大打折扣的问题。通过垂直拆分和微型模型可以实现。\n阿里数仓不使用此技术的原因：\n微型维度的局限性。 ETL逻辑复杂。 破坏了维度的可浏览性。 10.4 特殊维度 10.4.1 递归层次 按照层级是否固定分为均衡层次结构和非均衡层次结构。\n由于很多数据仓库系统和商业只能工具不支持递归SQL，且递归的成本较高，所以需要对此层次结构进行处理。\n层次结构扁平化。（回填，将类目向下虚拟） 层次桥接表。灵活性高但是复杂。 10.4.2 行为维度 种类划分：\n另一个维度的过去行为。 快照事实行为维度。 分组事实行为维度。 复杂逻辑是时行为维度。 两种处理方式：\n将其冗余至现有的维度表中。 加工成单独的维度表。 两个原则：\n避免过快增长。 避免耦合度过高。 10.4.3 多值维度 三种常见的处理方式：\n降低事实表的粒度。 采用多字段。 采用较为通用的桥接表。 10.4.4 多值属性 维表中的某个属性字段同时有多个值成为多值属性。\n三种常见的处理方式：\n保持维度主键不变，将多值属性放在维度的一个属性字段中。（扩展性好，使用麻烦） 保持维度主键不变，将多值属性放在维度的多个属性字段中。 维度主键发生变化，一个维度值存放多条记录。（扩展性好，使用方便，但是数据急剧膨胀） 10.4.5 杂项维度 是由操作型系统种的指示符或者标志字段组合而成的，一般不再一致性维度之列。\n通常的做法是将这些字段建立到一个维表中，在事实表中只保存一个外键。\n第11章 事实表设计 11.1 事实表基础 11.1.1 事实表特性 事实表作为数据仓库维度建模的核心，紧紧围绕业务过程来设计，通过获取描述业务过程的度量来表达业务过程，包含了引用的维度和业务过程有关的度量。\n事实表中一条巨禄所表达的业务细节程度被称为粒度。\n粒度的两种表述方式：\n维度属性组合所表示的细节粒度； 所表示的具体业务含义。 作为度量业务过程的事实，一般位整形或浮点型的十进制数值，有可加性、半可加性和不可加性三种类型。\n可加性是指可以按照与事实表关联的任意维度进行汇总。\n半可加性事实只能按照特定维度汇总。\n比率型事实完全不具备可加性。对于不可加性事实可分解为可加的组件来实现聚集。\n相对维表来说，通常事实表要细长得多，行的增加速度也比维表快很多。\n事实表的三种类型：\n事物事实表：用来描述业务过程，跟踪空间或时间上某点的度量事件，保存的是最原子的数据，也成为原子事实表。 周期快照事实表：依据有规律性的、可预见的时间见过记录事实，时间间隔如每天、每月、每年等。 累积快照事实表：用来表述过程开始和结束之间的关键步骤事件，覆盖过程的整个生命周期，通常具有多个日期字段来记录关键时间点，当过程随着生命周期不断变化时，记录也会随着过程的变化而被修改。 11.1.2 事实表设计原则 尽可能包含所有与业务过程相关的事实 之选择与业务过程相关的事实 分解不可加性事实为客家的组件 在选择维度和事实之前必须先声明粒度 在同一个事实表中不能有多种不同力度的事实 事实的单位要保持一直 对事实的null值要处理 使用退化维度提高事实表的易用性 11.1.3 事实表设计方法 Kimball的四步设计：选择业务过程、声明粒度、确定维度、确定事实。\n改进后的设计方法：\n选择业务过程及确定事实表类型。\n声明粒度。粒度意味着精确定义事实表的没一行所表示的业务含义，粒度传递的是与事实表粒度有关的细节层次。明确粒度能确保事实表中行的意思的理解不会产生混淆，保证所有的事实按照同样的细节层次记录。\n确定维度。选择能够描述清楚业务过程所处的环境的维度信息。\n确定事实。\n冗余维度。提高使用侠侣，降低数据获取的复杂性，减少关联的表数量。\n11.2 事务事实表 11.2.1 设计过程 任何类型的事件都可以被理解为一种事务。\n（1）选择业务过程\n（2）确定粒度\n（3）确定维度\n（4）确定事实\n（5）冗余维度\n11.2.2 单事务事实表 即针对每个业务过程设计一个事实表。可以方便地对每个业务过程进行独立的分析研究。\n11.2.3 多事务事实表 将不同的事实放到同一个事实表中，即对同一个事实包含不同的业务过程。\n进行事实处理的两种方式：\n不同业务过程的事实使用不同的事实字段进行存放。 不同业务过程的事实使用同一个事实字段进行存放，但增加一个业务过程标签。 多事务事实表的选择：\n当不同业务过程的度量比较相似、差异不大时，可以使用同一个字段来表示度量数据。存在的问题：在同一个周期内会存在多条记录。 当不同业务过程的度量差异较大时，可以将不同业务过程度量使用使用不同字段冗余到表中，非当前业务过程则置零表示。存在的问题：度量字段零值较多。 11.2.4 两种事实表对比 业务过程 单事务事实表，一个业务过程建立一个事实表，只反映一个业务过程的事实；\n多事务事实表，在同一个事实表中反映过个业务过程。\n需要相似性和业务源系统，选择是否放到同一个事实表中。\n粒度和维度 当不同业务过程的粒度相同，同时拥有相似的维度时，此时就可以考虑采用多事务事实表。\n如果粒度不同，则必定是不同的事实表。\n事实 单事务事实表在处理事实上比较方便和灵活，仅仅体现同一个业务过程的事实即可 ；\n多事务事实表由于有多个业务过程，所以有很多的事实需要处理。\n下游业务使用 单事务事实表对于下游用户而言更容易理解，关注哪个业务过程就使用响应的事务事实表\n计算存储成本 多事务事实表成本更低。\n11.2.5 父子事实的处理方式 11.2.6 事实的设计准则 事实完整性 事实一致性 事实可加性 11.3 周期快照事实表 在确定的间隔内对尸体的度量进行臭氧，这样可以很容易地研究尸体的度量值，而不需要聚集长期的事务历史。\n11.3.1 特性 快照事实表的粒度通常以维度形式声明；事务事实表是系数的，但快照事实表是稠密的；事务事实表中的事实是完全可加的，但快照模型将至少包含一个用来展示半可加性质的事实。\n用快照采样状态 快照事实表以预定的间隔采样状态度量。这种间隔联合一个或多个维度，将被涌来定义快照事实表的粒度，每行都将包含记录所涉及状态的事实。\n快照粒度 快照事实表的粒度通常总是被多维声明，可以简单地理解无快照需要采样的周期以及什么将被采样。\n密度与稀疏性 快照事实表无论是否有业务过程发生都会记录一行。\n半可加性 快照事实表中收集到的状态度量都是半可加的。\n11.3.2 实例 快照事实表的设计步骤：\n确定快照事实表的快照粒度。 确定快照事实表采样的状态度量。 单维度的每天快照事实表 （1）确定粒度\n（2）确定状态度量\n混合维度的每天快照事实表 混合维度相对于单维度，只是在每天的采样周期上针对多个维度进行采样。\n","permalink":"https://haokiu.com/blog/cffcc67d768246fd8624b3e5b98854f5/","summary":"序 大、快、多样性只是表象，大数据的真正价值在于生命性和生态性。（活数据）\n第1 章 总述 如果不能对数据进行有序、有结构地分类组织和存储，如果不能有效利用并发掘它，继而产生价值，那么它同时也成为一场“灾难”。无需、无结构的数据犹如堆积如山的垃圾，给企业带来的是有令人咋舌的高额成本。\n要求：\n如何建设高效的数据模型和体系，是数据易用，避免重复建设和数据不一致性； 如何提供高效易用的数据开发工具； 如何做好数据质量保障； 如何有效管理和控制日益增长的存储和计算消耗； 如何保证数据服务的稳定，保证其性能； 如何设计有效的数据产品高效赋能于外部客户和内部员工 数据采集层 日志采集体系方案包括两大体系：Aplus.JS是Web端日志采集技术方案；UserTrack是App端日记采集技术方案。\n在采集技术基础上面向各个场景的埋点规范。\n在传输方面采用TimeTunel（TT）,它既包括数据库的增量数据传输，也包括日志数据的传输；既支持实时流式计算，也知乎此各种时间窗口的批量计算。\n也通过数据同步工具（DataX和同步中心，其中同步中心是给予DataX易用性封装的）直连异构数据库（备库）来抽取各种时间窗口的数据。\n数据计算层 数据只有被整合和计算,才能被用于洞察商业规律,挖掘潜在信息，从而实现大数据价值,达到赋能于商业和创造价值的目的。\n阿里巴巴的数据计算层包括两大体系:数据存储及计算云平台（离线计算平台MaxCompute和实时计算平台StreamCompute）和数据整合及管理体系（内部称之为“ OneData ”） 。\nMaxCompute是阿里巴巴自主研发的离线大数据平台。\nStreamCompute是阿里巴巴自主研发的流式大数据平台。\nOneData是数据整合及管理的方法体系和工具。\n借助此体系，构建了数据公共层。\n从数据计算频率角度来看，阿里数据仓库可以分为离线数据仓库（传统的数据仓库概念）和实时数据仓库（典型应用：双11实时数据）。\n阿里数据仓库的数据加工链路也是遵循业界的分层理念，包括：\n操作数据层（Operational Data Store，ODS）; 明细数据层（Data WareHouse Detail，DWD）； 应用数据层（Application Data Store，ADS）。 通过数据仓库不同层次之间的加工过程实现从数据资产向信息资产的转化，并且对整个过程进行有效的元数据管理及数据质量处理。\n元数据模型整合及应用是一个重要的组成部分，主要包含：\n数据源元数据 数据仓库元数据 数据链路元数据 工具类元数据 数据质量类元数据 元数据应用主要面向数据发现、数据管理等，如用于存储、计算和成本管理。\n数据服务层 当数据已被整合和计算好之后，需要提供给产品和应用进行数据消费。\n针对不同的需求，数据服务层的数据源架构在多种数据库之上，如Mysql和HBase。\n数据服务层主要考虑性能、稳定性、扩展性。\nOneService（数据服务平台）一数据仓库整合计算好的数据作为数据源，对外通过接口的方式提供数据服务，主要提供简单数据查询服务、复杂数据查询服务（用户识别、用户画像等）和实时数据推送服务。\n数据应用层 第1篇 数据技术篇 第2章 日志采集 第2篇 数据模型篇 第8章 大数据领域建模综述 8.1 为什么需要数据建模 如何将数据进行有序、有结构地分类组织和存储？\n数据模型就是数据组织和存储方法，它强调从业务、数据存取和使用角度合理存储数据。有了适合业务和基础数据存储环境的模型，那么大数据就能获得以下好处：\n性能：良好的数据模型能帮助我们快速查询所需要的数据，减少数据的I/O吞吐。 成本：良好的数据模型能极大地减少不必要的数据冗余，也能实现计算结果复用，极大地降低大数据系统中的存储和计算成本。 效率：良好的数据模型能极大地改善用户使用数据的体验，提高使用数据的效率。 质量：良好的数据模型能改善数据统计口径的不一致性，减少数据计算错误的可能性。 8.2 关系行数据库系统和数据仓库 大数据领域仍然使用关系型数据库，使用关系理论描述数据之间的关系，只是基于其数据存储的特点关系数据模型的范式上有了不同的选择。\n8.3 从OLTP和OLAP系统特别看模型方法论的选择 OLTP系统通常面向的主要数据操作是随即读写，主要采用满足3NF的实体关系模型存储数据，从而在事务处理中解决数据的冗余和一致性问题；而OLAP系统面向的主要数据操作时批量读写，事物处理中的一致性不是OLAP所关注的，其主要关注数据的集合，以及在一次性的复杂大数据查询和处理中的性能，因此它需要采用一些不同的数据建模方法。\n8.4 典型的数据仓库建模方法论 8.4.1 ER模型 数据仓库中的3NF和OLPT系统中的3NF的却别在于，它是站在企业角度面向主题的抽象，而不是针对某个具体业务流程的实体对象关系的抽象。其具有以下几个特点：\n需要全面了解企业业务和数据； 事实周期非常长； 对建模人员的能力要求非常高。 采用ER模型建设数据仓库魔性的出发点是整合数据将个系统中的数据以整个企业角度按主题进项相似性组合和合并，并进行一致性处理，为数据分析决策服务，但是并不能直接用于分析决策。\n其建模步骤分为三个阶段：\n高层模型：一个高度抽象的模型，描述主要的主题以及主题间的关系，用语描述企业的业务总体概况。 中层模型：在高层模型的基础上，细化主题的数据项。 物理模型（也叫底层模型）：在中层模型的基础上，考虑物理存储，同时基于性能和平台特点进行物理属性的设计，也可能作一些表的合并、分区的设计等。 实践典型：金融业务FS-LDM。\n8.4.2 维度模型 是数据仓库工程领域最流行的数据仓库建模的经典。\n维度建模从分析决策的需求出发构建模型，为分析需求服务，因此它重点关注用户如何更快速地完成需求分析，同时具有较好的大规模复杂查询的响应性能。其典型的代表是星形模型，以及在一些特殊场景下使用的雪花模型。其设计分为一下几个步骤：\n选择需要进行分析决策的业务过程。业务过程可以是单个业务事件，比如交易的支付、退款等；也可以时某个时间的状态，比如当前的账户余额等；还可以是一系列相关业务时间组成的业务流程，具体需要看我们分析的是某些事件发生情况，还是当前状态，或是事件流转效率； 选择粒度。在事件分析中，我们要预判所有分析需要细分的程度，从而决定选择的粒度。粒度是维度的一个组合； 识别维表。选择好粒度之后，就需要细雨此粒度设计维表，包括维度属性，用于分析时进行分组和筛选； 选择事实。确定分析需要衡量的指标。 8.4.3 Data Vault模型 ER模型的衍生。其设计的出发点也是为了实现数据的整合，但不能直接用于数据分析决策。","title":"序"},{"content":"第1章 Java的I/O演进之路 1.1 I/O基础入门 1.1.1 Linux网络I/O模型简介 UNIX提供了5种I/O模型：\n（1）阻塞I/O模型\n（2）非阻塞I/O模型\n（3）I/O复用模型\n（4）信号驱动I/O模型\n（5）异步I/O\n1.1.2 I/O多路复用技术 把多个I/O阻塞复用到同一个select的阻塞上，从而是的系统在单线程的情况下可以同时处理多个客户端请求。比多线程有性能优势，节约资源。\n支持I/O多路复用的系统调用select/pselect/poll/epoll。\nepoll的优点：\n支持一个进程打开的socket描述符（FD）不受限制（仅受限于操作系统的最大文件句柄数（内存））。 I/O效率不会随着FD数目的增加而线性下降。 使用mmap加速内核与用户空间的消息传递。 epoll的API更加简单。 1.2 Java的I/O演进 历史题，略。\n第2章 NIO入门 2.1 传统的BIO编程 C/S模型，客户端发起连接请求，三次握手，通过Socket进行通信。\n2.1.1 BIO通信模型图 一请求一应答模型：每次接收到连接请求都创建一个新的线程进行链路处理。处理完成后通过输出流返回应答给客户端，线程销毁。\n该模型最大的问题就是：缺乏弹性伸缩能力，当客户端并发访问量增加后，服务端的线程个数和客户端并发访问数呈1：1的正比关系。\n2.1.2 同步阻塞式I/O创建的TimeServer源码分析 import java.io.IOException; import java.net.ServerSocket; import java.net.Socket; /** * \u0026lt;p\u0026gt;Description: 同步阻塞式I/O创建的TimeServer\u0026lt;/p\u0026gt; * * @author 李宏博 * @version xxx * @create 2019/8/14 17:58 */ public class TimeServer { /** * * @param args */ public static void main(String[] args) throws IOException { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } ServerSocket server = null; try { server = new ServerSocket(port); System.out.println(\u0026#34;服务端端口开启：\u0026#34; + port); Socket socket = null; while (true) { socket = server.accept(); new Thread(new TimeServerHandle(socket)).start(); } } finally { if (server != null) { System.out.println(\u0026#34;服务端关闭\u0026#34;); server.close(); server = null; } } } } import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.io.PrintWriter; import java.net.Socket; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version xxx * @create 2019/8/14 18:05 */ public class TimeServerHandle implements Runnable { private Socket socket; public TimeServerHandle(Socket socket) { this.socket = socket; } @Override public void run() { BufferedReader in = null; PrintWriter out = null; try { in = new BufferedReader(new InputStreamReader(this.socket.getInputStream())); out = new PrintWriter(this.socket.getOutputStream(),true); String currentTime = null; String body = null; while (true) { body = in.readLine(); if (body == null) { break; } System.out.println(\u0026#34;接收到命令：\u0026#34; + body); currentTime = \u0026#34;time\u0026#34;.equalsIgnoreCase(body) ? new java.util.Date(System.currentTimeMillis()).toString() : \u0026#34;命令错误\u0026#34;; out.println(currentTime); } } catch (Exception e) { if (in != null) { try { in.close(); } catch (IOException ex) { ex.printStackTrace(); } } if (out != null) { out.close(); out = null; } if (this.socket != null) { try { this.socket.close(); } catch (IOException ex) { ex.printStackTrace(); } finally { this.socket = null; } } } } } 2.1.3 同步阻塞式I/O创建的TimeClient源码分析 import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.io.PrintWriter; import java.net.Socket; import java.net.UnknownHostException; /** * \u0026lt;p\u0026gt;Description: 同步阻塞式I/O创建的TimeClient\u0026lt;/p\u0026gt; * * @author 李宏博 * @version xxx * @create 2019/8/14 18:21 */ public class TimeClient { /** * * @param args */ public static void main(String[] args) { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } Socket socket = null; BufferedReader in = null; PrintWriter out = null; try { socket = new Socket(\u0026#34;127.0.0.1\u0026#34;,port); in = new BufferedReader(new InputStreamReader(socket.getInputStream())); out = new PrintWriter(socket.getOutputStream(),true); out.println(\u0026#34;time\u0026#34;); System.out.println(\u0026#34;命令发送成功\u0026#34;); String resp = in.readLine(); System.out.println(\u0026#34;现在时间：\u0026#34; + resp); } catch (UnknownHostException e) { e.printStackTrace(); } catch (IOException e) { e.printStackTrace(); } finally { if (out != null) { out.close(); out = null; } if (in != null) { try { in.close(); } catch (IOException e) { e.printStackTrace(); } finally { in = null; } } if (socket != null) { try { socket.close(); } catch (IOException e) { e.printStackTrace(); } finally { socket = null; } } } } } 2.2 伪异步I/O编程 引入线程池。\n2.2.1 伪异步I/O模型图 由于线程池可以设置消息队列的大小和最大线程数，因此，它的资源占用式可控的，无论多少个客户端并发访问，都不会导致资源的耗尽和宕机。\n2.2.2 伪异步I/O创建的TimeServer源码分析 import java.io.IOException; import java.net.ServerSocket; import java.net.Socket; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version xxx * @create 2019/8/14 18:37 */ public class TimeServer2 { /** * * @param args */ public static void main(String[] args) throws IOException { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } ServerSocket server = null; try { server = new ServerSocket(port); System.out.println(\u0026#34;服务端端口开启：\u0026#34; + port); Socket socket = null; TimeServerHandlerExecutePool singleExecutePool = new TimeServerHandlerExecutePool(50,10000); while (true) { socket = server.accept(); singleExecutePool.execute(new TimeServerHandle(socket)); } } finally { if (server != null) { System.out.println(\u0026#34;服务端关闭\u0026#34;); server.close(); server = null; } } } } import java.util.concurrent.ArrayBlockingQueue; import java.util.concurrent.ExecutorService; import java.util.concurrent.ThreadPoolExecutor; import java.util.concurrent.TimeUnit; /** * \u0026lt;p\u0026gt;Description: 线程池\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/14 18:40 */ public class TimeServerHandlerExecutePool { private ExecutorService executor; public TimeServerHandlerExecutePool(int maxPoolSize,int queueSize) { executor = new ThreadPoolExecutor(Runtime.getRuntime().availableProcessors(),maxPoolSize,120L, TimeUnit.SECONDS,new ArrayBlockingQueue\u0026lt;Runnable\u0026gt;(queueSize)); } public void execute(Runnable task) { executor.execute(task); } } 由于底层的通信依然采用同步阻塞模型。因此无法从根本上解决问题。\n2.2.3 伪异步I/O弊端分析 操作Socket的输入流时，会一直阻塞，知道出现以下情况：\n有数据可读； 可用数据已经读取完毕； 发生空指针或者I/O异常。 输出流也会阻塞，TCP发送窗口跟接收窗口大小相关，流量控制。如果采用同步I/O会，wirte操作会被无限期阻塞。\n阻塞的时间取决于对方I/O线程的处理速度和网络I/O的传输速度。所以不能依赖对方的处理速度进行I/O。\n通信对方返回应答时间过程会引起的级联故障：\n（1）服务端处理缓慢，返回应答消息耗费60s，平时只需要10ms；\n（2）采用伪异步I/O的线程正在读取故障服务节点的响应，由于读取输入流时阻塞的，它将会被同步阻塞60s；\n（3）假如所有可用线程都被故障服务器阻塞，那后续所有的I/O消息都将在队列中排队。\n（4）由于线程池采用阻塞队列实现，当队列积满之后，后续入队列的操作将被阻塞。\n（5）由于前端只有一个Accptor线程接收客户端接入，它被阻塞在线程池的同步阻塞队列之后，新的客户端请求消息将被拒绝，客户端会发生大量的连接超时。\n（6）由于所有的连接都超时，调用者会认为系统已经崩溃，无法接收新的请求消息。\n2.3 NIO编程 本书使用的NIO都指的是非阻塞I/O。\n一般来说，低负载、低并发的应用程序可以选择同步I/O以降低编程复杂度；对于高负载、高并发的网络应用，需要使用NIO的非阻塞模式进行开发。\n2.3.1 NIO类库简介 缓冲区 Buffer Buffer是一个对象，包含一些要写入或者要读出的数据。在面向流的I/O种，可以将数据直接写入或者将数据直接读到Stream对象中。\n所有读写操作都通过缓冲区进行。\n实际上是一个数组。通常为ByteBuffer。\n通道 Channel 双向。流Stream是单向的。通道可以用于读、写或者二者同时进行。\n多路复用器 Selector Selector会不断地轮询注册在其上的Channel，如果某个Channel上面发生读或者写事件，这个Channe了就处于就绪状态，会被Selector轮询出来，然后通过SelectionKey可以获取就绪Channel的集合，进行后续的I/O操作。\n2.3.2 NIO服务端序列图 步骤一：打开ServerSocketChannel，用于监听客户端的连接，它是所有客户端连接的父管道；\nServerSocketChannel acceptorSvr = ServerSocketChannel.open(); 步骤二：绑定监听端口，设置连接为非阻塞模式；\nacceptorSvr.socket().bind(new InetSocketAddress(InetAddress.getByName(\u0026#34;IP\u0026#34;),port)); acceptorSvr.configureBlocking(false); 步骤三：创建Reactor线程，创建多路复用器并启动线程；\nSelector selector = Selector.open(); New Thread(new ReactorTask()).start(); 步骤四：将ServerSocketChannel注册到Reactor线程的多路复用器Selector上，监听ACCEPT事件；\nSelectionKey key = acceptorSvr.register(selector, SelectionKey.OP_ACCEPT, ioHandler); 步骤五：多路复用器在线程run方法的无限循环体内轮询准备就绪的Key；\nint num = Selector.select(); Set selectedKeys = selector.selectedKeys(); Iterator it = selectedKeys.iterator(); while (it.hasNext()) { SelectionKey key = (SelectionKey) it.next(); } 步骤六：多路复用监听器听到有新的客户端接入，处理新的接入请求，完成TCP三次握手，建立物理链路；\nSocketChannel channel = svrChannel.accept(); 步骤七：设置客户端链路为非阻塞模式；\nchannel.configureBlocking(false); channel.socket().setReuseAddress(true); 步骤八：将新接入的客户端连接注册到Reactor线程的多路复用器上，监听读操作，读取客户端发送的网络消息，示例代码如下；\nSelectionKey key = socketChannel.register(selector, SelectionKey.OP_READ,ioHandler); 步骤九：异步读取客户端请求消息到缓冲区；\nint readNumber = channel.read(receivedBuffer); 步骤十：对ByteBuffer进行编解码，如果有半包消息指针reset，继续读取后续的报文，将节码成功的消息封装成Task，投递到业务线程池中，进行业务逻辑编排；\nObject message = null; while(buffer.hasRemain()) { byteBuffer.mark(); Object message = decode(byteBuffer); if(message == null) { byteBuffer.reset(); break; } messageList.add(message); } if(!byteBuffer.hasRemain()) { byteBuffer.clear(); } else { byteBuffer.compact(); } .......................... 步骤十一：将POJO对象encode成Bytebuffer，调用SocketChannel的异步write接口，将消息异步发送到客户端；\nsocketChannel.write(buffer); 2.3.3 NIO创建的TimeServer源码分析 /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/15 11:40 */ public class TimeServer3 { public static void main(String[] args) { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } MultiplexerTimeServer timeServer = new MultiplexerTimeServer(port); new Thread(timeServer, \u0026#34;NIO-MultiplexerTimeServer-001\u0026#34;).start(); } } import java.io.IOException; import java.net.InetSocketAddress; import java.net.ServerSocket; import java.nio.ByteBuffer; import java.nio.channels.SelectionKey; import java.nio.channels.Selector; import java.nio.channels.ServerSocketChannel; import java.nio.channels.SocketChannel; import java.util.Iterator; import java.util.Set; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/15 11:42 */ public class MultiplexerTimeServer implements Runnable{ private Selector selector; private ServerSocketChannel serverSocketChannel; private volatile boolean stop; public MultiplexerTimeServer(int port) { try { selector = Selector.open(); serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.configureBlocking(false); serverSocketChannel.socket().bind(new InetSocketAddress(port),1024); serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); System.out.println(\u0026#34;服务器启动，端口号：\u0026#34;+port); } catch (IOException e) { e.printStackTrace(); System.exit(1); } } public void stop() { this.stop = true; } public void run() { while (!stop) { try { selector.select(1000); Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; it = selectionKeys.iterator(); SelectionKey key = null; while (it.hasNext()) { key = it.next(); it.remove(); try { handleInput(key); } catch (Exception e) { if (key != null) { key.cancel(); if (key.channel() != null) { key.channel().close(); } } } } } catch (Throwable t) { t.printStackTrace(); } } if (selector != null) { try { selector.close(); } catch (IOException e) { e.printStackTrace(); } } } private void handleInput(SelectionKey key) throws IOException { if (key.isValid()) { if (key.isAcceptable()) { ServerSocketChannel ssc = (ServerSocketChannel) key.channel(); SocketChannel sc = ssc.accept(); sc.configureBlocking(false); sc.register(selector,SelectionKey.OP_READ); } if (key.isReadable()) { SocketChannel sc = (SocketChannel) key.channel(); ByteBuffer readBuffer = ByteBuffer.allocate(1024); int readBytes = sc.read(readBuffer);//非阻塞 if (readBytes \u0026gt; 0) { readBuffer.flip(); byte[] bytes = new byte[readBuffer.remaining()]; readBuffer.get(bytes); String body = new String(bytes,\u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;服务器接收到命令：\u0026#34;+body); String currentTime = \u0026#34;time\u0026#34;.equalsIgnoreCase(body) ? new java.util.Date(System.currentTimeMillis()).toString() : \u0026#34;命令错误\u0026#34;; doWrite(sc,currentTime); } else if (readBytes \u0026lt; 0) {//返回值等于-1，链路已经关闭 key.cancel(); sc.close(); } else {//返回值等于0 } } } } private void doWrite(SocketChannel channel, String response) throws IOException { if (response != null \u0026amp;\u0026amp; response.trim().length() \u0026gt; 0) {//由于SocketChannel是异步非阻塞的，会出现“写半包”问题 byte[] bytes = response.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); writeBuffer.put(bytes); writeBuffer.flip(); channel.write(writeBuffer); } } } 2.3.4 NIO客户端序列图 步骤一：打开SocketChannel，绑定客户端本地地址（可选，默认随机分配）；\nSocketChannel clientChannel = SocketChannel.open(); 步骤二：设置SocketChannel为非阻塞模式，同时设置客户端连接的TCP参数；\nclientChannel.configureBlocking(false); socket.setReuseAddress(true); socket.setReceiveBufferSize(BUFFER_SIZE); socket.setSendBufferSize(BUFFER_SIZE); 步骤三：异步连接服务端；\nboolean connected = clientChannel.connect(new InetSocketAddress(\u0026#34;ip\u0026#34;,port)); 步骤四：判断是否连接成功，如果连接成功，则直接注册读状态位到多路复用器中，如果当前没有连接成功（异步连接，返回false，说明客户端已经发送sync包，服务端没有返回ack包，物理链路还没有建立）；\nif(connectied) { clientChannel.register(selector,Selection.OP_READ,ioHandler); } else { clientChannel.register(selector,Selection.OP_CONNECT,ioHandler); } 步骤五：向Reactor线程的多路复用器注册OP_CONNECT状态位，监听服务端的TCPACK应答；\nclientChannel.register(selector, Selection.OP_CONNECT, ioHandler); 步骤六：创建Reactor线程，创建多路复用器并启动线程；\nSelector seletor = Selector.open(); new Thread(new ReactorTask()).start(); 步骤七：多路复用器在线程run方法的无限循环体内轮询准备就绪的Key；\nint num = selector.select(); Set selectedKeys = selector,selectedKeys(); Irerator it = selectedKeys.iterator(); while (it.hasNext()) { SelectionKey key = (SelectionKey) it.next(); } 步骤八：接收connect事件进行处理；\nif(key.isConnectable()) { .. } 步骤九：判断连接结果，如果连接成功，注册读事件到多路复用器；\nif(channel.finishConnection()) { registerRead(); } 步骤十：注册读事件到多路复用器；\nclientChannel.register(selector, SelectionKey.OP_READ, ioHandler); 步骤十一：异步读客户端请求消息到缓冲区；\nint readNumber = channel.read(receiveBuffer); 步骤十二：对ByteBuffer进行编解码，如果有半包消息接收缓冲区Reset，继续读取后续的报文，将解码成功的消息封装成Task，投递到业务线程池中，进行业务逻辑编排。\n略\n步骤十三：将POKO对象encode成ByteBuffer，调用SocketChannel的异步write接口，将消息异步发送给客户端。\nsocketChannel.write(buffer); 2.3.5 NIO创建的TimeClient源码分析 package NIO; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/15 14:13 */ public class TimeClient { public static void main(String[] args) { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } new Thread(new TimeClientHandle(\u0026#34;127.0.0.1\u0026#34;,port),\u0026#34;TimeClient-001\u0026#34;).start(); } } package NIO; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.SelectionKey; import java.nio.channels.Selector; import java.nio.channels.SocketChannel; import java.util.Iterator; import java.util.Set; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/15 14:16 */ public class TimeClientHandle implements Runnable { private String host; private int port; private Selector selector; private SocketChannel socketChannel; private volatile boolean stop; public TimeClientHandle(String host, int port) { this.host = host == null ? \u0026#34;127.0.0.1\u0026#34; : host; this.port = port; try { selector = Selector.open(); socketChannel = SocketChannel.open(); socketChannel.configureBlocking(false); } catch (IOException e) { e.printStackTrace(); System.exit(1); } } @Override public void run() { try { doConnect(); } catch (IOException e) { e.printStackTrace(); System.exit(1); } while (!stop) { try { selector.select(1000); Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; it = selectionKeys.iterator(); SelectionKey key = null; while (it.hasNext()) { key = it.next(); it.remove(); try { handleInput(key); } catch (IOException e) { if (key != null) { key.cancel(); if (key.channel() != null) { key.channel().close(); } } } } } catch (Exception e) { e.printStackTrace(); System.exit(1); } } if (selector != null) { try { selector.close(); } catch (IOException e) { e.printStackTrace(); } } } private void handleInput(SelectionKey key) throws IOException { if (key.isValid()) { SocketChannel sc = (SocketChannel) key.channel(); if (key.isConnectable()) { if (sc.finishConnect()) { sc.register(selector, SelectionKey.OP_READ); doWrite(sc); } else { System.exit(1); } } if (key.isReadable()) { ByteBuffer readBuffer = ByteBuffer.allocate(1024); int readBytes = sc.read(readBuffer); if (readBytes \u0026gt; 0) { readBuffer.flip(); byte[] bytes = new byte[readBuffer.remaining()]; readBuffer.get(bytes); String body = new String(bytes,\u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;现在时间：\u0026#34; + body); this.stop = true; } else if (readBytes \u0026lt; 0) { key.cancel(); sc.close(); } else {} } } } private void doConnect() throws IOException { if (socketChannel.connect(new InetSocketAddress(host,port))) { socketChannel.register(selector, SelectionKey.OP_READ); doWrite(socketChannel); } else { socketChannel.register(selector,SelectionKey.OP_CONNECT); } } private void doWrite(SocketChannel sc) throws IOException { byte[] req = \u0026#34;Time\u0026#34;.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(req.length); writeBuffer.put(req); writeBuffer.flip(); sc.write(writeBuffer); if (!writeBuffer.hasRemaining()) { System.out.println(\u0026#34;命令发送成功\u0026#34;); } } } NIO编程的难度大，而且还没有考虑”半包读“和”半包写“，加上会更复杂。\nNIO的优点：\n（1）客户端发起的连接操作是异步的，可以通过在多路复用器注册OP_CONNECT等待后续结果，不需要像之前的客户端那样被同步阻塞。\n（2）SocketChannel的读写操作都是异步的，如果没有可读写的数据它不会同步等待，直接返回，这样I/O通信线程就可以处理其他的链路，不需要同步等待这个链路可用。\n（3）线程模型的优化：在linux上的底层是epoll。性能不随客户端的增加先行下降。\n因此适合做高性能，高负载的网络服务器。\n2.4 AIO编程 异步通道通过以下两种方式获取操作结果：\njava.util.concurrent.Future类表示异步操作的结果。 在执行异步操作的时候传入一个java.nio.channels。 CompletionHandle接口的实现类作为操作完成的回调。\n不需要多路复用器（Selector），简化NIO的编程模型。\n2.4.1 AIO创建的TimeServer源码分析 package AIO; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 9:38 */ public class TimeServer { public static void main(String[] args) { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } AsyncTimeServerHandler timeserver = new AsyncTimeServerHandler(port); new Thread(timeserver,\u0026#34;AIO-\u0026#34; + \u0026#34;AsyncTimeServerHandler-001\u0026#34;).start(); } } package AIO; import java.io.IOException; import java.net.InetSocketAddress; import java.nio.channels.AsynchronousServerSocketChannel; import java.util.concurrent.CountDownLatch; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 9:41 */ public class AsyncTimeServerHandler implements Runnable{ private int port; CountDownLatch latch; AsynchronousServerSocketChannel asynchronousServerSocketChannel; public AsyncTimeServerHandler(int port) { this.port = port; try { asynchronousServerSocketChannel = AsynchronousServerSocketChannel.open(); asynchronousServerSocketChannel.bind(new InetSocketAddress(port)); } catch (IOException e) { e.printStackTrace(); } } @Override public void run() { latch = new CountDownLatch(1); doAccept(); try { latch.await(); } catch (InterruptedException e) { e.printStackTrace(); } } private void doAccept() { asynchronousServerSocketChannel.accept(this, new AcceptCompletionHandler()); } } package AIO; import java.nio.ByteBuffer; import java.nio.channels.CompletionHandler; import java.nio.channels.AsynchronousSocketChannel; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 9:54 */ public class AcceptCompletionHandler implements CompletionHandler\u0026lt;AsynchronousSocketChannel,AsyncTimeServerHandler\u0026gt; { @Override public void completed(AsynchronousSocketChannel result, AsyncTimeServerHandler attachment) { attachment.asynchronousServerSocketChannel.accept(attachment,this); ByteBuffer buffer = ByteBuffer.allocate(1024); result.read(buffer, buffer, new ReadCompletionHandler(result)); } @Override public void failed(Throwable exc, AsyncTimeServerHandler attachment) { exc.printStackTrace(); attachment.latch.countDown(); } } package AIO; import java.io.IOException; import java.io.UnsupportedEncodingException; import java.nio.ByteBuffer; import java.nio.channels.AsynchronousSocketChannel; import java.nio.channels.CompletionHandler; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 10:14 */ public class ReadCompletionHandler implements CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt; { private AsynchronousSocketChannel channel; public ReadCompletionHandler(AsynchronousSocketChannel channel) { if (this.channel == null) { this.channel = channel; } } @Override public void completed(Integer result, ByteBuffer attachment) { attachment.flip(); byte[] body = new byte[attachment.remaining()]; attachment.get(body); try { String req = new String(body, \u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;服务器接收到命令：\u0026#34; + req); String currentTime = \u0026#34;time\u0026#34;.equalsIgnoreCase(req) ? new java.util.Date(System.currentTimeMillis()).toString() : \u0026#34;命令错误\u0026#34;; doWrite(currentTime); } catch (UnsupportedEncodingException e) { e.printStackTrace(); } } private void doWrite(String currentTime) { if (currentTime != null \u0026amp;\u0026amp; currentTime.trim().length() \u0026gt; 0) { byte[] bytes = (currentTime).getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); writeBuffer.put(bytes); writeBuffer.flip(); channel.write(writeBuffer, writeBuffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { @Override public void completed(Integer result, ByteBuffer buffer) { if (buffer.hasRemaining()) channel.write(buffer, buffer, this); } @Override public void failed(Throwable exc, ByteBuffer buffer) { try { channel.close(); } catch (IOException e) { e.printStackTrace(); } } }); } } @Override public void failed(Throwable exc, ByteBuffer attachment) { try { this.channel.close(); } catch (IOException e) { e.printStackTrace(); } } } 2.4.2 AIO创建的TimeClient源码分析 package AIO; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 10:32 */ public class TimeClient { public static void main(String[] args) { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } new Thread(new AsyncTimeClientHandler(\u0026#34;127.0.0.1\u0026#34;,port),\u0026#34;AIO-AsyncTimeClient-001\u0026#34;).start(); } } package AIO; import java.io.IOException; import java.io.UnsupportedEncodingException; import java.net.InetSocketAddress; import java.nio.ByteBuffer; import java.nio.channels.AsynchronousSocketChannel; import java.nio.channels.CompletionHandler; import java.util.concurrent.CountDownLatch; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 10:35 */ public class AsyncTimeClientHandler implements CompletionHandler\u0026lt;Void,AsyncTimeClientHandler\u0026gt;,Runnable { private AsynchronousSocketChannel client; private String host; private int port; private CountDownLatch latch; public AsyncTimeClientHandler(String host, int port) { this.host = host; this.port = port; try { client = AsynchronousSocketChannel.open(); } catch (IOException e) { e.printStackTrace(); } } @Override public void run() { latch = new CountDownLatch(1); client.connect(new InetSocketAddress(host, port), this, this); try { latch.await(); } catch (InterruptedException e) { e.printStackTrace(); } try { client.close(); } catch (IOException e) { e.printStackTrace(); } } @Override public void completed(Void result, AsyncTimeClientHandler attachment) { byte[] req = \u0026#34;time\u0026#34;.getBytes(); ByteBuffer writeBuffer = ByteBuffer.allocate(req.length); writeBuffer.put(req); writeBuffer.flip(); client.write(writeBuffer, writeBuffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { @Override public void completed(Integer result, ByteBuffer buffer) { if (buffer.hasRemaining()) { client.write(buffer, buffer, this); } else { ByteBuffer readBuffer = ByteBuffer.allocate(1024); client.read(readBuffer, readBuffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { @Override public void completed(Integer result, ByteBuffer buffer) { buffer.flip(); byte[] bytes = new byte[buffer.remaining()]; buffer.get(bytes); String body; try { body = new String(bytes,\u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;现在时间：\u0026#34; + body); latch.countDown(); } catch (UnsupportedEncodingException e) { e.printStackTrace(); } } @Override public void failed(Throwable exc, ByteBuffer buffer) { try { client.close(); } catch (IOException e) { e.printStackTrace(); } } }); } } @Override public void failed(Throwable exc, ByteBuffer buffer) { try { client.close(); } catch (IOException e) { e.printStackTrace(); } } }); } @Override public void failed(Throwable exc, AsyncTimeClientHandler attachment) { exc.printStackTrace(); try { client.close(); latch.countDown(); } catch (IOException e) { e.printStackTrace(); } } } 2.5 4种I/O的对比 2.5.1 概念澄清 异步非阻塞I/O JDK1.4开始提供的NIO严格按照网络编程模型和JDK实现来分类，实际上只能被称为非阻塞I/O不能叫异步非阻塞I/O。1.5用epoll替换了select/poll，只是底层性能的优化，并没有替换I/O模型。\nJDK1.7提供的NIO2.0是真正的异步I/O。\n但习惯上NIO相对于IO还是被称为异步非阻塞IO或非阻塞I/O。\n多路复用器Selector\n伪异步I/O\n完全来源于实践，加入一个缓冲区（线程池）。不是官方概念。\n2.5.2 不同I/O模型的对比 同步阻塞I/O（BIO） 伪异步I/O 非阻塞I/O（NIO） 异步I/O（AIO） 客户端个数：I/O线程 1：1 M:N（其中M可以大于N） M：1（1个I/O线程除了多个客户端连接） M：0（不需要启动额外的I/O线程，被动回调） I/O类型（阻塞） 阻塞I/O 阻塞I/O 非阻塞I/O 非阻塞I/O I/O类型（同步） 同步I/O 同步I/O 同步I/O（I/O多路复用） 异步I/O API使用难度 简单 简单 非常复杂 复杂 可靠性 非常差 差 高 高 吞吐量 低 中 高 高 2.6 选择Netty的理由 2.6.1 不选择Java原生NIO的原因 （1）NIO的类库和API繁杂，使用麻烦，需要熟练掌握Selector、ServerSocketChannel、SocketChannel、ByteBuffer等；\n（2）涉及到Reactor模式，必须非常熟悉多线程和网络编程；\n（3）可靠性补齐的工作量和难度大；\n（4）BUG，epoll bug。\n2.6.2 为什么选择Netty 优点如下：\nAPI使用简单，开发门槛低。 功能强大，预置了多种编解码功能，支持多种主流协议。 。。。 2.7 总结 第3章 Netty入门应用 3.1 Netty开发环境的搭建 注意Netty版本号为 5.0.0.Alpha1。\n3.2 Netty 服务端开发 NIO开发步骤回顾：\n（1）创建ServerSocketChannel，并配置为非阻塞；\n（2）绑定监听，配置TCP参数，例如backlog大小；\n（3）创建一个独立的I/O线程，用于轮询多路复用器Selector；\n（4）创建Selector，将之前的ServerSocketChannel注册在Selector上，监听SelectionKey.ACCEPT；\n（5）启动I/O线程，在循环体中执行Selector.select()方法，轮询就绪的Channel；\n（6）轮循处于就绪状态的Channel，对其判断，如果是OP_ACCEPT，说明是新的客户端接入，则调用ServerSocketChannel.accept()方法接受新的客户端；\n（7）设置新接入的客户端链路SocketChannel为非阻塞模式，配置其他的一些TCP参数；\n（8）将SocketChannel注册到Selector，监听OP_READ操作位；\n（9）监听到后读取；\n（10）如果是OP_WRITE，则继续发送。\npackage Time; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 15:05 */ public class TimeServer { public void bind(int port) throws Exception { //创建两个线程组的原因：一个用于服务端接受客户端的连接，另一个用于进行SocketChannel的网络读写 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //Netty用于启动NIO服务端的辅助启动类，目的是降低服务端的开发复杂度 ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup,workerGroup)//传入线程组 .channel(NioServerSocketChannel.class)//设置Channel，对应NIO中的ServerSocketChannel .option(ChannelOption.SO_BACKLOG, 1024)//配置TCP参数，设置backlog为1024 .childHandler(new ChildChannelHandler()); ChannelFuture f = b.bind(port).sync();//绑定并阻塞，完成后取消阻塞，返回一个ChannelFuture，类似于JDK的Future f.channel().closeFuture().sync();//阻塞，等待服务端链路关闭之后才退出main函数 } finally { //优雅退出 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } private class ChildChannelHandler extends ChannelInitializer\u0026lt;SocketChannel\u0026gt; { @Override protected void initChannel(SocketChannel arg0) throws Exception { arg0.pipeline().addLast(new TimeServerHandle()); } } public static void main(String[] args) throws Exception { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } new TimeServer().bind(port); } } package Time; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; import java.io.UnsupportedEncodingException; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 15:28 */ public class TimeServerHandler extends ChannelHandlerAdapter { public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg;//类似ByteBuffer，更强大灵活 byte[] req = new byte[buf.readableBytes()]; buf.readBytes(req); String body = new String(req, \u0026#34;UTF-8\u0026#34;); String currentTime = \u0026#34;time\u0026#34;.equalsIgnoreCase(body) ? new java.util.Date(System.currentTimeMillis()).toString() : \u0026#34;命令错误\u0026#34;; ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes()); ctx.write(resp); } public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.flush();//从性能角度考虑，为避免频繁唤醒Selector进行消息发送，Netty不直接写，而是先放到缓冲数组，再调用flush写入。 } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { ctx.close();//发生异常时释放。 } } 3.3 Netty客户端开发 package Time; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 15:47 */ public class TimeClient { public void connect(int port, String host) throws Exception { EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY,true) .handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new TimeClientHandler());//将ClientHandler设置到ChannelPipeline中，用于处理网络I/O事件 } }); ChannelFuture f = b.connect(host, port).sync();//connect异步连接，sync同步等待连接 f.channel().closeFuture().sync(); } finally { group.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } new TimeClient().connect(port, \u0026#34;127.0.0.1\u0026#34;); } } package Time; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandler; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; import io.netty.util.concurrent.EventExecutorGroup; import java.io.UnsupportedEncodingException; import java.util.logging.Logger; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 15:59 */ public class TimeClientHandler extends ChannelHandlerAdapter { private static final Logger logger = Logger.getLogger(TimeClientHandler.class.getName()); private final ByteBuf firstMessage; public TimeClientHandler() { byte[] req = \u0026#34;time\u0026#34;.getBytes(); firstMessage = Unpooled.buffer(req.length); firstMessage.writeBytes(req); } @Override public void channelActive(ChannelHandlerContext ctx) { ctx.writeAndFlush(firstMessage); } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; byte[] req = new byte[buf.readableBytes()]; buf.readBytes(req); String body = new String(req, \u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;现在时间：\u0026#34; + body); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { logger.warning(\u0026#34;出错：\u0026#34; + cause.getMessage()); ctx.close(); } } 3.4 运行和调试 略\n3.5 总结 第4章 TCP粘包/拆包问题的解决之道 4.1 TCP粘包/拆包 TCP不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行包的划分。\n4.1.1 TCP粘包/拆包问题说明 4种情况（假设客户端发包）：\n（1）服务端收到两个独立数据包，无粘包/拆包；\n（2）服务端收到两个粘合在一起的包，粘包；\n（3）服务端分两次读取到一个包，拆包；\n（4）同3；\n（5）接收窗口过小，出现多次拆包；\n4.1.2 TCP粘包/拆包发生的原因 3个原因：\n（1）应用程序write写入的字节大小大于套接口发送大小；\n（2）进行MSS（最大报文长度）大小的TCP分段；\n（3）以太网帧的payload大于MTU进行IP分片；\n4.1.3 粘包问题的解决策略 由于底层的TCP不能理解业务数据，只能通过上层的应用协议栈设计来解决，4个策略：\n（1）消息定长（例如固定每个报文段的大小为固定长度，不够则补空格）；\n（2）在包尾增加回车换行符进行分割，例如FTP协议；\n（3）消息头消息体，消息头中设立一个总长度字段；\n（4）更复杂的应用层协议。\n4.2 未考虑TCP粘包导致功能异常案例 4.2.1 TimeServer的改造 package _4_; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/16 15:28 */ public class TimeServerHandler extends ChannelHandlerAdapter { private int counter; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg;//类似ByteBuffer，更强大灵活 byte[] req = new byte[buf.readableBytes()]; buf.readBytes(req); String body = new String(req, \u0026#34;UTF-8\u0026#34;).substring(0, req.length - System.getProperty(\u0026#34;line.separator\u0026#34;).length()); System.out.println(\u0026#34;服务端接收到命令：\u0026#34; + body + \u0026#34;; 计数：\u0026#34; + ++counter); String currentTime = \u0026#34;time\u0026#34;.equalsIgnoreCase(body) ? new java.util.Date(System.currentTimeMillis()).toString() : \u0026#34;命令错误\u0026#34;; ByteBuf resp = Unpooled.copiedBuffer(currentTime.getBytes()); ctx.writeAndFlush(resp); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { ctx.close();//发生异常时释放。 } } 4.2.2 TimeClient的改造 package _4_; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; import java.util.logging.Logger; /** * */ public class TimeClientHandler extends ChannelHandlerAdapter { private static final Logger logger = Logger.getLogger(TimeClientHandler.class.getName()); private int counter; private byte[] req; public TimeClientHandler() { req = (\u0026#34;time\u0026#34; + System.getProperty(\u0026#34;line.separator\u0026#34;)).getBytes(); } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ByteBuf message = null; for (int i = 0; i \u0026lt; 100; i++) {//建立连接后循环发送100条消息，保证每条都被写入到Channel message = Unpooled.buffer(req.length); message.writeBytes(req); ctx.writeAndFlush(message); } } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { ByteBuf buf = (ByteBuf) msg; byte[] req = new byte[buf.readableBytes()]; buf.readBytes(req); String body = new String(req, \u0026#34;UTF-8\u0026#34;); System.out.println(\u0026#34;现在时间：\u0026#34; + body + \u0026#34;; 计数：\u0026#34; + ++counter); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { logger.warning(\u0026#34;出错：\u0026#34; + cause.getMessage()); ctx.close(); } } 4.2.3 运行结果 出现TCP粘包\n4.3 利用LineBasedFrameDecoder解决TCP粘包问题 代码不贴了，就是将自己在ByteBuf中的操作省去，然后加入两个解码器LineBasedFrameDecoder和StringDecoder。\n4.3.3 运行TCP粘包的时间服务器程序 运行成功，符合预期。成功解决了TCP粘包导致的读半包问题。\n4.3.4 LineBasedFrameDecoder和StringDecoder的原理分析 LineBasedFrameDecoder的工作原理：依次遍历，有“\\n”或者“\\r\\n”则结束。以换行符为结束标志的解码器，支持携带结束符或者不携带结束符两种解码方式，同时支持配置单行的最大长度。如果连续读取到最大长度后仍然没有发现换行符，就会抛出异常，同时忽略掉之前督导的异常码流。\nStringDecoder的功能非常简单，就是将接收到的对象转换成字符串，然后继续调用后面的Handler。\nLineBasedFrameDecoder+StringDecoder组合就是按行切换的文本解码器，被设计用来支持TCP的粘包和拆包。\n4.4 总结 第5章 分隔符和定长解码器的应用 区分消息的四种方式：\n（1）消息定长\n（2）回车换行符作为消息结束符\n（3）特殊符号作为结束标志，回车为一种特殊实现\n（4）通常在消息头中定义长度字段来标识消息的总长度\n5.1 DelimiterBasedFrameDecoder应用开发 以分隔符作为码流结束标识的消息的解码。以“$_”作为分隔符。\n5.1.3 DelimiterBasedFrameDecoder服务端开发 package _5_1_; import io.netty.bootstrap.ServerBootstrap; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.DelimiterBasedFrameDecoder; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.logging.LogLevel; import io.netty.handler.logging.LoggingHandler; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 11:03 */ public class EchoServer { public void bind(int port) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ByteBuf delimiter = Unpooled.copiedBuffer(\u0026#34;$_\u0026#34;.getBytes());//创建分隔符缓冲对象，以$_为分隔符。 ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024,delimiter));//设置单条消息最大长度，加入分隔符对象 ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new EchoServerHandler()); } }); ChannelFuture f = b.bind(port).sync(); f.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } new EchoServer().bind(port); } } package _5_1_; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandler; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.ChannelHandlerInvoker; import io.netty.util.concurrent.EventExecutorGroup; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 11:12 */ public class EchoServerHandler extends ChannelHandlerAdapter { int counter = 0; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { String body = (String) msg; System.out.println(\u0026#34;第\u0026#34; + ++counter +\u0026#34;次接收来自客户端的消息：[\u0026#34;+body+\u0026#34;]\u0026#34;);//打印接收到的消息 body += \u0026#34;$_\u0026#34;; ByteBuf echo = Unpooled.copiedBuffer(body.getBytes()); ctx.writeAndFlush(echo); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } } 5.1.2 DelimiterBasedFrameDecoder客户端开发 package _5_1_; import io.netty.bootstrap.Bootstrap; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.codec.DelimiterBasedFrameDecoder; import io.netty.handler.codec.string.StringDecoder; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 11:18 */ public class EchoClient { public void connect(int port, String host) throws Exception { EventLoopGroup group = new NioEventLoopGroup(); try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY,true) .handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ByteBuf delimiter = Unpooled.copiedBuffer(\u0026#34;$_\u0026#34;.getBytes()); ch.pipeline().addLast(new DelimiterBasedFrameDecoder(1024,delimiter)); ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new EchoClientHandler()); } }); ChannelFuture f = b.connect(host, port).sync(); f.channel().closeFuture().sync(); } finally { group.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } new EchoClient().connect(port, \u0026#34;127.0.0.1\u0026#34;); } } package _5_1_; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 11:27 */ public class EchoClientHandler extends ChannelHandlerAdapter { private int counter; static final String ECHO_REQ = \u0026#34;hello,world.$_\u0026#34;; public EchoClientHandler() { } @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { for (int i = 0; i \u0026lt; 10; i++) { ctx.writeAndFlush(Unpooled.copiedBuffer(ECHO_REQ.getBytes())); } } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;第\u0026#34; + ++counter +\u0026#34;次接收来自服务端的返回：[\u0026#34;+msg+\u0026#34;]\u0026#34;); } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } } 5.2 FixedLengthFrameDecoder应用开发 FixedLengthFrameDecoder固定长度解码器。\n5.2.1 FixedLengthFrameDecoder服务端开发 利用FixedLengthFrameDecoder解码器，无论一次接收到多少数据报，它都会按照构造函数中设置的固定长度进行解码，如果是半包消息，FixedLengthFrameDecoder会缓存半包消息并等待下个包到达后进行拼包，知道读取到一个完整的包。\npackage _5_2_; import io.netty.bootstrap.ServerBootstrap; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.DelimiterBasedFrameDecoder; import io.netty.handler.codec.FixedLengthFrameDecoder; import io.netty.handler.codec.string.StringDecoder; import io.netty.handler.logging.LogLevel; import io.netty.handler.logging.LoggingHandler; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 11:03 */ public class EchoServer { public void bind(int port) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup,workGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100)//加入一个属性 .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new FixedLengthFrameDecoder(20));//设置单条消息最大长度，加入分隔符对象 ch.pipeline().addLast(new StringDecoder()); ch.pipeline().addLast(new EchoServerHandler()); } }); ChannelFuture f = b.bind(port).sync(); f.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } new EchoServer().bind(port); } } package _5_2_; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 11:12 */ public class EchoServerHandler extends ChannelHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { System.out.println(\u0026#34;接收到来自客户端的消息：\u0026#34;+\u0026#34;[\u0026#34;+msg+\u0026#34;]\u0026#34;); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } } 5.2.2 利用telnet命令行测试EchoServer服务端 telnet命令相关操作此处不赘述。\n以20字节长度进行截取。\n5.3 总结 DelimiterBasedFrameDecoder用于对使用分隔符结尾的消息进行自动解码。 FixLengthFrameDecoder用于对固定长度的消息进行自动解码。 第6章 编解码技术 Java序列化的目的：\n网络传输 对象持久化 Java对象编解码技术：在进行远程跨进程服务调用时，需要把被传输的Java对象编码为字节数组或者ByteBuffer对象。而当远程服务读取到ByteBuffer对象或者字节数组时，需要将其解码为发送时的Java对象。\nJava序列化仅仅是Java编解码技术的一种，有缺陷。\n6.1 Java序列化的缺点 RPC很少使用Java序列化进行消息的编解码和传输。原因如下：\n6.1.1 无法跨语言 Java序列化技术时Java语言内部的私有协议，其他语言并不支持，对于用户来说完全是黑盒。对于Java序列化后的字节数组，别的语言无法进行反序列化。\n6.1.2 序列化后的码流太大 序列化测试：\npackage _6_1_2_; import java.io.Serializable; import java.nio.ByteBuffer; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 12:52 */ public class UserInfo implements Serializable { private static final long serialVersionID = 1L; private String userName; private int userID; public UserInfo(String userName, int userID) { this.userName = userName; this.userID = userID; } public String getUserName() { return userName; } public void setUserName(String userName) { this.userName = userName; } public int getUserID() { return userID; } public void setUserID(int userID) { this.userID = userID; } public byte[] codeC() { ByteBuffer buffer = ByteBuffer.allocate(1024); byte[] value = this.userName.getBytes(); buffer.putInt(value.length); buffer.put(value); buffer.putInt(this.userID); buffer.flip(); value = null; byte[] result = new byte[buffer.remaining()]; buffer.get(result); return result; } } package _6_1_2_; import java.io.ByteArrayOutputStream; import java.io.IOException; import java.io.ObjectOutputStream; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 12:59 */ public class TestUserInfo { public static void main(String[] args) throws IOException { UserInfo info = new UserInfo(\u0026#34;Welcome to Netty\u0026#34;, 100); ByteArrayOutputStream bos = new ByteArrayOutputStream(); ObjectOutputStream os = new ObjectOutputStream(bos); os.writeObject(info); os.flush(); os.close(); byte[] b = bos.toByteArray(); System.out.println(\u0026#34;JDK序列化长度：\u0026#34; + b.length); bos.close(); System.out.println(\u0026#34;-------------------------\u0026#34;); System.out.println(\u0026#34;byte数组序列化长度：\u0026#34; + info.codeC().length); } } 测试结果：JDK序列化机制编码后的二进制数组大小是二进制编码的5倍多。\n评判编解码框架的优劣时，考虑如下因素：\n是否支持跨语言，支持的语言种类是否丰富； 编码后的码流大小； 编解码的性能； 类库是否小巧，API使用是否方便； 使用者需要手工开发的工作量和难度。 编码后的字节数组大，存储时占用空间大，硬件成本大，网络传输时更占用带宽，导致系统的吞吐量降低。\n6.1.3 序列化性能太低 性能测试：\npackage _6_1_3_; import java.io.ByteArrayOutputStream; import java.io.IOException; import java.io.ObjectOutputStream; import java.nio.ByteBuffer; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 13:43 */ public class PerformTestUserInfo { public static void main(String[] args) throws IOException { UserInfo info = new UserInfo(\u0026#34;Welcome to Netty\u0026#34;, 100); int loop = 1000000; ByteArrayOutputStream bos = null; ObjectOutputStream os = null; long startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; loop; i++) { bos = new ByteArrayOutputStream(); os = new ObjectOutputStream(bos); os.flush(); os.close(); byte[] b = bos.toByteArray(); bos.close(); } long endTime = System.currentTimeMillis(); System.out.println(\u0026#34;JDK序列化用时：\u0026#34;+(endTime - startTime)+\u0026#34; ms\u0026#34;); System.out.println(\u0026#34;=========================================\u0026#34;); ByteBuffer buffer = ByteBuffer.allocate(1024); startTime = System.currentTimeMillis(); for (int i = 0; i \u0026lt; loop; i++) { byte[] b = info.codeC(buffer); } endTime = System.currentTimeMillis(); System.out.println(\u0026#34;byte数组序列化用时：\u0026#34;+(endTime - startTime)+\u0026#34; ms\u0026#34;); } } Java序列化性能只有二进制编码的6%左右，性能很低。\n6.2 业界主流的编解码框架 略\n6.3 总结 第7章 MessagePack编解码 MessagePack是一个高效的二进制序列化框架。像JSON一样支持不同语言间的数据交换，但是性能更快，序列化之后的码流也更小。\n7.1 MessagePack介绍 特点如下：\n编解码高效，性能高； 序列化之后的码流小； 支持跨语言。 7.1.1 MessagePack多语言支持 几乎都支持，不例举。\n7.1.2 MessagePack Java API介绍 略\n7.2 MessagePack编码器和解码器开发 Netty的编解码框架可以非常方便的继承第三方序列化框架。\n7.2.1 MessagePack编码器开发 package _7_2_1_; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.MessageToByteEncoder; import org.msgpack.MessagePack; import java.util.List; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 14:05 */ public class MsgpackEncoder extends MessageToByteEncoder\u0026lt;Object\u0026gt; { @Override protected void encode(ChannelHandlerContext atg0, Object arg1, ByteBuf arg2) throws Exception { MessagePack msgpack = new MessagePack(); byte[] raw = msgpack.write(arg1); arg2.writeBytes(raw); } } MsgpackEncoder继承MessageToByteEncoder，负责将Object类型的POJO对象编码为byte数组，然后写入到ByteBuf中。\n7.2.2 MessagePack解码器开发 package _7_2_1_; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.MessageToMessageDecoder; import org.msgpack.MessagePack; import java.util.List; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/19 14:39 */ public class MsgpackDecoder extends MessageToMessageDecoder\u0026lt;ByteBuf\u0026gt; { @Override protected void decode(ChannelHandlerContext arg0, ByteBuf arg1, List\u0026lt;Object\u0026gt; arg2) throws Exception { final byte[] array; final int length = arg1.readableBytes(); array = new byte[length]; arg1.getBytes(arg1.readerIndex(), array, 0, length); MessagePack msgpack = new MessagePack(); arg2.add(msgpack.read(array));//解码 } } 7.2.3 功能测试 暂未通过；\n第8章 Google Protobuf编解码 略\n第9章 JBoss Marshalling编解码 第10章 HTTP协议开发应用 HTTP是一个属于应用层的面向对象的协议。Netty的HTTP协议也是异步非阻塞的。\n10.1 HTTP协议介绍 主要特点：\n支持C/S模式； 简单——客户端向服务端请求服务，秩序指定服务URL，携带必要的请求参数或消息体； 灵活——HTTP允许传输任意类型的数据对象，传输的内容类型由HTTP消息头中的Content-Type加以标记； 无状态——对事务处理没有记忆能力。 10.1.1 HTTP协议的URL http://host[\u0026#34;:\u0026#34;port][abs_path] 详细介绍不赘述。\n10.1.2 HTTP请求消息（HttpRequest） 三部分：\nHTTP请求行； HTTP消息头； HTTP请求正文。 GET和POST的区别：\n（1）根据HTTP规范，GET用于信息获取，应该是安全的和幂等的；POST则表示可能改变服务器上的资源的请求。\n（2）GET提交，请求的数据会附在URL之后，就是把数据放置在请求行中，以“?”分隔URL和传输数据，多个参数用“\u0026amp;”连接；而POST提交会把提交的数据放置再HTTP消息的包体中，数据不会在地址栏中显示出来。\n（3）传输数据的大小不同，GET受具体浏览器长度的限制。POST理论上长度不受限制。\n（4）安全性。\n10.1.3 HTTP响应消息（HttpResponse） 三部分：\n状态行； 消息报头； 响应正文。 10.2 Netty HTTP服务端入门开发 相比于传统的Tomcat、Jetty等Web容器，它更加轻量和小巧，灵活性和定制性也更好。\n10.2.1 HTTP服务端例程场景描述 例程场景如下：文件服务器使用HTTP协议对外提供服务，当客户端通过浏览器访问文件服务器时，对访问路径进行检查，检查失败时返回HTTP403错误，该页无法访问；如果校验通过，以连接的方式打开当前文件目录，每个目录或者文件都是个超链接，可以递归访问。\n如果是目录，可以继续递归访问它下面的子目录或者文件，如果时文件且可读，则可以在浏览器端直接打开，或者通过【目标另存为】下载该文件。\n10.2.2 HTTP服务端开发 package HTTP; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.http.HttpObjectAggregator; import io.netty.handler.codec.http.HttpRequestDecoder; import io.netty.handler.codec.http.HttpResponseEncoder; import io.netty.handler.stream.ChunkedWriteHandler; import java.net.InetAddress; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/21 10:44 */ public class HttpFileServer { private static final String DEFAULT_URL = \u0026#34;/src\u0026#34;; public void run(final int port, final String url) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(\u0026#34;http-decoder\u0026#34;, new HttpRequestDecoder());//向ChannelPipeLine中添加HTTP请求消息解码器 ch.pipeline().addLast(\u0026#34;http-aggregator\u0026#34;, new HttpObjectAggregator(65536));//添加HttpObjectAggregator解码器 ch.pipeline().addLast(\u0026#34;http-encoder\u0026#34;, new HttpResponseEncoder());//HTTP响应编码器 ch.pipeline().addLast(\u0026#34;http-chunked\u0026#34;, new ChunkedWriteHandler());//支持异步发送大的码流（例如大文件传输，但不占用过多内存，防止Java内存溢出错误） ch.pipeline().addLast(\u0026#34;fileServerHandler\u0026#34;, new HttpFileServerHandler(url));// } }); ChannelFuture f = b.bind(InetAddress.getLocalHost().getHostAddress(), port).sync(); System.out.println(\u0026#34;Http文件目录服务器启动，网址是：\u0026#34; + InetAddress.getLocalHost().getHostAddress() +\u0026#34;:\u0026#34; + port + url); f.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception{ int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } String url = DEFAULT_URL; if (args.length \u0026gt; 1) url = args[1]; new HttpFileServer().run(port, url); } } package HTTP; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.*; import io.netty.handler.codec.http.*; import io.netty.handler.stream.ChunkedFile; import javax.activation.MimetypesFileTypeMap; import java.io.File; import java.io.FileNotFoundException; import java.io.RandomAccessFile; import java.io.UnsupportedEncodingException; import java.net.URLDecoder; import java.util.regex.Pattern; import static io.netty.handler.codec.http.HttpHeaders.Names.*; import static io.netty.handler.codec.http.HttpHeaders.isKeepAlive; import static io.netty.handler.codec.http.HttpHeaders.setContentLength; import static io.netty.handler.codec.http.HttpMethod.GET; import static io.netty.handler.codec.http.HttpResponseStatus.*; import static io.netty.handler.codec.http.HttpVersion.HTTP_1_1; import static io.netty.util.CharsetUtil.UTF_8; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/21 11:02 */ public class HttpFileServerHandler extends SimpleChannelInboundHandler\u0026lt;FullHttpRequest\u0026gt; { private final String url; public HttpFileServerHandler(String url) { this.url = url; } @Override protected void messageReceived(ChannelHandlerContext ctx, FullHttpRequest request) throws Exception { //对Http请求消息的解码结果进行判断，如果解码失败，直接构造HTTP400错误返回。 if (!request.getDecoderResult().isSuccess()) { sendError(ctx, BAD_REQUEST); return; } //对请求行中的方法进行判断，如果不是从浏览器或者表单设置为GET发起的请求（例如POST），则构造HTTP405错误返回。 if (request.getMethod() != GET) { sendError(ctx, METHOD_NOT_ALLOWED); return; } final String uri = request.getUri(); //对URL进行包装 final String path = sanitizeUri(uri); //如果构造的URI不合法，则返回403错误 if (path == null) { sendError(ctx, FORBIDDEN); return; } //使用新组装的URI路径构造File对象。 File file = new File(path); //如果文件不存在或是系统隐藏文件，则构造Http404异常返回 if (file.isHidden() || !file.exists()) { sendError(ctx, NOT_FOUND); return; } //如果文件是目录，则发送目录的链接给客户端连接 if (file.isDirectory()) { if (uri.endsWith(\u0026#34;/\u0026#34;)) { sendListing(ctx, file); } else { sendRedirect(ctx, uri + \u0026#34;/\u0026#34;); } return; } //点击或下载文件，校验文件合法性。 if (!file.isFile()) { sendError(ctx, FORBIDDEN); return; } //使用随机文件读写类以制度的方式打开文件，如果文件打开失败，则返回404错误。 RandomAccessFile randomAccessFile = null; try { randomAccessFile = new RandomAccessFile(file, \u0026#34;r\u0026#34;);//以只读方式打开文件 } catch (FileNotFoundException fnfe) { sendError(ctx, NOT_FOUND); return; } //获取文件的长度，构造成功的Http应答信息 long fileLength = randomAccessFile.length(); HttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, OK); setContentLength(response, fileLength); setContentTypeHeader(response, file); //判断连接是否KeepAlive，如果是，则设置 if (isKeepAlive(request)) { response.headers().set(CONNECTION, HttpHeaders.Values.KEEP_ALIVE); } ctx.write(response); ChannelFuture sendFileFuture; //通过Netty的ChunkedFile对象直接将文件写入到发送缓冲区。 sendFileFuture = ctx.write(new ChunkedFile(randomAccessFile, 0, fileLength, 8192), ctx.newProgressivePromise()); sendFileFuture.addListener(new ChannelProgressiveFutureListener() { @Override public void operationProgressed(ChannelProgressiveFuture future, long progress, long total) throws Exception { if (total \u0026lt; 0) System.err.println(\u0026#34;传输出错：\u0026#34; + progress); else System.err.println(\u0026#34;传输进度：\u0026#34; + progress+\u0026#34;/\u0026#34;+total); } @Override public void operationComplete(ChannelProgressiveFuture future) throws Exception { System.out.println(\u0026#34;传输完成。\u0026#34;); } }); //使用chunked编码，最后需要发送一个编码结束的空消息体，将LastHttpContent.EMPTY_LAST_CONTENT发送到缓冲区，标识所有消息体都发送完成。 ChannelFuture lastContentFuture = ctx.writeAndFlush(LastHttpContent.EMPTY_LAST_CONTENT); if (!isKeepAlive(request)) { lastContentFuture.addListener(ChannelFutureListener.CLOSE); } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); if (ctx.channel().isActive()) { sendError(ctx, INTERNAL_SERVER_ERROR); } } private static final Pattern INSECURE_URI = Pattern.compile(\u0026#34;.*[\u0026lt;\u0026gt;\u0026amp;\\\u0026#34;].*\u0026#34;); private String sanitizeUri(String uri) { try { //使用java.net.URLDecoder对URL进行解码，使用UTF-8字符集。 uri = URLDecoder.decode(uri, \u0026#34;UTF-8\u0026#34;); } catch (UnsupportedEncodingException e) { try { uri = URLDecoder.decode(uri, \u0026#34;ISO-8859-1\u0026#34;); } catch (UnsupportedEncodingException ex) { throw new Error(); } } //对URI进行合法性判断，如果URI与允许访问的URI一致或者是其子目录（文件），则校验通过，否则返回空。 if (!uri.startsWith(url)) return null; if (!uri.startsWith(\u0026#34;/\u0026#34;)) return null; //将硬编码的文件路径替换为本地操作系统的文件路径分隔符。 uri = uri.replace(\u0026#39;/\u0026#39;, File.separatorChar); //对新的URI进行二次合法性校验。 if(uri.contains(File.separator + \u0026#39;.\u0026#39;) || uri.contains(\u0026#39;.\u0026#39; + File.separator) || uri.startsWith(\u0026#34;.\u0026#34;) || uri.endsWith(\u0026#34;.\u0026#34;) || INSECURE_URI.matcher(uri).matches()){ return null; } //校验完成，使用当前运行程序所在的工作目录+URI构造绝对路径返回。 return System.getProperty(\u0026#34;user.dir\u0026#34;) + File.separator + uri; } private static final Pattern ALLOWED_FILE_NAME = Pattern.compile(\u0026#34;[A-Za-z0-9][-_A-Za-z0-9\\\\.]*\u0026#34;); private void sendListing(ChannelHandlerContext ctx, File dir) { //创建成功的Http响应消息，并设置消息头 FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, OK); response.headers().set(CONTENT_TYPE, \u0026#34;text/html;charset=UTF-8\u0026#34;); //消息体 String dirPath = dir.getPath(); StringBuilder buf = new StringBuilder(); buf.append(\u0026#34;\u0026lt;!DOCTYPE html\u0026gt;\\r\\n\u0026#34;); buf.append(\u0026#34;\u0026lt;html\u0026gt;\u0026lt;head\u0026gt;\u0026lt;title\u0026gt;\u0026#34;); buf.append(dirPath); buf.append(\u0026#34;目录:\u0026#34;); buf.append(\u0026#34;\u0026lt;/title\u0026gt;\u0026lt;/head\u0026gt;\u0026lt;body\u0026gt;\\r\\n\u0026#34;); buf.append(\u0026#34;\u0026lt;h3\u0026gt;\u0026#34;); buf.append(dirPath).append(\u0026#34; 目录：\u0026#34;); buf.append(\u0026#34;\u0026lt;/h3\u0026gt;\\r\\n\u0026#34;); buf.append(\u0026#34;\u0026lt;ul\u0026gt;\u0026#34;); buf.append(\u0026#34;\u0026lt;li\u0026gt;链接：\u0026lt;a href=\\\u0026#34; ../\\\u0026#34;\u0026gt;..\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\\r\\n\u0026#34;); //展示所有文件和文件夹，同时使用超链接来标识 for (File f : dir.listFiles()) { if(f.isHidden() || !f.canRead()) { continue; } String name = f.getName(); if (!ALLOWED_FILE_NAME.matcher(name).matches()) { continue; } buf.append(\u0026#34;\u0026lt;li\u0026gt;链接：\u0026lt;a href=\\\u0026#34;\u0026#34;); buf.append(name); buf.append(\u0026#34;\\\u0026#34;\u0026gt;\u0026#34;); buf.append(name); buf.append(\u0026#34;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\\r\\n\u0026#34;); } buf.append(\u0026#34;\u0026lt;/ul\u0026gt;\u0026lt;/body\u0026gt;\u0026lt;/html\u0026gt;\\r\\n\u0026#34;); //分配对应消息的缓冲对象。 ByteBuf buffer = Unpooled.copiedBuffer(buf, UTF_8); //将缓冲区中的响应消息存放到Http应答消息中，然后释放缓冲区 response.content().writeBytes(buffer); buffer.release(); ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE); } private void sendRedirect(ChannelHandlerContext ctx, String newUri) { FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, FOUND); response.headers().set(LOCATION,newUri); ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE); } private void sendError(ChannelHandlerContext ctx, HttpResponseStatus status) { FullHttpResponse response = new DefaultFullHttpResponse(HTTP_1_1, status, Unpooled.copiedBuffer(\u0026#34;Failure: \u0026#34; + status.toString() + \u0026#34;\\r\\n\u0026#34;, UTF_8)); response.headers().set(CONTENT_TYPE, \u0026#34;text/html;charset=UTF-8\u0026#34;); ctx.writeAndFlush(response).addListener(ChannelFutureListener.CLOSE); } private void setContentTypeHeader(HttpResponse response, File file) { MimetypesFileTypeMap mimetypesFileTypeMap = new MimetypesFileTypeMap(); response.headers().set(CONTENT_TYPE, mimetypesFileTypeMap.getContentType(file.getPath())); } } 10.3 Netty HTTP+XML协议栈开发 由于HTTP协议的通用性，很多异构系统间的通信交互采用HTTP协议，通过HTTP协议承载业务数据进行消息交互。例如非常流行的HTTP+XML或者Restful+JSON。\n很多基于HTTP的应用都是后台应用，HTTP仅仅是承载数据交换的一个通道，是一个载体而不是Web容器。所以在这种场景下，一般不需要Tomcat这样的重量行Web容器。\n且Tomcat会有很多安全漏洞。所以一个轻量级的HTTP协议栈是个更好的选择。\n10.3.1 开发场景介绍 模拟一个简单的用户订购系统。客户端填写订单，通过HTTP客户端向服务端发送订购请求，请求消息放在HTTP消息体中，以XML承载，即采用HTTP+XML的方式进行通信。\n双方采用HTTP1.1协议，连接类型为CLOSE方式，即双方交互完成，由HTTP服务端主动关闭链路，随后客户端也关闭链路并退出。\n订购请求消息定义如表所示：\n字段名称 类型 备注 订购数量 Int64 订购的商品数量 客户信息 Customer 客户信息，负责POJO对象 账单地址 Address 账单的地址 寄送方式 Shippling 枚举类型如下：普通快递宅急送国际配送国内快递国际快递 送货地址 Address 总价 float 客户信息定义：\n字段名称 类型 备注 客户ID Int64 客户ID，厂整型 姓 String 客户姓氏，字符串 名 String 客户名字，字符串 全名 List\u0026lt;String\u0026gt; 客户全程，字符列表 地址信息定义：\n字段名称 类型 备注 街道1 String 街道2 String 城市 String 省份 String 邮政编码 String 国家 String 邮递方式定义：\n字段名称 类型 备注 普通邮递 枚举类型 宅急送 枚举类型 国际邮递 枚举类型 国内快递 枚举类型 国际快递 枚举类型 10.3.2 HTTP+XML协议栈设计 步骤：\n构造订购请求消息，将请求消息编码为HTTP+XML格式； HTTP客户端发起连接，通过HTTP协议栈发送HTTP请求消息； HTTP服务端对HTTP+XML请求消息进行解码，解码成请求POJO； 服务端构造应答消息并编码，通过HTTP+XML方式返回给客户端； 客户端对HTTP+XML响应消息进行解码，解码成响应POJO。 流程分析：\n步骤1，需要自定义HTTP+XML格式的请求消息编码器；\n步骤2，可重用Netty的能力；\n步骤3，Netty可解析HTTP请求消息，但是消息体为XML，Netty无法将其解码为POJO，需要在Netty协议栈的基础上扩展实现。\n步骤4，需定制将POJO以XML方式发送\n步骤5，需定制解码。\n设计思路：\n（1）需要一套通用、高性能的XML序列化框架，它能够灵活的实现POJO-XML的互相转换，最好能够通过工具自动生成绑定关系，或者通过XML的方式配置双方的映射关系；\n（2）作为通用的HTTP+XML协议栈，XML-POJO的映射关系应该非常灵活，支持命名空间和自定义标签。\n（3）一系列HTTP+XML消息编解码器\n（4）编解码过程应该对协议栈使用者透明，对上层业务零侵入。\n10.3.3 高效的XML绑定框架JiBx JiBX入门 专门为Java语言设计的XML数据绑定框架JiBx。\n优点：转换效率高、配置绑定文件简单、不需要操作xpath文件、不需要写输行的get/set方法、对象属性名与XML文件element名可以不同等。\n绑定XML与Java对象的两个步骤：第一步是绑定XML文件，也就是映射XML文件与Java对象之间的对应关系；第二步是在运行时，实现XML文件与Java势力之间的互相转换。\n在运行程序之前，需要先配置绑定文件并进行绑定，在绑定过沉重它将会动态地修改程序中相应地class文件，主要是生成对应对象实例地方法和添加呗绑定标记地输行JiBX_bindingList等。它使用的技术是BCEL(Byte Code Engineering Library)，BCEL是Apache Software Foundation的Jakarta项目的一部分，也是目前Java classworking最广泛使用的一种框架，它可以让你深入JVM汇编语言进行类操作。在JiBX运行时，它使用了目前比较流行的一个技术XPP（Xml Pull Parsing），这也是JiBX如此高效的原因。\nXPP：将整个文档写入内存，然后进行DOM操作，也不是使用基于事件流的SAX。XPP使用饿是不断增加的数据流处理方式，同时允许在解析XML文件时中断。\n因书上的项目为Ant打包，与我使用的Maven有冲突，所以开发过程略。\n第11章 WebSocket协议开发 WebSocket解决的问题：由于HTTP协议的开销，导致它们不合适低延迟应用。\nWebSocket将网络套接字引入到了客户端和服务端，浏览器和服务器之间可以通过套接字建立持久的连接，双方随时都可以互发数据给对方，而不是之前由客户端控制的一请求一应答模式。\n11.1 HTTP协议的弊端 主要弊端如下：\n（1）HTTP协议为半双工。可以双向但不能同时。\n（2）HTTP消息冗长而繁琐。HTTP消息包含消息头、消息体、换行符等。通常以文本传输，相比于其他二进制通信协议，冗长而繁琐。\n（3）针对服务器推送的黑客攻击。例如长时间轮询。\n11.2 WebSocket入门 H5提供的一种浏览器与服务器间进行全双工通信的网络技术。\n在WebSocketAPI中，浏览器和服务器只需要一个握手的动作，然后浏览器和服务器直接就形成了一条快速通道，两者就可以直接互相传送数据了。基于TCP双向全双工进行消息传递。\nWebSocket的特点：\n单一的TCP连接，采用全双工模式通信； 对代理、防火墙和路由器透明； 无头部信息、Cookie和身份验证； 无安全开销； 通过“ping/pong”帧保持链路激活； 服务器可以主动传递消息给客户端，不再需要客户端轮询。 11.2.1 WebSocket背景 取代轮询和Comet技术，是客户端浏览器具备像C/S架构下桌面系统一样的实时通信能力。\n在流量和负载增大的情况下，WebSocket方案相比传统的AJAX轮询方案有极大的性能优势。\n11.2.2 WebSocket连接建立 发送一个HTTP请求，与平常的不同，包含一些附加头信息。\n返回的也包含附加信息。\n11.2.3 WebSocket生命周期 握手成功后，就能通过“messages”的方式进行通信了。一个消息由一个或多个帧组成。可以被分割成多个帧或者被合并。\n11.2.4 WebSocket连接关闭 为关闭WebSocket连接，客户端与服务端需要通过一个安全的方法关闭底层TCP连接以及TLS会话。如果合适，丢弃任何可能已经接收的字节，必要时（比如受到攻击）可以通过任何可用的手段关闭连接。\n底层的TCP连接，在正常情况下，应该首先由服务器关闭。在异常情况下（例如在一个合理的时间周期后没有接收到服务器的TCP Close），客户端可以发起TCP Close。因此，当服务器被指示关闭WebSocket连接时，它应该立即发起一个TCP Close操作；客户端应该等待服务器的TCP Close。\nWebSocket的握手关闭消息带有一个状态码和一个可选的关闭原因，它必须按照协议要求发送一个Close控制帧，当对端接收到关闭控制帧指令时，需要主动关闭WebSocket连接。\n11.3 Netty WebSocket协议开发 11.3.1 WebSocket服务端功能介绍 支持WebSocket的浏览器通过WebSocket协议发送请求消息给服务端，服务端对请求消息进行判断，如果时合法的WebSocket请求，则获取请求消息体（文本），并在后面追加字符串“欢迎使用Netty WebSocket服务，现在时刻：系统时间”。\n客户端HTML通过内嵌的JS脚本创建WebSocket连接，如果握手成功，在文本框中打印“打开WebSocket服务正常。浏览器支持WebSocket！”。\n11.3.2 WebSocket服务端开发 package WebSocket.server; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.Channel; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelPipeline; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.codec.http.HttpObjectAggregator; import io.netty.handler.codec.http.HttpServerCodec; import io.netty.handler.stream.ChunkedWriteHandler; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/23 13:12 */ public class WebSocketServer { public void run(int port) throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ChannelPipeline pipeline = ch.pipeline(); pipeline.addLast(\u0026#34;http-codec\u0026#34;, new HttpServerCodec());//添加HttpServerCodec，将请求和应答消息编码或者解码为HTTP消息； pipeline.addLast(\u0026#34;aggregator\u0026#34;, new HttpObjectAggregator(65536));//添加HttpObjectAggregator，将HTTP消息的多个部分组合成一条完整的HTTP消息 ch.pipeline().addLast(\u0026#34;http-chunked\u0026#34;, new ChunkedWriteHandler());//向客户端发送H5文件，主要用于支持浏览器和服务端进行WebSocket通信 pipeline.addLast(\u0026#34;handler\u0026#34;, new WebSocketServerHandler()); } }); Channel ch = b.bind(port).sync().channel(); System.out.println(\u0026#34;Websocket服务器启动，端口：\u0026#34; + port + \u0026#39;。\u0026#39;); System.out.println(\u0026#34;浏览器访问\u0026#34;+\u0026#34;http://localhost:\u0026#34;+ port + \u0026#39;/\u0026#39;); ch.closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } public static void main(String[] args) throws Exception { int port = 8080; if (args.length \u0026gt; 0 ) { try { port = Integer.parseInt(args[0]); } catch (Exception e) { e.printStackTrace(); } } new WebSocketServer().run(port); } } package WebSocket.server; import io.netty.buffer.ByteBuf; import io.netty.buffer.Unpooled; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelFutureListener; import io.netty.channel.ChannelHandlerContext; import io.netty.channel.SimpleChannelInboundHandler; import io.netty.handler.codec.http.DefaultFullHttpResponse; import io.netty.handler.codec.http.FullHttpRequest; import io.netty.handler.codec.http.websocketx.*; import java.util.logging.Level; import java.util.logging.Logger; import static io.netty.handler.codec.http.HttpHeaders.isKeepAlive; import static io.netty.handler.codec.http.HttpHeaders.setContentLength; import static io.netty.handler.codec.http.HttpResponseStatus.BAD_REQUEST; import static io.netty.handler.codec.http.HttpVersion.HTTP_1_1; import static io.netty.util.CharsetUtil.UTF_8; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/23 13:33 */ public class WebSocketServerHandler extends SimpleChannelInboundHandler\u0026lt;Object\u0026gt; { private static final Logger logger = Logger.getLogger(WebSocketServerHandler.class.getName()); private WebSocketServerHandshaker handshaker; @Override protected void messageReceived(ChannelHandlerContext ctx, Object msg) throws Exception { if (msg instanceof FullHttpRequest) {//握手请求 handleHttpRequest(ctx, (FullHttpRequest) msg); } else if (msg instanceof WebSocketFrame) { handleWebSocketFrame(ctx, (WebSocketFrame) msg); } } private void handleHttpRequest(ChannelHandlerContext ctx, FullHttpRequest req) { if (!req.getDecoderResult().isSuccess() || (!\u0026#34;websocket\u0026#34;.equals(req.headers().get(\u0026#34;Upgrade\u0026#34;)))) { sendHttpResponse(ctx, req, new DefaultFullHttpResponse(HTTP_1_1, BAD_REQUEST));//如果不是握手请求就返回400； return; } //构造握手工厂 WebSocketServerHandshakerFactory wsFactory = new WebSocketServerHandshakerFactory(\u0026#34;ws://localhost:8080/socket\u0026#34;, null, false); //握手处理类 handshaker = wsFactory.newHandshaker(req); if (handshaker == null) { WebSocketServerHandshakerFactory.sendUnsupportedWebSocketVersionResponse(ctx.channel()); } else { handshaker.handshake(ctx.channel(), req); } } private void sendHttpResponse(ChannelHandlerContext ctx, FullHttpRequest req, DefaultFullHttpResponse resp) { if (resp.getStatus().code() != 200) { ByteBuf buf = Unpooled.copiedBuffer(resp.getStatus().toString(), UTF_8); resp.content().writeBytes(buf); buf.release(); setContentLength(resp, resp.content().readableBytes()); } ChannelFuture f =ctx.channel().writeAndFlush(resp); if (!isKeepAlive(req) || resp.getStatus().code() != 200) { f.addListener(ChannelFutureListener.CLOSE); } } private void handleWebSocketFrame(ChannelHandlerContext ctx, WebSocketFrame frame) { if (frame instanceof CloseWebSocketFrame) { handshaker.close(ctx.channel(), ((CloseWebSocketFrame) frame).retain()); return; } if (frame instanceof PingWebSocketFrame) { ctx.channel().write(new PongWebSocketFrame(frame.content().retain())); return; } if (!(frame instanceof TextWebSocketFrame)) { throw new UnsupportedOperationException(String.format(\u0026#34;%s frame types not supported\u0026#34;, frame.getClass().getName())); } String request = ((TextWebSocketFrame) frame).text(); logger.info(request); if (logger.isLoggable(Level.FINE)) { logger.fine(String.format(\u0026#34;%s received %s\u0026#34;, ctx.channel(), request)); } ctx.channel().write( new TextWebSocketFrame(request + \u0026#34; , 欢迎使用Netty WebSocket服务，现在时刻：\u0026#34; + new java.util.Date().toString())); } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { ctx.flush(); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); ctx.close(); } } WebSocket本身非常复杂，可以通过多种形式（文本方式，二进制方式）承载信息。\n第12章 私有协议栈开发 私有协议灵活，在公司内部或组织内部使用。\n绝大多数私有协议传输层采用TCP/IP。\n12.1 私有协议介绍 除非授权，不然其他厂商无法使用。私有协议也称非标准协议。\n传统的Java应用中，通常使用以下4中方式进行跨节点通信：\n（1）通过RMI进行远程服务调用；\n（2）通过Java的Socket+Java序列化的方式进行跨节点调用；\n（3）利用一些开源的RPC框架进行远程服务嗲用，如Facebook的Thrift、Apache的Avro等；\n（4）利用标准的公有协议进行跨节点调用，例如HTTP+XML、RESTful+JSON或者WebService。\n私有协议：链路层的物理连接，对请求和响应消息进行编码，在请求和应答消息本身以外，也需要携带一些其他控制和管理类指令，例如链路建立的握手请求和响应消息、链路检测的心跳消息等。\n并没有标准的定义，只要能够用于跨进程、跨主机数据交换的非标准协议，都可以称为私有协议。\n12.2 Netty协议栈功能设计 用于内部各模块之间的通信， 它基于TCP/IP协议栈，是一个类HTTP协议的应用层协议栈。\n12.1.1 网络拓扑图 无固定客户端，服务端。谁发起谁就是客户端，接收时服务端。\n12.2.2 协议栈功能描述 （1）基于Netty的NIO通信框架，提供高性能饿异步通信能力；\n（2）提供消息的编解码框架，可以实现POJO的序列化和反序列化；\n（3）提供基于IP地址的白名单接入认证机制；\n（4）链路的有效性检验机制；\n（5）链路的断连重连机制。\n12.2.3 通信模型 具体步骤：\n（1）Netty协议栈客户端发送握手请求消息，携带节点ID等有效身份认证信息；\n（2）Netty协议栈服务端对握手请求消息进行合法性校验，包括节点ID有效性校验、节点重复登录校验和IP地址合法性校验，校验通过后，返回登录成功的握手应答消息；\n（3）链路建立成功之后，客户端发送业务；\n（4）链路成功之后，服务端发送心跳信息；\n（5）链路建立成功之后，客户端法统心跳信息；\n（6）链路建立成功之后，服务端发送业务消息；\n（7）服务端退出时，服务端关闭连接，客户端感知对方关闭连接后，被动关闭客户端连接。\n12.2.4 消息定义 两部分：\n消息头； 消息体。 协议详细描述部分不赘述，因为是私有协议，内容不重要，开发过程才是重点，之后看Dubbo在着重看协议内容。\n12.3 Netty协议栈开发 12.3.1 数据结构定义 package PrivateProtocol.struct; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/23 14:49 */ public class NettyMessage { private Header header;//消息头 private Object body;//消息体 public Header getHeader() { return header; } public void setHeader(Header header) { this.header = header; } public Object getBody() { return body; } public void setBody(Object body) { this.body = body; } @Override public String toString() { return \u0026#34;NettyMessage{\u0026#34; + \u0026#34;header=\u0026#34; + header + \u0026#34;, body=\u0026#34; + body + \u0026#39;}\u0026#39;; } } package PrivateProtocol.struct; import java.util.HashMap; import java.util.Map; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/23 14:50 */ public class Header { private int crcCode = 0xabef0101; private int length;//消息长度 private long sessionID;//会话ID private byte type;//消息类型 private byte priority;//消息优先级 private Map\u0026lt;String, Object\u0026gt; attachment = new HashMap\u0026lt;String, Object\u0026gt;();//附件 public int getCrcCode() { return crcCode; } public void setCrcCode(int crcCode) { this.crcCode = crcCode; } public int getLength() { return length; } public void setLength(int length) { this.length = length; } public long getSessionID() { return sessionID; } public void setSessionID(long sessionID) { this.sessionID = sessionID; } public byte getType() { return type; } public void setType(byte type) { this.type = type; } public byte getPriority() { return priority; } public void setPriority(byte priority) { this.priority = priority; } public Map\u0026lt;String, Object\u0026gt; getAttachment() { return attachment; } public void setAttachment(Map\u0026lt;String, Object\u0026gt; attachment) { this.attachment = attachment; } @Override public String toString() { return \u0026#34;Header{\u0026#34; + \u0026#34;crcCode=\u0026#34; + crcCode + \u0026#34;, length=\u0026#34; + length + \u0026#34;, sessionID=\u0026#34; + sessionID + \u0026#34;, type=\u0026#34; + type + \u0026#34;, priority=\u0026#34; + priority + \u0026#34;, attachment=\u0026#34; + attachment + \u0026#39;}\u0026#39;; } } 由于心跳消息、握手请求和握手应答消息都可以统一由NettyMessage承载，所以不需要为这几类控制消息做单独的数据结构定义。\n12.3.2 消息编解码 package PrivateProtocol.codec; import PrivateProtocol.struct.NettyMessage; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.MessageToByteEncoder; import java.io.IOException; import java.util.Map; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/23 14:59 */ public class NettyMessageEncoder extends MessageToByteEncoder\u0026lt;NettyMessage\u0026gt; { MarshallingEncoder marshallingEncoder; public NettyMessageEncoder() throws IOException{ this.marshallingEncoder = new MarshallingEncoder(); } @Override protected void encode(ChannelHandlerContext ctx, NettyMessage msg, ByteBuf sendBuf) throws Exception { if (msg == null || msg.getHeader() == null) { throw new Exception(\u0026#34;The encode message is null\u0026#34;); } sendBuf.writeInt(msg.getHeader().getCrcCode()); sendBuf.writeInt(msg.getHeader().getLength()); sendBuf.writeLong(msg.getHeader().getSessionID()); sendBuf.writeByte(msg.getHeader().getType()); sendBuf.writeByte(msg.getHeader().getPriority()); sendBuf.writeInt(msg.getHeader().getAttachment().size()); String key = null; byte[] keyArray = null; Object value = null; for (Map.Entry\u0026lt;String, Object\u0026gt; param : msg.getHeader().getAttachment().entrySet()) { key = param.getKey(); keyArray = key.getBytes(\u0026#34;UTF-8\u0026#34;); sendBuf.writeInt(keyArray.length); sendBuf.writeBytes(keyArray); value = param.getValue(); marshallingEncoder.encode(value, sendBuf); } key = null; keyArray = null; value = null; if (msg.getBody() != null) { marshallingEncoder.encode(msg.getBody(), sendBuf); } else sendBuf.writeInt(0); sendBuf.setInt(4, sendBuf.readableBytes() - 8); } } package PrivateProtocol.codec; import io.netty.buffer.ByteBuf; import org.jboss.marshalling.Marshaller; import java.io.IOException; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/23 15:06 */ public class MarshallingEncoder { private static final byte[] LENGTH_PLACEHOLDER = new byte[4]; Marshaller marshaller; public MarshallingEncoder() throws IOException { marshaller = MarshallingCodecFactory.buildMarshalling(); } public void encode(Object msg, ByteBuf out) throws IOException { try { int lengthPos = out.writerIndex(); out.writeBytes(LENGTH_PLACEHOLDER); ChannelBufferByteOutput output = new ChannelBufferByteOutput(out); marshaller.start(output); marshaller.writeObject(msg); marshaller.finish(); out.setInt(lengthPos, out.writerIndex() - lengthPos - 4); } finally { marshaller.close(); } } } package PrivateProtocol.codec; import PrivateProtocol.struct.Header; import PrivateProtocol.struct.NettyMessage; import io.netty.buffer.ByteBuf; import io.netty.channel.ChannelHandlerContext; import io.netty.handler.codec.LengthFieldBasedFrameDecoder; import java.io.IOException; import java.nio.ByteOrder; import java.util.HashMap; import java.util.Map; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/23 15:36 */ /* *Netty的LengthFieldBasedFrameDecoder解码器，它支持自动的TCP粘包和半包处理， *只需要给出标识消息长度饿字段偏移量和消息长度自身所占的字节数，Netty就能自动实现对半包的处理。 */ public class NettyMessageDecoder extends LengthFieldBasedFrameDecoder { MarshallingDecoder marshallingDecoder; public NettyMessageDecoder(int maxFrameLength, int lengthFieldOffset, int lengthFieldLength) throws IOException { super(maxFrameLength, lengthFieldOffset, lengthFieldLength); marshallingDecoder = new MarshallingDecoder(); } @Override protected Object decode(ChannelHandlerContext ctx, ByteBuf in) throws Exception { ByteBuf frame = (ByteBuf) super.decode(ctx, in); if (frame == null) { return null; } NettyMessage message = new NettyMessage(); Header header = new Header(); header.setCrcCode(frame.readInt()); header.setLength(frame.readInt()); header.setSessionID(frame.readLong()); header.setType(frame.readByte()); header.setPriority(frame.readByte()); int size = frame.readInt(); if (size \u0026gt; 0) { Map\u0026lt;String, Object\u0026gt; attch = new HashMap\u0026lt;String, Object\u0026gt;(size); int keySize = 0; byte[] keyArray = null; String key = null; for (int i = 0; i \u0026lt; size; i++) { keySize = frame.readInt(); keyArray = new byte[keySize]; frame.readBytes(keyArray); key = new String(keyArray, \u0026#34;UTF-8\u0026#34;); attch.put(key, marshallingDecoder.decode(frame)); } keyArray = null; key = null; header.setAttachment(attch); } if (frame.readableBytes() \u0026gt; 4) { message.setBody(marshallingDecoder.decode(frame)); } message.setHeader(header); return message; } } package PrivateProtocol.codec; import io.netty.buffer.ByteBuf; import org.jboss.marshalling.ByteInput; import org.jboss.marshalling.Unmarshaller; import java.io.IOException; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/23 15:47 */ public class MarshallingDecoder { private final Unmarshaller unmarshaller; public MarshallingDecoder() throws IOException { unmarshaller = MarshallingCodecFactory.buildUnMarshalling(); } protected Object decode(ByteBuf in) throws Exception { int objectSize = in.readInt(); ByteBuf buf = in.slice(in.readerIndex(), objectSize); ByteInput input = new ChannelBufferByteInput(buf); try { unmarshaller.start(input); Object obj = unmarshaller.readObject(); unmarshaller.finish(); in.readerIndex(in.readerIndex() + objectSize); return obj; } finally { unmarshaller.close(); } } } 12.3.3 握手和安全验证 package PrivateProtocol.client; import PrivateProtocol.struct.Header; import PrivateProtocol.struct.NettyMessage; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; import java.awt.*; import static PrivateProtocol.common.MessageType.LOGIN_REQ; import static PrivateProtocol.common.MessageType.LOGIN_RESP; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/23 16:08 */ public class LoginAuthReqHandler extends ChannelHandlerAdapter { private static final Log LOG = LogFactory.getLog(LoginAuthReqHandler.class); //TCP连接三次握手成功之后又客户端构造握手请求消息发送给服务端，由于采用白名单认证机制，不需要携带消息体。 @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { ctx.writeAndFlush(buildLoginReq()); } //对我收应答消息进行处理 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { NettyMessage message = (NettyMessage) msg; if (message.getHeader() != null \u0026amp;\u0026amp; message.getHeader().getType() == LOGIN_RESP.value()) { byte loginResult = (byte) message.getBody(); //非0则认证失败，关闭链路 if (loginResult != (byte) 0) { ctx.close(); } else { LOG.info(\u0026#34;Login is ok：\u0026#34; + message); ctx.fireChannelRead(msg); } } else { //不是握手应答消息，传递给后面的ChannelHandler处理 ctx.fireChannelRead(msg); } } private NettyMessage buildLoginReq() { NettyMessage message = new NettyMessage(); Header header = new Header(); header.setType(LOGIN_REQ.value()); message.setHeader(header); return message; } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { ctx.fireExceptionCaught(cause); } } package PrivateProtocol.server; import PrivateProtocol.struct.Header; import PrivateProtocol.struct.NettyMessage; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; import java.net.InetAddress; import java.net.InetSocketAddress; import java.net.UnknownHostException; import java.util.Map; import java.util.concurrent.ConcurrentHashMap; import static PrivateProtocol.common.MessageType.LOGIN_REQ; import static PrivateProtocol.common.MessageType.LOGIN_RESP; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/23 15:56 */ public class LoginAuthRespHandler extends ChannelHandlerAdapter { public final static Log LOG = LogFactory.getLog(LoginAuthRespHandler.class); //重复登录保护 private Map\u0026lt;String, Boolean\u0026gt; nodeCheck = new ConcurrentHashMap\u0026lt;String, Boolean\u0026gt;(); //白名单 private String[] whitekList = {\u0026#34;127.0.0.1\u0026#34;, InetAddress.getLocalHost().getHostAddress()}; public LoginAuthRespHandler() throws UnknownHostException { } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { NettyMessage message = (NettyMessage) msg; if (message.getHeader() != null \u0026amp;\u0026amp; message.getHeader().getType() == LOGIN_REQ.value()) { String nodeIndex = ctx.channel().remoteAddress().toString(); NettyMessage loginResp = null; if (nodeCheck.containsKey(nodeIndex)) { loginResp = buildResponse((byte)-1); } else { InetSocketAddress address = (InetSocketAddress) ctx.channel().remoteAddress(); String ip = address.getAddress().getHostAddress(); boolean isOK = false; for (String WIP : whitekList) { if (WIP.equals(ip)) { isOK = true; break; } } loginResp = isOK ? buildResponse((byte)0) : buildResponse((byte)-1); if (isOK) { nodeCheck.put(nodeIndex, true); } LOG.info(\u0026#34;The login response is : \u0026#34; + loginResp + \u0026#34; body [\u0026#34; + loginResp.getBody() + \u0026#34;]\u0026#34;); ctx.writeAndFlush(loginResp); } } else { ctx.fireChannelRead(msg); } } private NettyMessage buildResponse(byte result) { NettyMessage message = new NettyMessage(); Header header = new Header(); header.setType(LOGIN_RESP.value()); message.setHeader(header); message.setBody(result); return message; } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); //出现异常时需要去注册，保证后续客户端可以重连成功 nodeCheck.remove(ctx.channel().remoteAddress().toString()); ctx.close(); ctx.fireExceptionCaught(cause); } } 12.3.4 心跳检测机制 package PrivateProtocol.client; import PrivateProtocol.struct.Header; import PrivateProtocol.struct.NettyMessage; import io.netty.channel.ChannelHandlerAdapter; import io.netty.channel.ChannelHandlerContext; import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; import java.util.concurrent.ScheduledFuture; import java.util.concurrent.TimeUnit; import static PrivateProtocol.common.MessageType.*; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/26 10:36 */ public class HeartBeatReqHandler extends ChannelHandlerAdapter { private static final Log LOG = LogFactory.getLog(HeartBeatReqHandler.class); private volatile ScheduledFuture\u0026lt;?\u0026gt; heartBeat; //握手成功后启动无限循环定时器用于定期发送心跳消息 @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { NettyMessage message = (NettyMessage) msg; if (message.getHeader() != null \u0026amp;\u0026amp; message.getHeader().getType() == LOGIN_RESP.value()) { //每5秒发送一条心跳消息 heartBeat = ctx.executor().scheduleAtFixedRate( new HeartBeatTask(ctx), 0, 5000, TimeUnit.MILLISECONDS ); //处理服务端发送的心跳应答消息 } else if (message.getHeader() != null \u0026amp;\u0026amp; message.getHeader().getType() == HEARTBEAT_RESP.value()) { LOG.info(\u0026#34;Client receive server heart beat message : ---\u0026gt; \u0026#34; + message); } else { ctx.fireChannelRead(msg); } } private class HeartBeatTask implements Runnable { private final ChannelHandlerContext ctx; private HeartBeatTask(ChannelHandlerContext ctx) { this.ctx = ctx; } @Override public void run() { NettyMessage heartBeat = buildHeartBeat(); LOG.info(\u0026#34;Client send heart beat messsage to server : ---\u0026gt; \u0026#34; + heartBeat); ctx.writeAndFlush(heartBeat); } private NettyMessage buildHeartBeat() { NettyMessage message = new NettyMessage(); Header header = new Header(); header.setType(HEARTBEAT_REQ.value()); message.setHeader(header); return message; } } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { cause.printStackTrace(); if (heartBeat != null) { heartBeat.cancel(true); heartBeat = null; } ctx.fireExceptionCaught(cause); } } package PrivateProtocol.server; import PrivateProtocol.struct.Header; import PrivateProtocol.struct.NettyMessage; import io.netty.channel.ChannelHandlerAppender; import io.netty.channel.ChannelHandlerContext; import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; import static PrivateProtocol.common.MessageType.HEARTBEAT_REQ; import static PrivateProtocol.common.MessageType.HEARTBEAT_RESP; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/26 10:55 */ public class HeartBeatRespHandler extends ChannelHandlerAppender { private static final Log LOG = LogFactory.getLog(HeartBeatRespHandler.class); @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { NettyMessage message = (NettyMessage) msg; if (message.getHeader() != null \u0026amp;\u0026amp; message.getHeader().getType() == HEARTBEAT_REQ.value()) { LOG.info(\u0026#34;Receive client heart beat message : ---\u0026gt; \u0026#34; + message); NettyMessage heartBeat = buildHeatBeat(); LOG.info(\u0026#34;Send heart beat response message to client : ---\u0026gt; \u0026#34; + heartBeat); ctx.writeAndFlush(heartBeat); } else { ctx.fireChannelRead(msg); } } private NettyMessage buildHeatBeat() { NettyMessage message = new NettyMessage(); Header header = new Header(); header.setType(HEARTBEAT_RESP.value()); message.setHeader(header); return message; } } 12.3.5 断线重连 package PrivateProtocol.client; import PrivateProtocol.codec.NettyMessageDecoder; import PrivateProtocol.codec.NettyMessageEncoder; import PrivateProtocol.common.NettyConstant; import io.netty.bootstrap.Bootstrap; import io.netty.channel.ChannelFuture; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioSocketChannel; import io.netty.handler.timeout.ReadTimeoutHandler; import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; import java.net.InetSocketAddress; import java.util.concurrent.Executors; import java.util.concurrent.ScheduledExecutorService; import java.util.concurrent.TimeUnit; import static PrivateProtocol.common.NettyConstant.*; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/26 11:04 */ public class NettyClient { private static final Log LOG = LogFactory.getLog(NettyClient.class); private ScheduledExecutorService executor = Executors.newScheduledThreadPool(1); EventLoopGroup group = new NioEventLoopGroup(); public void connect(int port, String host) throws Exception { try { Bootstrap b = new Bootstrap(); b.group(group) .channel(NioSocketChannel.class) .option(ChannelOption.TCP_NODELAY, true) .handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { //消息解码，并设置了最大长度上限 ch.pipeline().addLast(new NettyMessageDecoder(1024 * 1024, 4, 4)); //消息编码 ch.pipeline().addLast(\u0026#34;MessageEncoder\u0026#34;, new NettyMessageEncoder()); //读超时 ch.pipeline().addLast(\u0026#34;readTimeoutHandler\u0026#34;, new ReadTimeoutHandler(50)); //握手请求 ch.pipeline().addLast(\u0026#34;LoginAuthHandler\u0026#34;, new LoginAuthReqHandler()); //心跳消息 ch.pipeline().addLast(\u0026#34;HeartBeatHandler\u0026#34;, new HeartBeatReqHandler()); //类似于AOP但比AOP性能更高。 } }); //ChannelFuture f = b.connect(new InetSocketAddress(host, port), //new InetSocketAddress(LOCALIP, LOCAL_PORT)).sync(); ChannelFuture f = b.connect(\u0026#34;127.0.0.1\u0026#34;, 8080).sync(); f.channel().closeFuture().sync(); } finally { executor.execute(new Runnable() { @Override public void run() { try { TimeUnit.SECONDS.sleep(1); try { connect(PORT, REMOTEIP);//发起重连操作 } catch (Exception e) { e.printStackTrace(); } } catch (InterruptedException e) { e.printStackTrace(); } } }); } } public static void main(String[] args) throws Exception { new NettyClient().connect(PORT, REMOTEIP); } } package PrivateProtocol.server; import PrivateProtocol.codec.NettyMessageDecoder; import PrivateProtocol.codec.NettyMessageEncoder; import io.netty.bootstrap.ServerBootstrap; import io.netty.channel.ChannelInitializer; import io.netty.channel.ChannelOption; import io.netty.channel.EventLoopGroup; import io.netty.channel.nio.NioEventLoopGroup; import io.netty.channel.socket.SocketChannel; import io.netty.channel.socket.nio.NioServerSocketChannel; import io.netty.handler.logging.LogLevel; import io.netty.handler.logging.LoggingHandler; import io.netty.handler.timeout.ReadTimeoutHandler; import org.apache.commons.logging.Log; import org.apache.commons.logging.LogFactory; import static PrivateProtocol.common.NettyConstant.PORT; import static PrivateProtocol.common.NettyConstant.REMOTEIP; /** * \u0026lt;p\u0026gt;Description: xx\u0026lt;/p\u0026gt; * * @author 李宏博 * @version 1.0 * @create 2019/8/26 11:23 */ public class NettyServer { private static final Log LOG = LogFactory.getLog(NettyServer.class); public void bind() throws Exception { EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); ServerBootstrap b = new ServerBootstrap(); b.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 100) .handler(new LoggingHandler(LogLevel.INFO)) .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { ch.pipeline().addLast(new NettyMessageDecoder(1024 * 1024, 4, 4)); ch.pipeline().addLast(new NettyMessageEncoder()); ch.pipeline().addLast(new ReadTimeoutHandler(50)); ch.pipeline().addLast(new LoginAuthRespHandler()); ch.pipeline().addLast(new HeartBeatRespHandler()); } }); b.bind(REMOTEIP, PORT).sync(); LOG.info(\u0026#34;Netty server start ok : \u0026#34; + (REMOTEIP + \u0026#34; : \u0026#34; + PORT)); } public static void main(String[] args) throws Exception { new NettyServer().bind(); } } 12.5 总结 协议栈还有很多缺陷，比如断线后，发送的消息保存在哪里？\n之后的章节 源码就不记录了，详细看这个https://www.javadoop.com/post/netty-part-1\n","permalink":"https://haokiu.com/blog/e15796699f1a419ba85731d159eba322/","summary":"第1章 Java的I/O演进之路 1.1 I/O基础入门 1.1.1 Linux网络I/O模型简介 UNIX提供了5种I/O模型：\n（1）阻塞I/O模型\n（2）非阻塞I/O模型\n（3）I/O复用模型\n（4）信号驱动I/O模型\n（5）异步I/O\n1.1.2 I/O多路复用技术 把多个I/O阻塞复用到同一个select的阻塞上，从而是的系统在单线程的情况下可以同时处理多个客户端请求。比多线程有性能优势，节约资源。\n支持I/O多路复用的系统调用select/pselect/poll/epoll。\nepoll的优点：\n支持一个进程打开的socket描述符（FD）不受限制（仅受限于操作系统的最大文件句柄数（内存））。 I/O效率不会随着FD数目的增加而线性下降。 使用mmap加速内核与用户空间的消息传递。 epoll的API更加简单。 1.2 Java的I/O演进 历史题，略。\n第2章 NIO入门 2.1 传统的BIO编程 C/S模型，客户端发起连接请求，三次握手，通过Socket进行通信。\n2.1.1 BIO通信模型图 一请求一应答模型：每次接收到连接请求都创建一个新的线程进行链路处理。处理完成后通过输出流返回应答给客户端，线程销毁。\n该模型最大的问题就是：缺乏弹性伸缩能力，当客户端并发访问量增加后，服务端的线程个数和客户端并发访问数呈1：1的正比关系。\n2.1.2 同步阻塞式I/O创建的TimeServer源码分析 import java.io.IOException; import java.net.ServerSocket; import java.net.Socket; /** * \u0026lt;p\u0026gt;Description: 同步阻塞式I/O创建的TimeServer\u0026lt;/p\u0026gt; * * @author 李宏博 * @version xxx * @create 2019/8/14 17:58 */ public class TimeServer { /** * * @param args */ public static void main(String[] args) throws IOException { int port = 8080; if (args != null \u0026amp;\u0026amp; args.length \u0026gt; 0) { try { port = Integer.valueOf(args[0]); } catch (NumberFormatException e) { e.printStackTrace(); } } ServerSocket server = null; try { server = new ServerSocket(port); System.","title":"第1章 Java的I/O演进之路"},{"content":"第1章 Spring框架的由来 1.1 Spring之崛起 1.2 Spring框架概述 基于POJO（Plain Old Java Object，简单Java对象）的轻量级开发理念。\nSpring总体架构：\n1.3 Spring大观园 1.4 小结 第2章 Spring的IOC容器 2.1 我们的理念是：让别人为你服务 2.2 手语，呼喊，还是心有灵犀 2.2.1 构造方法注入 IoC Service Provider会检查被注入对象的构造方法，取得它所需要的依赖对象列表，进而为其注 入相应的对象。同一个对象是不可能被构造两次的，因此，被注入对象的构造乃至其整个生命周期， 应该是由IoC Service Provider来管理的。\n2.2.2 setter方法注入 setter方法注入虽不像构造方法注入那样，让对象构造完成后即可使用，但相对来说更宽松一些， 可以在对象构造完成后再注入。\n2.2.3 接口注入 对于前两种注入方式来说，接口注入没有那么简单明了。被注入对象如果想要IoC Service Provider为其注入依赖对象，就必须实现某个接口。这个接口提供一个方法，用来为其注入依赖对象。 IoC Service Provider最终通过这些接口来了解应该为被注入对象注入什么依赖对象。\n示例：\n2.2.4 三种注入方式的比较 接口注入。不提倡，带有侵入性 构造方法注入。这种注入方式的优点就是，对象在构造完成之后，即已进入就绪状态，可以马上使用。缺点就是，当依赖对象比较多的时候，构造方法的参数列表会比较长。而通过反射构造对象的时候，对相同类型的参数的处理会比较困难，维护和使用上也比较麻烦。而且在Java中，构造方法无法被继承，无法设置默认值。对于非必须的依赖处理，可能需要引入多个构造方法，而参数数量的变动可能造成维护上的不便。 setter方法注入。因为方法可以命名， 所以setter方法注入在描述性上要比构造方法注入好一些。另外， setter方法可以被继承，允许设置默认值，而且有良好的IDE支持。缺点当然就是对象无法在构造完成后马上进入就绪状态。 2.3 IOC的附加值 ","permalink":"https://haokiu.com/blog/567c6d054f1d4d53a29e9d24f213165a/","summary":"第1章 Spring框架的由来 1.1 Spring之崛起 1.2 Spring框架概述 基于POJO（Plain Old Java Object，简单Java对象）的轻量级开发理念。\nSpring总体架构：\n1.3 Spring大观园 1.4 小结 第2章 Spring的IOC容器 2.1 我们的理念是：让别人为你服务 2.2 手语，呼喊，还是心有灵犀 2.2.1 构造方法注入 IoC Service Provider会检查被注入对象的构造方法，取得它所需要的依赖对象列表，进而为其注 入相应的对象。同一个对象是不可能被构造两次的，因此，被注入对象的构造乃至其整个生命周期， 应该是由IoC Service Provider来管理的。\n2.2.2 setter方法注入 setter方法注入虽不像构造方法注入那样，让对象构造完成后即可使用，但相对来说更宽松一些， 可以在对象构造完成后再注入。\n2.2.3 接口注入 对于前两种注入方式来说，接口注入没有那么简单明了。被注入对象如果想要IoC Service Provider为其注入依赖对象，就必须实现某个接口。这个接口提供一个方法，用来为其注入依赖对象。 IoC Service Provider最终通过这些接口来了解应该为被注入对象注入什么依赖对象。\n示例：\n2.2.4 三种注入方式的比较 接口注入。不提倡，带有侵入性 构造方法注入。这种注入方式的优点就是，对象在构造完成之后，即已进入就绪状态，可以马上使用。缺点就是，当依赖对象比较多的时候，构造方法的参数列表会比较长。而通过反射构造对象的时候，对相同类型的参数的处理会比较困难，维护和使用上也比较麻烦。而且在Java中，构造方法无法被继承，无法设置默认值。对于非必须的依赖处理，可能需要引入多个构造方法，而参数数量的变动可能造成维护上的不便。 setter方法注入。因为方法可以命名， 所以setter方法注入在描述性上要比构造方法注入好一些。另外， setter方法可以被继承，允许设置默认值，而且有良好的IDE支持。缺点当然就是对象无法在构造完成后马上进入就绪状态。 2.3 IOC的附加值 ","title":"第1章 Spring框架的由来"},{"content":"第1章 概述 互联网公司的分布式两个特点：规模大、成本低。\n1.1 分布式存储概念 定义：分布式存储系统是大量普通PC服务器通过Internet互联，对外作为一个整体提供存储服务。\n特性：\n可扩展。集群，性能随规模线性增长。 低成本。有自动容错，自动负载均衡机制。所以可以构建在普通PC机器。 高性能。 易用。提供易用的对外接口。 主要挑战：数据、状态信息的持久化，要求在自动迁移、自动容错、并发读写的过程中保证数据的一致性。\n主要技术来自于分布式系统和数据库：\n数据分布：如何保证均匀？如何实现跨服务器读写？ 一致性：如何复制？如何保证出现异常也一致？ 容错：如何检测？出错如何迁移？ 负载均衡：如何实现？如何做到迁移时不影响其他业务？ 事务与并发控制：如何实现分布式事务？如何实现MVCC？ 易用性：如何易用？如何方便运维？ 压缩/解压缩：如何根据数据特点设计压缩/解压缩算法？如何平衡节省的存储空间和消耗的CPU资源浪费？ 1.2 分布式存储分类 数据大致分为三类：\n非结构化数据：包括所有格式的办公文档、文本、图片、图像、音频和视频信息等。 结构化数据：一般存储在关系数据库中，可用二位关系表结构来表示。 半结构化数据：与结构化的区别在于，半结构化数据的模式结构和内容混在一起，没有明显的区分，也不需要预先定义数据的模式结构。 存储系统分为四类：\n分布式文件系统 图片、照片、视频等非结构化数据对象，以对象组织，对象之间没有关联，称为Blob（Binary Large Object，二进制大对象）数据。\n总体上看：分布式文件系统存储三种类型的数据：Blob对象、定长块以及大文件。在系统层面，分布式文件系统内部按照数据块来组织数据，每个数据块的大小大致相同，每个数据块可以包含多个Blob对象或者定长块，一个大文件也可以拆分成多个数据块。\n分布式键值系统 用于存储关系简单的半结构化数据，它只提供基于主键的CRUD功能，即根据主键创建、读取、更新或者删除一条键值记录。\n与传统哈希表相似，但是支持将数据分布到多个存储节点。\n分布式键值系统是分布式表格系统的一种简化实现，一般用作缓存。\n分布式表格系统 用于存储较为复杂的半结构化数据。不仅仅支持简单的CRUD操作，而且支持扫面某个主键范围。\n借鉴了许多关系型数据库的技术，例如支持某种程度上的事务，比如单行事务，某个实体组下的多行事务。\n与分布式数据库先比，仅支持针对单张表格的操作，不支持复杂操作。\n分布式数据库 一般从单机数据库扩展而来，用于存储结构化数据。\n第2章 单机存储系统 单机存储引擎就是哈希表、B树等数据结构在机械磁盘、SSD等持久化介质上的实现。\n2.1 硬件基础 2.1.1 CPU架构 经典的多CPU架构为对称多处理结构（Symmetric Multi-Processing，SMP），即在一个计算机上汇集了一组处理器，它们之间对称工作，无主次或从属关系，共享相同的物理内存及总线。\n2.1.2 IO总线 存储系统的性能瓶颈一般在与IO。\n2.1.3 网络拓扑 传统的数据中心网络拓扑，分三层。最下面是接入层，中间是汇聚层，上面是汇聚层。存在的问题：大量下层接入，导致同一个接入层下的服务器之间的带宽减小。\n2.1.4 性能参数 2.1.5 存储层次架构 存储系统的性能主要包括两个维度：吞吐量以及访问延时。\n2.2 单机存储引擎 2.2.1 哈希存储引擎 Bitcask是一个基于哈希表结构的键值寸尺系统，它仅支持追加操作（Append-only），即所有的写操作只追加而不修改老的数据。\n在Bitcask系统中，每个文件有一定的大小限制，当文件增加到相应的大小时，就会产生一个新的文件，老的文件只读不写。在任意时刻，只有一个文件市可写的，用于数据追加，称为活跃数据文件。而其他已经达到大小限制的文件，称为老数据文件。\n数据结构 一条一条写入，每条记录的数据项分别为：主键（key），value内容（value），主键长度（key_sz），value长度（value_sz），时间戳（timetamp）以及crc校验值。（删除不会删除旧的条目，而是将value设定为一个特殊的之作标识）。内存中的结构是hash表。\n定期合并 为解决垃圾文件问题。将所有老数据文件中的数据扫描一遍生成一个新的数据文件。对用一个key的多个操作以保留最新的一个原则进行删除。\n快速恢复 每次合并时，将内存中的哈希索引表转储到磁盘中，生成一个索引文件。这个索引文件只存储value的位置。\n2.2.2 B树存储引擎 不仅支持随机读取，还支持范围扫描。\n数据结构 InnoDB按照页面（Page）来组织数据，每个页面对用B+树的一个节点。\nB+树的根节点是常驻内存的。修改操作首先需要记录提交日志，接着修改内存中的B+树。\n缓冲区管理 LRU、LIRS\n2.2.3 LSM树存储引擎 将对数据的修改增量保持在内存中，达到指定的大小先之后将这些修改操作批量写入磁盘，读取时需要合并磁盘中的历史数据和内存中最近的修改操作。\n","permalink":"https://haokiu.com/blog/b221a7f05b774f7ab4305cff0f244d52/","summary":"第1章 概述 互联网公司的分布式两个特点：规模大、成本低。\n1.1 分布式存储概念 定义：分布式存储系统是大量普通PC服务器通过Internet互联，对外作为一个整体提供存储服务。\n特性：\n可扩展。集群，性能随规模线性增长。 低成本。有自动容错，自动负载均衡机制。所以可以构建在普通PC机器。 高性能。 易用。提供易用的对外接口。 主要挑战：数据、状态信息的持久化，要求在自动迁移、自动容错、并发读写的过程中保证数据的一致性。\n主要技术来自于分布式系统和数据库：\n数据分布：如何保证均匀？如何实现跨服务器读写？ 一致性：如何复制？如何保证出现异常也一致？ 容错：如何检测？出错如何迁移？ 负载均衡：如何实现？如何做到迁移时不影响其他业务？ 事务与并发控制：如何实现分布式事务？如何实现MVCC？ 易用性：如何易用？如何方便运维？ 压缩/解压缩：如何根据数据特点设计压缩/解压缩算法？如何平衡节省的存储空间和消耗的CPU资源浪费？ 1.2 分布式存储分类 数据大致分为三类：\n非结构化数据：包括所有格式的办公文档、文本、图片、图像、音频和视频信息等。 结构化数据：一般存储在关系数据库中，可用二位关系表结构来表示。 半结构化数据：与结构化的区别在于，半结构化数据的模式结构和内容混在一起，没有明显的区分，也不需要预先定义数据的模式结构。 存储系统分为四类：\n分布式文件系统 图片、照片、视频等非结构化数据对象，以对象组织，对象之间没有关联，称为Blob（Binary Large Object，二进制大对象）数据。\n总体上看：分布式文件系统存储三种类型的数据：Blob对象、定长块以及大文件。在系统层面，分布式文件系统内部按照数据块来组织数据，每个数据块的大小大致相同，每个数据块可以包含多个Blob对象或者定长块，一个大文件也可以拆分成多个数据块。\n分布式键值系统 用于存储关系简单的半结构化数据，它只提供基于主键的CRUD功能，即根据主键创建、读取、更新或者删除一条键值记录。\n与传统哈希表相似，但是支持将数据分布到多个存储节点。\n分布式键值系统是分布式表格系统的一种简化实现，一般用作缓存。\n分布式表格系统 用于存储较为复杂的半结构化数据。不仅仅支持简单的CRUD操作，而且支持扫面某个主键范围。\n借鉴了许多关系型数据库的技术，例如支持某种程度上的事务，比如单行事务，某个实体组下的多行事务。\n与分布式数据库先比，仅支持针对单张表格的操作，不支持复杂操作。\n分布式数据库 一般从单机数据库扩展而来，用于存储结构化数据。\n第2章 单机存储系统 单机存储引擎就是哈希表、B树等数据结构在机械磁盘、SSD等持久化介质上的实现。\n2.1 硬件基础 2.1.1 CPU架构 经典的多CPU架构为对称多处理结构（Symmetric Multi-Processing，SMP），即在一个计算机上汇集了一组处理器，它们之间对称工作，无主次或从属关系，共享相同的物理内存及总线。\n2.1.2 IO总线 存储系统的性能瓶颈一般在与IO。\n2.1.3 网络拓扑 传统的数据中心网络拓扑，分三层。最下面是接入层，中间是汇聚层，上面是汇聚层。存在的问题：大量下层接入，导致同一个接入层下的服务器之间的带宽减小。\n2.1.4 性能参数 2.1.5 存储层次架构 存储系统的性能主要包括两个维度：吞吐量以及访问延时。\n2.2 单机存储引擎 2.2.1 哈希存储引擎 Bitcask是一个基于哈希表结构的键值寸尺系统，它仅支持追加操作（Append-only），即所有的写操作只追加而不修改老的数据。\n在Bitcask系统中，每个文件有一定的大小限制，当文件增加到相应的大小时，就会产生一个新的文件，老的文件只读不写。在任意时刻，只有一个文件市可写的，用于数据追加，称为活跃数据文件。而其他已经达到大小限制的文件，称为老数据文件。\n数据结构 一条一条写入，每条记录的数据项分别为：主键（key），value内容（value），主键长度（key_sz），value长度（value_sz），时间戳（timetamp）以及crc校验值。（删除不会删除旧的条目，而是将value设定为一个特殊的之作标识）。内存中的结构是hash表。\n定期合并 为解决垃圾文件问题。将所有老数据文件中的数据扫描一遍生成一个新的数据文件。对用一个key的多个操作以保留最新的一个原则进行删除。\n快速恢复 每次合并时，将内存中的哈希索引表转储到磁盘中，生成一个索引文件。这个索引文件只存储value的位置。\n2.2.2 B树存储引擎 不仅支持随机读取，还支持范围扫描。\n数据结构 InnoDB按照页面（Page）来组织数据，每个页面对用B+树的一个节点。\nB+树的根节点是常驻内存的。修改操作首先需要记录提交日志，接着修改内存中的B+树。\n缓冲区管理 LRU、LIRS\n2.2.3 LSM树存储引擎 将对数据的修改增量保持在内存中，达到指定的大小先之后将这些修改操作批量写入磁盘，读取时需要合并磁盘中的历史数据和内存中最近的修改操作。","title":"第1章 概述"},{"content":"第2章 InnoDB存储引擎 事务安全。\n2.1 InnoDB存储引擎概述 Mysql5.5开始是默认的表存储引擎（之前尽在Window下是）。第一个完整支持ACID事务的MySQL存储引擎。其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读，同时被设计用来最有效地利用以及使用内存和CUP。\n高性能、高可用、高扩展。\n2.2 InnoDB存储引擎的版本 略\n2.3 InnoDB体系结构 后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据。\n此外将已修改的数据文件刷新到磁盘文件，同时保证在数据库发生异常的情况下InnoDB能恢复到正常运行状态。\n2.3.1 后台线程 多线程模型。不同的后台线程处理不同的任务。\nMaster Thread 将缓冲池的数据异步刷新到磁盘，保证数据一致性，包括脏页的刷新、合并插入缓冲（INSERT BUFFER）、UNDO页的回收。\nIO Thread 大量使用AIO（Async IO），极大提高性能。IO Thread主要负责这些IO请求的回调处理。\n第3章 文件 参数文件：告诉MySQL启动时查找文件的地址，指定初始化参数； 日志文件：错误日志文件、二进制文件日志文件、慢查询日志文件、查询日志文件； socket：当用UNIX域套接字方式进行连接时需要的文件 pid文件：MySQL实例的进程ID文件 MySQL表结构文件：用来存放MySQL表结构定义文件 存储引擎文件：每个存储引擎都会有自己的文件来保存各种数据，这些存储引擎真正存储了记录和索引等数据。 3.1 参数文件 MySQL实例也可以不需要参数文件，这是编译MySQL时指定的默认值。但是如果在默认的数据库目录下找不到mysql架构，则会启动失败。\n3.1.1 什么是参数 数据库中的参数是键值对。MySQL中无类似Oracle中的隐藏参数。\n3.1.2 参数类型 动态参数：运行时可修改 静态参数：在整个实例的生命周期都不能修改。 3.2 日志文件 日志文件记录了MySQL数据库的各种类型活动。\n3.2.1 错误日志 对MySQL的启动、运行、关闭过程进行了记录。当出现MySQL数据库不能正常启动时，第一个必须查找的文件应该就是错误日志文件。\n3.2.2 慢查询日志 帮助DBA定位可能存在问题的SOL语句，从而进行SQL语句层面的优化。设置一个阈值（最小精度是微秒），超过（必须是大于，等于不行）时将该SQL语句记录到慢查询日志中。\n默认情况下并不启动慢查询日志。\n如果没有使用索引也会被记录。\n3.2.3 查询日志 记录了所有对MySQL数据库请求的信息，无论这些请求是否得到了正确的执行。\n3.2.4 二进制文件 记录了对MySQL数据库执行更改的所有操作，但是不包括SELEC和SHOW这类操作。\n作用：\n恢复：某些数据的恢复需要二进制日志。 复制：主从复制 审计：通过审计二进制文件，判断是否有数据库进行注入的攻击。 二进制日志文件在默认情况下并没有启动，需要手动指定参数来启动。会影响性能，但仅仅1%。\n缓冲写宕机问题，无缓冲写宕机问题\n3.3 套接字文件 3.4 pid文件 3.5 表结构定义文件 记录该存储引擎对应的表结构\n3.6 InnoDB存储引擎文件 InnoDB独有的文件\n3.6.1 表空间文件 InnoDB采用将存储的数据按表空间进行存放的设计。\n还可设置独立表空间，用户不用将所有数据都存放于默认的表空间中。\n单独的表空间仅存储表的数据、索引和插入缓冲BITMAP等信息，其余的信息存放到默认表空间。\n3.6.2 重做日志文件 宕机问题。\n重做日志文件与二进制文件的区别：\n记录范围，二进制日志会记录所有与MySQL数据库有关的日志记录，而InnoDB仅记录该存储引擎的事务日志。 记录内容，二进制日志记录具体操作（逻辑日志），而InnoDB的重做日志文件是关于每个Page的更改的物理情况 写入时间，二进制日志文件只在事务提交前进行一次写入，而重做日志文件在事务的进行过程中，一直会被写入。 3.7 小结 重做日志文件使得InnoDB存储引擎可以提供可靠的事务。\n第4章 表 4.1 索引组织表 在InnoDB存储引擎中，表都是根据主键顺序组织存放。\n在InnoDB存储引擎中，每张表都有个主键，如果没有显示定义，则按如下方式创建：\n首先判断表中是否含有唯一非空索引（Unique NOT NULL），如果有，则该列即为主键。（按定义索引的顺序选择） 如果不符合上述条件，InnoDB存储引擎自动创建一个6字节大小的指针。 _rowid仅适用于单个列为主键的情况。\n4.2 InnoDB逻辑存储结构 表空间由段（segment），区（extent），页（page）组成。\n4.2.1 表空间 独立表空间：存放数据、索引和插入缓冲Bitmap页。\n共享表空间：存放其他类的数据，如回滚（undo）信息，插入缓冲索引页、系统事务信息，二次写缓冲。\n回滚不会导致共享表空间缩小，只是会把不需要的undo信息标记为可用空间。\n4.2.2 段 段有InnoDB存储引擎自身完成，DBA不能也没有必要控制段。常见的有数据段、索引段、回滚段等。\n数据段为B+树的叶子节点。\n索引段为B+树的非叶子节点。\n4.2.3 区 区是由连续页组成的空间，每个区大小都是1MB。\n默认页大小为16KB，一个区中有64个连续的页。\n不论页的大小如何变，区的大小都是1M。\n4.2.4 页 InnoDB管理磁盘的最小单位。\n在InnoDB存储引擎中，常见的页有：\n数据页 undo页 系统页 事务数据页 插入缓冲位图页 插入缓冲空闲列表页 未压缩的二进制大对象页 压缩的二进制大对象页 4.2.5 行 InnoDB存储引擎是面向列的，也就是说数据是按行进行存放的。\n每个页最多允许存放16KB/2-200行的记录，也就是7992行记录。\n4.3 InnoDB 行记录格式 新版本都使用Compact格式。旧版本使用Redundant格式。\n数据库实例的作用之一就是读取页中存放的行记录。\n4.3.1 Compact行记录格式 NULL值不占用空间。\n4.3.2 Redundant行记录格式 4.3.3 行溢出数据 InnoDB存储引擎可以将一条记录中的某些数据存储在真正的数据页面之外。\nVARCHAR最大长度65535字节（建表时填写的是字符数）。\n每个页中至少应该有两条行记录（否则失去了B+Tree的意义，变成了链表）。\n第6章 锁 一个开发难点：利用数据库的并发访问，同时又要确保一致性读与写。数据库系统区别于文件系统的关进特性。\n人们认为行级锁总会增加开销，实际上，只有当实现本身会增加开销时，行级锁才会增加开销。InnoDB不需要锁升级，因为一个锁和多个锁的开销时相同的。\n6.1 什么是锁？ 锁机制用于管理对共享资源的并发访问。不只是行级锁，同时会在内部其他地方使用锁。例如操作缓冲池LRU列表。\n数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。\n不同数据库实现对于锁的实现不同。\nMyISAM引擎是表锁设计。并发情况下读没有问题，但是并发插入的性能差一些。\nInnoDB存储引擎，提供一致性的非锁定读、行级锁支持。行级锁没有额外的开销，并可以同时得到并发性和一致性。\n6.2 lock和latch 都可以被称为“锁”，但含义不同。这里主要说lock。\nlatch分为mutex（互斥锁）和rwlock（读写锁）。其目的是用来保证并发线程操作资源的正确性，没有死锁检测机制。\nlock的对象是事务，锁定的是数据库中的对象，如表、页、行。并且一般lock的对象仅在事务commit和rollback后进行释放（不同隔离级别释放时间不同）。有死锁机制。\n查看latch的命令：SHOW ENGINE INNODE MUTEX;\n6.3 InnoDB存储引擎中的锁 6.3.1 锁的类型 两种标准类型的行级锁：\n共享锁（S Lock） 排他锁（X Lock） X锁与任何的锁都不兼容，S锁仅与S锁兼容。\nInnoDB存储引擎支持多粒度锁定，允许行级锁和表级锁同时存在。为了支持不同粒度上加锁，InnoDB支持了一种额外的锁方式，意向锁（Intention Lock）。\n意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望再更细力度上进行加锁。\n即先用意向锁锁粗粒度，最后用行级锁锁住行。\n意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁。 意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁。 InnoDB支持的是行级别的锁，因此意向锁其实不会阻塞除全表扫描以外的任何请求。\nlock_data不可信。当用户运行一个范围查找时，lock_data只返回第一行的主键值。\n6.3.2 一致性非锁定读 一致性非锁定读是指InnoDB通过多版本控制的方式来读取当前执行时间数据库中行的数据。\n如果读取的行正在执行DELETE或UPDATE操作，这是读取操作不会因此去等待行上锁的释放。而是去读取行的一个快照数据。\n非锁定是因为不需要等待X锁地释放。快照通过undo实现，没有额外开销。而且读快照不需要上锁。\nRC和RR下，InnoDB使用非锁定地一致性读。但对快照地定义不同。\nRC违反了隔离性。\n6.3.3 一致性锁定读 两种一致性锁定读操作：\nSELECT \u0026hellip; FOR UPDATE; SELECT \u0026hellip; LOCK IN SHARE MODE; SELECT \u0026hellip; FOR UPDATE;对读取地行记录加一个X锁，其他事务不能对已锁定地行加上任何锁。\nSELECT \u0026hellip; LOCK IN SHARE MODE;对读取的行记录加一个S锁，其他事务可以向被锁定的行加S锁，但是如果加X会被阻塞。\n事务提交时锁就释放了。\n6.3.4 自增长与锁 再InnoDB的内存结构中，对每个含有自增长值得表都有一个自增长计数器。当对含有自增长技术器得表进行插入操作时，这个计数器会被初始化，执行如下得语句来得到计数器的值：\nSELECT MAX(auto_inc_col) FROM t FOR UPDATE;\n插入操作将其加1。这个实现风湿称作AUTO-INC Locking。这种锁其实是采用一种特殊得表锁机制，为了提高插入得性能，锁不在事务完成后释放，而是完成对自增长得SQL语句后立即释放。\n虽然AUTO-INC Locking从一定程度上提高了并发插入得效率，但还是有性能问题。事务必须等待前一个插入的完成。其次对于INSERT\u0026hellip;SELECT 的大数量的插入会影响插入的性能，因为另一个事务中的插入会被阻塞。\n=========\n5.1.22之后对这部分进行了一个优化：提供了一种轻量级互斥量的自增长实现机制，这种机制大大提高了自增长插入的性能。\n并且从该版本开始，InnoDB存储引擎提供了一个参数innodb_autonic_lock_mode来控制自增长，默认值为1。\n自增长的插入分类图：\ninnodb_autoinc_lock_mode各个设置下对自增的影响：\n特别注意：InnoDB的自增长实现与与MyISAM不同，MyISAM存储引擎是表锁设计，自增长不用考虑并发插入的问题。\n在InnoDB中，自增长值得列必须是索引，同时必须是索引得第一个列。\n6.3.5 外键和锁 6.4 锁的算法 6.4.1 行锁的3种算法 Record Lock：单个行记录上的锁 GapLock：间隙锁，锁定一个范围，但不包含记录本身 Next-Key Lock：Record Lock + GapLock，锁定一个范围并且锁定记录本身。 Record Lock总是会去锁住索引记录，如果建表时没有设置索引，则会使用隐式的主键来进行锁定。\nNext-Key Lock锁定的区间为左开右闭区间，例如一个索引有10，11，13，20，那么可以锁定的区间有：\n采用Next-Key Lock的锁定技术称为Next-Key Locking。其设计目的时为了解决幻读。而利用这种锁定技术，锁定的时范围。\n如果事务T1已经通过Next-Key Locking锁定了如果下范围： 那么插入新的记录12时，锁定的范围会变成： 特别注意三种情况：\n就是说当查询的索引含有唯一属性，Next-Key Lock会被降级为Record Lock，即仅锁住索引本身，而不是范围。\nNext-Key Lock仅在查询的列时唯一索引的情况下。若是辅助索引，则还是使用传统的Next-Key Locking技术加锁，因为有两个索引，则需要分别锁定。对于聚集索引，则加Record Lock。而且辅助索引的下一索引加上gap lock。\n若唯一索引由多个列组成，而查询仅是查找多个唯一索引的其中一个，还是使用Next-Key Lock。\n显示的关闭Gap Lock：\n将事务的隔离级别设置为RC； 将参数innodb_locks_unsafe_for_binlog设置为1 使用INSERT INTO SELECT进行复制表时，若查询的范围被锁定则插入操作会被阻塞。\n6.4.2 解决幻象问题（幻读与不可重复读） 索引1，2，5的情况，执行SELECT * FROM t WHERE a \u0026gt; 2 FOR UPDATE;\n锁住的是 。\n如果用户通过索引查询一个值，并对该行加上了一个S Lock，那么即使查询的值不存在，其锁定的也是一个范围，因此若没有返回任何行，那么新插入的值一定是唯一的。\n若此时有并发情况则会死锁，所以并不会改变唯一性：\n6.5 锁问题 6.5.1 脏读 脏数据事务对缓冲池中行记录的修改，并且还没有被提交。\n脏读即一个事务可以读到另外一个事务中未提交的数据，违反了隔离性。\nRU下会产生脏读。主从复制的从节点的查询不需要特别精确的返回值，所以可以利用脏读。\n6.5.2 不可重复读 RC下会有，且允许不可重复读。\n6.5.3 丢失更新 当前所有的隔离级别下都不会导致丢失更行。因为对于行的DML操作都会对行或其他粗粒度级别的对象加锁。\n银行转账问题，或者超卖问题。通过加排他锁（悲观锁思想）解决。（我在秒杀系统中解决超卖使用的是乐观锁思想）\n6.6 阻塞 阻塞会导致超时，InnoDB默认不会回滚超时引发的异常，其实InnoDB在大部分情况下都不会对异常进行回滚，这个情况非常危险！！\n6.7 死锁 6.7.1 死锁的概念 死锁是指两个或两个以上的事务在执行过程中，因争夺资源而造成的一种互相等待的现象。\n超时机制，超时就回滚。\n等待图（类似操作系统中的资源分配图），主动检测死锁。深度优先遍历图，并且在后来的版本中将递归改为非递归。\n6.7.2 死锁概率 系统中事务的数量越多发生死锁的概率越大； 每个事务操作的数量越多，发生死锁的概率越大； 操作数据的集合越小发生死锁的概率越大。 死锁异常会回滚！\n6.8 锁升级 锁升级会导致锁粒度将低而导致并发性能降低。\nInnoDB不存在锁升级。InnoDB不是根据每条记录来产生行锁的，相反，其根据每个事务访问的每个页对锁进行管理，采用位图的方式。因此不管一个事务锁住页中一个记录还是多个记录，开销是一致的。\nInnoDB的加锁开销小。\n","permalink":"https://haokiu.com/blog/232f08ac38d0478dab889420f809c20e/","summary":"第2章 InnoDB存储引擎 事务安全。\n2.1 InnoDB存储引擎概述 Mysql5.5开始是默认的表存储引擎（之前尽在Window下是）。第一个完整支持ACID事务的MySQL存储引擎。其特点是行锁设计、支持MVCC、支持外键、提供一致性非锁定读，同时被设计用来最有效地利用以及使用内存和CUP。\n高性能、高可用、高扩展。\n2.2 InnoDB存储引擎的版本 略\n2.3 InnoDB体系结构 后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据。\n此外将已修改的数据文件刷新到磁盘文件，同时保证在数据库发生异常的情况下InnoDB能恢复到正常运行状态。\n2.3.1 后台线程 多线程模型。不同的后台线程处理不同的任务。\nMaster Thread 将缓冲池的数据异步刷新到磁盘，保证数据一致性，包括脏页的刷新、合并插入缓冲（INSERT BUFFER）、UNDO页的回收。\nIO Thread 大量使用AIO（Async IO），极大提高性能。IO Thread主要负责这些IO请求的回调处理。\n第3章 文件 参数文件：告诉MySQL启动时查找文件的地址，指定初始化参数； 日志文件：错误日志文件、二进制文件日志文件、慢查询日志文件、查询日志文件； socket：当用UNIX域套接字方式进行连接时需要的文件 pid文件：MySQL实例的进程ID文件 MySQL表结构文件：用来存放MySQL表结构定义文件 存储引擎文件：每个存储引擎都会有自己的文件来保存各种数据，这些存储引擎真正存储了记录和索引等数据。 3.1 参数文件 MySQL实例也可以不需要参数文件，这是编译MySQL时指定的默认值。但是如果在默认的数据库目录下找不到mysql架构，则会启动失败。\n3.1.1 什么是参数 数据库中的参数是键值对。MySQL中无类似Oracle中的隐藏参数。\n3.1.2 参数类型 动态参数：运行时可修改 静态参数：在整个实例的生命周期都不能修改。 3.2 日志文件 日志文件记录了MySQL数据库的各种类型活动。\n3.2.1 错误日志 对MySQL的启动、运行、关闭过程进行了记录。当出现MySQL数据库不能正常启动时，第一个必须查找的文件应该就是错误日志文件。\n3.2.2 慢查询日志 帮助DBA定位可能存在问题的SOL语句，从而进行SQL语句层面的优化。设置一个阈值（最小精度是微秒），超过（必须是大于，等于不行）时将该SQL语句记录到慢查询日志中。\n默认情况下并不启动慢查询日志。\n如果没有使用索引也会被记录。\n3.2.3 查询日志 记录了所有对MySQL数据库请求的信息，无论这些请求是否得到了正确的执行。\n3.2.4 二进制文件 记录了对MySQL数据库执行更改的所有操作，但是不包括SELEC和SHOW这类操作。\n作用：\n恢复：某些数据的恢复需要二进制日志。 复制：主从复制 审计：通过审计二进制文件，判断是否有数据库进行注入的攻击。 二进制日志文件在默认情况下并没有启动，需要手动指定参数来启动。会影响性能，但仅仅1%。\n缓冲写宕机问题，无缓冲写宕机问题\n3.3 套接字文件 3.4 pid文件 3.5 表结构定义文件 记录该存储引擎对应的表结构\n3.6 InnoDB存储引擎文件 InnoDB独有的文件\n3.6.1 表空间文件 InnoDB采用将存储的数据按表空间进行存放的设计。\n还可设置独立表空间，用户不用将所有数据都存放于默认的表空间中。\n单独的表空间仅存储表的数据、索引和插入缓冲BITMAP等信息，其余的信息存放到默认表空间。\n3.6.2 重做日志文件 宕机问题。\n重做日志文件与二进制文件的区别：\n记录范围，二进制日志会记录所有与MySQL数据库有关的日志记录，而InnoDB仅记录该存储引擎的事务日志。 记录内容，二进制日志记录具体操作（逻辑日志），而InnoDB的重做日志文件是关于每个Page的更改的物理情况 写入时间，二进制日志文件只在事务提交前进行一次写入，而重做日志文件在事务的进行过程中，一直会被写入。 3.7 小结 重做日志文件使得InnoDB存储引擎可以提供可靠的事务。\n第4章 表 4.1 索引组织表 在InnoDB存储引擎中，表都是根据主键顺序组织存放。\n在InnoDB存储引擎中，每张表都有个主键，如果没有显示定义，则按如下方式创建：\n首先判断表中是否含有唯一非空索引（Unique NOT NULL），如果有，则该列即为主键。（按定义索引的顺序选择） 如果不符合上述条件，InnoDB存储引擎自动创建一个6字节大小的指针。 _rowid仅适用于单个列为主键的情况。","title":"第2章 InnoDB存储引擎"},{"content":"第2章 Tomcat总体架构 系统设计及中间件设计时的参考：生命周期管理、可扩展的容器组件设计、类加载方式。\n2.1 总体设计 如何设计一个应用服务器？\n2.1.1 Server 最基本的功能：接收请求，业务处理，返回响应。\n两个方法：\nstart()：启动服务器，打开Socket链接，监听端口，负责接收请求，处理及返回。 stop()：停止服务器并释放网络资源。 作为嵌入在应用系统中的远程请求处理方案，且访问量低时可行。但作为应用服务器不可行。\n2.1.2 Connector和Container 请求监听与请求处理放到一起扩展性差。\nConnector负责监听，返回。\nContainer负责处理请求。\n均分别拥有自己的start()和stop()方法来加载和释放自己维护的资源。\n明显的缺陷：如何让Connector与Container对应？可以维护一个复杂关系映射，但是并不必需。Container设计足够灵活。\n引入Service，负责维护多个Connector和一个Container。\n在Tomcat中，Container是一个更加通用的概念。为了与Tomcat中的组件命名一致，所以重新命名为Engine，用以表示整个Servlet引擎。\nEngine表示整个Servlet引擎。Server表示整个Servlet容器。\n2.1.3 Container设计 应用服务器是用来部署并运行Web应用的，是一个运行环境，而不是独立的业务处理系统。因此需要在Engine容器中支持管理Web应用，当接收到Connector的处理请求时，Engine容器能够找到一个合适的Web应用来处理。\n使用一个Context来表示一个Web应用，并且一个Engine可以包含多个Context。\n虚拟主机，加入Host。一个Host可以包含多个Context。\nTomcat的设计中Engine可以包含Host也可以包含Context，这是由具体的Engine实现确定的。Tomcat提供的默认实现StandardEngine只能包含Host。\n一个Web应用可以包含多个Servlet实例。在Tomcat中，Servlet定义被称为Wrapper。\n“容器”的作用都是处理请求并返回响应数据。所以引入一个Container接口：addchild()添加子容器，backgroundProcess()实现文件变更的扫描。\n2.1.4 Lifecycle 所有组件均存在启动、停止这两个生命周期方法，可在此基础上扩展生命周期管理的方法，即对于生命周期管理进行一次接口抽象。\n将Server接口替换为Lifecycle接口：\nInit()：初始化组件 start()：启动组件 stop()：停止组件 destory()：销毁组件 addLifecycleListener：添加事件监听器（用于监听组件的状态变化） removeLifecycleListener：删除 Tomcat核心组件的默认实现均继承自LifecycleBeanBase抽象类，该类不但负责组件各个状态的转换和事件处理，还将组件自身注册为MBean，以便通过Tomcat的管理工具进行动态维护。\n2.1.5 Pipeline和Valve 以上设计以保证核心架构的了可伸缩性和可扩展性。但是还要考虑各个组件的灵活性，使其同样可扩展。\n责任链模式是一种比较好的选择。Tomcat即采用该模式来实现客户端请求的处理。在Tomcat中每个Container组件通过执行一个责任链来完成具体的请求处理。\nPipeline（管道）用于构造责任链，Valve（阀）代表责任链上的每个处理器。Pipeline中维护了一个基础的Valve（位于末端，最后执行）。\nTomcat的每个层级的容器（Engine、Host、Context、Wrapper）均有对应的基础Valve实现，同时维护一个Pipeline实例。即任何层级的容器都可以对请求处理进行可扩展。\n2.1.6 Connector设计 基本功能：\n监听服务器端口，读取来自客户端的请求。 将请求数据按照指定协议进行解析。 根据请求地址匹配正确的容器进行处理。 将响应返回客户端。 Tomcat支持多协议，默认支持HTTP和AJP。同时支持多种I/O方式，包括BIO（8.5之后移除）、NIO、APR。而且在Tomcat8之后新增了对NIO2和HTTP/2协议的支持。因此对协议和I/O进行抽象和建模时需要关注的重点。\n在Tomcat中，ProtocolHandler表示一个协议处理器，其包含一个Endpoint（无此接口，仅有AbstractEndpoint抽象类）用于启动Socket监听，还包含一个Processor用于按照指定协议读取数据，并将请求交由容器处理。\n在Connector启动时，Endpoint会启动线程来监听，并在接收到请求后调用Processor进行数据读取。\n当Processor读取客户端请求后，需要按照请求地址映射到具体的容器进行处理，这个过程即为请求映射。由于Tomcat各个组件采用通用的生命周期管理，而且可以通过管理工具进行状态变更，因此请求映射除考虑映射规则的实现外，还要考虑容器组件的注册与销毁。\nTomcat通过Mapper和MapperListener两个类实现上述功能。前者用于维护容器映射信息，同时按照映射规则（Servlet规范）查找容器。后者实现了ContainerListener和LifecycleListener，用于在容器组件状态发生变更时，注册或者取消对应的容器映射信息。为了实现上述功能，MapperListener实现了Lifecycle接口，当其启动时（在Service启动时启动），会自动作为监听器注册到各个容器组件上，同时将已创建的容器注册到Mapper。\nTomcat通过适配器模式（Adapter）实现了Connector与Mapper、Container的解耦。实现自己的Adapter可以脱离Servlet容器又使用Tomcat链接器。\n2.1.7 Excutor 并发问题的解决方案。采用线程池（默认采用JDK5的线程池，继承自Lifecycle，当作通用组件进行管理）对线程进行统一管理。\n在Tomcat中Excutor由Service维护，因此同一个Service中的组件可以共享一个线程池。\n如果没有定义任何线程池，相关组件（Endpoint）会自动创建线程池，此时线程池不再共享。\n在Tomcat中，Endpoint会启动一组线程来监听Socket端口，当接收到客户端请求后，会创建请求处理对象，并交由线程池处理，由此支持并发处理客户端请求。\n2.1.8 Bootstrap和Catalina 除开前面的核心组件外，还需要提供一套配置环境来支持系统的可配置性，便于通过修改配置来优化应用。\n集群、安全等组件同样重要，但不属于通用概念。\nTomcat通过类Catalina提供了一个Shell程序，用于解析server.xml创建各种组件，同时，负责启动、停止应用服务器（只需要启动Tomcat顶层组件Server）。\nTomcat使用Digester解析XML文件，包括server.xml以及web.xml等。\n最后，Tomcat提供了Bootstrap作为应用服务器启动入口。Bootstrap负责创建Catalina实例，根据执行参数调用Catalina相关方法完成针对应用服务器的操作（启动、停止）。\nBootstrap与Tomcat应用服务器完全松耦合（通过反射调用Catalina实例），它可以直接依赖JRE运行并为Tomcat应用服务器创建共享类加载器，用于构造Catalina实例以及整个Tomcat服务器。\n上述是Tomcat标准的启动方式。但是Server及其子组件代表了应用服务器本身，那么我们可以不通过Bootstrap和Catalina来启动服务器。\nTomcat组件说明：\n组件名称 说明 Server 表示整个Servlet容器，因此Tomcat运行环境中只有唯一一个Server实例 Service Service表示一个或者多个Connector的集合，这些Connector共享同一个Container来处理其请求。在同一个Tomcat实例内可以包含任意多个Service实例，它们彼此独立 Connector 即Tomcat链接器，用于监听并转化Socket请求，同时将读取的Socket请求交由Container处理，支持不同协议以及不同的I/O方式 Container Container表示能够执行客户端请求并返回响应的一类对象。在Tomcat中存在不同级别的容器：Engine、Host、Context、Warpper Engine Engine表示整个Servlet引擎。在Tomcat中，Engine为最高层级的容器对象。尽管Engine不是直接处理请求的容器，确实获取目标容器的入口 Host Hostz作为一类容器，表示Servlet容器中的虚拟机，与一个服务器的网络名有关，如域名等。客户端可以使用这个网络名连接服务器，这个名称必须在DNS服务器上注册。 Context Context作为一类容器，用于表示ServletContext，在Servlet规范中，一个ServletContext即表示一个独立的Web应用 Wrapper Wrapper作为一类容器，用于表示Web应用中动议的Servlet Executor 表示Tomcat组件可以共享的线程池 2.2 Tomcat启动 Tomcat默认实现在相关概念的基础上结合生命周期管理监听器完成了大量的启动工作。\nTomcat的启动流程非常标准化，统一按照生命周期管理接口Lifecycle的定义进行启动。首先调用init()方法进行组件的逐级初始化，然后再调用start()方法进行启动。\n每次调用均伴随着生命周期状态变更事件的触发。\n2.3 请求处理 从本质上讲，应用服务器的请求处理开始于监听的Socket端口接收到数据，结束与讲服务器处理结果写入Socket输入流。\n2.4 类加载器 2.4.1 J2SE标准了类加载器 Bootstrap Ext System 应用程序在不自己构造类加载器的情况下，使用System作为默认的类加载器。如果构造也是以System作为父类加载器。\nJVM还提供了Ensdorsed Standerds Override Mechanism机制用于允许替换JCP之外生成的API。应用程序可以提供新版本的API来覆盖JVM的实现。\n2.4.2 Tomcat加载器 应用服务器通常会自行创建类加载器以实现更灵活的控制，这一方面是对规范的实现（Servlet规范要求每个Web应用都有一个独立的类加载器实例），另一方面也有架构层面的考虑。\n隔离性：Web应用库相互隔离，避免依赖库或者应用包相互影响。 灵活性：类加载器相互独立可以实现只对容器中的某一个Web应用进行重新部署。 性能：搜索Jar包的范围小，性能高。 除了每个Web应用的类加载器外，Tomcat也提供了3个基础的类加载器和Web应用类加载器，而且这3个类加载器指向的路径和包列表均可由catalina.properties配置。\nCommon：以System为父类加载器，Tomcat中最顶层的公关类加载器。路径为common.loader，默认指向$CATALINA_HOME$/lib下的包。 Catalina：以Common为父类加载器，用于加载Tomcat应用服务器的类加载器。路径为server.loader，默认为空（此时Tomcat使用Common类加载器加载应用服务器）。 Shared：以Common为父类加载器，是所有Web应用的父类加载器。路径为shared.loader，默认为空（此时Tomcat使用Common类加载器加载应用服务器）。 Web应用：以Shared为父类加载器，加载/WEB-INF/classes目录下的未压缩的Class和资源文件以及/WEB-INF/lib目录下的jar包。该类加载器只对当前Web应用可见，对其他Web应用不可见。 默认情况下三个类加载器为同一个（Common），但可以通过配置创建三个不同的类加载器。\nCommon类加载器负责加载Tomcat应用服务器内部和Web应用均可见的类，例如Servlet规范和一些通用的包。\nCatalina类加载器负责加载只有Tomcat应用服务器内部可见的类，这些类对Web应用不可见。如Tomcat的具体实现类，因为我们的Web应用最好与服务器松耦合，故不应该以来应用服务器的内部类。\nShared类加载器服负责加载Web应用共享的类，这些类Tomcat服务器不会依赖。\n举个使用这个特性的例子：分布式Session。需要用到第三方包时，但是我们不希望这些包对Web应用可见（可能存在包版本冲突之类的问题，也可能根本不需要这些包）。此时我们可以配置server.loader，创建独立的Catalina类加载器。\n$CATALINA_HOME/bin$目录下的包作为启动入口由System类加载器加载。简化了应用服务器的启动，同时增加了灵活性。\n从架构层面分析Tomcat的类加载器方案（补充）：\n共享。通过分层实现了Jar包在各个层面及子层面的共享，同时确保了不会引入太多的包。 隔离性。区别于前者，这服务器与Web应用的隔离。理论上，出去Servlet规范定义的接口外，Web应用不应该依赖服务器的任何实现类（有利于Web应用的可移植性）。正因如此Tomcat支持通过Catalina类加载器加载服务器依赖的包，以便应用服务器与Web应用更好地隔离。 默认情况下Tomcat通过JVM安全策略许可，实现在同一个类加载器下，禁止Web应用使用服务器的相关实现类的。\n2.4.3 Web应用类加载器 双亲委派过程：\n从缓存中加载 如果缓存中没有，则从父类加载器中加载 如果父类加载器没有，则从当前类加载器加载 如果没有则抛出异常 Tomcat的委派模型与此的不同之处：当进行类加载时，除JVM基础的类库外，它会首先尝试通过当前类加载器加载，然后在进行委派。\n所以Web应用类加载器默认加载顺序如下：\n从缓存中加载 若无，JVM的Bootstrap类加载器加载 若无，则从当前类加载器加载（按照WEB-INF/classes、WEB-INF/lib的顺序） 若无，从父类加载器加载（双亲委派），加载顺序为System、Common、Shared。 Tomcat提供了delegate属性用于控制是否启用Java委派，默认false（不启用）。当配置为true时，Tomcat将使用Java默认的委派模式，则将上述3与4交换顺序。\nTomcat还可以通过packageTriggersDeny属性只让某些包路径采用Java的委派模式，Web应用类加载器对于符合packageTriggersDeny指定包路径的类强制采用Java的委派模式。\n2.5 小结 第3章 Catalina 3.1 什么是Catalina Catalina包含了前面讲到的所有容器组件，以及后续章节将会涉及的安全、会话、集群、部署、管理等Servlet容器架构的各个方面。它通过松耦合的方式集成Coyote，以及完成按照请求协议进行数据读写。同时，它还包括启动入口、Shell程序。\n3.2 Digester Catalina使用Digester解析XML（server.xml）配置文件并创建应用服务器。\nTomcat在Catalina的创建过程中通过Digester结合LifecycleListener做了大量的初始化工作。\nDigester及SAX的事件驱动，简而言之，就是通过流读取XML文件，当识别出特定XML节点后便会执行特定的动作，或者创建Java对象，或者执行对象的某个方法。因此Digester的核心是匹配模式和处理规则。\n对象栈机制用于构造Java对象。Digester是非线程安全的。\n3.2.1 对象栈 Digester的对象栈主要在匹配模式满足时，由处理规则进行操作。\nDigester的设计模式是指，在文件读取过程中，如果遇到一个XML节点的开始部分，则会出发处理规则事件创建Java对象，并将其放入栈。当处理该节点的子节点时，该对象都将维护在栈中。当遇到该节点的结束部分时，该对象将会从栈中取出并清除。\n需要解决的问题：\n如何在创建的对象之间建立关联？最终得到的结果应该是一个Java对象树。Digester提供了一个处理规则实现（SetNextRule），该规则会调用位于栈顶部对象之后对象（即父对象）得某个方法，同时将顶部对象（子对象）作为参数传入。通过此种方式不管是一对一还是一对多得关系都可创建。 如何持有创建的首个对象，即XML得传入结果？Digester对于曾经放入栈中的第一个对象将会持有一个引用，同时作为parse()方法得返回值。还有一个方式（哨兵）。Tomcat采用哨兵的方式实现。 3.2.2 匹配模式 在需要确定当读取到某个约定的XML节点时需要执行何种操作，Digester通过匹配模式指定相关约定。\n匹配类似于简单的正则，还可以使用“*”进行模糊匹配。\n当匹配模式指定多个处理规则，或者多个匹配规则匹配同一个节点时，均会出现一个节点执行多个处理规则的情况。此时，Digester的处理方式：开始读取节点时按照注册顺序执行处理规则，而完成读取时按照反向顺序执行，即先进后出的规则。\n3.2.4 处理规则 处理规则需要实现接口org.apache.commoms.digester.Rule，该接口定义了模式匹配时触发的事件方法。\n3.2.4 示例程序 由于Digester已经提供了常见处理规则的工厂方法，因此，直接嗲用相关方法即可。整个处理过程都不需要手动为何对象输行和对象间关系，不需要解析XML Dom。\n3.3 创建Server 3.3.1 Server的解析 从此处开始涉及到源码。已搭建好源码阅读环境，粗略看了一下内容过多，暂不深入。\n","permalink":"https://haokiu.com/blog/a9dcb2a7a21d49dea965eedc7e169c79/","summary":"第2章 Tomcat总体架构 系统设计及中间件设计时的参考：生命周期管理、可扩展的容器组件设计、类加载方式。\n2.1 总体设计 如何设计一个应用服务器？\n2.1.1 Server 最基本的功能：接收请求，业务处理，返回响应。\n两个方法：\nstart()：启动服务器，打开Socket链接，监听端口，负责接收请求，处理及返回。 stop()：停止服务器并释放网络资源。 作为嵌入在应用系统中的远程请求处理方案，且访问量低时可行。但作为应用服务器不可行。\n2.1.2 Connector和Container 请求监听与请求处理放到一起扩展性差。\nConnector负责监听，返回。\nContainer负责处理请求。\n均分别拥有自己的start()和stop()方法来加载和释放自己维护的资源。\n明显的缺陷：如何让Connector与Container对应？可以维护一个复杂关系映射，但是并不必需。Container设计足够灵活。\n引入Service，负责维护多个Connector和一个Container。\n在Tomcat中，Container是一个更加通用的概念。为了与Tomcat中的组件命名一致，所以重新命名为Engine，用以表示整个Servlet引擎。\nEngine表示整个Servlet引擎。Server表示整个Servlet容器。\n2.1.3 Container设计 应用服务器是用来部署并运行Web应用的，是一个运行环境，而不是独立的业务处理系统。因此需要在Engine容器中支持管理Web应用，当接收到Connector的处理请求时，Engine容器能够找到一个合适的Web应用来处理。\n使用一个Context来表示一个Web应用，并且一个Engine可以包含多个Context。\n虚拟主机，加入Host。一个Host可以包含多个Context。\nTomcat的设计中Engine可以包含Host也可以包含Context，这是由具体的Engine实现确定的。Tomcat提供的默认实现StandardEngine只能包含Host。\n一个Web应用可以包含多个Servlet实例。在Tomcat中，Servlet定义被称为Wrapper。\n“容器”的作用都是处理请求并返回响应数据。所以引入一个Container接口：addchild()添加子容器，backgroundProcess()实现文件变更的扫描。\n2.1.4 Lifecycle 所有组件均存在启动、停止这两个生命周期方法，可在此基础上扩展生命周期管理的方法，即对于生命周期管理进行一次接口抽象。\n将Server接口替换为Lifecycle接口：\nInit()：初始化组件 start()：启动组件 stop()：停止组件 destory()：销毁组件 addLifecycleListener：添加事件监听器（用于监听组件的状态变化） removeLifecycleListener：删除 Tomcat核心组件的默认实现均继承自LifecycleBeanBase抽象类，该类不但负责组件各个状态的转换和事件处理，还将组件自身注册为MBean，以便通过Tomcat的管理工具进行动态维护。\n2.1.5 Pipeline和Valve 以上设计以保证核心架构的了可伸缩性和可扩展性。但是还要考虑各个组件的灵活性，使其同样可扩展。\n责任链模式是一种比较好的选择。Tomcat即采用该模式来实现客户端请求的处理。在Tomcat中每个Container组件通过执行一个责任链来完成具体的请求处理。\nPipeline（管道）用于构造责任链，Valve（阀）代表责任链上的每个处理器。Pipeline中维护了一个基础的Valve（位于末端，最后执行）。\nTomcat的每个层级的容器（Engine、Host、Context、Wrapper）均有对应的基础Valve实现，同时维护一个Pipeline实例。即任何层级的容器都可以对请求处理进行可扩展。\n2.1.6 Connector设计 基本功能：\n监听服务器端口，读取来自客户端的请求。 将请求数据按照指定协议进行解析。 根据请求地址匹配正确的容器进行处理。 将响应返回客户端。 Tomcat支持多协议，默认支持HTTP和AJP。同时支持多种I/O方式，包括BIO（8.5之后移除）、NIO、APR。而且在Tomcat8之后新增了对NIO2和HTTP/2协议的支持。因此对协议和I/O进行抽象和建模时需要关注的重点。\n在Tomcat中，ProtocolHandler表示一个协议处理器，其包含一个Endpoint（无此接口，仅有AbstractEndpoint抽象类）用于启动Socket监听，还包含一个Processor用于按照指定协议读取数据，并将请求交由容器处理。\n在Connector启动时，Endpoint会启动线程来监听，并在接收到请求后调用Processor进行数据读取。\n当Processor读取客户端请求后，需要按照请求地址映射到具体的容器进行处理，这个过程即为请求映射。由于Tomcat各个组件采用通用的生命周期管理，而且可以通过管理工具进行状态变更，因此请求映射除考虑映射规则的实现外，还要考虑容器组件的注册与销毁。\nTomcat通过Mapper和MapperListener两个类实现上述功能。前者用于维护容器映射信息，同时按照映射规则（Servlet规范）查找容器。后者实现了ContainerListener和LifecycleListener，用于在容器组件状态发生变更时，注册或者取消对应的容器映射信息。为了实现上述功能，MapperListener实现了Lifecycle接口，当其启动时（在Service启动时启动），会自动作为监听器注册到各个容器组件上，同时将已创建的容器注册到Mapper。\nTomcat通过适配器模式（Adapter）实现了Connector与Mapper、Container的解耦。实现自己的Adapter可以脱离Servlet容器又使用Tomcat链接器。\n2.1.7 Excutor 并发问题的解决方案。采用线程池（默认采用JDK5的线程池，继承自Lifecycle，当作通用组件进行管理）对线程进行统一管理。\n在Tomcat中Excutor由Service维护，因此同一个Service中的组件可以共享一个线程池。\n如果没有定义任何线程池，相关组件（Endpoint）会自动创建线程池，此时线程池不再共享。\n在Tomcat中，Endpoint会启动一组线程来监听Socket端口，当接收到客户端请求后，会创建请求处理对象，并交由线程池处理，由此支持并发处理客户端请求。\n2.1.8 Bootstrap和Catalina 除开前面的核心组件外，还需要提供一套配置环境来支持系统的可配置性，便于通过修改配置来优化应用。\n集群、安全等组件同样重要，但不属于通用概念。\nTomcat通过类Catalina提供了一个Shell程序，用于解析server.xml创建各种组件，同时，负责启动、停止应用服务器（只需要启动Tomcat顶层组件Server）。\nTomcat使用Digester解析XML文件，包括server.xml以及web.xml等。\n最后，Tomcat提供了Bootstrap作为应用服务器启动入口。Bootstrap负责创建Catalina实例，根据执行参数调用Catalina相关方法完成针对应用服务器的操作（启动、停止）。\nBootstrap与Tomcat应用服务器完全松耦合（通过反射调用Catalina实例），它可以直接依赖JRE运行并为Tomcat应用服务器创建共享类加载器，用于构造Catalina实例以及整个Tomcat服务器。\n上述是Tomcat标准的启动方式。但是Server及其子组件代表了应用服务器本身，那么我们可以不通过Bootstrap和Catalina来启动服务器。\nTomcat组件说明：\n组件名称 说明 Server 表示整个Servlet容器，因此Tomcat运行环境中只有唯一一个Server实例 Service Service表示一个或者多个Connector的集合，这些Connector共享同一个Container来处理其请求。在同一个Tomcat实例内可以包含任意多个Service实例，它们彼此独立 Connector 即Tomcat链接器，用于监听并转化Socket请求，同时将读取的Socket请求交由Container处理，支持不同协议以及不同的I/O方式 Container Container表示能够执行客户端请求并返回响应的一类对象。在Tomcat中存在不同级别的容器：Engine、Host、Context、Warpper Engine Engine表示整个Servlet引擎。在Tomcat中，Engine为最高层级的容器对象。尽管Engine不是直接处理请求的容器，确实获取目标容器的入口 Host Hostz作为一类容器，表示Servlet容器中的虚拟机，与一个服务器的网络名有关，如域名等。客户端可以使用这个网络名连接服务器，这个名称必须在DNS服务器上注册。 Context Context作为一类容器，用于表示ServletContext，在Servlet规范中，一个ServletContext即表示一个独立的Web应用 Wrapper Wrapper作为一类容器，用于表示Web应用中动议的Servlet Executor 表示Tomcat组件可以共享的线程池 2.2 Tomcat启动 Tomcat默认实现在相关概念的基础上结合生命周期管理监听器完成了大量的启动工作。","title":"第2章 Tomcat总体架构"},{"content":"第6章 深入分析ClassLoader工作机制 三个作用：\n将Class加载到JVM中； 审查每个类应该由谁加载（双亲委派）； 将CLass字节码重新解析成JVM统一要求的格式。 6.1 ClassLoader类结构解析 defineClass方法：将byte字节流解析成JVM能够识别的Class对象。意味着不仅仅可以通过class文件实例化对象。调用此方法生成的Class对象还没有resolve，resolve会在对象真正实例化时才进行。\nfindClass方法：通过直接覆盖ClassLoader父类的findClass方法来实现类的加载规则，从而取得要加载的字节码。然后调用defineClass方法生成类的Class对象。如果想在类被加载到JVM的时候就被链接（Link），那么可以接着调用另外一个resolveClass方法。\n如果想实现自己的ClassLader，一般都会继承URLClassLoader。\n6.2 ClassLoader的等级加载机制 双亲委派。\n（1）Bootstrap ClassLoader，主要加载JVM自身工作需要的类，完全由JVM自己控制。（既没有更高一级的父加载器，也没有子加载器）。\n（2）ExtClassLoader，并不是JVM亲自实现，加载System.getProperty(“java.ext.dirs”)目录下的类。\n（3）AppClassLoader，父类是ExtClassLoader。加载System.getProperty(“java.class.path”)目录下的类都可以被其加载。\n实现自己的类加载器，都必须最终调用getSystemClassLoader()作为父加载器。而此方法获取到的就是AppClassLoader。\n注意Bootstrap ClassLoader并不是如其他文章所说，而是其并无子类也无父类。ExtClassLoader并没有父类加载器。\nExtClassLoader和AppClassLoader都继承了URLClassloader类，而URLClassLoader又实现了抽象类ClassLoader，在创建Launcher对象时会首先创建ExtClassLoader，然后讲ExtClassLoader对象作为父加载器创建AppClassLoader对象。所以如果在Java应用中没有定义其他的ClassLoader，那么除了System.getProperty(“java.ext.dirs”)目录下的类是由ExtClassloader加载，其他类都是由AppClassLoader加载。\n加载class文件到内存的两种方式：隐式，显式。\n6.3 如何加载class文件 加载、验证、准备、解析、初始化。\n第13章 Spring框架的设计理念与设计模式分析 13.1 Spring的骨骼架构 三个核心组件：Core、Context和Bean。\n13.1.1 Spring的设计理念 最核心：Bean。（面向Bean编程）\n解决了一个关键问题：把对象之间的依赖关系转而用配置文件来管理（依赖注入）。\nSpring通过把对象包装在Bean中，从而达到管理这些对象及做一系列额外操作的目的。\n这种设计策略完全类似于OOP的设计理念。构建一个数据结构，然后根据这个数据结构设计它的生存环境，并让它在这个环境中按照一定的规律不停地运动，在它们地不停运动中设计一个系列于环境或者与其他各地完成信息交换。（同时也是大多数框架地设计理念）\n13.1.12 核心组件如何协同工作 Context负责发现每个Bean之间的关系，建立关系并且维护关系。所以Context就是一个Bean关系的集合，也叫Ioc容器。\nCore就是发现、建立和维护每个Bean之间的关系所需要的一系列工具。（也就是一些Util）\n13.2 核心组件详解 13.2.1 Bean组件 包：org.springframework.beans。这个包下的类主要解决三件事：Bean的定义、Bean的创建及对Bean的解析。（使用者只需关心创建）\nSpring是典型的工厂模式，工厂的继承层次关系图如下：\n顶级接口BeanFactory有3个子接口：ListableBeanFactory、HierarchicalBeanFantory和AutowireCapableBeanFactory。\nDefaultListableBeanFactory实现了所有的结构。\n定义多接口的原因：每个接口有不同的使用场景，主要是为了区分Spring内部对象的传递和转化过程中，对对象的数据访问所作的限制。例如，ListableBeanFactory接口标识这些Bean是可列表的，HierarchicalBeanFactory表示这些Bean是有继承关系的，AutowireCapableBeanFactory接口定义Bean的自动装配规则。4个接口共同定义了Bean的集合、Bean之间的关系和Bean的行为。\nBean的定义主要有Beandefinition描述：\nBean是配置文件信息中\u0026lt;bean/\u0026gt;节点信息的转化。Spring解析完成后，内部就是一个BeanDefinition对象。\nBean的解析过程过于繁琐，不赘述。\n13.2.2 Context组件 ApplicationContext继承了BeanFactory。\nApplicationContext的子类主要包含两个方面：\nConfigurableApplicationContext表示该Context是可修改的，也就是构建Context中，用户可以动态添加或修改已有的配置信息。 WebApplication，用于Web，可以直接访问Servletcontext。 ApplicationContext必须完成的事情：\n标识一个应用环境 利用BeanFactory创建Bean对象 保存对象关系表 能够捕获各种事件 13.2.3 Core组件 其中有很多关键类，一个重要的组成部分就是定义了资源的访问方式。\nResource类相关：封装了各种可能的资源类型，也就是说对使用者来说屏蔽了文件类型的不同。通过继承InputStreamSource接口，在这个接口中有个getInputStream方法，返回InputStream类，所有资源都可以通过InputStream来获取，及屏蔽了资源的提供者。\nContext把资源的加载、解析和描述工作委托给了ResourcePatternResolver类来完成。\n13.2.4 Ioc容器如何工作 如何创建BeanFactory工厂 refresh方法。源码已阅就不贴了。步骤如下：\n（1）构建BeanFactory\n（2）注册可能感兴趣的事件\n（3）创建Bean实例对象\n（4）出发被监听的事件\n如何创建Bean实例并构建Bean的关系网 详见源码。\nIoc容器的扩展点 BeanFactoryPostProcessor和BeanPostProcessor，分别在构建BeanFactory和构建Be\u0026rsquo;an对象时调用。还有就是InitPostProcessor和DisposableBean，它们分别在Bean实例创建和销毁时被调用。用户可以实现在这些接口中定义的方法，Spring会在适当的时候调用他们。还有一个是FactoryBean。（会扩展是精通Spring的第一步）\nIoc容器如何为我所用 扩展点。通过扩展点来改变Spring的通用行为。（AOP是一个例子，可以作为参考）\n13.3 Spring中AOP的特性详解 13.3.1 动态代理的实现原理 java.lang.reflect.Proxy。\n重点看公有方法。\n阅读源码部分略。\n13.2.2 Spring AOP如何实现 13.4 设计模式解析之代理模式 给某一个对象创建一个代理对象，有代理对象控制对原对象的引用，而创建代理对象之后可以再调用时增加一些额外的操作。\n13.5 设计模式解析之策略模式 CGLIB与JDK动态代理的选择，就是策略模式的一种实现。\n","permalink":"https://haokiu.com/blog/eec901917e884002a43f917c02f47dd9/","summary":"第6章 深入分析ClassLoader工作机制 三个作用：\n将Class加载到JVM中； 审查每个类应该由谁加载（双亲委派）； 将CLass字节码重新解析成JVM统一要求的格式。 6.1 ClassLoader类结构解析 defineClass方法：将byte字节流解析成JVM能够识别的Class对象。意味着不仅仅可以通过class文件实例化对象。调用此方法生成的Class对象还没有resolve，resolve会在对象真正实例化时才进行。\nfindClass方法：通过直接覆盖ClassLoader父类的findClass方法来实现类的加载规则，从而取得要加载的字节码。然后调用defineClass方法生成类的Class对象。如果想在类被加载到JVM的时候就被链接（Link），那么可以接着调用另外一个resolveClass方法。\n如果想实现自己的ClassLader，一般都会继承URLClassLoader。\n6.2 ClassLoader的等级加载机制 双亲委派。\n（1）Bootstrap ClassLoader，主要加载JVM自身工作需要的类，完全由JVM自己控制。（既没有更高一级的父加载器，也没有子加载器）。\n（2）ExtClassLoader，并不是JVM亲自实现，加载System.getProperty(“java.ext.dirs”)目录下的类。\n（3）AppClassLoader，父类是ExtClassLoader。加载System.getProperty(“java.class.path”)目录下的类都可以被其加载。\n实现自己的类加载器，都必须最终调用getSystemClassLoader()作为父加载器。而此方法获取到的就是AppClassLoader。\n注意Bootstrap ClassLoader并不是如其他文章所说，而是其并无子类也无父类。ExtClassLoader并没有父类加载器。\nExtClassLoader和AppClassLoader都继承了URLClassloader类，而URLClassLoader又实现了抽象类ClassLoader，在创建Launcher对象时会首先创建ExtClassLoader，然后讲ExtClassLoader对象作为父加载器创建AppClassLoader对象。所以如果在Java应用中没有定义其他的ClassLoader，那么除了System.getProperty(“java.ext.dirs”)目录下的类是由ExtClassloader加载，其他类都是由AppClassLoader加载。\n加载class文件到内存的两种方式：隐式，显式。\n6.3 如何加载class文件 加载、验证、准备、解析、初始化。\n第13章 Spring框架的设计理念与设计模式分析 13.1 Spring的骨骼架构 三个核心组件：Core、Context和Bean。\n13.1.1 Spring的设计理念 最核心：Bean。（面向Bean编程）\n解决了一个关键问题：把对象之间的依赖关系转而用配置文件来管理（依赖注入）。\nSpring通过把对象包装在Bean中，从而达到管理这些对象及做一系列额外操作的目的。\n这种设计策略完全类似于OOP的设计理念。构建一个数据结构，然后根据这个数据结构设计它的生存环境，并让它在这个环境中按照一定的规律不停地运动，在它们地不停运动中设计一个系列于环境或者与其他各地完成信息交换。（同时也是大多数框架地设计理念）\n13.1.12 核心组件如何协同工作 Context负责发现每个Bean之间的关系，建立关系并且维护关系。所以Context就是一个Bean关系的集合，也叫Ioc容器。\nCore就是发现、建立和维护每个Bean之间的关系所需要的一系列工具。（也就是一些Util）\n13.2 核心组件详解 13.2.1 Bean组件 包：org.springframework.beans。这个包下的类主要解决三件事：Bean的定义、Bean的创建及对Bean的解析。（使用者只需关心创建）\nSpring是典型的工厂模式，工厂的继承层次关系图如下：\n顶级接口BeanFactory有3个子接口：ListableBeanFactory、HierarchicalBeanFantory和AutowireCapableBeanFactory。\nDefaultListableBeanFactory实现了所有的结构。\n定义多接口的原因：每个接口有不同的使用场景，主要是为了区分Spring内部对象的传递和转化过程中，对对象的数据访问所作的限制。例如，ListableBeanFactory接口标识这些Bean是可列表的，HierarchicalBeanFactory表示这些Bean是有继承关系的，AutowireCapableBeanFactory接口定义Bean的自动装配规则。4个接口共同定义了Bean的集合、Bean之间的关系和Bean的行为。\nBean的定义主要有Beandefinition描述：\nBean是配置文件信息中\u0026lt;bean/\u0026gt;节点信息的转化。Spring解析完成后，内部就是一个BeanDefinition对象。\nBean的解析过程过于繁琐，不赘述。\n13.2.2 Context组件 ApplicationContext继承了BeanFactory。\nApplicationContext的子类主要包含两个方面：\nConfigurableApplicationContext表示该Context是可修改的，也就是构建Context中，用户可以动态添加或修改已有的配置信息。 WebApplication，用于Web，可以直接访问Servletcontext。 ApplicationContext必须完成的事情：\n标识一个应用环境 利用BeanFactory创建Bean对象 保存对象关系表 能够捕获各种事件 13.2.3 Core组件 其中有很多关键类，一个重要的组成部分就是定义了资源的访问方式。\nResource类相关：封装了各种可能的资源类型，也就是说对使用者来说屏蔽了文件类型的不同。通过继承InputStreamSource接口，在这个接口中有个getInputStream方法，返回InputStream类，所有资源都可以通过InputStream来获取，及屏蔽了资源的提供者。\nContext把资源的加载、解析和描述工作委托给了ResourcePatternResolver类来完成。\n13.2.4 Ioc容器如何工作 如何创建BeanFactory工厂 refresh方法。源码已阅就不贴了。步骤如下：\n（1）构建BeanFactory\n（2）注册可能感兴趣的事件\n（3）创建Bean实例对象\n（4）出发被监听的事件\n如何创建Bean实例并构建Bean的关系网 详见源码。\nIoc容器的扩展点 BeanFactoryPostProcessor和BeanPostProcessor，分别在构建BeanFactory和构建Be\u0026rsquo;an对象时调用。还有就是InitPostProcessor和DisposableBean，它们分别在Bean实例创建和销毁时被调用。用户可以实现在这些接口中定义的方法，Spring会在适当的时候调用他们。还有一个是FactoryBean。（会扩展是精通Spring的第一步）\nIoc容器如何为我所用 扩展点。通过扩展点来改变Spring的通用行为。（AOP是一个例子，可以作为参考）\n13.3 Spring中AOP的特性详解 13.3.1 动态代理的实现原理 java.lang.reflect.Proxy。\n重点看公有方法。\n阅读源码部分略。\n13.2.2 Spring AOP如何实现 13.4 设计模式解析之代理模式 给某一个对象创建一个代理对象，有代理对象控制对原对象的引用，而创建代理对象之后可以再调用时增加一些额外的操作。\n13.5 设计模式解析之策略模式 CGLIB与JDK动态代理的选择，就是策略模式的一种实现。","title":"第6章 深入分析ClassLoader工作机制"},{"content":"6.4字节码指令简介 Java虚拟机的指令由一个字节长度的、代表着某种特定操作含义的数字（称为操作码，Opcode）以及跟随其后的零至多个代表此操作所需参数（称为操作数，Operands）而构成。由于Java虚拟机采用面向操作数栈而不是寄存器的架构，所以大多数的指令都不包含操作数，而只有一个操作码。\n6.4.1 字节码与数据类型 Java虚拟机的指令集中，大多数的指令都包含了其操作数所对应的数据类型信息。\n如果每一种与数据类型相关的指令都支持Java虚拟机所有运行时数据类型的话，那指令的数量恐怕就会超出一个字节所能表示的数量范围了\n前面的被系统吞了 之后再补上\n第8章 虚拟机字节码执行系统 8.1概述 8.2 运行时栈帧结构 8.2.1 局部变量表 是一组变量存储空间，用于存放方法参数和方法内部定义的局部变量。\n用于存放方法参数和方法内部定义的局部变量。\n容量以变量槽（Variable Slot）为最小单位，虚拟机规范中并没有明确指明一个Slot应占用的内存空间大小，知识很有导向性地说道每个Slot都应该能存放一个boolean、byte、char、short、int、float、reference或returnAddress类型的数据。\n只要保证计时在64位虚拟机中使用了64位的物理内存空间去实现一个Slot，虚拟机仍要使用对齐和不败的手段让Slot在外观上看起来与32位虚拟机中的一致。\nJava中占用32位以内的数据类型有boolean、byte、char、short、int、float、reference和returnAddress8种类型。（Java语言与Java虚拟机种的剧本数据类型是存在本质差别的）。reference类型表示对一个对象实例的引用。虚拟机规范没有指明长度和结构。但需要做到如下两点：\n从引用中直接或间接地查找到对象在Java堆中的数据存放的起始地址索引； 引用中直接或简介地查找到对象所属数据类型在方法区中地存储的类型信息，否则无法实现Java语言规范中定义的语法约束。 returnAddress类型目前已经很少见了，为字节码指令jsr、jsr_w和ret服务的，指向一条字节码指令的地址，很古老的Java虚拟机曾经使用这几条指令来实现异常处理，现在已经由异常表替代。\nJava中明确的64位的数据类型只有long和double两种。分割存储的做法与“long和double的非原子性协定”类似。\n但在局部变量表中不会引起数据安全问题（线程私有）。\n索引定位。访问32位数据类型的变量，索引n就代表了使用第n个Slot。64位则会同时使用n和n+1两个Slot。对于两个相邻的共同存放一个64位数据的两个Slot，不允许采用任何方式单独访问其中的某一个。\n在方法执行时，如果执行的实例（非static），局部变量表中第0位索引的Slot默认时用于传递方法所属对象实例的引用，在方法中可以通过关键字“this”来访问到这个隐含的参数。\n为了尽可能节省栈帧空间，局部变量表中的Slot是可以重用的，方法中定义的变量，其作用域并不一定会覆盖整个方法体。副作用：某些情况下会直接影响到GC。\n实例，placeholder能否被回收的根本原因是：局部变量表中的Slot是否还存有关于placeholder数组对象的引用。\n局部变量表是GC Roots的一部分。把不用的占用了大量内存的变量手动设置为null值。\n但冲编码角度讲，以恰当的变量作用域来控制变量回收时间才是最优雅的解决方法。\n———————————待补充———————————\n局部变量不负初值会编译不通过。\n","permalink":"https://haokiu.com/blog/499b1754f0844c299d9bf24652161845/","summary":"6.4字节码指令简介 Java虚拟机的指令由一个字节长度的、代表着某种特定操作含义的数字（称为操作码，Opcode）以及跟随其后的零至多个代表此操作所需参数（称为操作数，Operands）而构成。由于Java虚拟机采用面向操作数栈而不是寄存器的架构，所以大多数的指令都不包含操作数，而只有一个操作码。\n6.4.1 字节码与数据类型 Java虚拟机的指令集中，大多数的指令都包含了其操作数所对应的数据类型信息。\n如果每一种与数据类型相关的指令都支持Java虚拟机所有运行时数据类型的话，那指令的数量恐怕就会超出一个字节所能表示的数量范围了\n前面的被系统吞了 之后再补上\n第8章 虚拟机字节码执行系统 8.1概述 8.2 运行时栈帧结构 8.2.1 局部变量表 是一组变量存储空间，用于存放方法参数和方法内部定义的局部变量。\n用于存放方法参数和方法内部定义的局部变量。\n容量以变量槽（Variable Slot）为最小单位，虚拟机规范中并没有明确指明一个Slot应占用的内存空间大小，知识很有导向性地说道每个Slot都应该能存放一个boolean、byte、char、short、int、float、reference或returnAddress类型的数据。\n只要保证计时在64位虚拟机中使用了64位的物理内存空间去实现一个Slot，虚拟机仍要使用对齐和不败的手段让Slot在外观上看起来与32位虚拟机中的一致。\nJava中占用32位以内的数据类型有boolean、byte、char、short、int、float、reference和returnAddress8种类型。（Java语言与Java虚拟机种的剧本数据类型是存在本质差别的）。reference类型表示对一个对象实例的引用。虚拟机规范没有指明长度和结构。但需要做到如下两点：\n从引用中直接或间接地查找到对象在Java堆中的数据存放的起始地址索引； 引用中直接或简介地查找到对象所属数据类型在方法区中地存储的类型信息，否则无法实现Java语言规范中定义的语法约束。 returnAddress类型目前已经很少见了，为字节码指令jsr、jsr_w和ret服务的，指向一条字节码指令的地址，很古老的Java虚拟机曾经使用这几条指令来实现异常处理，现在已经由异常表替代。\nJava中明确的64位的数据类型只有long和double两种。分割存储的做法与“long和double的非原子性协定”类似。\n但在局部变量表中不会引起数据安全问题（线程私有）。\n索引定位。访问32位数据类型的变量，索引n就代表了使用第n个Slot。64位则会同时使用n和n+1两个Slot。对于两个相邻的共同存放一个64位数据的两个Slot，不允许采用任何方式单独访问其中的某一个。\n在方法执行时，如果执行的实例（非static），局部变量表中第0位索引的Slot默认时用于传递方法所属对象实例的引用，在方法中可以通过关键字“this”来访问到这个隐含的参数。\n为了尽可能节省栈帧空间，局部变量表中的Slot是可以重用的，方法中定义的变量，其作用域并不一定会覆盖整个方法体。副作用：某些情况下会直接影响到GC。\n实例，placeholder能否被回收的根本原因是：局部变量表中的Slot是否还存有关于placeholder数组对象的引用。\n局部变量表是GC Roots的一部分。把不用的占用了大量内存的变量手动设置为null值。\n但冲编码角度讲，以恰当的变量作用域来控制变量回收时间才是最优雅的解决方法。\n———————————待补充———————————\n局部变量不负初值会编译不通过。","title":"第8章 虚拟机字节码执行系统"},{"content":"本书特色 结合JDK源码介绍了Java并发框架、线程池的实现原理。\n不仅仅局限于Java层面，更深入JVM，CPU。\n结合线上应用，给出了一些并发编程实战技巧。\n第一章 并发编程的挑战 如果希望通过多线程执行任务让程序运行得更快，会面临非常多得挑战，如上下文切换的问题、死锁的问题，以及受限于硬件和软件的资源限制问题。\n1.1 上下文切换 单核处理器支持多线程执行代码，CPU通过给每个线程分配COU时间片来实现。\n时间片非常短，所以CPU通过不停的切换线程执行，让我们感觉多个线程是同时执行的，几十毫秒ms。\nCPU通过时间片分配算法来循环执行任务。任务从保存到加载的过程就是一次上下文切换。\n上下文切换回影响多线程的执行速度。\n1.1.1 多线程一定快吗 累加，并发执行的速度比串行慢是因为线程有创建和上下文切换的开销。\n1.1.2 测试上下文切换次数和时长 Lmbech3可以测量上下文切换的时长。\ncmstat可以测量上下文切换的次数。\nCS(Content Switch)表示上下文切换的次数。\n1.1.3 如何减少上下文切换 较少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。\n无所并发编程：多线程竞争锁时，回引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。 CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样回造成大量线程都处于等待状态。 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。 1.1.4 减少上下文切换实战 通过见扫线上大量WAITING的线程，来减少上下文切换次数。\n1.2 死锁 避免死锁的几个常见方法：\n避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的的情况。 1.3 资源限制的挑战 （1）什么是资源限制\n资源是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。\n硬件资源限制：带宽的上传/下载速读、硬盘读写速度和CPU的处理速度。\n软件资源限制：数据库的连接数和scoket连接数。\n（2）资源限制引发的问题\n在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行，但是如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的问题。\n（3）如何解决资源限制的问题\n对于硬件资源限制，可以考虑使用集群并行执行程序。既然单机的资源有限制，那么就让程序在多级上运行。比如使用ODPS、Hadoop或者自己搭建服务器集群，不同的机器吹不同的数据。可以通过“数据ID%机器数”，计算得到一个机器编号，然后由对应编号的机器处理这笔数据。\n对于软件资源限制，可以考虑使用资源池将资源复用。比如使用连接池将数据库和Socket连接复用，或者调用对方webservice接口获取数据时，只建立一个连接。\n（4）在资源限制情况下进行并发编程\n如何在资源限制的情况下，让程序执行得更快呢？方法就是，根据不同得资源限制调整程序得并发度。\n1.4 本章小结 本章介绍了在进行并发编程时会遇到的几个挑战，并给出了一些建议。\n第二章 Java并发机制的底层实现原理 JVM执行字节码，最终需要转化为汇编指令在CPU上执行，Java中所使用得并发机制依赖于JVM得实现和CPU的指令。\n2.1 volatile的应用 1.volatile的定义与实现原理 volatile是轻量级的synchronized，在多处理器开发中保证了共享变量的“可见性”。使用得当的话，比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。本文分析Intel处理器是如何实现volatile的。\nCPU的术语定义：\n术语 英文单词 术语描述 内存屏障 memory barriers 是一组处理器指令，用于事项对内存操作的顺序限制 缓冲行 cache line 缓存中可以分配的最小存储单位。处理器填写缓存线时会加载整个缓存线，需要使用多个主内存读周期 原子操作 atomic line 不可终端的一个或一系列操作 缓存行填充 cache line fill 当处理器试别到内存中读取操作数时可缓存的，处理器读取整个缓存行到适当的缓存（L1,L2,L3的或所有） 缓存命中 cache hit 如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存读取 写命中 write hit 当处理器将操作数写回到一个内存缓存的区域时，它首先回检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回到内存，这个操作被称为写命中 写缺失 write misses the cache 一个有效的缓存行被写入到不存在的内存区域 为了提高处理速度，处理器不直接个内存进行通信，二十先将系统内存的数据督导内部缓存（L1,L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会像处理器发送一条Lock前缀的指令，将这个变量所在缓存的数据写回到系统内存。但是就算写回到内存，如过其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，再多处理器下，未了保证各个处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的换粗你一直，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，回重新从系统内存中把数据读到处理器缓存里。\nLock前缀的指令在多核处理器下会引发两件事情：\n将当前处理器缓存行的数据写回到系统内存 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效 volatile的两条实现原则：\nLock前缀指令会引起处理器缓存回写到内存 一个处理器的缓存回写到内存会导致其他处理器的缓存无效 2.volatile的使用优化 追加字节到64字节，因为高速缓存行普遍是64字节宽，不支持部分填充缓存行。如果队列的头节点和尾节点都不足64字节的话，处理器会将它们都读到同一个高速缓存行中，在多处理器下每个处理器都会缓存同样的头、尾节点，当一个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致其他处理器不能访问自己告诉缓存中的尾节点，而队列的入队和出队操作则需要不停修改头节点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。\n追加到64字节的方式来填满告诉缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存行，使头，尾节点在修改时不会互相锁定。\n一下两种场景不适用：\n缓存行非64字节宽的处理器。 共享变量不会被频繁地写。 Java7之后不能生效，会淘汰或重新排列无用字段，需要采用其他追加字节的方式。\n2.2 synchronized的实现原理与应用 syschronized实现同步的基础：Java中的每一个对象都可以作为锁。具体表现以下3种形式：\n对于普通同步方法，锁是当前实例对象。 对于静态同步方法，锁是当前类的Class对象。 对于同步方法块，锁是Synchronized括号里配置的对象。 当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。\nJVM基于进入和退出Monitor对象来实现方法同步和代码块同步。\nmonnitorenter指令===\u0026gt;同步代码块开头，monitorexit===\u0026gt;方法结束处和异常处。两者配对。任何对象都有一个monitor与之关联，当一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。\n2.2.1 Java对象头 synchronized用的锁时存在Java对象头里的。\n长度 内容 说明 32/64bit Mark Word 存储对象的hashCode或锁信息 32/64bit Class Metadata Address 存储到对象类型数据的指针 32/32bit Array leng 数组的长度（如果当前对象是数组） Mark Word的默认存储结构：\n锁状态 25bit 4bit 1bit偏向锁 2bit锁标志位 无锁状态 对象的hashCode 对象分代年龄 0 01 运行期，Mark Word里存储的数据会随着锁标志位的变化而变化。\n2.2.2 锁的升级与对比 锁从低到高四个状态：无状态所、偏向锁状态、轻量级锁状态和重量级锁状态。为了提高获得锁和释放锁的效率，锁可以升级但不能降级。\n偏向锁 目的：为了让线程获得锁的代价更低。\n当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头地Mar Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。\n（1）偏向锁的撤销\n","permalink":"https://haokiu.com/blog/f6ad1487667e4880973e3b21505810be/","summary":"本书特色 结合JDK源码介绍了Java并发框架、线程池的实现原理。\n不仅仅局限于Java层面，更深入JVM，CPU。\n结合线上应用，给出了一些并发编程实战技巧。\n第一章 并发编程的挑战 如果希望通过多线程执行任务让程序运行得更快，会面临非常多得挑战，如上下文切换的问题、死锁的问题，以及受限于硬件和软件的资源限制问题。\n1.1 上下文切换 单核处理器支持多线程执行代码，CPU通过给每个线程分配COU时间片来实现。\n时间片非常短，所以CPU通过不停的切换线程执行，让我们感觉多个线程是同时执行的，几十毫秒ms。\nCPU通过时间片分配算法来循环执行任务。任务从保存到加载的过程就是一次上下文切换。\n上下文切换回影响多线程的执行速度。\n1.1.1 多线程一定快吗 累加，并发执行的速度比串行慢是因为线程有创建和上下文切换的开销。\n1.1.2 测试上下文切换次数和时长 Lmbech3可以测量上下文切换的时长。\ncmstat可以测量上下文切换的次数。\nCS(Content Switch)表示上下文切换的次数。\n1.1.3 如何减少上下文切换 较少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。\n无所并发编程：多线程竞争锁时，回引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法取模分段，不同的线程处理不同段的数据。 CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样回造成大量线程都处于等待状态。 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。 1.1.4 减少上下文切换实战 通过见扫线上大量WAITING的线程，来减少上下文切换次数。\n1.2 死锁 避免死锁的几个常见方法：\n避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的的情况。 1.3 资源限制的挑战 （1）什么是资源限制\n资源是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。\n硬件资源限制：带宽的上传/下载速读、硬盘读写速度和CPU的处理速度。\n软件资源限制：数据库的连接数和scoket连接数。\n（2）资源限制引发的问题\n在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行，但是如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的问题。\n（3）如何解决资源限制的问题\n对于硬件资源限制，可以考虑使用集群并行执行程序。既然单机的资源有限制，那么就让程序在多级上运行。比如使用ODPS、Hadoop或者自己搭建服务器集群，不同的机器吹不同的数据。可以通过“数据ID%机器数”，计算得到一个机器编号，然后由对应编号的机器处理这笔数据。\n对于软件资源限制，可以考虑使用资源池将资源复用。比如使用连接池将数据库和Socket连接复用，或者调用对方webservice接口获取数据时，只建立一个连接。\n（4）在资源限制情况下进行并发编程\n如何在资源限制的情况下，让程序执行得更快呢？方法就是，根据不同得资源限制调整程序得并发度。\n1.4 本章小结 本章介绍了在进行并发编程时会遇到的几个挑战，并给出了一些建议。\n第二章 Java并发机制的底层实现原理 JVM执行字节码，最终需要转化为汇编指令在CPU上执行，Java中所使用得并发机制依赖于JVM得实现和CPU的指令。\n2.1 volatile的应用 1.volatile的定义与实现原理 volatile是轻量级的synchronized，在多处理器开发中保证了共享变量的“可见性”。使用得当的话，比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。本文分析Intel处理器是如何实现volatile的。\nCPU的术语定义：\n术语 英文单词 术语描述 内存屏障 memory barriers 是一组处理器指令，用于事项对内存操作的顺序限制 缓冲行 cache line 缓存中可以分配的最小存储单位。处理器填写缓存线时会加载整个缓存线，需要使用多个主内存读周期 原子操作 atomic line 不可终端的一个或一系列操作 缓存行填充 cache line fill 当处理器试别到内存中读取操作数时可缓存的，处理器读取整个缓存行到适当的缓存（L1,L2,L3的或所有） 缓存命中 cache hit 如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存读取 写命中 write hit 当处理器将操作数写回到一个内存缓存的区域时，它首先回检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回到内存，这个操作被称为写命中 写缺失 write misses the cache 一个有效的缓存行被写入到不存在的内存区域 为了提高处理速度，处理器不直接个内存进行通信，二十先将系统内存的数据督导内部缓存（L1,L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会像处理器发送一条Lock前缀的指令，将这个变量所在缓存的数据写回到系统内存。但是就算写回到内存，如过其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，再多处理器下，未了保证各个处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的换粗你一直，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，回重新从系统内存中把数据读到处理器缓存里。\nLock前缀的指令在多核处理器下会引发两件事情：\n将当前处理器缓存行的数据写回到系统内存 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效 volatile的两条实现原则：","title":"第一章 并发编程的挑战"},{"content":"lantern 是一款专业的代理软件，方便更好的使用互联网，输入我的邀请码 46KBX2 来获得三个月的蓝灯专业版！立即下载 https://github.com/getlantern/forum\n","permalink":"https://haokiu.com/blog/g6ADCM/","summary":"lantern 是一款专业的代理软件，方便更好的使用互联网，输入我的邀请码 46KBX2 来获得三个月的蓝灯专业版！立即下载 https://github.com/getlantern/forum","title":"lantern 邀请码"},{"content":"随着JDK 11发布, Oracle同时调整了JDK的授权许可证,里面包含了好几个动作。\n首先, Oracle从JDK 11起把以前的商业特性全部开源给OpenJDK,这样OpenJDK 11和OracleJDK 11的代码和功能,在本质上就是完全相同的(官方原文是Essentially Identical)。\n然后, Oracle宣布以后将会同时发行两个JDK:一个是以GPLV2+CE协议下由Oracle发行的OpenJDK (本书后面章节称其为Oracle OpenJDK) ,另一个是在新的OTN协议下发行的传统的OracleJDK。\n这两个JDK共享绝大部分源码,在功能上是几乎一样的,核心差异是前者可以免费在开发、测试或生产环境中使用，但是只有半年时间的更新支持;后者个人依然可以免费使用，但若在生产环境中商用就必须付费，可以有三年时间的更新支持。\n如果说由此能得出\u0026quot;Java要收费\u0026quot;的结论,那是纯属标题党,最多只能说Oracle在迫使商业用户要么不断升级JDK的版本,要么就去购买商业支持。\nJDK选择建议 JDK8 分情况 8u211和之后的版本商用需付费，JDK 9/10 免费 JDK 11及以上所有版本商用需付费\n免费建议：JDK8 使用 8u202 版本，JDK8 以上版本使用 OpenJDK 或大型机构替代版本Zulu JDK 、Amazon Corretto JDK等\n说明 Java 的版本发布周期变更为每六个月一次 ， 每半年发布一个大版本，每个季度发布一个中间特性版本，Java 9 和 Java 10 这两个被称为“功能性的版本”，两者均只提供半年的技术支持，Java 11 不仅提供了长期支持服务，还将作为 Java 平台的参考实现。Oracle 直到2023年9月都会为 Java 11 提供技术支持，而补丁和安全警告等扩展支持将持续到2026年。所以，Java11 必将是下一代长期使用的版本。\n","permalink":"https://haokiu.com/blog/AWAwA5/","summary":"随着JDK 11发布, Oracle同时调整了JDK的授权许可证,里面包含了好几个动作。\n首先, Oracle从JDK 11起把以前的商业特性全部开源给OpenJDK,这样OpenJDK 11和OracleJDK 11的代码和功能,在本质上就是完全相同的(官方原文是Essentially Identical)。\n然后, Oracle宣布以后将会同时发行两个JDK:一个是以GPLV2+CE协议下由Oracle发行的OpenJDK (本书后面章节称其为Oracle OpenJDK) ,另一个是在新的OTN协议下发行的传统的OracleJDK。\n这两个JDK共享绝大部分源码,在功能上是几乎一样的,核心差异是前者可以免费在开发、测试或生产环境中使用，但是只有半年时间的更新支持;后者个人依然可以免费使用，但若在生产环境中商用就必须付费，可以有三年时间的更新支持。\n如果说由此能得出\u0026quot;Java要收费\u0026quot;的结论,那是纯属标题党,最多只能说Oracle在迫使商业用户要么不断升级JDK的版本,要么就去购买商业支持。\nJDK选择建议 JDK8 分情况 8u211和之后的版本商用需付费，JDK 9/10 免费 JDK 11及以上所有版本商用需付费\n免费建议：JDK8 使用 8u202 版本，JDK8 以上版本使用 OpenJDK 或大型机构替代版本Zulu JDK 、Amazon Corretto JDK等\n说明 Java 的版本发布周期变更为每六个月一次 ， 每半年发布一个大版本，每个季度发布一个中间特性版本，Java 9 和 Java 10 这两个被称为“功能性的版本”，两者均只提供半年的技术支持，Java 11 不仅提供了长期支持服务，还将作为 Java 平台的参考实现。Oracle 直到2023年9月都会为 Java 11 提供技术支持，而补丁和安全警告等扩展支持将持续到2026年。所以，Java11 必将是下一代长期使用的版本。","title":"java 到底要不要收费"},{"content":"neovide 是一个简单的 neovim 用户图像工具，相对于 Neovim 会有一些界面的提升的，但它的功能类似于终端用户界面。\nneovide 的官网：https://github.com/Kethku/neovide。\ngitbhub上有更多关于它的安装及使用教程。\n","permalink":"https://haokiu.com/blog/neovide/","summary":"neovide 是一个简单的 neovim 用户图像工具，相对于 Neovim 会有一些界面的提升的，但它的功能类似于终端用户界面。\nneovide 的官网：https://github.com/Kethku/neovide。\ngitbhub上有更多关于它的安装及使用教程。","title":"Neovide"},{"content":"eth2 相对于 eth1的优势：\n1、提高可扩展性 ETH1.0每秒仅支持15个左右的事务。而ETH2.0升级后最终将被划分为64（将来可能会更多）个分片，理论上可以使网络每秒完成达上千甚至上万笔交易。ETH2.0解决了主网运算能力过于集中的问题，并进一步提高了可扩展性。\n2、环境可持续性 ETH现阶段仍是使用较为主流的PoW工作量证明共识机制来运行及维护网络安全，PoW模式虽然在确保安全性和去中心化程度上具有一定的优势，但对于维护网络安全的节点付出的代价却是昂贵的。最终只有一个节点会找到正确的哈希值，获得记账权和奖励，但全球所有参与其中的节点却都付出了大量的算力和电力，这样的模式不仅效率低且对于环境资源而言是一种浪费。而升级为PoS权益证明共识机制后，ETH将不再依靠大量的算力和电力来维护、运行网络，而是依靠持币权益验证的方式来创建链上的区块和交易。\n","permalink":"https://haokiu.com/blog/eth2/","summary":"eth2 相对于 eth1的优势：\n1、提高可扩展性 ETH1.0每秒仅支持15个左右的事务。而ETH2.0升级后最终将被划分为64（将来可能会更多）个分片，理论上可以使网络每秒完成达上千甚至上万笔交易。ETH2.0解决了主网运算能力过于集中的问题，并进一步提高了可扩展性。\n2、环境可持续性 ETH现阶段仍是使用较为主流的PoW工作量证明共识机制来运行及维护网络安全，PoW模式虽然在确保安全性和去中心化程度上具有一定的优势，但对于维护网络安全的节点付出的代价却是昂贵的。最终只有一个节点会找到正确的哈希值，获得记账权和奖励，但全球所有参与其中的节点却都付出了大量的算力和电力，这样的模式不仅效率低且对于环境资源而言是一种浪费。而升级为PoS权益证明共识机制后，ETH将不再依靠大量的算力和电力来维护、运行网络，而是依靠持币权益验证的方式来创建链上的区块和交易。","title":"eth2 的优势"},{"content":"linux复制文件和目录用cp命令，--parents 参数可以确保不存在目录的创建，比如文件 cp --parents java/doc/readme.md ../doc ，如果目录 doc不存在目录：java/doc则会创建。\n高级操作：\n#查找当前目录下所有.md文件，并将它们复制到DataxDoc目录，如果目录不存在则双肩 find . -name \u0026#34;*.md\u0026#34; | xargs -I {} cp --parents {} ../DataxDoc ","permalink":"https://haokiu.com/blog/a0lZoj/","summary":"linux复制文件和目录用cp命令，--parents 参数可以确保不存在目录的创建，比如文件 cp --parents java/doc/readme.md ../doc ，如果目录 doc不存在目录：java/doc则会创建。\n高级操作：\n#查找当前目录下所有.md文件，并将它们复制到DataxDoc目录，如果目录不存在则双肩 find . -name \u0026#34;*.md\u0026#34; | xargs -I {} cp --parents {} ../DataxDoc ","title":"linux 复制文件，并创建不存在的目录"},{"content":"CassandraReader 插件文档 1 快速介绍 CassandraReader插件实现了从Cassandra读取数据。在底层实现上，CassandraReader通过datastax的java driver连接Cassandra实例，并执行相应的cql语句将数据从cassandra中SELECT出来。\n2 实现原理 简而言之，CassandraReader通过java driver连接到Cassandra实例，并根据用户配置的信息生成查询SELECT CQL语句，然后发送到Cassandra，并将该CQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column的信息，CassandraReader将其拼接为CQL语句发送到Cassandra。\n3 功能说明 3.1 配置样例 配置一个从Cassandra同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;cassandrareader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 9042, \u0026#34;useSSL\u0026#34;: false, \u0026#34;keyspace\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;datax_src\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;textCol\u0026#34;, \u0026#34;blobCol\u0026#34;, \u0026#34;writetime(blobCol)\u0026#34;, \u0026#34;boolCol\u0026#34;, \u0026#34;smallintCol\u0026#34;, \u0026#34;tinyintCol\u0026#34;, \u0026#34;intCol\u0026#34;, \u0026#34;bigintCol\u0026#34;, \u0026#34;varintCol\u0026#34;, \u0026#34;floatCol\u0026#34;, \u0026#34;doubleCol\u0026#34;, \u0026#34;decimalCol\u0026#34;, \u0026#34;dateCol\u0026#34;, \u0026#34;timeCol\u0026#34;, \u0026#34;timeStampCol\u0026#34;, \u0026#34;uuidCol\u0026#34;, \u0026#34;inetCol\u0026#34;, \u0026#34;durationCol\u0026#34;, \u0026#34;listCol\u0026#34;, \u0026#34;mapCol\u0026#34;, \u0026#34;setCol\u0026#34; \u0026#34;tupleCol\u0026#34; \u0026#34;udtCol\u0026#34;, ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true } } } ] } } 3.2 参数说明 host\n描述：Cassandra连接点的域名或ip，多个node之间用逗号分隔。 必选：是 默认值：无 port\n描述：Cassandra端口。 必选：是 默认值：9042 username\n描述：数据源的用户名 必选：否 默认值：无 password\n描述：数据源指定用户名的密码 必选：否 默认值：无 useSSL\n描述：是否使用SSL连接。\n必选：否 默认值：false keyspace\n描述：需要同步的表所在的keyspace。\n必选：是 默认值：无 table\n描述：所选取的需要同步的表。\n必选：是 默认值：无 column\n描述：所配置的表中需要同步的列集合。 其中的元素可以指定列的名称或writetime(column_name)，后一种形式会读取column_name列的时间戳而不是数据。\n必选：是 默认值：无 where\n描述：数据筛选条件的cql表达式，例如: \u0026#34;where\u0026#34;:\u0026#34;textcol=\u0026#39;a\u0026#39;\u0026#34; 必选：否 默认值：无 allowFiltering\n描述：是否在服务端过滤数据。参考cassandra文档中ALLOW FILTERING关键字的相关描述。\n必选：否 默认值：无 consistancyLevel\n描述：数据一致性级别。可选ONE|QUORUM|LOCAL_QUORUM|EACH_QUORUM|ALL|ANY|TWO|THREE|LOCAL_ONE\n必选：否 默认值：LOCAL_QUORUM 3.3 类型转换 目前CassandraReader支持除counter和Custom类型之外的所有类型。\n下面列出CassandraReader针对Cassandra类型转换列表:\nDataX 内部类型 Cassandra 数据类型 Long int, tinyint, smallint,varint,bigint,time Double float, double, decimal String ascii,varchar, text,uuid,timeuuid,duration,list,map,set,tuple,udt,inet Date date, timestamp Boolean bool Bytes blob 请注意:\n目前不支持counter类型和custom类型。 4 性能报告 略\n5 约束限制 5.1 主备同步数据恢复问题 略\n6 FAQ ","permalink":"https://haokiu.com/blog/b0b0444d45c74c8f8b1a9fc4d2af738a/","summary":"CassandraReader 插件文档 1 快速介绍 CassandraReader插件实现了从Cassandra读取数据。在底层实现上，CassandraReader通过datastax的java driver连接Cassandra实例，并执行相应的cql语句将数据从cassandra中SELECT出来。\n2 实现原理 简而言之，CassandraReader通过java driver连接到Cassandra实例，并根据用户配置的信息生成查询SELECT CQL语句，然后发送到Cassandra，并将该CQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column的信息，CassandraReader将其拼接为CQL语句发送到Cassandra。\n3 功能说明 3.1 配置样例 配置一个从Cassandra同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;cassandrareader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 9042, \u0026#34;useSSL\u0026#34;: false, \u0026#34;keyspace\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;datax_src\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;textCol\u0026#34;, \u0026#34;blobCol\u0026#34;, \u0026#34;writetime(blobCol)\u0026#34;, \u0026#34;boolCol\u0026#34;, \u0026#34;smallintCol\u0026#34;, \u0026#34;tinyintCol\u0026#34;, \u0026#34;intCol\u0026#34;, \u0026#34;bigintCol\u0026#34;, \u0026#34;varintCol\u0026#34;, \u0026#34;floatCol\u0026#34;, \u0026#34;doubleCol\u0026#34;, \u0026#34;decimalCol\u0026#34;, \u0026#34;dateCol\u0026#34;, \u0026#34;timeCol\u0026#34;, \u0026#34;timeStampCol\u0026#34;, \u0026#34;uuidCol\u0026#34;, \u0026#34;inetCol\u0026#34;, \u0026#34;durationCol\u0026#34;, \u0026#34;listCol\u0026#34;, \u0026#34;mapCol\u0026#34;, \u0026#34;setCol\u0026#34; \u0026#34;tupleCol\u0026#34; \u0026#34;udtCol\u0026#34;, ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true } } } ] } } 3.2 参数说明 host\n描述：Cassandra连接点的域名或ip，多个node之间用逗号分隔。 必选：是 默认值：无 port\n描述：Cassandra端口。 必选：是 默认值：9042 username\n描述：数据源的用户名 必选：否 默认值：无 password","title":"CassandraReader 插件文档"},{"content":"CassandraWriter 插件文档 1 快速介绍 CassandraWriter插件实现了向Cassandra写入数据。在底层实现上，CassandraWriter通过datastax的java driver连接Cassandra实例，并执行相应的cql语句将数据写入cassandra中。\n2 实现原理 简而言之，CassandraWriter通过java driver连接到Cassandra实例，并根据用户配置的信息生成INSERT CQL语句，然后发送到Cassandra。\n对于用户配置Table、Column的信息，CassandraReader将其拼接为CQL语句发送到Cassandra。\n3 功能说明 3.1 配置样例 配置一个从内存产生到Cassandra导入的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [ {\u0026#34;value\u0026#34;:\u0026#34;name\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;false\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;bool\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;1988-08-08 08:08:08\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;date\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;addr\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;bytes\u0026#34;}, {\u0026#34;value\u0026#34;:1.234,\u0026#34;type\u0026#34;:\u0026#34;double\u0026#34;}, {\u0026#34;value\u0026#34;:12345678,\u0026#34;type\u0026#34;:\u0026#34;long\u0026#34;}, {\u0026#34;value\u0026#34;:2.345,\u0026#34;type\u0026#34;:\u0026#34;double\u0026#34;}, {\u0026#34;value\u0026#34;:3456789,\u0026#34;type\u0026#34;:\u0026#34;long\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;4a0ef8c0-4d97-11d0-db82-ebecdb03ffa5\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;value\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;bytes\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;-838383838,37377373,-383883838,27272772,393993939,-38383883,83883838,-1350403181,817650816,1630642337,251398784,-622020148\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;}, ], \u0026#34;sliceRecordCount\u0026#34;: 10000000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;cassandrawriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 9042, \u0026#34;useSSL\u0026#34;: false, \u0026#34;keyspace\u0026#34;: \u0026#34;stresscql\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;dst\u0026#34;, \u0026#34;batchSize\u0026#34;:10, \u0026#34;column\u0026#34;: [ \u0026#34;name\u0026#34;, \u0026#34;choice\u0026#34;, \u0026#34;date\u0026#34;, \u0026#34;address\u0026#34;, \u0026#34;dbl\u0026#34;, \u0026#34;lval\u0026#34;, \u0026#34;fval\u0026#34;, \u0026#34;ival\u0026#34;, \u0026#34;uid\u0026#34;, \u0026#34;value\u0026#34;, \u0026#34;listval\u0026#34; ] } } } ] } } 3.2 参数说明 host\n描述：Cassandra连接点的域名或ip，多个node之间用逗号分隔。 必选：是 默认值：无 port\n描述：Cassandra端口。 必选：是 默认值：9042 username\n描述：数据源的用户名 必选：否 默认值：无 password\n描述：数据源指定用户名的密码 必选：否 默认值：无 useSSL\n描述：是否使用SSL连接。\n必选：否 默认值：false connectionsPerHost\n描述：客户端连接池配置：与服务器每个节点建多少个连接。\n必选：否 默认值：8 maxPendingPerConnection\n描述：客户端连接池配置：每个连接最大请求数。\n必选：否 默认值：128 keyspace\n描述：需要同步的表所在的keyspace。\n必选：是 默认值：无 table\n描述：所选取的需要同步的表。\n必选：是 默认值：无 column\n描述：所配置的表中需要同步的列集合。 内容可以是列的名称或\u0026quot;writetime()\u0026quot;。如果将列名配置为writetime()，会将这一列的内容作为时间戳。\n必选：是 默认值：无 consistancyLevel\n描述：数据一致性级别。可选ONE|QUORUM|LOCAL_QUORUM|EACH_QUORUM|ALL|ANY|TWO|THREE|LOCAL_ONE\n必选：否 默认值：LOCAL_QUORUM batchSize\n描述：一次批量提交(UNLOGGED BATCH)的记录数大小（条数）。注意batch的大小有如下限制： （1）不能超过65535。 (2) batch中的内容大小受到服务器端batch_size_fail_threshold_in_kb的限制。 (3) 如果batch中的内容超过了batch_size_warn_threshold_in_kb的限制，会打出warn日志，但并不影响写入，忽略即可。 如果批量提交失败，会把这个批量的所有内容重新逐条写入一遍。\n必选：否 默认值：1 3.3 类型转换 目前CassandraReader支持除counter和Custom类型之外的所有类型。\n下面列出CassandraReader针对Cassandra类型转换列表:\nDataX 内部类型 Cassandra 数据类型 Long int, tinyint, smallint,varint,bigint,time Double float, double, decimal String ascii,varchar, text,uuid,timeuuid,duration,list,map,set,tuple,udt,inet Date date, timestamp Boolean bool Bytes blob 请注意:\n目前不支持counter类型和custom类型。 4 性能报告 略\n5 约束限制 5.1 主备同步数据恢复问题 略\n6 FAQ ","permalink":"https://haokiu.com/blog/056d47f442c1471da1b62d7062dd00e2/","summary":"CassandraWriter 插件文档 1 快速介绍 CassandraWriter插件实现了向Cassandra写入数据。在底层实现上，CassandraWriter通过datastax的java driver连接Cassandra实例，并执行相应的cql语句将数据写入cassandra中。\n2 实现原理 简而言之，CassandraWriter通过java driver连接到Cassandra实例，并根据用户配置的信息生成INSERT CQL语句，然后发送到Cassandra。\n对于用户配置Table、Column的信息，CassandraReader将其拼接为CQL语句发送到Cassandra。\n3 功能说明 3.1 配置样例 配置一个从内存产生到Cassandra导入的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [ {\u0026#34;value\u0026#34;:\u0026#34;name\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;false\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;bool\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;1988-08-08 08:08:08\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;date\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;addr\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;bytes\u0026#34;}, {\u0026#34;value\u0026#34;:1.234,\u0026#34;type\u0026#34;:\u0026#34;double\u0026#34;}, {\u0026#34;value\u0026#34;:12345678,\u0026#34;type\u0026#34;:\u0026#34;long\u0026#34;}, {\u0026#34;value\u0026#34;:2.345,\u0026#34;type\u0026#34;:\u0026#34;double\u0026#34;}, {\u0026#34;value\u0026#34;:3456789,\u0026#34;type\u0026#34;:\u0026#34;long\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;4a0ef8c0-4d97-11d0-db82-ebecdb03ffa5\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;value\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;bytes\u0026#34;}, {\u0026#34;value\u0026#34;:\u0026#34;-838383838,37377373,-383883838,27272772,393993939,-38383883,83883838,-1350403181,817650816,1630642337,251398784,-622020148\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;}, ], \u0026#34;sliceRecordCount\u0026#34;: 10000000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;cassandrawriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 9042, \u0026#34;useSSL\u0026#34;: false, \u0026#34;keyspace\u0026#34;: \u0026#34;stresscql\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;dst\u0026#34;, \u0026#34;batchSize\u0026#34;:10, \u0026#34;column\u0026#34;: [ \u0026#34;name\u0026#34;, \u0026#34;choice\u0026#34;, \u0026#34;date\u0026#34;, \u0026#34;address\u0026#34;, \u0026#34;dbl\u0026#34;, \u0026#34;lval\u0026#34;, \u0026#34;fval\u0026#34;, \u0026#34;ival\u0026#34;, \u0026#34;uid\u0026#34;, \u0026#34;value\u0026#34;, \u0026#34;listval\u0026#34; ] } } } ] } } 3.2 参数说明 host\n描述：Cassandra连接点的域名或ip，多个node之间用逗号分隔。 必选：是 默认值：无 port","title":"CassandraWriter 插件文档"},{"content":" DataX DataX 是阿里巴巴集团内被广泛使用的离线数据同步工具/平台，实现包括 MySQL、Oracle、SqlServer、Postgre、HDFS、Hive、ADS、HBase、TableStore(OTS)、MaxCompute(ODPS)、DRDS 等各种异构数据源之间高效的数据同步功能。\nDataX 商业版本 阿里云DataWorks数据集成是DataX团队在阿里云上的商业化产品，致力于提供复杂网络环境下、丰富的异构数据源之间高速稳定的数据移动能力，以及繁杂业务背景下的数据同步解决方案。目前已经支持云上近3000家客户，单日同步数据超过3万亿条。DataWorks数据集成目前支持离线50+种数据源，可以进行整库迁移、批量上云、增量同步、分库分表等各类同步解决方案。2020年更新实时同步能力，2020年更新实时同步能力，支持10+种数据源的读写任意组合。提供MySQL，Oracle等多种数据源到阿里云MaxCompute，Hologres等大数据引擎的一键全增量同步解决方案。\nhttps://www.aliyun.com/product/bigdata/ide\nFeatures DataX本身作为数据同步框架，将不同数据源的同步抽象为从源头数据源读取数据的Reader插件，以及向目标端写入数据的Writer插件，理论上DataX框架可以支持任意数据源类型的数据同步工作。同时DataX插件体系作为一套生态系统, 每接入一套新数据源该新加入的数据源即可实现和现有的数据源互通。\nDataX详细介绍 请参考：DataX-Introduction Quick Start Download DataX下载地址 请点击：Quick Start Support Data Channels DataX目前已经有了比较全面的插件体系，主流的RDBMS数据库、NOSQL、大数据计算系统都已经接入，目前支持数据如下图，详情请点击：DataX数据源参考指南\n类型 数据源 Reader(读) Writer(写) 文档 RDBMS 关系型数据库 MySQL √ √ 读 、写 Oracle √ √ 读 、写 SQLServer √ √ 读 、写 PostgreSQL √ √ 读 、写 DRDS √ √ 读 、写 通用RDBMS(支持所有关系型数据库) √ √ 读 、写 阿里云数仓数据存储 ODPS √ √ 读 、写 ADS √ 写 OSS √ √ 读 、写 OCS √ √ 读 、写 NoSQL数据存储 OTS √ √ 读 、写 Hbase0.94 √ √ 读 、写 Hbase1.1 √ √ 读 、写 Phoenix4.x √ √ 读 、写 Phoenix5.x √ √ 读 、写 MongoDB √ √ 读 、写 Hive √ √ 读 、写 Cassandra √ √ 读 、写 无结构化数据存储 TxtFile √ √ 读 、写 FTP √ √ 读 、写 HDFS √ √ 读 、写 Elasticsearch √ 写 时间序列数据库 OpenTSDB √ 读 TSDB √ √ 读 、写 阿里云DataWorks数据集成 目前DataX的已有能力已经全部融和进阿里云的数据集成，并且比DataX更加高效、安全，同时数据集成具备DataX不具备的其它高级特性和功能。可以理解为数据集成是DataX的全面升级的商业化用版本，为企业可以提供稳定、可靠、安全的数据传输服务。与DataX相比，数据集成主要有以下几大突出特点：\n支持实时同步：\n功能简介：https://help.aliyun.com/document_detail/181912.html 支持的数据源：https://help.aliyun.com/document_detail/146778.html 支持数据处理：https://help.aliyun.com/document_detail/146777.html 离线同步数据源种类大幅度扩充：\n新增比如：DB2、Kafka、Hologres、MetaQ、SAPHANA、达梦等等，持续扩充中 离线同步支持的数据源：https://help.aliyun.com/document_detail/137670.html 具备同步解决方案： 解决方案系统：https://help.aliyun.com/document_detail/171765.html 一键全增量：https://help.aliyun.com/document_detail/175676.html 整库迁移：https://help.aliyun.com/document_detail/137809.html 批量上云：https://help.aliyun.com/document_detail/146671.html 更新更多能力请访问：https://help.aliyun.com/document_detail/137663.html 我要开发新的插件 请点击：DataX插件开发宝典\n项目成员 核心Contributions: 言柏 、枕水、秋奇、青砾、一斅、云时\n感谢天烬、光戈、祁然、巴真、静行对DataX做出的贡献。\nLicense This software is free to use under the Apache License Apache license.\n请及时提出issue给我们。请前往：DataxIssue\n开源版DataX企业用户 长期招聘 联系邮箱：datax@alibabacloud.com 【JAVA开发职位】 职位名称：JAVA资深开发工程师/专家/高级专家 工作年限 : 2年以上 学历要求 : 本科（如果能力靠谱，这些都不是条件） 期望层级 : P6/P7/P8 岗位描述： 1. 负责阿里云大数据平台（数加）的开发设计。 2. 负责面向政企客户的大数据相关产品开发； 3. 利用大规模机器学习算法挖掘数据之间的联系，探索数据挖掘技术在实际场景中的产品应用 ； 4. 一站式大数据开发平台 5. 大数据任务调度引擎 6. 任务执行引擎 7. 任务监控告警 8. 海量异构数据同步 岗位要求： 1. 拥有3年以上JAVA Web开发经验； 2. 熟悉Java的基础技术体系。包括JVM、类装载、线程、并发、IO资源管理、网络； 3. 熟练使用常用Java技术框架、对新技术框架有敏锐感知能力；深刻理解面向对象、设计原则、封装抽象； 4. 熟悉HTML/HTML5和JavaScript；熟悉SQL语言； 5. 执行力强，具有优秀的团队合作精神、敬业精神； 6. 深刻理解设计模式及应用场景者加分； 7. 具有较强的问题分析和处理能力、比较强的动手能力，对技术有强烈追求者优先考虑； 8. 对高并发、高稳定可用性、高性能、大数据处理有过实际项目及产品经验者优先考虑； 9. 有大数据产品、云产品、中间件技术解决方案者优先考虑。 钉钉用户群：\nDataX开源用户交流群\nDataX开源用户交流群2\nDataX开源用户交流群3\nDataX开源用户交流群4\nDataX开源用户交流群5\n","permalink":"https://haokiu.com/blog/dcdba0138c4f45f0a08968ab48edb900/","summary":"DataX DataX 是阿里巴巴集团内被广泛使用的离线数据同步工具/平台，实现包括 MySQL、Oracle、SqlServer、Postgre、HDFS、Hive、ADS、HBase、TableStore(OTS)、MaxCompute(ODPS)、DRDS 等各种异构数据源之间高效的数据同步功能。\nDataX 商业版本 阿里云DataWorks数据集成是DataX团队在阿里云上的商业化产品，致力于提供复杂网络环境下、丰富的异构数据源之间高速稳定的数据移动能力，以及繁杂业务背景下的数据同步解决方案。目前已经支持云上近3000家客户，单日同步数据超过3万亿条。DataWorks数据集成目前支持离线50+种数据源，可以进行整库迁移、批量上云、增量同步、分库分表等各类同步解决方案。2020年更新实时同步能力，2020年更新实时同步能力，支持10+种数据源的读写任意组合。提供MySQL，Oracle等多种数据源到阿里云MaxCompute，Hologres等大数据引擎的一键全增量同步解决方案。\nhttps://www.aliyun.com/product/bigdata/ide\nFeatures DataX本身作为数据同步框架，将不同数据源的同步抽象为从源头数据源读取数据的Reader插件，以及向目标端写入数据的Writer插件，理论上DataX框架可以支持任意数据源类型的数据同步工作。同时DataX插件体系作为一套生态系统, 每接入一套新数据源该新加入的数据源即可实现和现有的数据源互通。\nDataX详细介绍 请参考：DataX-Introduction Quick Start Download DataX下载地址 请点击：Quick Start Support Data Channels DataX目前已经有了比较全面的插件体系，主流的RDBMS数据库、NOSQL、大数据计算系统都已经接入，目前支持数据如下图，详情请点击：DataX数据源参考指南\n类型 数据源 Reader(读) Writer(写) 文档 RDBMS 关系型数据库 MySQL √ √ 读 、写 Oracle √ √ 读 、写 SQLServer √ √ 读 、写 PostgreSQL √ √ 读 、写 DRDS √ √ 读 、写 通用RDBMS(支持所有关系型数据库) √ √ 读 、写 阿里云数仓数据存储 ODPS √ √ 读 、写 ADS √ 写 OSS √ √ 读 、写 OCS √ √ 读 、写 NoSQL数据存储 OTS √ √ 读 、写 Hbase0.94 √ √ 读 、写 Hbase1.1 √ √ 读 、写 Phoenix4.x √ √ 读 、写 Phoenix5.","title":"DataX"},{"content":"DataX DataX 是阿里巴巴集团内被广泛使用的离线数据同步工具/平台，实现包括 MySQL、SQL Server、Oracle、PostgreSQL、HDFS、Hive、HBase、OTS、ODPS 等各种异构数据源之间高效的数据同步功能。\nFeatures DataX本身作为数据同步框架，将不同数据源的同步抽象为从源头数据源读取数据的Reader插件，以及向目标端写入数据的Writer插件，理论上DataX框架可以支持任意数据源类型的数据同步工作。同时DataX插件体系作为一套生态系统, 每接入一套新数据源该新加入的数据源即可实现和现有的数据源互通。\nSystem Requirements Linux JDK(1.8以上，推荐1.8) Python(推荐Python2.6.X) Apache Maven 3.x (Compile DataX) Quick Start 工具部署\n方法一、直接下载DataX工具包：DataX下载地址\n下载后解压至本地某个目录，进入bin目录，即可运行同步作业：\n$ cd {YOUR_DATAX_HOME}/bin $ python datax.py {YOUR_JOB.json} 自检脚本： python {YOUR_DATAX_HOME}/bin/datax.py {YOUR_DATAX_HOME}/job/job.json\n方法二、下载DataX源码，自己编译：DataX源码\n(1)、下载DataX源码：\n$ git clone git@github.com:alibaba/DataX.git (2)、通过maven打包：\n$ cd {DataX_source_code_home} $ mvn -U clean package assembly:assembly -Dmaven.test.skip=true 打包成功，日志显示如下：\n[INFO] BUILD SUCCESS [INFO] ----------------------------------------------------------------- [INFO] Total time: 08:12 min [INFO] Finished at: 2015-12-13T16:26:48+08:00 [INFO] Final Memory: 133M/960M [INFO] ----------------------------------------------------------------- 打包成功后的DataX包位于 {DataX_source_code_home}/target/datax/datax/ ，结构如下：\n$ cd {DataX_source_code_home} $ ls ./target/datax/datax/ bin\tconf\tjob\tlib\tlog\tlog_perf\tplugin\tscript\ttmp 配置示例：从stream读取数据并打印到控制台\n第一步、创建作业的配置文件（json格式）\n可以通过命令查看配置模板： python datax.py -r {YOUR_READER} -w {YOUR_WRITER}\n$ cd {YOUR_DATAX_HOME}/bin $ python datax.py -r streamreader -w streamwriter DataX (UNKNOWN_DATAX_VERSION), From Alibaba ! Copyright (C) 2010-2015, Alibaba Group. All Rights Reserved. Please refer to the streamreader document: https://github.com/alibaba/DataX/blob/master/streamreader/doc/streamreader.md Please refer to the streamwriter document: https://github.com/alibaba/DataX/blob/master/streamwriter/doc/streamwriter.md Please save the following configuration as a json file and use python {DATAX_HOME}/bin/datax.py {JSON_FILE_NAME}.json to run the job. { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [], \u0026#34;sliceRecordCount\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;encoding\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;print\u0026#34;: true } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: \u0026#34;\u0026#34; } } } } 根据模板配置json如下：\n#stream2stream.json { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sliceRecordCount\u0026#34;: 10, \u0026#34;column\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;10\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;hello，你好，世界-DataX\u0026#34; } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;print\u0026#34;: true } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } } } } 第二步：启动DataX\n$ cd {YOUR_DATAX_DIR_BIN} $ python datax.py ./stream2stream.json 同步结束，显示日志如下：\n... 2015-12-17 11:20:25.263 [job-0] INFO JobContainer - 任务启动时刻 : 2015-12-17 11:20:15 任务结束时刻 : 2015-12-17 11:20:25 任务总计耗时 : 10s 任务平均流量 : 205B/s 记录写入速度 : 5rec/s 读出记录总数 : 50 读写失败总数 : 0 Contact us Google Groups: DataX-user\n","permalink":"https://haokiu.com/blog/f4223fe7c5a64b12ae87c43ed48cc971/","summary":"DataX DataX 是阿里巴巴集团内被广泛使用的离线数据同步工具/平台，实现包括 MySQL、SQL Server、Oracle、PostgreSQL、HDFS、Hive、HBase、OTS、ODPS 等各种异构数据源之间高效的数据同步功能。\nFeatures DataX本身作为数据同步框架，将不同数据源的同步抽象为从源头数据源读取数据的Reader插件，以及向目标端写入数据的Writer插件，理论上DataX框架可以支持任意数据源类型的数据同步工作。同时DataX插件体系作为一套生态系统, 每接入一套新数据源该新加入的数据源即可实现和现有的数据源互通。\nSystem Requirements Linux JDK(1.8以上，推荐1.8) Python(推荐Python2.6.X) Apache Maven 3.x (Compile DataX) Quick Start 工具部署\n方法一、直接下载DataX工具包：DataX下载地址\n下载后解压至本地某个目录，进入bin目录，即可运行同步作业：\n$ cd {YOUR_DATAX_HOME}/bin $ python datax.py {YOUR_JOB.json} 自检脚本： python {YOUR_DATAX_HOME}/bin/datax.py {YOUR_DATAX_HOME}/job/job.json\n方法二、下载DataX源码，自己编译：DataX源码\n(1)、下载DataX源码：\n$ git clone git@github.com:alibaba/DataX.git (2)、通过maven打包：\n$ cd {DataX_source_code_home} $ mvn -U clean package assembly:assembly -Dmaven.test.skip=true 打包成功，日志显示如下：\n[INFO] BUILD SUCCESS [INFO] ----------------------------------------------------------------- [INFO] Total time: 08:12 min [INFO] Finished at: 2015-12-13T16:26:48+08:00 [INFO] Final Memory: 133M/960M [INFO] ----------------------------------------------------------------- 打包成功后的DataX包位于 {DataX_source_code_home}/target/datax/datax/ ，结构如下：\n$ cd {DataX_source_code_home} $ ls ./target/datax/datax/ bin\tconf\tjob\tlib\tlog\tlog_perf\tplugin\tscript\ttmp 配置示例：从stream读取数据并打印到控制台\n第一步、创建作业的配置文件（json格式）\n可以通过命令查看配置模板： python datax.py -r {YOUR_READER} -w {YOUR_WRITER}","title":"DataX"},{"content":"DataXDataX ADB PG WriterDataX ADS写入CassandraReader 插件文档CassandraWriter 插件文档Readme.mdDataX插件开发宝典DrdsReader 插件文档DataX DRDSWriterREADME.mdDataX ElasticSearchWriterDataX FtpReader 说明DataX FtpWriter 说明DataX GDBReaderDataX GDBWriterHbase094XReader \u0026amp; Hbase11XReader 插件文档Hbase094XWriter \u0026amp; Hbase11XWriter 插件文档Hbase094XReader \u0026amp; Hbase11XReader 插件文档hbase11xsqlreader 插件文档HBase11xsqlwriter插件文档Hbase094XWriter \u0026amp; Hbase11XWriter 插件文档hbase20xsqlreader 插件文档HBase20xsqlwriter插件文档DataX HdfsReader 插件文档DataX HdfsWriter 插件文档阿里云开源离线同步工具DataX3.0介绍KingbaseesReader 插件文档DataX KingbaseesWriterdatax-kudu-plugindatax-kudu-pluginsDatax MongoDBReaderDatax MongoDBWriterMysqlReader 插件文档DataX MysqlWriterDataX OCSWriter 适用memcached客户端写入ocsDataX ODPSReaderDataX ODPS写入OpenTSDBReader 插件文档OracleReader 插件文档DataX OracleWriterDataX OSSReader 说明DataX OSSWriter 说明OTSReader 插件文档TableStore增量数据导出通道：TableStoreStreamReaderOTSWriter 插件文档PostgresqlReader 插件文档DataX PostgresqlWriterRDBMSReader 插件文档RDBMSWriter 插件文档SqlServerReader 插件文档DataX SqlServerWriterDataX TransformerTSDBReader 插件文档TSDBWriter 插件文档DataX TxtFileReader 说明DataX TxtFileWriter 说明DataX\n","permalink":"https://haokiu.com/blog/bk-4/","summary":"DataXDataX ADB PG WriterDataX ADS写入CassandraReader 插件文档CassandraWriter 插件文档Readme.mdDataX插件开发宝典DrdsReader 插件文档DataX DRDSWriterREADME.mdDataX ElasticSearchWriterDataX FtpReader 说明DataX FtpWriter 说明DataX GDBReaderDataX GDBWriterHbase094XReader \u0026amp; Hbase11XReader 插件文档Hbase094XWriter \u0026amp; Hbase11XWriter 插件文档Hbase094XReader \u0026amp; Hbase11XReader 插件文档hbase11xsqlreader 插件文档HBase11xsqlwriter插件文档Hbase094XWriter \u0026amp; Hbase11XWriter 插件文档hbase20xsqlreader 插件文档HBase20xsqlwriter插件文档DataX HdfsReader 插件文档DataX HdfsWriter 插件文档阿里云开源离线同步工具DataX3.0介绍KingbaseesReader 插件文档DataX KingbaseesWriterdatax-kudu-plugindatax-kudu-pluginsDatax MongoDBReaderDatax MongoDBWriterMysqlReader 插件文档DataX MysqlWriterDataX OCSWriter 适用memcached客户端写入ocsDataX ODPSReaderDataX ODPS写入OpenTSDBReader 插件文档OracleReader 插件文档DataX OracleWriterDataX OSSReader 说明DataX OSSWriter 说明OTSReader 插件文档TableStore增量数据导出通道：TableStoreStreamReaderOTSWriter 插件文档PostgresqlReader 插件文档DataX PostgresqlWriterRDBMSReader 插件文档RDBMSWriter 插件文档SqlServerReader 插件文档DataX SqlServerWriterDataX TransformerTSDBReader 插件文档TSDBWriter 插件文档DataX TxtFileReader 说明DataX TxtFileWriter 说明DataX","title":"datax 3.0 教程"},{"content":"DataX ADB PG Writer 1 快速介绍 AdbpgWriter 插件实现了写入数据到 ABD PG版数据库的功能。在底层实现上，AdbpgWriter 插件会先缓存需要写入的数据，当缓存的 数据量达到 commitSize 时，插件会通过 JDBC 连接远程 ADB PG版 数据库，并执行 COPY 命令将数据写入 ADB PG 数据库。\nAdbpgWriter 可以作为数据迁移工具为用户提供服务。\n2 实现原理 AdbpgWriter 通过 DataX 框架获取 Reader 生成的协议数据，首先会将数据缓存，当缓存的数据量达到commitSize时，插件根据你配置生成相应的COPY语句，执行 COPY命令将数据写入ADB PG数据库中。\n3 功能说明 3.1 配置样例 这里使用一份从内存产生到 AdbpgWriter导入的数据 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 32 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ] }, \u0026#34;sliceRecordCount\u0026#34;: 1000 }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;adbpgwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;host\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;1234\u0026#34;, \u0026#34;database\u0026#34;: \u0026#34;database\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;schema\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;table\u0026#34;, \u0026#34;preSql\u0026#34;: [\u0026#34;delete * from table\u0026#34;], \u0026#34;postSql\u0026#34;: [\u0026#34;select * from table\u0026#34;], \u0026#34;column\u0026#34;: [\u0026#34;*\u0026#34;] } } } ] } } 3.2 参数说明 name\n描述：插件名称 必选：是 默认值：无 username\n描述：目的数据库的用户名 必选：是 默认值：无 password\n描述：目的数据库的密码 必选：是 默认值：无 host\n描述：目的数据库主机名 必选：是 默认值：无 port\n描述：目的数据库的端口 必选：是 默认值：无 database\n描述：需要写入的表所属的数据库名称 必选：是 默认值：无 schema\n描述：需要写入的表所属的schema名称 必选：是 默认值：无 table\n描述：需要写入的表名称 必选：是 默认值：无 column\n描述：目的表需要写入数据的字段,字段之间用英文逗号分隔。例如: \u0026ldquo;column\u0026rdquo;: [\u0026ldquo;id\u0026rdquo;,\u0026ldquo;name\u0026rdquo;,\u0026ldquo;age\u0026rdquo;]。如果要依次写入全部列，使用表示, 例如: \u0026ldquo;column\u0026rdquo;: [\u0026quot;\u0026quot;]\n注意：1、我们强烈不推荐你这样配置，因为当你目的表字段个数、类型等有改动时，你的任务可能运行不正确或者失败 2、此处 column 不能配置任何常量值 必选：是 默认值：否 preSql\n描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，可以使用 @table 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, \u0026hellip; datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：\u0026quot;preSql\u0026quot;:[\u0026quot;delete from @table\u0026quot;]，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称 必选：否 默认值：否 postSql\n描述：写入数据到目的表后，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，可以使用 @table 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。 必选：否 默认值：否 3.3 类型转换 目前 AdbpgWriter 支持大部分 ADB PG 数据库的类型，但也存在部分没有支持的情况，请注意检查你的类型。\n下面列出 AdbpgWriter 针对 ADB PG 类型转换列表:\nDataX 内部类型 ADB PG 数据类型 Long bigint, bigserial, integer, smallint, serial Double double precision, float, numeric, real String varchar, char, text Date date, time, timestamp Boolean bool 4 性能报告 4.1 环境准备 4.1.1 数据特征 建表语句：\ncreate table schematest.test_datax ( t1 int, t2 bigint, t3 bigserial, t4 float, t5 timestamp, t6 varchar )distributed by(t1); 4.1.2 机器参数 执行DataX的机器参数为:\ncpu: 24核 mem: 96GB ADB PG数据库机器参数为:\n平均core数量:4 primary segment 数量: 4 计算组数量:2 4.2 测试报告 4.2.1 单表测试报告 通道数 commitSize MB DataX速度(Rec/s) DataX流量(M/s) 1 10 54098 15.54 1 20 55000 15.80 4 10 183333 52.66 4 20 173684 49.89 8 10 330000 94.79 8 20 300000 86.17 16 10 412500 118.48 16 20 366666 105.32 32 10 366666 105.32 4.2.2 性能测试小结 channel数对性能影响很大 通常不建议写入数据库时，通道个数 \u0026gt; 32 ","permalink":"https://haokiu.com/blog/1c4beb639bad47a79445e1bb8ccd68a5/","summary":"DataX ADB PG Writer 1 快速介绍 AdbpgWriter 插件实现了写入数据到 ABD PG版数据库的功能。在底层实现上，AdbpgWriter 插件会先缓存需要写入的数据，当缓存的 数据量达到 commitSize 时，插件会通过 JDBC 连接远程 ADB PG版 数据库，并执行 COPY 命令将数据写入 ADB PG 数据库。\nAdbpgWriter 可以作为数据迁移工具为用户提供服务。\n2 实现原理 AdbpgWriter 通过 DataX 框架获取 Reader 生成的协议数据，首先会将数据缓存，当缓存的数据量达到commitSize时，插件根据你配置生成相应的COPY语句，执行 COPY命令将数据写入ADB PG数据库中。\n3 功能说明 3.1 配置样例 这里使用一份从内存产生到 AdbpgWriter导入的数据 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 32 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ] }, \u0026#34;sliceRecordCount\u0026#34;: 1000 }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;adbpgwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;host\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;1234\u0026#34;, \u0026#34;database\u0026#34;: \u0026#34;database\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;schema\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;table\u0026#34;, \u0026#34;preSql\u0026#34;: [\u0026#34;delete * from table\u0026#34;], \u0026#34;postSql\u0026#34;: [\u0026#34;select * from table\u0026#34;], \u0026#34;column\u0026#34;: [\u0026#34;*\u0026#34;] } } } ] } } 3.","title":"DataX ADB PG Writer"},{"content":"DataX ADS写入 1 快速介绍 欢迎ADS加入DataX生态圈！ADSWriter插件实现了其他数据源向ADS写入功能，现有DataX所有的数据源均可以无缝接入ADS，实现数据快速导入ADS。\nADS写入预计支持两种实现方式：\nADSWriter 支持向ODPS中转落地导入ADS方式，优点在于当数据量较大时(\u0026gt;1KW)，可以以较快速度进行导入，缺点引入了ODPS作为落地中转，因此牵涉三方系统(DataX、ADS、ODPS)鉴权认证。\nADSWriter 同时支持向ADS直接写入的方式，优点在于小批量数据写入能够较快完成(\u0026lt;1KW)，缺点在于大数据导入较慢。\n注意：\n如果从ODPS导入数据到ADS，请用户提前在源ODPS的Project中授权ADS Build账号具有读取你源表ODPS的权限，同时，ODPS源表创建人和ADS写入属于同一个阿里云账号。\n如果从非ODPS导入数据到ADS，请用户提前在目的端ADS空间授权ADS Build账号具备Load data权限。\n以上涉及ADS Build账号请联系ADS管理员提供。\n2 实现原理 ADS写入预计支持两种实现方式：\n2.1 Load模式 DataX 将数据导入ADS为当前导入任务分配的ADS项目表，随后DataX通知ADS完成数据加载。该类数据导入方式实际上是写ADS完成数据同步，由于ADS是分布式存储集群，因此该通道吞吐量较大，可以支持TB级别数据导入。\nDataX底层得到明文的 jdbc://host:port/dbname + username + password + table， 以此连接ADS， 执行show grants; 前置检查该用户是否有ADS中目标表的Load Data或者更高的权限。注意，此时ADSWriter使用用户填写的ADS用户名+密码信息完成登录鉴权工作。\n检查通过后，通过ADS中目标表的元数据反向生成ODPS DDL，在ODPS中间project中，以ADSWriter的账户建立ODPS表（非分区表，生命周期设为1-2Day), 并调用ODPSWriter把数据源的数据写入该ODPS表中。\n注意，这里需要使用中转ODPS的账号AK向中转ODPS写入数据。\n写入完成后，以中转ODPS账号连接ADS，发起Load Data From ‘odps://中转project/中转table/\u0026rsquo; [overwrite] into adsdb.adstable [partition (xx,xx=xx)]; 这个命令返回一个Job ID需要记录。\n注意，此时ADS使用自己的Build账号访问中转ODPS，因此需要中转ODPS对这个Build账号提前开放读取权限。\n连接ADS一分钟一次轮询执行 select state from information_schema.job_instances where job_id like ‘$Job ID’，查询状态，注意这个第一个一分钟可能查不到状态记录。\nSuccess或者Fail后返回给用户，然后删除中转ODPS表，任务结束。\n上述流程是从其他非ODPS数据源导入ADS流程，对于ODPS导入ADS流程使用如下流程：\n2.2 Insert模式 DataX 将数据直连ADS接口，利用ADS暴露的INSERT接口直写到ADS。该类数据导入方式写入吞吐量较小，不适合大批量数据写入。有如下注意点：\nADSWriter使用JDBC连接直连ADS，并只使用了JDBC Statement进行数据插入。ADS不支持PreparedStatement，故ADSWriter只能单行多线程进行写入。\nADSWriter支持筛选部分列，列换序等功能，即用户可以填写列。\n考虑到ADS负载问题，建议ADSWriter Insert模式建议用户使用TPS限流，最高在1W TPS。\nADSWriter在所有Task完成写入任务后，Job Post单例执行flush工作，保证数据在ADS整体更新。\n3 功能说明 3.1 配置样例 这里使用一份从内存产生到ADS，使用Load模式进行导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 100000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;adswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;odps\u0026#34;: { \u0026#34;accessId\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;account\u0026#34;: \u0026#34;xxx@aliyun.com\u0026#34;, \u0026#34;odpsServer\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;tunnelServer\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;accountType\u0026#34;: \u0026#34;aliyun\u0026#34;, \u0026#34;project\u0026#34;: \u0026#34;transfer_project\u0026#34; }, \u0026#34;writeMode\u0026#34;: \u0026#34;load\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;127.0.0.1:3306\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;schema\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;table\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;partition\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;lifeCycle\u0026#34;: 2, \u0026#34;overWrite\u0026#34;: true, } } } ] } } 这里使用一份从内存产生到ADS，使用Insert模式进行导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 100000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;adswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;writeMode\u0026#34;: \u0026#34;insert\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;127.0.0.1:3306\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;schema\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;table\u0026#34;, \u0026#34;column\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;username\u0026#34;: \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;partition\u0026#34;: \u0026#34;id,ds=2015\u0026#34; } } } ] } } 3.2 参数说明 （用户配置规格） url\n描述：ADS连接信息，格式为\u0026quot;ip:port\u0026quot;。\n必选：是 默认值：无 schema\n描述：ADS的schema名称。\n必选：是 默认值：无 username\n描述：ADS对应的username，目前就是accessId 必选：是 默认值：无 password\n描述：ADS对应的password，目前就是accessKey 必选：是 默认值：无 table\n描述：目的表的表名称。\n必选：是 默认值：无 partition\n描述：目标表的分区名称，当目标表为分区表，需要指定该字段。\n必选：否 默认值：无 writeMode\n描述：支持Load和Insert两种写入模式\n必选：是 默认值：无 column\n描述：目的表字段列表，可以为[\u0026quot;*\u0026quot;]，或者具体的字段列表，例如[\u0026ldquo;a\u0026rdquo;, \u0026ldquo;b\u0026rdquo;, \u0026ldquo;c\u0026rdquo;]\n必选：是 默认值：无 overWrite\n描述：ADS写入是否覆盖当前写入的表，true为覆盖写入，false为不覆盖(追加)写入。当writeMode为Load，该值才会生效。\n必选：是 默认值：无 lifeCycle\n描述：ADS 临时表生命周期。当writeMode为Load时，该值才会生效。\n必选：是 默认值：无 batchSize\n描述：ADS 提交数据写的批量条数，当writeMode为insert时，该值才会生效。\n必选：writeMode为insert时才有用 默认值：32 bufferSize\n描述：DataX数据收集缓冲区大小，缓冲区的目的是攒一个较大的buffer，源头的数据首先进入到此buffer中进行排序，排序完成后再提交ads写。排序是根据ads的分区列模式进行的，排序的目的是数据顺序对ADS服务端更友好，出于性能考虑。bufferSize缓冲区中的数据会经过batchSize批量提交到ADS中，一般如果要设置bufferSize，设置bufferSize为batchSize数量的多倍。当writeMode为insert时，该值才会生效。\n必选：writeMode为insert时才有用 默认值：默认不配置不开启此功能 3.3 类型转换 DataX 内部类型 ADS 数据类型 Long int, tinyint, smallint, int, bigint Double float, double, decimal String varchar Date date Boolean bool Bytes 无 注意:\nmultivalue ADS支持multivalue类型，DataX对于该类型支持待定？ 4 插件约束 如果Reader为ODPS，且ADSWriter写入模式为Load模式时，ODPS的partition只支持如下三种配置方式(以两级分区为例)：\n\u0026#34;partition\u0026#34;:[\u0026#34;pt=*,ds=*\u0026#34;] (读取test表所有分区的数据) \u0026#34;partition\u0026#34;:[\u0026#34;pt=1,ds=*\u0026#34;] (读取test表下面，一级分区pt=1下面的所有二级分区) \u0026#34;partition\u0026#34;:[\u0026#34;pt=1,ds=hangzhou\u0026#34;] (读取test表下面，一级分区pt=1下面，二级分区ds=hz的数据) 5 性能报告（线上环境实测） 5.1 环境准备 5.2 测试报告 6 FAQ ","permalink":"https://haokiu.com/blog/5d26f13c5f3e4cda84adc613514cdd53/","summary":"DataX ADS写入 1 快速介绍 欢迎ADS加入DataX生态圈！ADSWriter插件实现了其他数据源向ADS写入功能，现有DataX所有的数据源均可以无缝接入ADS，实现数据快速导入ADS。\nADS写入预计支持两种实现方式：\nADSWriter 支持向ODPS中转落地导入ADS方式，优点在于当数据量较大时(\u0026gt;1KW)，可以以较快速度进行导入，缺点引入了ODPS作为落地中转，因此牵涉三方系统(DataX、ADS、ODPS)鉴权认证。\nADSWriter 同时支持向ADS直接写入的方式，优点在于小批量数据写入能够较快完成(\u0026lt;1KW)，缺点在于大数据导入较慢。\n注意：\n如果从ODPS导入数据到ADS，请用户提前在源ODPS的Project中授权ADS Build账号具有读取你源表ODPS的权限，同时，ODPS源表创建人和ADS写入属于同一个阿里云账号。\n如果从非ODPS导入数据到ADS，请用户提前在目的端ADS空间授权ADS Build账号具备Load data权限。\n以上涉及ADS Build账号请联系ADS管理员提供。\n2 实现原理 ADS写入预计支持两种实现方式：\n2.1 Load模式 DataX 将数据导入ADS为当前导入任务分配的ADS项目表，随后DataX通知ADS完成数据加载。该类数据导入方式实际上是写ADS完成数据同步，由于ADS是分布式存储集群，因此该通道吞吐量较大，可以支持TB级别数据导入。\nDataX底层得到明文的 jdbc://host:port/dbname + username + password + table， 以此连接ADS， 执行show grants; 前置检查该用户是否有ADS中目标表的Load Data或者更高的权限。注意，此时ADSWriter使用用户填写的ADS用户名+密码信息完成登录鉴权工作。\n检查通过后，通过ADS中目标表的元数据反向生成ODPS DDL，在ODPS中间project中，以ADSWriter的账户建立ODPS表（非分区表，生命周期设为1-2Day), 并调用ODPSWriter把数据源的数据写入该ODPS表中。\n注意，这里需要使用中转ODPS的账号AK向中转ODPS写入数据。\n写入完成后，以中转ODPS账号连接ADS，发起Load Data From ‘odps://中转project/中转table/\u0026rsquo; [overwrite] into adsdb.adstable [partition (xx,xx=xx)]; 这个命令返回一个Job ID需要记录。\n注意，此时ADS使用自己的Build账号访问中转ODPS，因此需要中转ODPS对这个Build账号提前开放读取权限。\n连接ADS一分钟一次轮询执行 select state from information_schema.job_instances where job_id like ‘$Job ID’，查询状态，注意这个第一个一分钟可能查不到状态记录。\nSuccess或者Fail后返回给用户，然后删除中转ODPS表，任务结束。\n上述流程是从其他非ODPS数据源导入ADS流程，对于ODPS导入ADS流程使用如下流程：\n2.2 Insert模式 DataX 将数据直连ADS接口，利用ADS暴露的INSERT接口直写到ADS。该类数据导入方式写入吞吐量较小，不适合大批量数据写入。有如下注意点：\nADSWriter使用JDBC连接直连ADS，并只使用了JDBC Statement进行数据插入。ADS不支持PreparedStatement，故ADSWriter只能单行多线程进行写入。\nADSWriter支持筛选部分列，列换序等功能，即用户可以填写列。\n考虑到ADS负载问题，建议ADSWriter Insert模式建议用户使用TPS限流，最高在1W TPS。\nADSWriter在所有Task完成写入任务后，Job Post单例执行flush工作，保证数据在ADS整体更新。\n3 功能说明 3.1 配置样例 这里使用一份从内存产生到ADS，使用Load模式进行导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 100000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;adswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;odps\u0026#34;: { \u0026#34;accessId\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;account\u0026#34;: \u0026#34;xxx@aliyun.","title":"DataX ADS写入"},{"content":"DataX DRDSWriter 1 快速介绍 DRDSWriter 插件实现了写入数据到 DRDS 的目的表的功能。在底层实现上， DRDSWriter 通过 JDBC 连接远程 DRDS 数据库的 Proxy，并执行相应的 replace into \u0026hellip; 的 sql 语句将数据写入 DRDS，特别注意执行的 Sql 语句是 replace into，为了避免数据重复写入，需要你的表具备主键或者唯一性索引(Unique Key)。\nDRDSWriter 面向ETL开发工程师，他们使用 DRDSWriter 从数仓导入数据到 DRDS。同时 DRDSWriter 亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 DRDSWriter 通过 DataX 框架获取 Reader 生成的协议数据，通过 replace into...(没有遇到主键/唯一性索引冲突时，与 insert into 行为一致，冲突时会用新行替换原有行所有字段) 的语句写入数据到 DRDS。DRDSWriter 累积一定数据，提交给 DRDS 的 Proxy，该 Proxy 内部决定数据是写入一张还是多张表以及多张表写入时如何路由数据。 注意：整个任务至少需要具备 replace into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 DRDS 导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;drdswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;writeMode\u0026#34;: \u0026#34;insert\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from test\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:mysql://127.0.0.1:3306/datax?useUnicode=true\u0026amp;characterEncoding=gbk\u0026#34;, \u0026#34;table\u0026#34;: [ \u0026#34;test\u0026#34; ] } ] } } } ] } } 3.2 参数说明 jdbcUrl\n描述：目的数据库的 JDBC 连接信息。作业运行时，DataX 会在你提供的 jdbcUrl 后面追加如下属性：yearIsDateType=false\u0026amp;zeroDateTimeBehavior=convertToNull\u0026amp;rewriteBatchedStatements=true\n注意：1、在一个数据库上只能配置一个 jdbcUrl 值 2、一个DRDS 写入任务仅能配置一个 jdbcUrl 3、jdbcUrl按照Mysql/DRDS官方规范，并可以填写连接附加控制信息，比如想指定连接编码为 gbk ，则在 jdbcUrl 后面追加属性 useUnicode=true\u0026amp;characterEncoding=gbk。具体请参看 Mysql/DRDS官方文档或者咨询对应 DBA。 必选：是 默认值：无 username\n描述：目的数据库的用户名 必选：是 默认值：无 password\n描述：目的数据库的密码 必选：是 默认值：无 table\n描述：目的表的表名称。 只能配置一个DRDS 的表名称。\n注意：table 和 jdbcUrl 必须包含在 connection 配置单元中 必选：是 默认值：无 column\n描述：目的表需要写入数据的字段,字段之间用英文逗号分隔。例如: \u0026ldquo;column\u0026rdquo;: [\u0026ldquo;id\u0026rdquo;,\u0026ldquo;name\u0026rdquo;,\u0026ldquo;age\u0026rdquo;]。如果要依次写入全部列，使用表示, 例如: \u0026ldquo;column\u0026rdquo;: [\u0026quot;\u0026quot;]\n**column配置项必须指定，不能留空！** 注意：1、我们强烈不推荐你这样配置，因为当你目的表字段个数、类型等有改动时，你的任务可能运行不正确或者失败 2、此处 column 不能配置任何常量值 必选：是 默认值：否 preSql\n描述：写入数据到目的表前，会先执行这里的标准语句。比如你想在导入数据前清空数据表中的数据，那么可以配置为:\u0026quot;preSql\u0026quot;:[\u0026quot;delete from yourTableName\u0026quot;] 必选：否 默认值：无 postSql\n描述：写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ） 必选：否 默认值：无 writeMode\n描述：默认为 replace，目前仅支持 replace，可以不配置。 必选：否 默认值：replace batchSize\n描述：一次性批量提交的记录数大小，该值可以极大减少DataX与DRDS的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。\n必选：否 默认值：\n3.3 类型转换 类似 MysqlWriter ，目前 DRDSWriter 支持大部分 Mysql 类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出 DRDSWriter 针对 Mysql 类型转换列表:\nDataX 内部类型 Mysql 数据类型 Long int, tinyint, smallint, mediumint, int, bigint, year Double float, double, decimal String varchar, char, tinytext, text, mediumtext, longtext Date date, datetime, timestamp, time Boolean bit, bool Bytes tinyblob, mediumblob, blob, longblob, varbinary 4 性能报告 5 约束限制 FAQ Q: DRDSWriter 执行 postSql 语句报错，那么数据导入到目标数据库了吗?\nA: DataX 导入过程存在三块逻辑，pre 操作、导入操作、post 操作，其中任意一环报错，DataX 作业报错。由于 DataX 不能保证在同一个事务完成上述几个操作，因此有可能数据已经落入到目标端。\nQ: 按照上述说法，那么有部分脏数据导入数据库，如果影响到线上数据库怎么办?\nA: 目前有两种解法，第一种配置 pre 语句，该 sql 可以清理当天导入数据， DataX 每次导入时候可以把上次清理干净并导入完整数据。第二种，向临时表导入数据，完成后再 rename 到线上表。\nQ: 上面第二种方法可以避免对线上数据造成影响，那我具体怎样操作?\nA: 可以配置临时表导入\n","permalink":"https://haokiu.com/blog/d31c9e889b154a0f96e4eb4be5c50467/","summary":"DataX DRDSWriter 1 快速介绍 DRDSWriter 插件实现了写入数据到 DRDS 的目的表的功能。在底层实现上， DRDSWriter 通过 JDBC 连接远程 DRDS 数据库的 Proxy，并执行相应的 replace into \u0026hellip; 的 sql 语句将数据写入 DRDS，特别注意执行的 Sql 语句是 replace into，为了避免数据重复写入，需要你的表具备主键或者唯一性索引(Unique Key)。\nDRDSWriter 面向ETL开发工程师，他们使用 DRDSWriter 从数仓导入数据到 DRDS。同时 DRDSWriter 亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 DRDSWriter 通过 DataX 框架获取 Reader 生成的协议数据，通过 replace into...(没有遇到主键/唯一性索引冲突时，与 insert into 行为一致，冲突时会用新行替换原有行所有字段) 的语句写入数据到 DRDS。DRDSWriter 累积一定数据，提交给 DRDS 的 Proxy，该 Proxy 内部决定数据是写入一张还是多张表以及多张表写入时如何路由数据。 注意：整个任务至少需要具备 replace into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 DRDS 导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;drdswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;writeMode\u0026#34;: \u0026#34;insert\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from test\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:mysql://127.","title":"DataX DRDSWriter"},{"content":"DataX ElasticSearchWriter 1 快速介绍 数据导入elasticsearch的插件\n2 实现原理 使用elasticsearch的rest api接口， 批量把从reader读入的数据写入elasticsearch\n3 功能说明 3.1 配置样例 job.json { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { ... }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;elasticsearchwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://xxx:9999\u0026#34;, \u0026#34;accessId\u0026#34;: \u0026#34;xxxx\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;xxxx\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;test-1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;cleanup\u0026#34;: true, \u0026#34;settings\u0026#34;: {\u0026#34;index\u0026#34; :{\u0026#34;number_of_shards\u0026#34;: 1, \u0026#34;number_of_replicas\u0026#34;: 0}}, \u0026#34;discovery\u0026#34;: false, \u0026#34;batchSize\u0026#34;: 1000, \u0026#34;splitter\u0026#34;: \u0026#34;,\u0026#34;, \u0026#34;column\u0026#34;: [ {\u0026#34;name\u0026#34;: \u0026#34;pk\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;id\u0026#34;}, { \u0026#34;name\u0026#34;: \u0026#34;col_ip\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;ip\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_double\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_long\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_integer\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_keyword\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_text\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;}, { \u0026#34;name\u0026#34;: \u0026#34;col_geo_point\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;geo_point\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_date\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;}, { \u0026#34;name\u0026#34;: \u0026#34;col_nested1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;nested\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_nested2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;nested\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_object1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_object2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_integer_array\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;integer\u0026#34;, \u0026#34;array\u0026#34;:true}, { \u0026#34;name\u0026#34;: \u0026#34;col_geo_shape\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;geo_shape\u0026#34;, \u0026#34;tree\u0026#34;: \u0026#34;quadtree\u0026#34;, \u0026#34;precision\u0026#34;: \u0026#34;10m\u0026#34;} ] } } } ] } } 3.2 参数说明 endpoint\n描述：ElasticSearch的连接地址\n必选：是\n默认值：无\naccessId\n描述：http auth中的user\n必选：否\n默认值：空\naccessKey\n描述：http auth中的password\n必选：否\n默认值：空\nindex\n描述：elasticsearch中的index名\n必选：是\n默认值：无\ntype\n描述：elasticsearch中index的type名\n必选：否\n默认值：index名\ncleanup\n描述：是否删除原表\n必选：否\n默认值：false\nbatchSize\n描述：每次批量数据的条数\n必选：否\n默认值：1000\ntrySize\n描述：失败后重试的次数\n必选：否\n默认值：30\ntimeout\n描述：客户端超时时间\n必选：否\n默认值：600000\ndiscovery\n描述：启用节点发现将(轮询)并定期更新客户机中的服务器列表。\n必选：否\n默认值：false\ncompression\n描述：http请求，开启压缩\n必选：否\n默认值：true\nmultiThread\n描述：http请求，是否有多线程\n必选：否\n默认值：true\nignoreWriteError\n描述：忽略写入错误，不重试，继续写入\n必选：否\n默认值：false\nignoreParseError\n描述：忽略解析数据格式错误，继续写入\n必选：否\n默认值：true\nalias\n描述：数据导入完成后写入别名\n必选：否\n默认值：无\naliasMode\n描述：数据导入完成后增加别名的模式，append(增加模式), exclusive(只留这一个)\n必选：否\n默认值：append\nsettings\n描述：创建index时候的settings, 与elasticsearch官方相同\n必选：否\n默认值：无\nsplitter\n描述：如果插入数据是array，就使用指定分隔符\n必选：否\n默认值：-,-\ncolumn\n描述：elasticsearch所支持的字段类型，样例中包含了全部\n必选：是\ndynamic\n描述: 不使用datax的mappings，使用es自己的自动mappings\n必选: 否\n默认值: false\n4 性能报告 4.1 环境准备 总数据量 1kw条数据, 每条0.1kb 1个shard, 0个replica 不加id，这样默认是append_only模式，不检查版本，插入速度会有20%左右的提升 4.1.1 输入数据类型(streamreader) {\u0026#34;value\u0026#34;: \u0026#34;1.1.1.1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, {\u0026#34;value\u0026#34;: 19890604.0, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34;}, {\u0026#34;value\u0026#34;: 19890604, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;}, {\u0026#34;value\u0026#34;: 19890604, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;}, {\u0026#34;value\u0026#34;: \u0026#34;hello world\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, {\u0026#34;value\u0026#34;: \u0026#34;hello world\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, {\u0026#34;value\u0026#34;: \u0026#34;41.12,-71.34\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, {\u0026#34;value\u0026#34;: \u0026#34;2017-05-25\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;}, 4.1.2 输出数据类型(eswriter) { \u0026#34;name\u0026#34;: \u0026#34;col_ip\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;ip\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_double\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_long\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_integer\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_keyword\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_text\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;}, { \u0026#34;name\u0026#34;: \u0026#34;col_geo_point\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;geo_point\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_date\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;} 4.1.2 机器参数 cpu: 32 Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz mem: 128G net: 千兆双网卡 4.1.3 DataX jvm 参数 -Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError\n4.2 测试报告 通道数 批量提交行数 DataX速度(Rec/s) DataX流量(MB/s) 4 256 11013 0.828 4 1024 19417 1.43 4 4096 23923 1.76 4 8172 24449 1.80 8 256 21459 1.58 8 1024 37037 2.72 8 4096 45454 3.34 8 8172 45871 3.37 16 1024 67567 4.96 16 4096 78125 5.74 16 8172 77519 5.69 32 1024 94339 6.93 32 4096 96153 7.06 64 1024 91743 6.74 4.3 测试总结 最好的结果是32通道，每次传4096，如果单条数据很大， 请适当减少批量数，防止oom 当然这个很容易水平扩展，而且es也是分布式的，多设置几个shard也可以水平扩展 5 约束限制 如果导入id，这样数据导入失败也会重试，重新导入也仅仅是覆盖，保证数据一致性 如果不导入id，就是append_only模式，elasticsearch自动生成id，速度会提升20%左右，但数据无法修复，适合日志型数据(对数据精度要求不高的) ","permalink":"https://haokiu.com/blog/5e857fe9cf5743dc837f14fbc9f0a876/","summary":"DataX ElasticSearchWriter 1 快速介绍 数据导入elasticsearch的插件\n2 实现原理 使用elasticsearch的rest api接口， 批量把从reader读入的数据写入elasticsearch\n3 功能说明 3.1 配置样例 job.json { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { ... }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;elasticsearchwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://xxx:9999\u0026#34;, \u0026#34;accessId\u0026#34;: \u0026#34;xxxx\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;xxxx\u0026#34;, \u0026#34;index\u0026#34;: \u0026#34;test-1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;default\u0026#34;, \u0026#34;cleanup\u0026#34;: true, \u0026#34;settings\u0026#34;: {\u0026#34;index\u0026#34; :{\u0026#34;number_of_shards\u0026#34;: 1, \u0026#34;number_of_replicas\u0026#34;: 0}}, \u0026#34;discovery\u0026#34;: false, \u0026#34;batchSize\u0026#34;: 1000, \u0026#34;splitter\u0026#34;: \u0026#34;,\u0026#34;, \u0026#34;column\u0026#34;: [ {\u0026#34;name\u0026#34;: \u0026#34;pk\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;id\u0026#34;}, { \u0026#34;name\u0026#34;: \u0026#34;col_ip\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;ip\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_double\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_long\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_integer\u0026#34;,\u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_keyword\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;keyword\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_text\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34;, \u0026#34;analyzer\u0026#34;: \u0026#34;ik_max_word\u0026#34;}, { \u0026#34;name\u0026#34;: \u0026#34;col_geo_point\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;geo_point\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_date\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy-MM-dd HH:mm:ss\u0026#34;}, { \u0026#34;name\u0026#34;: \u0026#34;col_nested1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;nested\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_nested2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;nested\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_object1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_object2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col_integer_array\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;integer\u0026#34;, \u0026#34;array\u0026#34;:true}, { \u0026#34;name\u0026#34;: \u0026#34;col_geo_shape\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;geo_shape\u0026#34;, \u0026#34;tree\u0026#34;: \u0026#34;quadtree\u0026#34;, \u0026#34;precision\u0026#34;: \u0026#34;10m\u0026#34;} ] } } } ] } } 3.","title":"DataX ElasticSearchWriter"},{"content":"DataX FtpReader 说明 1 快速介绍 FtpReader提供了读取远程FTP文件系统数据存储的能力。在底层实现上，FtpReader获取远程FTP文件数据，并转换为DataX传输协议传递给Writer。\n本地文件内容存放的是一张逻辑意义上的二维表，例如CSV格式的文本信息。\n2 功能与限制 FtpReader实现了从远程FTP文件读取数据并转为DataX协议的功能，远程FTP文件本身是无结构化数据存储，对于DataX而言，FtpReader实现上类比TxtFileReader，有诸多相似之处。目前FtpReader支持功能如下：\n支持且仅支持读取TXT的文件，且要求TXT中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n支持多种类型数据读取(使用String表示)，支持列裁剪，支持列常量\n支持递归读取、支持文件名过滤。\n支持文本压缩，现有压缩格式为zip、gzip、bzip2。\n多个File可以支持并发读取。\n我们暂时不能做到：\n单个File支持多线程并发读取，这里涉及到单个File内部切分算法。二期考虑支持。\n单个File在压缩情况下，从技术上无法支持多线程并发读取。\n3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ftpreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;protocol\u0026#34;: \u0026#34;sftp\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;: 22, \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;/home/hanfa.shf/ftpReaderTest/data\u0026#34; ], \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy.MM.dd\u0026#34; } ], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ftpWriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/home/hanfa.shf/ftpReaderTest/result\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;shihf\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy-MM-dd\u0026#34; } } } ] } } 3.2 参数说明 protocol\n描述：ftp服务器协议，目前支持传输协议有ftp和sftp。 必选：是 默认值：无 host\n描述：ftp服务器地址。 必选：是 默认值：无 port\n描述：ftp服务器端口。 必选：否 默认值：若传输协议是sftp协议，默认值是22；若传输协议是标准ftp协议，默认值是21 timeout\n描述：连接ftp服务器连接超时时间，单位毫秒。 必选：否 默认值：60000（1分钟）\nconnectPattern\n描述：连接模式（主动模式或者被动模式）。该参数只在传输协议是标准ftp协议时使用，值只能为：PORT (主动)，PASV（被动）。两种模式主要的不同是数据连接建立的不同。对于Port模式，是客户端在本地打开一个端口等服务器去连接建立数据连接，而Pasv模式就是服务器打开一个端口等待客户端去建立一个数据连接。\n必选：否 默认值：PASV\nusername\n描述：ftp服务器访问用户名。 必选：是 默认值：无 password\n描述：ftp服务器访问密码。 必选：是 默认值：无 path\n描述：远程FTP文件系统的路径信息，注意这里可以支持填写多个路径。 当指定单个远程FTP文件，FtpReader暂时只能使用单线程进行数据抽取。二期考虑在非压缩文件情况下针对单个File可以进行多线程并发读取。\n当指定多个远程FTP文件，FtpReader支持使用多线程进行数据抽取。线程并发数通过通道数指定。\n当指定通配符，FtpReader尝试遍历出多个文件信息。例如: 指定/*代表读取/目录下所有的文件，指定/bazhen/*代表读取bazhen目录下游所有的文件。FtpReader目前只支持*作为文件通配符。\n特别需要注意的是，DataX会将一个作业下同步的所有Text File视作同一张数据表。用户必须自己保证所有的File能够适配同一套schema信息。读取文件用户必须保证为类CSV格式，并且提供给DataX权限可读。\n特别需要注意的是，如果Path指定的路径下没有符合匹配的文件抽取，DataX将报错。\n必选：是 默认值：无 column\n描述：读取字段列表，type指定源数据的类型，index指定当前列来自于文本第几列(以0开始)，value指定当前类型为常量，不从源头文件读取数据，而是根据value值自动生成对应的列。 默认情况下，用户可以全部按照String类型读取数据，配置如下：\n\u0026#34;column\u0026#34;: [\u0026#34;*\u0026#34;] 用户可以指定Column字段信息，配置如下：\n{ \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;index\u0026#34;: 0 //从远程FTP文件文本第一列获取int字段 }, { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;alibaba\u0026#34; //从FtpReader内部生成alibaba的字符串字段作为当前字段 } 对于用户指定Column信息，type必须填写，index/value必须选择其一。\n必选：是 默认值：全部按照string类型读取 fieldDelimiter\n描述：读取的字段分隔符 必选：是 默认值：, compress\n描述：文本压缩类型，默认不填写意味着没有压缩。支持压缩类型为zip、gzip、bzip2。 必选：否 默认值：没有压缩 encoding\n描述：读取文件的编码配置。\n必选：否 默认值：utf-8 skipHeader\n描述：类CSV格式文件可能存在表头为标题情况，需要跳过。默认不跳过。\n必选：否 默认值：false nullFormat\n描述：文本文件中无法使用标准字符串定义null(空指针)，DataX提供nullFormat定义哪些字符串可以表示为null。\n例如如果用户配置: nullFormat:\u0026quot;\\N\u0026quot;，那么如果源头数据是\u0026quot;\\N\u0026quot;，DataX视作null字段。\n必选：否 默认值：\\N maxTraversalLevel\n描述：允许遍历文件夹的最大层数。\n必选：否 默认值：100 csvReaderConfig\n描述：读取CSV类型文件参数配置，Map类型。读取CSV类型文件使用的CsvReader进行读取，会有很多配置，不配置则使用默认值。\n必选：否 默认值：无 常见配置：\n\u0026#34;csvReaderConfig\u0026#34;:{ \u0026#34;safetySwitch\u0026#34;: false, \u0026#34;skipEmptyRecords\u0026#34;: false, \u0026#34;useTextQualifier\u0026#34;: false } 所有配置项及默认值,配置时 csvReaderConfig 的map中请严格按照以下字段名字进行配置：\nboolean caseSensitive = true; char textQualifier = 34; boolean trimWhitespace = true; boolean useTextQualifier = true;//是否使用csv转义字符 char delimiter = 44;//分隔符 char recordDelimiter = 0; char comment = 35; boolean useComments = false; int escapeMode = 1; boolean safetySwitch = true;//单列长度是否限制100000字符 boolean skipEmptyRecords = true;//是否跳过空行 boolean captureRawRecord = true; 3.3 类型转换 远程FTP文件本身不提供数据类型，该类型是DataX FtpReader定义：\nDataX 内部类型 远程FTP文件 数据类型 Long Long Double Double String String Boolean Boolean Date Date 其中：\n远程FTP文件 Long是指远程FTP文件文本中使用整形的字符串表示形式，例如\u0026quot;19901219\u0026quot;。 远程FTP文件 Double是指远程FTP文件文本中使用Double的字符串表示形式，例如\u0026quot;3.1415\u0026quot;。 远程FTP文件 Boolean是指远程FTP文件文本中使用Boolean的字符串表示形式，例如\u0026quot;true\u0026quot;、\u0026ldquo;false\u0026rdquo;。不区分大小写。 远程FTP文件 Date是指远程FTP文件文本中使用Date的字符串表示形式，例如\u0026quot;2014-12-31\u0026quot;，Date可以指定format格式。 4 性能报告 5 约束限制 略\n6 FAQ 略\n","permalink":"https://haokiu.com/blog/0b6970ee252d4875841a98382b04f30b/","summary":"DataX FtpReader 说明 1 快速介绍 FtpReader提供了读取远程FTP文件系统数据存储的能力。在底层实现上，FtpReader获取远程FTP文件数据，并转换为DataX传输协议传递给Writer。\n本地文件内容存放的是一张逻辑意义上的二维表，例如CSV格式的文本信息。\n2 功能与限制 FtpReader实现了从远程FTP文件读取数据并转为DataX协议的功能，远程FTP文件本身是无结构化数据存储，对于DataX而言，FtpReader实现上类比TxtFileReader，有诸多相似之处。目前FtpReader支持功能如下：\n支持且仅支持读取TXT的文件，且要求TXT中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n支持多种类型数据读取(使用String表示)，支持列裁剪，支持列常量\n支持递归读取、支持文件名过滤。\n支持文本压缩，现有压缩格式为zip、gzip、bzip2。\n多个File可以支持并发读取。\n我们暂时不能做到：\n单个File支持多线程并发读取，这里涉及到单个File内部切分算法。二期考虑支持。\n单个File在压缩情况下，从技术上无法支持多线程并发读取。\n3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ftpreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;protocol\u0026#34;: \u0026#34;sftp\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, \u0026#34;port\u0026#34;: 22, \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;path\u0026#34;: [ \u0026#34;/home/hanfa.shf/ftpReaderTest/data\u0026#34; ], \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy.MM.dd\u0026#34; } ], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ftpWriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/home/hanfa.","title":"DataX FtpReader 说明"},{"content":"DataX FtpWriter 说明 1 快速介绍 FtpWriter提供了向远程FTP文件写入CSV格式的一个或者多个文件，在底层实现上，FtpWriter将DataX传输协议下的数据转换为csv格式，并使用FTP相关的网络协议写出到远程FTP服务器。\n写入FTP文件内容存放的是一张逻辑意义上的二维表，例如CSV格式的文本信息。\n2 功能与限制 FtpWriter实现了从DataX协议转为FTP文件功能，FTP文件本身是无结构化数据存储，FtpWriter如下几个方面约定:\n支持且仅支持写入文本类型(不支持BLOB如视频数据)的文件，且要求文本中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n写出时不支持文本压缩。\n支持多线程写入，每个线程写入不同子文件。\n我们不能做到：\n单个文件不能支持并发写入。 3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: {}, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ftpwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;protocol\u0026#34;: \u0026#34;sftp\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;port\u0026#34;: 22, \u0026#34;username\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;timeout\u0026#34;: \u0026#34;60000\u0026#34;, \u0026#34;connectPattern\u0026#34;: \u0026#34;PASV\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/tmp/data/\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;yixiao\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate|append|nonConflict\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;nullFormat\u0026#34;: \u0026#34;null\u0026#34;, \u0026#34;dateFormat\u0026#34;: \u0026#34;yyyy-MM-dd\u0026#34;, \u0026#34;fileFormat\u0026#34;: \u0026#34;csv\u0026#34;, \u0026#34;suffix\u0026#34;: \u0026#34;.csv\u0026#34;, \u0026#34;header\u0026#34;: [] } } } ] } } 3.2 参数说明 protocol\n描述：ftp服务器协议，目前支持传输协议有ftp和sftp。 必选：是 默认值：无 host\n描述：ftp服务器地址。 必选：是 默认值：无 port\n描述：ftp服务器端口。 必选：否 默认值：若传输协议是sftp协议，默认值是22；若传输协议是标准ftp协议，默认值是21 timeout\n描述：连接ftp服务器连接超时时间，单位毫秒。 必选：否 默认值：60000（1分钟）\nusername\n描述：ftp服务器访问用户名。 必选：是 默认值：无 password\n描述：ftp服务器访问密码。 必选：是 默认值：无 path\n描述：FTP文件系统的路径信息，FtpWriter会写入Path目录下属多个文件。 必选：是 默认值：无 fileName\n描述：FtpWriter写入的文件名，该文件名会添加随机的后缀作为每个线程写入实际文件名。 必选：是 默认值：无 writeMode\n描述：FtpWriter写入前数据清理处理模式： truncate，写入前清理目录下一fileName前缀的所有文件。 append，写入前不做任何处理，DataX FtpWriter直接使用filename写入，并保证文件名不冲突。 nonConflict，如果目录下有fileName前缀的文件，直接报错。 必选：是 默认值：无 fieldDelimiter\n描述：读取的字段分隔符 必选：否 默认值：, compress\n描述：文本压缩类型，暂时不支持。 必选：否 默认值：无压缩 encoding\n描述：读取文件的编码配置。\n必选：否 默认值：utf-8 nullFormat\n描述：文本文件中无法使用标准字符串定义null(空指针)，DataX提供nullFormat定义哪些字符串可以表示为null。\n例如如果用户配置: nullFormat=\u0026quot;\\N\u0026quot;，那么如果源头数据是\u0026quot;\\N\u0026quot;，DataX视作null字段。\n必选：否 默认值：\\N dateFormat\n描述：日期类型的数据序列化到文件中时的格式，例如 \u0026ldquo;dateFormat\u0026rdquo;: \u0026ldquo;yyyy-MM-dd\u0026rdquo;。\n必选：否 默认值：无 fileFormat\n描述：文件写出的格式，包括csv (http://zh.wikipedia.org/wiki/%E9%80%97%E5%8F%B7%E5%88%86%E9%9A%94%E5%80%BC) 和text两种，csv是严格的csv格式，如果待写数据包括列分隔符，则会按照csv的转义语法转义，转义符号为双引号\u0026quot;；text格式是用列分隔符简单分割待写数据，对于待写数据包括列分隔符情况下不做转义。\n必选：否 默认值：text suffix\n描述：最后输出文件的后缀，当前支持 \u0026ldquo;.text\u0026quot;以及\u0026rdquo;.csv\u0026quot;\n必选：否 默认值：\u0026quot;\u0026quot; header\n描述：txt写出时的表头，示例[\u0026lsquo;id\u0026rsquo;, \u0026rsquo;name\u0026rsquo;, \u0026lsquo;age\u0026rsquo;]。\n必选：否 默认值：无 3.3 类型转换 FTP文件本身不提供数据类型，该类型是DataX FtpWriter定义：\nDataX 内部类型 FTP文件 数据类型 Long Long -\u0026gt; 字符串序列化表示 Double Double -\u0026gt; 字符串序列化表示 String String -\u0026gt; 字符串序列化表示 Boolean Boolean -\u0026gt; 字符串序列化表示 Date Date -\u0026gt; 字符串序列化表示 其中：\nFTP文件 Long是指FTP文件文本中使用整形的字符串表示形式，例如\u0026quot;19901219\u0026quot;。 FTP文件 Double是指FTP文件文本中使用Double的字符串表示形式，例如\u0026quot;3.1415\u0026quot;。 FTP文件 Boolean是指FTP文件文本中使用Boolean的字符串表示形式，例如\u0026quot;true\u0026quot;、\u0026ldquo;false\u0026rdquo;。不区分大小写。 FTP文件 Date是指FTP文件文本中使用Date的字符串表示形式，例如\u0026quot;2014-12-31\u0026quot;，Date可以指定format格式。 4 性能报告 5 约束限制 略\n6 FAQ 略\n","permalink":"https://haokiu.com/blog/8f4c3b36705842458a8550717b87b66c/","summary":"DataX FtpWriter 说明 1 快速介绍 FtpWriter提供了向远程FTP文件写入CSV格式的一个或者多个文件，在底层实现上，FtpWriter将DataX传输协议下的数据转换为csv格式，并使用FTP相关的网络协议写出到远程FTP服务器。\n写入FTP文件内容存放的是一张逻辑意义上的二维表，例如CSV格式的文本信息。\n2 功能与限制 FtpWriter实现了从DataX协议转为FTP文件功能，FTP文件本身是无结构化数据存储，FtpWriter如下几个方面约定:\n支持且仅支持写入文本类型(不支持BLOB如视频数据)的文件，且要求文本中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n写出时不支持文本压缩。\n支持多线程写入，每个线程写入不同子文件。\n我们不能做到：\n单个文件不能支持并发写入。 3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: {}, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ftpwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;protocol\u0026#34;: \u0026#34;sftp\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;port\u0026#34;: 22, \u0026#34;username\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;timeout\u0026#34;: \u0026#34;60000\u0026#34;, \u0026#34;connectPattern\u0026#34;: \u0026#34;PASV\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/tmp/data/\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;yixiao\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate|append|nonConflict\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;nullFormat\u0026#34;: \u0026#34;null\u0026#34;, \u0026#34;dateFormat\u0026#34;: \u0026#34;yyyy-MM-dd\u0026#34;, \u0026#34;fileFormat\u0026#34;: \u0026#34;csv\u0026#34;, \u0026#34;suffix\u0026#34;: \u0026#34;.csv\u0026#34;, \u0026#34;header\u0026#34;: [] } } } ] } } 3.2 参数说明 protocol\n描述：ftp服务器协议，目前支持传输协议有ftp和sftp。 必选：是 默认值：无 host\n描述：ftp服务器地址。 必选：是 默认值：无 port\n描述：ftp服务器端口。 必选：否 默认值：若传输协议是sftp协议，默认值是22；若传输协议是标准ftp协议，默认值是21 timeout\n描述：连接ftp服务器连接超时时间，单位毫秒。 必选：否 默认值：60000（1分钟）","title":"DataX FtpWriter 说明"},{"content":"DataX GDBReader 1. 快速介绍 GDBReader插件实现读取GDB实例数据的功能，通过Gremlin Client连接远程GDB实例，按配置提供的label生成查询DSL，遍历点或边数据，包括属性数据，并将数据写入到Record中给到Writer使用。\n2. 实现原理 GDBReader使用Gremlin Client连接GDB实例，按label分不同Task取点或边数据。 单个Task中按label遍历点或边的id，再切分范围分多次请求查询点或边和属性数据，最后将点或边数据根据配置转换成指定格式记录发送给下游写插件。\nGDBReader按label切分多个Task并发，同一个label的数据批量异步获取来加快读取速度。如果配置读取的label列表为空，任务启动前会从GDB查询所有label再切分Task。\n3. 功能说明 GDB中点和边不同，读取需要区分点和边点配置。\n3.1 点配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } \u0026#34;errorLimit\u0026#34;: { \u0026#34;record\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;gdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;10.218.145.24\u0026#34;, \u0026#34;port\u0026#34;: 8182, \u0026#34;username\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;fetchBatchSize\u0026#34;: 100, \u0026#34;rangeSplitSize\u0026#34;: 1000, \u0026#34;labelType\u0026#34;: \u0026#34;VERTEX\u0026#34;, \u0026#34;labels\u0026#34;: [\u0026#34;label1\u0026#34;, \u0026#34;label2\u0026#34;], \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;primaryKey\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;label\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;primaryLabel\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;age\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;int\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;vertexProperty\u0026#34; } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: true } } } ] } } 3.2 边配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 }, \u0026#34;errorLimit\u0026#34;: { \u0026#34;record\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;gdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;10.218.145.24\u0026#34;, \u0026#34;port\u0026#34;: 8182, \u0026#34;username\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;fetchBatchSize\u0026#34;: 100, \u0026#34;rangeSplitSize\u0026#34;: 1000, \u0026#34;labelType\u0026#34;: \u0026#34;EDGE\u0026#34;, \u0026#34;labels\u0026#34;: [\u0026#34;label1\u0026#34;, \u0026#34;label2\u0026#34;], \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;primaryKey\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;label\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;primaryLabel\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;srcId\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;srcPrimaryKey\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;srcLabel\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;srcPrimaryLabel\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;dstId\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;srcPrimaryKey\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;dstLabel\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;srcPrimaryLabel\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;name\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;edgeProperty\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;weight\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;edgeProperty\u0026#34; } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: true } } } ] } } 3.3 参数说明 host\n描述：GDB实例连接地址，对应\u0026rsquo;实例管理\u0026rsquo;-\u0026gt;\u0026lsquo;基本信息\u0026rsquo;页面的网络地址 必选：是 默认值：无 port\n描述：GDB实例连接地址对应的端口 必选：是 默认值：8182 username\n描述：GDB实例账号名 必选：是 默认值：无 password\n描述：GDB实例账号名对应的密码 必选：是 默认值：无 fetchBatchSize\n描述：一次GDB请求读取点或边的数量，响应包含点或边以及属性 必选：是 默认值：100 rangeSplitSize\n描述：id遍历，一次遍历请求扫描的id个数 必选：是 默认值：10 * fetchBatchSize labels\n描述：标签数组，即需要导出的点或边标签，支持读取多个标签，用数组表示。如果留空([])，表示GDB中所有点或边标签 必选：是 默认值：无 labelType\n描述：数据标签类型，支持点、边两种枚举值 VERTEX：表示点 EDGE：表示边 必选：是 默认值：无 column\n描述：点或边字段映射关系配置 必选：是 默认值：无 column -\u0026gt; name\n描述：点或边映射关系的字段名，指定属性时表示读取的属性名，读取其他字段时会被忽略 必选：是 默认值：无 column -\u0026gt; type\n描述：点或边映射关系的字段类型 id, label在GDB中都是string类型，配置非string类型时可能会转换失败 普通属性支持基础类型，包括int, long, float, double, boolean, string GDBReader尽量将读取到的数据转换成配置要求的类型，但转换失败会导致该条记录错误 必选：是 默认值：无 column -\u0026gt; columnType\n描述：GDB点或边数据到列数据的映射关系，支持以下枚举值： primaryKey： 表示该字段是点或边的id primaryLabel： 表示该字段是点或边的label srcPrimaryKey： 表示该字段是边关联的起点id，只在读取边时使用 srcPrimaryLabel： 表示该字段是边关联的起点label，只在读取边时使用 dstPrimaryKey： 表示该字段是边关联的终点id，只在读取边时使用 dstPrimaryLabel： 表示该字段是边关联的终点label，只在读取边时使用 vertexProperty： 表示该字段是点的属性，只在读取点时使用，应用到SET属性时只读取其中的一个属性值 vertexJsonProperty： 表示该字段是点的属性集合，只在读取点时使用。属性集合使用JSON格式输出，包含所有的属性，不能与其他vertexProperty配置一起使用 edgeProperty： 表示该字段是边的属性，只在读取边时使用 edgeJsonProperty： 表示该字段是边的属性集合，只在读取边时使用。属性集合使用JSON格式输出，包含所有的属性，不能与其他edgeProperty配置一起使用 必选：是 默认值：无 vertexJsonProperty格式示例，新增c字段区分SET属性，但是SET属性只包含单个属性值时会标记成普通属性 {\u0026#34;properties\u0026#34;:[ {\u0026#34;k\u0026#34;:\u0026#34;name\u0026#34;,\u0026#34;t\u0026#34;,\u0026#34;string\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;Jack\u0026#34;,\u0026#34;c\u0026#34;:\u0026#34;set\u0026#34;}, {\u0026#34;k\u0026#34;:\u0026#34;name\u0026#34;,\u0026#34;t\u0026#34;,\u0026#34;string\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;Luck\u0026#34;,\u0026#34;c\u0026#34;:\u0026#34;set\u0026#34;}, {\u0026#34;k\u0026#34;:\u0026#34;age\u0026#34;,\u0026#34;t\u0026#34;,\u0026#34;int\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;20\u0026#34;,\u0026#34;c\u0026#34;:\u0026#34;single\u0026#34;} ]} edgeJsonProperty格式示例，边不支持多值属性 {\u0026#34;properties\u0026#34;:[ {\u0026#34;k\u0026#34;:\u0026#34;created_at\u0026#34;,\u0026#34;t\u0026#34;,\u0026#34;long\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;153498653\u0026#34;}, {\u0026#34;k\u0026#34;:\u0026#34;weight\u0026#34;,\u0026#34;t\u0026#34;,\u0026#34;double\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;3.14\u0026#34;} ]} 4 性能报告 (TODO)\n5 使用约束 无\n6 FAQ 无\n","permalink":"https://haokiu.com/blog/ef41ae35929b479db90214d2ebe5ff8a/","summary":"DataX GDBReader 1. 快速介绍 GDBReader插件实现读取GDB实例数据的功能，通过Gremlin Client连接远程GDB实例，按配置提供的label生成查询DSL，遍历点或边数据，包括属性数据，并将数据写入到Record中给到Writer使用。\n2. 实现原理 GDBReader使用Gremlin Client连接GDB实例，按label分不同Task取点或边数据。 单个Task中按label遍历点或边的id，再切分范围分多次请求查询点或边和属性数据，最后将点或边数据根据配置转换成指定格式记录发送给下游写插件。\nGDBReader按label切分多个Task并发，同一个label的数据批量异步获取来加快读取速度。如果配置读取的label列表为空，任务启动前会从GDB查询所有label再切分Task。\n3. 功能说明 GDB中点和边不同，读取需要区分点和边点配置。\n3.1 点配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } \u0026#34;errorLimit\u0026#34;: { \u0026#34;record\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;gdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;10.218.145.24\u0026#34;, \u0026#34;port\u0026#34;: 8182, \u0026#34;username\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;fetchBatchSize\u0026#34;: 100, \u0026#34;rangeSplitSize\u0026#34;: 1000, \u0026#34;labelType\u0026#34;: \u0026#34;VERTEX\u0026#34;, \u0026#34;labels\u0026#34;: [\u0026#34;label1\u0026#34;, \u0026#34;label2\u0026#34;], \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;primaryKey\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;label\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;primaryLabel\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;age\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;int\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;vertexProperty\u0026#34; } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: true } } } ] } } 3.","title":"DataX GDBReader"},{"content":"DataX GDBWriter 1 快速介绍 GDBWriter插件实现了写入数据到GDB实例的功能。GDBWriter通过Gremlin Client连接远程GDB实例，获取Reader的数据，生成写入DSL语句，将数据写入到GDB。\n2 实现原理 GDBWriter通过DataX框架获取Reader生成的协议数据，使用g.addV/E(GDB___label).property(id, GDB___id).property(GDB___PK1, GDB___PV1)...语句写入数据到GDB实例。\n可以配置Gremlin Client工作在session模式，由客户端控制事务，在一次事务中实现多个记录的批量写入。\n3 功能说明 因为GDB中点和边的配置不同，导入时需要区分点和边的配置。\n3.1 点配置样例 这里是一份从内存生成点数据导入GDB实例的配置 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;random\u0026#34;: \u0026#34;1,100\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;1000,1200\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;60,64\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;100,1000\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;32,48\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;gdbwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;gdb-endpoint\u0026#34;, \u0026#34;port\u0026#34;: 8182, \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;INSERT\u0026#34;, \u0026#34;labelType\u0026#34;: \u0026#34;VERTEX\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;#{1}\u0026#34;, \u0026#34;idTransRule\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;session\u0026#34;: true, \u0026#34;maxRecordsInBatch\u0026#34;: 64, \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{0}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;primaryKey\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;vertex_propKey\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{2}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;vertexSetProperty\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;vertex_propKey\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{3}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;vertexSetProperty\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;vertex_propKey2\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{4}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;vertexProperty\u0026#34; } ] } } } ] } } 3.2 边配置样例 这里是一份从内存生成边数据导入GDB实例的配置 注意 下面配置导入边时，需要提前在GDB实例中写入点，要求分别存在id为person-{{i}}和book-{{i}}的点，其中i取值0~100。\n{ \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;random\u0026#34;: \u0026#34;100,200\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;1,100\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;1,100\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;2000,2200\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;60,64\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;gdbwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;gdb-endpoint\u0026#34;, \u0026#34;port\u0026#34;: 8182, \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;INSERT\u0026#34;, \u0026#34;labelType\u0026#34;: \u0026#34;EDGE\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;#{3}\u0026#34;, \u0026#34;idTransRule\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;srcIdTransRule\u0026#34;: \u0026#34;labelPrefix\u0026#34;, \u0026#34;dstIdTransRule\u0026#34;: \u0026#34;labelPrefix\u0026#34;, \u0026#34;srcLabel\u0026#34;:\u0026#34;person-\u0026#34;, \u0026#34;dstLabel\u0026#34;:\u0026#34;book-\u0026#34;, \u0026#34;session\u0026#34;:false, \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{0}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;primaryKey\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{1}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;srcPrimaryKey\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{2}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;dstPrimaryKey\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;edge_propKey\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{4}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;edgeProperty\u0026#34; } ] } } } ] } } 3.3 参数说明 host\n描述：GDB实例连接域名，对应阿里云控制台-\u0026gt;\u0026ldquo;图数据库 GDB\u0026rdquo;-\u0026gt;\u0026ldquo;实例管理\u0026rdquo;-\u0026gt;\u0026ldquo;基本信息\u0026rdquo; 中的\u0026quot;内网地址\u0026quot;； 必选：是 默认值：无 port\n描述：GDB实例连接端口 必选：是 默认值：8182 username\n描述：GDB实例账号名 必选：是 默认值：无 password\n描述：图实例账号名对应密码 必选：是 默认值：无 label\n描述：类型名，即点/边名称； label支持从源列中读取，如#{0}，表示取第一列字段作为label名。源列索引从0开始； 必选：是 默认值：无 labelType\n描述：label类型； 枚举值\u0026quot;VERTEX\u0026quot;表示点 枚举值\u0026quot;EDGE\u0026quot;表示边 必选：是 默认值：无 srcLabel\n描述：当label为边时，表示起点的点名称；srcLabel支持从源列中读取，如#{0}，表示取第一列字段作为label名。源列索引从0开始； 必选：labelType为边，srcIdTransRule为none时可不填写，否则必填； 默认值：无 dstLabel\n描述：当label为边时，表示终点的点名称；dstLabel支持从源列中读取，如#{0}，表示取第一列字段作为label名。源列索引从0开始； 必选：labelType为边，dstIdTransRule为none时可不填写，否则必填； 默认值：无 writeMode\n描述：导入id重复时的处理模式； 枚举值\u0026quot;INSERT\u0026quot;表示会报错，错误记录数加1； 枚举值\u0026quot;MERGE\u0026quot;表示更新属性值，不计入错误； 枚举值\u0026quot;SKIP\u0026quot;表示跳过，不计入错误 必选：是 默认值：INSERT idTransRule\n描述：主键id转换规则； 枚举值\u0026quot;labelPrefix\u0026quot;表示将映射的值转换为{label名}{源字段} 枚举值\u0026quot;none\u0026quot;表示映射的值不做转换 必选：是 默认值：\u0026ldquo;none\u0026rdquo; srcIdTransRule\n描述：当label为边时，表示起点的主键id转换规则； 枚举值\u0026quot;labelPrefix\u0026quot;表示映射的值转换为为{label名}{源字段} 枚举值\u0026quot;none\u0026quot;表示映射的值不做转换，此时srcLabel 可不填写 必选：label为边时必选 默认值：\u0026ldquo;none\u0026rdquo; dstIdTransRule\n描述：当label为边时，表示终点的主键id转换规则； 枚举值\u0026quot;labelPrefix\u0026quot;表示映射的值转换为为{label名}{源字段} 枚举值\u0026quot;none\u0026quot;表示映射的值不做转换，此时dstLabel 可不填写 必选：label为边时必选 默认值：\u0026ldquo;none\u0026rdquo; session\n描述：是否使用Gremlin Client的session模式写入数据 必选：否 默认值：false maxRecordsInBatch\n描述：使用Gremlin Client的session模式时，一次事务处理的记录数 必选：否 默认值：16 column\n描述：点/边字段映射关系配置 必选：是 默认值：无 column -\u0026gt; name\n描述：点/边映射关系的字段名 必选：是 默认值：无 column -\u0026gt; value\n描述：点/边映射关系的字段值； #{N}表示直接映射源端值，N为源端column索引，从0开始；#{0}表示映射源端column第1个字段； test-#{0} 表示源端值做拼接转换，#{0}值前/后可添加固定字符串; #{0}-#{1}表示做多字段拼接，也可在任意位置添加固定字符串，如test-#{0}-test1-#{1}-test2 必选：是 默认值：无 column -\u0026gt; type\n描述：点/边映射关系的字段值类型； 主键id只支持string类型，GDBWriter插件会强制转换，源id必须保证可转换为string； 普通属性支持类型：int, long, float, double, boolean, string 必选：是 默认值：无 column -\u0026gt; columnType\n描述：点/边映射关系字段对应到GDB点/边数据的类型，支持以下几类枚举值： 公共枚举值： primaryKey：表示该字段是主键id 点枚举值： vertexProperty：labelType为点时，表示该字段是点的普通属性 vertexSetProperty：labelType为点时，表示该字段是点的SET属性，value是SET属性中的一个属性值 vertexJsonProperty：labelType为点时，表示是点json属性，value结构请见备注json properties示例，点配置最多只允许出现一个json属性； 边枚举值： srcPrimaryKey：labelType为边时，表示该字段是起点主键id dstPrimaryKey：labelType为边时，表示该字段是终点主键id edgeProperty：labelType为边时，表示该字段是边的普通属性 edgeJsonProperty：labelType为边时，表示是边json属性，value结构请见备注json properties示例，边配置最多只允许出现一个json属性； 必选：是 默认值：无 备注：json properties示例 {\u0026#34;properties\u0026#34;:[ {\u0026#34;k\u0026#34;:\u0026#34;name\u0026#34;,\u0026#34;t\u0026#34;:\u0026#34;string\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;tom\u0026#34;}, {\u0026#34;k\u0026#34;:\u0026#34;age\u0026#34;,\u0026#34;t\u0026#34;:\u0026#34;int\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;20\u0026#34;}, {\u0026#34;k\u0026#34;:\u0026#34;sex\u0026#34;,\u0026#34;t\u0026#34;:\u0026#34;string\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;male\u0026#34;} ]} # json格式同样支持给点添加SET属性，格式如下 {\u0026#34;properties\u0026#34;:[ {\u0026#34;k\u0026#34;:\u0026#34;name\u0026#34;,\u0026#34;t\u0026#34;:\u0026#34;string\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;tom\u0026#34;,\u0026#34;c\u0026#34;:\u0026#34;set\u0026#34;}, {\u0026#34;k\u0026#34;:\u0026#34;name\u0026#34;,\u0026#34;t\u0026#34;:\u0026#34;string\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;jack\u0026#34;,\u0026#34;c\u0026#34;:\u0026#34;set\u0026#34;}, {\u0026#34;k\u0026#34;:\u0026#34;age\u0026#34;,\u0026#34;t\u0026#34;:\u0026#34;int\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;20\u0026#34;}, {\u0026#34;k\u0026#34;:\u0026#34;sex\u0026#34;,\u0026#34;t\u0026#34;:\u0026#34;string\u0026#34;,\u0026#34;v\u0026#34;:\u0026#34;male\u0026#34;} ]} 4 性能报告 4.1 环境参数 GDB实例规格\n16core 128GB, 1TB SSD DataX压测机器\ncpu: 4 * Intel(R) Xeon(R) Platinum 8163 CPU @ 2.50GHz mem: 16GB net: 千兆双网卡 os: CentOS 7, 3.10.0-957.5.1.el7.x86_64 jvm: -Xms4g -Xmx4g 4.2 数据特征 { id: random double(1~10000) from: random long(1~40000000) to: random long(1~40000000) label: random long(20000000 ~ 20005000) propertyKey: random string(len: 120~128) propertyName: random string(len: 120~128) } 点/边都有一个属性，属性key和value都是长度120~128字节的随机字符串 label是范围20000000 ~ 20005000的随机整数转换的字符串 id是浮点数转换的字符串，防止重复 边包含关联起点和终点，测试边时已经提前导入twitter数据集的点数据(4200W) 4.3 任务配置 分点和边的配置，具体配置与上述的示例配置相似，下面列出关键的差异点\n增加并发任务数量 \u0026ldquo;channel\u0026rdquo;: 32\n使用session模式 \u0026ldquo;session\u0026rdquo;: true\n增加事务批量处理记录个数 \u0026ldquo;maxRecordsInBatch\u0026rdquo;: 128\n4.4 测试结果 点导入性能：\n任务平均流量： 4.07MB/s 任务总计耗时： 412s 记录写入速度： 15609rec/s 读出记录总数： 6400000 边导入性能：\n任务平均流量： 2.76MB/s 任务总计耗时： 1602s 记录写入速度： 10000rec/s 读出记录总数： 16000000 5 约束限制 导入边记录前要求GDB中已经存在边关联的起点/终点 GDBWriter插件与用户查询DSL使用相同的GDB实例端口，导入时可能会影响查询性能 FAQ 使用SET属性需要升级GDB实例到1.0.20版本及以上。 边只支持普通单值属性，不能给边写SET属性数据。 ","permalink":"https://haokiu.com/blog/3830a303d3e34cec88b98eab9934006d/","summary":"DataX GDBWriter 1 快速介绍 GDBWriter插件实现了写入数据到GDB实例的功能。GDBWriter通过Gremlin Client连接远程GDB实例，获取Reader的数据，生成写入DSL语句，将数据写入到GDB。\n2 实现原理 GDBWriter通过DataX框架获取Reader生成的协议数据，使用g.addV/E(GDB___label).property(id, GDB___id).property(GDB___PK1, GDB___PV1)...语句写入数据到GDB实例。\n可以配置Gremlin Client工作在session模式，由客户端控制事务，在一次事务中实现多个记录的批量写入。\n3 功能说明 因为GDB中点和边的配置不同，导入时需要区分点和边的配置。\n3.1 点配置样例 这里是一份从内存生成点数据导入GDB实例的配置 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;random\u0026#34;: \u0026#34;1,100\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;1000,1200\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;60,64\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;100,1000\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;random\u0026#34;: \u0026#34;32,48\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;gdbwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;gdb-endpoint\u0026#34;, \u0026#34;port\u0026#34;: 8182, \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;INSERT\u0026#34;, \u0026#34;labelType\u0026#34;: \u0026#34;VERTEX\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;#{1}\u0026#34;, \u0026#34;idTransRule\u0026#34;: \u0026#34;none\u0026#34;, \u0026#34;session\u0026#34;: true, \u0026#34;maxRecordsInBatch\u0026#34;: 64, \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{0}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;primaryKey\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;vertex_propKey\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{2}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;vertexSetProperty\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;vertex_propKey\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{3}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;vertexSetProperty\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;vertex_propKey2\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;#{4}\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;columnType\u0026#34;: \u0026#34;vertexProperty\u0026#34; } ] } } } ] } } 3.","title":"DataX GDBWriter"},{"content":"DataX HdfsReader 插件文档 1 快速介绍 HdfsReader提供了读取分布式文件系统数据存储的能力。在底层实现上，HdfsReader获取分布式文件系统上文件的数据，并转换为DataX传输协议传递给Writer。\n目前HdfsReader支持的文件格式有textfile（text）、orcfile（orc）、rcfile（rc）、sequence file（seq）和普通逻辑二维表（csv）类型格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表。\nHdfsReader需要Jdk1.7及以上版本的支持。\n2 功能与限制 HdfsReader实现了从Hadoop分布式文件系统Hdfs中读取文件数据并转为DataX协议的功能。textfile是Hive建表时默认使用的存储格式，数据不做压缩，本质上textfile就是以文本的形式将数据存放在hdfs中，对于DataX而言，HdfsReader实现上类比TxtFileReader，有诸多相似之处。orcfile，它的全名是Optimized Row Columnar file，是对RCFile做了优化。据官方文档介绍，这种文件格式可以提供一种高效的方法来存储Hive数据。HdfsReader利用Hive提供的OrcSerde类，读取解析orcfile文件的数据。目前HdfsReader支持的功能如下：\n支持textfile、orcfile、rcfile、sequence file和csv格式的文件，且要求文件内容存放的是一张逻辑意义上的二维表。\n支持多种类型数据读取(使用String表示)，支持列裁剪，支持列常量\n支持递归读取、支持正则表达式（\u0026quot;*\u0026ldquo;和\u0026rdquo;?\u0026quot;）。\n支持orcfile数据压缩，目前支持SNAPPY，ZLIB两种压缩方式。\n多个File可以支持并发读取。\n支持sequence file数据压缩，目前支持lzo压缩方式。\ncsv类型支持压缩格式有：gzip、bz2、zip、lzo、lzo_deflate、snappy。\n目前插件中Hive版本为1.1.1，Hadoop版本为2.7.1（Apache［为适配JDK1.7］,在Hadoop 2.5.0, Hadoop 2.6.0 和Hive 1.2.0测试环境中写入正常；其它版本需后期进一步测试；\n支持kerberos认证（注意：如果用户需要进行kerberos认证，那么用户使用的Hadoop集群版本需要和hdfsreader的Hadoop版本保持一致，如果高于hdfsreader的Hadoop版本，不保证kerberos认证有效）\n我们暂时不能做到：\n单个File支持多线程并发读取，这里涉及到单个File内部切分算法。二期考虑支持。 目前还不支持hdfs HA; 3 功能说明 3.1 配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hdfsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/user/hive/warehouse/mytable01/*\u0026#34;, \u0026#34;defaultFS\u0026#34;: \u0026#34;hdfs://xxx:port\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;hello\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; } ], \u0026#34;fileType\u0026#34;: \u0026#34;orc\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: true } } } ] } } 3.2 参数说明（各个配置项值前后不允许有空格） path\n描述：要读取的文件路径，如果要读取多个文件，可以使用正则表达式\u0026quot;*\u0026quot;，注意这里可以支持填写多个路径。。 当指定单个Hdfs文件，HdfsReader暂时只能使用单线程进行数据抽取。二期考虑在非压缩文件情况下针对单个File可以进行多线程并发读取。\n当指定多个Hdfs文件，HdfsReader支持使用多线程进行数据抽取。线程并发数通过通道数指定。\n当指定通配符，HdfsReader尝试遍历出多个文件信息。例如: 指定/代表读取/目录下所有的文件，指定/bazhen/*代表读取bazhen目录下游所有的文件。HdfsReader目前只支持\u0026quot;\u0026ldquo;和\u0026rdquo;?\u0026ldquo;作为文件通配符。\n特别需要注意的是，DataX会将一个作业下同步的所有的文件视作同一张数据表。用户必须自己保证所有的File能够适配同一套schema信息。并且提供给DataX权限可读。\n必选：是 默认值：无 defaultFS\n描述：Hadoop hdfs文件系统namenode节点地址。 目前HdfsReader已经支持Kerberos认证，如果需要权限认证，则需要用户配置kerberos参数，见下面\n必选：是 默认值：无 fileType\n描述：文件的类型，目前只支持用户配置为\u0026quot;text\u0026rdquo;、\u0026ldquo;orc\u0026rdquo;、\u0026ldquo;rc\u0026rdquo;、\u0026ldquo;seq\u0026rdquo;、\u0026ldquo;csv\u0026rdquo;。 text表示textfile文件格式\norc表示orcfile文件格式\nrc表示rcfile文件格式\nseq表示sequence file文件格式\ncsv表示普通hdfs文件格式（逻辑二维表）\n特别需要注意的是，HdfsReader能够自动识别文件是orcfile、textfile或者还是其它类型的文件，但该项是必填项，HdfsReader则会只读取用户配置的类型的文件，忽略路径下其他格式的文件\n另外需要注意的是，由于textfile和orcfile是两种完全不同的文件格式，所以HdfsReader对这两种文件的解析方式也存在差异，这种差异导致hive支持的复杂复合类型(比如map,array,struct,union)在转换为DataX支持的String类型时，转换的结果格式略有差异，比如以map类型为例：\norcfile map类型经hdfsreader解析转换成datax支持的string类型后，结果为\u0026quot;{job=80, team=60, person=70}\u0026quot;\ntextfile map类型经hdfsreader解析转换成datax支持的string类型后，结果为\u0026quot;job:80,team:60,person:70\u0026quot;\n从上面的转换结果可以看出，数据本身没有变化，但是表示的格式略有差异，所以如果用户配置的文件路径中要同步的字段在Hive中是复合类型的话，建议配置统一的文件格式。\n如果需要统一复合类型解析出来的格式，我们建议用户在hive客户端将textfile格式的表导成orcfile格式的表\n必选：是 默认值：无 column\n描述：读取字段列表，type指定源数据的类型，index指定当前列来自于文本第几列(以0开始)，value指定当前类型为常量，不从源头文件读取数据，而是根据value值自动生成对应的列。 默认情况下，用户可以全部按照String类型读取数据，配置如下：\n\u0026#34;column\u0026#34;: [\u0026#34;*\u0026#34;] 用户可以指定Column字段信息，配置如下：\n{ \u0026ldquo;type\u0026rdquo;: \u0026ldquo;long\u0026rdquo;, \u0026ldquo;index\u0026rdquo;: 0 //从本地文件文本第一列获取int字段 }, { \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo;, \u0026ldquo;value\u0026rdquo;: \u0026ldquo;alibaba\u0026rdquo; //HdfsReader内部生成alibaba的字符串字段作为当前字段 } ```\n对于用户指定Column信息，type必须填写，index/value必须选择其一。 * 必选：是 \u0026lt;br /\u0026gt; * 默认值：全部按照string类型读取 \u0026lt;br /\u0026gt; fieldDelimiter\n描述：读取的字段分隔符 另外需要注意的是，HdfsReader在读取textfile数据时，需要指定字段分割符，如果不指定默认为\u0026rsquo;,\u0026rsquo;，HdfsReader在读取orcfile时，用户无需指定字段分割符\n必选：否 默认值：, encoding\n描述：读取文件的编码配置。\n必选：否 默认值：utf-8 nullFormat\n描述：文本文件中无法使用标准字符串定义null(空指针)，DataX提供nullFormat定义哪些字符串可以表示为null。\n例如如果用户配置: nullFormat:\u0026quot;\\N\u0026quot;，那么如果源头数据是\u0026quot;\\N\u0026quot;，DataX视作null字段。\n必选：否 默认值：无 haveKerberos\n描述：是否有Kerberos认证，默认false\n例如如果用户配置true，则配置项kerberosKeytabFilePath，kerberosPrincipal为必填。\n必选：haveKerberos 为true必选 默认值：false kerberosKeytabFilePath\n描述：Kerberos认证 keytab文件路径，绝对路径\n必选：否 默认值：无 kerberosPrincipal\n描述：Kerberos认证Principal名，如xxxx/hadoopclient@xxx.xxx 必选：haveKerberos 为true必选 默认值：无 compress\n描述：当fileType（文件类型）为csv下的文件压缩方式，目前仅支持 gzip、bz2、zip、lzo、lzo_deflate、hadoop-snappy、framing-snappy压缩；值得注意的是，lzo存在两种压缩格式：lzo和lzo_deflate，用户在配置的时候需要留心，不要配错了；另外，由于snappy目前没有统一的stream format，datax目前只支持最主流的两种：hadoop-snappy（hadoop上的snappy stream format）和framing-snappy（google建议的snappy stream format）;orc文件类型下无需填写。\n必选：否 默认值：无 hadoopConfig\n描述：hadoopConfig里可以配置与Hadoop相关的一些高级参数，比如HA的配置。\n\u0026#34;hadoopConfig\u0026#34;:{ \u0026#34;dfs.nameservices\u0026#34;: \u0026#34;testDfs\u0026#34;, \u0026#34;dfs.ha.namenodes.testDfs\u0026#34;: \u0026#34;namenode1,namenode2\u0026#34;, \u0026#34;dfs.namenode.rpc-address.aliDfs.namenode1\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;dfs.namenode.rpc-address.aliDfs.namenode2\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;dfs.client.failover.proxy.provider.testDfs\u0026#34;: \u0026#34;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\u0026#34; } 必选：否 默认值：无 csvReaderConfig\n描述：读取CSV类型文件参数配置，Map类型。读取CSV类型文件使用的CsvReader进行读取，会有很多配置，不配置则使用默认值。\n必选：否 默认值：无 常见配置：\n\u0026#34;csvReaderConfig\u0026#34;:{ \u0026#34;safetySwitch\u0026#34;: false, \u0026#34;skipEmptyRecords\u0026#34;: false, \u0026#34;useTextQualifier\u0026#34;: false } 所有配置项及默认值,配置时 csvReaderConfig 的map中请严格按照以下字段名字进行配置：\nboolean caseSensitive = true; char textQualifier = 34; boolean trimWhitespace = true; boolean useTextQualifier = true;//是否使用csv转义字符 char delimiter = 44;//分隔符 char recordDelimiter = 0; char comment = 35; boolean useComments = false; int escapeMode = 1; boolean safetySwitch = true;//单列长度是否限制100000字符 boolean skipEmptyRecords = true;//是否跳过空行 boolean captureRawRecord = true; 3.3 类型转换 由于textfile和orcfile文件表的元数据信息由Hive维护并存放在Hive自己维护的数据库（如mysql）中，目前HdfsReader不支持对Hive元数\n据数据库进行访问查询，因此用户在进行类型转换的时候，必须指定数据类型，如果用户配置的column为\u0026quot;*\u0026quot;，则所有column默认转换为\nstring类型。HdfsReader提供了类型转换的建议表如下：\nDataX 内部类型 Hive表 数据类型 Long TINYINT,SMALLINT,INT,BIGINT Double FLOAT,DOUBLE String String,CHAR,VARCHAR,STRUCT,MAP,ARRAY,UNION,BINARY Boolean BOOLEAN Date Date,TIMESTAMP 其中：\nLong是指Hdfs文件文本中使用整形的字符串表示形式，例如\u0026quot;123456789\u0026quot;。 Double是指Hdfs文件文本中使用Double的字符串表示形式，例如\u0026quot;3.1415\u0026quot;。 Boolean是指Hdfs文件文本中使用Boolean的字符串表示形式，例如\u0026quot;true\u0026quot;、\u0026ldquo;false\u0026rdquo;。不区分大小写。 Date是指Hdfs文件文本中使用Date的字符串表示形式，例如\u0026quot;2014-12-31\u0026quot;。 特别提醒：\nHive支持的数据类型TIMESTAMP可以精确到纳秒级别，所以textfile、orcfile中TIMESTAMP存放的数据类似于\u0026quot;2015-08-21 22:40:47.397898389\u0026quot;，如果转换的类型配置为DataX的Date，转换之后会导致纳秒部分丢失，所以如果需要保留纳秒部分的数据，请配置转换类型为DataX的String类型。 3.4 按分区读取 Hive在建表的时候，可以指定分区partition，例如创建分区partition(day=\u0026ldquo;20150820\u0026rdquo;,hour=\u0026ldquo;09\u0026rdquo;)，对应的hdfs文件系统中，相应的表的目录下则会多出/20150820和/09两个目录，且/20150820是/09的父目录。了解了分区都会列成相应的目录结构，在按照某个分区读取某个表所有数据时，则只需配置好json中path的值即可。\n比如需要读取表名叫mytable01下分区day为20150820这一天的所有数据，则配置如下：\n\u0026#34;path\u0026#34;: \u0026#34;/user/hive/warehouse/mytable01/20150820/*\u0026#34; 4 性能报告 5 约束限制 略\n6 FAQ 如果报java.io.IOException: Maximum column length of 100,000 exceeded in column\u0026hellip;异常信息，说明数据源column字段长度超过了100000字符。 需要在json的reader里增加如下配置\n\u0026#34;csvReaderConfig\u0026#34;:{ \u0026#34;safetySwitch\u0026#34;: false, \u0026#34;skipEmptyRecords\u0026#34;: false, \u0026#34;useTextQualifier\u0026#34;: false } safetySwitch = false;//单列长度不限制100000字符\n","permalink":"https://haokiu.com/blog/e123c1afd572427f9fa4d27ba10b1e99/","summary":"DataX HdfsReader 插件文档 1 快速介绍 HdfsReader提供了读取分布式文件系统数据存储的能力。在底层实现上，HdfsReader获取分布式文件系统上文件的数据，并转换为DataX传输协议传递给Writer。\n目前HdfsReader支持的文件格式有textfile（text）、orcfile（orc）、rcfile（rc）、sequence file（seq）和普通逻辑二维表（csv）类型格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表。\nHdfsReader需要Jdk1.7及以上版本的支持。\n2 功能与限制 HdfsReader实现了从Hadoop分布式文件系统Hdfs中读取文件数据并转为DataX协议的功能。textfile是Hive建表时默认使用的存储格式，数据不做压缩，本质上textfile就是以文本的形式将数据存放在hdfs中，对于DataX而言，HdfsReader实现上类比TxtFileReader，有诸多相似之处。orcfile，它的全名是Optimized Row Columnar file，是对RCFile做了优化。据官方文档介绍，这种文件格式可以提供一种高效的方法来存储Hive数据。HdfsReader利用Hive提供的OrcSerde类，读取解析orcfile文件的数据。目前HdfsReader支持的功能如下：\n支持textfile、orcfile、rcfile、sequence file和csv格式的文件，且要求文件内容存放的是一张逻辑意义上的二维表。\n支持多种类型数据读取(使用String表示)，支持列裁剪，支持列常量\n支持递归读取、支持正则表达式（\u0026quot;*\u0026ldquo;和\u0026rdquo;?\u0026quot;）。\n支持orcfile数据压缩，目前支持SNAPPY，ZLIB两种压缩方式。\n多个File可以支持并发读取。\n支持sequence file数据压缩，目前支持lzo压缩方式。\ncsv类型支持压缩格式有：gzip、bz2、zip、lzo、lzo_deflate、snappy。\n目前插件中Hive版本为1.1.1，Hadoop版本为2.7.1（Apache［为适配JDK1.7］,在Hadoop 2.5.0, Hadoop 2.6.0 和Hive 1.2.0测试环境中写入正常；其它版本需后期进一步测试；\n支持kerberos认证（注意：如果用户需要进行kerberos认证，那么用户使用的Hadoop集群版本需要和hdfsreader的Hadoop版本保持一致，如果高于hdfsreader的Hadoop版本，不保证kerberos认证有效）\n我们暂时不能做到：\n单个File支持多线程并发读取，这里涉及到单个File内部切分算法。二期考虑支持。 目前还不支持hdfs HA; 3 功能说明 3.1 配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hdfsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/user/hive/warehouse/mytable01/*\u0026#34;, \u0026#34;defaultFS\u0026#34;: \u0026#34;hdfs://xxx:port\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;hello\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; } ], \u0026#34;fileType\u0026#34;: \u0026#34;orc\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: true } } } ] } } 3.","title":"DataX HdfsReader 插件文档"},{"content":"DataX HdfsWriter 插件文档 1 快速介绍 HdfsWriter提供向HDFS文件系统指定路径中写入TEXTFile文件和ORCFile文件,文件内容可与hive中表关联。\n2 功能与限制 (1)、目前HdfsWriter仅支持textfile和orcfile两种格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表; (2)、由于HDFS是文件系统，不存在schema的概念，因此不支持对部分列写入; (3)、目前仅支持与以下Hive数据类型： 数值型：TINYINT,SMALLINT,INT,BIGINT,FLOAT,DOUBLE 字符串类型：STRING,VARCHAR,CHAR 布尔类型：BOOLEAN 时间类型：DATE,TIMESTAMP 目前不支持：decimal、binary、arrays、maps、structs、union类型; (4)、对于Hive分区表目前仅支持一次写入单个分区; (5)、对于textfile需用户保证写入hdfs文件的分隔符与在Hive上创建表时的分隔符一致,从而实现写入hdfs数据与Hive表字段关联; (6)、HdfsWriter实现过程是：首先根据用户指定的path，创建一个hdfs文件系统上不存在的临时目录，创建规则：path_随机；然后将读取的文件写入这个临时目录；全部写入后再将这个临时目录下的文件移动到用户指定目录（在创建文件时保证文件名不重复）; 最后删除临时目录。如果在中间过程发生网络中断等情况造成无法与hdfs建立连接，需要用户手动删除已经写入的文件和临时目录。 (7)、目前插件中Hive版本为1.1.1，Hadoop版本为2.7.1（Apache［为适配JDK1.7］,在Hadoop 2.5.0, Hadoop 2.6.0 和Hive 1.2.0测试环境中写入正常；其它版本需后期进一步测试； (8)、目前HdfsWriter支持Kerberos认证（注意：如果用户需要进行kerberos认证，那么用户使用的Hadoop集群版本需要和hdfsreader的Hadoop版本保持一致，如果高于hdfsreader的Hadoop版本，不保证kerberos认证有效） 3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: [\u0026#34;/Users/shf/workplace/txtWorkplace/job/dataorcfull.txt\u0026#34;], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;DOUBLE\u0026#34; }, { \u0026#34;index\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;DOUBLE\u0026#34; }, { \u0026#34;index\u0026#34;: 6, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, { \u0026#34;index\u0026#34;: 7, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, { \u0026#34;index\u0026#34;: 8, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, { \u0026#34;index\u0026#34;: 9, \u0026#34;type\u0026#34;: \u0026#34;BOOLEAN\u0026#34; }, { \u0026#34;index\u0026#34;: 10, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;index\u0026#34;: 11, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;\\t\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hdfswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;defaultFS\u0026#34;: \u0026#34;hdfs://xxx:port\u0026#34;, \u0026#34;fileType\u0026#34;: \u0026#34;orc\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/user/hive/warehouse/writerorc.db/orcfull\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;xxxx\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;col1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;TINYINT\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;SMALLINT\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col3\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;INT\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col4\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;BIGINT\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col5\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;FLOAT\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col6\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;DOUBLE\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col7\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col8\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;VARCHAR\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col9\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;CHAR\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col10\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;BOOLEAN\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col11\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;col12\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;TIMESTAMP\u0026#34; } ], \u0026#34;writeMode\u0026#34;: \u0026#34;append\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;\\t\u0026#34;, \u0026#34;compress\u0026#34;:\u0026#34;NONE\u0026#34; } } } ] } } 3.2 参数说明 defaultFS\n描述：Hadoop hdfs文件系统namenode节点地址。格式：hdfs://ip:端口；例如：hdfs://127.0.0.1:9000\n必选：是 默认值：无 fileType\n描述：文件的类型，目前只支持用户配置为\u0026quot;text\u0026quot;或\u0026quot;orc\u0026quot;。 text表示textfile文件格式\norc表示orcfile文件格式\n必选：是 默认值：无 path\n描述：存储到Hadoop hdfs文件系统的路径信息，HdfsWriter会根据并发配置在Path目录下写入多个文件。为与hive表关联，请填写hive表在hdfs上的存储路径。例：Hive上设置的数据仓库的存储路径为：/user/hive/warehouse/ ，已建立数据库：test，表：hello；则对应的存储路径为：/user/hive/warehouse/test.db/hello 必选：是 默认值：无 fileName\n描述：HdfsWriter写入时的文件名，实际执行时会在该文件名后添加随机的后缀作为每个线程写入实际文件名。 必选：是 默认值：无 column\n描述：写入数据的字段，不支持对部分列写入。为与hive中表关联，需要指定表中所有字段名和字段类型，其中：name指定字段名，type指定字段类型。 用户可以指定Column字段信息，配置如下：\n\u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;userName\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;age\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; } ] 必选：是 默认值：无 writeMode\n描述：hdfswriter写入前数据清理处理模式： append，写入前不做任何处理，DataX hdfswriter直接使用filename写入，并保证文件名不冲突。 nonConflict，如果目录下有fileName前缀的文件，直接报错。 必选：是 默认值：无 fieldDelimiter\n描述：hdfswriter写入时的字段分隔符,需要用户保证与创建的Hive表的字段分隔符一致，否则无法在Hive表中查到数据 必选：是 默认值：无 compress\n描述：hdfs文件压缩类型，默认不填写意味着没有压缩。其中：text类型文件支持压缩类型有gzip、bzip2;orc类型文件支持的压缩类型有NONE、SNAPPY（需要用户安装SnappyCodec）。 必选：否 默认值：无压缩 hadoopConfig\n描述：hadoopConfig里可以配置与Hadoop相关的一些高级参数，比如HA的配置。\n\u0026#34;hadoopConfig\u0026#34;:{ \u0026#34;dfs.nameservices\u0026#34;: \u0026#34;testDfs\u0026#34;, \u0026#34;dfs.ha.namenodes.testDfs\u0026#34;: \u0026#34;namenode1,namenode2\u0026#34;, \u0026#34;dfs.namenode.rpc-address.aliDfs.namenode1\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;dfs.namenode.rpc-address.aliDfs.namenode2\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;dfs.client.failover.proxy.provider.testDfs\u0026#34;: \u0026#34;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider\u0026#34; } 必选：否 默认值：无 encoding\n描述：写文件的编码配置。\n必选：否 默认值：utf-8，慎重修改 haveKerberos\n描述：是否有Kerberos认证，默认false\n例如如果用户配置true，则配置项kerberosKeytabFilePath，kerberosPrincipal为必填。\n必选：haveKerberos 为true必选 默认值：false kerberosKeytabFilePath\n描述：Kerberos认证 keytab文件路径，绝对路径\n必选：否 默认值：无 kerberosPrincipal\n描述：Kerberos认证Principal名，如xxxx/hadoopclient@xxx.xxx 必选：haveKerberos 为true必选 默认值：无 3.3 类型转换 目前 HdfsWriter 支持大部分 Hive 类型，请注意检查你的类型。\n下面列出 HdfsWriter 针对 Hive 数据类型转换列表:\nDataX 内部类型 HIVE 数据类型 Long TINYINT,SMALLINT,INT,BIGINT Double FLOAT,DOUBLE String STRING,VARCHAR,CHAR Boolean BOOLEAN Date DATE,TIMESTAMP 4 配置步骤 步骤一、在Hive中创建数据库、表 Hive数据库在HDFS上存储配置,在hive安装目录下 conf/hive-site.xml文件中配置，默认值为：/user/hive/warehouse 如下所示： \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hive.metastore.warehouse.dir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;/user/hive/warehouse\u0026lt;/value\u0026gt; \u0026lt;description\u0026gt;location of default database for the warehouse\u0026lt;/description\u0026gt; \u0026lt;/property\u0026gt; Hive建库／建表语法 参考 Hive操作手册\n例： （1）建立存储为textfile文件类型的表\ncreate database IF NOT EXISTS hdfswriter; use hdfswriter; create table text_table( col1 TINYINT, col2 SMALLINT, col3 INT, col4 BIGINT, col5 FLOAT, col6 DOUBLE, col7 STRING, col8 VARCHAR(10), col9 CHAR(10), col10 BOOLEAN, col11 date, col12 TIMESTAMP ) row format delimited fields terminated by \u0026#34;\\t\u0026#34; STORED AS TEXTFILE; text_table在hdfs上存储路径为：/user/hive/warehouse/hdfswriter.db/text_table/\n（2）建立存储为orcfile文件类型的表\ncreate database IF NOT EXISTS hdfswriter; use hdfswriter; create table orc_table( col1 TINYINT, col2 SMALLINT, col3 INT, col4 BIGINT, col5 FLOAT, col6 DOUBLE, col7 STRING, col8 VARCHAR(10), col9 CHAR(10), col10 BOOLEAN, col11 date, col12 TIMESTAMP ) ROW FORMAT DELIMITED FIELDS TERMINATED BY \u0026#39;\\t\u0026#39; STORED AS ORC; orc_table在hdfs上存储路径为：/user/hive/warehouse/hdfswriter.db/orc_table/\n步骤二、根据步骤一的配置信息配置HdfsWriter作业 5 约束限制 略\n6 FAQ 略\n","permalink":"https://haokiu.com/blog/dd5ebd2f221f4913ae09f61f3877725e/","summary":"DataX HdfsWriter 插件文档 1 快速介绍 HdfsWriter提供向HDFS文件系统指定路径中写入TEXTFile文件和ORCFile文件,文件内容可与hive中表关联。\n2 功能与限制 (1)、目前HdfsWriter仅支持textfile和orcfile两种格式的文件，且文件内容存放的必须是一张逻辑意义上的二维表; (2)、由于HDFS是文件系统，不存在schema的概念，因此不支持对部分列写入; (3)、目前仅支持与以下Hive数据类型： 数值型：TINYINT,SMALLINT,INT,BIGINT,FLOAT,DOUBLE 字符串类型：STRING,VARCHAR,CHAR 布尔类型：BOOLEAN 时间类型：DATE,TIMESTAMP 目前不支持：decimal、binary、arrays、maps、structs、union类型; (4)、对于Hive分区表目前仅支持一次写入单个分区; (5)、对于textfile需用户保证写入hdfs文件的分隔符与在Hive上创建表时的分隔符一致,从而实现写入hdfs数据与Hive表字段关联; (6)、HdfsWriter实现过程是：首先根据用户指定的path，创建一个hdfs文件系统上不存在的临时目录，创建规则：path_随机；然后将读取的文件写入这个临时目录；全部写入后再将这个临时目录下的文件移动到用户指定目录（在创建文件时保证文件名不重复）; 最后删除临时目录。如果在中间过程发生网络中断等情况造成无法与hdfs建立连接，需要用户手动删除已经写入的文件和临时目录。 (7)、目前插件中Hive版本为1.1.1，Hadoop版本为2.7.1（Apache［为适配JDK1.7］,在Hadoop 2.5.0, Hadoop 2.6.0 和Hive 1.2.0测试环境中写入正常；其它版本需后期进一步测试； (8)、目前HdfsWriter支持Kerberos认证（注意：如果用户需要进行kerberos认证，那么用户使用的Hadoop集群版本需要和hdfsreader的Hadoop版本保持一致，如果高于hdfsreader的Hadoop版本，不保证kerberos认证有效） 3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: [\u0026#34;/Users/shf/workplace/txtWorkplace/job/dataorcfull.txt\u0026#34;], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;DOUBLE\u0026#34; }, { \u0026#34;index\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;DOUBLE\u0026#34; }, { \u0026#34;index\u0026#34;: 6, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, { \u0026#34;index\u0026#34;: 7, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, { \u0026#34;index\u0026#34;: 8, \u0026#34;type\u0026#34;: \u0026#34;STRING\u0026#34; }, { \u0026#34;index\u0026#34;: 9, \u0026#34;type\u0026#34;: \u0026#34;BOOLEAN\u0026#34; }, { \u0026#34;index\u0026#34;: 10, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;index\u0026#34;: 11, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;\\t\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hdfswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;defaultFS\u0026#34;: \u0026#34;hdfs://xxx:port\u0026#34;, \u0026#34;fileType\u0026#34;: \u0026#34;orc\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/user/hive/warehouse/writerorc.","title":"DataX HdfsWriter 插件文档"},{"content":"DataX KingbaseesWriter 1 快速介绍 KingbaseesWriter插件实现了写入数据到 KingbaseES主库目的表的功能。在底层实现上，KingbaseesWriter通过JDBC连接远程 KingbaseES 数据库，并执行相应的 insert into \u0026hellip; sql 语句将数据写入 KingbaseES，内部会分批次提交入库。\nKingbaseesWriter面向ETL开发工程师，他们使用KingbaseesWriter从数仓导入数据到KingbaseES。同时 KingbaseesWriter亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 KingbaseesWriter通过 DataX 框架获取 Reader 生成的协议数据，根据你配置生成相应的SQL插入语句\ninsert into...(当主键/唯一性索引冲突时会写不进去冲突的行) 注意： 1. 目的表所在数据库必须是主库才能写入数据；整个任务至少需具备 insert into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 2. KingbaseesWriter和MysqlWriter不同，不支持配置writeMode参数。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 KingbaseesWriter导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;kingbaseeswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from test\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:kingbase8://127.0.0.1:3002/datax\u0026#34;, \u0026#34;table\u0026#34;: [ \u0026#34;test\u0026#34; ] } ] } } } ] } } 3.2 参数说明 jdbcUrl\n描述：目的数据库的 JDBC 连接信息 ,jdbcUrl必须包含在connection配置单元中。\n注意：1、在一个数据库上只能配置一个值。 2、jdbcUrl按照KingbaseES官方规范，并可以填写连接附加参数信息。具体请参看KingbaseES官方文档或者咨询对应 DBA。\n必选：是 默认值：无 username\n描述：目的数据库的用户名 必选：是 默认值：无 password\n描述：目的数据库的密码 必选：是 默认值：无 table\n描述：目的表的表名称。支持写入一个或者多个表。当配置为多张表时，必须确保所有表结构保持一致。\n注意：table 和 jdbcUrl 必须包含在 connection 配置单元中 必选：是 默认值：无 column\n描述：目的表需要写入数据的字段,字段之间用英文逗号分隔。例如: \u0026ldquo;column\u0026rdquo;: [\u0026ldquo;id\u0026rdquo;,\u0026ldquo;name\u0026rdquo;,\u0026ldquo;age\u0026rdquo;]。如果要依次写入全部列，使用*表示, 例如: \u0026ldquo;column\u0026rdquo;: [\u0026quot;*\u0026quot;]\n注意：1、我们强烈不推荐你这样配置，因为当你目的表字段个数、类型等有改动时，你的任务可能运行不正确或者失败 2、此处 column 不能配置任何常量值 必选：是 默认值：否 preSql\n描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 @table 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, \u0026hellip; datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：\u0026quot;preSql\u0026quot;:[\u0026quot;delete from @table\u0026quot;]，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称 必选：否 默认值：无 postSql\n描述：写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ） 必选：否 默认值：无 batchSize\n描述：一次性批量提交的记录数大小，该值可以极大减少DataX与KingbaseES的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。\n必选：否 默认值：1024 3.3 类型转换 目前 KingbaseesWriter支持大部分 KingbaseES类型，但也存在部分没有支持的情况，请注意检查你的类型。\n下面列出 KingbaseesWriter针对 KingbaseES类型转换列表:\nDataX 内部类型 KingbaseES 数据类型 Long bigint, bigserial, integer, smallint, serial Double double precision, money, numeric, real String varchar, char, text, bit Date date, time, timestamp Boolean bool Bytes bytea FAQ Q: KingbaseesWriter 执行 postSql 语句报错，那么数据导入到目标数据库了吗?\nA: DataX 导入过程存在三块逻辑，pre 操作、导入操作、post 操作，其中任意一环报错，DataX 作业报错。由于 DataX 不能保证在同一个事务完成上述几个操作，因此有可能数据已经落入到目标端。\nQ: 按照上述说法，那么有部分脏数据导入数据库，如果影响到线上数据库怎么办?\nA: 目前有两种解法，第一种配置 pre 语句，该 sql 可以清理当天导入数据， DataX 每次导入时候可以把上次清理干净并导入完整数据。 第二种，向临时表导入数据，完成后再 rename 到线上表。\n","permalink":"https://haokiu.com/blog/a50c2cb341e14f7d995d470380e24d34/","summary":"DataX KingbaseesWriter 1 快速介绍 KingbaseesWriter插件实现了写入数据到 KingbaseES主库目的表的功能。在底层实现上，KingbaseesWriter通过JDBC连接远程 KingbaseES 数据库，并执行相应的 insert into \u0026hellip; sql 语句将数据写入 KingbaseES，内部会分批次提交入库。\nKingbaseesWriter面向ETL开发工程师，他们使用KingbaseesWriter从数仓导入数据到KingbaseES。同时 KingbaseesWriter亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 KingbaseesWriter通过 DataX 框架获取 Reader 生成的协议数据，根据你配置生成相应的SQL插入语句\ninsert into...(当主键/唯一性索引冲突时会写不进去冲突的行) 注意： 1. 目的表所在数据库必须是主库才能写入数据；整个任务至少需具备 insert into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 2. KingbaseesWriter和MysqlWriter不同，不支持配置writeMode参数。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 KingbaseesWriter导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;kingbaseeswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from test\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:kingbase8://127.","title":"DataX KingbaseesWriter"},{"content":"Datax MongoDBReader 1 快速介绍 MongoDBReader 插件利用 MongoDB 的java客户端MongoClient进行MongoDB的读操作。最新版本的Mongo已经将DB锁的粒度从DB级别降低到document级别，配合上MongoDB强大的索引功能，基本可以达到高性能的读取MongoDB的需求。\n2 实现原理 MongoDBReader通过Datax框架从MongoDB并行的读取数据，通过主控的JOB程序按照指定的规则对MongoDB中的数据进行分片，并行读取，然后将MongoDB支持的类型通过逐一判断转换成Datax支持的类型。\n3 功能说明 该示例从ODPS读一份数据到MongoDB。\n{ \u0026quot;job\u0026quot;: { \u0026quot;setting\u0026quot;: { \u0026quot;speed\u0026quot;: { \u0026quot;channel\u0026quot;: 2 } }, \u0026quot;content\u0026quot;: [ { \u0026quot;reader\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;mongodbreader\u0026quot;, \u0026quot;parameter\u0026quot;: { \u0026quot;address\u0026quot;: [\u0026quot;127.0.0.1:27017\u0026quot;], \u0026quot;userName\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;userPassword\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;dbName\u0026quot;: \u0026quot;tag_per_data\u0026quot;, \u0026quot;collectionName\u0026quot;: \u0026quot;tag_data12\u0026quot;, \u0026quot;column\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;unique_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;sid\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;user_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;auction_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;content_type\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;pool_type\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;frontcat_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;spliter\u0026quot;: \u0026quot;\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;categoryid\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;spliter\u0026quot;: \u0026quot;\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;gmt_create\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;taglist\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;spliter\u0026quot;: \u0026quot; \u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;property\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scorea\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scoreb\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scorec\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; } ] } }, \u0026quot;writer\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;odpswriter\u0026quot;, \u0026quot;parameter\u0026quot;: { \u0026quot;project\u0026quot;: \u0026quot;tb_ai_recommendation\u0026quot;, \u0026quot;table\u0026quot;: \u0026quot;jianying_tag_datax_read_test01\u0026quot;, \u0026quot;column\u0026quot;: [ \u0026quot;unique_id\u0026quot;, \u0026quot;sid\u0026quot;, \u0026quot;user_id\u0026quot;, \u0026quot;auction_id\u0026quot;, \u0026quot;content_type\u0026quot;, \u0026quot;pool_type\u0026quot;, \u0026quot;frontcat_id\u0026quot;, \u0026quot;categoryid\u0026quot;, \u0026quot;gmt_create\u0026quot;, \u0026quot;taglist\u0026quot;, \u0026quot;property\u0026quot;, \u0026quot;scorea\u0026quot;, \u0026quot;scoreb\u0026quot; ], \u0026quot;accessId\u0026quot;: \u0026quot;**************\u0026quot;, \u0026quot;accessKey\u0026quot;: \u0026quot;********************\u0026quot;, \u0026quot;truncate\u0026quot;: true, \u0026quot;odpsServer\u0026quot;: \u0026quot;xxx/api\u0026quot;, \u0026quot;tunnelServer\u0026quot;: \u0026quot;xxx\u0026quot;, \u0026quot;accountType\u0026quot;: \u0026quot;aliyun\u0026quot; } } } ] } } 4 参数说明 address： MongoDB的数据地址信息，因为MonogDB可能是个集群，则ip端口信息需要以Json数组的形式给出。【必填】 userName：MongoDB的用户名。【选填】 userPassword： MongoDB的密码。【选填】 collectionName： MonogoDB的集合名。【必填】 column：MongoDB的文档列名。【必填】 name：Column的名字。【必填】 type：Column的类型。【选填】 splitter：因为MongoDB支持数组类型，但是Datax框架本身不支持数组类型，所以mongoDB读出来的数组类型要通过这个分隔符合并成字符串。【选填】 query: MongoDB的额外查询条件。【选填】 5 类型转换 DataX 内部类型 MongoDB 数据类型 Long int, Long Double double String string, array Date date Boolean boolean Bytes bytes 6 性能报告 7 测试报告 ","permalink":"https://haokiu.com/blog/41dfc822f8ca4bca812501f2801fc78e/","summary":"Datax MongoDBReader 1 快速介绍 MongoDBReader 插件利用 MongoDB 的java客户端MongoClient进行MongoDB的读操作。最新版本的Mongo已经将DB锁的粒度从DB级别降低到document级别，配合上MongoDB强大的索引功能，基本可以达到高性能的读取MongoDB的需求。\n2 实现原理 MongoDBReader通过Datax框架从MongoDB并行的读取数据，通过主控的JOB程序按照指定的规则对MongoDB中的数据进行分片，并行读取，然后将MongoDB支持的类型通过逐一判断转换成Datax支持的类型。\n3 功能说明 该示例从ODPS读一份数据到MongoDB。\n{ \u0026quot;job\u0026quot;: { \u0026quot;setting\u0026quot;: { \u0026quot;speed\u0026quot;: { \u0026quot;channel\u0026quot;: 2 } }, \u0026quot;content\u0026quot;: [ { \u0026quot;reader\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;mongodbreader\u0026quot;, \u0026quot;parameter\u0026quot;: { \u0026quot;address\u0026quot;: [\u0026quot;127.0.0.1:27017\u0026quot;], \u0026quot;userName\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;userPassword\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;dbName\u0026quot;: \u0026quot;tag_per_data\u0026quot;, \u0026quot;collectionName\u0026quot;: \u0026quot;tag_data12\u0026quot;, \u0026quot;column\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;unique_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;sid\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;user_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;auction_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;content_type\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;pool_type\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;frontcat_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;spliter\u0026quot;: \u0026quot;\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;categoryid\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;spliter\u0026quot;: \u0026quot;\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;gmt_create\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;taglist\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;spliter\u0026quot;: \u0026quot; \u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;property\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scorea\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scoreb\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scorec\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; } ] } }, \u0026quot;writer\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;odpswriter\u0026quot;, \u0026quot;parameter\u0026quot;: { \u0026quot;project\u0026quot;: \u0026quot;tb_ai_recommendation\u0026quot;, \u0026quot;table\u0026quot;: \u0026quot;jianying_tag_datax_read_test01\u0026quot;, \u0026quot;column\u0026quot;: [ \u0026quot;unique_id\u0026quot;, \u0026quot;sid\u0026quot;, \u0026quot;user_id\u0026quot;, \u0026quot;auction_id\u0026quot;, \u0026quot;content_type\u0026quot;, \u0026quot;pool_type\u0026quot;, \u0026quot;frontcat_id\u0026quot;, \u0026quot;categoryid\u0026quot;, \u0026quot;gmt_create\u0026quot;, \u0026quot;taglist\u0026quot;, \u0026quot;property\u0026quot;, \u0026quot;scorea\u0026quot;, \u0026quot;scoreb\u0026quot; ], \u0026quot;accessId\u0026quot;: \u0026quot;**************\u0026quot;, \u0026quot;accessKey\u0026quot;: \u0026quot;********************\u0026quot;, \u0026quot;truncate\u0026quot;: true, \u0026quot;odpsServer\u0026quot;: \u0026quot;xxx/api\u0026quot;, \u0026quot;tunnelServer\u0026quot;: \u0026quot;xxx\u0026quot;, \u0026quot;accountType\u0026quot;: \u0026quot;aliyun\u0026quot; } } } ] } } 4 参数说明 address： MongoDB的数据地址信息，因为MonogDB可能是个集群，则ip端口信息需要以Json数组的形式给出。【必填】 userName：MongoDB的用户名。【选填】 userPassword： MongoDB的密码。【选填】 collectionName： MonogoDB的集合名。【必填】 column：MongoDB的文档列名。【必填】 name：Column的名字。【必填】 type：Column的类型。【选填】 splitter：因为MongoDB支持数组类型，但是Datax框架本身不支持数组类型，所以mongoDB读出来的数组类型要通过这个分隔符合并成字符串。【选填】 query: MongoDB的额外查询条件。【选填】 5 类型转换 DataX 内部类型 MongoDB 数据类型 Long int, Long Double double String string, array Date date Boolean boolean Bytes bytes 6 性能报告 7 测试报告 ","title":"Datax MongoDBReader"},{"content":"Datax MongoDBWriter 1 快速介绍 MongoDBWriter 插件利用 MongoDB 的java客户端MongoClient进行MongoDB的写操作。最新版本的Mongo已经将DB锁的粒度从DB级别降低到document级别，配合上MongoDB强大的索引功能，基本可以满足数据源向MongoDB写入数据的需求，针对数据更新的需求，通过配置业务主键的方式也可以实现。\n2 实现原理 MongoDBWriter通过Datax框架获取Reader生成的数据，然后将Datax支持的类型通过逐一判断转换成MongoDB支持的类型。其中一个值得指出的点就是Datax本身不支持数组类型，但是MongoDB支持数组类型，并且数组类型的索引还是蛮强大的。为了使用MongoDB的数组类型，则可以通过参数的特殊配置，将字符串可以转换成MongoDB中的数组。类型转换之后，就可以依托于Datax框架并行的写入MongoDB。\n3 功能说明 该示例从ODPS读一份数据到MongoDB。\n{ \u0026quot;job\u0026quot;: { \u0026quot;setting\u0026quot;: { \u0026quot;speed\u0026quot;: { \u0026quot;channel\u0026quot;: 2 } }, \u0026quot;content\u0026quot;: [ { \u0026quot;reader\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;odpsreader\u0026quot;, \u0026quot;parameter\u0026quot;: { \u0026quot;accessId\u0026quot;: \u0026quot;********\u0026quot;, \u0026quot;accessKey\u0026quot;: \u0026quot;*********\u0026quot;, \u0026quot;project\u0026quot;: \u0026quot;tb_ai_recommendation\u0026quot;, \u0026quot;table\u0026quot;: \u0026quot;jianying_tag_datax_test\u0026quot;, \u0026quot;column\u0026quot;: [ \u0026quot;unique_id\u0026quot;, \u0026quot;sid\u0026quot;, \u0026quot;user_id\u0026quot;, \u0026quot;auction_id\u0026quot;, \u0026quot;content_type\u0026quot;, \u0026quot;pool_type\u0026quot;, \u0026quot;frontcat_id\u0026quot;, \u0026quot;categoryid\u0026quot;, \u0026quot;gmt_create\u0026quot;, \u0026quot;taglist\u0026quot;, \u0026quot;property\u0026quot;, \u0026quot;scorea\u0026quot;, \u0026quot;scoreb\u0026quot; ], \u0026quot;splitMode\u0026quot;: \u0026quot;record\u0026quot;, \u0026quot;odpsServer\u0026quot;: \u0026quot;http://xxx/api\u0026quot; } }, \u0026quot;writer\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;mongodbwriter\u0026quot;, \u0026quot;parameter\u0026quot;: { \u0026quot;address\u0026quot;: [ \u0026quot;127.0.0.1:27017\u0026quot; ], \u0026quot;userName\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;userPassword\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;dbName\u0026quot;: \u0026quot;tag_per_data\u0026quot;, \u0026quot;collectionName\u0026quot;: \u0026quot;tag_data\u0026quot;, \u0026quot;column\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;unique_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;sid\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;user_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;auction_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;content_type\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;pool_type\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;frontcat_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;splitter\u0026quot;: \u0026quot; \u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;categoryid\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;splitter\u0026quot;: \u0026quot; \u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;gmt_create\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;taglist\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;splitter\u0026quot;: \u0026quot; \u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;property\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scorea\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scoreb\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scorec\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; } ], \u0026quot;upsertInfo\u0026quot;: { \u0026quot;isUpsert\u0026quot;: \u0026quot;true\u0026quot;, \u0026quot;upsertKey\u0026quot;: \u0026quot;unique_id\u0026quot; } } } } ] } } 4 参数说明 address： MongoDB的数据地址信息，因为MonogDB可能是个集群，则ip端口信息需要以Json数组的形式给出。【必填】 userName：MongoDB的用户名。【选填】 userPassword： MongoDB的密码。【选填】 collectionName： MonogoDB的集合名。【必填】 column：MongoDB的文档列名。【必填】 name：Column的名字。【必填】 type：Column的类型。【选填】 splitter：特殊分隔符，当且仅当要处理的字符串要用分隔符分隔为字符数组时，才使用这个参数，通过这个参数指定的分隔符，将字符串分隔存储到MongoDB的数组中。【选填】 upsertInfo：指定了传输数据时更新的信息。【选填】 isUpsert：当设置为true时，表示针对相同的upsertKey做更新操作。【选填】 upsertKey：upsertKey指定了没行记录的业务主键。用来做更新时使用。【选填】 5 类型转换 DataX 内部类型 MongoDB 数据类型 Long int, Long Double double String string, array Date date Boolean boolean Bytes bytes 6 性能报告 7 测试报告 ","permalink":"https://haokiu.com/blog/1b755458e9fa4e6f89a7d44321cd92ec/","summary":"Datax MongoDBWriter 1 快速介绍 MongoDBWriter 插件利用 MongoDB 的java客户端MongoClient进行MongoDB的写操作。最新版本的Mongo已经将DB锁的粒度从DB级别降低到document级别，配合上MongoDB强大的索引功能，基本可以满足数据源向MongoDB写入数据的需求，针对数据更新的需求，通过配置业务主键的方式也可以实现。\n2 实现原理 MongoDBWriter通过Datax框架获取Reader生成的数据，然后将Datax支持的类型通过逐一判断转换成MongoDB支持的类型。其中一个值得指出的点就是Datax本身不支持数组类型，但是MongoDB支持数组类型，并且数组类型的索引还是蛮强大的。为了使用MongoDB的数组类型，则可以通过参数的特殊配置，将字符串可以转换成MongoDB中的数组。类型转换之后，就可以依托于Datax框架并行的写入MongoDB。\n3 功能说明 该示例从ODPS读一份数据到MongoDB。\n{ \u0026quot;job\u0026quot;: { \u0026quot;setting\u0026quot;: { \u0026quot;speed\u0026quot;: { \u0026quot;channel\u0026quot;: 2 } }, \u0026quot;content\u0026quot;: [ { \u0026quot;reader\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;odpsreader\u0026quot;, \u0026quot;parameter\u0026quot;: { \u0026quot;accessId\u0026quot;: \u0026quot;********\u0026quot;, \u0026quot;accessKey\u0026quot;: \u0026quot;*********\u0026quot;, \u0026quot;project\u0026quot;: \u0026quot;tb_ai_recommendation\u0026quot;, \u0026quot;table\u0026quot;: \u0026quot;jianying_tag_datax_test\u0026quot;, \u0026quot;column\u0026quot;: [ \u0026quot;unique_id\u0026quot;, \u0026quot;sid\u0026quot;, \u0026quot;user_id\u0026quot;, \u0026quot;auction_id\u0026quot;, \u0026quot;content_type\u0026quot;, \u0026quot;pool_type\u0026quot;, \u0026quot;frontcat_id\u0026quot;, \u0026quot;categoryid\u0026quot;, \u0026quot;gmt_create\u0026quot;, \u0026quot;taglist\u0026quot;, \u0026quot;property\u0026quot;, \u0026quot;scorea\u0026quot;, \u0026quot;scoreb\u0026quot; ], \u0026quot;splitMode\u0026quot;: \u0026quot;record\u0026quot;, \u0026quot;odpsServer\u0026quot;: \u0026quot;http://xxx/api\u0026quot; } }, \u0026quot;writer\u0026quot;: { \u0026quot;name\u0026quot;: \u0026quot;mongodbwriter\u0026quot;, \u0026quot;parameter\u0026quot;: { \u0026quot;address\u0026quot;: [ \u0026quot;127.0.0.1:27017\u0026quot; ], \u0026quot;userName\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;userPassword\u0026quot;: \u0026quot;\u0026quot;, \u0026quot;dbName\u0026quot;: \u0026quot;tag_per_data\u0026quot;, \u0026quot;collectionName\u0026quot;: \u0026quot;tag_data\u0026quot;, \u0026quot;column\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;unique_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;sid\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;user_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;auction_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;content_type\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;pool_type\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;frontcat_id\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;splitter\u0026quot;: \u0026quot; \u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;categoryid\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;splitter\u0026quot;: \u0026quot; \u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;gmt_create\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;taglist\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;Array\u0026quot;, \u0026quot;splitter\u0026quot;: \u0026quot; \u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;property\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;string\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scorea\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scoreb\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;scorec\u0026quot;, \u0026quot;type\u0026quot;: \u0026quot;int\u0026quot; } ], \u0026quot;upsertInfo\u0026quot;: { \u0026quot;isUpsert\u0026quot;: \u0026quot;true\u0026quot;, \u0026quot;upsertKey\u0026quot;: \u0026quot;unique_id\u0026quot; } } } } ] } } 4 参数说明 address： MongoDB的数据地址信息，因为MonogDB可能是个集群，则ip端口信息需要以Json数组的形式给出。【必填】 userName：MongoDB的用户名。【选填】 userPassword： MongoDB的密码。【选填】 collectionName： MonogoDB的集合名。【必填】 column：MongoDB的文档列名。【必填】 name：Column的名字。【必填】 type：Column的类型。【选填】 splitter：特殊分隔符，当且仅当要处理的字符串要用分隔符分隔为字符数组时，才使用这个参数，通过这个参数指定的分隔符，将字符串分隔存储到MongoDB的数组中。【选填】 upsertInfo：指定了传输数据时更新的信息。【选填】 isUpsert：当设置为true时，表示针对相同的upsertKey做更新操作。【选填】 upsertKey：upsertKey指定了没行记录的业务主键。用来做更新时使用。【选填】 5 类型转换 DataX 内部类型 MongoDB 数据类型 Long int, Long Double double String string, array Date date Boolean boolean Bytes bytes 6 性能报告 7 测试报告 ","title":"Datax MongoDBWriter"},{"content":"DataX MysqlWriter 1 快速介绍 MysqlWriter 插件实现了写入数据到 Mysql 主库的目的表的功能。在底层实现上， MysqlWriter 通过 JDBC 连接远程 Mysql 数据库，并执行相应的 insert into \u0026hellip; 或者 ( replace into \u0026hellip;) 的 sql 语句将数据写入 Mysql，内部会分批次提交入库，需要数据库本身采用 innodb 引擎。\nMysqlWriter 面向ETL开发工程师，他们使用 MysqlWriter 从数仓导入数据到 Mysql。同时 MysqlWriter 亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 MysqlWriter 通过 DataX 框架获取 Reader 生成的协议数据，根据你配置的 writeMode 生成\ninsert into...(当主键/唯一性索引冲突时会写不进去冲突的行) 或者 replace into...(没有遇到主键/唯一性索引冲突时，与 insert into 行为一致，冲突时会用新行替换原有行所有字段) 的语句写入数据到 Mysql。出于性能考虑，采用了 PreparedStatement + Batch，并且设置了：rewriteBatchedStatements=true，将数据缓冲到线程上下文 Buffer 中，当 Buffer 累计到预定阈值时，才发起写入请求。 注意：目的表所在数据库必须是主库才能写入数据；整个任务至少需要具备 insert/replace into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 Mysql 导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;mysqlwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;writeMode\u0026#34;: \u0026#34;insert\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;session\u0026#34;: [ \u0026#34;set session sql_mode=\u0026#39;ANSI\u0026#39;\u0026#34; ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from test\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:mysql://127.0.0.1:3306/datax?useUnicode=true\u0026amp;characterEncoding=gbk\u0026#34;, \u0026#34;table\u0026#34;: [ \u0026#34;test\u0026#34; ] } ] } } } ] } } 3.2 参数说明 jdbcUrl\n描述：目的数据库的 JDBC 连接信息。作业运行时，DataX 会在你提供的 jdbcUrl 后面追加如下属性：yearIsDateType=false\u0026amp;zeroDateTimeBehavior=convertToNull\u0026amp;rewriteBatchedStatements=true\n注意：1、在一个数据库上只能配置一个 jdbcUrl 值。这与 MysqlReader 支持多个备库探测不同，因为此处不支持同一个数据库存在多个主库的情况(双主导入数据情况) 2、jdbcUrl按照Mysql官方规范，并可以填写连接附加控制信息，比如想指定连接编码为 gbk ，则在 jdbcUrl 后面追加属性 useUnicode=true\u0026amp;characterEncoding=gbk。具体请参看 Mysql官方文档或者咨询对应 DBA。 必选：是 默认值：无 username\n描述：目的数据库的用户名 必选：是 默认值：无 password\n描述：目的数据库的密码 必选：是 默认值：无 table\n描述：目的表的表名称。支持写入一个或者多个表。当配置为多张表时，必须确保所有表结构保持一致。\n注意：table 和 jdbcUrl 必须包含在 connection 配置单元中 必选：是 默认值：无 column\n描述：目的表需要写入数据的字段,字段之间用英文逗号分隔。例如: \u0026ldquo;column\u0026rdquo;: [\u0026ldquo;id\u0026rdquo;,\u0026ldquo;name\u0026rdquo;,\u0026ldquo;age\u0026rdquo;]。如果要依次写入全部列，使用*表示, 例如: \u0026quot;column\u0026quot;: [\u0026quot;*\u0026quot;]。\n**column配置项必须指定，不能留空！** 注意：1、我们强烈不推荐你这样配置，因为当你目的表字段个数、类型等有改动时，你的任务可能运行不正确或者失败 2、 column 不能配置任何常量值 必选：是 默认值：否 session\n描述: DataX在获取Mysql连接时，执行session指定的SQL语句，修改当前connection session属性\n必须: 否\n默认值: 空\npreSql\n描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 @table 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, \u0026hellip; datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：\u0026quot;preSql\u0026quot;:[\u0026quot;delete from 表名\u0026quot;]，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称 必选：否 默认值：无 postSql\n描述：写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ） 必选：否 默认值：无 writeMode\n描述：控制写入数据到目标表采用 insert into 或者 replace into 或者 ON DUPLICATE KEY UPDATE 语句\n必选：是 所有选项：insert/replace/update 默认值：insert batchSize\n描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Mysql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。\n必选：否 默认值：1024 3.3 类型转换 类似 MysqlReader ，目前 MysqlWriter 支持大部分 Mysql 类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出 MysqlWriter 针对 Mysql 类型转换列表:\nDataX 内部类型 Mysql 数据类型 Long int, tinyint, smallint, mediumint, int, bigint, year Double float, double, decimal String varchar, char, tinytext, text, mediumtext, longtext Date date, datetime, timestamp, time Boolean bit, bool Bytes tinyblob, mediumblob, blob, longblob, varbinary bit类型目前是未定义类型转换 4 性能报告 4.1 环境准备 4.1.1 数据特征 建表语句：\nCREATE TABLE `datax_mysqlwriter_perf_00` ( `biz_order_id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id', `key_value` varchar(4000) NOT NULL COMMENT 'Key-value的内容', `gmt_create` datetime NOT NULL COMMENT '创建时间', `gmt_modified` datetime NOT NULL COMMENT '修改时间', `attribute_cc` int(11) DEFAULT NULL COMMENT '防止并发修改的标志', `value_type` int(11) NOT NULL DEFAULT '0' COMMENT '类型', `buyer_id` bigint(20) DEFAULT NULL COMMENT 'buyerid', `seller_id` bigint(20) DEFAULT NULL COMMENT 'seller_id', PRIMARY KEY (`biz_order_id`,`value_type`), KEY `idx_biz_vertical_gmtmodified` (`gmt_modified`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='datax perf test' 单行记录类似于：\nkey_value: ;orderIds:20148888888,2014888888813800; gmt_create: 2011-09-24 11:07:20 gmt_modified: 2011-10-24 17:56:34 attribute_cc: 1 value_type: 3 buyer_id: 8888888 seller_id: 1 4.1.2 机器参数 执行DataX的机器参数为:\ncpu: 24核 Intel(R) Xeon(R) CPU E5-2630 0 @ 2.30GHz mem: 48GB net: 千兆双网卡 disc: DataX 数据不落磁盘，不统计此项 Mysql数据库机器参数为:\ncpu: 32核 Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz mem: 256GB net: 千兆双网卡 disc: BTWL419303E2800RGN INTEL SSDSC2BB800G4 D2010370 4.1.3 DataX jvm 参数 -Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError 4.2 测试报告 4.2.1 单表测试报告 通道数 批量提交行数 DataX速度(Rec/s) DataX流量(MB/s) DataX机器网卡流出流量(MB/s) DataX机器运行负载 DB网卡进入流量(MB/s) DB运行负载 DB TPS 1 128 5319 0.260 0.580 0.05 0.620 0.5 50 1 512 14285 0.697 1.6 0.12 1.6 0.6 28 1 1024 17241 0.842 1.9 0.20 1.9 0.6 16 1 2048 31250 1.49 2.8 0.15 3.0 0.8 15 1 4096 31250 1.49 3.5 0.20 3.6 0.8 8 4 128 11764 0.574 1.5 0.21 1.6 0.8 112 4 512 30769 1.47 3.5 0.3 3.6 0.9 88 4 1024 50000 2.38 5.4 0.3 5.5 1.0 66 4 2048 66666 3.18 7.0 0.3 7.1 1.37 46 4 4096 80000 3.81 7.3 0.5 7.3 1.40 26 8 128 17777 0.868 2.9 0.28 2.9 0.8 200 8 512 57142 2.72 8.5 0.5 8.5 0.70 159 8 1024 88888 4.24 12.2 0.9 12.4 1.0 108 8 2048 133333 6.36 14.7 0.9 14.7 1.0 81 8 4096 166666 7.95 19.5 0.9 19.5 3.0 45 16 128 32000 1.53 3.3 0.6 3.4 0.88 401 16 512 106666 5.09 16.1 0.9 16.2 2.16 260 16 1024 173913 8.29 22.1 1.5 22.2 4.5 200 16 2048 228571 10.90 28.6 1.61 28.7 4.60 128 16 4096 246153 11.74 31.1 1.65 31.2 4.66 57 32 1024 246153 11.74 30.5 3.17 30.7 12.10 270 说明：\n这里的单表，主键类型为 bigint(20),自增。 batchSize 和 通道个数，对性能影响较大。 16通道，4096批量提交时，出现 full gc 2次。 4.2.2 分表测试报告(2个分库，每个分库4张分表，共计8张分表) 通道数 批量提交行数 DataX速度(Rec/s) DataX流量(MB/s) DataX机器网卡流出流量(MB/s) DataX机器运行负载 DB网卡进入流量(MB/s) DB运行负载 DB TPS 8 128 26764 1.28 2.9 0.5 3.0 0.8 209 8 512 95180 4.54 10.5 0.7 10.9 0.8 188 8 1024 94117 4.49 12.3 0.6 12.4 1.09 120 8 2048 133333 6.36 19.4 0.9 19.5 1.35 85 8 4096 191692 9.14 22.1 1.0 22.2 1.45 45 4.2.3 分表测试报告(2个分库，每个分库8张分表，共计16张分表) 通道数 批量提交行数 DataX速度(Rec/s) DataX流量(MB/s) DataX机器网卡流出流量(MB/s) DataX机器运行负载 DB网卡进入流量(MB/s) DB运行负载 DB TPS 16 128 50124 2.39 5.6 0.40 6.0 2.42 378 16 512 155084 7.40 18.6 1.30 18.9 2.82 325 16 1024 177777 8.48 24.1 1.43 25.5 3.5 233 16 2048 289382 13.8 33.1 2.5 33.5 4.5 150 16 4096 326451 15.52 33.7 1.5 33.9 4.3 80 4.2.4 性能测试小结 批量提交行数（batchSize）对性能影响很大，当 batchSize\u0026gt;=512 之后，单线程写入速度能达到每秒写入一万行 在 batchSize\u0026gt;=512 的基础上，随着通道数的增加（通道数\u0026lt;32），速度呈线性比增加。 通常不建议写入数据库时，通道个数 \u0026gt;32 5 约束限制 FAQ Q: MysqlWriter 执行 postSql 语句报错，那么数据导入到目标数据库了吗?\nA: DataX 导入过程存在三块逻辑，pre 操作、导入操作、post 操作，其中任意一环报错，DataX 作业报错。由于 DataX 不能保证在同一个事务完成上述几个操作，因此有可能数据已经落入到目标端。\nQ: 按照上述说法，那么有部分脏数据导入数据库，如果影响到线上数据库怎么办?\nA: 目前有两种解法，第一种配置 pre 语句，该 sql 可以清理当天导入数据， DataX 每次导入时候可以把上次清理干净并导入完整数据。第二种，向临时表导入数据，完成后再 rename 到线上表。\nQ: 上面第二种方法可以避免对线上数据造成影响，那我具体怎样操作?\nA: 可以配置临时表导入\n","permalink":"https://haokiu.com/blog/ee3103b29d5b4fa696cb69e35fefb970/","summary":"DataX MysqlWriter 1 快速介绍 MysqlWriter 插件实现了写入数据到 Mysql 主库的目的表的功能。在底层实现上， MysqlWriter 通过 JDBC 连接远程 Mysql 数据库，并执行相应的 insert into \u0026hellip; 或者 ( replace into \u0026hellip;) 的 sql 语句将数据写入 Mysql，内部会分批次提交入库，需要数据库本身采用 innodb 引擎。\nMysqlWriter 面向ETL开发工程师，他们使用 MysqlWriter 从数仓导入数据到 Mysql。同时 MysqlWriter 亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 MysqlWriter 通过 DataX 框架获取 Reader 生成的协议数据，根据你配置的 writeMode 生成\ninsert into...(当主键/唯一性索引冲突时会写不进去冲突的行) 或者 replace into...(没有遇到主键/唯一性索引冲突时，与 insert into 行为一致，冲突时会用新行替换原有行所有字段) 的语句写入数据到 Mysql。出于性能考虑，采用了 PreparedStatement + Batch，并且设置了：rewriteBatchedStatements=true，将数据缓冲到线程上下文 Buffer 中，当 Buffer 累计到预定阈值时，才发起写入请求。 注意：目的表所在数据库必须是主库才能写入数据；整个任务至少需要具备 insert/replace into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 Mysql 导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;mysqlwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;writeMode\u0026#34;: \u0026#34;insert\u0026#34;, \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;session\u0026#34;: [ \u0026#34;set session sql_mode=\u0026#39;ANSI\u0026#39;\u0026#34; ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from test\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:mysql://127.","title":"DataX MysqlWriter"},{"content":"DataX OCSWriter 适用memcached客户端写入ocs 1 快速介绍 1.1 OCS简介 开放缓存服务( Open Cache Service，简称OCS）是基于内存的缓存服务，支持海量小数据的高速访问。OCS可以极大缓解对后端存储的压力，提高网站或应用的响应速度。OCS支持Key-Value的数据结构，兼容Memcached协议的客户端都可与OCS通信。\nOCS 支持即开即用的方式快速部署；对于动态Web、APP应用，可通过缓存服务减轻对数据库的压力，从而提高网站整体的响应速度。\n与本地MemCache相同之处在于OCS兼容Memcached协议，与用户环境兼容，可直接用于OCS服务 不同之处在于硬件和数据部署在云端，有完善的基础设施、网络安全保障、系统维护服务。所有的这些服务，都不需要投资，只需根据使用量进行付费即可。\n1.2 OCSWriter简介 OCSWriter是DataX实现的，基于Memcached协议的数据写入OCS通道。\n2 功能说明 2.1 配置样例 这里使用一份从内存产生的数据导入到OCS。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ocswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;proxy\u0026#34;: \u0026#34;xxxx\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;11211\u0026#34;, \u0026#34;userName\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;set|add|replace|append|prepend\u0026#34;, \u0026#34;writeFormat\u0026#34;: \u0026#34;text|binary\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;\\u0001\u0026#34;, \u0026#34;expireTime\u0026#34;: 1000, \u0026#34;indexes\u0026#34;: \u0026#34;0,2\u0026#34;, \u0026#34;batchSize\u0026#34;: 1000 } } } ] } } 2.2 参数说明 proxy\n描述：OCS机器的ip或host。 必选：是 port\n描述：OCS的连接域名，默认为11211 必选：否 默认值：11211 username\n描述：OCS连接的访问账号。 必选：是 password\n描述：OCS连接的访问密码 必选：是 writeMode\n描述: OCSWriter写入方式，具体为： set: 存储这个数据，如果已经存在则覆盖 add: 存储这个数据，当且仅当这个key不存在的时候 replace: 存储这个数据，当且仅当这个key存在 append: 将数据存放在已存在的key对应的内容的后面，忽略exptime prepend: 将数据存放在已存在的key对应的内容的前面，忽略exptime 必选：是 writeFormat\n描述: OCSWriter写出数据格式，目前支持两类数据写入方式: text: 将源端数据序列化为文本格式，其中第一个字段作为OCS写入的KEY，后续所有字段序列化为STRING类型，使用用户指定的fieldDelimiter作为间隔符，将文本拼接为完整的字符串再写入OCS。 binary: 将源端数据作为二进制直接写入，这类场景为未来做扩展使用，目前不支持。如果填写binary将会报错！ 必选：否 默认值：text expireTime\n描述: OCS值缓存失效时间，目前MemCache支持两类过期时间，\nUnix时间(自1970.1.1开始到现在的秒数)，该时间指定了到未来某个时刻数据失效。 相对当前时间的秒数，该时间指定了从现在开始多长时间后数据失效。 注意：如果过期时间的秒数大于606024*30(即30天)，则服务端认为是Unix时间。 单位：秒 必选：否\n默认值：0【0表示永久有效】\nindexes\n描述: 用数据的第几列当做ocs的key 必选：否 默认值：0 batchSize\n描述：一次性批量提交的记录数大小，该值可以极大减少DataX与OCS的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况[memcached版本暂不支持批量写]。 必选：否 默认值：256 fieldDelimiter\n描述：写入ocs的key和value分隔符。比如：key=tom\\u0001boston, value=28\\u0001lawer\\u0001male\\u0001married 必选：否 默认值：\\u0001 3 性能报告 3.1 datax机器配置 CPU:16核、内存:24GB、网卡:单网卡1000mbps 3.2 任务资源配置 -Xms8g -Xmx8g -XX:+HeapDumpOnOutOfMemoryError 3.3 测试报告 单条数据大小 通道并发数 TPS 通道流量 出口流量 备注 1KB 1 579 tps 583.31KB/s 648.63KB/s 无 1KB 10 6006 tps 5.87MB/s 6.73MB/s 无 1KB 100 49916 tps 48.56MB/s 55.55MB/s 无 10KB 1 438 tps 4.62MB/s 5.07MB/s 无 10KB 10 4313 tps 45.57MB/s 49.51MB/s 无 10KB 100 10713 tps 112.80MB/s 123.01MB/s 无 100KB 1 275 tps 26.09MB/s 144.90KB/s 无。数据冗余大，压缩比高。 100KB 10 2492 tps 236.33MB/s 1.30MB/s 无 100KB 100 3187 tps 302.17MB/s 1.77MB/s 无 3.4 性能测试小结 单条数据小于10KB时建议开启100并发。 不建议10KB以上的数据写入ocs。 ","permalink":"https://haokiu.com/blog/d4b1e453f8274dda834a305a5e6a38bf/","summary":"DataX OCSWriter 适用memcached客户端写入ocs 1 快速介绍 1.1 OCS简介 开放缓存服务( Open Cache Service，简称OCS）是基于内存的缓存服务，支持海量小数据的高速访问。OCS可以极大缓解对后端存储的压力，提高网站或应用的响应速度。OCS支持Key-Value的数据结构，兼容Memcached协议的客户端都可与OCS通信。\nOCS 支持即开即用的方式快速部署；对于动态Web、APP应用，可通过缓存服务减轻对数据库的压力，从而提高网站整体的响应速度。\n与本地MemCache相同之处在于OCS兼容Memcached协议，与用户环境兼容，可直接用于OCS服务 不同之处在于硬件和数据部署在云端，有完善的基础设施、网络安全保障、系统维护服务。所有的这些服务，都不需要投资，只需根据使用量进行付费即可。\n1.2 OCSWriter简介 OCSWriter是DataX实现的，基于Memcached协议的数据写入OCS通道。\n2 功能说明 2.1 配置样例 这里使用一份从内存产生的数据导入到OCS。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ocswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;proxy\u0026#34;: \u0026#34;xxxx\u0026#34;, \u0026#34;port\u0026#34;: \u0026#34;11211\u0026#34;, \u0026#34;userName\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;set|add|replace|append|prepend\u0026#34;, \u0026#34;writeFormat\u0026#34;: \u0026#34;text|binary\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;\\u0001\u0026#34;, \u0026#34;expireTime\u0026#34;: 1000, \u0026#34;indexes\u0026#34;: \u0026#34;0,2\u0026#34;, \u0026#34;batchSize\u0026#34;: 1000 } } } ] } } 2.","title":"DataX OCSWriter 适用memcached客户端写入ocs"},{"content":"DataX ODPSReader 1 快速介绍 ODPSReader 实现了从 ODPS读取数据的功能，有关ODPS请参看(https://help.aliyun.com/document_detail/27800.html?spm=5176.doc27803.6.101.NxCIgY)。 在底层实现上，ODPSReader 根据你配置的 源头项目 / 表 / 分区 / 表字段 等信息，通过 Tunnel 从 ODPS 系统中读取数据。\n注意 1、如果你需要使用ODPSReader/Writer插件，由于 AccessId/AccessKey 解密的需要，请务必使用 JDK 1.6.32 及以上版本。JDK 安装事项，请联系 PE 处理 2、ODPSReader 不是通过 ODPS SQL （select ... from ... where ... ）来抽取数据的 3、注意区分你要读取的表是线上环境还是线下环境 4、目前 DataX3 依赖的 SDK 版本是： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.odps\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;odps-sdk-core-internal\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.13.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2 实现原理 ODPSReader 支持读取分区表、非分区表，不支持读取虚拟视图。当要读取分区表时，需要指定出具体的分区配置，比如读取 t0 表，其分区为 pt=1,ds=hangzhou 那么你需要在配置中配置该值。当要读取非分区表时，你不能提供分区配置。表字段可以依序指定全部列，也可以指定部分列，或者调整列顺序，或者指定常量字段，但是表字段中不能指定分区列（分区列不是表字段）。\n注意：要特别注意 odpsServer、project、table、accessId、accessKey 的配置，因为直接影响到是否能够加载到你需要读取数据的表。很多权限问题都出现在这里。 3 功能说明 3.1 配置样例 这里使用一份读出 ODPS 数据然后打印到屏幕的配置样板。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;odpsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;accessId\u0026#34;: \u0026#34;accessId\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;accessKey\u0026#34;, \u0026#34;project\u0026#34;: \u0026#34;targetProjectName\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;tableName\u0026#34;, \u0026#34;partition\u0026#34;: [ \u0026#34;pt=1,ds=hangzhou\u0026#34; ], \u0026#34;column\u0026#34;: [ \u0026#34;customer_id\u0026#34;, \u0026#34;nickname\u0026#34; ], \u0026#34;packageAuthorizedProject\u0026#34;: \u0026#34;yourCurrentProjectName\u0026#34;, \u0026#34;splitMode\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;odpsServer\u0026#34;: \u0026#34;http://xxx/api\u0026#34;, \u0026#34;tunnelServer\u0026#34;: \u0026#34;http://dt.odps.aliyun.com\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;\\t\u0026#34;, \u0026#34;print\u0026#34;: \u0026#34;true\u0026#34; } } } ] } } 3.2 参数说明 参数 accessId\n描述：ODPS系统登录ID 必选：是 默认值：无 accessKey\n描述：ODPS系统登录Key 必选：是 默认值：无 project\n描述：读取数据表所在的 ODPS 项目名称（大小写不敏感） 必选：是 默认值：无 table\n描述：读取数据表的表名称（大小写不敏感） 必选：是 默认值：无 partition\n描述：读取数据所在的分区信息，支持linux shell通配符，包括 * 表示0个或多个字符，?代表任意一个字符。例如现在有分区表 test，其存在 pt=1,ds=hangzhou pt=1,ds=shanghai pt=2,ds=hangzhou pt=2,ds=beijing 四个分区，如果你想读取 pt=1,ds=shanghai 这个分区的数据，那么你应该配置为: \u0026quot;partition\u0026quot;:[\u0026quot;pt=1,ds=shanghai\u0026quot;]； 如果你想读取 pt=1下的所有分区，那么你应该配置为: \u0026quot;partition\u0026quot;:[\u0026quot;pt=1,ds=* \u0026quot;]；如果你想读取整个 test 表的所有分区的数据，那么你应该配置为: \u0026quot;partition\u0026quot;:[\u0026quot;pt=*,ds=*\u0026quot;] 必选：如果表为分区表，则必填。如果表为非分区表，则不能填写 默认值：无 column\n描述：读取 odps 源头表的列信息。例如现在有表 test，其字段为：id,name,age 如果你想依次读取 id,name,age 那么你应该配置为: \u0026quot;column\u0026quot;:[\u0026quot;id\u0026quot;,\u0026quot;name\u0026quot;,\u0026quot;age\u0026quot;] 或者配置为:\u0026quot;column\u0026quot;=[\u0026quot;*\u0026quot;] 这里 * 表示依次读取表的每个字段，但是我们不推荐你配置抽取字段为 * ，因为当你的表字段顺序调整、类型变更或者个数增减，你的任务就会存在源头表列和目的表列不能对齐的风险，会直接导致你的任务运行结果不正确甚至运行失败。如果你想依次读取 name,id 那么你应该配置为: \u0026quot;coulumn\u0026quot;:[\u0026quot;name\u0026quot;,\u0026quot;id\u0026quot;] 如果你想在源头抽取的字段中添加常量字段(以适配目标表的字段顺序)，比如你想抽取的每一行数据值为 age 列对应的值,name列对应的值,常量日期值1988-08-08 08:08:08,id 列对应的值 那么你应该配置为:\u0026quot;column\u0026quot;:[\u0026quot;age\u0026quot;,\u0026quot;name\u0026quot;,\u0026quot;'1988-08-08 08:08:08'\u0026quot;,\u0026quot;id\u0026quot;] 即常量列首尾用符号' 包住即可，我们内部实现上识别常量是通过检查你配置的每一个字段，如果发现有字段首尾都有'，则认为其是常量字段，其实际值为去除' 之后的值。\n注意：ODPSReader 抽取数据表不是通过 ODPS 的 Select SQL 语句，所以不能在字段上指定函数，也不能指定分区字段名称（分区字段不属于表字段） 必选：是 默认值：无 odpsServer\n描述：源头表 所在 ODPS 系统的server 地址 必选：是 默认值：无 tunnelServer\n描述：源头表 所在 ODPS 系统的tunnel 地址 必选：是 默认值：无 splitMode\n描述：读取源头表时切分所需要的模式。默认值为 record，可不填，表示根据切分份数，按照记录数进行切分。如果你的任务目的端为 Mysql，并且是 Mysql 的多个表，那么根据现在 DataX 结构，你的源头表必须是分区表，并且每个分区依次对应目的端 Mysql 的多个分表，则此时应该配置为\u0026quot;splitMode\u0026quot;:\u0026quot;partition\u0026quot; 必选：否 默认值：record accountProvider [待定]\n描述：读取时使用的 ODPS 账号类型。目前支持 aliyun/taobao 两种类型。默认为 aliyun，可不填 必选：否 默认值：aliyun packageAuthorizedProject\n* 描述：被package授权的project，即用户当前所在project \u0026lt;br /\u0026gt; 必选：否 默认值：无 isCompress\n* 描述：是否压缩读取，bool类型: \u0026quot;true\u0026quot;表示压缩, \u0026quot;false\u0026quot;标示不压缩 \u0026lt;br /\u0026gt; 必选：否 默认值：\u0026ldquo;false\u0026rdquo; : 不压缩 3.3 类型转换 下面列出 ODPSReader 读出类型与 DataX 内部类型的转换关系：\nODPS 数据类型 DataX 内部类型 BIGINT Long DOUBLE Double STRING String DATETIME Date Boolean Bool 4 性能报告（线上环境实测） 4.1 环境准备 4.1.1 数据特征 建表语句：\nuse cdo_datasync; create table datax3_odpswriter_perf_10column_1kb_00( s_0 string, bool_1 boolean, bi_2 bigint, dt_3 datetime, db_4 double, s_5 string, s_6 string, s_7 string, s_8 string, s_9 string )PARTITIONED by (pt string,year string); 单行记录类似于：\ns_0 : 485924f6ab7f272af361cd3f7f2d23e0d764942351#$%^\u0026amp;fdafdasfdas%%^(*\u0026amp;^^\u0026amp;* bool_1 : true bi_2 : 1696248667889 dt_3 : 2013-07-0600: 00: 00 db_4 : 3.141592653578 s_5 : 100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209 s_6 : 100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11fdsafdsfdsa209 s_7 : 100DAFDSAFDSAHOFJDPSAWIFDISHAF;dsadsafdsahfdsajf;dsfdsa;FJDSAL;11209 s_8 : 100dafdsafdsahofjdpsawifdishaf;DSADSAFDSAHFDSAJF;dsfdsa;fjdsal;11209 s_9 : 12~!2345100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209 4.1.2 机器参数 执行DataX的机器参数为:\ncpu : 24 Core Intel(R) Xeon(R) CPU E5-2630 0 @ 2.30GHz cache 15.36MB mem : 50GB net : 千兆双网卡 jvm : -Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError disc: DataX 数据不落磁盘，不统计此项 任务配置为:\n{ \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;odpsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;accessId\u0026#34;: \u0026#34;******************************\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;*****************************\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;partition\u0026#34;: [ \u0026#34;pt=20141010000000,year=2014\u0026#34; ], \u0026#34;odpsServer\u0026#34;: \u0026#34;http://xxx/api\u0026#34;, \u0026#34;project\u0026#34;: \u0026#34;cdo_datasync\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;datax3_odpswriter_perf_10column_1kb_00\u0026#34;, \u0026#34;tunnelServer\u0026#34;: \u0026#34;http://xxx\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: false, \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;485924f6ab7f272af361cd3f7f2d23e0d764942351#$%^\u0026amp;fdafdasfdas%%^(*\u0026amp;^^\u0026amp;*\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1696248667889\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;2013-07-06 00:00:00\u0026#34;, \u0026#34;dateFormat\u0026#34;: \u0026#34;yyyy-mm-dd hh:mm:ss\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;3.141592653578\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11fdsafdsfdsa209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100DAFDSAFDSAHOFJDPSAWIFDISHAF;dsadsafdsahfdsajf;dsfdsa;FJDSAL;11209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100dafdsafdsahofjdpsawifdishaf;DSADSAFDSAHFDSAJF;dsfdsa;fjdsal;11209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;12~!2345100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209\u0026#34; } ] } } } ] } } 4.2 测试报告 并发任务数 DataX速度(Rec/s) DataX流量(MB/S) 网卡流量(MB/S) DataX运行负载 1 117507 50.20 53.7 0.62 2 232976 99.54 108.1 0.99 4 387382 165.51 181.3 1.98 5 426054 182.03 202.2 2.35 6 434793 185.76 204.7 2.77 8 495904 211.87 230.2 2.86 16 501596 214.31 234.7 2.84 32 501577 214.30 234.7 2.99 64 501625 214.32 234.7 3.22 说明：\nOdpsReader 影响速度最主要的是channel数目，这里到达8时已经打满网卡，过多调大反而会影响系统性能。 channel数目的选择，可以考虑odps表文件组织，可尝试合并小文件再进行同步调优。 5 约束限制 FAQ（待补充） Q: 你来问\nA: 我来答。\n","permalink":"https://haokiu.com/blog/5b1b6009df684895ab2ef943e412ee8a/","summary":"DataX ODPSReader 1 快速介绍 ODPSReader 实现了从 ODPS读取数据的功能，有关ODPS请参看(https://help.aliyun.com/document_detail/27800.html?spm=5176.doc27803.6.101.NxCIgY)。 在底层实现上，ODPSReader 根据你配置的 源头项目 / 表 / 分区 / 表字段 等信息，通过 Tunnel 从 ODPS 系统中读取数据。\n注意 1、如果你需要使用ODPSReader/Writer插件，由于 AccessId/AccessKey 解密的需要，请务必使用 JDK 1.6.32 及以上版本。JDK 安装事项，请联系 PE 处理 2、ODPSReader 不是通过 ODPS SQL （select ... from ... where ... ）来抽取数据的 3、注意区分你要读取的表是线上环境还是线下环境 4、目前 DataX3 依赖的 SDK 版本是： \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.odps\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;odps-sdk-core-internal\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.13.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 2 实现原理 ODPSReader 支持读取分区表、非分区表，不支持读取虚拟视图。当要读取分区表时，需要指定出具体的分区配置，比如读取 t0 表，其分区为 pt=1,ds=hangzhou 那么你需要在配置中配置该值。当要读取非分区表时，你不能提供分区配置。表字段可以依序指定全部列，也可以指定部分列，或者调整列顺序，或者指定常量字段，但是表字段中不能指定分区列（分区列不是表字段）。\n注意：要特别注意 odpsServer、project、table、accessId、accessKey 的配置，因为直接影响到是否能够加载到你需要读取数据的表。很多权限问题都出现在这里。 3 功能说明 3.1 配置样例 这里使用一份读出 ODPS 数据然后打印到屏幕的配置样板。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;odpsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;accessId\u0026#34;: \u0026#34;accessId\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;accessKey\u0026#34;, \u0026#34;project\u0026#34;: \u0026#34;targetProjectName\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;tableName\u0026#34;, \u0026#34;partition\u0026#34;: [ \u0026#34;pt=1,ds=hangzhou\u0026#34; ], \u0026#34;column\u0026#34;: [ \u0026#34;customer_id\u0026#34;, \u0026#34;nickname\u0026#34; ], \u0026#34;packageAuthorizedProject\u0026#34;: \u0026#34;yourCurrentProjectName\u0026#34;, \u0026#34;splitMode\u0026#34;: \u0026#34;record\u0026#34;, \u0026#34;odpsServer\u0026#34;: \u0026#34;http://xxx/api\u0026#34;, \u0026#34;tunnelServer\u0026#34;: \u0026#34;http://dt.","title":"DataX ODPSReader"},{"content":"DataX ODPS写入 1 快速介绍 ODPSWriter插件用于实现往ODPS插入或者更新数据，主要提供给etl开发同学将业务数据导入odps，适合于TB,GB数量级的数据传输，如果需要传输PB量级的数据，请选择dt task工具 ;\n2 实现原理 在底层实现上，ODPSWriter是通过DT Tunnel写入ODPS系统的，有关ODPS的更多技术细节请参看 ODPS主站 https://data.aliyun.com/product/odps 和ODPS产品文档 https://help.aliyun.com/product/27797.html\n目前 DataX3 依赖的 SDK 版本是：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.odps\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;odps-sdk-core-internal\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.13.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 注意: 如果你需要使用ODPSReader/Writer插件，请务必使用JDK 1.6-32及以上版本 使用java -version查看Java版本号\n3 功能说明 3.1 配置样例 这里使用一份从内存产生到ODPS导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;byte\u0026#34;: 1048576 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 100000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;odpswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;project\u0026#34;: \u0026#34;chinan_test\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;odps_write_test00_partitioned\u0026#34;, \u0026#34;partition\u0026#34;: \u0026#34;school=SiChuan-School,class=1\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;accessId\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;xxxx\u0026#34;, \u0026#34;truncate\u0026#34;: true, \u0026#34;odpsServer\u0026#34;: \u0026#34;http://sxxx/api\u0026#34;, \u0026#34;tunnelServer\u0026#34;: \u0026#34;http://xxx\u0026#34;, \u0026#34;accountType\u0026#34;: \u0026#34;aliyun\u0026#34; } } } ] } } 3.2 参数说明 accessId\n描述：ODPS系统登录ID 必选：是 默认值：无 accessKey\n描述：ODPS系统登录Key 必选：是 默认值：无 project\n描述：ODPS表所属的project，注意:Project只能是字母+数字组合，请填写英文名称。在云端等用户看到的ODPS项目中文名只是显示名，请务必填写底层真实地Project英文标识名。 必选：是 默认值：无 table\n描述：写入数据的表名，不能填写多张表，因为DataX不支持同时导入多张表。 必选：是 默认值：无 partition\n描述：需要写入数据表的分区信息，必须指定到最后一级分区。把数据写入一个三级分区表，必须配置到最后一级分区，例如pt=20150101/type＝1/biz=2。 必选：如果是分区表，该选项必填，如果非分区表，该选项不可填写。 默认值：空 column\n描述：需要导入的字段列表，当导入全部字段时，可以配置为\u0026quot;column\u0026quot;: [\u0026quot;*\u0026quot;], 当需要插入部分odps列填写部分列，例如\u0026quot;column\u0026quot;: [\u0026ldquo;id\u0026rdquo;, \u0026ldquo;name\u0026rdquo;]。ODPSWriter支持列筛选、列换序，例如表有a,b,c三个字段，用户只同步c,b两个字段。可以配置成[\u0026ldquo;c\u0026rdquo;,\u0026ldquo;b\u0026rdquo;], 在导入过程中，字段a自动补空，设置为null。 必选：否 默认值：无 truncate\n描述：ODPSWriter通过配置\u0026quot;truncate\u0026quot;: true，保证写入的幂等性，即当出现写入失败再次运行时，ODPSWriter将清理前述数据，并导入新数据，这样可以保证每次重跑之后的数据都保持一致。 **truncate选项不是原子操作！ODPS SQL无法做到原子性。因此当多个任务同时向一个Table/Partition清理分区时候，可能出现并发时序问题，请务必注意！**针对这类问题，我们建议尽量不要多个作业DDL同时操作同一份分区，或者在多个并发作业启动前，提前创建分区。\n必选：是 默认值：无 odpsServer\n描述：ODPS的server地址，线上地址为 http://service.odps.aliyun.com/api 必选：是 默认值：无 tunnelServer\n描述：ODPS的tunnelserver地址，线上地址为 http://dt.odps.aliyun.com 必选：是， 默认值：无 3.3 类型转换 类似ODPSReader，目前ODPSWriter支持大部分ODPS类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出ODPSWriter针对ODPS类型转换列表:\nDataX 内部类型 ODPS 数据类型 Long bigint Double double String string Date datetime Boolean bool 4 插件特点 4.1 关于列筛选的问题 ODPS本身不支持列筛选、重排序、补空等等，但是DataX ODPSWriter完成了上述需求，支持列筛选、重排序、补空。例如需要导入的字段列表，当导入全部字段时，可以配置为\u0026quot;column\u0026quot;: [\u0026quot;*\u0026quot;]，odps表有a,b,c三个字段，用户只同步c,b两个字段，在列配置中可以写成\u0026quot;column\u0026quot;: [\u0026ldquo;c\u0026rdquo;,\u0026ldquo;b\u0026rdquo;]，表示会把reader的第一列和第二列导入odps的c字段和b字段，而odps表中新插入记录的a字段会被置为null. 4.2 列配置错误的处理 为了保证写入数据的可靠性，避免多余列数据丢失造成数据质量故障。对于写入多余的列，ODPSWriter将报错。例如ODPS表字段为a,b,c，但是ODPSWriter写入的字段为多于3列的话ODPSWriter将报错。 4.3 分区配置注意事项 ODPSWriter只提供 写入到最后一级分区 功能，不支持写入按照某个字段进行分区路由等功能。假设表一共有3级分区，那么在分区配置中就必须指明写入到某个三级分区，例如把数据写入一个表的第三级分区，可以配置为 pt=20150101/type＝1/biz=2，但是不能配置为pt=20150101/type＝1或者pt=20150101。 4.4 任务重跑和failover ODPSWriter通过配置\u0026quot;truncate\u0026quot;: true，保证写入的幂等性，即当出现写入失败再次运行时，ODPSWriter将清理前述数据，并导入新数据，这样可以保证每次重跑之后的数据都保持一致。如果在运行过程中因为其他的异常导致了任务中断，是不能保证数据的原子性的，数据不会回滚也不会自动重跑，需要用户利用幂等性这一特点重跑去确保保证数据的完整性。truncate为true的情况下，会将指定分区\\表的数据全部清理，请谨慎使用！ 5 性能报告（线上环境实测） 5.1 环境准备 5.1.1 数据特征 建表语句：\nuse cdo_datasync; create table datax3_odpswriter_perf_10column_1kb_00( s_0 string, bool_1 boolean, bi_2 bigint, dt_3 datetime, db_4 double, s_5 string, s_6 string, s_7 string, s_8 string, s_9 string )PARTITIONED by (pt string,year string); 单行记录类似于：\ns_0 : 485924f6ab7f272af361cd3f7f2d23e0d764942351#$%^\u0026amp;fdafdasfdas%%^(*\u0026amp;^^\u0026amp;* bool_1 : true bi_2 : 1696248667889 dt_3 : 2013-07-0600: 00: 00 db_4 : 3.141592653578 s_5 : 100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209 s_6 : 100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11fdsafdsfdsa209 s_7 : 100DAFDSAFDSAHOFJDPSAWIFDISHAF;dsadsafdsahfdsajf;dsfdsa;FJDSAL;11209 s_8 : 100dafdsafdsahofjdpsawifdishaf;DSADSAFDSAHFDSAJF;dsfdsa;fjdsal;11209 s_9 : 12~!2345100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209 5.1.2 机器参数 执行DataX的机器参数为:\ncpu : 24 Core Intel(R) Xeon(R) CPU E5-2630 0 @ 2.30GHz cache 15.36MB mem : 50GB net : 千兆双网卡 jvm : -Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError disc: DataX 数据不落磁盘，不统计此项 任务配置为:\n{ \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: \u0026#34;1,2,4,5,6,8,16,32,64\u0026#34; } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;odpsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;accessId\u0026#34;: \u0026#34;******************************\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;*****************************\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;*\u0026#34; ], \u0026#34;partition\u0026#34;: [ \u0026#34;pt=20141010000000,year=2014\u0026#34; ], \u0026#34;odpsServer\u0026#34;: \u0026#34;http://service.odps.aliyun.com/api\u0026#34;, \u0026#34;project\u0026#34;: \u0026#34;cdo_datasync\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;datax3_odpswriter_perf_10column_1kb_00\u0026#34;, \u0026#34;tunnelServer\u0026#34;: \u0026#34;http://dt.odps.aliyun.com\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: false, \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;485924f6ab7f272af361cd3f7f2d23e0d764942351#$%^\u0026amp;fdafdasfdas%%^(*\u0026amp;^^\u0026amp;*\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1696248667889\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;2013-07-06 00:00:00\u0026#34;, \u0026#34;dateFormat\u0026#34;: \u0026#34;yyyy-mm-dd hh:mm:ss\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;3.141592653578\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11fdsafdsfdsa209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100DAFDSAFDSAHOFJDPSAWIFDISHAF;dsadsafdsahfdsajf;dsfdsa;FJDSAL;11209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100dafdsafdsahofjdpsawifdishaf;DSADSAFDSAHFDSAJF;dsfdsa;fjdsal;11209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;12~!2345100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209\u0026#34; } ] } } } ] } } 5.2 测试报告 并发任务数 blockSizeInMB DataX速度(Rec/s) DataX流量(MB/S) 网卡流量(MB/S) DataX运行负载 1 32 30303 13.03 14.5 0.12 1 64 38461 16.54 16.5 0.44 1 128 46454 20.55 26.7 0.47 1 256 52631 22.64 26.7 0.47 1 512 58823 25.30 28.7 0.44 4 32 114816 49.38 55.3 0.75 4 64 147577 63.47 71.3 0.82 4 128 177744 76.45 83.2 0.97 4 256 173913 74.80 80.1 1.01 4 512 200000 86.02 95.1 1.41 8 32 204480 87.95 92.7 1.16 8 64 294224 126.55 135.3 1.65 8 128 365475 157.19 163.7 2.89 8 256 394713 169.83 176.7 2.72 8 512 241691 103.95 125.7 2.29 16 32 420838 181.01 198.0 2.56 16 64 458144 197.05 217.4 2.85 16 128 443219 190.63 210.5 3.29 16 256 315235 135.58 140.0 0.95 16 512 OOM 说明：\nOdpsWriter 影响速度的是channel 和 blockSizeInMB。blockSizeInMB 取32 和 64时，速度比较稳定,过分大的 blockSizeInMB 可能造成速度波动以及内存OOM。 channel 和 blockSizeInMB 对速度的影响都很明显，建议综合考虑配合选择。 channel 数目的选择，可以综合考虑源端数据特征进行选择，对于StreamReader，在16个channel时将网卡打满。 6 FAQ 1 导数据到 odps 的日志中有以下报错，该怎么处理呢？\u0026ldquo;ODPS-0420095: Access Denied - Authorization Failed [4002], You doesn‘t exist in project example_dev“ 解决办法 :找ODPS Prject 的 owner给用户的云账号授权，授权语句： grant Describe,Select,Alter,Update on table [tableName] to user XXX\n2 可以导入数据到odps的视图吗？ 目前不支持通过视图到数据到odps,视图是ODPS非实体化数据存储对象，技术上无法向视图导入数据。\n","permalink":"https://haokiu.com/blog/ab33f89c494e47eaae02f9c21465b322/","summary":"DataX ODPS写入 1 快速介绍 ODPSWriter插件用于实现往ODPS插入或者更新数据，主要提供给etl开发同学将业务数据导入odps，适合于TB,GB数量级的数据传输，如果需要传输PB量级的数据，请选择dt task工具 ;\n2 实现原理 在底层实现上，ODPSWriter是通过DT Tunnel写入ODPS系统的，有关ODPS的更多技术细节请参看 ODPS主站 https://data.aliyun.com/product/odps 和ODPS产品文档 https://help.aliyun.com/product/27797.html\n目前 DataX3 依赖的 SDK 版本是：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.aliyun.odps\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;odps-sdk-core-internal\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.13.2\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 注意: 如果你需要使用ODPSReader/Writer插件，请务必使用JDK 1.6-32及以上版本 使用java -version查看Java版本号\n3 功能说明 3.1 配置样例 这里使用一份从内存产生到ODPS导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;byte\u0026#34;: 1048576 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 100000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;odpswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;project\u0026#34;: \u0026#34;chinan_test\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;odps_write_test00_partitioned\u0026#34;, \u0026#34;partition\u0026#34;: \u0026#34;school=SiChuan-School,class=1\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;accessId\u0026#34;: \u0026#34;xxx\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;xxxx\u0026#34;, \u0026#34;truncate\u0026#34;: true, \u0026#34;odpsServer\u0026#34;: \u0026#34;http://sxxx/api\u0026#34;, \u0026#34;tunnelServer\u0026#34;: \u0026#34;http://xxx\u0026#34;, \u0026#34;accountType\u0026#34;: \u0026#34;aliyun\u0026#34; } } } ] } } 3.","title":"DataX ODPS写入"},{"content":"DataX OracleWriter 1 快速介绍 OracleWriter 插件实现了写入数据到 Oracle 主库的目的表的功能。在底层实现上， OracleWriter 通过 JDBC 连接远程 Oracle 数据库，并执行相应的 insert into \u0026hellip; sql 语句将数据写入 Oracle，内部会分批次提交入库。\nOracleWriter 面向ETL开发工程师，他们使用 OracleWriter 从数仓导入数据到 Oracle。同时 OracleWriter 亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 OracleWriter 通过 DataX 框架获取 Reader 生成的协议数据，根据你配置生成相应的SQL语句\ninsert into...(当主键/唯一性索引冲突时会写不进去冲突的行) 注意： 1. 目的表所在数据库必须是主库才能写入数据；整个任务至少需具备 insert into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 2.OracleWriter和MysqlWriter不同，不支持配置writeMode参数。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 Oracle 导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;oraclewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from test\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:oracle:thin:@[HOST_NAME]:PORT:[DATABASE_NAME]\u0026#34;, \u0026#34;table\u0026#34;: [ \u0026#34;test\u0026#34; ] } ] } } } ] } } 3.2 参数说明 jdbcUrl\n描述：目的数据库的 JDBC 连接信息 ,jdbcUrl必须包含在connection配置单元中。\n注意：1、在一个数据库上只能配置一个值。这与 OracleReader 支持多个备库探测不同，因为此处不支持同一个数据库存在多个主库的情况(双主导入数据情况) 2、jdbcUrl按照Oracle官方规范，并可以填写连接附加参数信息。具体请参看 Oracle官方文档或者咨询对应 DBA。 必选：是 默认值：无 username\n描述：目的数据库的用户名 必选：是 默认值：无 password\n描述：目的数据库的密码 必选：是 默认值：无 table\n描述：目的表的表名称。支持写入一个或者多个表。当配置为多张表时，必须确保所有表结构保持一致。\n注意：table 和 jdbcUrl 必须包含在 connection 配置单元中 必选：是 默认值：无 column\n描述：目的表需要写入数据的字段,字段之间用英文逗号分隔。例如: \u0026ldquo;column\u0026rdquo;: [\u0026ldquo;id\u0026rdquo;,\u0026ldquo;name\u0026rdquo;,\u0026ldquo;age\u0026rdquo;]。如果要依次写入全部列，使用表示, 例如: \u0026ldquo;column\u0026rdquo;: [\u0026quot;\u0026quot;]\n**column配置项必须指定，不能留空！** 注意：1、我们强烈不推荐你这样配置，因为当你目的表字段个数、类型等有改动时，你的任务可能运行不正确或者失败 2、此处 column 不能配置任何常量值 必选：是 默认值：否 preSql\n描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 @table 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, \u0026hellip; datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：\u0026quot;preSql\u0026quot;:[\u0026quot;delete from @table\u0026quot;]，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称 必选：否 默认值：无 postSql\n描述：写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ） 必选：否 默认值：无 batchSize\n描述：一次性批量提交的记录数大小，该值可以极大减少DataX与Oracle的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。\n必选：否 默认值：1024 session\n描述：设置oracle连接时的session信息，格式示例如下： \u0026#34;session\u0026#34;:[ \u0026#34;alter session set nls_date_format = \u0026#39;dd.mm.yyyy hh24:mi:ss\u0026#39;;\u0026#34; \u0026#34;alter session set NLS_LANG = \u0026#39;AMERICAN\u0026#39;;\u0026#34; ] 必选：否 默认值：无 3.3 类型转换 类似 OracleReader ，目前 OracleWriter 支持大部分 Oracle 类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出 OracleWriter 针对 Oracle 类型转换列表:\nDataX 内部类型 Oracle 数据类型 Long NUMBER,INTEGER,INT,SMALLINT Double NUMERIC,DECIMAL,FLOAT,DOUBLE PRECISION,REAL String LONG,CHAR,NCHAR,VARCHAR,VARCHAR2,NVARCHAR2,CLOB,NCLOB,CHARACTER,CHARACTER VARYING,CHAR VARYING,NATIONAL CHARACTER,NATIONAL CHAR,NATIONAL CHARACTER VARYING,NATIONAL CHAR VARYING,NCHAR VARYING Date TIMESTAMP,DATE Boolean bit, bool Bytes BLOB,BFILE,RAW,LONG RAW 4 性能报告 4.1 环境准备 4.1.1 数据特征 建表语句：\n--DROP TABLE PERF_ORACLE_WRITER; CREATE TABLE PERF_ORACLE_WRITER ( COL1 VARCHAR2(255 BYTE) NULL , COL2 NUMBER(32) NULL , COL3 NUMBER(32) NULL , COL4 DATE NULL , COL5 FLOAT NULL , COL6 VARCHAR2(255 BYTE) NULL , COL7 VARCHAR2(255 BYTE) NULL , COL8 VARCHAR2(255 BYTE) NULL , COL9 VARCHAR2(255 BYTE) NULL , COL10 VARCHAR2(255 BYTE) NULL ) LOGGING NOCOMPRESS NOCACHE; 单行记录类似于：\ncol1:485924f6ab7f272af361cd3f7f2d23e0d764942351#$%^\u0026amp;fdafdasfdas%%^(*\u0026amp;^^\u0026amp;* co12:1 co13:1696248667889 co14:2013-01-06 00:00:00 co15:3.141592653578 co16:100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209 co17:100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11fdsafdsfdsa209 co18:100DAFDSAFDSAHOFJDPSAWIFDISHAF;dsadsafdsahfdsajf;dsfdsa;FJDSAL;11209 co19:100dafdsafdsahofjdpsawifdishaf;DSADSAFDSAHFDSAJF;dsfdsa;fjdsal;11209 co110:12~!2345100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209 4.1.2 机器参数 执行 DataX 的机器参数为:\ncpu: 24 Core Intel(R) Xeon(R) CPU E5-2430 0 @ 2.20GHz mem: 94GB net: 千兆双网卡 disc: DataX 数据不落磁盘，不统计此项 Oracle 数据库机器参数为:\ncpu: 4 Core Intel(R) Xeon(R) CPU E5420 @ 2.50GHz mem: 7GB 4.1.3 DataX jvm 参数 -Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError 4.1.4 性能测试作业配置 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 4 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sliceRecordCount\u0026#34;: 1000000000, \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;485924f6ab7f272af361cd3f7f2d23e0d764942351#$%^\u0026amp;fdafdasfdas%%^(*\u0026amp;^^\u0026amp;*\u0026#34; }, { \u0026#34;value\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1696248667889\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;2013-07-06 00:00:00\u0026#34;, \u0026#34;dateFormat\u0026#34;: \u0026#34;yyyy-mm-dd hh:mm:ss\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;3.141592653578\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11fdsafdsfdsa209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100DAFDSAFDSAHOFJDPSAWIFDISHAF;dsadsafdsahfdsajf;dsfdsa;FJDSAL;11209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;100dafdsafdsahofjdpsawifdishaf;DSADSAFDSAHFDSAJF;dsfdsa;fjdsal;11209\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;12~!2345100dafdsafdsahofjdpsawifdishaf;dsadsafdsahfdsajf;dsfdsa;fjdsal;11209\u0026#34; } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;oraclewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;username\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;, \u0026#34;truncate\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;batchSize\u0026#34;: \u0026#34;512\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;col1\u0026#34;, \u0026#34;col2\u0026#34;, \u0026#34;col3\u0026#34;, \u0026#34;col4\u0026#34;, \u0026#34;col5\u0026#34;, \u0026#34;col6\u0026#34;, \u0026#34;col7\u0026#34;, \u0026#34;col8\u0026#34;, \u0026#34;col9\u0026#34;, \u0026#34;col10\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;PERF_ORACLE_WRITER\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:oracle:thin:@ip:port:dataplat\u0026#34; } ] } } } ] } } 4.2 测试报告 4.2.1 测试报告 通道数 批量提交行数 DataX速度(Rec/s) DataX流量(MB/s) DataX机器网卡流出流量(MB/s) DataX机器运行负载 DB网卡进入流量(MB/s) DB运行负载 1 128 15564 6.51 7.5 0.02 7.4 1.08 1 512 29491 10.90 12.6 0.05 12.4 1.55 1 1024 31529 11.87 13.5 0.22 13.3 1.58 1 2048 33469 12.57 14.3 0.17 14.3 1.53 1 4096 31363 12.48 13.4 0.10 10.0 1.72 4 10 9440 4.05 5.6 0.01 5.0 3.75 4 128 42832 16.48 18.3 0.07 18.5 2.89 4 512 46643 20.02 22.7 0.35 21.1 3.31 4 1024 39116 16.79 18.7 0.10 18.1 3.05 4 2048 39526 16.96 18.5 0.32 17.1 2.86 4 4096 37683 16.17 17.2 0.23 15.5 2.26 8 128 38336 16.45 17.5 0.13 16.2 3.87 8 512 31078 13.34 14.9 0.11 13.4 2.09 8 1024 37888 16.26 18.5 0.20 18.5 3.14 8 2048 38502 16.52 18.5 0.18 18.5 2.96 8 4096 38092 16.35 18.3 0.10 17.8 3.19 16 128 35366 15.18 16.9 0.13 15.6 3.49 16 512 35584 15.27 16.8 0.23 17.4 3.05 16 1024 38297 16.44 17.5 0.20 17.0 3.42 16 2048 28467 12.22 13.8 0.10 12.4 3.38 16 4096 27852 11.95 12.3 0.11 12.3 3.86 32 1024 34406 14.77 15.4 0.09 15.4 3.55 batchSize 和 通道个数，对性能影响较大 通常不建议写入数据库时，通道个数 \u0026gt;32 5 约束限制 FAQ Q: OracleWriter 执行 postSql 语句报错，那么数据导入到目标数据库了吗?\nA: DataX 导入过程存在三块逻辑，pre 操作、导入操作、post 操作，其中任意一环报错，DataX 作业报错。由于 DataX 不能保证在同一个事务完成上述几个操作，因此有可能数据已经落入到目标端。\nQ: 按照上述说法，那么有部分脏数据导入数据库，如果影响到线上数据库怎么办?\nA: 目前有两种解法，第一种配置 pre 语句，该 sql 可以清理当天导入数据， DataX 每次导入时候可以把上次清理干净并导入完整数据。第二种，向临时表导入数据，完成后再 rename 到线上表。\nQ: 上面第二种方法可以避免对线上数据造成影响，那我具体怎样操作?\nA: 可以配置临时表导入\n","permalink":"https://haokiu.com/blog/1eb2fdd8968d4f6e8bbc0312c6647246/","summary":"DataX OracleWriter 1 快速介绍 OracleWriter 插件实现了写入数据到 Oracle 主库的目的表的功能。在底层实现上， OracleWriter 通过 JDBC 连接远程 Oracle 数据库，并执行相应的 insert into \u0026hellip; sql 语句将数据写入 Oracle，内部会分批次提交入库。\nOracleWriter 面向ETL开发工程师，他们使用 OracleWriter 从数仓导入数据到 Oracle。同时 OracleWriter 亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 OracleWriter 通过 DataX 框架获取 Reader 生成的协议数据，根据你配置生成相应的SQL语句\ninsert into...(当主键/唯一性索引冲突时会写不进去冲突的行) 注意： 1. 目的表所在数据库必须是主库才能写入数据；整个任务至少需具备 insert into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 2.OracleWriter和MysqlWriter不同，不支持配置writeMode参数。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 Oracle 导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;oraclewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from test\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:oracle:thin:@[HOST_NAME]:PORT:[DATABASE_NAME]\u0026#34;, \u0026#34;table\u0026#34;: [ \u0026#34;test\u0026#34; ] } ] } } } ] } } 3.","title":"DataX OracleWriter"},{"content":"DataX OSSReader 说明 1 快速介绍 OSSReader提供了读取OSS数据存储的能力。在底层实现上，OSSReader使用OSS官方Java SDK获取OSS数据，并转换为DataX传输协议传递给Writer。\nOSS 产品介绍, 参看[阿里云OSS Portal] OSS Java SDK, 参看[阿里云OSS Java SDK] 2 功能与限制 OSSReader实现了从OSS读取数据并转为DataX协议的功能，OSS本身是无结构化数据存储，对于DataX而言，OSSReader实现上类比TxtFileReader，有诸多相似之处。目前OSSReader支持功能如下：\n支持且仅支持读取TXT的文件，且要求TXT中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n支持多种类型数据读取(使用String表示)，支持列裁剪，支持列常量\n支持递归读取、支持文件名过滤。\n支持文本压缩，现有压缩格式为zip、gzip、bzip2。注意，一个压缩包不允许多文件打包压缩。\n多个object可以支持并发读取。\n我们暂时不能做到：\n单个Object(File)支持多线程并发读取，这里涉及到单个Object内部切分算法。二期考虑支持。\n单个Object在压缩情况下，从技术上无法支持多线程并发读取。\n3 功能说明 3.1 配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: {}, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ossreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://oss.aliyuncs.com\u0026#34;, \u0026#34;accessId\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;bucket\u0026#34;: \u0026#34;myBucket\u0026#34;, \u0026#34;object\u0026#34;: [ \u0026#34;bazhen/*\u0026#34; ], \u0026#34;column\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;index\u0026#34;: 0 }, { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;alibaba\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;index\u0026#34;: 1, \u0026#34;format\u0026#34;: \u0026#34;yyyy-MM-dd\u0026#34; } ], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;\\t\u0026#34;, \u0026#34;compress\u0026#34;: \u0026#34;gzip\u0026#34; } }, \u0026#34;writer\u0026#34;: {} } ] } } 3.2 参数说明 endpoint\n描述：OSS Server的EndPoint地址，例如http://oss.aliyuncs.com。\n必选：是 默认值：无 accessId\n描述：OSS的accessId 必选：是 默认值：无 accessKey\n描述：OSS的accessKey 必选：是 默认值：无 bucket\n描述：OSS的bucket 必选：是 默认值：无 object\n描述：OSS的object信息，注意这里可以支持填写多个Object。 当指定单个OSS Object，OSSReader暂时只能使用单线程进行数据抽取。二期考虑在非压缩文件情况下针对单个Object可以进行多线程并发读取。\n当指定多个OSS Object，OSSReader支持使用多线程进行数据抽取。线程并发数通过通道数指定。\n当指定通配符，OSSReader尝试遍历出多个Object信息。例如: 指定/*代表读取bucket下游所有的Object，指定/bazhen/*代表读取bazhen目录下游所有的Object。\n特别需要注意的是，DataX会将一个作业下同步的所有Object视作同一张数据表。用户必须自己保证所有的Object能够适配同一套schema信息。\n必选：是 默认值：无 column\n描述：读取字段列表，type指定源数据的类型，index指定当前列来自于文本第几列(以0开始)，value指定当前类型为常量，不从源头文件读取数据，而是根据value值自动生成对应的列。 默认情况下，用户可以全部按照String类型读取数据，配置如下：\n\u0026#34;column\u0026#34;: [\u0026#34;*\u0026#34;] 用户可以指定Column字段信息，配置如下：\n{ \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;index\u0026#34;: 0 //从OSS文本第一列获取int字段 }, { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;alibaba\u0026#34; //从OSSReader内部生成alibaba的字符串字段作为当前字段 } 对于用户指定Column信息，type必须填写，index/value必须选择其一。\n必选：是 默认值：全部按照string类型读取 fieldDelimiter\n描述：读取的字段分隔符 必选：是 默认值：, compress\n描述：文本压缩类型，默认不填写意味着没有压缩。支持压缩类型为zip、gzip、bzip2。 必选：否 默认值：不压缩 encoding\n描述：读取文件的编码配置，目前只支持utf-8/gbk。\n必选：否 默认值：utf-8 nullFormat\n描述：文本文件中无法使用标准字符串定义null(空指针)，DataX提供nullFormat定义哪些字符串可以表示为null。\n例如如果用户配置: nullFormat=\u0026quot;\\N\u0026quot;，那么如果源头数据是\u0026quot;\\N\u0026quot;，DataX视作null字段。\n必选：否 默认值：\\N skipHeader\n描述：类CSV格式文件可能存在表头为标题情况，需要跳过。默认不跳过。\n必选：否 默认值：false csvReaderConfig\n描述：读取CSV类型文件参数配置，Map类型。读取CSV类型文件使用的CsvReader进行读取，会有很多配置，不配置则使用默认值。\n必选：否 默认值：无 常见配置：\n\u0026#34;csvReaderConfig\u0026#34;:{ \u0026#34;safetySwitch\u0026#34;: false, \u0026#34;skipEmptyRecords\u0026#34;: false, \u0026#34;useTextQualifier\u0026#34;: false } 所有配置项及默认值,配置时 csvReaderConfig 的map中请严格按照以下字段名字进行配置：\nboolean caseSensitive = true; char textQualifier = 34; boolean trimWhitespace = true; boolean useTextQualifier = true;//是否使用csv转义字符 char delimiter = 44;//分隔符 char recordDelimiter = 0; char comment = 35; boolean useComments = false; int escapeMode = 1; boolean safetySwitch = true;//单列长度是否限制100000字符 boolean skipEmptyRecords = true;//是否跳过空行 boolean captureRawRecord = true; 3.3 类型转换 OSS本身不提供数据类型，该类型是DataX OSSReader定义：\nDataX 内部类型 OSS 数据类型 Long Long Double Double String String Boolean Boolean Date Date 其中：\nOSS Long是指OSS文本中使用整形的字符串表示形式，例如\u0026quot;19901219\u0026quot;。 OSS Double是指OSS文本中使用Double的字符串表示形式，例如\u0026quot;3.1415\u0026quot;。 OSS Boolean是指OSS文本中使用Boolean的字符串表示形式，例如\u0026quot;true\u0026quot;、\u0026ldquo;false\u0026rdquo;。不区分大小写。 OSS Date是指OSS文本中使用Date的字符串表示形式，例如\u0026quot;2014-12-31\u0026quot;，Date可以指定format格式。 4 性能报告 并发数 DataX 流量 Datax 记录数 1 971.40KB/s 10047rec/s 2 1.81MB/s 19181rec/s 4 3.46MB/s 36695rec/s 8 6.57MB/s 69289 records/s 16 7.92MB/s 83920 records/s 32 7.87MB/s 83350 records/s 5 约束限制 略\n6 FAQ 略\n","permalink":"https://haokiu.com/blog/bf15e9112ab546c9a6d8baab000d9601/","summary":"DataX OSSReader 说明 1 快速介绍 OSSReader提供了读取OSS数据存储的能力。在底层实现上，OSSReader使用OSS官方Java SDK获取OSS数据，并转换为DataX传输协议传递给Writer。\nOSS 产品介绍, 参看[阿里云OSS Portal] OSS Java SDK, 参看[阿里云OSS Java SDK] 2 功能与限制 OSSReader实现了从OSS读取数据并转为DataX协议的功能，OSS本身是无结构化数据存储，对于DataX而言，OSSReader实现上类比TxtFileReader，有诸多相似之处。目前OSSReader支持功能如下：\n支持且仅支持读取TXT的文件，且要求TXT中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n支持多种类型数据读取(使用String表示)，支持列裁剪，支持列常量\n支持递归读取、支持文件名过滤。\n支持文本压缩，现有压缩格式为zip、gzip、bzip2。注意，一个压缩包不允许多文件打包压缩。\n多个object可以支持并发读取。\n我们暂时不能做到：\n单个Object(File)支持多线程并发读取，这里涉及到单个Object内部切分算法。二期考虑支持。\n单个Object在压缩情况下，从技术上无法支持多线程并发读取。\n3 功能说明 3.1 配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: {}, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;ossreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://oss.aliyuncs.com\u0026#34;, \u0026#34;accessId\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;bucket\u0026#34;: \u0026#34;myBucket\u0026#34;, \u0026#34;object\u0026#34;: [ \u0026#34;bazhen/*\u0026#34; ], \u0026#34;column\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;index\u0026#34;: 0 }, { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;alibaba\u0026#34; }, { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;index\u0026#34;: 1, \u0026#34;format\u0026#34;: \u0026#34;yyyy-MM-dd\u0026#34; } ], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;\\t\u0026#34;, \u0026#34;compress\u0026#34;: \u0026#34;gzip\u0026#34; } }, \u0026#34;writer\u0026#34;: {} } ] } } 3.2 参数说明 endpoint\n描述：OSS Server的EndPoint地址，例如http://oss.","title":"DataX OSSReader 说明"},{"content":"DataX OSSWriter 说明 1 快速介绍 OSSWriter提供了向OSS写入类CSV格式的一个或者多个表文件。\n写入OSS内容存放的是一张逻辑意义上的二维表，例如CSV格式的文本信息。\nOSS 产品介绍, 参看[阿里云OSS Portal] OSS Java SDK, 参看[阿里云OSS Java SDK] 2 功能与限制 OSSWriter实现了从DataX协议转为OSS中的TXT文件功能，OSS本身是无结构化数据存储，OSSWriter需要在如下几个方面增加:\n支持且仅支持写入 TXT的文件，且要求TXT中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n暂时不支持文本压缩。\n支持多线程写入，每个线程写入不同子文件。\n文件支持滚动，当文件大于某个size值或者行数值，文件需要切换。 [暂不支持]\n我们不能做到：\n单个文件不能支持并发写入。 3 功能说明 3.1 配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: {}, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;osswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://oss.aliyuncs.com\u0026#34;, \u0026#34;accessId\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;bucket\u0026#34;: \u0026#34;myBucket\u0026#34;, \u0026#34;object\u0026#34;: \u0026#34;cdo/datax\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate|append|nonConflict\u0026#34; } } } ] } } 3.2 参数说明 endpoint\n描述：OSS Server的EndPoint地址，例如http://oss.aliyuncs.com。\n必选：是 默认值：无 accessId\n描述：OSS的accessId 必选：是 默认值：无 accessKey\n描述：OSS的accessKey 必选：是 默认值：无 bucket\n描述：OSS的bucket 必选：是 默认值：无 object\n描述：OSSWriter写入的文件名，OSS使用文件名模拟目录的实现。 使用\u0026quot;object\u0026quot;: \u0026ldquo;datax\u0026rdquo;，写入object以datax开头，后缀添加随机字符串。 使用\u0026quot;object\u0026quot;: \u0026ldquo;cdo/datax\u0026rdquo;，写入的object以cdo/datax开头，后缀随机添加字符串，/作为OSS模拟目录的分隔符。\n必选：是 默认值：无 writeMode\n描述：OSSWriter写入前数据清理处理： truncate，写入前清理object名称前缀匹配的所有object。例如: \u0026ldquo;object\u0026rdquo;: \u0026ldquo;abc\u0026rdquo;，将清理所有abc开头的object。 append，写入前不做任何处理，DataX OSSWriter直接使用object名称写入，并使用随机UUID的后缀名来保证文件名不冲突。例如用户指定的object名为datax，实际写入为datax_xxxxxx_xxxx_xxxx nonConflict，如果指定路径出现前缀匹配的object，直接报错。例如: \u0026ldquo;object\u0026rdquo;: \u0026ldquo;abc\u0026rdquo;，如果存在abc123的object，将直接报错。 必选：是 默认值：无 fieldDelimiter\n描述：读取的字段分隔符 必选：否 默认值：, encoding\n描述：写出文件的编码配置。\n必选：否 默认值：utf-8 nullFormat\n描述：文本文件中无法使用标准字符串定义null(空指针)，DataX提供nullFormat定义哪些字符串可以表示为null。\n例如如果用户配置: nullFormat=\u0026quot;\\N\u0026quot;，那么如果源头数据是\u0026quot;\\N\u0026quot;，DataX视作null字段。\n必选：否 默认值：\\N dateFormat\n描述：日期类型的数据序列化到object中时的格式，例如 \u0026ldquo;dateFormat\u0026rdquo;: \u0026ldquo;yyyy-MM-dd\u0026rdquo;。\n必选：否 默认值：无 fileFormat\n描述：文件写出的格式，包括csv (http://zh.wikipedia.org/wiki/%E9%80%97%E5%8F%B7%E5%88%86%E9%9A%94%E5%80%BC) 和text两种，csv是严格的csv格式，如果待写数据包括列分隔符，则会按照csv的转义语法转义，转义符号为双引号\u0026quot;；text格式是用列分隔符简单分割待写数据，对于待写数据包括列分隔符情况下不做转义。\n必选：否 默认值：text header\n描述：Oss写出时的表头，示例[\u0026lsquo;id\u0026rsquo;, \u0026rsquo;name\u0026rsquo;, \u0026lsquo;age\u0026rsquo;]。\n必选：否 默认值：无 maxFileSize\n描述：Oss写出时单个Object文件的最大大小，默认为10000*10MB，类似log4j日志打印时根据日志文件大小轮转。OSS分块上传时，每个分块大小为10MB，每个OSS InitiateMultipartUploadRequest支持的分块最大数量为10000。轮转发生时，object名字规则是：在原有object前缀加UUID随机数的基础上，拼接_1,_2,_3等后缀。\n必选：否 默认值：100000MB 3.3 类型转换 4 性能报告 OSS本身不提供数据类型，该类型是DataX OSSWriter定义：\nDataX 内部类型 OSS 数据类型 Long Long Double Double String String Boolean Boolean Date Date 其中：\nOSS Long是指OSS文本中使用整形的字符串表示形式，例如\u0026quot;19901219\u0026quot;。 OSS Double是指OSS文本中使用Double的字符串表示形式，例如\u0026quot;3.1415\u0026quot;。 OSS Boolean是指OSS文本中使用Boolean的字符串表示形式，例如\u0026quot;true\u0026quot;、\u0026ldquo;false\u0026rdquo;。不区分大小写。 OSS Date是指OSS文本中使用Date的字符串表示形式，例如\u0026quot;2014-12-31\u0026quot;，Date可以指定format格式。 5 约束限制 略\n6 FAQ 略\n","permalink":"https://haokiu.com/blog/516202a7c10f4658ad32aa517c141a05/","summary":"DataX OSSWriter 说明 1 快速介绍 OSSWriter提供了向OSS写入类CSV格式的一个或者多个表文件。\n写入OSS内容存放的是一张逻辑意义上的二维表，例如CSV格式的文本信息。\nOSS 产品介绍, 参看[阿里云OSS Portal] OSS Java SDK, 参看[阿里云OSS Java SDK] 2 功能与限制 OSSWriter实现了从DataX协议转为OSS中的TXT文件功能，OSS本身是无结构化数据存储，OSSWriter需要在如下几个方面增加:\n支持且仅支持写入 TXT的文件，且要求TXT中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n暂时不支持文本压缩。\n支持多线程写入，每个线程写入不同子文件。\n文件支持滚动，当文件大于某个size值或者行数值，文件需要切换。 [暂不支持]\n我们不能做到：\n单个文件不能支持并发写入。 3 功能说明 3.1 配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: {}, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;osswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://oss.aliyuncs.com\u0026#34;, \u0026#34;accessId\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;accessKey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;bucket\u0026#34;: \u0026#34;myBucket\u0026#34;, \u0026#34;object\u0026#34;: \u0026#34;cdo/datax\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate|append|nonConflict\u0026#34; } } } ] } } 3.2 参数说明 endpoint\n描述：OSS Server的EndPoint地址，例如http://oss.aliyuncs.com。\n必选：是 默认值：无 accessId\n描述：OSS的accessId 必选：是 默认值：无 accessKey\n描述：OSS的accessKey 必选：是 默认值：无 bucket\n描述：OSS的bucket 必选：是 默认值：无 object\n描述：OSSWriter写入的文件名，OSS使用文件名模拟目录的实现。 使用\u0026quot;object\u0026quot;: \u0026ldquo;datax\u0026rdquo;，写入object以datax开头，后缀添加随机字符串。 使用\u0026quot;object\u0026quot;: \u0026ldquo;cdo/datax\u0026rdquo;，写入的object以cdo/datax开头，后缀随机添加字符串，/作为OSS模拟目录的分隔符。\n必选：是 默认值：无 writeMode","title":"DataX OSSWriter 说明"},{"content":"DataX PostgresqlWriter 1 快速介绍 PostgresqlWriter插件实现了写入数据到 PostgreSQL主库目的表的功能。在底层实现上，PostgresqlWriter通过JDBC连接远程 PostgreSQL 数据库，并执行相应的 insert into \u0026hellip; sql 语句将数据写入 PostgreSQL，内部会分批次提交入库。\nPostgresqlWriter面向ETL开发工程师，他们使用PostgresqlWriter从数仓导入数据到PostgreSQL。同时 PostgresqlWriter亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 PostgresqlWriter通过 DataX 框架获取 Reader 生成的协议数据，根据你配置生成相应的SQL插入语句\ninsert into...(当主键/唯一性索引冲突时会写不进去冲突的行) 注意： 1. 目的表所在数据库必须是主库才能写入数据；整个任务至少需具备 insert into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 2. PostgresqlWriter和MysqlWriter不同，不支持配置writeMode参数。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 PostgresqlWriter导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;postgresqlwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from test\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:postgresql://127.0.0.1:3002/datax\u0026#34;, \u0026#34;table\u0026#34;: [ \u0026#34;test\u0026#34; ] } ] } } } ] } } 3.2 参数说明 jdbcUrl\n描述：目的数据库的 JDBC 连接信息 ,jdbcUrl必须包含在connection配置单元中。\n注意：1、在一个数据库上只能配置一个值。 2、jdbcUrl按照PostgreSQL官方规范，并可以填写连接附加参数信息。具体请参看PostgreSQL官方文档或者咨询对应 DBA。\n必选：是 默认值：无 username\n描述：目的数据库的用户名 必选：是 默认值：无 password\n描述：目的数据库的密码 必选：是 默认值：无 table\n描述：目的表的表名称。支持写入一个或者多个表。当配置为多张表时，必须确保所有表结构保持一致。\n注意：table 和 jdbcUrl 必须包含在 connection 配置单元中 必选：是 默认值：无 column\n描述：目的表需要写入数据的字段,字段之间用英文逗号分隔。例如: \u0026ldquo;column\u0026rdquo;: [\u0026ldquo;id\u0026rdquo;,\u0026ldquo;name\u0026rdquo;,\u0026ldquo;age\u0026rdquo;]。如果要依次写入全部列，使用*表示, 例如: \u0026ldquo;column\u0026rdquo;: [\u0026quot;*\u0026quot;]\n注意：1、我们强烈不推荐你这样配置，因为当你目的表字段个数、类型等有改动时，你的任务可能运行不正确或者失败 2、此处 column 不能配置任何常量值 必选：是 默认值：否 preSql\n描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 @table 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。比如你的任务是要写入到目的端的100个同构分表(表名称为:datax_00,datax01, \u0026hellip; datax_98,datax_99)，并且你希望导入数据前，先对表中数据进行删除操作，那么你可以这样配置：\u0026quot;preSql\u0026quot;:[\u0026quot;delete from @table\u0026quot;]，效果是：在执行到每个表写入数据前，会先执行对应的 delete from 对应表名称 必选：否 默认值：无 postSql\n描述：写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ） 必选：否 默认值：无 batchSize\n描述：一次性批量提交的记录数大小，该值可以极大减少DataX与PostgreSql的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。\n必选：否 默认值：1024 3.3 类型转换 目前 PostgresqlWriter支持大部分 PostgreSQL类型，但也存在部分没有支持的情况，请注意检查你的类型。\n下面列出 PostgresqlWriter针对 PostgreSQL类型转换列表:\nDataX 内部类型 PostgreSQL 数据类型 Long bigint, bigserial, integer, smallint, serial Double double precision, money, numeric, real String varchar, char, text, bit Date date, time, timestamp Boolean bool Bytes bytea 4 性能报告 4.1 环境准备 4.1.1 数据特征 建表语句：\ncreate table pref_test( id serial, a_bigint bigint, a_bit bit(10), a_boolean boolean, a_char character(5), a_date date, a_double double precision, a_integer integer, a_money money, a_num numeric(10,2), a_real real, a_smallint smallint, a_text text, a_time time, a_timestamp timestamp )\n4.1.2 机器参数 执行DataX的机器参数为:\ncpu: 16核 Intel(R) Xeon(R) CPU E5620 @ 2.40GHz mem: MemTotal: 24676836kB MemFree: 6365080kB net: 百兆双网卡 PostgreSQL数据库机器参数为: D12 24逻辑核 192G内存 12*480G SSD 阵列\n4.2 测试报告 4.2.1 单表测试报告 通道数 批量提交batchSize DataX速度(Rec/s) DataX流量(M/s) DataX机器运行负载 1 128 9259 0.55 0.3 1 512 10869 0.653 0.3 1 2048 9803 0.589 0.8 4 128 30303 1.82 1 4 512 36363 2.18 1 4 2048 36363 2.18 1 8 128 57142 3.43 2 8 512 66666 4.01 1.5 8 2048 66666 4.01 1.1 16 128 88888 5.34 1.8 16 2048 94117 5.65 2.5 32 512 76190 4.58 3 4.2.2 性能测试小结 channel数对性能影响很大 通常不建议写入数据库时，通道个数 \u0026gt; 32 FAQ Q: PostgresqlWriter 执行 postSql 语句报错，那么数据导入到目标数据库了吗?\nA: DataX 导入过程存在三块逻辑，pre 操作、导入操作、post 操作，其中任意一环报错，DataX 作业报错。由于 DataX 不能保证在同一个事务完成上述几个操作，因此有可能数据已经落入到目标端。\nQ: 按照上述说法，那么有部分脏数据导入数据库，如果影响到线上数据库怎么办?\nA: 目前有两种解法，第一种配置 pre 语句，该 sql 可以清理当天导入数据， DataX 每次导入时候可以把上次清理干净并导入完整数据。 第二种，向临时表导入数据，完成后再 rename 到线上表。\n","permalink":"https://haokiu.com/blog/1c01500e456b4ef6b6c14eb5a072696e/","summary":"DataX PostgresqlWriter 1 快速介绍 PostgresqlWriter插件实现了写入数据到 PostgreSQL主库目的表的功能。在底层实现上，PostgresqlWriter通过JDBC连接远程 PostgreSQL 数据库，并执行相应的 insert into \u0026hellip; sql 语句将数据写入 PostgreSQL，内部会分批次提交入库。\nPostgresqlWriter面向ETL开发工程师，他们使用PostgresqlWriter从数仓导入数据到PostgreSQL。同时 PostgresqlWriter亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 PostgresqlWriter通过 DataX 框架获取 Reader 生成的协议数据，根据你配置生成相应的SQL插入语句\ninsert into...(当主键/唯一性索引冲突时会写不进去冲突的行) 注意： 1. 目的表所在数据库必须是主库才能写入数据；整个任务至少需具备 insert into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 2. PostgresqlWriter和MysqlWriter不同，不支持配置writeMode参数。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 PostgresqlWriter导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34; : [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19880808, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 1000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;postgresqlwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from test\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:postgresql://127.","title":"DataX PostgresqlWriter"},{"content":"DataX SqlServerWriter 1 快速介绍 SqlServerWriter 插件实现了写入数据到 SqlServer 库的目的表的功能。在底层实现上， SqlServerWriter 通过 JDBC 连接远程 SqlServer 数据库，并执行相应的 insert into \u0026hellip; sql 语句将数据写入 SqlServer，内部会分批次提交入库。\nSqlServerWriter 面向ETL开发工程师，他们使用 SqlServerWriter 从数仓导入数据到 SqlServer。同时 SqlServerWriter 亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 SqlServerWriter 通过 DataX 框架获取 Reader 生成的协议数据，根据你配置生成相应的SQL语句\ninsert into...(当主键/唯一性索引冲突时会写不进去冲突的行) 注意： 1. 目的表所在数据库必须是主库才能写入数据；整个任务至少需具备 insert into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 2.SqlServerWriter和MysqlWriter不同，不支持配置writeMode参数。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 SqlServer 导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: {}, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;sqlserverwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;db_id\u0026#34;, \u0026#34;db_type\u0026#34;, \u0026#34;db_ip\u0026#34;, \u0026#34;db_port\u0026#34;, \u0026#34;db_role\u0026#34;, \u0026#34;db_name\u0026#34;, \u0026#34;db_username\u0026#34;, \u0026#34;db_password\u0026#34;, \u0026#34;db_modify_time\u0026#34;, \u0026#34;db_modify_user\u0026#34;, \u0026#34;db_description\u0026#34;, \u0026#34;db_tddl_info\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;db_info_for_writer\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:sqlserver://[HOST_NAME]:PORT;DatabaseName=[DATABASE_NAME]\u0026#34; } ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from @table where db_id = -1;\u0026#34; ], \u0026#34;postSql\u0026#34;: [ \u0026#34;update @table set db_modify_time = now() where db_id = 1;\u0026#34; ] } } } ] } } 3.2 参数说明 jdbcUrl\n描述：目的数据库的 JDBC 连接信息 ,jdbcUrl必须包含在connection配置单元中。\n注意：1、在一个数据库上只能配置一个值。这与 SqlServerReader 支持多个备库探测不同，因为此处不支持同一个数据库存在多个主库的情况(双主导入数据情况) 2、jdbcUrl按照SqlServer官方规范，并可以填写连接附加参数信息。具体请参看 SqlServer官方文档或者咨询对应 DBA。 必选：是 默认值：无 username\n描述：目的数据库的用户名 必选：是 默认值：无 password\n描述：目的数据库的密码 必选：是 默认值：无 table\n描述：目的表的表名称。支持写入一个或者多个表。当配置为多张表时，必须确保所有表结构保持一致。\n注意：table 和 jdbcUrl 必须包含在 connection 配置单元中 必选：是 默认值：无 column\n描述：目的表需要写入数据的字段,字段之间用英文逗号分隔。例如: \u0026ldquo;column\u0026rdquo;: [\u0026ldquo;id\u0026rdquo;,\u0026ldquo;name\u0026rdquo;,\u0026ldquo;age\u0026rdquo;]。如果要依次写入全部列，使用表示, 例如: \u0026ldquo;column\u0026rdquo;: [\u0026quot;\u0026quot;]\n**column配置项必须指定，不能留空！** 注意：1、我们强烈不推荐你这样配置，因为当你目的表字段个数、类型等有改动时，你的任务可能运行不正确或者失败 2、此处 column 不能配置任何常量值 必选：是 默认值：否 preSql\n描述：写入数据到目的表前，会先执行这里的标准语句。如果 Sql 中有你需要操作到的表名称，请使用 @table 表示，这样在实际执行 Sql 语句时，会对变量按照实际表名称进行替换。\n必选：否 默认值：无 postSql\n描述：写入数据到目的表后，会执行这里的标准语句。（原理同 preSql ） 必选：否 默认值：无 batchSize\n描述：一次性批量提交的记录数大小，该值可以极大减少DataX与SqlServer的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。\n必选：否 默认值：1024 3.3 类型转换 类似 SqlServerReader ，目前 SqlServerWriter 支持大部分 SqlServer 类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出 SqlServerWriter 针对 SqlServer 类型转换列表:\nDataX 内部类型 SqlServer 数据类型 Long Double String Date Boolean Bytes 4 性能报告 4.1 环境准备 4.1.1 数据特征 建表语句：\n单行记录类似于：\n4.1.2 机器参数 执行 DataX 的机器参数为:\ncpu: 24 Core Intel(R) Xeon(R) CPU E5-2430 0 @ 2.20GHz mem: 94GB net: 千兆双网卡 disc: DataX 数据不落磁盘，不统计此项 SqlServer 数据库机器参数为:\ncpu: 4 Core Intel(R) Xeon(R) CPU E5420 @ 2.50GHz mem: 7GB 4.1.3 DataX jvm 参数 -Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError 4.1.4 性能测试作业配置 4.2 测试报告 4.2.1 测试报告 5 约束限制 FAQ Q: SqlServerWriter 执行 postSql 语句报错，那么数据导入到目标数据库了吗?\nA: DataX 导入过程存在三块逻辑，pre 操作、导入操作、post 操作，其中任意一环报错，DataX 作业报错。由于 DataX 不能保证在同一个事务完成上述几个操作，因此有可能数据已经落入到目标端。\nQ: 按照上述说法，那么有部分脏数据导入数据库，如果影响到线上数据库怎么办?\nA: 目前有两种解法，第一种配置 pre 语句，该 sql 可以清理当天导入数据， DataX 每次导入时候可以把上次清理干净并导入完整数据。第二种，向临时表导入数据，完成后再 rename 到线上表。\nQ: 上面第二种方法可以避免对线上数据造成影响，那我具体怎样操作?\nA: 可以配置临时表导入\n","permalink":"https://haokiu.com/blog/f23fb4346cfa45459b6eaa8537ff5d17/","summary":"DataX SqlServerWriter 1 快速介绍 SqlServerWriter 插件实现了写入数据到 SqlServer 库的目的表的功能。在底层实现上， SqlServerWriter 通过 JDBC 连接远程 SqlServer 数据库，并执行相应的 insert into \u0026hellip; sql 语句将数据写入 SqlServer，内部会分批次提交入库。\nSqlServerWriter 面向ETL开发工程师，他们使用 SqlServerWriter 从数仓导入数据到 SqlServer。同时 SqlServerWriter 亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 SqlServerWriter 通过 DataX 框架获取 Reader 生成的协议数据，根据你配置生成相应的SQL语句\ninsert into...(当主键/唯一性索引冲突时会写不进去冲突的行) 注意： 1. 目的表所在数据库必须是主库才能写入数据；整个任务至少需具备 insert into...的权限，是否需要其他权限，取决于你任务配置中在 preSql 和 postSql 中指定的语句。 2.SqlServerWriter和MysqlWriter不同，不支持配置writeMode参数。 3 功能说明 3.1 配置样例 这里使用一份从内存产生到 SqlServer 导入的数据。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: {}, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;sqlserverwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;db_id\u0026#34;, \u0026#34;db_type\u0026#34;, \u0026#34;db_ip\u0026#34;, \u0026#34;db_port\u0026#34;, \u0026#34;db_role\u0026#34;, \u0026#34;db_name\u0026#34;, \u0026#34;db_username\u0026#34;, \u0026#34;db_password\u0026#34;, \u0026#34;db_modify_time\u0026#34;, \u0026#34;db_modify_user\u0026#34;, \u0026#34;db_description\u0026#34;, \u0026#34;db_tddl_info\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;db_info_for_writer\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:sqlserver://[HOST_NAME]:PORT;DatabaseName=[DATABASE_NAME]\u0026#34; } ], \u0026#34;preSql\u0026#34;: [ \u0026#34;delete from @table where db_id = -1;\u0026#34; ], \u0026#34;postSql\u0026#34;: [ \u0026#34;update @table set db_modify_time = now() where db_id = 1;\u0026#34; ] } } } ] } } 3.","title":"DataX SqlServerWriter"},{"content":"DataX Transformer Transformer定义 在数据同步、传输过程中，存在用户对于数据传输进行特殊定制化的需求场景，包括裁剪列、转换列等工作，可以借助ETL的T过程实现(Transformer)。DataX包含了完整的E(Extract)、T(Transformer)、L(Load)支持。\n运行模型 UDF手册 dx_substr 参数：3个 第一个参数：字段编号，对应record中第几个字段。 第二个参数：字段值的开始位置。 第三个参数：目标字段长度。 返回： 从字符串的指定位置（包含）截取指定长度的字符串。如果开始位置非法抛出异常。如果字段为空值，直接返回（即不参与本transformer） 举例： dx_substr(1,\u0026#34;2\u0026#34;,\u0026#34;5\u0026#34;) column 1的value为“dataxTest”=\u0026gt;\u0026#34;taxTe\u0026#34; dx_substr(1,\u0026#34;5\u0026#34;,\u0026#34;10\u0026#34;) column 1的value为“dataxTest”=\u0026gt;\u0026#34;Test\u0026#34; dx_pad 参数：4个 第一个参数：字段编号，对应record中第几个字段。 第二个参数：\u0026ldquo;l\u0026rdquo;,\u0026ldquo;r\u0026rdquo;, 指示是在头进行pad，还是尾进行pad。 第三个参数：目标字段长度。 第四个参数：需要pad的字符。 返回： 如果源字符串长度小于目标字段长度，按照位置添加pad字符后返回。如果长于，直接截断（都截右边）。如果字段为空值，转换为空字符串进行pad，即最后的字符串全是需要pad的字符 举例： dx_pad(1,\u0026#34;l\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;A\u0026#34;), 如果column 1 的值为 xyz=\u0026gt; Axyz， 值为 xyzzzzz =\u0026gt; xyzz dx_pad(1,\u0026#34;r\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;A\u0026#34;), 如果column 1 的值为 xyz=\u0026gt; xyzA， 值为 xyzzzzz =\u0026gt; xyzz dx_replace 参数：4个 第一个参数：字段编号，对应record中第几个字段。 第二个参数：字段值的开始位置。 第三个参数：需要替换的字段长度。 第四个参数：需要替换的字符串。 返回： 从字符串的指定位置（包含）替换指定长度的字符串。如果开始位置非法抛出异常。如果字段为空值，直接返回（即不参与本transformer） 举例： dx_replace(1,\u0026#34;2\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;****\u0026#34;) column 1的value为“dataxTest”=\u0026gt;\u0026#34;da****est\u0026#34; dx_replace(1,\u0026#34;5\u0026#34;,\u0026#34;10\u0026#34;,\u0026#34;****\u0026#34;) column 1的value为“dataxTest”=\u0026gt;\u0026#34;data****\u0026#34; dx_filter （关联filter暂不支持，即多个字段的联合判断，函参太过复杂，用户难以使用。） 参数： 第一个参数：字段编号，对应record中第几个字段。 第二个参数：运算符，支持一下运算符：like, not like, \u0026gt;, =, \u0026lt;, \u0026gt;=, !=, \u0026lt;= 第三个参数：正则表达式（java正则表达式）、值。 返回： 如果匹配正则表达式，返回Null，表示过滤该行。不匹配表达式时，表示保留该行。（注意是该行）。对于\u0026gt;=\u0026lt;都是对字段直接compare的结果. like ， not like是将字段转换成String，然后和目标正则表达式进行全匹配。 , =, \u0026lt;, \u0026gt;=, !=, \u0026lt;= 对于DoubleColumn比较double值，对于LongColumn和DateColumn比较long值，其他StringColumn，BooleanColumn以及ByteColumn均比较的是StringColumn值。\n如果目标colunn为空（null），对于 = null的过滤条件，将满足条件，被过滤。！=null的过滤条件，null不满足过滤条件，不被过滤。 like，字段为null不满足条件，不被过滤，和not like，字段为null满足条件，被过滤。 举例： dx_filter(1,\u0026#34;like\u0026#34;,\u0026#34;dataTest\u0026#34;) dx_filter(1,\u0026#34;\u0026gt;=\u0026#34;,\u0026#34;10\u0026#34;) dx_groovy 参数。 第一个参数： groovy code 第二个参数（列表或者为空）：extraPackage 备注： dx_groovy只能调用一次。不能多次调用。 groovy code中支持java.lang, java.util的包，可直接引用的对象有record，以及element下的各种column（BoolColumn.class,BytesColumn.class,DateColumn.class,DoubleColumn.class,LongColumn.class,StringColumn.class）。不支持其他包，如果用户有需要用到其他包，可设置extraPackage，注意extraPackage不支持第三方jar包。 groovy code中，返回更新过的Record（比如record.setColumn(columnIndex, new StringColumn(newValue));），或者null。返回null表示过滤此行。 用户可以直接调用静态的Util方式（GroovyTransformerStaticUtil），目前GroovyTransformerStaticUtil的方法列表 (按需补充)： 举例: groovy 实现的subStr: String code = \u0026#34;Column column = record.getColumn(1);\\n\u0026#34; + \u0026#34; String oriValue = column.asString();\\n\u0026#34; + \u0026#34; String newValue = oriValue.substring(0, 3);\\n\u0026#34; + \u0026#34; record.setColumn(1, new StringColumn(newValue));\\n\u0026#34; + \u0026#34; return record;\u0026#34;; dx_groovy(record); groovy 实现的Replace String code2 = \u0026#34;Column column = record.getColumn(1);\\n\u0026#34; + \u0026#34; String oriValue = column.asString();\\n\u0026#34; + \u0026#34; String newValue = \\\u0026#34;****\\\u0026#34; + oriValue.substring(3, oriValue.length());\\n\u0026#34; + \u0026#34; record.setColumn(1, new StringColumn(newValue));\\n\u0026#34; + \u0026#34; return record;\u0026#34;; groovy 实现的Pad String code3 = \u0026#34;Column column = record.getColumn(1);\\n\u0026#34; + \u0026#34; String oriValue = column.asString();\\n\u0026#34; + \u0026#34; String padString = \\\u0026#34;12345\\\u0026#34;;\\n\u0026#34; + \u0026#34; String finalPad = \\\u0026#34;\\\u0026#34;;\\n\u0026#34; + \u0026#34; int NeedLength = 8 - oriValue.length();\\n\u0026#34; + \u0026#34; while (NeedLength \u0026gt; 0) {\\n\u0026#34; + \u0026#34;\\n\u0026#34; + \u0026#34; if (NeedLength \u0026gt;= padString.length()) {\\n\u0026#34; + \u0026#34; finalPad += padString;\\n\u0026#34; + \u0026#34; NeedLength -= padString.length();\\n\u0026#34; + \u0026#34; } else {\\n\u0026#34; + \u0026#34; finalPad += padString.substring(0, NeedLength);\\n\u0026#34; + \u0026#34; NeedLength = 0;\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; }\\n\u0026#34; + \u0026#34; String newValue= finalPad + oriValue;\\n\u0026#34; + \u0026#34; record.setColumn(1, new StringColumn(newValue));\\n\u0026#34; + \u0026#34; return record;\u0026#34;; Job定义 本例中，配置3个UDF。 { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 }, \u0026#34;errorLimit\u0026#34;: { \u0026#34;record\u0026#34;: 0 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;column\u0026#34;: [ { \u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;value\u0026#34;: 19890604, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;1989-06-04 00:00:00\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34; }, { \u0026#34;value\u0026#34;: true, \u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34; }, { \u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34; } ], \u0026#34;sliceRecordCount\u0026#34;: 100000 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } }, \u0026#34;transformer\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;dx_substr\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;columnIndex\u0026#34;:5, \u0026#34;paras\u0026#34;:[\u0026#34;1\u0026#34;,\u0026#34;3\u0026#34;] } }, { \u0026#34;name\u0026#34;: \u0026#34;dx_replace\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;columnIndex\u0026#34;:4, \u0026#34;paras\u0026#34;:[\u0026#34;3\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;****\u0026#34;] } }, { \u0026#34;name\u0026#34;: \u0026#34;dx_groovy\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;code\u0026#34;: \u0026#34;//groovy code//\u0026#34;, \u0026#34;extraPackage\u0026#34;:[ \u0026#34;import somePackage1;\u0026#34;, \u0026#34;import somePackage2;\u0026#34; ] } } ] } ] } } 计量和脏数据 Transform过程涉及到数据的转换，可能造成数据的增加或减少，因此更加需要精确度量，包括：\nTransform的入参Record条数、字节数。 Transform的出参Record条数、字节数。 Transform的脏数据Record条数、字节数。 如果是多个Transform，某一个发生脏数据，将不会再进行后面的transform，直接统计为脏数据。 目前只提供了所有Transform的计量（成功，失败，过滤的count，以及transform的消耗时间）。 涉及到运行过程的计量数据展现定义如下：\nTotal 1000000 records, 22000000 bytes | Transform 100000 records(in), 10000 records(out) | Speed 2.10MB/s, 100000 records/s | Error 0 records, 0 bytes | Percentage 100.00% 注意，这里主要记录转换的输入输出，需要检测数据输入输出的记录数量变化。\n涉及到最终作业的计量数据展现定义如下：\n任务启动时刻 : 2015-03-10 17:34:21 任务结束时刻 : 2015-03-10 17:34:31 任务总计耗时 : 10s 任务平均流量 : 2.10MB/s 记录写入速度 : 100000rec/s 转换输入总数\t: 1000000 转换输出总数\t: 1000000 读出记录总数 : 1000000 同步失败总数 : 0 注意，这里主要记录转换的输入输出，需要检测数据输入输出的记录数量变化。\n","permalink":"https://haokiu.com/blog/760d0498cfcd435bafba3fe96793cd01/","summary":"DataX Transformer Transformer定义 在数据同步、传输过程中，存在用户对于数据传输进行特殊定制化的需求场景，包括裁剪列、转换列等工作，可以借助ETL的T过程实现(Transformer)。DataX包含了完整的E(Extract)、T(Transformer)、L(Load)支持。\n运行模型 UDF手册 dx_substr 参数：3个 第一个参数：字段编号，对应record中第几个字段。 第二个参数：字段值的开始位置。 第三个参数：目标字段长度。 返回： 从字符串的指定位置（包含）截取指定长度的字符串。如果开始位置非法抛出异常。如果字段为空值，直接返回（即不参与本transformer） 举例： dx_substr(1,\u0026#34;2\u0026#34;,\u0026#34;5\u0026#34;) column 1的value为“dataxTest”=\u0026gt;\u0026#34;taxTe\u0026#34; dx_substr(1,\u0026#34;5\u0026#34;,\u0026#34;10\u0026#34;) column 1的value为“dataxTest”=\u0026gt;\u0026#34;Test\u0026#34; dx_pad 参数：4个 第一个参数：字段编号，对应record中第几个字段。 第二个参数：\u0026ldquo;l\u0026rdquo;,\u0026ldquo;r\u0026rdquo;, 指示是在头进行pad，还是尾进行pad。 第三个参数：目标字段长度。 第四个参数：需要pad的字符。 返回： 如果源字符串长度小于目标字段长度，按照位置添加pad字符后返回。如果长于，直接截断（都截右边）。如果字段为空值，转换为空字符串进行pad，即最后的字符串全是需要pad的字符 举例： dx_pad(1,\u0026#34;l\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;A\u0026#34;), 如果column 1 的值为 xyz=\u0026gt; Axyz， 值为 xyzzzzz =\u0026gt; xyzz dx_pad(1,\u0026#34;r\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;A\u0026#34;), 如果column 1 的值为 xyz=\u0026gt; xyzA， 值为 xyzzzzz =\u0026gt; xyzz dx_replace 参数：4个 第一个参数：字段编号，对应record中第几个字段。 第二个参数：字段值的开始位置。 第三个参数：需要替换的字段长度。 第四个参数：需要替换的字符串。 返回： 从字符串的指定位置（包含）替换指定长度的字符串。如果开始位置非法抛出异常。如果字段为空值，直接返回（即不参与本transformer） 举例： dx_replace(1,\u0026#34;2\u0026#34;,\u0026#34;4\u0026#34;,\u0026#34;****\u0026#34;) column 1的value为“dataxTest”=\u0026gt;\u0026#34;da****est\u0026#34; dx_replace(1,\u0026#34;5\u0026#34;,\u0026#34;10\u0026#34;,\u0026#34;****\u0026#34;) column 1的value为“dataxTest”=\u0026gt;\u0026#34;data****\u0026#34; dx_filter （关联filter暂不支持，即多个字段的联合判断，函参太过复杂，用户难以使用。） 参数： 第一个参数：字段编号，对应record中第几个字段。 第二个参数：运算符，支持一下运算符：like, not like, \u0026gt;, =, \u0026lt;, \u0026gt;=, !=, \u0026lt;= 第三个参数：正则表达式（java正则表达式）、值。 返回： 如果匹配正则表达式，返回Null，表示过滤该行。不匹配表达式时，表示保留该行。（注意是该行）。对于\u0026gt;=\u0026lt;都是对字段直接compare的结果. like ， not like是将字段转换成String，然后和目标正则表达式进行全匹配。 , =, \u0026lt;, \u0026gt;=, !=, \u0026lt;= 对于DoubleColumn比较double值，对于LongColumn和DateColumn比较long值，其他StringColumn，BooleanColumn以及ByteColumn均比较的是StringColumn值。\n如果目标colunn为空（null），对于 = null的过滤条件，将满足条件，被过滤。！=null的过滤条件，null不满足过滤条件，不被过滤。 like，字段为null不满足条件，不被过滤，和not like，字段为null满足条件，被过滤。 举例： dx_filter(1,\u0026#34;like\u0026#34;,\u0026#34;dataTest\u0026#34;) dx_filter(1,\u0026#34;\u0026gt;=\u0026#34;,\u0026#34;10\u0026#34;) dx_groovy 参数。 第一个参数： groovy code 第二个参数（列表或者为空）：extraPackage 备注： dx_groovy只能调用一次。不能多次调用。 groovy code中支持java.","title":"DataX Transformer"},{"content":"DataX TxtFileReader 说明 1 快速介绍 TxtFileReader提供了读取本地文件系统数据存储的能力。在底层实现上，TxtFileReader获取本地文件数据，并转换为DataX传输协议传递给Writer。\n本地文件内容存放的是一张逻辑意义上的二维表，例如CSV格式的文本信息。\n2 功能与限制 TxtFileReader实现了从本地文件读取数据并转为DataX协议的功能，本地文件本身是无结构化数据存储，对于DataX而言，TxtFileReader实现上类比OSSReader，有诸多相似之处。目前TxtFileReader支持功能如下：\n支持且仅支持读取TXT的文件，且要求TXT中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n支持多种类型数据读取(使用String表示)，支持列裁剪，支持列常量\n支持递归读取、支持文件名过滤。\n支持文本压缩，现有压缩格式为zip、gzip、bzip2。\n多个File可以支持并发读取。\n我们暂时不能做到：\n单个File支持多线程并发读取，这里涉及到单个File内部切分算法。二期考虑支持。\n单个File在压缩情况下，从技术上无法支持多线程并发读取。\n3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: [\u0026#34;/home/haiwei.luo/case00/data\u0026#34;], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy.MM.dd\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/home/haiwei.luo/case00/result\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;luohw\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy-MM-dd\u0026#34; } } } ] } } 3.2 参数说明 path\n描述：本地文件系统的路径信息，注意这里可以支持填写多个路径。 当指定单个本地文件，TxtFileReader暂时只能使用单线程进行数据抽取。二期考虑在非压缩文件情况下针对单个File可以进行多线程并发读取。\n当指定多个本地文件，TxtFileReader支持使用多线程进行数据抽取。线程并发数通过通道数指定。\n当指定通配符，TxtFileReader尝试遍历出多个文件信息。例如: 指定/*代表读取/目录下所有的文件，指定/bazhen/*代表读取bazhen目录下游所有的文件。TxtFileReader目前只支持*作为文件通配符。\n特别需要注意的是，DataX会将一个作业下同步的所有Text File视作同一张数据表。用户必须自己保证所有的File能够适配同一套schema信息。读取文件用户必须保证为类CSV格式，并且提供给DataX权限可读。\n特别需要注意的是，如果Path指定的路径下没有符合匹配的文件抽取，DataX将报错。\n必选：是 默认值：无 column\n描述：读取字段列表，type指定源数据的类型，index指定当前列来自于文本第几列(以0开始)，value指定当前类型为常量，不从源头文件读取数据，而是根据value值自动生成对应的列。 默认情况下，用户可以全部按照String类型读取数据，配置如下：\n\u0026#34;column\u0026#34;: [\u0026#34;*\u0026#34;] 用户可以指定Column字段信息，配置如下：\n{ \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;, \u0026#34;index\u0026#34;: 0 //从本地文件文本第一列获取int字段 }, { \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;: \u0026#34;alibaba\u0026#34; //从TxtFileReader内部生成alibaba的字符串字段作为当前字段 } 对于用户指定Column信息，type必须填写，index/value必须选择其一。\n必选：是 默认值：全部按照string类型读取 fieldDelimiter\n描述：读取的字段分隔符 必选：是 默认值：, compress\n描述：文本压缩类型，默认不填写意味着没有压缩。支持压缩类型为zip、gzip、bzip2。 必选：否 默认值：没有压缩 encoding\n描述：读取文件的编码配置。\n必选：否 默认值：utf-8 skipHeader\n描述：类CSV格式文件可能存在表头为标题情况，需要跳过。默认不跳过。\n必选：否 默认值：false nullFormat\n描述：文本文件中无法使用标准字符串定义null(空指针)，DataX提供nullFormat定义哪些字符串可以表示为null。\n例如如果用户配置: nullFormat:\u0026quot;\\N\u0026quot;，那么如果源头数据是\u0026quot;\\N\u0026quot;，DataX视作null字段。\n必选：否 默认值：\\N csvReaderConfig\n描述：读取CSV类型文件参数配置，Map类型。读取CSV类型文件使用的CsvReader进行读取，会有很多配置，不配置则使用默认值。\n必选：否 默认值：无 常见配置：\n\u0026#34;csvReaderConfig\u0026#34;:{ \u0026#34;safetySwitch\u0026#34;: false, \u0026#34;skipEmptyRecords\u0026#34;: false, \u0026#34;useTextQualifier\u0026#34;: false } 所有配置项及默认值,配置时 csvReaderConfig 的map中请严格按照以下字段名字进行配置：\nboolean caseSensitive = true; char textQualifier = 34; boolean trimWhitespace = true; boolean useTextQualifier = true;//是否使用csv转义字符 char delimiter = 44;//分隔符 char recordDelimiter = 0; char comment = 35; boolean useComments = false; int escapeMode = 1; boolean safetySwitch = true;//单列长度是否限制100000字符 boolean skipEmptyRecords = true;//是否跳过空行 boolean captureRawRecord = true; 3.3 类型转换 本地文件本身不提供数据类型，该类型是DataX TxtFileReader定义：\nDataX 内部类型 本地文件 数据类型 Long Long Double Double String String Boolean Boolean Date Date 其中：\n本地文件 Long是指本地文件文本中使用整形的字符串表示形式，例如\u0026quot;19901219\u0026quot;。 本地文件 Double是指本地文件文本中使用Double的字符串表示形式，例如\u0026quot;3.1415\u0026quot;。 本地文件 Boolean是指本地文件文本中使用Boolean的字符串表示形式，例如\u0026quot;true\u0026quot;、\u0026ldquo;false\u0026rdquo;。不区分大小写。 本地文件 Date是指本地文件文本中使用Date的字符串表示形式，例如\u0026quot;2014-12-31\u0026quot;，Date可以指定format格式。 4 性能报告 5 约束限制 略\n6 FAQ 略\n","permalink":"https://haokiu.com/blog/cbeab748638041dfa63c78ebe4fa91db/","summary":"DataX TxtFileReader 说明 1 快速介绍 TxtFileReader提供了读取本地文件系统数据存储的能力。在底层实现上，TxtFileReader获取本地文件数据，并转换为DataX传输协议传递给Writer。\n本地文件内容存放的是一张逻辑意义上的二维表，例如CSV格式的文本信息。\n2 功能与限制 TxtFileReader实现了从本地文件读取数据并转为DataX协议的功能，本地文件本身是无结构化数据存储，对于DataX而言，TxtFileReader实现上类比OSSReader，有诸多相似之处。目前TxtFileReader支持功能如下：\n支持且仅支持读取TXT的文件，且要求TXT中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n支持多种类型数据读取(使用String表示)，支持列裁剪，支持列常量\n支持递归读取、支持文件名过滤。\n支持文本压缩，现有压缩格式为zip、gzip、bzip2。\n多个File可以支持并发读取。\n我们暂时不能做到：\n单个File支持多线程并发读取，这里涉及到单个File内部切分算法。二期考虑支持。\n单个File在压缩情况下，从技术上无法支持多线程并发读取。\n3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: [\u0026#34;/home/haiwei.luo/case00/data\u0026#34;], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy.MM.dd\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/home/haiwei.luo/case00/result\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;luohw\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy-MM-dd\u0026#34; } } } ] } } 3.","title":"DataX TxtFileReader 说明"},{"content":"DataX TxtFileWriter 说明 1 快速介绍 TxtFileWriter提供了向本地文件写入类CSV格式的一个或者多个表文件。TxtFileWriter服务的用户主要在于DataX开发、测试同学。\n写入本地文件内容存放的是一张逻辑意义上的二维表，例如CSV格式的文本信息。\n2 功能与限制 TxtFileWriter实现了从DataX协议转为本地TXT文件功能，本地文件本身是无结构化数据存储，TxtFileWriter如下几个方面约定:\n支持且仅支持写入 TXT的文件，且要求TXT中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n支持文本压缩，现有压缩格式为gzip、bzip2。\n支持多线程写入，每个线程写入不同子文件。\n文件支持滚动，当文件大于某个size值或者行数值，文件需要切换。 [暂不支持]\n我们不能做到：\n单个文件不能支持并发写入。 3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: [\u0026#34;/home/haiwei.luo/case00/data\u0026#34;], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy.MM.dd\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/home/haiwei.luo/case00/result\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;luohw\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate\u0026#34;, \u0026#34;dateFormat\u0026#34;: \u0026#34;yyyy-MM-dd\u0026#34; } } } ] } } 3.2 参数说明 path\n描述：本地文件系统的路径信息，TxtFileWriter会写入Path目录下属多个文件。 必选：是 默认值：无 fileName\n描述：TxtFileWriter写入的文件名，该文件名会添加随机的后缀作为每个线程写入实际文件名。 必选：是 默认值：无 writeMode\n描述：TxtFileWriter写入前数据清理处理模式： truncate，写入前清理目录下一fileName前缀的所有文件。 append，写入前不做任何处理，DataX TxtFileWriter直接使用filename写入，并保证文件名不冲突。 nonConflict，如果目录下有fileName前缀的文件，直接报错。 必选：是 默认值：无 fieldDelimiter\n描述：读取的字段分隔符 必选：否 默认值：, compress\n描述：文本压缩类型，默认不填写意味着没有压缩。支持压缩类型为zip、lzo、lzop、tgz、bzip2。 必选：否 默认值：无压缩 encoding\n描述：读取文件的编码配置。\n必选：否 默认值：utf-8 nullFormat\n描述：文本文件中无法使用标准字符串定义null(空指针)，DataX提供nullFormat定义哪些字符串可以表示为null。\n例如如果用户配置: nullFormat=\u0026quot;\\N\u0026quot;，那么如果源头数据是\u0026quot;\\N\u0026quot;，DataX视作null字段。\n必选：否 默认值：\\N dateFormat\n描述：日期类型的数据序列化到文件中时的格式，例如 \u0026ldquo;dateFormat\u0026rdquo;: \u0026ldquo;yyyy-MM-dd\u0026rdquo;。\n必选：否 默认值：无 fileFormat\n描述：文件写出的格式，包括csv (http://zh.wikipedia.org/wiki/%E9%80%97%E5%8F%B7%E5%88%86%E9%9A%94%E5%80%BC) 和text两种，csv是严格的csv格式，如果待写数据包括列分隔符，则会按照csv的转义语法转义，转义符号为双引号\u0026quot;；text格式是用列分隔符简单分割待写数据，对于待写数据包括列分隔符情况下不做转义。\n必选：否 默认值：text header\n描述：txt写出时的表头，示例[\u0026lsquo;id\u0026rsquo;, \u0026rsquo;name\u0026rsquo;, \u0026lsquo;age\u0026rsquo;]。\n必选：否 默认值：无 3.3 类型转换 本地文件本身不提供数据类型，该类型是DataX TxtFileWriter定义：\nDataX 内部类型 本地文件 数据类型 Long Long Double Double String String Boolean Boolean Date Date 其中：\n本地文件 Long是指本地文件文本中使用整形的字符串表示形式，例如\u0026quot;19901219\u0026quot;。 本地文件 Double是指本地文件文本中使用Double的字符串表示形式，例如\u0026quot;3.1415\u0026quot;。 本地文件 Boolean是指本地文件文本中使用Boolean的字符串表示形式，例如\u0026quot;true\u0026quot;、\u0026ldquo;false\u0026rdquo;。不区分大小写。 本地文件 Date是指本地文件文本中使用Date的字符串表示形式，例如\u0026quot;2014-12-31\u0026quot;，Date可以指定format格式。 4 性能报告 5 约束限制 略\n6 FAQ 略\n","permalink":"https://haokiu.com/blog/599f9ae387e54760ab26e177bd423e82/","summary":"DataX TxtFileWriter 说明 1 快速介绍 TxtFileWriter提供了向本地文件写入类CSV格式的一个或者多个表文件。TxtFileWriter服务的用户主要在于DataX开发、测试同学。\n写入本地文件内容存放的是一张逻辑意义上的二维表，例如CSV格式的文本信息。\n2 功能与限制 TxtFileWriter实现了从DataX协议转为本地TXT文件功能，本地文件本身是无结构化数据存储，TxtFileWriter如下几个方面约定:\n支持且仅支持写入 TXT的文件，且要求TXT中shema为一张二维表。\n支持类CSV格式文件，自定义分隔符。\n支持文本压缩，现有压缩格式为gzip、bzip2。\n支持多线程写入，每个线程写入不同子文件。\n文件支持滚动，当文件大于某个size值或者行数值，文件需要切换。 [暂不支持]\n我们不能做到：\n单个文件不能支持并发写入。 3 功能说明 3.1 配置样例 { \u0026#34;setting\u0026#34;: {}, \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 2 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: [\u0026#34;/home/haiwei.luo/case00/data\u0026#34;], \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;long\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;boolean\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;double\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;yyyy.MM.dd\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/home/haiwei.luo/case00/result\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;luohw\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate\u0026#34;, \u0026#34;dateFormat\u0026#34;: \u0026#34;yyyy-MM-dd\u0026#34; } } } ] } } 3.","title":"DataX TxtFileWriter 说明"},{"content":"datax-kudu-plugin datax kudu的writer插件\n仅在kudu11进行过测试\n","permalink":"https://haokiu.com/blog/3909c1ec487c48198ae49ab46ba98dcb/","summary":"datax-kudu-plugin datax kudu的writer插件\n仅在kudu11进行过测试","title":"datax-kudu-plugin"},{"content":"datax-kudu-plugins datax kudu的writer插件\neg:\n{ \u0026#34;name\u0026#34;: \u0026#34;kuduwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;kuduConfig\u0026#34;: { \u0026#34;kudu.master_addresses\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;timeout\u0026#34;: 60000, \u0026#34;sessionTimeout\u0026#34;: 60000 }, \u0026#34;table\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;replicaCount\u0026#34;: 3, \u0026#34;truncate\u0026#34;: false, \u0026#34;writeMode\u0026#34;: \u0026#34;upsert\u0026#34;, \u0026#34;partition\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;column1\u0026#34;: [ { \u0026#34;lower\u0026#34;: \u0026#34;2020-08-25\u0026#34;, \u0026#34;upper\u0026#34;: \u0026#34;2020-08-26\u0026#34; }, { \u0026#34;lower\u0026#34;: \u0026#34;2020-08-26\u0026#34;, \u0026#34;upper\u0026#34;: \u0026#34;2020-08-27\u0026#34; }, { \u0026#34;lower\u0026#34;: \u0026#34;2020-08-27\u0026#34;, \u0026#34;upper\u0026#34;: \u0026#34;2020-08-28\u0026#34; } ] }, \u0026#34;hash\u0026#34;: { \u0026#34;column\u0026#34;: [ \u0026#34;column1\u0026#34; ], \u0026#34;number\u0026#34;: 3 } }, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;name\u0026#34;: \u0026#34;c1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;primaryKey\u0026#34;: true }, { \u0026#34;index\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;c2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;compress\u0026#34;: \u0026#34;DEFAULT_COMPRESSION\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;AUTO_ENCODING\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;注解xxxx\u0026#34; } ], \u0026#34;batchSize\u0026#34;: 1024, \u0026#34;bufferSize\u0026#34;: 2048, \u0026#34;skipFail\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } 必须参数：\n\u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;kuduwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;kuduConfig\u0026#34;: { \u0026#34;kudu.master_addresses\u0026#34;: \u0026#34;***\u0026#34; }, \u0026#34;table\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;c1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;primaryKey\u0026#34;: true }, { \u0026#34;name\u0026#34;: \u0026#34;c2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, }, { \u0026#34;name\u0026#34;: \u0026#34;c3\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;c4\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ] } } 主键列请写到最前面\n配置列表 name default description 是否必须 kuduConfig kudu配置 （kudu.master_addresses等） 是 table 导入目标表名 是 partition 分区 否 column 列 是 name 列名 是 type string 列的类型，现支持INT, FLOAT, STRING, BIGINT, DOUBLE, BOOLEAN, LONG。 否 index 升序排列 列索引位置(要么全部列都写，要么都不写)，如reader中取到的某一字段在第二位置（eg： name， id， age）但kudu目标表结构不同（eg：id，name， age），此时就需要将index赋值为（1，0，2），默认顺序（0，1，2） 否 primaryKey false 是否为主键（请将所有的主键列写在前面）,不表明主键将不会检查过滤脏数据 否 compress DEFAULT_COMPRESSION 压缩格式 否 encoding AUTO_ENCODING 编码 否 replicaCount 3 保留副本个数 否 hash hash分区 否 number 3 hash分区个数 否 range range分区 否 lower range分区下限 (eg: sql建表：partition value=\u0026lsquo;haha\u0026rsquo; 对应：“lower”：“haha”，“upper”：“haha\\000”) 否 upper range分区上限(eg: sql建表：partition \u0026ldquo;10\u0026rdquo; \u0026lt;= VALUES \u0026lt; \u0026ldquo;20\u0026rdquo; 对应：“lower”：“10”，“upper”：“20”) 否 truncate false 是否清空表，本质上是删表重建 否 writeMode upsert upsert，insert，update 否 batchSize 512 每xx行数据flush一次结果（最好不要超过1024） 否 bufferSize 3072 缓冲区大小 否 skipFail false 是否跳过插入不成功的数据 否 timeout 60000 client超时时间,如创建表，删除表操作的超时时间。单位：ms 否 sessionTimeout 60000 session超时时间 单位：ms 否 ","permalink":"https://haokiu.com/blog/23a56c95c6c4402998fb8bf16e29fc05/","summary":"datax-kudu-plugins datax kudu的writer插件\neg:\n{ \u0026#34;name\u0026#34;: \u0026#34;kuduwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;kuduConfig\u0026#34;: { \u0026#34;kudu.master_addresses\u0026#34;: \u0026#34;***\u0026#34;, \u0026#34;timeout\u0026#34;: 60000, \u0026#34;sessionTimeout\u0026#34;: 60000 }, \u0026#34;table\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;replicaCount\u0026#34;: 3, \u0026#34;truncate\u0026#34;: false, \u0026#34;writeMode\u0026#34;: \u0026#34;upsert\u0026#34;, \u0026#34;partition\u0026#34;: { \u0026#34;range\u0026#34;: { \u0026#34;column1\u0026#34;: [ { \u0026#34;lower\u0026#34;: \u0026#34;2020-08-25\u0026#34;, \u0026#34;upper\u0026#34;: \u0026#34;2020-08-26\u0026#34; }, { \u0026#34;lower\u0026#34;: \u0026#34;2020-08-26\u0026#34;, \u0026#34;upper\u0026#34;: \u0026#34;2020-08-27\u0026#34; }, { \u0026#34;lower\u0026#34;: \u0026#34;2020-08-27\u0026#34;, \u0026#34;upper\u0026#34;: \u0026#34;2020-08-28\u0026#34; } ] }, \u0026#34;hash\u0026#34;: { \u0026#34;column\u0026#34;: [ \u0026#34;column1\u0026#34; ], \u0026#34;number\u0026#34;: 3 } }, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;name\u0026#34;: \u0026#34;c1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;primaryKey\u0026#34;: true }, { \u0026#34;index\u0026#34;: 1, \u0026#34;name\u0026#34;: \u0026#34;c2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;compress\u0026#34;: \u0026#34;DEFAULT_COMPRESSION\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;AUTO_ENCODING\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;注解xxxx\u0026#34; } ], \u0026#34;batchSize\u0026#34;: 1024, \u0026#34;bufferSize\u0026#34;: 2048, \u0026#34;skipFail\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } 必须参数：","title":"datax-kudu-plugins"},{"content":"DataX插件开发宝典 本文面向DataX插件开发人员，尝试尽可能全面地阐述开发一个DataX插件所经过的历程，力求消除开发者的困惑，让插件开发变得简单。\n一、开发之前 路走对了，就不怕远。✓ 路走远了，就不管对不对。✕\n当你打开这篇文档，想必已经不用在此解释什么是DataX了。那下一个问题便是：\nDataX为什么要使用插件机制？ 从设计之初，DataX就把异构数据源同步作为自身的使命，为了应对不同数据源的差异、同时提供一致的同步原语和扩展能力，DataX自然而然地采用了框架 + 插件 的模式：\n插件只需关心数据的读取或者写入本身。 而同步的共性问题，比如：类型转换、性能、统计，则交由框架来处理。 作为插件开发人员，则需要关注两个问题：\n数据源本身的读写数据正确性。 如何与框架沟通、合理正确地使用框架。 开工前需要想明白的问题 就插件本身而言，希望在您动手coding之前，能够回答我们列举的这些问题，不然路走远了发现没走对，就尴尬了。\n二、插件视角看框架 逻辑执行模型 插件开发者不用关心太多，基本只需要关注特定系统读和写，以及自己的代码在逻辑上是怎样被执行的，哪一个方法是在什么时候被调用的。在此之前，需要明确以下概念：\nJob: Job是DataX用以描述从一个源头到一个目的端的同步作业，是DataX数据同步的最小业务单元。比如：从一张mysql的表同步到odps的一个表的特定分区。 Task: Task是为最大化而把Job拆分得到的最小执行单元。比如：读一张有1024个分表的mysql分库分表的Job，拆分成1024个读Task，用若干个并发执行。 TaskGroup: 描述的是一组Task集合。在同一个TaskGroupContainer执行下的Task集合称之为TaskGroup JobContainer: Job执行器，负责Job全局拆分、调度、前置语句和后置语句等工作的工作单元。类似Yarn中的JobTracker TaskGroupContainer: TaskGroup执行器，负责执行一组Task的工作单元，类似Yarn中的TaskTracker。 简而言之， Job拆分成Task，在分别在框架提供的容器中执行，插件只需要实现Job和Task两部分逻辑。\n物理执行模型 框架为插件提供物理上的执行能力（线程）。DataX框架有三种运行模式：\nStandalone: 单进程运行，没有外部依赖。 Local: 单进程运行，统计信息、错误信息汇报到集中存储。 Distrubuted: 分布式多进程运行，依赖DataX Service服务。 当然，上述三种模式对插件的编写而言没有什么区别，你只需要避开一些小错误，插件就能够在单机/分布式之间无缝切换了。 当JobContainer和TaskGroupContainer运行在同一个进程内时，就是单机模式（Standalone和Local）；当它们分布在不同的进程中执行时，就是分布式（Distributed）模式。\n是不是很简单？\n编程接口 那么，Job和Task的逻辑应是怎么对应到具体的代码中的？\n首先，插件的入口类必须扩展Reader或Writer抽象类，并且实现分别实现Job和Task两个内部抽象类，Job和Task的实现必须是 内部类 的形式，原因见 加载原理 一节。以Reader为例：\npublic class SomeReader extends Reader { public static class Job extends Reader.Job { @Override public void init() { } @Override public void prepare() { } @Override public List\u0026lt;Configuration\u0026gt; split(int adviceNumber) { return null; } @Override public void post() { } @Override public void destroy() { } } public static class Task extends Reader.Task { @Override public void init() { } @Override public void prepare() { } @Override public void startRead(RecordSender recordSender) { } @Override public void post() { } @Override public void destroy() { } } } Job接口功能如下：\ninit: Job对象初始化工作，此时可以通过super.getPluginJobConf()获取与本插件相关的配置。读插件获得配置中reader部分，写插件获得writer部分。 prepare: 全局准备工作，比如odpswriter清空目标表。 split: 拆分Task。参数adviceNumber框架建议的拆分数，一般是运行时所配置的并发度。值返回的是Task的配置列表。 post: 全局的后置工作，比如mysqlwriter同步完影子表后的rename操作。 destroy: Job对象自身的销毁工作。 Task接口功能如下：\ninit：Task对象的初始化。此时可以通过super.getPluginJobConf()获取与本Task相关的配置。这里的配置是Job的split方法返回的配置列表中的其中一个。 prepare：局部的准备工作。 startRead: 从数据源读数据，写入到RecordSender中。RecordSender会把数据写入连接Reader和Writer的缓存队列。 startWrite：从RecordReceiver中读取数据，写入目标数据源。RecordReceiver中的数据来自Reader和Writer之间的缓存队列。 post: 局部的后置工作。 destroy: Task象自身的销毁工作。 需要注意的是：\nJob和Task之间一定不能有共享变量，因为分布式运行时不能保证共享变量会被正确初始化。两者之间只能通过配置文件进行依赖。 prepare和post在Job和Task中都存在，插件需要根据实际情况确定在什么地方执行操作。 框架按照如下的顺序执行Job和Task的接口：\n上图中，黄色表示Job部分的执行阶段，蓝色表示Task部分的执行阶段，绿色表示框架执行阶段。\n相关类关系如下：\n插件定义 代码写好了，有没有想过框架是怎么找到插件的入口类的？框架是如何加载插件的呢？\n在每个插件的项目中，都有一个plugin.json文件，这个文件定义了插件的相关信息，包括入口类。例如：\n{ \u0026#34;name\u0026#34;: \u0026#34;mysqlwriter\u0026#34;, \u0026#34;class\u0026#34;: \u0026#34;com.alibaba.datax.plugin.writer.mysqlwriter.MysqlWriter\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Use Jdbc connect to database, execute insert sql.\u0026#34;, \u0026#34;developer\u0026#34;: \u0026#34;alibaba\u0026#34; } name: 插件名称，大小写敏感。框架根据用户在配置文件中指定的名称来搜寻插件。 十分重要 。 class: 入口类的全限定名称，框架通过反射插件入口类的实例。十分重要 。 description: 描述信息。 developer: 开发人员。 打包发布 DataX使用assembly打包，assembly的使用方法请咨询谷哥或者度娘。打包命令如下：\nmvn clean package -DskipTests assembly:assembly DataX插件需要遵循统一的目录结构：\nNULL |-- bin | `-- datax.py |-- conf | |-- core.json | `-- logback.xml |-- lib | `-- datax-core-dependencies.jar `-- plugin |-- reader | `-- mysqlreader | |-- libs | | `-- mysql-reader-plugin-dependencies.jar | |-- mysqlreader-0.0.1-SNAPSHOT.jar | `-- plugin.json `-- writer |-- mysqlwriter | |-- libs | | `-- mysql-writer-plugin-dependencies.jar | |-- mysqlwriter-0.0.1-SNAPSHOT.jar | `-- plugin.json |-- oceanbasewriter `-- odpswriter NULL/bin: 可执行程序目录。 NULL/conf: 框架配置目录。 NULL/lib: 框架依赖库目录。 NULL/plugin: 插件目录。 插件目录分为reader和writer子目录，读写插件分别存放。插件目录规范如下：\nNULL/libs: 插件的依赖库。 NULL/plugin-name-version.jar: 插件本身的jar。 NULL/plugin.json: 插件描述文件。 尽管框架加载插件时，会把NULL下所有的jar放到classpath，但还是推荐依赖库的jar和插件本身的jar分开存放。\n注意： 插件的目录名字必须和plugin.json中定义的插件名称一致。\n配置文件 DataX使用json作为配置文件的格式。一个典型的DataX任务配置如下：\n{ \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;odpsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;accessKey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;accessId\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;column\u0026#34;: [\u0026#34;\u0026#34;], \u0026#34;isCompress\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;odpsServer\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;partition\u0026#34;: [ \u0026#34;\u0026#34; ], \u0026#34;project\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;tunnelServer\u0026#34;: \u0026#34;\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;oraclewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;column\u0026#34;: [\u0026#34;*\u0026#34;], \u0026#34;connection\u0026#34;: [ { \u0026#34;jdbcUrl\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;table\u0026#34;: [ \u0026#34;\u0026#34; ] } ] } } } ] } } DataX框架有core.json配置文件，指定了框架的默认行为。任务的配置里头可以指定框架中已经存在的配置项，而且具有更高的优先级，会覆盖core.json中的默认值。\n配置中job.content.reader.parameter的value部分会传给Reader.Job；job.content.writer.parameter的value部分会传给Writer.Job ，Reader.Job和Writer.Job可以通过super.getPluginJobConf()来获取。\nDataX框架支持对特定的配置项进行RSA加密，例子中以*开头的项目便是加密后的值。 配置项加密解密过程对插件是透明，插件仍然以不带*的key来查询配置和操作配置项 。\n如何设计配置参数 配置文件的设计是插件开发的第一步！\n任务配置中reader和writer下parameter部分是插件的配置参数，插件的配置参数应当遵循以下原则：\n驼峰命名：所有配置项采用驼峰命名法，首字母小写，单词首字母大写。\n正交原则：配置项必须正交，功能没有重复，没有潜规则。\n富类型：合理使用json的类型，减少无谓的处理逻辑，减少出错的可能。\n使用正确的数据类型。比如，bool类型的值使用true/false，而非\u0026quot;yes\u0026quot;/\u0026quot;true\u0026quot;/0等。 合理使用集合类型，比如，用数组替代有分隔符的字符串。 类似通用：遵守同一类型的插件的习惯，比如关系型数据库的connection参数都是如下结构：\n{ \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table_1\u0026#34;, \u0026#34;table_2\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:mysql://127.0.0.1:3306/database_1\u0026#34;, \u0026#34;jdbc:mysql://127.0.0.2:3306/database_1_slave\u0026#34; ] }, { \u0026#34;table\u0026#34;: [ \u0026#34;table_3\u0026#34;, \u0026#34;table_4\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:mysql://127.0.0.3:3306/database_2\u0026#34;, \u0026#34;jdbc:mysql://127.0.0.4:3306/database_2_slave\u0026#34; ] } ] } \u0026hellip;\n如何使用Configuration类 为了简化对json的操作，DataX提供了简单的DSL配合Configuration类使用。\nConfiguration提供了常见的get, 带类型get，带默认值get，set等读写配置项的操作，以及clone, toJSON等方法。配置项读写操作都需要传入一个path做为参数，这个path就是DataX定义的DSL。语法有两条：\n子map用.key表示，path的第一个点省略。 数组元素用[index]表示。 比如操作如下json：\n{ \u0026#34;a\u0026#34;: { \u0026#34;b\u0026#34;: { \u0026#34;c\u0026#34;: 2 }, \u0026#34;f\u0026#34;: [ 1, 2, { \u0026#34;g\u0026#34;: true, \u0026#34;h\u0026#34;: false }, 4 ] }, \u0026#34;x\u0026#34;: 4 } 比如调用configuration.get(path)方法，当path为如下值的时候得到的结果为：\nx：4 a.b.c：2 a.b.c.d：null a.b.f[0]：1 a.b.f[2].g：true 注意，因为插件看到的配置只是整个配置的一部分。使用Configuration对象时，需要注意当前的根路径是什么。\n更多Configuration的操作请参考ConfigurationTest.java。\n插件数据传输 跟一般的生产者-消费者模式一样，Reader插件和Writer插件之间也是通过channel来实现数据的传输的。channel可以是内存的，也可能是持久化的，插件不必关心。插件通过RecordSender往channel写入数据，通过RecordReceiver从channel读取数据。\nchannel中的一条数据为一个Record的对象，Record中可以放多个Column对象，这可以简单理解为数据库中的记录和列。\nRecord有如下方法：\npublic interface Record { // 加入一个列，放在最后的位置 void addColumn(Column column); // 在指定下标处放置一个列 void setColumn(int i, final Column column); // 获取一个列 Column getColumn(int i); // 转换为json String String toString(); // 获取总列数 int getColumnNumber(); // 计算整条记录在内存中占用的字节数 int getByteSize(); } 因为Record是一个接口，Reader插件首先调用RecordSender.createRecord()创建一个Record实例，然后把Column一个个添加到Record中。\nWriter插件调用RecordReceiver.getFromReader()方法获取Record，然后把Column遍历出来，写入目标存储中。当Reader尚未退出，传输还在进行时，如果暂时没有数据RecordReceiver.getFromReader()方法会阻塞直到有数据。如果传输已经结束，会返回null，Writer插件可以据此判断是否结束startWrite方法。\nColumn的构造和操作，我们在《类型转换》一节介绍。\n类型转换 为了规范源端和目的端类型转换操作，保证数据不失真，DataX支持六种内部数据类型：\nLong：定点数(Int、Short、Long、BigInteger等)。 Double：浮点数(Float、Double、BigDecimal(无限精度)等)。 String：字符串类型，底层不限长，使用通用字符集(Unicode)。 Date：日期类型。 Bool：布尔值。 Bytes：二进制，可以存放诸如MP3等非结构化数据。 对应地，有DateColumn、LongColumn、DoubleColumn、BytesColumn、StringColumn和BoolColumn六种Column的实现。\nColumn除了提供数据相关的方法外，还提供一系列以as开头的数据类型转换转换方法。\nDataX的内部类型在实现上会选用不同的java类型：\n内部类型 实现类型 备注 Date java.util.Date Long java.math.BigInteger 使用无限精度的大整数，保证不失真 Double java.lang.String 用String表示，保证不失真 Bytes byte[] String java.lang.String Bool java.lang.Boolean 类型之间相互转换的关系如下：\nfrom\\to Date Long Double Bytes String Bool Date - 使用毫秒时间戳 不支持 不支持 使用系统配置的date/time/datetime格式转换 不支持 Long 作为毫秒时间戳构造Date - BigInteger转为BigDecimal，然后BigDecimal.doubleValue() 不支持 BigInteger.toString() 0为false，否则true Double 不支持 内部String构造BigDecimal，然后BigDecimal.longValue() - 不支持 直接返回内部String Bytes 不支持 不支持 不支持 - 按照common.column.encoding配置的编码转换为String，默认utf-8 不支持 String 按照配置的date/time/datetime/extra格式解析 用String构造BigDecimal，然后取longValue() 用String构造BigDecimal，然后取doubleValue(),会正确处理NaN/Infinity/-Infinity 按照common.column.encoding配置的编码转换为byte[]，默认utf-8 - \u0026ldquo;true\u0026quot;为true, \u0026ldquo;false\u0026quot;为false，大小写不敏感。其他字符串不支持 Bool 不支持 true为1L，否则0L true为1.0，否则0.0 不支持 - 脏数据处理 什么是脏数据？ 目前主要有三类脏数据：\nReader读到不支持的类型、不合法的值。 不支持的类型转换，比如：Bytes转换为Date。 写入目标端失败，比如：写mysql整型长度超长。 如何处理脏数据 在Reader.Task和Writer.Task中，通过AbstractTaskPlugin.getTaskPluginCollector()可以拿到一个TaskPluginCollector，它提供了一系列collectDirtyRecord的方法。当脏数据出现时，只需要调用合适的collectDirtyRecord方法，把被认为是脏数据的Record传入即可。\n用户可以在任务的配置中指定脏数据限制条数或者百分比限制，当脏数据超出限制时，框架会结束同步任务，退出。插件需要保证脏数据都被收集到，其他工作交给框架就好。\n加载原理 框架扫描plugin/reader和plugin/writer目录，加载每个插件的plugin.json文件。 以plugin.json文件中name为key，索引所有的插件配置。如果发现重名的插件，框架会异常退出。 用户在插件中在reader/writer配置的name字段指定插件名字。框架根据插件的类型（reader/writer）和插件名称去插件的路径下扫描所有的jar，加入classpath。 根据插件配置中定义的入口类，框架通过反射实例化对应的Job和Task对象。 三、Last but not Least 文档是工程师的良知。\n每个插件都必须在DataX官方wiki中有一篇文档，文档需要包括但不限于以下内容：\n快速介绍：介绍插件的使用场景，特点等。 实现原理：介绍插件实现的底层原理，比如mysqlwriter通过insert into和replace into来实现插入，tair插件通过tair客户端实现写入。 配置说明 给出典型场景下的同步任务的json配置文件。 介绍每个参数的含义、是否必选、默认值、取值范围和其他约束。 类型转换 插件是如何在实际的存储类型和DataX的内部类型之间进行转换的。 以及是否存在特殊处理。 性能报告 软硬件环境，系统版本，java版本，CPU、内存等。 数据特征，记录大小等。 测试参数集（多组），系统参数（比如并发数），插件参数（比如batchSize） 不同参数下同步速度（Rec/s, MB/s），机器负载（load, cpu）等，对数据源压力（load, cpu, mem等）。 约束限制：是否存在其他的使用限制条件。 FAQ：用户经常会遇到的问题。 ","permalink":"https://haokiu.com/blog/7c5af007072741d2a1b8a4578137e185/","summary":"DataX插件开发宝典 本文面向DataX插件开发人员，尝试尽可能全面地阐述开发一个DataX插件所经过的历程，力求消除开发者的困惑，让插件开发变得简单。\n一、开发之前 路走对了，就不怕远。✓ 路走远了，就不管对不对。✕\n当你打开这篇文档，想必已经不用在此解释什么是DataX了。那下一个问题便是：\nDataX为什么要使用插件机制？ 从设计之初，DataX就把异构数据源同步作为自身的使命，为了应对不同数据源的差异、同时提供一致的同步原语和扩展能力，DataX自然而然地采用了框架 + 插件 的模式：\n插件只需关心数据的读取或者写入本身。 而同步的共性问题，比如：类型转换、性能、统计，则交由框架来处理。 作为插件开发人员，则需要关注两个问题：\n数据源本身的读写数据正确性。 如何与框架沟通、合理正确地使用框架。 开工前需要想明白的问题 就插件本身而言，希望在您动手coding之前，能够回答我们列举的这些问题，不然路走远了发现没走对，就尴尬了。\n二、插件视角看框架 逻辑执行模型 插件开发者不用关心太多，基本只需要关注特定系统读和写，以及自己的代码在逻辑上是怎样被执行的，哪一个方法是在什么时候被调用的。在此之前，需要明确以下概念：\nJob: Job是DataX用以描述从一个源头到一个目的端的同步作业，是DataX数据同步的最小业务单元。比如：从一张mysql的表同步到odps的一个表的特定分区。 Task: Task是为最大化而把Job拆分得到的最小执行单元。比如：读一张有1024个分表的mysql分库分表的Job，拆分成1024个读Task，用若干个并发执行。 TaskGroup: 描述的是一组Task集合。在同一个TaskGroupContainer执行下的Task集合称之为TaskGroup JobContainer: Job执行器，负责Job全局拆分、调度、前置语句和后置语句等工作的工作单元。类似Yarn中的JobTracker TaskGroupContainer: TaskGroup执行器，负责执行一组Task的工作单元，类似Yarn中的TaskTracker。 简而言之， Job拆分成Task，在分别在框架提供的容器中执行，插件只需要实现Job和Task两部分逻辑。\n物理执行模型 框架为插件提供物理上的执行能力（线程）。DataX框架有三种运行模式：\nStandalone: 单进程运行，没有外部依赖。 Local: 单进程运行，统计信息、错误信息汇报到集中存储。 Distrubuted: 分布式多进程运行，依赖DataX Service服务。 当然，上述三种模式对插件的编写而言没有什么区别，你只需要避开一些小错误，插件就能够在单机/分布式之间无缝切换了。 当JobContainer和TaskGroupContainer运行在同一个进程内时，就是单机模式（Standalone和Local）；当它们分布在不同的进程中执行时，就是分布式（Distributed）模式。\n是不是很简单？\n编程接口 那么，Job和Task的逻辑应是怎么对应到具体的代码中的？\n首先，插件的入口类必须扩展Reader或Writer抽象类，并且实现分别实现Job和Task两个内部抽象类，Job和Task的实现必须是 内部类 的形式，原因见 加载原理 一节。以Reader为例：\npublic class SomeReader extends Reader { public static class Job extends Reader.Job { @Override public void init() { } @Override public void prepare() { } @Override public List\u0026lt;Configuration\u0026gt; split(int adviceNumber) { return null; } @Override public void post() { } @Override public void destroy() { } } public static class Task extends Reader.","title":"DataX插件开发宝典"},{"content":"DrdsReader 插件文档 1 快速介绍 DrdsReader插件实现了从DRDS(分布式RDS)读取数据。在底层实现上，DrdsReader通过JDBC连接远程DRDS数据库，并执行相应的sql语句将数据从DRDS库中SELECT出来。\nDRDS的插件目前DataX只适配了Mysql引擎的场景，DRDS对于DataX而言，就是一套分布式Mysql数据库，并且大部分通信协议遵守Mysql使用场景。\n2 实现原理 简而言之，DrdsReader通过JDBC连接器连接到远程的DRDS数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程DRDS数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，DrdsReader将其拼接为SQL语句发送到DRDS数据库。不同于普通的Mysql数据库，DRDS作为分布式数据库系统，无法适配所有Mysql的协议，包括复杂的Join等语句，DRDS暂时无法支持。\n3 功能说明 3.1 配置样例 配置一个从DRDS数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度，单位为byte/s，DataX运行会尽可能达到该速度但是不超过它. \u0026#34;byte\u0026#34;: 1048576 } //出错限制 \u0026#34;errorLimit\u0026#34;: { //出错的record条数上限，当大于该值即报错。 \u0026#34;record\u0026#34;: 0, //出错的record百分比上限 1.0表示100%，0.02表示2% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;drdsReader\u0026#34;, \u0026#34;parameter\u0026#34;: { // 数据库连接用户名 \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, // 数据库连接密码 \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;，\u0026#34;name\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:mysql://127.0.0.1:3306/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, //是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true, } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;drdsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;where\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10;\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:drds://localhost:3306/database\u0026#34;] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.2 参数说明 jdbcUrl\n描述：描述的是到对端数据库的JDBC连接信息，使用JSON的数组描述.注意，jdbcUrl必须包含在connection配置单元中。DRDSReader中关于jdbcUrl中JSON数组填写一个JDBC连接即可。\njdbcUrl按照Mysql官方规范，并可以填写连接附件控制信息。具体请参看mysql官方文档。\n必选：是 默认值：无 username\n描述：数据源的用户名 必选：是 默认值：无 password\n描述：数据源指定用户名的密码 必选：是 默认值：无 table\n描述：所选取需要抽取的表。注意，由于DRDS本身就是分布式数据源，因此填写多张表无意义。系统对多表不做校验。\n必选：是 默认值：无 column\n描述：所配置的表中需要同步的列名集合，使用JSON的数组描述字段信息。用户使用*代表默认使用所有列配置，例如[\u0026rsquo;*\u0026rsquo;]。\n支持列裁剪，即列可以挑选部分列进行导出。\n支持列换序，即列可以不按照表schema信息进行导出。\n支持常量配置，用户需要按照Mysql SQL语法格式: [\u0026ldquo;id\u0026rdquo;, \u0026ldquo;`table`\u0026rdquo;, \u0026ldquo;1\u0026rdquo;, \u0026ldquo;\u0026lsquo;bazhen.csy\u0026rsquo;\u0026rdquo;, \u0026ldquo;null\u0026rdquo;, \u0026ldquo;to_char(a + 1)\u0026rdquo;, \u0026ldquo;2.3\u0026rdquo; , \u0026ldquo;true\u0026rdquo;] id为普通列名，`table`为包含保留在的列名，1为整形数字常量，\u0026lsquo;bazhen.csy\u0026rsquo;为字符串常量，null为空指针，to_char(a + 1)为表达式，2.3为浮点数，true为布尔值。\ncolumn必须用户显示指定同步的列集合，不允许为空！\n必选：是 默认值：无 where\n描述：筛选条件，DrdsReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create \u0026gt; $bizdate 。。\nwhere条件可以有效地进行业务增量同步。where条件不配置或者为空，视作全表同步数据。 必选：否 默认值：无 querySql\n描述：暂时不支持配置querySql模式 3.3 类型转换 目前DrdsReader支持大部分DRDS类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出DrdsReader针对DRDS类型转换列表:\nDataX 内部类型 DRDS 数据类型 Long int, tinyint, smallint, mediumint, int, bigint Double float, double, decimal String varchar, char, tinytext, text, mediumtext, longtext Date date, datetime, timestamp, time, year Boolean bit, bool Bytes tinyblob, mediumblob, blob, longblob, varbinary 请注意:\n除上述罗列字段类型外，其他类型均不支持。 类似Mysql，tinyint(1)视作整形。 类似Mysql，bit类型读取目前是未定义状态。 4 性能报告 4.1 环境准备 4.1.1 数据特征 建表语句：\nCREATE TABLE `tc_biz_vertical_test_0000` ( `biz_order_id` bigint(20) NOT NULL COMMENT 'id', `key_value` varchar(4000) NOT NULL COMMENT 'Key-value的内容', `gmt_create` datetime NOT NULL COMMENT '创建时间', `gmt_modified` datetime NOT NULL COMMENT '修改时间', `attribute_cc` int(11) DEFAULT NULL COMMENT '防止并发修改的标志', `value_type` int(11) NOT NULL DEFAULT '0' COMMENT '类型', `buyer_id` bigint(20) DEFAULT NULL COMMENT 'buyerid', `seller_id` bigint(20) DEFAULT NULL COMMENT 'seller_id', PRIMARY KEY (`biz_order_id`,`value_type`), KEY `idx_biz_vertical_gmtmodified` (`gmt_modified`) ) ENGINE=InnoDB DEFAULT CHARSET=gbk COMMENT='tc_biz_vertical' 单行记录类似于：\nbiz_order_id: 888888888 key_value: ;orderIds:20148888888,2014888888813800; gmt_create: 2011-09-24 11:07:20 gmt_modified: 2011-10-24 17:56:34 attribute_cc: 1 value_type: 3 buyer_id: 8888888 seller_id: 1 4.1.2 机器参数 执行DataX的机器参数为:\ncpu: 24核 Intel(R) Xeon(R) CPU E5-2630 0 @ 2.30GHz mem: 48GB net: 千兆双网卡 disc: DataX 数据不落磁盘，不统计此项 DRDS数据库机器参数为:\ncpu: 32核 Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz mem: 256GB net: 千兆双网卡 disc: BTWL419303E2800RGN INTEL SSDSC2BB800G4 D2010370 4.1.3 DataX jvm 参数 -Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError 4.2 测试报告 4.2.1 单表测试报告 通道数 是否按照主键切分 DataX速度(Rec/s) DataX机器运行负载 DB网卡流出流量(MB/s) DB运行负载 说明：\n这里的单表，主键类型为 bigint(20),范围为：190247559466810-570722244711460，从主键范围划分看，数据分布均匀。 对单表如果没有安装主键切分，那么配置通道个数不会提升速度，效果与1个通道一样。 4.2.2 分表测试报告(2个分库，每个分库16张分表，共计32张分表) 通道数 DataX速度(Rec/s) DataX机器运行负载 DB网卡流出流量(MB/s) DB运行负载 5 约束限制 5.1 一致性视图问题 DRDS本身属于分布式数据库，对外无法提供一致性的多库多表视图，不同于Mysql等单库单表同步，DRDSReader无法抽取同一个时间切片的分库分表快照信息，也就是说DataX DrdsReader抽取底层不同的分表将获取不同的分表快照，无法保证强一致性。\n5.2 数据库编码问题 DRDS本身的编码设置非常灵活，包括指定编码到库、表、字段级别，甚至可以均不同编码。优先级从高到低为字段、表、库、实例。我们不推荐数据库用户设置如此混乱的编码，最好在库级别就统一到UTF-8。\nDrdsReader底层使用JDBC进行数据抽取，JDBC天然适配各类编码，并在底层进行了编码转换。因此DrdsReader不需用户指定编码，可以自动获取编码并转码。\n对于DRDS底层写入编码和其设定的编码不一致的混乱情况，DrdsReader对此无法识别，对此也无法提供解决方案，对于这类情况，导出有可能为乱码。\n5.3 增量数据同步 DrdsReader使用JDBC SELECT语句完成数据抽取工作，因此可以使用SELECT\u0026hellip;WHERE\u0026hellip;进行增量数据抽取，方式有多种：\n数据库在线应用写入数据库时，填充modify字段为更改时间戳，包括新增、更新、删除(逻辑删)。对于这类应用，DrdsReader只需要WHERE条件跟上一同步阶段时间戳即可。 对于新增流水型数据，DrdsReader可以WHERE条件后跟上一阶段最大自增ID即可。 对于业务上无字段区分新增、修改数据情况，DrdsReader也无法进行增量数据同步，只能同步全量数据。\n5.4 Sql安全性 DrdsReader提供querySql语句交给用户自己实现SELECT抽取语句，DrdsReader本身对querySql不做任何安全性校验。这块交由DataX用户方自己保证。\n6 FAQ Q: DrdsReader同步报错，报错信息为XXX\nA: 网络或者权限问题，请使用DRDS命令行测试：\nmysql -u -p -h -D -e \u0026ldquo;select * from \u0026lt;表名\u0026gt;\u0026rdquo;\n如果上述命令也报错，那可以证实是环境问题，请联系你的DBA。\nQ: 我想同步DRDS增量数据，怎么配置?\nA: DrdsReader必须业务支持增量字段DataX才能同步增量，例如在淘宝大部分业务表中，通过gmt_modified字段表征这条记录的最新修改时间，那么DataX DrdsReader只需要配置where条件为\n\u0026#34;where\u0026#34;: \u0026#34;Date(add_time) = \u0026#39;2014-06-01\u0026#39;\u0026#34; ","permalink":"https://haokiu.com/blog/20f3c6090e2448838d8be1baca3a5e1c/","summary":"DrdsReader 插件文档 1 快速介绍 DrdsReader插件实现了从DRDS(分布式RDS)读取数据。在底层实现上，DrdsReader通过JDBC连接远程DRDS数据库，并执行相应的sql语句将数据从DRDS库中SELECT出来。\nDRDS的插件目前DataX只适配了Mysql引擎的场景，DRDS对于DataX而言，就是一套分布式Mysql数据库，并且大部分通信协议遵守Mysql使用场景。\n2 实现原理 简而言之，DrdsReader通过JDBC连接器连接到远程的DRDS数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程DRDS数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，DrdsReader将其拼接为SQL语句发送到DRDS数据库。不同于普通的Mysql数据库，DRDS作为分布式数据库系统，无法适配所有Mysql的协议，包括复杂的Join等语句，DRDS暂时无法支持。\n3 功能说明 3.1 配置样例 配置一个从DRDS数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度，单位为byte/s，DataX运行会尽可能达到该速度但是不超过它. \u0026#34;byte\u0026#34;: 1048576 } //出错限制 \u0026#34;errorLimit\u0026#34;: { //出错的record条数上限，当大于该值即报错。 \u0026#34;record\u0026#34;: 0, //出错的record百分比上限 1.0表示100%，0.02表示2% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;drdsReader\u0026#34;, \u0026#34;parameter\u0026#34;: { // 数据库连接用户名 \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, // 数据库连接密码 \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;，\u0026#34;name\u0026#34; ], \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:mysql://127.0.0.1:3306/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, //是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true, } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;drdsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;where\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10;\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:drds://localhost:3306/database\u0026#34;] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.","title":"DrdsReader 插件文档"},{"content":"Hbase094XReader \u0026amp; Hbase11XReader 插件文档 1 快速介绍 HbaseReader 插件实现了从 Hbase中读取数据。在底层实现上，HbaseReader 通过 HBase 的 Java 客户端连接远程 HBase 服务，并通过 Scan 方式读取你指定 rowkey 范围内的数据，并将读取的数据使用 DataX 自定义的数据类型拼装为抽象的数据集，并传递给下游 Writer 处理。\n1.1支持的功能 1、目前HbaseReader支持的Hbase版本有：Hbase0.94.x和Hbase1.1.x。\n若您的hbase版本为Hbase0.94.x，reader端的插件请选择：hbase094xreader，即：\n\u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase094xreader\u0026#34; } 若您的hbase版本为Hbase1.1.x，reader端的插件请选择：hbase11xreader,即：\n\u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xreader\u0026#34; } 2、目前HbaseReader支持两模式读取：normal 模式、multiVersionFixedColumn模式；\nnormal 模式：把HBase中的表，当成普通二维表（横表）进行读取,读取最新版本数据。如：\nhbase(main):017:0\u0026gt; scan \u0026lsquo;users\u0026rsquo; ROW COLUMN+CELL lisi column=address:city, timestamp=1457101972764, value=beijing lisi column=address:contry, timestamp=1457102773908, value=china lisi column=address:province, timestamp=1457101972736, value=beijing lisi column=info:age, timestamp=1457101972548, value=27 lisi column=info:birthday, timestamp=1457101972604, value=1987-06-17 lisi column=info:company, timestamp=1457101972653, value=baidu xiaoming column=address:city, timestamp=1457082196082, value=hangzhou xiaoming column=address:contry, timestamp=1457082195729, value=china xiaoming column=address:province, timestamp=1457082195773, value=zhejiang xiaoming column=info:age, timestamp=1457082218735, value=29 xiaoming column=info:birthday, timestamp=1457082186830, value=1987-06-17 xiaoming column=info:company, timestamp=1457082189826, value=alibaba 2 row(s) in 0.0580 seconds\n读取后数据 | rowKey | addres:city | address:contry | address:province | info:age| info:birthday | info:company | | --------| ---------------- |----- |----- |--------| ---------------- |----- | | lisi | beijing| china| beijing |27 | 1987-06-17 | baidu| | xiaoming | hangzhou| china | zhejiang|29 | 1987-06-17 | alibaba| * multiVersionFixedColumn模式：把HBase中的表，当成竖表进行读取。读出的每条记录一定是四列形式，依次为：rowKey，family:qualifier，timestamp，value。读取时需要明确指定要读取的列，把每一个 cell 中的值，作为一条记录（record），若有多个版本就有多条记录（record）。如： ``` hbase(main):018:0\u0026gt; scan \u0026#39;users\u0026#39;,{VERSIONS=\u0026gt;5} ROW COLUMN+CELL lisi column=address:city, timestamp=1457101972764, value=beijing lisi column=address:contry, timestamp=1457102773908, value=china lisi column=address:province, timestamp=1457101972736, value=beijing lisi column=info:age, timestamp=1457101972548, value=27 lisi column=info:birthday, timestamp=1457101972604, value=1987-06-17 lisi column=info:company, timestamp=1457101972653, value=baidu xiaoming column=address:city, timestamp=1457082196082, value=hangzhou xiaoming column=address:contry, timestamp=1457082195729, value=china xiaoming column=address:province, timestamp=1457082195773, value=zhejiang xiaoming column=info:age, timestamp=1457082218735, value=29 xiaoming column=info:age, timestamp=1457082178630, value=24 xiaoming column=info:birthday, timestamp=1457082186830, value=1987-06-17 xiaoming column=info:company, timestamp=1457082189826, value=alibaba 2 row(s) in 0.0260 seconds 读取后数据(4列)\n| rowKey | column:qualifier| timestamp | value | | \u0026mdash;\u0026mdash;\u0026ndash;| \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- |\u0026mdash;\u0026ndash; |\u0026mdash;\u0026ndash; | | lisi | address:city| 1457101972764 | beijing | | lisi | address:contry| 1457102773908 | china | | lisi | address:province| 1457101972736 | beijing | | lisi | info:age| 1457101972548 | 27 | | lisi | info:birthday| 1457101972604 | 1987-06-17 | | lisi | info:company| 1457101972653 | beijing | | xiaoming | address:city| 1457082196082 | hangzhou | | xiaoming | address:contry| 1457082195729 | china | | xiaoming | address:province| 1457082195773 | zhejiang | | xiaoming | info:age| 1457082218735 | 29 | | xiaoming | info:age| 1457082178630 | 24 | | xiaoming | info:birthday| 1457082186830 | 1987-06-17 | | xiaoming | info:company| 1457082189826 | alibaba |\n1.2 限制 1、目前不支持动态列的读取。考虑网络传输流量（支持动态列，需要先将hbase所有列的数据读取出来，再按规则进行过滤），现支持的两种读取模式中需要用户明确指定要读取的列。\n2、关于同步作业的切分：目前的切分方式是根据用户hbase表数据的region分布进行切分。即：在用户填写的［startrowkey，endrowkey］范围内，一个region会切分成一个task，单个region不进行切分。\n3、multiVersionFixedColumn模式下不支持增加常量列\n2 实现原理 简而言之，HbaseReader 通过 HBase 的 Java 客户端，通过 HTable, Scan, ResultScanner 等 API，读取你指定 rowkey 范围内的数据，并将读取的数据使用 DataX 自定义的数据类型拼装为抽象的数据集，并传递给下游 Writer 处理。hbase11xreader与hbase094xreader的主要不同在于API的调用不同，Hbase1.1.x废弃了很多Hbase0.94.x的api。\n3 功能说明 3.1 配置样例 配置一个从 HBase 抽取数据到本地的作业:（normal 模式） { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;xxxf\u0026#34; }, \u0026#34;table\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;utf-8\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;normal\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;rowkey\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: age\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: birthday\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;:\u0026#34;yyyy-MM-dd\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: company\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: contry\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: province\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: city\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;range\u0026#34;: { \u0026#34;startRowkey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;endRowkey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;isBinaryRowkey\u0026#34;: true } } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase11xreader/result\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;qiran\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate\u0026#34; } } } ] } } 配置一个从 HBase 抽取数据到本地的作业:（ multiVersionFixedColumn 模式） { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;xxx\u0026#34; }, \u0026#34;table\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;utf-8\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;multiVersionFixedColumn\u0026#34;, \u0026#34;maxVersion\u0026#34;: \u0026#34;-1\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;rowkey\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: age\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: birthday\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;:\u0026#34;yyyy-MM-dd\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: company\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: contry\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: province\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: city\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;range\u0026#34;: { \u0026#34;startRowkey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;endRowkey\u0026#34;: \u0026#34;\u0026#34; } } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase11xreader/result\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;qiran\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate\u0026#34; } } } ] } } 3.2 参数说明 hbaseConfig\n描述：连接HBase集群需要的配置信息，JSON格式。必填的项是hbase.zookeeper.quorum，表示HBase的ZK链接地址。同时可以补充更多HBase client的配置，如：设置scan的cache、batch来优化与服务器的交互。\n必选：是 默认值：无 mode\n描述：读取hbase的模式，支持normal 模式、multiVersionFixedColumn模式，即：normal/multiVersionFixedColumn 必选：是 默认值：无 table\n描述：要读取的 hbase 表名（大小写敏感） 必选：是 默认值：无 encoding\n描述：编码方式，UTF-8 或是 GBK，用于对二进制存储的 HBase byte[] 转为 String 时的编码 必选：否 默认值：UTF-8 column\n描述：要读取的hbase字段，normal 模式与multiVersionFixedColumn 模式下必填项。 (1)、normal 模式下：name指定读取的hbase列，除了rowkey外，必须为 列族:列名 的格式，type指定源数据的类型，format指定日期类型的格式，value指定当前类型为常量，不从hbase读取数据，而是根据value值自动生成对应的列。配置格式如下： \u0026#34;column\u0026#34;: [ { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;rowkey\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; }, { \u0026ldquo;value\u0026rdquo;: \u0026ldquo;test\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; } ]\n``` normal 模式下，对于用户指定Column信息，type必须填写，name/value必须选择其一。 (2)、multiVersionFixedColumn 模式下：name指定读取的hbase列，除了rowkey外，必须为 列族:列名 的格式，type指定源数据的类型，format指定日期类型的格式 。multiVersionFixedColumn模式下不支持常量列。配置格式如下： ``` \u0026quot;column\u0026quot;: [ { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;rowkey\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; }, { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;info: age\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; } ] ```\n* 必选：是\u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; maxVersion\n描述：指定在多版本模式下的hbasereader读取的版本数，取值只能为－1或者大于1的数字，－1表示读取所有版本 必选：multiVersionFixedColumn 模式下必填项\n默认值：无\nrange\n描述：指定hbasereader读取的rowkey范围。\nstartRowkey：指定开始rowkey；\nendRowkey指定结束rowkey；\nisBinaryRowkey：指定配置的startRowkey和endRowkey转换为byte[]时的方式，默认值为false,若为true，则调用Bytes.toBytesBinary(rowkey)方法进行转换;若为false：则调用Bytes.toBytes(rowkey)\n配置格式如下： \u0026#34;range\u0026#34;: { \u0026#34;startRowkey\u0026#34;: \u0026#34;aaa\u0026#34;, \u0026#34;endRowkey\u0026#34;: \u0026#34;ccc\u0026#34;, \u0026#34;isBinaryRowkey\u0026#34;:false } ``` * 必选：否 \u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; scanCacheSize\n描述：Hbase client每次rpc从服务器端读取的行数 必选：否\n默认值：256\nscanBatchSize\n描述：Hbase client每次rpc从服务器端读取的列数 必选：否\n默认值：100\n3.3 类型转换 下面列出支持的读取HBase数据类型，HbaseReader 针对 HBase 类型转换列表:\nDataX 内部类型 HBase 数据类型 Long int, short ,long Double float, double String string,binarystring Date date Boolean boolean 请注意:\n除上述罗列字段类型外，其他类型均不支持。 4 性能报告 略\n5 约束限制 略\n6 FAQ ","permalink":"https://haokiu.com/blog/34ec6d7caba24a86b7a5e9a2f37d8c46/","summary":"Hbase094XReader \u0026amp; Hbase11XReader 插件文档 1 快速介绍 HbaseReader 插件实现了从 Hbase中读取数据。在底层实现上，HbaseReader 通过 HBase 的 Java 客户端连接远程 HBase 服务，并通过 Scan 方式读取你指定 rowkey 范围内的数据，并将读取的数据使用 DataX 自定义的数据类型拼装为抽象的数据集，并传递给下游 Writer 处理。\n1.1支持的功能 1、目前HbaseReader支持的Hbase版本有：Hbase0.94.x和Hbase1.1.x。\n若您的hbase版本为Hbase0.94.x，reader端的插件请选择：hbase094xreader，即：\n\u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase094xreader\u0026#34; } 若您的hbase版本为Hbase1.1.x，reader端的插件请选择：hbase11xreader,即：\n\u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xreader\u0026#34; } 2、目前HbaseReader支持两模式读取：normal 模式、multiVersionFixedColumn模式；\nnormal 模式：把HBase中的表，当成普通二维表（横表）进行读取,读取最新版本数据。如：\nhbase(main):017:0\u0026gt; scan \u0026lsquo;users\u0026rsquo; ROW COLUMN+CELL lisi column=address:city, timestamp=1457101972764, value=beijing lisi column=address:contry, timestamp=1457102773908, value=china lisi column=address:province, timestamp=1457101972736, value=beijing lisi column=info:age, timestamp=1457101972548, value=27 lisi column=info:birthday, timestamp=1457101972604, value=1987-06-17 lisi column=info:company, timestamp=1457101972653, value=baidu xiaoming column=address:city, timestamp=1457082196082, value=hangzhou xiaoming column=address:contry, timestamp=1457082195729, value=china xiaoming column=address:province, timestamp=1457082195773, value=zhejiang xiaoming column=info:age, timestamp=1457082218735, value=29 xiaoming column=info:birthday, timestamp=1457082186830, value=1987-06-17 xiaoming column=info:company, timestamp=1457082189826, value=alibaba 2 row(s) in 0.0580 seconds","title":"Hbase094XReader \u0026 Hbase11XReader 插件文档"},{"content":"Hbase094XReader \u0026amp; Hbase11XReader 插件文档 1 快速介绍 HbaseReader 插件实现了从 Hbase中读取数据。在底层实现上，HbaseReader 通过 HBase 的 Java 客户端连接远程 HBase 服务，并通过 Scan 方式读取你指定 rowkey 范围内的数据，并将读取的数据使用 DataX 自定义的数据类型拼装为抽象的数据集，并传递给下游 Writer 处理。\n1.1支持的功能 1、目前HbaseReader支持的Hbase版本有：Hbase0.94.x和Hbase1.1.x。\n若您的hbase版本为Hbase0.94.x，reader端的插件请选择：hbase094xreader，即：\n\u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase094xreader\u0026#34; } 若您的hbase版本为Hbase1.1.x，reader端的插件请选择：hbase11xreader,即：\n\u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xreader\u0026#34; } 2、目前HbaseReader支持两模式读取：normal 模式、multiVersionFixedColumn模式；\nnormal 模式：把HBase中的表，当成普通二维表（横表）进行读取,读取最新版本数据。如：\nhbase(main):017:0\u0026gt; scan \u0026lsquo;users\u0026rsquo; ROW COLUMN+CELL lisi column=address:city, timestamp=1457101972764, value=beijing lisi column=address:contry, timestamp=1457102773908, value=china lisi column=address:province, timestamp=1457101972736, value=beijing lisi column=info:age, timestamp=1457101972548, value=27 lisi column=info:birthday, timestamp=1457101972604, value=1987-06-17 lisi column=info:company, timestamp=1457101972653, value=baidu xiaoming column=address:city, timestamp=1457082196082, value=hangzhou xiaoming column=address:contry, timestamp=1457082195729, value=china xiaoming column=address:province, timestamp=1457082195773, value=zhejiang xiaoming column=info:age, timestamp=1457082218735, value=29 xiaoming column=info:birthday, timestamp=1457082186830, value=1987-06-17 xiaoming column=info:company, timestamp=1457082189826, value=alibaba 2 row(s) in 0.0580 seconds\n读取后数据 | rowKey | addres:city | address:contry | address:province | info:age| info:birthday | info:company | | --------| ---------------- |----- |----- |--------| ---------------- |----- | | lisi | beijing| china| beijing |27 | 1987-06-17 | baidu| | xiaoming | hangzhou| china | zhejiang|29 | 1987-06-17 | alibaba| * multiVersionFixedColumn模式：把HBase中的表，当成竖表进行读取。读出的每条记录一定是四列形式，依次为：rowKey，family:qualifier，timestamp，value。读取时需要明确指定要读取的列，把每一个 cell 中的值，作为一条记录（record），若有多个版本就有多条记录（record）。如： ``` hbase(main):018:0\u0026gt; scan \u0026#39;users\u0026#39;,{VERSIONS=\u0026gt;5} ROW COLUMN+CELL lisi column=address:city, timestamp=1457101972764, value=beijing lisi column=address:contry, timestamp=1457102773908, value=china lisi column=address:province, timestamp=1457101972736, value=beijing lisi column=info:age, timestamp=1457101972548, value=27 lisi column=info:birthday, timestamp=1457101972604, value=1987-06-17 lisi column=info:company, timestamp=1457101972653, value=baidu xiaoming column=address:city, timestamp=1457082196082, value=hangzhou xiaoming column=address:contry, timestamp=1457082195729, value=china xiaoming column=address:province, timestamp=1457082195773, value=zhejiang xiaoming column=info:age, timestamp=1457082218735, value=29 xiaoming column=info:age, timestamp=1457082178630, value=24 xiaoming column=info:birthday, timestamp=1457082186830, value=1987-06-17 xiaoming column=info:company, timestamp=1457082189826, value=alibaba 2 row(s) in 0.0260 seconds 读取后数据(4列)\n| rowKey | column:qualifier| timestamp | value | | \u0026mdash;\u0026mdash;\u0026ndash;| \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;- |\u0026mdash;\u0026ndash; |\u0026mdash;\u0026ndash; | | lisi | address:city| 1457101972764 | beijing | | lisi | address:contry| 1457102773908 | china | | lisi | address:province| 1457101972736 | beijing | | lisi | info:age| 1457101972548 | 27 | | lisi | info:birthday| 1457101972604 | 1987-06-17 | | lisi | info:company| 1457101972653 | beijing | | xiaoming | address:city| 1457082196082 | hangzhou | | xiaoming | address:contry| 1457082195729 | china | | xiaoming | address:province| 1457082195773 | zhejiang | | xiaoming | info:age| 1457082218735 | 29 | | xiaoming | info:age| 1457082178630 | 24 | | xiaoming | info:birthday| 1457082186830 | 1987-06-17 | | xiaoming | info:company| 1457082189826 | alibaba |\n3、HbaseReader中有一个必填配置项是：hbaseConfig，需要你联系 HBase PE，将hbase-site.xml 中与连接 HBase 相关的配置项提取出来，以 json 格式填入，同时可以补充更多HBase client的配置，如：设置scan的cache（hbase.client.scanner.caching）、batch来优化与服务器的交互。\n如：hbase-site.xml的配置内容如下\n\u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.rootdir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://ip:9000/hbase\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.cluster.distributed\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.zookeeper.quorum\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;***\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 转换后的json为：\n\u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.rootdir\u0026#34;: \u0026#34;hdfs: //ip:9000/hbase\u0026#34;, \u0026#34;hbase.cluster.distributed\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;***\u0026#34; } 1.2 限制 1、目前不支持动态列的读取。考虑网络传输流量（支持动态列，需要先将hbase所有列的数据读取出来，再按规则进行过滤），现支持的两种读取模式中需要用户明确指定要读取的列。\n2、关于同步作业的切分：目前的切分方式是根据用户hbase表数据的region分布进行切分。即：在用户填写的［startrowkey，endrowkey］范围内，一个region会切分成一个task，单个region不进行切分。\n3、multiVersionFixedColumn模式下不支持增加常量列\n2 实现原理 简而言之，HbaseReader 通过 HBase 的 Java 客户端，通过 HTable, Scan, ResultScanner 等 API，读取你指定 rowkey 范围内的数据，并将读取的数据使用 DataX 自定义的数据类型拼装为抽象的数据集，并传递给下游 Writer 处理。hbase11xreader与hbase094xreader的主要不同在于API的调用不同，Hbase1.1.x废弃了很多Hbase0.94.x的api。\n3 功能说明 3.1 配置样例 配置一个从 HBase 抽取数据到本地的作业:（normal 模式） { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.rootdir\u0026#34;: \u0026#34;hdfs: //xxx: 9000/hbase\u0026#34;, \u0026#34;hbase.cluster.distributed\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;xxx\u0026#34; }, \u0026#34;table\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;utf-8\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;normal\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;rowkey\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: age\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: birthday\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;:\u0026#34;yyyy-MM-dd\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: company\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: contry\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: province\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: city\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;range\u0026#34;: { \u0026#34;startRowkey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;endRowkey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;isBinaryRowkey\u0026#34;: true } } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase11xreader/result\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;qiran\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate\u0026#34; } } } ] } } 配置一个从 HBase 抽取数据到本地的作业:（ multiVersionFixedColumn 模式） { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.rootdir\u0026#34;: \u0026#34;hdfs: //xxx: 9000/hbase\u0026#34;, \u0026#34;hbase.cluster.distributed\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;xxx\u0026#34; }, \u0026#34;table\u0026#34;: \u0026#34;users\u0026#34;, \u0026#34;encoding\u0026#34;: \u0026#34;utf-8\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;multiVersionFixedColumn\u0026#34;, \u0026#34;maxVersion\u0026#34;: \u0026#34;-1\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;rowkey\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: age\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: birthday\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;:\u0026#34;yyyy-MM-dd\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;info: company\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: contry\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: province\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;name\u0026#34;: \u0026#34;address: city\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;range\u0026#34;: { \u0026#34;startRowkey\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;endRowkey\u0026#34;: \u0026#34;\u0026#34; } } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilewriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase11xreader/result\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;qiran\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;truncate\u0026#34; } } } ] } } 3.2 参数说明 hbaseConfig\n描述：每个HBase集群提供给DataX客户端连接的配置信息存放在hbase-site.xml，请联系你的HBase PE提供配置信息，并转换为JSON格式。同时可以补充更多HBase client的配置，如：设置scan的cache、batch来优化与服务器的交互。\n必选：是 默认值：无 mode\n描述：读取hbase的模式，支持normal 模式、multiVersionFixedColumn模式，即：normal/multiVersionFixedColumn 必选：是 默认值：无 table\n描述：要读取的 hbase 表名（大小写敏感） 必选：是 默认值：无 encoding\n描述：编码方式，UTF-8 或是 GBK，用于对二进制存储的 HBase byte[] 转为 String 时的编码 必选：否 默认值：UTF-8 column\n描述：要读取的hbase字段，normal 模式与multiVersionFixedColumn 模式下必填项。 (1)、normal 模式下：name指定读取的hbase列，除了rowkey外，必须为 列族:列名 的格式，type指定源数据的类型，format指定日期类型的格式，value指定当前类型为常量，不从hbase读取数据，而是根据value值自动生成对应的列。配置格式如下： \u0026#34;column\u0026#34;: [ { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;rowkey\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; }, { \u0026ldquo;value\u0026rdquo;: \u0026ldquo;test\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; } ]\n``` normal 模式下，对于用户指定Column信息，type必须填写，name/value必须选择其一。 (2)、multiVersionFixedColumn 模式下：name指定读取的hbase列，除了rowkey外，必须为 列族:列名 的格式，type指定源数据的类型，format指定日期类型的格式 。multiVersionFixedColumn模式下不支持常量列。配置格式如下： ``` \u0026quot;column\u0026quot;: [ { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;rowkey\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; }, { \u0026ldquo;name\u0026rdquo;: \u0026ldquo;info: age\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; } ] ```\n* 必选：是\u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; maxVersion\n描述：指定在多版本模式下的hbasereader读取的版本数，取值只能为－1或者大于1的数字，－1表示读取所有版本 必选：multiVersionFixedColumn 模式下必填项\n默认值：无\nrange\n描述：指定hbasereader读取的rowkey范围。\nstartRowkey：指定开始rowkey；\nendRowkey指定结束rowkey；\nisBinaryRowkey：指定配置的startRowkey和endRowkey转换为byte[]时的方式，默认值为false,若为true，则调用Bytes.toBytesBinary(rowkey)方法进行转换;若为false：则调用Bytes.toBytes(rowkey)\n配置格式如下： \u0026#34;range\u0026#34;: { \u0026#34;startRowkey\u0026#34;: \u0026#34;aaa\u0026#34;, \u0026#34;endRowkey\u0026#34;: \u0026#34;ccc\u0026#34;, \u0026#34;isBinaryRowkey\u0026#34;:false } ``` * 必选：否 \u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; scanCacheSize\n描述：Hbase client每次rpc从服务器端读取的行数 必选：否\n默认值：256\nscanBatchSize\n描述：Hbase client每次rpc从服务器端读取的列数 必选：否\n默认值：100\n3.3 类型转换 下面列出支持的读取HBase数据类型，HbaseReader 针对 HBase 类型转换列表:\nDataX 内部类型 HBase 数据类型 Long int, short ,long Double float, double String string,binarystring Date date Boolean boolean 请注意:\n除上述罗列字段类型外，其他类型均不支持。 4 性能报告 略\n5 约束限制 略\n6 FAQ ","permalink":"https://haokiu.com/blog/7c5fc71d1a124a5396b1a17e8293be71/","summary":"Hbase094XReader \u0026amp; Hbase11XReader 插件文档 1 快速介绍 HbaseReader 插件实现了从 Hbase中读取数据。在底层实现上，HbaseReader 通过 HBase 的 Java 客户端连接远程 HBase 服务，并通过 Scan 方式读取你指定 rowkey 范围内的数据，并将读取的数据使用 DataX 自定义的数据类型拼装为抽象的数据集，并传递给下游 Writer 处理。\n1.1支持的功能 1、目前HbaseReader支持的Hbase版本有：Hbase0.94.x和Hbase1.1.x。\n若您的hbase版本为Hbase0.94.x，reader端的插件请选择：hbase094xreader，即：\n\u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase094xreader\u0026#34; } 若您的hbase版本为Hbase1.1.x，reader端的插件请选择：hbase11xreader,即：\n\u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xreader\u0026#34; } 2、目前HbaseReader支持两模式读取：normal 模式、multiVersionFixedColumn模式；\nnormal 模式：把HBase中的表，当成普通二维表（横表）进行读取,读取最新版本数据。如：\nhbase(main):017:0\u0026gt; scan \u0026lsquo;users\u0026rsquo; ROW COLUMN+CELL lisi column=address:city, timestamp=1457101972764, value=beijing lisi column=address:contry, timestamp=1457102773908, value=china lisi column=address:province, timestamp=1457101972736, value=beijing lisi column=info:age, timestamp=1457101972548, value=27 lisi column=info:birthday, timestamp=1457101972604, value=1987-06-17 lisi column=info:company, timestamp=1457101972653, value=baidu xiaoming column=address:city, timestamp=1457082196082, value=hangzhou xiaoming column=address:contry, timestamp=1457082195729, value=china xiaoming column=address:province, timestamp=1457082195773, value=zhejiang xiaoming column=info:age, timestamp=1457082218735, value=29 xiaoming column=info:birthday, timestamp=1457082186830, value=1987-06-17 xiaoming column=info:company, timestamp=1457082189826, value=alibaba 2 row(s) in 0.0580 seconds","title":"Hbase094XReader \u0026 Hbase11XReader 插件文档"},{"content":"Hbase094XWriter \u0026amp; Hbase11XWriter 插件文档 1 快速介绍 HbaseWriter 插件实现了从向Hbase中写取数据。在底层实现上，HbaseWriter 通过 HBase 的 Java 客户端连接远程 HBase 服务，并通过 put 方式写入Hbase。\n1.1支持功能 1、目前HbaseWriter支持的Hbase版本有：Hbase0.94.x和Hbase1.1.x。\n若您的hbase版本为Hbase0.94.x，writer端的插件请选择：hbase094xwriter，即：\n\u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase094xwriter\u0026#34; } 若您的hbase版本为Hbase1.1.x，writer端的插件请选择：hbase11xwriter,即：\n\u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xwriter\u0026#34; } 2、目前HbaseWriter支持源端多个字段拼接作为hbase 表的 rowkey，具体配置参考：rowkeyColumn配置；\n3、写入hbase的时间戳（版本）支持：用当前时间作为版本，指定源端列作为版本，指定一个时间 三种方式作为版本；\n4、HbaseWriter中有一个必填配置项是：hbaseConfig，需要你联系 HBase PE，将hbase-site.xml 中与连接 HBase 相关的配置项提取出来，以 json 格式填入，同时可以补充更多HBase client的配置来优化与服务器的交互。\n如：hbase-site.xml的配置内容如下\n\u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.rootdir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://ip:9000/hbase\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.cluster.distributed\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.zookeeper.quorum\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;***\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 转换后的json为：\n\u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.rootdir\u0026#34;: \u0026#34;hdfs: //ip: 9000/hbase\u0026#34;, \u0026#34;hbase.cluster.distributed\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;***\u0026#34; } 1.2 限制 1、目前只支持源端为横表写入，不支持竖表（源端读出的为四元组: rowKey，family:qualifier，timestamp，value）模式的数据写入；本期目标主要是替换DataX2中的habsewriter，下次迭代考虑支持。\n2、目前不支持写入hbase前清空表数据，若需要清空数据请联系HBase PE\n2 实现原理 简而言之，HbaseWriter 通过 HBase 的 Java 客户端，通过 HTable, Put等 API，将从上游Reader读取的数据写入HBase你hbase11xwriter与hbase094xwriter的主要不同在于API的调用不同，Hbase1.1.x废弃了很多Hbase0.94.x的api。\n3 功能说明 3.1 配置样例 配置一个从本地写入hbase1.1.x的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase11xwriter/txt/normal.txt\u0026#34;, \u0026#34;charset\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;String\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 6, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.rootdir\u0026#34;: \u0026#34;hdfs: //ip: 9000/hbase\u0026#34;, \u0026#34;hbase.cluster.distributed\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;***\u0026#34; }, \u0026#34;table\u0026#34;: \u0026#34;writer\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;normal\u0026#34;, \u0026#34;rowkeyColumn\u0026#34;: [ { \u0026#34;index\u0026#34;:0, \u0026#34;type\u0026#34;:\u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:-1, \u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;_\u0026#34; } ], \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;:1, \u0026#34;name\u0026#34;: \u0026#34;cf1:q1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:2, \u0026#34;name\u0026#34;: \u0026#34;cf1:q2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:3, \u0026#34;name\u0026#34;: \u0026#34;cf1:q3\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:4, \u0026#34;name\u0026#34;: \u0026#34;cf2:q1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:5, \u0026#34;name\u0026#34;: \u0026#34;cf2:q2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:6, \u0026#34;name\u0026#34;: \u0026#34;cf2:q3\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;versionColumn\u0026#34;:{ \u0026#34;index\u0026#34;: -1, \u0026#34;value\u0026#34;:\u0026#34;123456789\u0026#34; }, \u0026#34;encoding\u0026#34;: \u0026#34;utf-8\u0026#34; } } } ] } } 3.2 参数说明 hbaseConfig\n描述：每个HBase集群提供给DataX客户端连接的配置信息存放在hbase-site.xml，请联系你的HBase PE提供配置信息，并转换为JSON格式。同时可以补充更多HBase client的配置，如：设置scan的cache、batch来优化与服务器的交互。\n必选：是 默认值：无 mode\n描述：写hbase的模式，目前只支持normal 模式，后续考虑动态列模式\n必选：是 默认值：无 table\n描述：要写的 hbase 表名（大小写敏感） 必选：是 默认值：无 encoding\n描述：编码方式，UTF-8 或是 GBK，用于 String 转 HBase byte[]时的编码 必选：否 默认值：UTF-8 column\n描述：要写入的hbase字段。index：指定该列对应reader端column的索引，从0开始；name：指定hbase表中的列，必须为 列族:列名 的格式；type：指定写入数据类型，用于转换HBase byte[]。配置格式如下： \u0026ldquo;column\u0026rdquo;: [ { \u0026ldquo;index\u0026rdquo;:1, \u0026ldquo;name\u0026rdquo;: \u0026ldquo;cf1:q1\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; }, { \u0026ldquo;index\u0026rdquo;:2, \u0026ldquo;name\u0026rdquo;: \u0026ldquo;cf1:q2\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; } ］\n``` * 必选：是\u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; rowkeyColumn\n描述：要写入的hbase的rowkey列。index：指定该列对应reader端column的索引，从0开始，若为常量index为－1；type：指定写入数据类型，用于转换HBase byte[]；value：配置常量，常作为多个字段的拼接符。hbasewriter会将rowkeyColumn中所有列按照配置顺序进行拼接作为写入hbase的rowkey，不能全为常量。配置格式如下： \u0026ldquo;rowkeyColumn\u0026rdquo;: [ { \u0026ldquo;index\u0026rdquo;:0, \u0026ldquo;type\u0026rdquo;:\u0026ldquo;string\u0026rdquo; }, { \u0026ldquo;index\u0026rdquo;:-1, \u0026ldquo;type\u0026rdquo;:\u0026ldquo;string\u0026rdquo;, \u0026ldquo;value\u0026rdquo;:\u0026quot;_\u0026quot; } ]\n``` * 必选：是\u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; versionColumn\n描述：指定写入hbase的时间戳。支持：当前时间、指定时间列，指定时间，三者选一。若不配置表示用当前时间。index：指定对应reader端column的索引，从0开始，需保证能转换为long,若是Date类型，会尝试用yyyy-MM-dd HH:mm:ss和yyyy-MM-dd HH:mm:ss SSS去解析；若为指定时间index为－1；value：指定时间的值,long值。配置格式如下： \u0026ldquo;versionColumn\u0026rdquo;:{ \u0026ldquo;index\u0026rdquo;:1 }\n``` 或者 ``` \u0026ldquo;versionColumn\u0026rdquo;:{ \u0026ldquo;index\u0026rdquo;:－1, \u0026ldquo;value\u0026rdquo;:123456789 }\n``` * 必选：否\u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; nullMode\n描述：读取的null值时，如何处理。支持两种方式：（1）skip：表示不向hbase写这列；（2）empty：写入HConstants.EMPTY_BYTE_ARRAY，即new byte [0] 必选：否\n默认值：skip\nwalFlag\n描述：在HBae client向集群中的RegionServer提交数据时（Put/Delete操作），首先会先写WAL（Write Ahead Log）日志（即HLog，一个RegionServer上的所有Region共享一个HLog），只有当WAL日志写成功后，再接着写MemStore，然后客户端被通知提交数据成功；如果写WAL日志失败，客户端则被通知提交失败。关闭（false）放弃写WAL日志，从而提高数据写入的性能。\n必选：否\n默认值：false\nwriteBufferSize\n描述：设置HBae client的写buffer大小，单位字节。配合autoflush使用。autoflush，开启（true）表示Hbase client在写的时候有一条put就执行一次更新；关闭（false），表示Hbase client在写的时候只有当put填满客户端写缓存时，才实际向HBase服务端发起写请求\n必选：否\n默认值：8M\n3.3 HBase支持的列类型 BOOLEAN SHORT INT LONG FLOAT DOUBLE STRING 请注意:\n除上述罗列字段类型外，其他类型均不支持。 4 性能报告 略\n5 约束限制 略\n6 FAQ ","permalink":"https://haokiu.com/blog/0172fbcbd4674f98a8782403fc6a7ca5/","summary":"Hbase094XWriter \u0026amp; Hbase11XWriter 插件文档 1 快速介绍 HbaseWriter 插件实现了从向Hbase中写取数据。在底层实现上，HbaseWriter 通过 HBase 的 Java 客户端连接远程 HBase 服务，并通过 put 方式写入Hbase。\n1.1支持功能 1、目前HbaseWriter支持的Hbase版本有：Hbase0.94.x和Hbase1.1.x。\n若您的hbase版本为Hbase0.94.x，writer端的插件请选择：hbase094xwriter，即：\n\u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase094xwriter\u0026#34; } 若您的hbase版本为Hbase1.1.x，writer端的插件请选择：hbase11xwriter,即：\n\u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xwriter\u0026#34; } 2、目前HbaseWriter支持源端多个字段拼接作为hbase 表的 rowkey，具体配置参考：rowkeyColumn配置；\n3、写入hbase的时间戳（版本）支持：用当前时间作为版本，指定源端列作为版本，指定一个时间 三种方式作为版本；\n4、HbaseWriter中有一个必填配置项是：hbaseConfig，需要你联系 HBase PE，将hbase-site.xml 中与连接 HBase 相关的配置项提取出来，以 json 格式填入，同时可以补充更多HBase client的配置来优化与服务器的交互。\n如：hbase-site.xml的配置内容如下\n\u0026lt;configuration\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.rootdir\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;hdfs://ip:9000/hbase\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.cluster.distributed\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;true\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;property\u0026gt; \u0026lt;name\u0026gt;hbase.zookeeper.quorum\u0026lt;/name\u0026gt; \u0026lt;value\u0026gt;***\u0026lt;/value\u0026gt; \u0026lt;/property\u0026gt; \u0026lt;/configuration\u0026gt; 转换后的json为：\n\u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.rootdir\u0026#34;: \u0026#34;hdfs: //ip: 9000/hbase\u0026#34;, \u0026#34;hbase.cluster.distributed\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;***\u0026#34; } 1.2 限制 1、目前只支持源端为横表写入，不支持竖表（源端读出的为四元组: rowKey，family:qualifier，timestamp，value）模式的数据写入；本期目标主要是替换DataX2中的habsewriter，下次迭代考虑支持。\n2、目前不支持写入hbase前清空表数据，若需要清空数据请联系HBase PE\n2 实现原理 简而言之，HbaseWriter 通过 HBase 的 Java 客户端，通过 HTable, Put等 API，将从上游Reader读取的数据写入HBase你hbase11xwriter与hbase094xwriter的主要不同在于API的调用不同，Hbase1.1.x废弃了很多Hbase0.94.x的api。\n3 功能说明 3.1 配置样例 配置一个从本地写入hbase1.1.x的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase11xwriter/txt/normal.","title":"Hbase094XWriter \u0026 Hbase11XWriter 插件文档"},{"content":"Hbase094XWriter \u0026amp; Hbase11XWriter 插件文档 1 快速介绍 HbaseWriter 插件实现了从向Hbase中写取数据。在底层实现上，HbaseWriter 通过 HBase 的 Java 客户端连接远程 HBase 服务，并通过 put 方式写入Hbase。\n1.1支持功能 1、目前HbaseWriter支持的Hbase版本有：Hbase0.94.x和Hbase1.1.x。\n若您的hbase版本为Hbase0.94.x，writer端的插件请选择：hbase094xwriter，即：\n\u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase094xwriter\u0026#34; } 若您的hbase版本为Hbase1.1.x，writer端的插件请选择：hbase11xwriter,即：\n\u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xwriter\u0026#34; } 2、目前HbaseWriter支持源端多个字段拼接作为hbase 表的 rowkey，具体配置参考：rowkeyColumn配置；\n3、写入hbase的时间戳（版本）支持：用当前时间作为版本，指定源端列作为版本，指定一个时间 三种方式作为版本；\n1.2 限制 1、目前只支持源端为横表写入，不支持竖表（源端读出的为四元组: rowKey，family:qualifier，timestamp，value）模式的数据写入；本期目标主要是替换DataX2中的habsewriter，下次迭代考虑支持。\n2、目前不支持写入hbase前清空表数据，若需要清空数据请联系HBase PE\n2 实现原理 简而言之，HbaseWriter 通过 HBase 的 Java 客户端，通过 HTable, Put等 API，将从上游Reader读取的数据写入HBase你hbase11xwriter与hbase094xwriter的主要不同在于API的调用不同，Hbase1.1.x废弃了很多Hbase0.94.x的api。\n3 功能说明 3.1 配置样例 配置一个从本地写入hbase1.1.x的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase11xwriter/txt/normal.txt\u0026#34;, \u0026#34;charset\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;String\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 6, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;***\u0026#34; }, \u0026#34;table\u0026#34;: \u0026#34;writer\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;normal\u0026#34;, \u0026#34;rowkeyColumn\u0026#34;: [ { \u0026#34;index\u0026#34;:0, \u0026#34;type\u0026#34;:\u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:-1, \u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;_\u0026#34; } ], \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;:1, \u0026#34;name\u0026#34;: \u0026#34;cf1:q1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:2, \u0026#34;name\u0026#34;: \u0026#34;cf1:q2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:3, \u0026#34;name\u0026#34;: \u0026#34;cf1:q3\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:4, \u0026#34;name\u0026#34;: \u0026#34;cf2:q1\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:5, \u0026#34;name\u0026#34;: \u0026#34;cf2:q2\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;:6, \u0026#34;name\u0026#34;: \u0026#34;cf2:q3\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;versionColumn\u0026#34;:{ \u0026#34;index\u0026#34;: -1, \u0026#34;value\u0026#34;:\u0026#34;123456789\u0026#34; }, \u0026#34;encoding\u0026#34;: \u0026#34;utf-8\u0026#34; } } } ] } } 3.2 参数说明 hbaseConfig\n描述：连接HBase集群需要的配置信息，JSON格式。必填的项是hbase.zookeeper.quorum，表示HBase的ZK链接地址。同时可以补充更多HBase client的配置，如：设置scan的cache、batch来优化与服务器的交互。\n必选：是 默认值：无 mode\n描述：写hbase的模式，目前只支持normal 模式，后续考虑动态列模式\n必选：是 默认值：无 table\n描述：要写的 hbase 表名（大小写敏感） 必选：是 默认值：无 encoding\n描述：编码方式，UTF-8 或是 GBK，用于 String 转 HBase byte[]时的编码 必选：否 默认值：UTF-8 column\n描述：要写入的hbase字段。index：指定该列对应reader端column的索引，从0开始；name：指定hbase表中的列，必须为 列族:列名 的格式；type：指定写入数据类型，用于转换HBase byte[]。配置格式如下： \u0026ldquo;column\u0026rdquo;: [ { \u0026ldquo;index\u0026rdquo;:1, \u0026ldquo;name\u0026rdquo;: \u0026ldquo;cf1:q1\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; }, { \u0026ldquo;index\u0026rdquo;:2, \u0026ldquo;name\u0026rdquo;: \u0026ldquo;cf1:q2\u0026rdquo;, \u0026ldquo;type\u0026rdquo;: \u0026ldquo;string\u0026rdquo; } ］\n``` * 必选：是\u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; rowkeyColumn\n描述：要写入的hbase的rowkey列。index：指定该列对应reader端column的索引，从0开始，若为常量index为－1；type：指定写入数据类型，用于转换HBase byte[]；value：配置常量，常作为多个字段的拼接符。hbasewriter会将rowkeyColumn中所有列按照配置顺序进行拼接作为写入hbase的rowkey，不能全为常量。配置格式如下： \u0026ldquo;rowkeyColumn\u0026rdquo;: [ { \u0026ldquo;index\u0026rdquo;:0, \u0026ldquo;type\u0026rdquo;:\u0026ldquo;string\u0026rdquo; }, { \u0026ldquo;index\u0026rdquo;:-1, \u0026ldquo;type\u0026rdquo;:\u0026ldquo;string\u0026rdquo;, \u0026ldquo;value\u0026rdquo;:\u0026quot;_\u0026quot; } ]\n``` * 必选：是\u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; versionColumn\n描述：指定写入hbase的时间戳。支持：当前时间、指定时间列，指定时间，三者选一。若不配置表示用当前时间。index：指定对应reader端column的索引，从0开始，需保证能转换为long,若是Date类型，会尝试用yyyy-MM-dd HH:mm:ss和yyyy-MM-dd HH:mm:ss SSS去解析；若为指定时间index为－1；value：指定时间的值,long值。配置格式如下： \u0026ldquo;versionColumn\u0026rdquo;:{ \u0026ldquo;index\u0026rdquo;:1 }\n``` 或者 ``` \u0026ldquo;versionColumn\u0026rdquo;:{ \u0026ldquo;index\u0026rdquo;:－1, \u0026ldquo;value\u0026rdquo;:123456789 }\n``` * 必选：否\u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; nullMode\n描述：读取的null值时，如何处理。支持两种方式：（1）skip：表示不向hbase写这列；（2）empty：写入HConstants.EMPTY_BYTE_ARRAY，即new byte [0] 必选：否\n默认值：skip\nwalFlag\n描述：在HBae client向集群中的RegionServer提交数据时（Put/Delete操作），首先会先写WAL（Write Ahead Log）日志（即HLog，一个RegionServer上的所有Region共享一个HLog），只有当WAL日志写成功后，再接着写MemStore，然后客户端被通知提交数据成功；如果写WAL日志失败，客户端则被通知提交失败。关闭（false）放弃写WAL日志，从而提高数据写入的性能。\n必选：否\n默认值：false\nwriteBufferSize\n描述：设置HBae client的写buffer大小，单位字节。配合autoflush使用。autoflush，开启（true）表示Hbase client在写的时候有一条put就执行一次更新；关闭（false），表示Hbase client在写的时候只有当put填满客户端写缓存时，才实际向HBase服务端发起写请求\n必选：否\n默认值：8M\n3.3 HBase支持的列类型 BOOLEAN SHORT INT LONG FLOAT DOUBLE STRING 请注意:\n除上述罗列字段类型外，其他类型均不支持。 4 性能报告 略\n5 约束限制 略\n6 FAQ ","permalink":"https://haokiu.com/blog/745df21fdbd349ab9a9fc5c94551b336/","summary":"Hbase094XWriter \u0026amp; Hbase11XWriter 插件文档 1 快速介绍 HbaseWriter 插件实现了从向Hbase中写取数据。在底层实现上，HbaseWriter 通过 HBase 的 Java 客户端连接远程 HBase 服务，并通过 put 方式写入Hbase。\n1.1支持功能 1、目前HbaseWriter支持的Hbase版本有：Hbase0.94.x和Hbase1.1.x。\n若您的hbase版本为Hbase0.94.x，writer端的插件请选择：hbase094xwriter，即：\n\u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase094xwriter\u0026#34; } 若您的hbase版本为Hbase1.1.x，writer端的插件请选择：hbase11xwriter,即：\n\u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xwriter\u0026#34; } 2、目前HbaseWriter支持源端多个字段拼接作为hbase 表的 rowkey，具体配置参考：rowkeyColumn配置；\n3、写入hbase的时间戳（版本）支持：用当前时间作为版本，指定源端列作为版本，指定一个时间 三种方式作为版本；\n1.2 限制 1、目前只支持源端为横表写入，不支持竖表（源端读出的为四元组: rowKey，family:qualifier，timestamp，value）模式的数据写入；本期目标主要是替换DataX2中的habsewriter，下次迭代考虑支持。\n2、目前不支持写入hbase前清空表数据，若需要清空数据请联系HBase PE\n2 实现原理 简而言之，HbaseWriter 通过 HBase 的 Java 客户端，通过 HTable, Put等 API，将从上游Reader读取的数据写入HBase你hbase11xwriter与hbase094xwriter的主要不同在于API的调用不同，Hbase1.1.x废弃了很多Hbase0.94.x的api。\n3 功能说明 3.1 配置样例 配置一个从本地写入hbase1.1.x的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase11xwriter/txt/normal.txt\u0026#34;, \u0026#34;charset\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;String\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 4, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 5, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 6, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.","title":"Hbase094XWriter \u0026 Hbase11XWriter 插件文档"},{"content":"hbase11xsqlreader 插件文档 1 快速介绍 hbase11xsqlreader插件实现了从Phoenix(HBase SQL)读取数据。在底层实现上，hbase11xsqlreader通过Phoenix客户端去连接远程的HBase集群，并执行相应的sql语句将数据从Phoenix库中SELECT出来。\n2 实现原理 简而言之，hbase11xsqlreader通过Phoenix客户端去连接远程的HBase集群，并根据用户配置的信息生成查询SELECT 语句，然后发送到HBase集群，并将返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\nhbase11xsqlreader 插件文档 1 快速介绍 hbase11xsqlreader插件实现了从Phoenix(HBase SQL)读取数据。在底层实现上，hbase11xsqlreader通过Phoenix客户端去连接远程的HBase集群，并执行相应的sql语句将数据从Phoenix库中SELECT出来。\n2 实现原理 简而言之，hbase11xsqlreader通过Phoenix客户端去连接远程的HBase集群，并根据用户配置的信息生成查询SELECT 语句，然后发送到HBase集群，并将返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n3 功能说明 3.1 配置样例 配置一个从Phoenix同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度，单位为byte/s，DataX运行会尽可能达到该速度但是不超过它. \u0026#34;byte\u0026#34;:10485760 }, //出错限制 \u0026#34;errorLimit\u0026#34;: { //出错的record条数上限，当大于该值即报错。 \u0026#34;record\u0026#34;: 0, //出错的record百分比上限 1.0表示100%，0.02表示2% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { //指定插件为hbase11xsqlreader \u0026#34;name\u0026#34;: \u0026#34;hbase11xsqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { //填写连接Phoenix的hbase集群zk地址 \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;hb-proxy-xxx-002.hbase.rds.aliyuncs.com,hb-proxy-xxx-001.hbase.rds.aliyuncs.com,hb-proxy-xxx-003.hbase.rds.aliyuncs.com\u0026#34; }, //填写要读取的phoenix的表名 \u0026#34;table\u0026#34;: \u0026#34;US_POPULATION\u0026#34;, //填写要读取的列名，不填读取所有列 \u0026#34;column\u0026#34;: [ ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, //是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.2 参数说明 hbaseConfig\n描述：hbase11xsqlreader需要通过Phoenix客户端去连接hbase集群，因此这里需要填写对应hbase集群的zkurl地址，注意不要添加2181。\n必选：是 默认值：无 table\n描述：编写Phoenix中的表名,如果有namespace，该值设置为\u0026rsquo;namespace.tablename'\n必选：是 默认值：无 column\n描述：填写需要从phoenix表中读取的列名集合，使用JSON的数组描述字段信息，空值表示读取所有列。\n必选：是 默认值：无 3.3 类型转换 目前hbase11xsqlreader支持大部分Phoenix类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出MysqlReader针对Mysql类型转换列表:\nDataX 内部类型 Phoenix 数据类型 String CHAR, VARCHAR Bytes BINARY, VARBINARY Bool BOOLEAN Long INTEGER, TINYINT, SMALLINT, BIGINT Double FLOAT, DECIMAL, DOUBLE, Date DATE, TIME, TIMESTAMP 4 性能报告 略\n5 约束限制 略\n6 FAQ 3 功能说明 3.1 配置样例 配置一个从Phoenix同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度，单位为byte/s，DataX运行会尽可能达到该速度但是不超过它. \u0026#34;byte\u0026#34;:10485760 }, //出错限制 \u0026#34;errorLimit\u0026#34;: { //出错的record条数上限，当大于该值即报错。 \u0026#34;record\u0026#34;: 0, //出错的record百分比上限 1.0表示100%，0.02表示2% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { //指定插件为hbase11xsqlreader \u0026#34;name\u0026#34;: \u0026#34;hbase11xsqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { //填写连接Phoenix的hbase集群zk地址 \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;hb-proxy-xxx-002.hbase.rds.aliyuncs.com,hb-proxy-xxx-001.hbase.rds.aliyuncs.com,hb-proxy-xxx-003.hbase.rds.aliyuncs.com\u0026#34; }, //填写要读取的phoenix的表名 \u0026#34;table\u0026#34;: \u0026#34;US_POPULATION\u0026#34;, //填写要读取的列名，不填读取所有列 \u0026#34;column\u0026#34;: [ ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, //是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.2 参数说明 hbaseConfig\n描述：hbase11xsqlreader需要通过Phoenix客户端去连接hbase集群，因此这里需要填写对应hbase集群的zkurl地址，注意不要添加2181。\n必选：是 默认值：无 table\n描述：编写Phoenix中的表名,如果有namespace，该值设置为\u0026rsquo;namespace.tablename'\n必选：是 默认值：无 column\n描述：填写需要从phoenix表中读取的列名集合，使用JSON的数组描述字段信息，空值表示读取所有列。\n必选：是 默认值：无 3.3 类型转换 目前hbase11xsqlreader支持大部分Phoenix类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出MysqlReader针对Mysql类型转换列表:\nDataX 内部类型 Phoenix 数据类型 String CHAR, VARCHAR Bytes BINARY, VARBINARY Bool BOOLEAN Long INTEGER, TINYINT, SMALLINT, BIGINT Double FLOAT, DECIMAL, DOUBLE, Date DATE, TIME, TIMESTAMP 4 性能报告 略\n5 约束限制 略\n6 FAQ ","permalink":"https://haokiu.com/blog/283a89fffad54e6f909c2936a1ff08ad/","summary":"hbase11xsqlreader 插件文档 1 快速介绍 hbase11xsqlreader插件实现了从Phoenix(HBase SQL)读取数据。在底层实现上，hbase11xsqlreader通过Phoenix客户端去连接远程的HBase集群，并执行相应的sql语句将数据从Phoenix库中SELECT出来。\n2 实现原理 简而言之，hbase11xsqlreader通过Phoenix客户端去连接远程的HBase集群，并根据用户配置的信息生成查询SELECT 语句，然后发送到HBase集群，并将返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\nhbase11xsqlreader 插件文档 1 快速介绍 hbase11xsqlreader插件实现了从Phoenix(HBase SQL)读取数据。在底层实现上，hbase11xsqlreader通过Phoenix客户端去连接远程的HBase集群，并执行相应的sql语句将数据从Phoenix库中SELECT出来。\n2 实现原理 简而言之，hbase11xsqlreader通过Phoenix客户端去连接远程的HBase集群，并根据用户配置的信息生成查询SELECT 语句，然后发送到HBase集群，并将返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n3 功能说明 3.1 配置样例 配置一个从Phoenix同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度，单位为byte/s，DataX运行会尽可能达到该速度但是不超过它. \u0026#34;byte\u0026#34;:10485760 }, //出错限制 \u0026#34;errorLimit\u0026#34;: { //出错的record条数上限，当大于该值即报错。 \u0026#34;record\u0026#34;: 0, //出错的record百分比上限 1.0表示100%，0.02表示2% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { //指定插件为hbase11xsqlreader \u0026#34;name\u0026#34;: \u0026#34;hbase11xsqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { //填写连接Phoenix的hbase集群zk地址 \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;hb-proxy-xxx-002.hbase.rds.aliyuncs.com,hb-proxy-xxx-001.hbase.rds.aliyuncs.com,hb-proxy-xxx-003.hbase.rds.aliyuncs.com\u0026#34; }, //填写要读取的phoenix的表名 \u0026#34;table\u0026#34;: \u0026#34;US_POPULATION\u0026#34;, //填写要读取的列名，不填读取所有列 \u0026#34;column\u0026#34;: [ ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, //是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.2 参数说明 hbaseConfig\n描述：hbase11xsqlreader需要通过Phoenix客户端去连接hbase集群，因此这里需要填写对应hbase集群的zkurl地址，注意不要添加2181。\n必选：是 默认值：无 table\n描述：编写Phoenix中的表名,如果有namespace，该值设置为\u0026rsquo;namespace.tablename'\n必选：是 默认值：无 column","title":"hbase11xsqlreader  插件文档"},{"content":"HBase11xsqlwriter插件文档 1. 快速介绍 HBase11xsqlwriter实现了向hbase中的SQL表(phoenix)批量导入数据的功能。Phoenix因为对rowkey做了数据编码，所以，直接使用HBaseAPI进行写入会面临手工数据转换的问题，麻烦且易错。本插件提供了单间的SQL表的数据导入方式。\n在底层实现上，通过Phoenix的JDBC驱动，执行UPSERT语句向hbase写入数据。\n1.1 支持的功能 支持带索引的表的数据导入，可以同步更新所有的索引表 1.2 限制 仅支持1.x系列的hbase 仅支持通过phoenix创建的表，不支持原生HBase表 不支持带时间戳的数据导入 2. 实现原理 通过Phoenix的JDBC驱动，执行UPSERT语句向表中批量写入数据。因为使用上层接口，所以，可以同步更新索引表。\n3. 配置说明 3.1 配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;entry\u0026#34;: { \u0026#34;jvm\u0026#34;: \u0026#34;-Xms2048m -Xmx2048m\u0026#34; }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase11xsqlwriter/txt/normal.txt\u0026#34;, \u0026#34;charset\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;String\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xsqlwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;batchSize\u0026#34;: \u0026#34;256\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;UID\u0026#34;, \u0026#34;TS\u0026#34;, \u0026#34;EVENTID\u0026#34;, \u0026#34;CONTENT\u0026#34; ], \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;目标hbase集群的ZK服务器地址，向PE咨询\u0026#34;, \u0026#34;zookeeper.znode.parent\u0026#34;: \u0026#34;目标hbase集群的znode，向PE咨询\u0026#34; }, \u0026#34;nullMode\u0026#34;: \u0026#34;skip\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;目标hbase表名，大小写有关\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } } } } 3.2 参数说明 name\n描述：插件名字，必须是hbase11xsqlwriter 必选：是 默认值：无 table\n描述：要导入的表名，大小写敏感，通常phoenix表都是大写表名 必选：是 默认值：无 column\n描述：列名，大小写敏感，通常phoenix的列名都是大写。 需要注意列的顺序，必须与reader输出的列的顺序一一对应。 不需要填写数据类型，会自动从phoenix获取列的元数据 必选：是 默认值：无 hbaseConfig\n描述：hbase集群地址，zk为必填项，格式：ip1,ip2,ip3，注意，多个IP之间使用英文的逗号分隔。znode是可选的，默认值是/hbase 必选：是 默认值：无 batchSize\n描述：批量写入的最大行数 必选：否 默认值：256 nullMode\n描述：读取到的列值为null时，如何处理。目前有两种方式： skip：跳过这一列，即不插入这一列(如果该行的这一列之前已经存在，则会被删除) empty：插入空值，值类型的空值是0，varchar的空值是空字符串 必选：否 默认值：skip 4. 性能报告 无\n5. 约束限制 writer中的列的定义顺序必须与reader的列顺序匹配。reader中的列顺序定义了输出的每一行中，列的组织顺序。而writer的列顺序，定义的是在收到的数据中，writer期待的列的顺序。例如：\nreader的列顺序是： c1, c2, c3, c4\nwriter的列顺序是： x1, x2, x3, x4\n则reader输出的列c1就会赋值给writer的列x1。如果writer的列顺序是x1, x2, x4, x3，则c3会赋值给x4，c4会赋值给x3.\n6. FAQ 并发开多少合适？速度慢时增加并发有用吗？ 数据导入进程默认JVM的堆大小是2GB，并发(channel数)是通过多线程实现的，开过多的线程有时并不能提高导入速度，反而可能因为过于频繁的GC导致性能下降。一般建议并发数(channel)为5-10.\nbatchSize设置多少比较合适？ 默认是256，但应根据每行的大小来计算最合适的batchSize。通常一次操作的数据量在2MB-4MB左右，用这个值除以行大小，即可得到batchSize。\n","permalink":"https://haokiu.com/blog/1c329829c22c499d8e684735252966c1/","summary":"HBase11xsqlwriter插件文档 1. 快速介绍 HBase11xsqlwriter实现了向hbase中的SQL表(phoenix)批量导入数据的功能。Phoenix因为对rowkey做了数据编码，所以，直接使用HBaseAPI进行写入会面临手工数据转换的问题，麻烦且易错。本插件提供了单间的SQL表的数据导入方式。\n在底层实现上，通过Phoenix的JDBC驱动，执行UPSERT语句向hbase写入数据。\n1.1 支持的功能 支持带索引的表的数据导入，可以同步更新所有的索引表 1.2 限制 仅支持1.x系列的hbase 仅支持通过phoenix创建的表，不支持原生HBase表 不支持带时间戳的数据导入 2. 实现原理 通过Phoenix的JDBC驱动，执行UPSERT语句向表中批量写入数据。因为使用上层接口，所以，可以同步更新索引表。\n3. 配置说明 3.1 配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;entry\u0026#34;: { \u0026#34;jvm\u0026#34;: \u0026#34;-Xms2048m -Xmx2048m\u0026#34; }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase11xsqlwriter/txt/normal.txt\u0026#34;, \u0026#34;charset\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;String\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase11xsqlwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;batchSize\u0026#34;: \u0026#34;256\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;UID\u0026#34;, \u0026#34;TS\u0026#34;, \u0026#34;EVENTID\u0026#34;, \u0026#34;CONTENT\u0026#34; ], \u0026#34;hbaseConfig\u0026#34;: { \u0026#34;hbase.zookeeper.quorum\u0026#34;: \u0026#34;目标hbase集群的ZK服务器地址，向PE咨询\u0026#34;, \u0026#34;zookeeper.znode.parent\u0026#34;: \u0026#34;目标hbase集群的znode，向PE咨询\u0026#34; }, \u0026#34;nullMode\u0026#34;: \u0026#34;skip\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;目标hbase表名，大小写有关\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } } } } 3.","title":"HBase11xsqlwriter插件文档"},{"content":"hbase20xsqlreader 插件文档 1 快速介绍 hbase20xsqlreader插件实现了从Phoenix(HBase SQL)读取数据，对应版本为HBase2.X和Phoenix5.X。\n2 实现原理 简而言之，hbase20xsqlreader通过Phoenix轻客户端去连接Phoenix QueryServer，并根据用户配置信息生成查询SELECT 语句，然后发送到QueryServer读取HBase数据，并将返回结果使用DataX自定义的数据类型拼装为抽象的数据集，最终传递给下游Writer处理。\n3 功能说明 3.1 配置样例 配置一个从Phoenix同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase20xsqlreader\u0026#34;, //指定插件为hbase20xsqlreader \u0026#34;parameter\u0026#34;: { \u0026#34;queryServerAddress\u0026#34;: \u0026#34;http://127.0.0.1:8765\u0026#34;, //填写连接Phoenix QueryServer地址 \u0026#34;serialization\u0026#34;: \u0026#34;PROTOBUF\u0026#34;, //QueryServer序列化格式 \u0026#34;table\u0026#34;: \u0026#34;TEST\u0026#34;, //读取表名 \u0026#34;column\u0026#34;: [\u0026#34;ID\u0026#34;, \u0026#34;NAME\u0026#34;], //所要读取列名 \u0026#34;splitKey\u0026#34;: \u0026#34;ID\u0026#34; //切分列，必须是表主键 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;print\u0026#34;: true } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: \u0026#34;3\u0026#34; } } } } 3.2 参数说明 queryServerAddress\n描述：hbase20xsqlreader需要通过Phoenix轻客户端去连接Phoenix QueryServer，因此这里需要填写对应QueryServer地址。 增强版/Lindorm 用户若需透传user, password参数，可以在queryServerAddress后增加对应可选属性. 格式参考：http://127.0.0.1:8765;user=root;password=root\n必选：是 默认值：无 serialization\n描述：QueryServer使用的序列化协议\n必选：否 默认值：PROTOBUF table\n描述：所要读取表名\n必选：是 默认值：无 schema\n描述：表所在的schema\n必选：否 默认值：无 column\n描述：填写需要从phoenix表中读取的列名集合，使用JSON的数组描述字段信息，空值表示读取所有列。\n必选： 否\n默认值：全部列 splitKey\n描述：读取表时对表进行切分并行读取，切分时有两种方式：1.根据该列的最大最小值按照指定channel个数均分，这种方式仅支持整形和字符串类型切分列；2.根据设置的splitPoint进行切分\n必选：是 默认值：无 splitPoints\n描述：由于根据切分列最大最小值切分时不能保证避免数据热点，splitKey支持用户根据数据特征动态指定切分点，对表数据进行切分。建议切分点根据Region的startkey和endkey设置，保证每个查询对应单个Region\n必选： 否\n默认值：无 where\n描述：支持对表查询增加过滤条件，每个切分都会携带该过滤条件。\n必选： 否\n默认值：无\nquerySql\n描述：支持指定多个查询语句，但查询列类型和数目必须保持一致，用户可根据实际情况手动输入表查询语句或多表联合查询语句，设置该参数后，除queryserverAddress参数必须设置外，其余参数将失去作用或可不设置。\n必选： 否\n默认值：无\n3.3 类型转换 目前hbase20xsqlreader支持大部分Phoenix类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出MysqlReader针对Mysql类型转换列表:\nDataX 内部类型 Phoenix 数据类型 String CHAR, VARCHAR Bytes BINARY, VARBINARY Bool BOOLEAN Long INTEGER, TINYINT, SMALLINT, BIGINT Double FLOAT, DECIMAL, DOUBLE, Date DATE, TIME, TIMESTAMP 4 性能报告 略\n5 约束限制 切分表时切分列仅支持单个列，且该列必须是表主键 不设置splitPoint默认使用自动切分，此时切分列仅支持整形和字符型 表名和SCHEMA名及列名大小写敏感，请与Phoenix表实际大小写保持一致 仅支持通过Phoenix QeuryServer读取数据，因此您的Phoenix必须启动QueryServer服务才能使用本插件 6 FAQ ","permalink":"https://haokiu.com/blog/d74e56a13f78424182e14164c8b4e5e4/","summary":"hbase20xsqlreader 插件文档 1 快速介绍 hbase20xsqlreader插件实现了从Phoenix(HBase SQL)读取数据，对应版本为HBase2.X和Phoenix5.X。\n2 实现原理 简而言之，hbase20xsqlreader通过Phoenix轻客户端去连接Phoenix QueryServer，并根据用户配置信息生成查询SELECT 语句，然后发送到QueryServer读取HBase数据，并将返回结果使用DataX自定义的数据类型拼装为抽象的数据集，最终传递给下游Writer处理。\n3 功能说明 3.1 配置样例 配置一个从Phoenix同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase20xsqlreader\u0026#34;, //指定插件为hbase20xsqlreader \u0026#34;parameter\u0026#34;: { \u0026#34;queryServerAddress\u0026#34;: \u0026#34;http://127.0.0.1:8765\u0026#34;, //填写连接Phoenix QueryServer地址 \u0026#34;serialization\u0026#34;: \u0026#34;PROTOBUF\u0026#34;, //QueryServer序列化格式 \u0026#34;table\u0026#34;: \u0026#34;TEST\u0026#34;, //读取表名 \u0026#34;column\u0026#34;: [\u0026#34;ID\u0026#34;, \u0026#34;NAME\u0026#34;], //所要读取列名 \u0026#34;splitKey\u0026#34;: \u0026#34;ID\u0026#34; //切分列，必须是表主键 } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;print\u0026#34;: true } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: \u0026#34;3\u0026#34; } } } } 3.2 参数说明 queryServerAddress\n描述：hbase20xsqlreader需要通过Phoenix轻客户端去连接Phoenix QueryServer，因此这里需要填写对应QueryServer地址。 增强版/Lindorm 用户若需透传user, password参数，可以在queryServerAddress后增加对应可选属性. 格式参考：http://127.0.0.1:8765;user=root;password=root\n必选：是 默认值：无 serialization\n描述：QueryServer使用的序列化协议\n必选：否 默认值：PROTOBUF table\n描述：所要读取表名\n必选：是 默认值：无 schema\n描述：表所在的schema\n必选：否 默认值：无 column\n描述：填写需要从phoenix表中读取的列名集合，使用JSON的数组描述字段信息，空值表示读取所有列。\n必选： 否\n默认值：全部列 splitKey","title":"hbase20xsqlreader  插件文档"},{"content":"HBase20xsqlwriter插件文档 1. 快速介绍 HBase20xsqlwriter实现了向hbase中的SQL表(phoenix)批量导入数据的功能。Phoenix因为对rowkey做了数据编码，所以，直接使用HBaseAPI进行写入会面临手工数据转换的问题，麻烦且易错。本插件提供了SQL方式直接向Phoenix表写入数据。\n在底层实现上，通过Phoenix QueryServer的轻客户端驱动，执行UPSERT语句向Phoenix写入数据。\n1.1 支持的功能 支持带索引的表的数据导入，可以同步更新所有的索引表 1.2 限制 要求版本为Phoenix5.x及HBase2.x 仅支持通过Phoenix QeuryServer导入数据，因此您Phoenix必须启动QueryServer服务才能使用本插件 不支持清空已有表数据 仅支持通过phoenix创建的表，不支持原生HBase表 不支持带时间戳的数据导入 2. 实现原理 通过Phoenix轻客户端，连接Phoenix QueryServer服务，执行UPSERT语句向表中批量写入数据。因为使用上层接口，所以，可以同步更新索引表。\n3. 配置说明 3.1 配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;entry\u0026#34;: { \u0026#34;jvm\u0026#34;: \u0026#34;-Xms2048m -Xmx2048m\u0026#34; }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase20xsqlwriter/txt/normal.txt\u0026#34;, \u0026#34;charset\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;String\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase20xsqlwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;batchSize\u0026#34;: \u0026#34;100\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;UID\u0026#34;, \u0026#34;TS\u0026#34;, \u0026#34;EVENTID\u0026#34;, \u0026#34;CONTENT\u0026#34; ], \u0026#34;queryServerAddress\u0026#34;: \u0026#34;http://127.0.0.1:8765\u0026#34;, \u0026#34;nullMode\u0026#34;: \u0026#34;skip\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;目标hbase表名，大小写有关\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } } } } 3.2 参数说明 name\n描述：插件名字，必须是hbase11xsqlwriter 必选：是 默认值：无 schema\n描述：表所在的schema\n必选：否 默认值：无 table\n描述：要导入的表名，大小写敏感，通常phoenix表都是大写表名 必选：是 默认值：无 column\n描述：列名，大小写敏感，通常phoenix的列名都是大写。 需要注意列的顺序，必须与reader输出的列的顺序一一对应。 不需要填写数据类型，会自动从phoenix获取列的元数据 必选：是 默认值：无 queryServerAddress\n描述：Phoenix QueryServer地址，为必填项，格式：http://NULL:NULL，如http://172.16.34.58:8765。 增强版/Lindorm 用户若需透传user, password参数，可以在queryServerAddress后增加对应可选属性. 格式参考：http://127.0.0.1:8765;user=root;password=root 必选：是 默认值：无 serialization\n描述：QueryServer使用的序列化协议 必选：否 默认值：PROTOBUF batchSize\n描述：批量写入的最大行数 必选：否 默认值：256 nullMode\n描述：读取到的列值为null时，如何处理。目前有两种方式： skip：跳过这一列，即不插入这一列(如果该行的这一列之前已经存在，则会被删除) empty：插入空值，值类型的空值是0，varchar的空值是空字符串 必选：否 默认值：skip 4. 性能报告 无\n5. 约束限制 writer中的列的定义顺序必须与reader的列顺序匹配。reader中的列顺序定义了输出的每一行中，列的组织顺序。而writer的列顺序，定义的是在收到的数据中，writer期待的列的顺序。例如：\nreader的列顺序是： c1, c2, c3, c4\nwriter的列顺序是： x1, x2, x3, x4\n则reader输出的列c1就会赋值给writer的列x1。如果writer的列顺序是x1, x2, x4, x3，则c3会赋值给x4，c4会赋值给x3.\n6. FAQ 并发开多少合适？速度慢时增加并发有用吗？ 数据导入进程默认JVM的堆大小是2GB，并发(channel数)是通过多线程实现的，开过多的线程有时并不能提高导入速度，反而可能因为过于频繁的GC导致性能下降。一般建议并发数(channel)为5-10.\nbatchSize设置多少比较合适？ 默认是256，但应根据每行的大小来计算最合适的batchSize。通常一次操作的数据量在2MB-4MB左右，用这个值除以行大小，即可得到batchSize。\n","permalink":"https://haokiu.com/blog/28250260969448579bc8cee8c2963319/","summary":"HBase20xsqlwriter插件文档 1. 快速介绍 HBase20xsqlwriter实现了向hbase中的SQL表(phoenix)批量导入数据的功能。Phoenix因为对rowkey做了数据编码，所以，直接使用HBaseAPI进行写入会面临手工数据转换的问题，麻烦且易错。本插件提供了SQL方式直接向Phoenix表写入数据。\n在底层实现上，通过Phoenix QueryServer的轻客户端驱动，执行UPSERT语句向Phoenix写入数据。\n1.1 支持的功能 支持带索引的表的数据导入，可以同步更新所有的索引表 1.2 限制 要求版本为Phoenix5.x及HBase2.x 仅支持通过Phoenix QeuryServer导入数据，因此您Phoenix必须启动QueryServer服务才能使用本插件 不支持清空已有表数据 仅支持通过phoenix创建的表，不支持原生HBase表 不支持带时间戳的数据导入 2. 实现原理 通过Phoenix轻客户端，连接Phoenix QueryServer服务，执行UPSERT语句向表中批量写入数据。因为使用上层接口，所以，可以同步更新索引表。\n3. 配置说明 3.1 配置样例 { \u0026#34;job\u0026#34;: { \u0026#34;entry\u0026#34;: { \u0026#34;jvm\u0026#34;: \u0026#34;-Xms2048m -Xmx2048m\u0026#34; }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;txtfilereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;path\u0026#34;: \u0026#34;/Users/shf/workplace/datax_test/hbase20xsqlwriter/txt/normal.txt\u0026#34;, \u0026#34;charset\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;column\u0026#34;: [ { \u0026#34;index\u0026#34;: 0, \u0026#34;type\u0026#34;: \u0026#34;String\u0026#34; }, { \u0026#34;index\u0026#34;: 1, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 2, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; }, { \u0026#34;index\u0026#34;: 3, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34; } ], \u0026#34;fieldDelimiter\u0026#34;: \u0026#34;,\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;hbase20xsqlwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;batchSize\u0026#34;: \u0026#34;100\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;UID\u0026#34;, \u0026#34;TS\u0026#34;, \u0026#34;EVENTID\u0026#34;, \u0026#34;CONTENT\u0026#34; ], \u0026#34;queryServerAddress\u0026#34;: \u0026#34;http://127.0.0.1:8765\u0026#34;, \u0026#34;nullMode\u0026#34;: \u0026#34;skip\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;目标hbase表名，大小写有关\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } } } } 3.","title":"HBase20xsqlwriter插件文档"},{"content":"KingbaseesReader 插件文档 1 快速介绍 KingbaseesReader插件实现了从KingbaseES读取数据。在底层实现上，KingbaseesReader通过JDBC连接远程KingbaseES数据库，并执行相应的sql语句将数据从KingbaseES库中SELECT出来。\n2 实现原理 简而言之，KingbaseesReader通过JDBC连接器连接到远程的KingbaseES数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程KingbaseES数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，KingbaseesReader将其拼接为SQL语句发送到KingbaseES数据库；对于用户配置querySql信息，KingbaseesReader直接将其发送到KingbaseES数据库。\n3 功能说明 3.1 配置样例 配置一个从KingbaseES数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度，单位为byte/s，DataX运行会尽可能达到该速度但是不超过它. \u0026#34;byte\u0026#34;: 1048576 }, //出错限制 \u0026#34;errorLimit\u0026#34;: { //出错的record条数上限，当大于该值即报错。 \u0026#34;record\u0026#34;: 0, //出错的record百分比上限 1.0表示100%，0.02表示2% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;kingbaseesreader\u0026#34;, \u0026#34;parameter\u0026#34;: { // 数据库连接用户名 \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, // 数据库连接密码 \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;，\u0026#34;name\u0026#34; ], //切分主键 \u0026#34;splitPk\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:kingbase8://host:port/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, //是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true, } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: 1048576 }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;kingbaseesreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;where\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10;\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:kingbase8://host:port/database\u0026#34;, \u0026#34;jdbc:kingbase8://host:port/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.2 参数说明 jdbcUrl\n描述：描述的是到对端数据库的JDBC连接信息，使用JSON的数组描述，并支持一个库填写多个连接地址。之所以使用JSON数组描述连接信息，是因为阿里集团内部支持多个IP探测，如果配置了多个，KingbaseesReader可以依次探测ip的可连接性，直到选择一个合法的IP。如果全部连接失败，KingbaseesReader报错。 注意，jdbcUrl必须包含在connection配置单元中。对于阿里集团外部使用情况，JSON数组填写一个JDBC连接即可。\njdbcUrl按照KingbaseES官方规范，并可以填写连接附件控制信息。具体请参看KingbaseES官方文档。\n必选：是 默认值：无 username\n描述：数据源的用户名 必选：是 默认值：无 password\n描述：数据源指定用户名的密码 必选：是 默认值：无 table\n描述：所选取的需要同步的表。使用JSON的数组描述，因此支持多张表同时抽取。当配置为多张表时，用户自己需保证多张表是同一schema结构，KingbaseesReader不予检查表是否同一逻辑表。注意，table必须包含在connection配置单元中。\n必选：是 默认值：无 column\n描述：所配置的表中需要同步的列名集合，使用JSON的数组描述字段信息。用户使用*代表默认使用所有列配置，例如[\u0026rsquo;*\u0026rsquo;]。\n支持列裁剪，即列可以挑选部分列进行导出。\n支持列换序，即列可以不按照表schema信息进行导出。\n支持常量配置，用户需要按照KingbaseES语法格式: [\u0026ldquo;id\u0026rdquo;, \u0026ldquo;\u0026lsquo;hello\u0026rsquo;::varchar\u0026rdquo;, \u0026ldquo;true\u0026rdquo;, \u0026ldquo;2.5::real\u0026rdquo;, \u0026ldquo;power(2,3)\u0026rdquo;] id为普通列名，\u0026lsquo;hello\u0026rsquo;::varchar为字符串常量，true为布尔值，2.5为浮点数, power(2,3)为函数。\ncolumn必须用户显示指定同步的列集合，不允许为空！\n必选：是 默认值：无 splitPk\n描述：KingbaseesReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。\n推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。\n目前splitPk仅支持整形数据切分，不支持浮点、字符串型、日期等其他类型。如果用户指定其他非支持类型，KingbaseesReader将报错！\nsplitPk设置为空，底层将视作用户不允许对单表进行切分，因此使用单通道进行抽取。\n必选：否 默认值：空 where\n描述：筛选条件，KingbaseesReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create \u0026gt; $bizdate 。注意：不可以将where条件指定为limit 10，limit不是SQL的合法where子句。\nwhere条件可以有效地进行业务增量同步。\twhere条件不配置或者为空，视作全表同步数据。 必选：否 默认值：无 querySql\n描述：在有些业务场景下，where这一配置项不足以描述所筛选的条件，用户可以通过该配置型来自定义筛选SQL。当用户配置了这一项之后，DataX系统就会忽略table，column这些配置型，直接使用这个配置项的内容对数据进行筛选，例如需要进行多表join后同步数据，使用select a,b from table_a join table_b on table_a.id = table_b.id 当用户配置querySql时，KingbaseesReader直接忽略table、column、where条件的配置。\n必选：否 默认值：无 fetchSize\n描述：该配置项定义了插件和数据库服务器端每次批量数据获取条数，该值决定了DataX和服务器端的网络交互次数，能够较大的提升数据抽取性能。 注意，该值过大(\u0026gt;2048)可能造成DataX进程OOM。。\n必选：否 默认值：1024 3.3 类型转换 目前KingbaseesReader支持大部分KingbaseES类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出KingbaseesReader针对KingbaseES类型转换列表:\nDataX 内部类型 KingbaseES 数据类型 Long bigint, bigserial, integer, smallint, serial Double double precision, money, numeric, real String varchar, char, text, bit, inet Date date, time, timestamp Boolean bool Bytes bytea 请注意:\n除上述罗列字段类型外，其他类型均不支持; money,inet,bit需用户使用a_inet::varchar类似的语法转换。 ","permalink":"https://haokiu.com/blog/cc7bd03f72154435ae9af2d67a214f6d/","summary":"KingbaseesReader 插件文档 1 快速介绍 KingbaseesReader插件实现了从KingbaseES读取数据。在底层实现上，KingbaseesReader通过JDBC连接远程KingbaseES数据库，并执行相应的sql语句将数据从KingbaseES库中SELECT出来。\n2 实现原理 简而言之，KingbaseesReader通过JDBC连接器连接到远程的KingbaseES数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程KingbaseES数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，KingbaseesReader将其拼接为SQL语句发送到KingbaseES数据库；对于用户配置querySql信息，KingbaseesReader直接将其发送到KingbaseES数据库。\n3 功能说明 3.1 配置样例 配置一个从KingbaseES数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度，单位为byte/s，DataX运行会尽可能达到该速度但是不超过它. \u0026#34;byte\u0026#34;: 1048576 }, //出错限制 \u0026#34;errorLimit\u0026#34;: { //出错的record条数上限，当大于该值即报错。 \u0026#34;record\u0026#34;: 0, //出错的record百分比上限 1.0表示100%，0.02表示2% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;kingbaseesreader\u0026#34;, \u0026#34;parameter\u0026#34;: { // 数据库连接用户名 \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, // 数据库连接密码 \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;，\u0026#34;name\u0026#34; ], //切分主键 \u0026#34;splitPk\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:kingbase8://host:port/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, //是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true, } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: 1048576 }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;kingbaseesreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;where\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10;\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:kingbase8://host:port/database\u0026#34;, \u0026#34;jdbc:kingbase8://host:port/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.","title":"KingbaseesReader 插件文档"},{"content":"MysqlReader 插件文档 1 快速介绍 MysqlReader插件实现了从Mysql读取数据。在底层实现上，MysqlReader通过JDBC连接远程Mysql数据库，并执行相应的sql语句将数据从mysql库中SELECT出来。\n不同于其他关系型数据库，MysqlReader不支持FetchSize.\n2 实现原理 简而言之，MysqlReader通过JDBC连接器连接到远程的Mysql数据库，并根据用户配置的信息生成查询SELECT SQL语句，然后发送到远程Mysql数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，MysqlReader将其拼接为SQL语句发送到Mysql数据库；对于用户配置querySql信息，MysqlReader直接将其发送到Mysql数据库。\n3 功能说明 3.1 配置样例 配置一个从Mysql数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 }, \u0026#34;errorLimit\u0026#34;: { \u0026#34;record\u0026#34;: 0, \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;mysqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;splitPk\u0026#34;: \u0026#34;db_id\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:mysql://127.0.0.1:3306/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;:1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;mysqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10;\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:mysql://bad_ip:3306/database\u0026#34;, \u0026#34;jdbc:mysql://127.0.0.1:bad_port/database\u0026#34;, \u0026#34;jdbc:mysql://127.0.0.1:3306/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.2 参数说明 jdbcUrl\n描述：描述的是到对端数据库的JDBC连接信息，使用JSON的数组描述，并支持一个库填写多个连接地址。之所以使用JSON数组描述连接信息，是因为阿里集团内部支持多个IP探测，如果配置了多个，MysqlReader可以依次探测ip的可连接性，直到选择一个合法的IP。如果全部连接失败，MysqlReader报错。 注意，jdbcUrl必须包含在connection配置单元中。对于阿里集团外部使用情况，JSON数组填写一个JDBC连接即可。\njdbcUrl按照Mysql官方规范，并可以填写连接附件控制信息。具体请参看Mysql官方文档。\n必选：是 默认值：无 username\n描述：数据源的用户名 必选：是 默认值：无 password\n描述：数据源指定用户名的密码 必选：是 默认值：无 table\n描述：所选取的需要同步的表。使用JSON的数组描述，因此支持多张表同时抽取。当配置为多张表时，用户自己需保证多张表是同一schema结构，MysqlReader不予检查表是否同一逻辑表。注意，table必须包含在connection配置单元中。\n必选：是 默认值：无 column\n描述：所配置的表中需要同步的列名集合，使用JSON的数组描述字段信息。用户使用*代表默认使用所有列配置，例如[\u0026rsquo;*\u0026rsquo;]。\n支持列裁剪，即列可以挑选部分列进行导出。\n支持列换序，即列可以不按照表schema信息进行导出。\n支持常量配置，用户需要按照Mysql SQL语法格式: [\u0026ldquo;id\u0026rdquo;, \u0026ldquo;`table`\u0026rdquo;, \u0026ldquo;1\u0026rdquo;, \u0026ldquo;\u0026lsquo;bazhen.csy\u0026rsquo;\u0026rdquo;, \u0026ldquo;null\u0026rdquo;, \u0026ldquo;to_char(a + 1)\u0026rdquo;, \u0026ldquo;2.3\u0026rdquo; , \u0026ldquo;true\u0026rdquo;] id为普通列名，`table`为包含保留在的列名，1为整形数字常量，\u0026lsquo;bazhen.csy\u0026rsquo;为字符串常量，null为空指针，to_char(a + 1)为表达式，2.3为浮点数，true为布尔值。\n必选：是 默认值：无 splitPk\n描述：MysqlReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。\n推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。\n目前splitPk仅支持整形数据切分，不支持浮点、字符串、日期等其他类型。如果用户指定其他非支持类型，MysqlReader将报错！\n如果splitPk不填写，包括不提供splitPk或者splitPk值为空，DataX视作使用单通道同步该表数据。 必选：否 默认值：空 where\n描述：筛选条件，MysqlReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create \u0026gt; $bizdate 。注意：不可以将where条件指定为limit 10，limit不是SQL的合法where子句。\nwhere条件可以有效地进行业务增量同步。如果不填写where语句，包括不提供where的key或者value，DataX均视作同步全量数据。 必选：否 默认值：无 querySql\n描述：在有些业务场景下，where这一配置项不足以描述所筛选的条件，用户可以通过该配置型来自定义筛选SQL。当用户配置了这一项之后，DataX系统就会忽略table，column这些配置型，直接使用这个配置项的内容对数据进行筛选，例如需要进行多表join后同步数据，使用select a,b from table_a join table_b on table_a.id = table_b.id 当用户配置querySql时，MysqlReader直接忽略table、column、where条件的配置，querySql优先级大于table、column、where选项。\n必选：否 默认值：无 3.3 类型转换 目前MysqlReader支持大部分Mysql类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出MysqlReader针对Mysql类型转换列表:\nDataX 内部类型 Mysql 数据类型 Long int, tinyint, smallint, mediumint, int, bigint Double float, double, decimal String varchar, char, tinytext, text, mediumtext, longtext, year Date date, datetime, timestamp, time Boolean bit, bool Bytes tinyblob, mediumblob, blob, longblob, varbinary 请注意:\n除上述罗列字段类型外，其他类型均不支持。 tinyint(1) DataX视作为整形。 year DataX视作为字符串类型 bit DataX属于未定义行为。 4 性能报告 4.1 环境准备 4.1.1 数据特征 建表语句：\nCREATE TABLE `tc_biz_vertical_test_0000` ( `biz_order_id` bigint(20) NOT NULL COMMENT 'id', `key_value` varchar(4000) NOT NULL COMMENT 'Key-value的内容', `gmt_create` datetime NOT NULL COMMENT '创建时间', `gmt_modified` datetime NOT NULL COMMENT '修改时间', `attribute_cc` int(11) DEFAULT NULL COMMENT '防止并发修改的标志', `value_type` int(11) NOT NULL DEFAULT '0' COMMENT '类型', `buyer_id` bigint(20) DEFAULT NULL COMMENT 'buyerid', `seller_id` bigint(20) DEFAULT NULL COMMENT 'seller_id', PRIMARY KEY (`biz_order_id`,`value_type`), KEY `idx_biz_vertical_gmtmodified` (`gmt_modified`) ) ENGINE=InnoDB DEFAULT CHARSET=gbk COMMENT='tc_biz_vertical' 单行记录类似于：\nbiz_order_id: 888888888 key_value: ;orderIds:20148888888,2014888888813800; gmt_create: 2011-09-24 11:07:20 gmt_modified: 2011-10-24 17:56:34 attribute_cc: 1 value_type: 3 buyer_id: 8888888 seller_id: 1 4.1.2 机器参数 执行DataX的机器参数为:\ncpu: 24核 Intel(R) Xeon(R) CPU E5-2630 0 @ 2.30GHz mem: 48GB net: 千兆双网卡 disc: DataX 数据不落磁盘，不统计此项 Mysql数据库机器参数为:\ncpu: 32核 Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz mem: 256GB net: 千兆双网卡 disc: BTWL419303E2800RGN INTEL SSDSC2BB800G4 D2010370 4.1.3 DataX jvm 参数 -Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError 4.2 测试报告 4.2.1 单表测试报告 通道数 是否按照主键切分 DataX速度(Rec/s) DataX流量(MB/s) DataX机器网卡进入流量(MB/s) DataX机器运行负载 DB网卡流出流量(MB/s) DB运行负载 1 否 183185 18.11 29 0.6 31 0.6 1 是 183185 18.11 29 0.6 31 0.6 4 否 183185 18.11 29 0.6 31 0.6 4 是 329733 32.60 58 0.8 60 0.76 8 否 183185 18.11 29 0.6 31 0.6 8 是 549556 54.33 115 1.46 120 0.78 说明：\n这里的单表，主键类型为 bigint(20),范围为：190247559466810-570722244711460，从主键范围划分看，数据分布均匀。 对单表如果没有安装主键切分，那么配置通道个数不会提升速度，效果与1个通道一样。 4.2.2 分表测试报告(2个分库，每个分库16张分表，共计32张分表) 通道数 DataX速度(Rec/s) DataX流量(MB/s) DataX机器网卡进入流量(MB/s) DataX机器运行负载 DB网卡流出流量(MB/s) DB运行负载 1 202241 20.06 31.5 1.0 32 1.1 4 726358 72.04 123.9 3.1 132 3.6 8 1074405 106.56 197 5.5 205 5.1 16 1227892 121.79 229.2 8.1 233 7.3 5 约束限制 5.1 主备同步数据恢复问题 主备同步问题指Mysql使用主从灾备，备库从主库不间断通过binlog恢复数据。由于主备数据同步存在一定的时间差，特别在于某些特定情况，例如网络延迟等问题，导致备库同步恢复的数据与主库有较大差别，导致从备库同步的数据不是一份当前时间的完整镜像。\n针对这个问题，我们提供了preSql功能，该功能待补充。\n5.2 一致性约束 Mysql在数据存储划分中属于RDBMS系统，对外可以提供强一致性数据查询接口。例如当一次同步任务启动运行过程中，当该库存在其他数据写入方写入数据时，MysqlReader完全不会获取到写入更新数据，这是由于数据库本身的快照特性决定的。关于数据库快照特性，请参看MVCC Wikipedia\n上述是在MysqlReader单线程模型下数据同步一致性的特性，由于MysqlReader可以根据用户配置信息使用了并发数据抽取，因此不能严格保证数据一致性：当MysqlReader根据splitPk进行数据切分后，会先后启动多个并发任务完成数据同步。由于多个并发任务相互之间不属于同一个读事务，同时多个并发任务存在时间间隔。因此这份数据并不是完整的、一致的数据快照信息。\n针对多线程的一致性快照需求，在技术上目前无法实现，只能从工程角度解决，工程化的方式存在取舍，我们提供几个解决思路给用户，用户可以自行选择：\n使用单线程同步，即不再进行数据切片。缺点是速度比较慢，但是能够很好保证一致性。\n关闭其他数据写入方，保证当前数据为静态数据，例如，锁表、关闭备库同步等等。缺点是可能影响在线业务。\n5.3 数据库编码问题 Mysql本身的编码设置非常灵活，包括指定编码到库、表、字段级别，甚至可以均不同编码。优先级从高到低为字段、表、库、实例。我们不推荐数据库用户设置如此混乱的编码，最好在库级别就统一到UTF-8。\nMysqlReader底层使用JDBC进行数据抽取，JDBC天然适配各类编码，并在底层进行了编码转换。因此MysqlReader不需用户指定编码，可以自动获取编码并转码。\n对于Mysql底层写入编码和其设定的编码不一致的混乱情况，MysqlReader对此无法识别，对此也无法提供解决方案，对于这类情况，导出有可能为乱码。\n5.4 增量数据同步 MysqlReader使用JDBC SELECT语句完成数据抽取工作，因此可以使用SELECT\u0026hellip;WHERE\u0026hellip;进行增量数据抽取，方式有多种：\n数据库在线应用写入数据库时，填充modify字段为更改时间戳，包括新增、更新、删除(逻辑删)。对于这类应用，MysqlReader只需要WHERE条件跟上一同步阶段时间戳即可。 对于新增流水型数据，MysqlReader可以WHERE条件后跟上一阶段最大自增ID即可。 对于业务上无字段区分新增、修改数据情况，MysqlReader也无法进行增量数据同步，只能同步全量数据。\n5.5 Sql安全性 MysqlReader提供querySql语句交给用户自己实现SELECT抽取语句，MysqlReader本身对querySql不做任何安全性校验。这块交由DataX用户方自己保证。\n6 FAQ Q: MysqlReader同步报错，报错信息为XXX\nA: 网络或者权限问题，请使用mysql命令行测试：\nmysql -u\u0026lt;username\u0026gt; -p\u0026lt;password\u0026gt; -h\u0026lt;ip\u0026gt; -D\u0026lt;database\u0026gt; -e \u0026quot;select * from \u0026lt;表名\u0026gt;\u0026quot; 如果上述命令也报错，那可以证实是环境问题，请联系你的DBA。\n","permalink":"https://haokiu.com/blog/29875f5b780c46929670f9b8699ed462/","summary":"MysqlReader 插件文档 1 快速介绍 MysqlReader插件实现了从Mysql读取数据。在底层实现上，MysqlReader通过JDBC连接远程Mysql数据库，并执行相应的sql语句将数据从mysql库中SELECT出来。\n不同于其他关系型数据库，MysqlReader不支持FetchSize.\n2 实现原理 简而言之，MysqlReader通过JDBC连接器连接到远程的Mysql数据库，并根据用户配置的信息生成查询SELECT SQL语句，然后发送到远程Mysql数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，MysqlReader将其拼接为SQL语句发送到Mysql数据库；对于用户配置querySql信息，MysqlReader直接将其发送到Mysql数据库。\n3 功能说明 3.1 配置样例 配置一个从Mysql数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 }, \u0026#34;errorLimit\u0026#34;: { \u0026#34;record\u0026#34;: 0, \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;mysqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;, \u0026#34;name\u0026#34; ], \u0026#34;splitPk\u0026#34;: \u0026#34;db_id\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:mysql://127.0.0.1:3306/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;:1 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;mysqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10;\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:mysql://bad_ip:3306/database\u0026#34;, \u0026#34;jdbc:mysql://127.","title":"MysqlReader 插件文档"},{"content":"OpenTSDBReader 插件文档 1 快速介绍 OpenTSDBReader 插件实现了从 OpenTSDB 读取数据。OpenTSDB 是主要由 Yahoo 维护的、可扩展的、分布式时序数据库，与阿里巴巴自研 TSDB 的关系与区别详见阿里云官网：《相比 OpenTSDB 优势》\n2 实现原理 在底层实现上，OpenTSDBReader 通过 HTTP 请求链接到 OpenTSDB 实例，利用 /api/config 接口获取到其底层存储 HBase 的连接信息，再利用 AsyncHBase 框架连接 HBase，通过 Scan 的方式将数据点扫描出来。整个同步的过程通过 metric 和时间段进行切分，即某个 metric 在某一个小时内的数据迁移，组合成一个迁移 Task。\n3 功能说明 3.1 配置样例 配置一个从 OpenTSDB 数据库同步抽取数据到本地的作业： { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;opentsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:4242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;m\u0026#34; ], \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 03:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;print\u0026#34;: true } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } } } } 3.2 参数说明 name\n描述：本插件的名称 必选：是 默认值：opentsdbreader parameter\nendpoint 描述：OpenTSDB 的 HTTP 连接地址 必选：是 格式：http://IP:Port 默认值：无\ncolumn 描述：数据迁移任务需要迁移的 Metric 列表 必选：是 默认值：无 beginDateTime\n描述：和 endDateTime 配合使用，用于指定哪个时间段内的数据点，需要被迁移 必选：是 格式：yyyy-MM-dd HH:mm:ss 默认值：无 注意：指定起止时间会自动忽略分钟和秒，转为整点时刻，例如 2019-4-18 的 [3:35, 4:55) 会被转为 [3:00, 4:00) endDateTime\n描述：和 beginDateTime 配合使用，用于指定哪个时间段内的数据点，需要被迁移 必选：是 格式：yyyy-MM-dd HH:mm:ss 默认值：无 注意：指定起止时间会自动忽略分钟和秒，转为整点时刻，例如 2019-4-18 的 [3:35, 4:55) 会被转为 [3:00, 4:00) 3.3 类型转换 DataX 内部类型 TSDB 数据类型 String TSDB 数据点序列化字符串，包括 timestamp、metric、tags 和 value 4 性能报告 4.1 环境准备 4.1.1 数据特征 从 Metric、时间线、Value 和 采集周期 四个方面来描述：\nmetric 固定指定一个 metric 为 m。\ntagkv 前四个 tagkv 全排列，形成 10 * 20 * 100 * 100 = 2000000 条时间线，最后 IP 对应 2000000 条时间线从 1 开始自增。\ntag_k tag_v zone z1~z10 cluster c1~c20 group g1~100 app a1~a100 ip ip1~ip2000000 value 度量值为 [1, 100] 区间内的随机值\ninterval 采集周期为 10 秒，持续摄入 3 小时，总数据量为 3 * 60 * 60 / 10 * 2000000 = 2,160,000,000 个数据点。\n4.1.2 机器参数 OpenTSDB Reader 机型: 64C256G\nHBase 机型： 8C16G * 5\n4.1.3 DataX jvm 参数 \u0026ldquo;-Xms4096m -Xmx4096m\u0026rdquo;\n4.2 测试报告 通道数 DataX 速度 (Rec/s) DataX 流量 (MB/s) 1 215428 25.65 2 424994 50.60 3 603132 71.81 5 约束限制 5.1 需要确保与 OpenTSDB 底层存储的网络是连通的 具体缘由详见 6.1\n5.2 如果存在某一个 Metric 下在一个小时范围内的数据量过大，可能需要通过 -j 参数调整 JVM 内存大小 考虑到下游 Writer 如果写入速度不及 OpenTSDB reader 的查询数据，可能会存在积压的情况，因此需要适当地调整 JVM 参数。以\u0026quot;从 OpenTSDB 数据库同步抽取数据到本地的作业\u0026quot;为例，启动命令如下：\npython datax/bin/datax.py opentsdb2stream.json -j \u0026#34;-Xms4096m -Xmx4096m\u0026#34; 5.3 指定起止时间会自动被转为整点时刻 指定起止时间会自动被转为整点时刻，例如 2019-4-18 的 [3:35, 3:55) 会被转为 [3:00, 4:00)\n5.4 目前只支持兼容 OpenTSDB 2.3.x 其他版本暂不保证兼容\n6 FAQ Q：为什么需要连接 OpenTSDB 的底层存储，为什么不直接使用 /api/query 查询获取数据点？\nA：因为通过 OpenTSDB 的 HTTP 接口（/api/query）来读取数据的话，经内部压测发现，在大数据量的情况下，会导致 OpenTSDB 的异步框架会报 CallBack 过多的问题；所以，采用了直连底层 HBase 存储，通过 Scan 的方式来扫描数据点，来避免这个问题。另外，还考虑到，可以通过指定 metric 和时间范围，可以顺序地 Scan HBase 表，提高查询效率。\n","permalink":"https://haokiu.com/blog/4e39a8595b6247fabfd6f625f053b0b6/","summary":"OpenTSDBReader 插件文档 1 快速介绍 OpenTSDBReader 插件实现了从 OpenTSDB 读取数据。OpenTSDB 是主要由 Yahoo 维护的、可扩展的、分布式时序数据库，与阿里巴巴自研 TSDB 的关系与区别详见阿里云官网：《相比 OpenTSDB 优势》\n2 实现原理 在底层实现上，OpenTSDBReader 通过 HTTP 请求链接到 OpenTSDB 实例，利用 /api/config 接口获取到其底层存储 HBase 的连接信息，再利用 AsyncHBase 框架连接 HBase，通过 Scan 的方式将数据点扫描出来。整个同步的过程通过 metric 和时间段进行切分，即某个 metric 在某一个小时内的数据迁移，组合成一个迁移 Task。\n3 功能说明 3.1 配置样例 配置一个从 OpenTSDB 数据库同步抽取数据到本地的作业： { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;opentsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:4242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;m\u0026#34; ], \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 03:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;print\u0026#34;: true } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } } } } 3.2 参数说明 name\n描述：本插件的名称 必选：是 默认值：opentsdbreader parameter","title":"OpenTSDBReader 插件文档"},{"content":"OracleReader 插件文档 1 快速介绍 OracleReader插件实现了从Oracle读取数据。在底层实现上，OracleReader通过JDBC连接远程Oracle数据库，并执行相应的sql语句将数据从Oracle库中SELECT出来。\n2 实现原理 简而言之，OracleReader通过JDBC连接器连接到远程的Oracle数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程Oracle数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，OracleReader将其拼接为SQL语句发送到Oracle数据库；对于用户配置querySql信息，Oracle直接将其发送到Oracle数据库。\n3 功能说明 3.1 配置样例 配置一个从Oracle数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度 byte/s 尽量逼近这个速度但是不高于它. // channel 表示通道数量，byte表示通道速度，如果单通道速度1MB，配置byte为1048576表示一个channel \u0026#34;byte\u0026#34;: 1048576 }, //出错限制 \u0026#34;errorLimit\u0026#34;: { //先选择record \u0026#34;record\u0026#34;: 0, //百分比 1表示100% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;oraclereader\u0026#34;, \u0026#34;parameter\u0026#34;: { // 数据库连接用户名 \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, // 数据库连接密码 \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;,\u0026#34;name\u0026#34; ], //切分主键 \u0026#34;splitPk\u0026#34;: \u0026#34;db_id\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:oracle:thin:@[HOST_NAME]:PORT:[DATABASE_NAME]\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, // 是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: true } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;oraclereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;where\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:oracle:thin:@[HOST_NAME]:PORT:[DATABASE_NAME]\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;visible\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.2 参数说明 jdbcUrl\n描述：描述的是到对端数据库的JDBC连接信息，使用JSON的数组描述，并支持一个库填写多个连接地址。之所以使用JSON数组描述连接信息，是因为阿里集团内部支持多个IP探测，如果配置了多个，OracleReader可以依次探测ip的可连接性，直到选择一个合法的IP。如果全部连接失败，OracleReader报错。 注意，jdbcUrl必须包含在connection配置单元中。对于阿里集团外部使用情况，JSON数组填写一个JDBC连接即可。\njdbcUrl按照Oracle官方规范，并可以填写连接附件控制信息。具体请参看Oracle官方文档。\n必选：是 默认值：无 username\n描述：数据源的用户名 必选：是 默认值：无 password\n描述：数据源指定用户名的密码 必选：是 默认值：无 table\n描述：所选取的需要同步的表。使用JSON的数组描述，因此支持多张表同时抽取。当配置为多张表时，用户自己需保证多张表是同一schema结构，OracleReader不予检查表是否同一逻辑表。注意，table必须包含在connection配置单元中。\n必选：是 默认值：无 column\n描述：所配置的表中需要同步的列名集合，使用JSON的数组描述字段信息。用户使用*代表默认使用所有列配置，例如[\u0026rsquo;*\u0026rsquo;]。\n支持列裁剪，即列可以挑选部分列进行导出。\n支持列换序，即列可以不按照表schema信息进行导出。\n支持常量配置，用户需要按照JSON格式: [\u0026ldquo;id\u0026rdquo;, \u0026ldquo;table\u0026rdquo;, \u0026ldquo;1\u0026rdquo;, \u0026ldquo;\u0026lsquo;bazhen.csy\u0026rsquo;\u0026rdquo;, \u0026ldquo;null\u0026rdquo;, \u0026ldquo;to_char(a + 1)\u0026rdquo;, \u0026ldquo;2.3\u0026rdquo; , \u0026ldquo;true\u0026rdquo;] id为普通列名，`table`为包含保留在的列名，1为整形数字常量，\u0026lsquo;bazhen.csy\u0026rsquo;为字符串常量，null为空指针，to_char(a + 1)为表达式，2.3为浮点数，true为布尔值。\nColumn必须显示填写，不允许为空！\n必选：是 默认值：无 splitPk\n描述：OracleReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。\n推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。\n目前splitPk仅支持整形、字符串型数据切分，不支持浮点、日期等其他类型。如果用户指定其他非支持类型，OracleReader将报错！\nsplitPk如果不填写，将视作用户不对单表进行切分，OracleReader使用单通道同步全量数据。\n必选：否 默认值：无 where\n描述：筛选条件，MysqlReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create \u0026gt; $bizdate 。注意：不可以将where条件指定为limit 10，limit不是SQL的合法where子句。\nwhere条件可以有效地进行业务增量同步。 必选：否 默认值：无 querySql\n描述：在有些业务场景下，where这一配置项不足以描述所筛选的条件，用户可以通过该配置型来自定义筛选SQL。当用户配置了这一项之后，DataX系统就会忽略table，column这些配置型，直接使用这个配置项的内容对数据进行筛选，例如需要进行多表join后同步数据，使用select a,b from table_a join table_b on table_a.id = table_b.id 当用户配置querySql时，OracleReader直接忽略table、column、where条件的配置。\n必选：否 默认值：无 fetchSize\n描述：该配置项定义了插件和数据库服务器端每次批量数据获取条数，该值决定了DataX和服务器端的网络交互次数，能够较大的提升数据抽取性能。 注意，该值过大(\u0026gt;2048)可能造成DataX进程OOM。。\n必选：否 默认值：1024 session\n描述：控制写入数据的时间格式，时区等的配置，如果表中有时间字段，配置该值以明确告知写入 oracle 的时间格式。通常配置的参数为：NLS_DATE_FORMAT,NLS_TIME_FORMAT。其配置的值为 json 格式，例如： \u0026#34;session\u0026#34;: [ \u0026#34;alter session set NLS_DATE_FORMAT=\u0026#39;yyyy-mm-dd hh24:mi:ss\u0026#39;\u0026#34;, \u0026#34;alter session set NLS_TIMESTAMP_FORMAT=\u0026#39;yyyy-mm-dd hh24:mi:ss\u0026#39;\u0026#34;, \u0026#34;alter session set NLS_TIMESTAMP_TZ_FORMAT=\u0026#39;yyyy-mm-dd hh24:mi:ss\u0026#39;\u0026#34;, \u0026#34;alter session set TIME_ZONE=\u0026#39;US/Pacific\u0026#39;\u0026#34; ] (注意\u0026amp;quot;是 \u0026quot; 的转义字符串)。\n* 必选：否 \u0026lt;br /\u0026gt; * 默认值：无 \u0026lt;br /\u0026gt; 3.3 类型转换 目前OracleReader支持大部分Oracle类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出OracleReader针对Oracle类型转换列表:\nDataX 内部类型 Oracle 数据类型 Long NUMBER,INTEGER,INT,SMALLINT Double NUMERIC,DECIMAL,FLOAT,DOUBLE PRECISION,REAL String LONG,CHAR,NCHAR,VARCHAR,VARCHAR2,NVARCHAR2,CLOB,NCLOB,CHARACTER,CHARACTER VARYING,CHAR VARYING,NATIONAL CHARACTER,NATIONAL CHAR,NATIONAL CHARACTER VARYING,NATIONAL CHAR VARYING,NCHAR VARYING Date TIMESTAMP,DATE Boolean bit, bool Bytes BLOB,BFILE,RAW,LONG RAW 请注意:\n除上述罗列字段类型外，其他类型均不支持。 4 性能报告 4.1 环境准备 4.1.1 数据特征 为了模拟线上真实数据，我们设计两个Oracle数据表，分别为:\n4.1.2 机器参数 执行DataX的机器参数为:\nOracle数据库机器参数为:\n4.2 测试报告 4.2.1 表1测试报告 并发任务数 DataX速度(Rec/s) DataX流量 网卡流量 DataX运行负载 DB运行负载 1 DataX 统计速度(Rec/s) DataX统计流量 网卡流量 DataX运行负载 DB运行负载 5 约束限制 5.1 主备同步数据恢复问题 主备同步问题指Oracle使用主从灾备，备库从主库不间断通过binlog恢复数据。由于主备数据同步存在一定的时间差，特别在于某些特定情况，例如网络延迟等问题，导致备库同步恢复的数据与主库有较大差别，导致从备库同步的数据不是一份当前时间的完整镜像。\n针对这个问题，我们提供了preSql功能，该功能待补充。\n5.2 一致性约束 Oracle在数据存储划分中属于RDBMS系统，对外可以提供强一致性数据查询接口。例如当一次同步任务启动运行过程中，当该库存在其他数据写入方写入数据时，OracleReader完全不会获取到写入更新数据，这是由于数据库本身的快照特性决定的。关于数据库快照特性，请参看MVCC Wikipedia\n上述是在OracleReader单线程模型下数据同步一致性的特性，由于OracleReader可以根据用户配置信息使用了并发数据抽取，因此不能严格保证数据一致性：当OracleReader根据splitPk进行数据切分后，会先后启动多个并发任务完成数据同步。由于多个并发任务相互之间不属于同一个读事务，同时多个并发任务存在时间间隔。因此这份数据并不是完整的、一致的数据快照信息。\n针对多线程的一致性快照需求，在技术上目前无法实现，只能从工程角度解决，工程化的方式存在取舍，我们提供几个解决思路给用户，用户可以自行选择：\n使用单线程同步，即不再进行数据切片。缺点是速度比较慢，但是能够很好保证一致性。\n关闭其他数据写入方，保证当前数据为静态数据，例如，锁表、关闭备库同步等等。缺点是可能影响在线业务。\n5.3 数据库编码问题 OracleReader底层使用JDBC进行数据抽取，JDBC天然适配各类编码，并在底层进行了编码转换。因此OracleReader不需用户指定编码，可以自动获取编码并转码。\n对于Oracle底层写入编码和其设定的编码不一致的混乱情况，OracleReader对此无法识别，对此也无法提供解决方案，对于这类情况，导出有可能为乱码。\n5.4 增量数据同步 OracleReader使用JDBC SELECT语句完成数据抽取工作，因此可以使用SELECT\u0026hellip;WHERE\u0026hellip;进行增量数据抽取，方式有多种：\n数据库在线应用写入数据库时，填充modify字段为更改时间戳，包括新增、更新、删除(逻辑删)。对于这类应用，OracleReader只需要WHERE条件跟上一同步阶段时间戳即可。 对于新增流水型数据，OracleReader可以WHERE条件后跟上一阶段最大自增ID即可。 对于业务上无字段区分新增、修改数据情况，OracleReader也无法进行增量数据同步，只能同步全量数据。\n5.5 Sql安全性 OracleReader提供querySql语句交给用户自己实现SELECT抽取语句，OracleReader本身对querySql不做任何安全性校验。这块交由DataX用户方自己保证。\n6 FAQ Q: OracleReader同步报错，报错信息为XXX\nA: 网络或者权限问题，请使用Oracle命令行测试： sqlplus username/password@//host:port/sid\n如果上述命令也报错，那可以证实是环境问题，请联系你的DBA。\nQ: OracleReader抽取速度很慢怎么办？\nA: 影响抽取时间的原因大概有如下几个：(来自专业 DBA 卫绾)\n由于SQL的plan异常，导致的抽取时间长； 在抽取时，尽可能使用全表扫描代替索引扫描; 合理sql的并发度，减少抽取时间；根据表的大小， \u0026lt;50G可以不用并发， \u0026lt;100G添加如下hint: parallel(a,2）, 100G添加如下hint : parallel(a,4);\n抽取sql要简单，尽量不用replace等函数，这个非常消耗cpu，会严重影响抽取速度; ","permalink":"https://haokiu.com/blog/0ffdd59e828b4bb0a53cef538910db12/","summary":"OracleReader 插件文档 1 快速介绍 OracleReader插件实现了从Oracle读取数据。在底层实现上，OracleReader通过JDBC连接远程Oracle数据库，并执行相应的sql语句将数据从Oracle库中SELECT出来。\n2 实现原理 简而言之，OracleReader通过JDBC连接器连接到远程的Oracle数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程Oracle数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，OracleReader将其拼接为SQL语句发送到Oracle数据库；对于用户配置querySql信息，Oracle直接将其发送到Oracle数据库。\n3 功能说明 3.1 配置样例 配置一个从Oracle数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度 byte/s 尽量逼近这个速度但是不高于它. // channel 表示通道数量，byte表示通道速度，如果单通道速度1MB，配置byte为1048576表示一个channel \u0026#34;byte\u0026#34;: 1048576 }, //出错限制 \u0026#34;errorLimit\u0026#34;: { //先选择record \u0026#34;record\u0026#34;: 0, //百分比 1表示100% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;oraclereader\u0026#34;, \u0026#34;parameter\u0026#34;: { // 数据库连接用户名 \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, // 数据库连接密码 \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;,\u0026#34;name\u0026#34; ], //切分主键 \u0026#34;splitPk\u0026#34;: \u0026#34;db_id\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:oracle:thin:@[HOST_NAME]:PORT:[DATABASE_NAME]\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, // 是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: true } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;oraclereader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;where\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:oracle:thin:@[HOST_NAME]:PORT:[DATABASE_NAME]\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;visible\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.","title":"OracleReader 插件文档"},{"content":"OTSReader 插件文档 1 快速介绍 OTSReader插件实现了从OTS读取数据，并可以通过用户指定抽取数据范围可方便的实现数据增量抽取的需求。目前支持三种抽取方式：\n全表抽取 范围抽取 指定分片抽取 OTS是构建在阿里云飞天分布式系统之上的 NoSQL数据库服务，提供海量结构化数据的存储和实时访问。OTS 以实例和表的形式组织数据，通过数据分片和负载均衡技术，实现规模上的无缝扩展。\n2 实现原理 简而言之，OTSReader通过OTS官方Java SDK连接到OTS服务端，获取并按照DataX官方协议标准转为DataX字段信息传递给下游Writer端。\nOTSReader会根据OTS的表范围，按照Datax并发的数目N，将范围等分为N份Task。每个Task都会有一个OTSReader线程来执行。\n3 功能说明 3.1 配置样例 配置一个从OTS全表同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;otsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { /* ----------- 必填 --------------*/ \u0026#34;endpoint\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;accessId\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;accessKey\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;instanceName\u0026#34;:\u0026#34;\u0026#34;, // 导出数据表的表名 \u0026#34;table\u0026#34;:\u0026#34;\u0026#34;, // 需要导出的列名，支持重复列和常量列，区分大小写 // 常量列：类型支持STRING，INT，DOUBLE，BOOL和BINARY // 备注：BINARY需要通过Base64转换为对应的字符串传入插件 \u0026#34;column\u0026#34;:[ {\u0026#34;name\u0026#34;:\u0026#34;col1\u0026#34;}, // 普通列 {\u0026#34;name\u0026#34;:\u0026#34;col2\u0026#34;}, // 普通列 {\u0026#34;name\u0026#34;:\u0026#34;col3\u0026#34;}, // 普通列 {\u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;, \u0026#34;value\u0026#34; : \u0026#34;bazhen\u0026#34;}, // 常量列(字符串) {\u0026#34;type\u0026#34;:\u0026#34;INT\u0026#34;, \u0026#34;value\u0026#34; : \u0026#34;\u0026#34;}, // 常量列(整形) {\u0026#34;type\u0026#34;:\u0026#34;DOUBLE\u0026#34;, \u0026#34;value\u0026#34; : \u0026#34;\u0026#34;}, // 常量列(浮点) {\u0026#34;type\u0026#34;:\u0026#34;BOOL\u0026#34;, \u0026#34;value\u0026#34; : \u0026#34;\u0026#34;}, // 常量列(布尔) {\u0026#34;type\u0026#34;:\u0026#34;BINARY\u0026#34;, \u0026#34;value\u0026#34; : \u0026#34;Base64(bin)\u0026#34;} // 常量列(二进制),使用Base64编码完成 ], \u0026#34;range\u0026#34;:{ // 导出数据的起始范围 // 支持INF_MIN, INF_MAX, STRING, INT \u0026#34;begin\u0026#34;:[ {\u0026#34;type\u0026#34;:\u0026#34;INF_MIN\u0026#34;}, ], // 导出数据的结束范围 // 支持INF_MIN, INF_MAX, STRING, INT \u0026#34;end\u0026#34;:[ {\u0026#34;type\u0026#34;:\u0026#34;INF_MAX\u0026#34;}, ] } } }, \u0026#34;writer\u0026#34;: {} } ] } } 配置一个定义抽取范围的OTSReader： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;byte\u0026#34;:10485760 }, \u0026#34;errorLimit\u0026#34;:0.0 }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;otsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;accessId\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;accessKey\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;instanceName\u0026#34;:\u0026#34;\u0026#34;, // 导出数据表的表名 \u0026#34;table\u0026#34;:\u0026#34;\u0026#34;, // 需要导出的列名，支持重复类和常量列，区分大小写 // 常量列：类型支持STRING，INT，DOUBLE，BOOL和BINARY // 备注：BINARY需要通过Base64转换为对应的字符串传入插件 \u0026#34;column\u0026#34;:[ {\u0026#34;name\u0026#34;:\u0026#34;col1\u0026#34;}, // 普通列 {\u0026#34;name\u0026#34;:\u0026#34;col2\u0026#34;}, // 普通列 {\u0026#34;name\u0026#34;:\u0026#34;col3\u0026#34;}, // 普通列 {\u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;,\u0026#34;value\u0026#34; : \u0026#34;\u0026#34;}, // 常量列(字符串) {\u0026#34;type\u0026#34;:\u0026#34;INT\u0026#34;,\u0026#34;value\u0026#34; : \u0026#34;\u0026#34;}, // 常量列(整形) {\u0026#34;type\u0026#34;:\u0026#34;DOUBLE\u0026#34;,\u0026#34;value\u0026#34; : \u0026#34;\u0026#34;}, // 常量列(浮点) {\u0026#34;type\u0026#34;:\u0026#34;BOOL\u0026#34;,\u0026#34;value\u0026#34; : \u0026#34;\u0026#34;}, // 常量列(布尔) {\u0026#34;type\u0026#34;:\u0026#34;BINARY\u0026#34;,\u0026#34;value\u0026#34; : \u0026#34;Base64(bin)\u0026#34;} // 常量列(二进制) ], \u0026#34;range\u0026#34;:{ // 导出数据的起始范围 // 支持INF_MIN, INF_MAX, STRING, INT \u0026#34;begin\u0026#34;:[ {\u0026#34;type\u0026#34;:\u0026#34;INF_MIN\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;INF_MAX\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;hello\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;INT\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;2999\u0026#34;}, ], // 导出数据的结束范围 // 支持INF_MIN, INF_MAX, STRING, INT \u0026#34;end\u0026#34;:[ {\u0026#34;type\u0026#34;:\u0026#34;INF_MAX\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;INF_MIN\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;hello\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;INT\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;2999\u0026#34;}, ] } } }, \u0026#34;writer\u0026#34;: {} } ] } } 3.2 参数说明 endpoint\n描述：OTS Server的EndPoint地址，例如http://bazhen.cn−hangzhou.ots.aliyuncs.com。\n必选：是 默认值：无 accessId\n描述：OTS的accessId 必选：是 默认值：无 accessKey\n描述：OTS的accessKey 必选：是 默认值：无 instanceName\n描述：OTS的实例名称，实例是用户使用和管理 OTS 服务的实体，用户在开通 OTS 服务之后，需要通过管理控制台来创建实例，然后在实例内进行表的创建和管理。实例是 OTS 资源管理的基础单元，OTS 对应用程序的访问控制和资源计量都在实例级别完成。 必选：是 默认值：无 table\n描述：所选取的需要抽取的表名称，这里有且只能填写一张表。在OTS不存在多表同步的需求。\n必选：是 默认值：无 column\n描述：所配置的表中需要同步的列名集合，使用JSON的数组描述字段信息。由于OTS本身是NoSQL系统，在OTSReader抽取数据过程中，必须指定相应地字段名称。\n支持普通的列读取，例如: {\u0026ldquo;name\u0026rdquo;:\u0026ldquo;col1\u0026rdquo;}\n支持部分列读取，如用户不配置该列，则OTSReader不予读取。\n支持常量列读取，例如: {\u0026ldquo;type\u0026rdquo;:\u0026ldquo;STRING\u0026rdquo;, \u0026ldquo;value\u0026rdquo; : \u0026ldquo;DataX\u0026rdquo;}。使用type描述常量类型，目前支持STRING、INT、DOUBLE、BOOL、BINARY(用户使用Base64编码填写)、INF_MIN(OTS的系统限定最小值，使用该值用户不能填写value属性，否则报错)、INF_MAX(OTS的系统限定最大值，使用该值用户不能填写value属性，否则报错)。\n不支持函数或者自定义表达式，由于OTS本身不提供类似SQL的函数或者表达式功能，OTSReader也不能提供函数或表达式列功能。\n必选：是 默认值：无 begin/end\n描述：该配置项必须配对使用，用于支持OTS表范围抽取。begin/end中描述的是OTS PrimaryKey的区间分布状态，而且必须保证区间覆盖到所有的PrimaryKey，需要指定该表下所有的PrimaryKey范围，不能遗漏任意一个PrimaryKey，对于无限大小的区间，可以使用{\u0026ldquo;type\u0026rdquo;:\u0026ldquo;INF_MIN\u0026rdquo;}，{\u0026ldquo;type\u0026rdquo;:\u0026ldquo;INF_MAX\u0026rdquo;}指代。例如对一张主键为 [DeviceID, SellerID]的OTS进行抽取任务，begin/end可以配置为: \u0026#34;range\u0026#34;: { \u0026#34;begin\u0026#34;: { {\u0026#34;type\u0026#34;:\u0026#34;INF_MIN\u0026#34;}, //指定deviceID最小值 {\u0026#34;type\u0026#34;:\u0026#34;INT\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;0\u0026#34;} //指定deviceID最小值 }, \u0026#34;end\u0026#34;: { {\u0026#34;type\u0026#34;:\u0026#34;INF_MAX\u0026#34;}, //指定deviceID抽取最大值 {\u0026#34;type\u0026#34;:\u0026#34;INT\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;9999\u0026#34;} //指定deviceID抽取最大值 } } 如果要对上述表抽取全表，可以使用如下配置： \u0026#34;range\u0026#34;: { \u0026#34;begin\u0026#34;: [ {\u0026#34;type\u0026#34;:\u0026#34;INF_MIN\u0026#34;}, //指定deviceID最小值 {\u0026#34;type\u0026#34;:\u0026#34;INF_MIN\u0026#34;} //指定SellerID最小值 ], \u0026#34;end\u0026#34;: [ {\u0026#34;type\u0026#34;:\u0026#34;INF_MAX\u0026#34;}, //指定deviceID抽取最大值 {\u0026#34;type\u0026#34;:\u0026#34;INF_MAX\u0026#34;} //指定SellerID抽取最大值 ] } 必选：是 默认值：空 split\n描述：该配置项属于高级配置项，是用户自己定义切分配置信息，普通情况下不建议用户使用。适用场景通常在OTS数据存储发生热点，使用OTSReader自动切分的策略不能生效情况下，使用用户自定义的切分规则。split指定是的在Begin、End区间内的切分点，且只能是partitionKey的切分点信息，即在split仅配置partitionKey，而不需要指定全部的PrimaryKey。\n例如对一张主键为 [DeviceID, SellerID]的OTS进行抽取任务，可以配置为:\n\u0026#34;range\u0026#34;: { \u0026#34;begin\u0026#34;: { {\u0026#34;type\u0026#34;:\u0026#34;INF_MIN\u0026#34;}, //指定deviceID最小值 {\u0026#34;type\u0026#34;:\u0026#34;INF_MIN\u0026#34;} //指定deviceID最小值 }, \u0026#34;end\u0026#34;: { {\u0026#34;type\u0026#34;:\u0026#34;INF_MAX\u0026#34;}, //指定deviceID抽取最大值 {\u0026#34;type\u0026#34;:\u0026#34;INF_MAX\u0026#34;} //指定deviceID抽取最大值 }， // 用户指定的切分点，如果指定了切分点，Job将按照begin、end和split进行Task的切分， // 切分的列只能是Partition Key（ParimaryKey的第一列） // 支持INF_MIN, INF_MAX, STRING, INT \u0026#34;split\u0026#34;:[ {\u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;1\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;2\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;3\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;4\u0026#34;}, {\u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;, \u0026#34;value\u0026#34;:\u0026#34;5\u0026#34;} ] } 必选：否 默认值：无 3.3 类型转换 目前OTSReader支持所有OTS类型，下面列出OTSReader针对OTS类型转换列表:\nDataX 内部类型 OTS 数据类型 Long Integer Double Double String String Boolean Boolean Bytes Binary 注意，OTS本身不支持日期型类型。应用层一般使用Long报错时间的Unix TimeStamp。 4 性能报告 4.1 环境准备 4.1.1 数据特征 15列String(10 Byte), 2两列Integer(8 Byte)，总计168Byte/r。\n4.1.2 机器参数 OTS端：3台前端机，5台后端机\nDataX运行端: 24核CPU， 98GB内存\n4.1.3 DataX jvm 参数 -Xms1024m -Xmx1024m -XX:+HeapDumpOnOutOfMemoryError 4.2 测试报告 4.2.1 测试报告 并发数 DataX CPU OTS 流量 DATAX流量 前端QPS 前端延时 2 36% 6.3M/s 12739 rec/s 4.7 308ms 11 155% 32M/s 60732 rec/s 23.9 412ms 50 377% 73M/s 145139 rec/s 54 874ms 100 448% 82M/s 156262 rec/s 60 1570ms 5 约束限制 5.1 一致性约束 OTS是类BigTable的存储系统，OTS本身能够保证单行写事务性，无法提供跨行级别的事务。对于OTSReader而言也无法提供全表的一致性视图。例如对于OTSReader在0点启动的数据同步任务，在整个表数据同步过程中，OTSReader同样会抽取到后续更新的数据，无法提供准确的0点时刻该表一致性视图。\n5.2 增量数据同步 OTS本质上KV存储，目前只能针对PK进行范围查询，暂不支持按照字段范围抽取数据。因此只能对于增量查询，如果PK能够表示范围信息，例如自增ID，或者时间戳。\n自增ID，OTSReader可以通过记录上次最大的ID信息，通过指定Range范围进行增量抽取。这样使用的前提是OTS中的PrimaryKey必须包含主键自增列(自增主键需要使用OTS应用方生成。)\n时间戳，\tOTSReader可以通过PK过滤时间戳，通过制定Range范围进行增量抽取。这样使用的前提是OTS中的PrimaryKey必须包含主键时间列(时间主键需要使用OTS应用方生成。)\n6 FAQ ","permalink":"https://haokiu.com/blog/2dc5ba5f4d58498e8453bd2d8efde079/","summary":"OTSReader 插件文档 1 快速介绍 OTSReader插件实现了从OTS读取数据，并可以通过用户指定抽取数据范围可方便的实现数据增量抽取的需求。目前支持三种抽取方式：\n全表抽取 范围抽取 指定分片抽取 OTS是构建在阿里云飞天分布式系统之上的 NoSQL数据库服务，提供海量结构化数据的存储和实时访问。OTS 以实例和表的形式组织数据，通过数据分片和负载均衡技术，实现规模上的无缝扩展。\n2 实现原理 简而言之，OTSReader通过OTS官方Java SDK连接到OTS服务端，获取并按照DataX官方协议标准转为DataX字段信息传递给下游Writer端。\nOTSReader会根据OTS的表范围，按照Datax并发的数目N，将范围等分为N份Task。每个Task都会有一个OTSReader线程来执行。\n3 功能说明 3.1 配置样例 配置一个从OTS全表同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;otsreader\u0026#34;, \u0026#34;parameter\u0026#34;: { /* ----------- 必填 --------------*/ \u0026#34;endpoint\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;accessId\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;accessKey\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;instanceName\u0026#34;:\u0026#34;\u0026#34;, // 导出数据表的表名 \u0026#34;table\u0026#34;:\u0026#34;\u0026#34;, // 需要导出的列名，支持重复列和常量列，区分大小写 // 常量列：类型支持STRING，INT，DOUBLE，BOOL和BINARY // 备注：BINARY需要通过Base64转换为对应的字符串传入插件 \u0026#34;column\u0026#34;:[ {\u0026#34;name\u0026#34;:\u0026#34;col1\u0026#34;}, // 普通列 {\u0026#34;name\u0026#34;:\u0026#34;col2\u0026#34;}, // 普通列 {\u0026#34;name\u0026#34;:\u0026#34;col3\u0026#34;}, // 普通列 {\u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;, \u0026#34;value\u0026#34; : \u0026#34;bazhen\u0026#34;}, // 常量列(字符串) {\u0026#34;type\u0026#34;:\u0026#34;INT\u0026#34;, \u0026#34;value\u0026#34; : \u0026#34;\u0026#34;}, // 常量列(整形) {\u0026#34;type\u0026#34;:\u0026#34;DOUBLE\u0026#34;, \u0026#34;value\u0026#34; : \u0026#34;\u0026#34;}, // 常量列(浮点) {\u0026#34;type\u0026#34;:\u0026#34;BOOL\u0026#34;, \u0026#34;value\u0026#34; : \u0026#34;\u0026#34;}, // 常量列(布尔) {\u0026#34;type\u0026#34;:\u0026#34;BINARY\u0026#34;, \u0026#34;value\u0026#34; : \u0026#34;Base64(bin)\u0026#34;} // 常量列(二进制),使用Base64编码完成 ], \u0026#34;range\u0026#34;:{ // 导出数据的起始范围 // 支持INF_MIN, INF_MAX, STRING, INT \u0026#34;begin\u0026#34;:[ {\u0026#34;type\u0026#34;:\u0026#34;INF_MIN\u0026#34;}, ], // 导出数据的结束范围 // 支持INF_MIN, INF_MAX, STRING, INT \u0026#34;end\u0026#34;:[ {\u0026#34;type\u0026#34;:\u0026#34;INF_MAX\u0026#34;}, ] } } }, \u0026#34;writer\u0026#34;: {} } ] } } 配置一个定义抽取范围的OTSReader： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;byte\u0026#34;:10485760 }, \u0026#34;errorLimit\u0026#34;:0.","title":"OTSReader 插件文档"},{"content":"OTSWriter 插件文档 1 快速介绍 OTSWriter插件实现了向OTS写入数据，目前支持三种写入方式：\nPutRow，对应于OTS API PutRow，插入数据到指定的行，如果该行不存在，则新增一行；若该行存在，则覆盖原有行。\nUpdateRow，对应于OTS API UpdateRow，更新指定行的数据，如果该行不存在，则新增一行；若该行存在，则根据请求的内容在这一行中新增、修改或者删除指定列的值。\nDeleteRow，对应于OTS API DeleteRow，删除指定行的数据。\nOTS是构建在阿里云飞天分布式系统之上的 NoSQL数据库服务，提供海量结构化数据的存储和实时访问。OTS 以实例和表的形式组织数据，通过数据分片和负载均衡技术，实现规模上的无缝扩展。\n2 实现原理 简而言之，OTSWriter通过OTS官方Java SDK连接到OTS服务端，并通过SDK写入OTS服务端。OTSWriter本身对于写入过程做了很多优化，包括写入超时重试、异常写入重试、批量提交等Feature。\n3 功能说明 3.1 配置样例 配置一个写入OTS作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: {}, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;otswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;accessId\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;accessKey\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;instanceName\u0026#34;:\u0026#34;\u0026#34;, // 导出数据表的表名 \u0026#34;table\u0026#34;:\u0026#34;\u0026#34;, // Writer支持不同类型之间进行相互转换 // 如下类型转换不支持: // ================================ // int -\u0026gt; binary // double -\u0026gt; bool, binary // bool -\u0026gt; binary // bytes -\u0026gt; int, double, bool // ================================ // 需要导入的PK列名，区分大小写 // 类型支持：STRING，INT // 1. 支持类型转换，注意类型转换时的精度丢失 // 2. 顺序不要求和表的Meta一致 \u0026#34;primaryKey\u0026#34; : [ {\u0026#34;name\u0026#34;:\u0026#34;pk1\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;pk2\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;int\u0026#34;} ], // 需要导入的列名，区分大小写 // 类型支持STRING，INT，DOUBLE，BOOL和BINARY \u0026#34;column\u0026#34; : [ {\u0026#34;name\u0026#34;:\u0026#34;col2\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;INT\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;col3\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;col4\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;col5\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;BINARY\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;col6\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;DOUBLE\u0026#34;} ], // 写入OTS的方式 // PutRow : 等同于OTS API中PutRow操作，检查条件是ignore // UpdateRow : 等同于OTS API中UpdateRow操作，检查条件是ignore // DeleteRow: 等同于OTS API中DeleteRow操作，检查条件是ignore \u0026#34;writeMode\u0026#34; : \u0026#34;PutRow\u0026#34; } } } ] } } 3.2 参数说明 endpoint\n描述：OTS Server的EndPoint(服务地址)，例如http://bazhen.cn−hangzhou.ots.aliyuncs.com。\n必选：是 默认值：无 accessId\n描述：OTS的accessId 必选：是 默认值：无 accessKey\n描述：OTS的accessKey 必选：是 默认值：无 instanceName\n描述：OTS的实例名称，实例是用户使用和管理 OTS 服务的实体，用户在开通 OTS 服务之后，需要通过管理控制台来创建实例，然后在实例内进行表的创建和管理。实例是 OTS 资源管理的基础单元，OTS 对应用程序的访问控制和资源计量都在实例级别完成。 必选：是 默认值：无 table\n描述：所选取的需要抽取的表名称，这里有且只能填写一张表。在OTS不存在多表同步的需求。\n必选：是 默认值：无 primaryKey\n描述: OTS的主键信息，使用JSON的数组描述字段信息。OTS本身是NoSQL系统，在OTSWriter导入数据过程中，必须指定相应地字段名称。\nOTS的PrimaryKey只能支持STRING，INT两种类型，因此OTSWriter本身也限定填写上述两种类型。\nDataX本身支持类型转换的，因此对于源头数据非String/Int，OTSWriter会进行数据类型转换。\n配置实例:\n\u0026#34;primaryKey\u0026#34; : [ {\u0026#34;name\u0026#34;:\u0026#34;pk1\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;pk2\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;int\u0026#34;} ], 必选：是 默认值：无 column\n描述：所配置的表中需要同步的列名集合，使用JSON的数组描述字段信息。使用格式为\n{\u0026#34;name\u0026#34;:\u0026#34;col2\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;INT\u0026#34;}, 其中的name指定写入的OTS列名，type指定写入的类型。OTS类型支持STRING，INT，DOUBLE，BOOL和BINARY几种类型 。\n写入过程不支持常量、函数或者自定义表达式。\n必选：是 默认值：无 writeMode\n描述：写入模式，目前支持两种模式，\nPutRow，对应于OTS API PutRow，插入数据到指定的行，如果该行不存在，则新增一行；若该行存在，则覆盖原有行。\nUpdateRow，对应于OTS API UpdateRow，更新指定行的数据，如果该行不存在，则新增一行；若该行存在，则根据请求的内容在这一行中新增、修改或者删除指定列的值。\nDeleteRow，对应于OTS API DeleteRow，删除指定行的数据。\n必选：是 默认值：无 3.3 类型转换 目前OTSWriter支持所有OTS类型，下面列出OTSWriter针对OTS类型转换列表:\nDataX 内部类型 OTS 数据类型 Long Integer Double Double String String Boolean Boolean Bytes Binary 注意，OTS本身不支持日期型类型。应用层一般使用Long报错时间的Unix TimeStamp。 4 性能报告 4.1 环境准备 4.1.1 数据特征 2列PK（10 + 8），15列String(10 Byte), 2两列Integer(8 Byte)，算上Column Name每行大概327Byte，每次BatchWriteRow写入100行数据，所以当个请求的数据大小是32KB。\n4.1.2 机器参数 OTS端：3台前端机，5台后端机\nDataX运行端: 24核CPU， 98GB内存\n4.2 测试报告 4.2.1 测试报告 并发数 DataX CPU DATAX流量 OTS 流量 BatchWrite前端QPS BatchWriteRow前端延时 40 1027% Speed 22.13MB/s, 112640 records/s 65.8M/s 42 153ms 50 1218% Speed 24.11MB/s, 122700 records/s 73.5M/s 47 174ms 60 1355% Speed 25.31MB/s, 128854 records/s 78.1M/s 50 190ms 70 1578% Speed 26.35MB/s, 134121 records/s 80.8M/s 52 210ms 80 1771% Speed 26.55MB/s, 135161 records/s 82.7M/s 53 230ms 5 约束限制 5.1 写入幂等性 OTS写入本身是支持幂等性的，也就是使用OTS SDK同一条数据写入OTS系统，一次和多次请求的结果可以理解为一致的。因此对于OTSWriter多次尝试写入同一条数据与写入一条数据结果是等同的。\n5.2 单任务FailOver 由于OTS写入本身是幂等性的，因此可以支持单任务FailOver。即一旦写入Fail，DataX会重新启动相关子任务进行重试。\n6 FAQ ","permalink":"https://haokiu.com/blog/7d2496e6853044daa824d7a78226b07d/","summary":"OTSWriter 插件文档 1 快速介绍 OTSWriter插件实现了向OTS写入数据，目前支持三种写入方式：\nPutRow，对应于OTS API PutRow，插入数据到指定的行，如果该行不存在，则新增一行；若该行存在，则覆盖原有行。\nUpdateRow，对应于OTS API UpdateRow，更新指定行的数据，如果该行不存在，则新增一行；若该行存在，则根据请求的内容在这一行中新增、修改或者删除指定列的值。\nDeleteRow，对应于OTS API DeleteRow，删除指定行的数据。\nOTS是构建在阿里云飞天分布式系统之上的 NoSQL数据库服务，提供海量结构化数据的存储和实时访问。OTS 以实例和表的形式组织数据，通过数据分片和负载均衡技术，实现规模上的无缝扩展。\n2 实现原理 简而言之，OTSWriter通过OTS官方Java SDK连接到OTS服务端，并通过SDK写入OTS服务端。OTSWriter本身对于写入过程做了很多优化，包括写入超时重试、异常写入重试、批量提交等Feature。\n3 功能说明 3.1 配置样例 配置一个写入OTS作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: {}, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;otswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;accessId\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;accessKey\u0026#34;:\u0026#34;\u0026#34;, \u0026#34;instanceName\u0026#34;:\u0026#34;\u0026#34;, // 导出数据表的表名 \u0026#34;table\u0026#34;:\u0026#34;\u0026#34;, // Writer支持不同类型之间进行相互转换 // 如下类型转换不支持: // ================================ // int -\u0026gt; binary // double -\u0026gt; bool, binary // bool -\u0026gt; binary // bytes -\u0026gt; int, double, bool // ================================ // 需要导入的PK列名，区分大小写 // 类型支持：STRING，INT // 1. 支持类型转换，注意类型转换时的精度丢失 // 2. 顺序不要求和表的Meta一致 \u0026#34;primaryKey\u0026#34; : [ {\u0026#34;name\u0026#34;:\u0026#34;pk1\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;string\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;pk2\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;int\u0026#34;} ], // 需要导入的列名，区分大小写 // 类型支持STRING，INT，DOUBLE，BOOL和BINARY \u0026#34;column\u0026#34; : [ {\u0026#34;name\u0026#34;:\u0026#34;col2\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;INT\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;col3\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;col4\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;STRING\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;col5\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;BINARY\u0026#34;}, {\u0026#34;name\u0026#34;:\u0026#34;col6\u0026#34;, \u0026#34;type\u0026#34;:\u0026#34;DOUBLE\u0026#34;} ], // 写入OTS的方式 // PutRow : 等同于OTS API中PutRow操作，检查条件是ignore // UpdateRow : 等同于OTS API中UpdateRow操作，检查条件是ignore // DeleteRow: 等同于OTS API中DeleteRow操作，检查条件是ignore \u0026#34;writeMode\u0026#34; : \u0026#34;PutRow\u0026#34; } } } ] } } 3.","title":"OTSWriter 插件文档"},{"content":"PostgresqlReader 插件文档 1 快速介绍 PostgresqlReader插件实现了从PostgreSQL读取数据。在底层实现上，PostgresqlReader通过JDBC连接远程PostgreSQL数据库，并执行相应的sql语句将数据从PostgreSQL库中SELECT出来。\n2 实现原理 简而言之，PostgresqlReader通过JDBC连接器连接到远程的PostgreSQL数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程PostgreSQL数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，PostgresqlReader将其拼接为SQL语句发送到PostgreSQL数据库；对于用户配置querySql信息，PostgresqlReader直接将其发送到PostgreSQL数据库。\n3 功能说明 3.1 配置样例 配置一个从PostgreSQL数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度，单位为byte/s，DataX运行会尽可能达到该速度但是不超过它. \u0026#34;byte\u0026#34;: 1048576 }, //出错限制 \u0026#34;errorLimit\u0026#34;: { //出错的record条数上限，当大于该值即报错。 \u0026#34;record\u0026#34;: 0, //出错的record百分比上限 1.0表示100%，0.02表示2% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;postgresqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { // 数据库连接用户名 \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, // 数据库连接密码 \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;，\u0026#34;name\u0026#34; ], //切分主键 \u0026#34;splitPk\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:postgresql://host:port/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, //是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true, } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: 1048576 }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;postgresqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;where\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10;\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:postgresql://host:port/database\u0026#34;, \u0026#34;jdbc:postgresql://host:port/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.2 参数说明 jdbcUrl\n描述：描述的是到对端数据库的JDBC连接信息，使用JSON的数组描述，并支持一个库填写多个连接地址。之所以使用JSON数组描述连接信息，是因为阿里集团内部支持多个IP探测，如果配置了多个，PostgresqlReader可以依次探测ip的可连接性，直到选择一个合法的IP。如果全部连接失败，PostgresqlReader报错。 注意，jdbcUrl必须包含在connection配置单元中。对于阿里集团外部使用情况，JSON数组填写一个JDBC连接即可。\njdbcUrl按照PostgreSQL官方规范，并可以填写连接附件控制信息。具体请参看PostgreSQL官方文档。\n必选：是 默认值：无 username\n描述：数据源的用户名 必选：是 默认值：无 password\n描述：数据源指定用户名的密码 必选：是 默认值：无 table\n描述：所选取的需要同步的表。使用JSON的数组描述，因此支持多张表同时抽取。当配置为多张表时，用户自己需保证多张表是同一schema结构，PostgresqlReader不予检查表是否同一逻辑表。注意，table必须包含在connection配置单元中。\n必选：是 默认值：无 column\n描述：所配置的表中需要同步的列名集合，使用JSON的数组描述字段信息。用户使用*代表默认使用所有列配置，例如[\u0026rsquo;*\u0026rsquo;]。\n支持列裁剪，即列可以挑选部分列进行导出。\n支持列换序，即列可以不按照表schema信息进行导出。\n支持常量配置，用户需要按照PostgreSQL语法格式: [\u0026ldquo;id\u0026rdquo;, \u0026ldquo;\u0026lsquo;hello\u0026rsquo;::varchar\u0026rdquo;, \u0026ldquo;true\u0026rdquo;, \u0026ldquo;2.5::real\u0026rdquo;, \u0026ldquo;power(2,3)\u0026rdquo;] id为普通列名，\u0026lsquo;hello\u0026rsquo;::varchar为字符串常量，true为布尔值，2.5为浮点数, power(2,3)为函数。\ncolumn必须用户显示指定同步的列集合，不允许为空！\n必选：是 默认值：无 splitPk\n描述：PostgresqlReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。\n推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。\n目前splitPk仅支持整形数据切分，不支持浮点、字符串型、日期等其他类型。如果用户指定其他非支持类型，PostgresqlReader将报错！\nsplitPk设置为空，底层将视作用户不允许对单表进行切分，因此使用单通道进行抽取。\n必选：否 默认值：空 where\n描述：筛选条件，MysqlReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create \u0026gt; $bizdate 。注意：不可以将where条件指定为limit 10，limit不是SQL的合法where子句。\nwhere条件可以有效地进行业务增量同步。\twhere条件不配置或者为空，视作全表同步数据。 必选：否 默认值：无 querySql\n描述：在有些业务场景下，where这一配置项不足以描述所筛选的条件，用户可以通过该配置型来自定义筛选SQL。当用户配置了这一项之后，DataX系统就会忽略table，column这些配置型，直接使用这个配置项的内容对数据进行筛选，例如需要进行多表join后同步数据，使用select a,b from table_a join table_b on table_a.id = table_b.id 当用户配置querySql时，PostgresqlReader直接忽略table、column、where条件的配置。\n必选：否 默认值：无 fetchSize\n描述：该配置项定义了插件和数据库服务器端每次批量数据获取条数，该值决定了DataX和服务器端的网络交互次数，能够较大的提升数据抽取性能。 注意，该值过大(\u0026gt;2048)可能造成DataX进程OOM。。\n必选：否 默认值：1024 3.3 类型转换 目前PostgresqlReader支持大部分PostgreSQL类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出PostgresqlReader针对PostgreSQL类型转换列表:\nDataX 内部类型 PostgreSQL 数据类型 Long bigint, bigserial, integer, smallint, serial Double double precision, money, numeric, real String varchar, char, text, bit, inet Date date, time, timestamp Boolean bool Bytes bytea 请注意:\n除上述罗列字段类型外，其他类型均不支持; money,inet,bit需用户使用a_inet::varchar类似的语法转换。 4 性能报告 4.1 环境准备 4.1.1 数据特征 建表语句：\ncreate table pref_test( id serial, a_bigint bigint, a_bit bit(10), a_boolean boolean, a_char character(5), a_date date, a_double double precision, a_integer integer, a_money money, a_num numeric(10,2), a_real real, a_smallint smallint, a_text text, a_time time, a_timestamp timestamp )\n4.1.2 机器参数 执行DataX的机器参数为:\ncpu: 16核 Intel(R) Xeon(R) CPU E5620 @ 2.40GHz mem: MemTotal: 24676836kB MemFree: 6365080kB net: 百兆双网卡 PostgreSQL数据库机器参数为: D12 24逻辑核 192G内存 12*480G SSD 阵列\n4.2 测试报告 4.2.1 单表测试报告 通道数 是否按照主键切分 DataX速度(Rec/s) DataX流量(MB/s) DataX机器运行负载 1 否 10211 0.63 0.2 1 是 10211 0.63 0.2 4 否 10211 0.63 0.2 4 是 40000 2.48 0.5 8 否 10211 0.63 0.2 8 是 78048 4.84 0.8 说明：\n这里的单表，主键类型为 serial，数据分布均匀。 对单表如果没有按照主键切分，那么配置通道个数不会提升速度，效果与1个通道一样。 ","permalink":"https://haokiu.com/blog/0adf103bd70440a1978ecbcc7dd63787/","summary":"PostgresqlReader 插件文档 1 快速介绍 PostgresqlReader插件实现了从PostgreSQL读取数据。在底层实现上，PostgresqlReader通过JDBC连接远程PostgreSQL数据库，并执行相应的sql语句将数据从PostgreSQL库中SELECT出来。\n2 实现原理 简而言之，PostgresqlReader通过JDBC连接器连接到远程的PostgreSQL数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程PostgreSQL数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，PostgresqlReader将其拼接为SQL语句发送到PostgreSQL数据库；对于用户配置querySql信息，PostgresqlReader直接将其发送到PostgreSQL数据库。\n3 功能说明 3.1 配置样例 配置一个从PostgreSQL数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { //设置传输速度，单位为byte/s，DataX运行会尽可能达到该速度但是不超过它. \u0026#34;byte\u0026#34;: 1048576 }, //出错限制 \u0026#34;errorLimit\u0026#34;: { //出错的record条数上限，当大于该值即报错。 \u0026#34;record\u0026#34;: 0, //出错的record百分比上限 1.0表示100%，0.02表示2% \u0026#34;percentage\u0026#34;: 0.02 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;postgresqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { // 数据库连接用户名 \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, // 数据库连接密码 \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34;，\u0026#34;name\u0026#34; ], //切分主键 \u0026#34;splitPk\u0026#34;: \u0026#34;id\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:postgresql://host:port/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { //writer类型 \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, //是否打印内容 \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;:true, } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: 1048576 }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;postgresqlreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;xx\u0026#34;, \u0026#34;where\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10;\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:postgresql://host:port/database\u0026#34;, \u0026#34;jdbc:postgresql://host:port/database\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.","title":"PostgresqlReader 插件文档"},{"content":"RDBMSReader 插件文档 1 快速介绍 RDBMSReader插件实现了从RDBMS读取数据。在底层实现上，RDBMSReader通过JDBC连接远程RDBMS数据库，并执行相应的sql语句将数据从RDBMS库中SELECT出来。目前支持达梦、db2、PPAS、Sybase数据库的读取。RDBMSReader是一个通用的关系数据库读插件，您可以通过注册数据库驱动等方式增加任意多样的关系数据库读支持。\n2 实现原理 简而言之，RDBMSReader通过JDBC连接器连接到远程的RDBMS数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程RDBMS数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，RDBMSReader将其拼接为SQL语句发送到RDBMS数据库；对于用户配置querySql信息，RDBMS直接将其发送到RDBMS数据库。\n3 功能说明 3.1 配置样例 配置一个从RDBMS数据库同步抽取数据作业: {\r\u0026#34;job\u0026#34;: {\r\u0026#34;setting\u0026#34;: {\r\u0026#34;speed\u0026#34;: {\r\u0026#34;byte\u0026#34;: 1048576\r},\r\u0026#34;errorLimit\u0026#34;: {\r\u0026#34;record\u0026#34;: 0,\r\u0026#34;percentage\u0026#34;: 0.02\r}\r},\r\u0026#34;content\u0026#34;: [\r{\r\u0026#34;reader\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;rdbmsreader\u0026#34;,\r\u0026#34;parameter\u0026#34;: {\r\u0026#34;username\u0026#34;: \u0026#34;xxx\u0026#34;,\r\u0026#34;password\u0026#34;: \u0026#34;xxx\u0026#34;,\r\u0026#34;column\u0026#34;: [\r\u0026#34;id\u0026#34;,\r\u0026#34;name\u0026#34;\r],\r\u0026#34;splitPk\u0026#34;: \u0026#34;pk\u0026#34;,\r\u0026#34;connection\u0026#34;: [\r{\r\u0026#34;table\u0026#34;: [\r\u0026#34;table\u0026#34;\r],\r\u0026#34;jdbcUrl\u0026#34;: [\r\u0026#34;jdbc:dm://ip:port/database\u0026#34;\r]\r}\r],\r\u0026#34;fetchSize\u0026#34;: 1024,\r\u0026#34;where\u0026#34;: \u0026#34;1 = 1\u0026#34;\r}\r},\r\u0026#34;writer\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;,\r\u0026#34;parameter\u0026#34;: {\r\u0026#34;print\u0026#34;: true\r}\r}\r}\r]\r}\r} 配置一个自定义SQL的数据库同步任务到ODPS的作业： {\r\u0026#34;job\u0026#34;: {\r\u0026#34;setting\u0026#34;: {\r\u0026#34;speed\u0026#34;: {\r\u0026#34;byte\u0026#34;: 1048576\r},\r\u0026#34;errorLimit\u0026#34;: {\r\u0026#34;record\u0026#34;: 0,\r\u0026#34;percentage\u0026#34;: 0.02\r}\r},\r\u0026#34;content\u0026#34;: [\r{\r\u0026#34;reader\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;rdbmsreader\u0026#34;,\r\u0026#34;parameter\u0026#34;: {\r\u0026#34;username\u0026#34;: \u0026#34;xxx\u0026#34;,\r\u0026#34;password\u0026#34;: \u0026#34;xxx\u0026#34;,\r\u0026#34;column\u0026#34;: [\r\u0026#34;id\u0026#34;,\r\u0026#34;name\u0026#34;\r],\r\u0026#34;splitPk\u0026#34;: \u0026#34;pk\u0026#34;,\r\u0026#34;connection\u0026#34;: [\r{\r\u0026#34;querySql\u0026#34;: [\r\u0026#34;SELECT * from dual\u0026#34;\r],\r\u0026#34;jdbcUrl\u0026#34;: [\r\u0026#34;jdbc:dm://ip:port/database\u0026#34;\r]\r}\r],\r\u0026#34;fetchSize\u0026#34;: 1024,\r\u0026#34;where\u0026#34;: \u0026#34;1 = 1\u0026#34;\r}\r},\r\u0026#34;writer\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;,\r\u0026#34;parameter\u0026#34;: {\r\u0026#34;print\u0026#34;: true\r}\r}\r}\r]\r}\r} 3.2 参数说明 jdbcUrl\n描述：描述的是到对端数据库的JDBC连接信息，jdbcUrl按照RDBMS官方规范，并可以填写连接附件控制信息。请注意不同的数据库jdbc的格式是不同的，DataX会根据具体jdbc的格式选择合适的数据库驱动完成数据读取。\n达梦 jdbc:dm://ip:port/database db2格式 jdbc:db2://ip:port/database PPAS格式 jdbc:edb://ip:port/database rdbmswriter如何增加新的数据库支持:\n进入rdbmsreader对应目录，这里${DATAX_HOME}为DataX主目录，即: ${DATAX_HOME}/plugin/reader/rdbmswriter 在rdbmsreader插件目录下有plugin.json配置文件，在此文件中注册您具体的数据库驱动，具体放在drivers数组中。rdbmsreader插件在任务执行时会动态选择合适的数据库驱动连接数据库。 {\r\u0026#34;name\u0026#34;: \u0026#34;rdbmsreader\u0026#34;,\r\u0026#34;class\u0026#34;: \u0026#34;com.alibaba.datax.plugin.reader.rdbmsreader.RdbmsReader\u0026#34;,\r\u0026#34;description\u0026#34;: \u0026#34;useScene: prod. mechanism: Jdbc connection using the database, execute select sql, retrieve data from the ResultSet. warn: The more you know about the database, the less problems you encounter.\u0026#34;,\r\u0026#34;developer\u0026#34;: \u0026#34;alibaba\u0026#34;,\r\u0026#34;drivers\u0026#34;: [\r\u0026#34;dm.jdbc.driver.DmDriver\u0026#34;,\r\u0026#34;com.ibm.db2.jcc.DB2Driver\u0026#34;,\r\u0026#34;com.sybase.jdbc3.jdbc.SybDriver\u0026#34;,\r\u0026#34;com.edb.Driver\u0026#34;\r]\r} 在rdbmsreader插件目录下有libs子目录，您需要将您具体的数据库驱动放到libs目录下。 $tree\r.\r|-- libs\r| |-- Dm7JdbcDriver16.jar\r| |-- commons-collections-3.0.jar\r| |-- commons-io-2.4.jar\r| |-- commons-lang3-3.3.2.jar\r| |-- commons-math3-3.1.1.jar\r| |-- datax-common-0.0.1-SNAPSHOT.jar\r| |-- datax-service-face-1.0.23-20160120.024328-1.jar\r| |-- db2jcc4.jar\r| |-- druid-1.0.15.jar\r| |-- edb-jdbc16.jar\r| |-- fastjson-1.1.46.sec01.jar\r| |-- guava-r05.jar\r| |-- hamcrest-core-1.3.jar\r| |-- jconn3-1.0.0-SNAPSHOT.jar\r| |-- logback-classic-1.0.13.jar\r| |-- logback-core-1.0.13.jar\r| |-- plugin-rdbms-util-0.0.1-SNAPSHOT.jar\r| `-- slf4j-api-1.7.10.jar\r|-- plugin.json\r|-- plugin_job_template.json\r`-- rdbmsreader-0.0.1-SNAPSHOT.jar 必选：是 默认值：无 username\n描述：数据源的用户名。 必选：是 默认值：无 password\n描述：数据源指定用户名的密码。 必选：是 默认值：无 table\n描述：所选取的需要同步的表名。\n必选：是 默认值：无 column\n描述：所配置的表中需要同步的列名集合，使用JSON的数组描述字段信息。用户使用代表默认使用所有列配置，例如[\u0026rsquo;\u0026rsquo;]。\n支持列裁剪，即列可以挑选部分列进行导出。\n支持列换序，即列可以不按照表schema信息进行导出。\n支持常量配置，用户需要按照JSON格式: [\u0026ldquo;id\u0026rdquo;, \u0026ldquo;1\u0026rdquo;, \u0026ldquo;\u0026lsquo;bazhen.csy\u0026rsquo;\u0026rdquo;, \u0026ldquo;null\u0026rdquo;, \u0026ldquo;to_char(a + 1)\u0026rdquo;, \u0026ldquo;2.3\u0026rdquo; , \u0026ldquo;true\u0026rdquo;] id为普通列名，1为整形数字常量，\u0026lsquo;bazhen.csy\u0026rsquo;为字符串常量，null为空指针，to_char(a + 1)为表达式，2.3为浮点数，true为布尔值。\nColumn必须显示填写，不允许为空！\n必选：是 默认值：无 splitPk\n描述：RDBMSReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。\n推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。\n目前splitPk仅支持整形数据切分，不支持浮点、字符串型、日期等其他类型。如果用户指定其他非支持类型，RDBMSReader将报错！\nsplitPk如果不填写，将视作用户不对单表进行切分，RDBMSReader使用单通道同步全量数据。\n必选：否 默认值：空 where\n描述：筛选条件，RDBMSReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。例如在做测试时，可以将where条件指定为limit 10；在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create \u0026gt; $bizdate 。。\nwhere条件可以有效地进行业务增量同步。where条件不配置或者为空，视作全表同步数据。\r必选：否 默认值：无 querySql\n描述：在有些业务场景下，where这一配置项不足以描述所筛选的条件，用户可以通过该配置型来自定义筛选SQL。当用户配置了这一项之后，DataX系统就会忽略table，column这些配置型，直接使用这个配置项的内容对数据进行筛选，例如需要进行多表join后同步数据，使用select a,b from table_a join table_b on table_a.id = table_b.id 当用户配置querySql时，RDBMSReader直接忽略table、column、where条件的配置。\n必选：否 默认值：无 fetchSize\n描述：该配置项定义了插件和数据库服务器端每次批量数据获取条数，该值决定了DataX和服务器端的网络交互次数，能够较大的提升数据抽取性能。 注意，该值过大(\u0026gt;2048)可能造成DataX进程OOM。。\n必选：否 默认值：1024 3.3 类型转换 目前RDBMSReader支持大部分通用得关系数据库类型如数字、字符等，但也存在部分个别类型没有支持的情况，请注意检查你的类型，根据具体的数据库做选择。\n","permalink":"https://haokiu.com/blog/34c79077064f4502a247f840e8b64c46/","summary":"RDBMSReader 插件文档 1 快速介绍 RDBMSReader插件实现了从RDBMS读取数据。在底层实现上，RDBMSReader通过JDBC连接远程RDBMS数据库，并执行相应的sql语句将数据从RDBMS库中SELECT出来。目前支持达梦、db2、PPAS、Sybase数据库的读取。RDBMSReader是一个通用的关系数据库读插件，您可以通过注册数据库驱动等方式增加任意多样的关系数据库读支持。\n2 实现原理 简而言之，RDBMSReader通过JDBC连接器连接到远程的RDBMS数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程RDBMS数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，RDBMSReader将其拼接为SQL语句发送到RDBMS数据库；对于用户配置querySql信息，RDBMS直接将其发送到RDBMS数据库。\n3 功能说明 3.1 配置样例 配置一个从RDBMS数据库同步抽取数据作业: {\r\u0026#34;job\u0026#34;: {\r\u0026#34;setting\u0026#34;: {\r\u0026#34;speed\u0026#34;: {\r\u0026#34;byte\u0026#34;: 1048576\r},\r\u0026#34;errorLimit\u0026#34;: {\r\u0026#34;record\u0026#34;: 0,\r\u0026#34;percentage\u0026#34;: 0.02\r}\r},\r\u0026#34;content\u0026#34;: [\r{\r\u0026#34;reader\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;rdbmsreader\u0026#34;,\r\u0026#34;parameter\u0026#34;: {\r\u0026#34;username\u0026#34;: \u0026#34;xxx\u0026#34;,\r\u0026#34;password\u0026#34;: \u0026#34;xxx\u0026#34;,\r\u0026#34;column\u0026#34;: [\r\u0026#34;id\u0026#34;,\r\u0026#34;name\u0026#34;\r],\r\u0026#34;splitPk\u0026#34;: \u0026#34;pk\u0026#34;,\r\u0026#34;connection\u0026#34;: [\r{\r\u0026#34;table\u0026#34;: [\r\u0026#34;table\u0026#34;\r],\r\u0026#34;jdbcUrl\u0026#34;: [\r\u0026#34;jdbc:dm://ip:port/database\u0026#34;\r]\r}\r],\r\u0026#34;fetchSize\u0026#34;: 1024,\r\u0026#34;where\u0026#34;: \u0026#34;1 = 1\u0026#34;\r}\r},\r\u0026#34;writer\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;,\r\u0026#34;parameter\u0026#34;: {\r\u0026#34;print\u0026#34;: true\r}\r}\r}\r]\r}\r} 配置一个自定义SQL的数据库同步任务到ODPS的作业： {\r\u0026#34;job\u0026#34;: {\r\u0026#34;setting\u0026#34;: {\r\u0026#34;speed\u0026#34;: {\r\u0026#34;byte\u0026#34;: 1048576\r},\r\u0026#34;errorLimit\u0026#34;: {\r\u0026#34;record\u0026#34;: 0,\r\u0026#34;percentage\u0026#34;: 0.","title":"RDBMSReader 插件文档"},{"content":"RDBMSWriter 插件文档 1 快速介绍 RDBMSWriter 插件实现了写入数据到 RDBMS 主库的目的表的功能。在底层实现上， RDBMSWriter 通过 JDBC 连接远程 RDBMS 数据库，并执行相应的 insert into \u0026hellip; 的 sql 语句将数据写入 RDBMS。 RDBMSWriter是一个通用的关系数据库写插件，您可以通过注册数据库驱动等方式增加任意多样的关系数据库写支持。\nRDBMSWriter 面向ETL开发工程师，他们使用 RDBMSWriter 从数仓导入数据到 RDBMS。同时 RDBMSWriter 亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 RDBMSWriter 通过 DataX 框架获取 Reader 生成的协议数据，RDBMSWriter 通过 JDBC 连接远程 RDBMS 数据库，并执行相应的 insert into \u0026hellip; 的 sql 语句将数据写入 RDBMS。\n3 功能说明 3.1 配置样例 配置一个写入RDBMS的作业。 {\r\u0026#34;job\u0026#34;: {\r\u0026#34;setting\u0026#34;: {\r\u0026#34;speed\u0026#34;: {\r\u0026#34;channel\u0026#34;: 1\r}\r},\r\u0026#34;content\u0026#34;: [\r{\r\u0026#34;reader\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;,\r\u0026#34;parameter\u0026#34;: {\r\u0026#34;column\u0026#34;: [\r{\r\u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;\r},\r{\r\u0026#34;value\u0026#34;: 19880808,\r\u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;\r},\r{\r\u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;\r},\r{\r\u0026#34;value\u0026#34;: true,\r\u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34;\r},\r{\r\u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34;\r}\r],\r\u0026#34;sliceRecordCount\u0026#34;: 1000\r}\r},\r\u0026#34;writer\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;rdbmswriter\u0026#34;,\r\u0026#34;parameter\u0026#34;: {\r\u0026#34;connection\u0026#34;: [\r{\r\u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:dm://ip:port/database\u0026#34;,\r\u0026#34;table\u0026#34;: [\r\u0026#34;table\u0026#34;\r]\r}\r],\r\u0026#34;username\u0026#34;: \u0026#34;username\u0026#34;,\r\u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;,\r\u0026#34;table\u0026#34;: \u0026#34;table\u0026#34;,\r\u0026#34;column\u0026#34;: [\r\u0026#34;*\u0026#34;\r],\r\u0026#34;preSql\u0026#34;: [\r\u0026#34;delete from XXX;\u0026#34;\r]\r}\r}\r}\r]\r}\r} 3.2 参数说明 jdbcUrl\n描述：描述的是到对端数据库的JDBC连接信息，jdbcUrl按照RDBMS官方规范，并可以填写连接附件控制信息。请注意不同的数据库jdbc的格式是不同的，DataX会根据具体jdbc的格式选择合适的数据库驱动完成数据读取。\n达梦 jdbc:dm://ip:port/database db2格式 jdbc:db2://ip:port/database PPAS格式 jdbc:edb://ip:port/database rdbmswriter如何增加新的数据库支持:\n进入rdbmswriter对应目录，这里${DATAX_HOME}为DataX主目录，即: ${DATAX_HOME}/plugin/writer/rdbmswriter 在rdbmswriter插件目录下有plugin.json配置文件，在此文件中注册您具体的数据库驱动，具体放在drivers数组中。rdbmswriter插件在任务执行时会动态选择合适的数据库驱动连接数据库。 { \u0026#34;name\u0026#34;: \u0026#34;rdbmswriter\u0026#34;, \u0026#34;class\u0026#34;: \u0026#34;com.alibaba.datax.plugin.reader.rdbmswriter.RdbmsWriter\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;useScene: prod. mechanism: Jdbc connection using the database, execute select sql, retrieve data from the ResultSet. warn: The more you know about the database, the less problems you encounter.\u0026#34;, \u0026#34;developer\u0026#34;: \u0026#34;alibaba\u0026#34;, \u0026#34;drivers\u0026#34;: [ \u0026#34;dm.jdbc.driver.DmDriver\u0026#34;, \u0026#34;com.ibm.db2.jcc.DB2Driver\u0026#34;, \u0026#34;com.sybase.jdbc3.jdbc.SybDriver\u0026#34;, \u0026#34;com.edb.Driver\u0026#34; ] } 在rdbmswriter插件目录下有libs子目录，您需要将您具体的数据库驱动放到libs目录下。 $tree\r.\r|-- libs\r| |-- Dm7JdbcDriver16.jar\r| |-- commons-collections-3.0.jar\r| |-- commons-io-2.4.jar\r| |-- commons-lang3-3.3.2.jar\r| |-- commons-math3-3.1.1.jar\r| |-- datax-common-0.0.1-SNAPSHOT.jar\r| |-- datax-service-face-1.0.23-20160120.024328-1.jar\r| |-- db2jcc4.jar\r| |-- druid-1.0.15.jar\r| |-- edb-jdbc16.jar\r| |-- fastjson-1.1.46.sec01.jar\r| |-- guava-r05.jar\r| |-- hamcrest-core-1.3.jar\r| |-- jconn3-1.0.0-SNAPSHOT.jar\r| |-- logback-classic-1.0.13.jar\r| |-- logback-core-1.0.13.jar\r| |-- plugin-rdbms-util-0.0.1-SNAPSHOT.jar\r| `-- slf4j-api-1.7.10.jar\r|-- plugin.json\r|-- plugin_job_template.json\r`-- rdbmswriter-0.0.1-SNAPSHOT.jar 必选：是 默认值：无 username\n描述：数据源的用户名 必选：是 默认值：无 password\n描述：数据源指定用户名的密码 必选：是 默认值：无 table\n描述：目标表名称，如果表的schema信息和上述配置username不一致，请使用schema.table的格式填写table信息。 必选：是 默认值：无 column\n描述：所配置的表中需要同步的列名集合。以英文逗号（,）进行分隔。我们强烈不推荐用户使用默认列情况 必选：是 默认值：无 preSql\n描述：执行数据同步任务之前率先执行的sql语句，目前只允许执行一条SQL语句，例如清除旧数据。 必选：否 默认值：无 postSql\n描述：执行数据同步任务之后执行的sql语句，目前只允许执行一条SQL语句，例如加上某一个时间戳。 必选：否 默认值：无 batchSize\n描述：一次性批量提交的记录数大小，该值可以极大减少DataX与RDBMS的网络交互次数，并提升整体吞吐量。但是该值设置过大可能会造成DataX运行进程OOM情况。\n必选：否 默认值：1024 3.3 类型转换 目前RDBMSReader支持大部分通用得关系数据库类型如数字、字符等，但也存在部分个别类型没有支持的情况，请注意检查你的类型，根据具体的数据库做选择。\n","permalink":"https://haokiu.com/blog/5d9d57b2e00d4d8ca994dc15ece38148/","summary":"RDBMSWriter 插件文档 1 快速介绍 RDBMSWriter 插件实现了写入数据到 RDBMS 主库的目的表的功能。在底层实现上， RDBMSWriter 通过 JDBC 连接远程 RDBMS 数据库，并执行相应的 insert into \u0026hellip; 的 sql 语句将数据写入 RDBMS。 RDBMSWriter是一个通用的关系数据库写插件，您可以通过注册数据库驱动等方式增加任意多样的关系数据库写支持。\nRDBMSWriter 面向ETL开发工程师，他们使用 RDBMSWriter 从数仓导入数据到 RDBMS。同时 RDBMSWriter 亦可以作为数据迁移工具为DBA等用户提供服务。\n2 实现原理 RDBMSWriter 通过 DataX 框架获取 Reader 生成的协议数据，RDBMSWriter 通过 JDBC 连接远程 RDBMS 数据库，并执行相应的 insert into \u0026hellip; 的 sql 语句将数据写入 RDBMS。\n3 功能说明 3.1 配置样例 配置一个写入RDBMS的作业。 {\r\u0026#34;job\u0026#34;: {\r\u0026#34;setting\u0026#34;: {\r\u0026#34;speed\u0026#34;: {\r\u0026#34;channel\u0026#34;: 1\r}\r},\r\u0026#34;content\u0026#34;: [\r{\r\u0026#34;reader\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;streamreader\u0026#34;,\r\u0026#34;parameter\u0026#34;: {\r\u0026#34;column\u0026#34;: [\r{\r\u0026#34;value\u0026#34;: \u0026#34;DataX\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;\r},\r{\r\u0026#34;value\u0026#34;: 19880808,\r\u0026#34;type\u0026#34;: \u0026#34;long\u0026#34;\r},\r{\r\u0026#34;value\u0026#34;: \u0026#34;1988-08-08 08:08:08\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;\r},\r{\r\u0026#34;value\u0026#34;: true,\r\u0026#34;type\u0026#34;: \u0026#34;bool\u0026#34;\r},\r{\r\u0026#34;value\u0026#34;: \u0026#34;test\u0026#34;,\r\u0026#34;type\u0026#34;: \u0026#34;bytes\u0026#34;\r}\r],\r\u0026#34;sliceRecordCount\u0026#34;: 1000\r}\r},\r\u0026#34;writer\u0026#34;: {\r\u0026#34;name\u0026#34;: \u0026#34;rdbmswriter\u0026#34;,\r\u0026#34;parameter\u0026#34;: {\r\u0026#34;connection\u0026#34;: [\r{\r\u0026#34;jdbcUrl\u0026#34;: \u0026#34;jdbc:dm://ip:port/database\u0026#34;,\r\u0026#34;table\u0026#34;: [\r\u0026#34;table\u0026#34;\r]\r}\r],\r\u0026#34;username\u0026#34;: \u0026#34;username\u0026#34;,\r\u0026#34;password\u0026#34;: \u0026#34;password\u0026#34;,\r\u0026#34;table\u0026#34;: \u0026#34;table\u0026#34;,\r\u0026#34;column\u0026#34;: [\r\u0026#34;*\u0026#34;\r],\r\u0026#34;preSql\u0026#34;: [\r\u0026#34;delete from XXX;\u0026#34;\r]\r}\r}\r}\r]\r}\r} 3.","title":"RDBMSWriter 插件文档"},{"content":"some script here.\n","permalink":"https://haokiu.com/blog/b007b0bc6dca40458f17c7c1826e9da5/","summary":"some script here.","title":"Readme.md"},{"content":"本插件仅在Elasticsearch 5.x上测试\n","permalink":"https://haokiu.com/blog/9dbd1273dcb848bbaa69f53c0105d5c4/","summary":"本插件仅在Elasticsearch 5.x上测试","title":"README.md"},{"content":"SqlServerReader 插件文档 1 快速介绍 SqlServerReader插件实现了从SqlServer读取数据。在底层实现上，SqlServerReader通过JDBC连接远程SqlServer数据库，并执行相应的sql语句将数据从SqlServer库中SELECT出来。\n2 实现原理 简而言之，SqlServerReader通过JDBC连接器连接到远程的SqlServer数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程SqlServer数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，SqlServerReader将其拼接为SQL语句发送到SqlServer数据库；对于用户配置querySql信息，SqlServer直接将其发送到SqlServer数据库。\n3 功能说明 3.1 配置样例 配置一个从SqlServer数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;byte\u0026#34;: 1048576 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;sqlserverreader\u0026#34;, \u0026#34;parameter\u0026#34;: { // 数据库连接用户名 \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, // 数据库连接密码 \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34; ], \u0026#34;splitPk\u0026#34;: \u0026#34;db_id\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:sqlserver://localhost:3433;DatabaseName=dbname\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: true, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: 1048576 }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;sqlserverreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;where\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10;\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:sqlserver://bad_ip:3433;DatabaseName=dbname\u0026#34;, \u0026#34;jdbc:sqlserver://127.0.0.1:bad_port;DatabaseName=dbname\u0026#34;, \u0026#34;jdbc:sqlserver://127.0.0.1:3306;DatabaseName=dbname\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;visible\u0026#34;: false, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 3.2 参数说明 jdbcUrl\n描述：描述的是到对端数据库的JDBC连接信息，使用JSON的数组描述，并支持一个库填写多个连接地址。之所以使用JSON数组描述连接信息，是因为阿里集团内部支持多个IP探测，如果配置了多个，SqlServerReader可以依次探测ip的可连接性，直到选择一个合法的IP。如果全部连接失败，SqlServerReader报错。 注意，jdbcUrl必须包含在connection配置单元中。对于阿里集团外部使用情况，JSON数组填写一个JDBC连接即可。\njdbcUrl按照SqlServer官方规范，并可以填写连接附件控制信息。具体请参看SqlServer官方文档。\n必选：是 默认值：无 username\n描述：数据源的用户名 必选：是 默认值：无 password\n描述：数据源指定用户名的密码 必选：是 默认值：无 table\n描述：所选取的需要同步的表。使用JSON的数组描述，因此支持多张表同时抽取。当配置为多张表时，用户自己需保证多张表是同一schema结构，SqlServerReader不予检查表是否同一逻辑表。注意，table必须包含在connection配置单元中。\n必选：是 默认值：无 column\n描述：所配置的表中需要同步的列名集合，使用JSON的数组描述字段信息。用户使用*代表默认使用所有列配置，例如[\u0026quot;*\u0026quot;]。\n支持列裁剪，即列可以挑选部分列进行导出。\n支持列换序，即列可以不按照表schema信息进行导出。\n支持常量配置，用户需要按照JSON格式: [\u0026ldquo;id\u0026rdquo;, \u0026ldquo;[table]\u0026rdquo;, \u0026ldquo;1\u0026rdquo;, \u0026ldquo;\u0026lsquo;bazhen.csy\u0026rsquo;\u0026rdquo;, \u0026ldquo;null\u0026rdquo;, \u0026ldquo;COUNT(*)\u0026rdquo;, \u0026ldquo;2.3\u0026rdquo; , \u0026ldquo;true\u0026rdquo;] id为普通列名，[table]为包含保留在的列名，1为整形数字常量，\u0026lsquo;bazhen.csy\u0026rsquo;为字符串常量，null为空指针，to_char(a + 1)为表达式，2.3为浮点数，true为布尔值。\ncolumn必须用户显示指定同步的列集合，不允许为空！\n必选：是 默认值：无 splitPk\n描述：SqlServerReader进行数据抽取时，如果指定splitPk，表示用户希望使用splitPk代表的字段进行数据分片，DataX因此会启动并发任务进行数据同步，这样可以大大提供数据同步的效能。\n推荐splitPk用户使用表主键，因为表主键通常情况下比较均匀，因此切分出来的分片也不容易出现数据热点。\n目前splitPk仅支持整形型数据切分，不支持浮点、字符串、日期等其他类型。如果用户指定其他非支持类型，SqlServerReader将报错！\nsplitPk设置为空，底层将视作用户不允许对单表进行切分，因此使用单通道进行抽取。\n必选：否 默认值：无 where\n描述：筛选条件，MysqlReader根据指定的column、table、where条件拼接SQL，并根据这个SQL进行数据抽取。在实际业务场景中，往往会选择当天的数据进行同步，可以将where条件指定为gmt_create \u0026gt; $bizdate 。注意：不可以将where条件指定为limit 10，limit不是SQL的合法where子句。\nwhere条件可以有效地进行业务增量同步。如果该值为空，代表同步全表所有的信息。 必选：否 默认值：无 querySql\n描述：在有些业务场景下，where这一配置项不足以描述所筛选的条件，用户可以通过该配置型来自定义筛选SQL。当用户配置了这一项之后，DataX系统就会忽略table，column这些配置型，直接使用这个配置项的内容对数据进行筛选，例如需要进行多表join后同步数据，使用select a,b from table_a join table_b on table_a.id = table_b.id 当用户配置querySql时，SqlServerReader直接忽略table、column、where条件的配置。\n必选：否 默认值：无 fetchSize\n描述：该配置项定义了插件和数据库服务器端每次批量数据获取条数，该值决定了DataX和服务器端的网络交互次数，能够较大的提升数据抽取性能。 注意，该值过大(\u0026gt;2048)可能造成DataX进程OOM。。\n必选：否 默认值：1024 3.3 类型转换 目前SqlServerReader支持大部分SqlServer类型，但也存在部分个别类型没有支持的情况，请注意检查你的类型。\n下面列出SqlServerReader针对SqlServer类型转换列表:\nDataX 内部类型 SqlServer 数据类型 Long bigint, int, smallint, tinyint Double float, decimal, real, numeric String char,nchar,ntext,nvarchar,text,varchar,nvarchar(MAX),varchar(MAX) Date date, datetime, time Boolean bit Bytes binary,varbinary,varbinary(MAX),timestamp 请注意:\n除上述罗列字段类型外，其他类型均不支持。 timestamp类型作为二进制类型。 4 性能报告 暂无\n5 约束限制 5.1 主备同步数据恢复问题 主备同步问题指SqlServer使用主从灾备，备库从主库不间断通过binlog恢复数据。由于主备数据同步存在一定的时间差，特别在于某些特定情况，例如网络延迟等问题，导致备库同步恢复的数据与主库有较大差别，导致从备库同步的数据不是一份当前时间的完整镜像。\n针对这个问题，我们提供了preSql功能，该功能待补充。\n5.2 一致性约束 SqlServer在数据存储划分中属于RDBMS系统，对外可以提供强一致性数据查询接口。例如当一次同步任务启动运行过程中，当该库存在其他数据写入方写入数据时，SqlServerReader完全不会获取到写入更新数据，这是由于数据库本身的快照特性决定的。关于数据库快照特性，请参看MVCC Wikipedia\n上述是在SqlServerReader单线程模型下数据同步一致性的特性，由于SqlServerReader可以根据用户配置信息使用了并发数据抽取，因此不能严格保证数据一致性：当SqlServerReader根据splitPk进行数据切分后，会先后启动多个并发任务完成数据同步。由于多个并发任务相互之间不属于同一个读事务，同时多个并发任务存在时间间隔。因此这份数据并不是完整的、一致的数据快照信息。\n针对多线程的一致性快照需求，在技术上目前无法实现，只能从工程角度解决，工程化的方式存在取舍，我们提供几个解决思路给用户，用户可以自行选择：\n使用单线程同步，即不再进行数据切片。缺点是速度比较慢，但是能够很好保证一致性。\n关闭其他数据写入方，保证当前数据为静态数据，例如，锁表、关闭备库同步等等。缺点是可能影响在线业务。\n5.3 数据库编码问题 SqlServerReader底层使用JDBC进行数据抽取，JDBC天然适配各类编码，并在底层进行了编码转换。因此SqlServerReader不需用户指定编码，可以自动识别编码并转码。\n5.4 增量数据同步 SqlServerReader使用JDBC SELECT语句完成数据抽取工作，因此可以使用SELECT\u0026hellip;WHERE\u0026hellip;进行增量数据抽取，方式有多种：\n数据库在线应用写入数据库时，填充modify字段为更改时间戳，包括新增、更新、删除(逻辑删)。对于这类应用，SqlServerReader只需要WHERE条件跟上一同步阶段时间戳即可。 对于新增流水型数据，SqlServerReader可以WHERE条件后跟上一阶段最大自增ID即可。 对于业务上无字段区分新增、修改数据情况，SqlServerReader也无法进行增量数据同步，只能同步全量数据。\n5.5 Sql安全性 SqlServerReader提供querySql语句交给用户自己实现SELECT抽取语句，SqlServerReader本身对querySql不做任何安全性校验。这块交由DataX用户方自己保证。\n6 FAQ ","permalink":"https://haokiu.com/blog/e30dc23cda1d465fa0872475e5c976a7/","summary":"SqlServerReader 插件文档 1 快速介绍 SqlServerReader插件实现了从SqlServer读取数据。在底层实现上，SqlServerReader通过JDBC连接远程SqlServer数据库，并执行相应的sql语句将数据从SqlServer库中SELECT出来。\n2 实现原理 简而言之，SqlServerReader通过JDBC连接器连接到远程的SqlServer数据库，并根据用户配置的信息生成查询SELECT SQL语句并发送到远程SqlServer数据库，并将该SQL执行返回结果使用DataX自定义的数据类型拼装为抽象的数据集，并传递给下游Writer处理。\n对于用户配置Table、Column、Where的信息，SqlServerReader将其拼接为SQL语句发送到SqlServer数据库；对于用户配置querySql信息，SqlServer直接将其发送到SqlServer数据库。\n3 功能说明 3.1 配置样例 配置一个从SqlServer数据库同步抽取数据到本地的作业: { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;byte\u0026#34;: 1048576 } }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;sqlserverreader\u0026#34;, \u0026#34;parameter\u0026#34;: { // 数据库连接用户名 \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, // 数据库连接密码 \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;id\u0026#34; ], \u0026#34;splitPk\u0026#34;: \u0026#34;db_id\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;table\u0026#34;: [ \u0026#34;table\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:sqlserver://localhost:3433;DatabaseName=dbname\u0026#34; ] } ] } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;print\u0026#34;: true, \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34; } } } ] } } 配置一个自定义SQL的数据库同步任务到本地内容的作业： { \u0026#34;job\u0026#34;: { \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: 1048576 }, \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;sqlserverreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;root\u0026#34;, \u0026#34;where\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;connection\u0026#34;: [ { \u0026#34;querySql\u0026#34;: [ \u0026#34;select db_id,on_line_flag from db_info where db_id \u0026lt; 10;\u0026#34; ], \u0026#34;jdbcUrl\u0026#34;: [ \u0026#34;jdbc:sqlserver://bad_ip:3433;DatabaseName=dbname\u0026#34;, \u0026#34;jdbc:sqlserver://127.","title":"SqlServerReader 插件文档"},{"content":"TableStore增量数据导出通道：TableStoreStreamReader 快速介绍 TableStoreStreamReader插件主要用于TableStore的增量数据导出，增量数据可以看作操作日志，除了数据本身外还附有操作信息。\n与全量导出插件不同，增量导出插件只有多版本模式，同时不支持指定列。这是与增量导出的原理有关的，导出的格式下面有详细介绍。\n使用插件前必须确保表上已经开启Stream功能，可以在建表的时候指定开启，或者使用SDK的UpdateTable接口开启。\n开启Stream的方法： SyncClient client = new SyncClient(\u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;); 1. 建表的时候开启： CreateTableRequest createTableRequest = new CreateTableRequest(tableMeta); createTableRequest.setStreamSpecification(new StreamSpecification(true, 24)); // 24代表增量数据保留24小时 client.createTable(createTableRequest); 2. 如果建表时未开启，可以通过UpdateTable开启: UpdateTableRequest updateTableRequest = new UpdateTableRequest(\u0026quot;tableName\u0026quot;); updateTableRequest.setStreamSpecification(new StreamSpecification(true, 24)); client.updateTable(updateTableRequest); 实现原理 首先用户使用SDK的UpdateTable功能，指定开启Stream并设置过期时间，即开启了增量功能。\n开启后，TableStore服务端就会将用户的操作日志额外保存起来， 每个分区有一个有序的操作日志队列，每条操作日志会在一定时间后被垃圾回收，这个时间即用户指定的过期时间。\nTableStore的SDK提供了几个Stream相关的API用于将这部分操作日志读取出来，增量插件也是通过TableStore SDK的接口获取到增量数据的，并将 增量数据转化为多个6元组的形式(pk, colName, version, colValue, opType, sequenceInfo)导入到ODPS中。\nReader的配置模版： \u0026quot;reader\u0026quot;: { \u0026quot;name\u0026quot; : \u0026quot;otsstreamreader\u0026quot;, \u0026quot;parameter\u0026quot; : { \u0026quot;endpoint\u0026quot; : \u0026quot;\u0026quot;, \u0026quot;accessId\u0026quot; : \u0026quot;\u0026quot;, \u0026quot;accessKey\u0026quot; : \u0026quot;\u0026quot;, \u0026quot;instanceName\u0026quot; : \u0026quot;\u0026quot;, //dataTable即需要导出数据的表。 \u0026quot;dataTable\u0026quot; : \u0026quot;\u0026quot;, //statusTable是Reader用于保存状态的表，若该表不存在，Reader会自动创建该表。 //一次离线导出任务完成后，用户不应删除该表，该表中记录的状态可用于下次导出任务中。 \u0026quot;statusTable\u0026quot; : \u0026quot;TableStoreStreamReaderStatusTable\u0026quot;, //增量数据的时间范围（左闭右开）的左边界。 \u0026quot;startTimestampMillis\u0026quot; : \u0026quot;\u0026quot;, //增量数据的时间范围（左闭右开）的右边界。 \u0026quot;endTimestampMillis\u0026quot; : \u0026quot;\u0026quot;, //采云间调度只支持天级别，所以提供该配置，作用与startTimestampMillis和endTimestampMillis类似。 \u0026quot;date\u0026quot;: \u0026quot;\u0026quot;, //是否导出时序信息。 \u0026quot;isExportSequenceInfo\u0026quot;: true, //从TableStore中读增量数据时，每次请求的最大重试次数，默认为30。 \u0026quot;maxRetries\u0026quot; : 30 } } 参数说明 名称 说明 类型 必选 endpoint TableStoreServer的Endpoint地址。 String 是 accessId 用于访问TableStore服务的accessId。 String 是 accessKey 用于访问TableStore服务的accessKey。 String 是 instanceName TableStore的实例名称。 String 是 dataTable 需要导出增量数据的表的名称。该表需要开启Stream，可以在建表时开启，或者使用UpdateTable接口开启。 String 是 statusTable Reader插件用于记录状态的表的名称，这些状态可用于减少对非目标范围内的数据的扫描，从而加快导出速度。 1. 用户不需要创建该表，只需要给出一个表名。Reader插件会尝试在用户的instance下创建该表，若该表不存在即创建新表，若该表已存在，会判断该表的Meta是否与期望一致，若不一致会抛出异常。 2. 在一次导出完成之后，用户不应删除该表，该表的状态可用于下次导出任务。 3. 该表会开启TTL，数据自动过期，因此可认为其数据量很小。 4. 针对同一个instance下的多个不同的dataTable的Reader配置，可以使用同一个statusTable，记录的状态信息互不影响。 综上，用户配置一个类似TableStoreStreamReaderStatusTable之类的名称即可，注意不要与业务相关的表重名。 String 是 startTimestampMillis 增量数据的时间范围（左闭右开）的左边界，单位毫秒。 1. Reader插件会从statusTable中找对应startTimestampMillis的位点，从该点开始读取开始导出数据。 2. 若statusTable中找不到对应的位点，则从系统保留的增量数据的第一条开始读取，并跳过写入时间小于startTimestampMillis的数据。 Long 否 endTimestampMillis 增量数据的时间范围（左闭右开）的右边界，单位毫秒。 1. Reader插件从startTimestampMillis位置开始导出数据后，当遇到第一条时间戳大于等于endTimestampMillis的数据时，结束导出数据，导出完成。 2. 当读取完当前全部的增量数据时，结束读取，即使未达到endTimestampMillis。 Long 否 date 日期格式为yyyyMMdd，如20151111，表示导出该日的数据。 若没有指定date，则必须指定startTimestampMillis和endTimestampMillis，反之也成立。 String 否 isExportSequenceInfo 是否导出时序信息，时序信息包含了数据的写入时间等。默认该值为false，即不导出。 Boolean 否 maxRetries 从TableStore中读增量数据时，每次请求的最大重试次数，默认为30，重试之间有间隔，30次重试总时间约为5分钟，一般无需更改。 Int 否 导出的数据格式 首先，在TableStore多版本模型下，表中的数据组织为“行－列－版本”三级的模式， 一行可以有任意列，列名也并非固定的，每一列可以含有多个版本，每个版本都有一个特定的时间戳（版本号）。\n用户可以通过TableStore的API进行一系列读写操作， TableStore通过记录用户最近对表的一系列写操作（或称为数据更改操作）来实现记录增量数据的目的， 所以也可以把增量数据看作一批操作记录。\nTableStore有三类数据更改操作：PutRow、UpdateRow、DeleteRow。\nPutRow的语义是写入一行，若该行已存在即覆盖该行。\nUpdateRow的语义是更新一行，对原行其他数据不做更改， 更新可能包括新增或覆盖（若对应列的对应版本已存在）一些列值、删除某一列的全部版本、删除某一列的某个版本。\nDeleteRow的语义是删除一行。\nTableStore会根据每种操作生成对应的增量数据记录，Reader插件会读出这些记录，并导出成Datax的数据格式。\n同时，由于TableStore具有动态列、多版本的特性，所以Reader插件导出的一行不对应TableStore中的一行，而是对应TableStore中的一列的一个版本。 即TableStore中的一行可能会导出很多行，每行包含主键值、该列的列名、该列下该版本的时间戳（版本号）、该版本的值、操作类型。若设置isExportSequenceInfo为true，还会包括时序信息。\n转换为Datax的数据格式后，我们定义了四种操作类型，分别为:\nU（UPDATE）: 写入一列的一个版本\nDO（DELETE_ONE_VERSION）: 删除某一列的某个版本\nDA（DELETE_ALL_VERSION）: 删除某一列的全部版本，此时需要根据主键和列名，将对应列的全部版本删除\nDR（DELETE_ROW）: 删除某一行，此时需要根据主键，将该行数据全部删除\n举例如下，假设该表有两个主键列，主键列名分别为pkName1, pkName2：\npkName1 pkName2 columnName timestamp columnValue opType pk1_V1 pk2_V1 col_a 1441803688001 col_val1 U pk1_V1 pk2_V1 col_a 1441803688002 col_val2 U pk1_V1 pk2_V1 col_b 1441803688003 col_val3 U pk1_V2 pk2_V2 col_a 1441803688000 DO pk1_V2 pk2_V2 col_b DA pk1_V3 pk2_V3 DR pk1_V3 pk2_V3 col_a 1441803688005 col_val1 U 假设导出的数据如上，共7行，对应TableStore表内的3行，主键分别是(pk1_V1,pk2_V1), (pk1_V2, pk2_V2), (pk1_V3, pk2_V3)。\n对于主键为(pk1_V1, pk2_V1)的一行，包含三个操作，分别是写入col_a列的两个版本和col_b列的一个版本。\n对于主键为(pk1_V2, pk2_V2)的一行，包含两个操作，分别是删除col_a列的一个版本、删除col_b列的全部版本。\n对于主键为(pk1_V3, pk2_V3)的一行，包含两个操作，分别是删除整行、写入col_a列的一个版本。\n","permalink":"https://haokiu.com/blog/6851df08c78c4eb1aab41d312b920bf9/","summary":"TableStore增量数据导出通道：TableStoreStreamReader 快速介绍 TableStoreStreamReader插件主要用于TableStore的增量数据导出，增量数据可以看作操作日志，除了数据本身外还附有操作信息。\n与全量导出插件不同，增量导出插件只有多版本模式，同时不支持指定列。这是与增量导出的原理有关的，导出的格式下面有详细介绍。\n使用插件前必须确保表上已经开启Stream功能，可以在建表的时候指定开启，或者使用SDK的UpdateTable接口开启。\n开启Stream的方法： SyncClient client = new SyncClient(\u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;\u0026quot;); 1. 建表的时候开启： CreateTableRequest createTableRequest = new CreateTableRequest(tableMeta); createTableRequest.setStreamSpecification(new StreamSpecification(true, 24)); // 24代表增量数据保留24小时 client.createTable(createTableRequest); 2. 如果建表时未开启，可以通过UpdateTable开启: UpdateTableRequest updateTableRequest = new UpdateTableRequest(\u0026quot;tableName\u0026quot;); updateTableRequest.setStreamSpecification(new StreamSpecification(true, 24)); client.updateTable(updateTableRequest); 实现原理 首先用户使用SDK的UpdateTable功能，指定开启Stream并设置过期时间，即开启了增量功能。\n开启后，TableStore服务端就会将用户的操作日志额外保存起来， 每个分区有一个有序的操作日志队列，每条操作日志会在一定时间后被垃圾回收，这个时间即用户指定的过期时间。\nTableStore的SDK提供了几个Stream相关的API用于将这部分操作日志读取出来，增量插件也是通过TableStore SDK的接口获取到增量数据的，并将 增量数据转化为多个6元组的形式(pk, colName, version, colValue, opType, sequenceInfo)导入到ODPS中。\nReader的配置模版： \u0026quot;reader\u0026quot;: { \u0026quot;name\u0026quot; : \u0026quot;otsstreamreader\u0026quot;, \u0026quot;parameter\u0026quot; : { \u0026quot;endpoint\u0026quot; : \u0026quot;\u0026quot;, \u0026quot;accessId\u0026quot; : \u0026quot;\u0026quot;, \u0026quot;accessKey\u0026quot; : \u0026quot;\u0026quot;, \u0026quot;instanceName\u0026quot; : \u0026quot;\u0026quot;, //dataTable即需要导出数据的表。 \u0026quot;dataTable\u0026quot; : \u0026quot;\u0026quot;, //statusTable是Reader用于保存状态的表，若该表不存在，Reader会自动创建该表。 //一次离线导出任务完成后，用户不应删除该表，该表中记录的状态可用于下次导出任务中。 \u0026quot;statusTable\u0026quot; : \u0026quot;TableStoreStreamReaderStatusTable\u0026quot;, //增量数据的时间范围（左闭右开）的左边界。 \u0026quot;startTimestampMillis\u0026quot; : \u0026quot;\u0026quot;, //增量数据的时间范围（左闭右开）的右边界。 \u0026quot;endTimestampMillis\u0026quot; : \u0026quot;\u0026quot;, //采云间调度只支持天级别，所以提供该配置，作用与startTimestampMillis和endTimestampMillis类似。 \u0026quot;date\u0026quot;: \u0026quot;\u0026quot;, //是否导出时序信息。 \u0026quot;isExportSequenceInfo\u0026quot;: true, //从TableStore中读增量数据时，每次请求的最大重试次数，默认为30。 \u0026quot;maxRetries\u0026quot; : 30 } } 参数说明 名称 说明 类型 必选 endpoint TableStoreServer的Endpoint地址。 String 是 accessId 用于访问TableStore服务的accessId。 String 是 accessKey 用于访问TableStore服务的accessKey。 String 是 instanceName TableStore的实例名称。 String 是 dataTable 需要导出增量数据的表的名称。该表需要开启Stream，可以在建表时开启，或者使用UpdateTable接口开启。 String 是 statusTable Reader插件用于记录状态的表的名称，这些状态可用于减少对非目标范围内的数据的扫描，从而加快导出速度。 1.","title":"TableStore增量数据导出通道：TableStoreStreamReader"},{"content":"TSDBReader 插件文档 1 快速介绍 TSDBReader 插件实现了从阿里云 TSDB 读取数据。阿里云时间序列数据库 ( Time Series Database , 简称 TSDB) 是一种集时序数据高效读写，压缩存储，实时计算能力为一体的数据库服务，可广泛应用于物联网和互联网领域，实现对设备及业务服务的实时监控，实时预测告警。详见 TSDB 的阿里云官网。\n2 实现原理 在底层实现上，TSDBReader 通过 HTTP 请求链接到 阿里云 TSDB 实例，利用 /api/query 或者 /api/mquery 接口将数据点扫描出来（更多细节详见：时序数据库 TSDB - HTTP API 概览）。而整个同步的过程，是通过时间线和查询时间线范围进行切分。\n3 功能说明 3.1 配置样例 配置一个从 阿里云 TSDB 数据库同步抽取数据到本地的作业，并以时序数据的格式输出： 时序数据样例：\n{\u0026#34;metric\u0026#34;:\u0026#34;m\u0026#34;,\u0026#34;tags\u0026#34;:{\u0026#34;app\u0026#34;:\u0026#34;a19\u0026#34;,\u0026#34;cluster\u0026#34;:\u0026#34;c5\u0026#34;,\u0026#34;group\u0026#34;:\u0026#34;g10\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;i999\u0026#34;,\u0026#34;zone\u0026#34;:\u0026#34;z1\u0026#34;},\u0026#34;timestamp\u0026#34;:1546272263,\u0026#34;value\u0026#34;:1} { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sinkDbType\u0026#34;: \u0026#34;TSDB\u0026#34;, \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;m\u0026#34; ], \u0026#34;splitIntervalMs\u0026#34;: 60000, \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 01:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;print\u0026#34;: true } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } } } } 配置一个从 阿里云 TSDB 数据库同步抽取数据到本地的作业，并以关系型数据的格式输出： 关系型数据样例：\nm\t1546272125\ta1\tc1\tg2\ti3021\tz4\t1.0 { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sinkDbType\u0026#34;: \u0026#34;RDB\u0026#34;, \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;__metric__\u0026#34;, \u0026#34;__ts__\u0026#34;, \u0026#34;app\u0026#34;, \u0026#34;cluster\u0026#34;, \u0026#34;group\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;zone\u0026#34;, \u0026#34;__value__\u0026#34; ], \u0026#34;metric\u0026#34;: [ \u0026#34;m\u0026#34; ], \u0026#34;splitIntervalMs\u0026#34;: 60000, \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 01:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;print\u0026#34;: true } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } } } } 配置一个从 阿里云 TSDB 数据库同步抽取单值数据到 ADB 的作业： { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sinkDbType\u0026#34;: \u0026#34;RDB\u0026#34;, \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;__metric__\u0026#34;, \u0026#34;__ts__\u0026#34;, \u0026#34;app\u0026#34;, \u0026#34;cluster\u0026#34;, \u0026#34;group\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;zone\u0026#34;, \u0026#34;__value__\u0026#34; ], \u0026#34;metric\u0026#34;: [ \u0026#34;m\u0026#34; ], \u0026#34;splitIntervalMs\u0026#34;: 60000, \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 01:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;adswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;`metric`\u0026#34;, \u0026#34;`ts`\u0026#34;, \u0026#34;`app`\u0026#34;, \u0026#34;`cluster`\u0026#34;, \u0026#34;`group`\u0026#34;, \u0026#34;`ip`\u0026#34;, \u0026#34;`zone`\u0026#34;, \u0026#34;`value`\u0026#34; ], \u0026#34;url\u0026#34;: \u0026#34;http://localhost:3306\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;datax_test\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;datax_test\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;insert\u0026#34;, \u0026#34;opIndex\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;batchSize\u0026#34;: \u0026#34;2\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } } } } 配置一个从 阿里云 TSDB 数据库同步抽取多值数据到 ADB 的作业： { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sinkDbType\u0026#34;: \u0026#34;RDB\u0026#34;, \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;__metric__\u0026#34;, \u0026#34;__ts__\u0026#34;, \u0026#34;app\u0026#34;, \u0026#34;cluster\u0026#34;, \u0026#34;group\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;zone\u0026#34;, \u0026#34;load\u0026#34;, \u0026#34;memory\u0026#34;, \u0026#34;cpu\u0026#34; ], \u0026#34;metric\u0026#34;: [ \u0026#34;m_field\u0026#34; ], \u0026#34;field\u0026#34;: { \u0026#34;m_field\u0026#34;: [ \u0026#34;load\u0026#34;, \u0026#34;memory\u0026#34;, \u0026#34;cpu\u0026#34; ] }, \u0026#34;splitIntervalMs\u0026#34;: 60000, \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 01:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;adswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;`metric`\u0026#34;, \u0026#34;`ts`\u0026#34;, \u0026#34;`app`\u0026#34;, \u0026#34;`cluster`\u0026#34;, \u0026#34;`group`\u0026#34;, \u0026#34;`ip`\u0026#34;, \u0026#34;`zone`\u0026#34;, \u0026#34;`load`\u0026#34;, \u0026#34;`memory`\u0026#34;, \u0026#34;`cpu`\u0026#34; ], \u0026#34;url\u0026#34;: \u0026#34;http://localhost:3306\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;datax_test\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;datax_test_multi_field\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;insert\u0026#34;, \u0026#34;opIndex\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;batchSize\u0026#34;: \u0026#34;2\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } } } } 配置一个从 阿里云 TSDB 数据库同步抽取单值数据到 ADB 的作业，并指定过滤部分时间线： { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sinkDbType\u0026#34;: \u0026#34;RDB\u0026#34;, \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;__metric__\u0026#34;, \u0026#34;__ts__\u0026#34;, \u0026#34;app\u0026#34;, \u0026#34;cluster\u0026#34;, \u0026#34;group\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;zone\u0026#34;, \u0026#34;__value__\u0026#34; ], \u0026#34;metric\u0026#34;: [ \u0026#34;m\u0026#34; ], \u0026#34;tag\u0026#34;: { \u0026#34;m\u0026#34;: { \u0026#34;app\u0026#34;: \u0026#34;a1\u0026#34;, \u0026#34;cluster\u0026#34;: \u0026#34;c1\u0026#34; } }, \u0026#34;splitIntervalMs\u0026#34;: 60000, \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 01:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;adswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;`metric`\u0026#34;, \u0026#34;`ts`\u0026#34;, \u0026#34;`app`\u0026#34;, \u0026#34;`cluster`\u0026#34;, \u0026#34;`group`\u0026#34;, \u0026#34;`ip`\u0026#34;, \u0026#34;`zone`\u0026#34;, \u0026#34;`value`\u0026#34; ], \u0026#34;url\u0026#34;: \u0026#34;http://localhost:3306\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;datax_test\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;datax_test\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;insert\u0026#34;, \u0026#34;opIndex\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;batchSize\u0026#34;: \u0026#34;2\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } } } } 配置一个从 阿里云 TSDB 数据库同步抽取多值数据到 ADB 的作业，并指定过滤部分时间线： { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sinkDbType\u0026#34;: \u0026#34;RDB\u0026#34;, \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;__metric__\u0026#34;, \u0026#34;__ts__\u0026#34;, \u0026#34;app\u0026#34;, \u0026#34;cluster\u0026#34;, \u0026#34;group\u0026#34;, \u0026#34;ip\u0026#34;, \u0026#34;zone\u0026#34;, \u0026#34;load\u0026#34;, \u0026#34;memory\u0026#34;, \u0026#34;cpu\u0026#34; ], \u0026#34;metric\u0026#34;: [ \u0026#34;m_field\u0026#34; ], \u0026#34;field\u0026#34;: { \u0026#34;m_field\u0026#34;: [ \u0026#34;load\u0026#34;, \u0026#34;memory\u0026#34;, \u0026#34;cpu\u0026#34; ] }, \u0026#34;tag\u0026#34;: { \u0026#34;m_field\u0026#34;: { \u0026#34;ip\u0026#34;: \u0026#34;i999\u0026#34; } }, \u0026#34;splitIntervalMs\u0026#34;: 60000, \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 01:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;adswriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;username\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;password\u0026#34;: \u0026#34;******\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;`metric`\u0026#34;, \u0026#34;`ts`\u0026#34;, \u0026#34;`app`\u0026#34;, \u0026#34;`cluster`\u0026#34;, \u0026#34;`group`\u0026#34;, \u0026#34;`ip`\u0026#34;, \u0026#34;`zone`\u0026#34;, \u0026#34;`load`\u0026#34;, \u0026#34;`memory`\u0026#34;, \u0026#34;`cpu`\u0026#34; ], \u0026#34;url\u0026#34;: \u0026#34;http://localhost:3306\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;datax_test\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;datax_test_multi_field\u0026#34;, \u0026#34;writeMode\u0026#34;: \u0026#34;insert\u0026#34;, \u0026#34;opIndex\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;batchSize\u0026#34;: \u0026#34;2\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } } } } 配置一个从 阿里云 TSDB 数据库同步抽取单值数据到另一个 阿里云 TSDB 数据库 的作业： { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sinkDbType\u0026#34;: \u0026#34;TSDB\u0026#34;, \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;m\u0026#34; ], \u0026#34;splitIntervalMs\u0026#34;: 60000, \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 01:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8240\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } } } } 配置一个从 阿里云 TSDB 数据库同步抽取多值数据到另一个 阿里云 TSDB 数据库 的作业： { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sinkDbType\u0026#34;: \u0026#34;TSDB\u0026#34;, \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;m_field\u0026#34; ], \u0026#34;field\u0026#34;: { \u0026#34;m_field\u0026#34;: [ \u0026#34;load\u0026#34;, \u0026#34;memory\u0026#34;, \u0026#34;cpu\u0026#34; ] }, \u0026#34;splitIntervalMs\u0026#34;: 60000, \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 01:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;multiField\u0026#34;: true, \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8240\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } } } } 3.2 参数说明 name\n描述：本插件的名称 必选：是 默认值：tsdbreader parameter\nsinkDbType\n描述：目标数据库的类型 必选：否 默认值：TSDB 注意：目前支持 TSDB 和 RDB 两个取值。其中，TSDB 包括 阿里云 TSDB、OpenTSDB、InfluxDB、Prometheus 和 TimeScale。RDB 包括 ADB、MySQL、Oracle、PostgreSQL 和 DRDS 等。 endpoint\n描述：阿里云 TSDB 的 HTTP 连接地址 必选：是 格式：http://IP:Port 默认值：无 column\n描述：TSDB 场景下：数据迁移任务需要迁移的 Metric 列表；RDB 场景下：映射到关系型数据库中的表字段，且增加 __metric__、__ts__ 和 __value__ 三个字段，其中 __metric__ 用于映射度量字段，__ts__ 用于映射 timestamp 字段，而 __value__ 仅适用于单值场景，用于映射度量值，多值场景下，直接指定 field 字段即可 必选：是 默认值：无 metric\n描述：仅适用于 RDB 场景下，表示数据迁移任务需要迁移的 Metric 列表 必选：否 默认值：无 field\n描述：仅适用于多值场景下，表示数据迁移任务需要迁移的 Field 列表 必选：否 默认值：无 tag\n描述：数据迁移任务需要迁移的 TagK 和 TagV，用于进一步过滤时间线 必选：否 默认值：无 splitIntervalMs\n描述：用于 DataX 内部切分 Task，每个 Task 只查询一小部分的时间段 必选：是 默认值：无 注意：单位是 ms 毫秒 beginDateTime\n描述：和 endDateTime 配合使用，用于指定哪个时间段内的数据点，需要被迁移 必选：是 格式：yyyy-MM-dd HH:mm:ss 默认值：无 注意：指定起止时间会自动忽略分钟和秒，转为整点时刻，例如 2019-4-18 的 [3:35, 4:55) 会被转为 [3:00, 4:00) endDateTime\n描述：和 beginDateTime 配合使用，用于指定哪个时间段内的数据点，需要被迁移 必选：是 格式：yyyy-MM-dd HH:mm:ss 默认值：无 注意：指定起止时间会自动忽略分钟和秒，转为整点时刻，例如 2019-4-18 的 [3:35, 4:55) 会被转为 [3:00, 4:00) 3.3 类型转换 DataX 内部类型 TSDB 数据类型 String TSDB 数据点序列化字符串，包括 timestamp、metric、tags、fields 和 value 4 约束限制 4.2 如果存在某一个 Metric 下在一个小时范围内的数据量过大，可能需要通过 -j 参数调整 JVM 内存大小 考虑到下游 Writer 如果写入速度不及 TSDB Reader 的查询数据，可能会存在积压的情况，因此需要适当地调整 JVM 参数。以\u0026quot;从 阿里云 TSDB 数据库同步抽取数据到本地的作业\u0026quot;为例，启动命令如下：\npython datax/bin/datax.py tsdb2stream.json -j \u0026#34;-Xms4096m -Xmx4096m\u0026#34; 4.3 指定起止时间会自动被转为整点时刻 指定起止时间会自动被转为整点时刻，例如 2019-4-18 的 [3:35, 3:55) 会被转为 [3:00, 4:00)\n","permalink":"https://haokiu.com/blog/66980d1599cc4aec9a2d6616d1f0c5e7/","summary":"TSDBReader 插件文档 1 快速介绍 TSDBReader 插件实现了从阿里云 TSDB 读取数据。阿里云时间序列数据库 ( Time Series Database , 简称 TSDB) 是一种集时序数据高效读写，压缩存储，实时计算能力为一体的数据库服务，可广泛应用于物联网和互联网领域，实现对设备及业务服务的实时监控，实时预测告警。详见 TSDB 的阿里云官网。\n2 实现原理 在底层实现上，TSDBReader 通过 HTTP 请求链接到 阿里云 TSDB 实例，利用 /api/query 或者 /api/mquery 接口将数据点扫描出来（更多细节详见：时序数据库 TSDB - HTTP API 概览）。而整个同步的过程，是通过时间线和查询时间线范围进行切分。\n3 功能说明 3.1 配置样例 配置一个从 阿里云 TSDB 数据库同步抽取数据到本地的作业，并以时序数据的格式输出： 时序数据样例：\n{\u0026#34;metric\u0026#34;:\u0026#34;m\u0026#34;,\u0026#34;tags\u0026#34;:{\u0026#34;app\u0026#34;:\u0026#34;a19\u0026#34;,\u0026#34;cluster\u0026#34;:\u0026#34;c5\u0026#34;,\u0026#34;group\u0026#34;:\u0026#34;g10\u0026#34;,\u0026#34;ip\u0026#34;:\u0026#34;i999\u0026#34;,\u0026#34;zone\u0026#34;:\u0026#34;z1\u0026#34;},\u0026#34;timestamp\u0026#34;:1546272263,\u0026#34;value\u0026#34;:1} { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;sinkDbType\u0026#34;: \u0026#34;TSDB\u0026#34;, \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;m\u0026#34; ], \u0026#34;splitIntervalMs\u0026#34;: 60000, \u0026#34;beginDateTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endDateTime\u0026#34;: \u0026#34;2019-01-01 01:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;streamwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;encoding\u0026#34;: \u0026#34;UTF-8\u0026#34;, \u0026#34;print\u0026#34;: true } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 3 } } } } 配置一个从 阿里云 TSDB 数据库同步抽取数据到本地的作业，并以关系型数据的格式输出： 关系型数据样例：","title":"TSDBReader 插件文档"},{"content":"TSDBWriter 插件文档 1 快速介绍 TSDBWriter 插件实现了将数据点写入到阿里巴巴自研 TSDB 数据库中（后续简称 TSDB）。\n时间序列数据库（Time Series Database , 简称 TSDB）是一种高性能，低成本，稳定可靠的在线时序数据库服务；提供高效读写，高压缩比存储、时序数据插值及聚合计算，广泛应用于物联网（IoT）设备监控系统 ，企业能源管理系统（EMS），生产安全监控系统，电力检测系统等行业场景。 TSDB 提供百万级时序数据秒级写入，高压缩比低成本存储、预降采样、插值、多维聚合计算，查询结果可视化功能；解决由于设备采集点数量巨大，数据采集频率高，造成的存储成本高，写入和查询分析效率低的问题。更多关于 TSDB 的介绍，详见阿里云 TSDB 官网。\n2 实现原理 通过 HTTP 连接 TSDB 实例，并通过 /api/put 接口将数据点写入。关于写入接口详见 TSDB 的接口说明文档。\n3 功能说明 3.1 配置样例 配置一个从 OpenTSDB 数据库同步抽取数据到 TSDB： { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;opentsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:4242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;m\u0026#34; ], \u0026#34;startTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endTime\u0026#34;: \u0026#34;2019-01-01 03:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbhttpwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } } } } 3.2 参数说明 name\n描述：本插件的名称 必选：是 默认值：tsdbhttpwriter parameter\nendpoint 描述：TSDB 的 HTTP 连接地址 必选：是 格式：http://IP:Port 默认值：无 batchSize\n描述：每次批量数据的条数 必选：否 格式：int，需要保证大于 0 默认值：100 maxRetryTime\n描述：失败后重试的次数 必选：否 格式：int，需要保证大于 1 默认值：3 ignoreWriteError\n描述：如果设置为 true，则忽略写入错误，继续写入；否则，多次重试后仍写入失败的话，则会终止写入任务 必选：否 格式：bool 默认值：false 3.3 类型转换 DataX 内部类型 TSDB 数据类型 String TSDB 数据点序列化字符串，包括 timestamp、metric、tags 和 value 4 性能报告 4.1 环境准备 4.1.1 数据特征 从 Metric、时间线、Value 和 采集周期 四个方面来描述：\nmetric 固定指定一个 metric 为 m。\ntagkv 前四个 tagkv 全排列，形成 10 * 20 * 100 * 100 = 2000000 条时间线，最后 IP 对应 2000000 条时间线从 1 开始自增。\ntag_k tag_v zone z1~z10 cluster c1~c20 group g1~100 app a1~a100 ip ip1~ip2000000 value 度量值为 [1, 100] 区间内的随机值\ninterval 采集周期为 10 秒，持续摄入 3 小时，总数据量为 3 * 60 * 60 / 10 * 2000000 = 2,160,000,000 个数据点。\n4.1.2 机器参数 TSDB Writer 机型: 64C256G\nHBase 机型： 8C16G * 5\n4.1.3 DataX jvm 参数 \u0026ldquo;-Xms4096m -Xmx4096m\u0026rdquo;\n4.2 测试报告 通道数 DataX 速度 (Rec/s) DataX 流量 (MB/s) 1 129753 15.45 2 284953 33.70 3 385868 45.71 5 约束限制 5.1 目前只支持兼容 TSDB 2.4.x 及以上版本 其他版本暂不保证兼容\n6 FAQ ","permalink":"https://haokiu.com/blog/2a52431a701d4468a150a7986b3b4752/","summary":"TSDBWriter 插件文档 1 快速介绍 TSDBWriter 插件实现了将数据点写入到阿里巴巴自研 TSDB 数据库中（后续简称 TSDB）。\n时间序列数据库（Time Series Database , 简称 TSDB）是一种高性能，低成本，稳定可靠的在线时序数据库服务；提供高效读写，高压缩比存储、时序数据插值及聚合计算，广泛应用于物联网（IoT）设备监控系统 ，企业能源管理系统（EMS），生产安全监控系统，电力检测系统等行业场景。 TSDB 提供百万级时序数据秒级写入，高压缩比低成本存储、预降采样、插值、多维聚合计算，查询结果可视化功能；解决由于设备采集点数量巨大，数据采集频率高，造成的存储成本高，写入和查询分析效率低的问题。更多关于 TSDB 的介绍，详见阿里云 TSDB 官网。\n2 实现原理 通过 HTTP 连接 TSDB 实例，并通过 /api/put 接口将数据点写入。关于写入接口详见 TSDB 的接口说明文档。\n3 功能说明 3.1 配置样例 配置一个从 OpenTSDB 数据库同步抽取数据到 TSDB： { \u0026#34;job\u0026#34;: { \u0026#34;content\u0026#34;: [ { \u0026#34;reader\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;opentsdbreader\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:4242\u0026#34;, \u0026#34;column\u0026#34;: [ \u0026#34;m\u0026#34; ], \u0026#34;startTime\u0026#34;: \u0026#34;2019-01-01 00:00:00\u0026#34;, \u0026#34;endTime\u0026#34;: \u0026#34;2019-01-01 03:00:00\u0026#34; } }, \u0026#34;writer\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;tsdbhttpwriter\u0026#34;, \u0026#34;parameter\u0026#34;: { \u0026#34;endpoint\u0026#34;: \u0026#34;http://localhost:8242\u0026#34; } } } ], \u0026#34;setting\u0026#34;: { \u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 1 } } } } 3.2 参数说明 name\n描述：本插件的名称 必选：是 默认值：tsdbhttpwriter parameter\nendpoint 描述：TSDB 的 HTTP 连接地址 必选：是 格式：http://IP:Port 默认值：无 batchSize","title":"TSDBWriter 插件文档"},{"content":"阿里云开源离线同步工具DataX3.0介绍 一. DataX\u00083.0概览 ​\tDataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。\n设计理念 为了解决异构数据源同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。\n当前使用现状 DataX在阿里巴巴集团内被广泛使用，承担了所有大数据的离线同步业务，并已持续稳定运行了6年之久。目前每天完成同步8w多道作业，每日传输数据量超过300TB。\n此前已经开源DataX1.0版本，此次介绍为阿里云开源全新版本DataX3.0，有了更多更强大的功能和更好的使用体验。Github主页地址：https://github.com/alibaba/DataX\n二、DataX3.0框架设计 DataX本身作为离线数据同步框架，采用Framework + plugin架构构建。将数据源读取和写入抽象成为Reader/Writer插件，纳入到整个同步框架中。\nReader：Reader\u0008为数据采集模块，负责采集数据源的数据，将数据发送给Framework。 Writer： Writer为数据写入模块，负责不断向Framework取数据，并将数据写入到目的端。 Framework：Framework用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。 三. DataX3.0插件体系 ​\t经过几年积累，DataX目前已经有了比较全面的插件体系，主流的RDBMS数据库、NOSQL、大数据计算系统都已经接入。DataX目前支持数据如下：\n类型 数据源 Reader(读) Writer(写) 文档 RDBMS 关系型数据库 MySQL √ √ 读 、写 Oracle √ √ 读 、写 SQLServer √ √ 读 、写 PostgreSQL √ √ 读 、写 DRDS √ √ 读 、写 达梦 √ √ 读 、写 通用RDBMS(支持所有关系型数据库) √ √ 读 、写 阿里云数仓数据存储 ODPS √ √ 读 、写 ADS √ 写 OSS √ √ 读 、写 OCS √ √ 读 、写 NoSQL数据存储 OTS √ √ 读 、写 Hbase0.94 √ √ 读 、写 Hbase1.1 √ √ 读 、写 MongoDB √ √ 读 、写 Hive √ √ 读 、写 无结构化数据存储 TxtFile √ √ 读 、写 FTP √ √ 读 、写 HDFS √ √ 读 、写 Elasticsearch √ 写 DataX Framework提供了简单的接口与插件交互，提供简单的插件接入机制，只需要任意加上一种插件，就能无缝对接其他数据源。详情请看：DataX数据源指南\n\u0008四、DataX3.0核心架构 DataX 3.0 开源版本支持单机多线程模式完成同步作业运行，本小节按一个DataX作业生命周期的时序图，从整体架构设计非常简要说明DataX各个模块相互关系。\n核心模块介绍： DataX完成单个数据同步的作业，我们称之为Job，DataX接受到一个Job之后，将启动一个进程来完成整个作业同步过程。DataX Job模块是单个作业的中枢管理节点，承担了数据清理、子任务切分(将单一作业计算转化为多个子Task)、TaskGroup管理等功能。 DataXJob启动后，会根据不同的源端切分策略，将Job切分成多个小的Task(子任务)，以便于并发执行。Task便是DataX作业的最小单元，每一个Task都会负责一部分数据的同步工作。 切分多个Task之后，DataX Job会调用Scheduler模块，根据配置的并发数据量，将拆分成的Task重新组合，组装成TaskGroup(任务组)。每一个TaskGroup负责以一定的并发运行完毕分配好的所有Task，默认单个任务组的并发数量为5。 每一个Task都由TaskGroup负责启动，Task启动后，会固定启动Reader—\u0026gt;Channel—\u0026gt;Writer的线程来完成任务同步工作。 DataX作业运行起来之后， Job监控并等待多个TaskGroup模块任务完成，等待所有TaskGroup任务完成后Job成功退出。否则，异常退出，进程退出值非0 DataX调度流程： 举例来说，用户提交了一个DataX作业，并且配置了20个并发，目的是将一个100张分表的mysql数据同步到odps里面。\tDataX的调度决策思路是：\nDataXJob根据分库分表切分成了100个Task。 根据20个并发，DataX计算共需要分配4个TaskGroup。 4个TaskGroup平分切分好的100个Task，每一个TaskGroup负责以5个并发共计运行25个Task。 五、DataX 3.0六大核心优势 可靠的数据质量监控 完美解决数据传输个别类型失真问题\nDataX旧版对于部分数据类型(比如时间戳)传输一直存在毫秒阶段等数据失真情况，新版本DataX3.0已经做到支持所有的强数据类型，每一种插件都有自己的数据类型转换策略，让数据可以完整无损的传输到目的端。\n提供作业全链路的流量、数据量\u0008运行时监控\nDataX3.0运行过程中可以将作业本身状态、数据流量、数据速度、执行进度等信息进行全面的展示，让用户可以实时了解作业状态。并可在作业执行过程中智能判断源端和目的端的速度对比情况，给予用户更多性能排查信息。\n提供脏数据探测\n在大量数据的传输过程中，必定会由于各种原因导致很多数据传输报错(比如类型转换错误)，这种数据DataX认为就是脏数据。DataX目前可以实现脏数据精确过滤、识别、采集、展示，为用户提供多种的脏数据处理模式，让用户准确把控数据质量大关！\n丰富的数据转换功能 DataX作为一个服务于大数据的ETL工具，除了提供数据快照搬迁功能之外，还提供了丰富数据转换的功能，让数据在传输过程中可以轻松完成数据脱敏，补全，过滤等数据转换功能，另外还提供了自动groovy函数，让用户自定义转换函数。详情请看DataX3的transformer详细介绍。\n精准的速度控制 还在为同步过程对在线存储压力影响而担心吗？新版本DataX3.0提供了包括通道(并发)、记录流、字节流三种流控模式，可以随意控制你的作业速度，让你的作业在库可以承受的范围内达到最佳的同步速度。\n\u0026#34;speed\u0026#34;: { \u0026#34;channel\u0026#34;: 5, \u0026#34;byte\u0026#34;: 1048576, \u0026#34;record\u0026#34;: 10000 } 强劲的同步性能 DataX3.0每一种读插件都有一种或多种切分策略，都能将作业合理切分成多个Task并行执行，单机多线程执行模型可以让DataX速度随并发成线性增长。在源端和目的端性能都足够的情况下，单个作业一定可以打满网卡。另外，DataX团队对所有的已经接入的插件都做了极致的性能优化，并且做了完整的性能测试。性能测试相关详情可以参照每单个数据源的详细介绍：DataX数据源指南\n健壮的容错机制 DataX作业是极易受外部因素的干扰，网络闪断、数据源不稳定等因素很容易让同步到一半的作业报错停止。因此稳定性是DataX的基本要求，在DataX 3.0的设计中，重点完善了框架和插件的稳定性。目前DataX3.0可以做到线程级别、进程级别(暂时未开放)、作业级别多层次局部/全局的重试，保证用户的作业稳定运行。\n线程内部重试\nDataX的核心插件都经过团队的全盘review，不同的网络交互方式都有不同的重试策略。\n线程级别重试\n目前DataX已经可以实现TaskFailover，针对于中间失败的Task，DataX框架可以做到整个Task级别的重新调度。\n极简的使用体验 易用\n下载即可用，支持linux和windows，只需要短短几步骤就可以完成数据的传输。请点击：Quick Start\n详细\nDataX在运行日志中打印了大量信息，其中包括传输速度，Reader、Writer性能，进程CPU，JVM和GC情况等等。\n传输过程中打印传输速度、进度等\n传输过程中会打印进程相关的CPU、JVM等\n在任务结束之后，打印总体运行情况\n","permalink":"https://haokiu.com/blog/408be8b90df543789f79c7b43375e5a3/","summary":"阿里云开源离线同步工具DataX3.0介绍 一. DataX\u00083.0概览 ​\tDataX 是一个异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。\n设计理念 为了解决异构数据源同步问题，DataX将复杂的网状的同步链路变成了星型数据链路，DataX作为中间传输载体负责连接各种数据源。当需要接入一个新的数据源的时候，只需要将此数据源对接到DataX，便能跟已有的数据源做到无缝数据同步。\n当前使用现状 DataX在阿里巴巴集团内被广泛使用，承担了所有大数据的离线同步业务，并已持续稳定运行了6年之久。目前每天完成同步8w多道作业，每日传输数据量超过300TB。\n此前已经开源DataX1.0版本，此次介绍为阿里云开源全新版本DataX3.0，有了更多更强大的功能和更好的使用体验。Github主页地址：https://github.com/alibaba/DataX\n二、DataX3.0框架设计 DataX本身作为离线数据同步框架，采用Framework + plugin架构构建。将数据源读取和写入抽象成为Reader/Writer插件，纳入到整个同步框架中。\nReader：Reader\u0008为数据采集模块，负责采集数据源的数据，将数据发送给Framework。 Writer： Writer为数据写入模块，负责不断向Framework取数据，并将数据写入到目的端。 Framework：Framework用于连接reader和writer，作为两者的数据传输通道，并处理缓冲，流控，并发，数据转换等核心技术问题。 三. DataX3.0插件体系 ​\t经过几年积累，DataX目前已经有了比较全面的插件体系，主流的RDBMS数据库、NOSQL、大数据计算系统都已经接入。DataX目前支持数据如下：\n类型 数据源 Reader(读) Writer(写) 文档 RDBMS 关系型数据库 MySQL √ √ 读 、写 Oracle √ √ 读 、写 SQLServer √ √ 读 、写 PostgreSQL √ √ 读 、写 DRDS √ √ 读 、写 达梦 √ √ 读 、写 通用RDBMS(支持所有关系型数据库) √ √ 读 、写 阿里云数仓数据存储 ODPS √ √ 读 、写 ADS √ 写 OSS √ √ 读 、写 OCS √ √ 读 、写 NoSQL数据存储 OTS √ √ 读 、写 Hbase0.94 √ √ 读 、写 Hbase1.1 √ √ 读 、写 MongoDB √ √ 读 、写 Hive √ √ 读 、写 无结构化数据存储 TxtFile √ √ 读 、写 FTP √ √ 读 、写 HDFS √ √ 读 、写 Elasticsearch √ 写 DataX Framework提供了简单的接口与插件交互，提供简单的插件接入机制，只需要任意加上一种插件，就能无缝对接其他数据源。详情请看：DataX数据源指南","title":"阿里云开源离线同步工具DataX3.0介绍"},{"content":"mysql replace 可以将字段的字符串内容替换，语法：\nUpdate `table_name` SET `field_name` = replace (`field_name`,’from_str’,\u0026#39;to_str’) Where `field_name` LIKE ‘%from_str%’ 使用样例：\n# 将 blog 表的字段 coentent 里的 \u0026#34;https://haokiu.com\u0026#34; 替换为 \u0026#34;http://haokiu.com\u0026#34; update blog set content = replace(content, \u0026#34;https://haokiu.com\u0026#34;, \u0026#34;http://haokiu.com\u0026#34;) where content like \u0026#39;%https://haokiu.com%\u0026#39; ","permalink":"https://haokiu.com/blog/nfvw4R/","summary":"mysql replace 可以将字段的字符串内容替换，语法：\nUpdate `table_name` SET `field_name` = replace (`field_name`,’from_str’,\u0026#39;to_str’) Where `field_name` LIKE ‘%from_str%’ 使用样例：\n# 将 blog 表的字段 coentent 里的 \u0026#34;https://haokiu.com\u0026#34; 替换为 \u0026#34;http://haokiu.com\u0026#34; update blog set content = replace(content, \u0026#34;https://haokiu.com\u0026#34;, \u0026#34;http://haokiu.com\u0026#34;) where content like \u0026#39;%https://haokiu.com%\u0026#39; ","title":"mysql replace "},{"content":"1.1 Go1的诺言 Go语言从2007年开始设计，2009年底正式开源，而第一个正式的版本Go1则是在2012年上半年发布。Go1的语法变迁主要从Go第一个正式版本开始，Go1是Go语言官方对整个社区的承诺：Go1之后的版本将保证源代码层面兼容。\n从Go1的发布日志可以发现，Go1对语言和标准库做了严谨的梳理和完善，Go1的重大变化主要集中在语言和标准库部分。其中语言部分最大的变化是将原先的os.Error接口用内置的error接口类型替代、内置函数引入了close函数用于管道的关闭操作。此外，还对加强了init、append内置函数；增强了复合类型字面值的支持；针对Unicode字符增加了rune别名；改善了对map的遍历和删除元素操作；改进了影子返回值的报警提示；复制结构体时涵盖未导出的成员；明确了哪些类型可以进行相等性测试。同时对每个标准库的路径和功能进行详细的设计和完善。\n经过多年的发展和普及，大家已经对Go1语言和标准库耳熟能详，对变更的细节就不详细展开了。但正是这次梳理工作才奠定了Go1之后高速发展的十年。\n","permalink":"https://haokiu.com/blog/3edad2cabde0428f9098185e6d62c870/","summary":"1.1 Go1的诺言 Go语言从2007年开始设计，2009年底正式开源，而第一个正式的版本Go1则是在2012年上半年发布。Go1的语法变迁主要从Go第一个正式版本开始，Go1是Go语言官方对整个社区的承诺：Go1之后的版本将保证源代码层面兼容。\n从Go1的发布日志可以发现，Go1对语言和标准库做了严谨的梳理和完善，Go1的重大变化主要集中在语言和标准库部分。其中语言部分最大的变化是将原先的os.Error接口用内置的error接口类型替代、内置函数引入了close函数用于管道的关闭操作。此外，还对加强了init、append内置函数；增强了复合类型字面值的支持；针对Unicode字符增加了rune别名；改善了对map的遍历和删除元素操作；改进了影子返回值的报警提示；复制结构体时涵盖未导出的成员；明确了哪些类型可以进行相等性测试。同时对每个标准库的路径和功能进行详细的设计和完善。\n经过多年的发展和普及，大家已经对Go1语言和标准库耳熟能详，对变更的细节就不详细展开了。但正是这次梳理工作才奠定了Go1之后高速发展的十年。","title":"1.1 Go1的诺言"},{"content":"1.2 Go1到Go1.10 因为Go1承诺，Go1后序的版本都保持了向前兼容的目标。不过在从Go1发展到Go1.10的过程中，语言依然是增加了一些新的特性。本节我们简单回顾Go1到Go1.10的变化。\n1.2.1 Go1.2（2013年12月） Go1.2最大的语言变化是切片操作时，可以设置新切片的容量。这个需求在Go1之前就被提出了，但是因为Go1修改工作较大而延期到了Go1.2才被实现。\n比如下面的代码：\nvar a = make([]int, 10) var b = a[i:j:k] 其中b切片是从a切片的第i个元素开始到第j个元素前结束，b切片的容量为k（k指定的容量不能超出a切片的容量）。\n为了配合切片语法的变更，reflect包也增加了相应的方法：\nfunc (v Value) SetCap(cap int) func (v Value) Slice3(low, high, max int) Value 其中Value.SetCap只调整切片的容量，和a[::cap]写法效果等价。而Value.Slice3在进行切片操作的同时也指定新切片的容量，和a[low:high:max]写法效果等价。\n通过限制子切片的容量，可以将不同子切片进行安全的分割，避免子切片无意越界操作其它切片空间。\n1.2.2 Go1.4（2014年12月） Go1.4语言部分对for语法进行了加强。在Go1.3之前for只有下面两种写法：\nfor i, v := range x { // ... } for i := range x { // ... } for range针对要循环变量类型的不同，产生的循环变量也有差异。在第一种写法中，如果要循环的是数组或切片类型则i和v分别表示索引的下标和元素的值，如果循环的类型是map类型时则i和v分别表示键和值，这种写法不能用于管道类型变量的迭代。而第二种循环也可以用管道变量的迭代，直到管道被关闭时结束。如果用第二种方式循环遍历数组或map，则和for i, _ := range x {}的写法相关相同，相当于忽略的要迭代的值。\n但是有时候我们仅仅是要循环几次而并不关心循环变量的值，在Go1.3之前可以这样写：\nvar times [5][0]int for i := 0; i \u0026lt; len(times); i++ { // ... } for _ = range times { // ... } 前一种方式采用传统的for循环方式遍历，而后一种方式采用for range遍历，但是获取了每次遍历到的值。\n在Go1.4中，后一种方式可以省略掉前面的垃圾桶变量，像这样写：\nvar times [5][0]int for range times { // ... } 其中times对应一个[5][0]int类型的数组，虽然第一维数组有长度，但是数组的元素[0]int大小是0，因此整个数组占用的内存大小依然是0。没有付出额外的内存代价，我们就通过for range方式实现了times次快速迭代。\n1.2.4 Go1.7（2016年8月） 在Go1.3的时代（2014年），Go语言官方博客专门属文引入了context概念包，并稍后在golang.org/x/net/context提供了官方的实现。context包是Go语言官方对Go进行并发编程的实践成果，用来简化对于处理单个请求的多个Goroutine之间与请求域的数据、超时和退出等操作。context包推出后就被社区快速吸收使用，例如gRPC以及很多Web框架都通过context来控制Goroutine的生命周期。\n在Go1.7发布时，作为扩展包的golang.org/x/net/context终于移到标准库中。Go语言官方博客已经有专文讲述了context包的使用，这里就不详细展开了。感兴趣的读者可以查看并发相关的文档和书籍。\n1.2.5 Go1.8（2017年2月） Go1.8语言有一个小的变化，如果两个结构体成员名字和底层的类型相同（忽略成员的标签字符串差异），那么结构体底层对应相同的结构可以相互强制转型。\n比如下面的代码：\nfunc main() { type T1 struct { X int `json:\u0026#34;foo\u0026#34;` } type T2 struct { X int `json:\u0026#34;bar\u0026#34;` } var v1 = T1{X: 9527} var v2 = T2(v1) // now legal fmt.Println(v2) } T1和T2仅仅是成员标签字符串不同，但是底层结构是相同的，它们可以相互强制转型。\n1.2.6 Go1.9（2017年8月） Go1.9终于引入了类型别名的特性。类型别名的特性如下：\ntype T1 = T2 类型别名T1是通过=符号从T2定义，这里的T1和T2是完全相同的类型。\nGo语言的接口是一大亮点特性，接口是方法的集合，而方法正是依附于类型的函数。而类型别名的一个特殊的地方是，T1并不是一个新的类型，因此我们不能再为T1定义任何新的方法。\n之所以引入类型别名，很大的原因是为了解决Go1.7将context扩展库移动到标准库带来的问题。因为标准库和扩展库中分别定义了context.Context类型，而不同包中的类型是不相容的。而gRPC等很多开源的库使用的是最开始以来的扩展库中的context.Context类型，结果导致其无法和Go1.7标准库中的context.Context类型兼容。这个问题最终通过类型别名解决了：扩展库中的context.Context类型是标准库中context.Context的别名类型，从而实现了和标准库的兼容。\n类型别名虽然是为了解决特定问题而引入的补丁特性。但是从类型别名我们可以发现一些有趣的用法:\ntype ReaderA interface { Read(p []byte) (n int, err error) } type ReaderB = interface { Read(p []byte) (n int, err error) } 上面定义的两个读接口都有同样的方法集合。而Go语言的接口是采用隐式的转义，因此可能有人会觉得这两种写法根本没有什么意义！\n但是接口本身也是一种类型，如果我们基于ReaderA和ReaderB类型继续构造新的方法，就产生了差异：\ntype MakeReaderA interface { MakeReader() ReaderA } type MakeReaderB interface { MakeReader() ReaderB } 虽然接口定义方法的名字相同，但是方法返回的是两种不同的类型，因此方法的签名是不同的，所以说上面的两个接口并不相同。\n我们现在考虑通过类型别名的方式定义一个ReaderC接口，然后定义一个MakeReaderC接口：\ntype ReaderC = interface { Read(p []byte) (n int, err error) } type MakeReaderC interface { MakeReader() ReaderC } 比较神奇的是MakeReaderC和MakeReaderB接口可能是等价的，因为它定义的方法名和签名都是相同的。MakeReader方法返回的都是一个匿名的interface { Read(p []byte) (n int, err error) }接口类型。而Go语言中，所有的结构相同的匿名类型其实是同一个类型。\n如果通过类型别名从匿名接口构造接口，就可以避免新定义的不同接口类型对接口的方法签名造成影响。\n","permalink":"https://haokiu.com/blog/7ec2e79995ed4c9f8b883cc07c8d78f9/","summary":"1.2 Go1到Go1.10 因为Go1承诺，Go1后序的版本都保持了向前兼容的目标。不过在从Go1发展到Go1.10的过程中，语言依然是增加了一些新的特性。本节我们简单回顾Go1到Go1.10的变化。\n1.2.1 Go1.2（2013年12月） Go1.2最大的语言变化是切片操作时，可以设置新切片的容量。这个需求在Go1之前就被提出了，但是因为Go1修改工作较大而延期到了Go1.2才被实现。\n比如下面的代码：\nvar a = make([]int, 10) var b = a[i:j:k] 其中b切片是从a切片的第i个元素开始到第j个元素前结束，b切片的容量为k（k指定的容量不能超出a切片的容量）。\n为了配合切片语法的变更，reflect包也增加了相应的方法：\nfunc (v Value) SetCap(cap int) func (v Value) Slice3(low, high, max int) Value 其中Value.SetCap只调整切片的容量，和a[::cap]写法效果等价。而Value.Slice3在进行切片操作的同时也指定新切片的容量，和a[low:high:max]写法效果等价。\n通过限制子切片的容量，可以将不同子切片进行安全的分割，避免子切片无意越界操作其它切片空间。\n1.2.2 Go1.4（2014年12月） Go1.4语言部分对for语法进行了加强。在Go1.3之前for只有下面两种写法：\nfor i, v := range x { // ... } for i := range x { // ... } for range针对要循环变量类型的不同，产生的循环变量也有差异。在第一种写法中，如果要循环的是数组或切片类型则i和v分别表示索引的下标和元素的值，如果循环的类型是map类型时则i和v分别表示键和值，这种写法不能用于管道类型变量的迭代。而第二种循环也可以用管道变量的迭代，直到管道被关闭时结束。如果用第二种方式循环遍历数组或map，则和for i, _ := range x {}的写法相关相同，相当于忽略的要迭代的值。\n但是有时候我们仅仅是要循环几次而并不关心循环变量的值，在Go1.3之前可以这样写：\nvar times [5][0]int for i := 0; i \u0026lt; len(times); i++ { // ... } for _ = range times { // ... } 前一种方式采用传统的for循环方式遍历，而后一种方式采用for range遍历，但是获取了每次遍历到的值。\n在Go1.4中，后一种方式可以省略掉前面的垃圾桶变量，像这样写：\nvar times [5][0]int for range times { // ... } 其中times对应一个[5][0]int类型的数组，虽然第一维数组有长度，但是数组的元素[0]int大小是0，因此整个数组占用的内存大小依然是0。没有付出额外的内存代价，我们就通过for range方式实现了times次快速迭代。","title":"1.2 Go1到Go1.10"},{"content":"1.3 Go1.10过渡到Go2 回顾前一节中Go1到Go1.10的语法变化可发现，在Go1之后除了Go1.2的切片语法完善和Go1.9的类型别名很少有重量级的语法特性加入。这是因为Go1.2之后Go语言的语言设计基本是被冻结了，涉及到语言变化的Issue原则上必须通过Russ Cox等核心成员的同意才会被考虑。但是从Go1.10开始，官方终于开始启动Go2.0的语言前期设计工作。首先是官方开始提交模块化的草案，其次是很多呼声较高的语法糖特性开始被考虑逐步加入。可以说Go1.10之后进入了后Go1.0时代，它要在Go2.0到来之前解逐步完善细节问题，从而最终能给轻装上阵开始进入Go2.0开发流程。\n1.3.1 Go1.11（2018年8月） 在Go语言的发展史中，2018年注定是一个重要的时间点，因为在2018年8月正式发布了Go1.11。Go1.11语言部分虽然没有变化，但是带来了3个重量级的更新：一是amd64平台完全支持AVX512高性能的指令集；二是Go1.11开始支持模块化的特性；三是Go语言开始WebAssembly平台。这几个个改进将成为后Go1时代最大的亮点。\n首先AVX512高性能的指令集可以让Go语言榨干CPU的全部性能，为Go2进军运算密集型应用做好准备（如果对Go汇编语言感兴趣，可以参考作者的《Go语言高级编程》中汇编语言相关的章节）。而模块是管理任何大型工程必备的工具，但是Go语言发布十年来一直缺乏官方的模块化工具。模块化的特性将彻底解决大型Go语言工程的管理问题，至此Go1除了缺少泛型等特性已经近乎完美。最后，WebAssembly作为一个Web汇编语言和虚拟机标准，Go语言可能为Web开发打开一个崭新的领域。\n关于模块和WebAssembly都是较大的主题，它们目前都还是作为实验特性，希望在后序版本中逐步完成。在本书将有专门的章节讨论模块和WebAssembly相关的技术。\n1.3.2 Go1.12（2019年2月） Go1.12并没有增加新的语言特性，但是官方正式决定在下个Go1.13版本中删除对二进制包的支持。二进制包的是在Go1.7版本作为实验性的特性引入的，一个包可以以类似C语言静态库的方式采用二进制包发布，从而避免公布源代码。在Go语言不支持二进制包特性的时候，社区对这个需求呼声甚高，但是当官方真正支持了之后却根本没有人使用。Go语言官方删除二进制包的决定也是Go的“少即是多”的哲学决定的，而正是这种极度的克制的基因才造就了目前的Go语言成功。\n1.3.3 Go1.13（2019年8月） 从Go1.13开始，从Go1.11开始酝酿的诸多决定终于开始逐个生效：首先是模块化将成为默认的特性，彻底告别GOPATH时代；其次是不是太重要的二进制特性将被废除；最后是语言的进化将再次启动，一些细微的语言特性将在Go2到来之前被提前实现。\n最有可能被优先实现的特性有：数字支持下划线分割的特性，以便于书写更容易阅读的数字，比如100000000可以写为1_0000_0000；其次Go语言将引入二进制的数字字面值，比如0b00001111是以二进制格式书写的整数。这虽然是很小的语法糖改进，但是标志了Go2语言的开发工作正逐步进入开发计划。\n","permalink":"https://haokiu.com/blog/2756df043ed74a91bd57f134270e6cbc/","summary":"1.3 Go1.10过渡到Go2 回顾前一节中Go1到Go1.10的语法变化可发现，在Go1之后除了Go1.2的切片语法完善和Go1.9的类型别名很少有重量级的语法特性加入。这是因为Go1.2之后Go语言的语言设计基本是被冻结了，涉及到语言变化的Issue原则上必须通过Russ Cox等核心成员的同意才会被考虑。但是从Go1.10开始，官方终于开始启动Go2.0的语言前期设计工作。首先是官方开始提交模块化的草案，其次是很多呼声较高的语法糖特性开始被考虑逐步加入。可以说Go1.10之后进入了后Go1.0时代，它要在Go2.0到来之前解逐步完善细节问题，从而最终能给轻装上阵开始进入Go2.0开发流程。\n1.3.1 Go1.11（2018年8月） 在Go语言的发展史中，2018年注定是一个重要的时间点，因为在2018年8月正式发布了Go1.11。Go1.11语言部分虽然没有变化，但是带来了3个重量级的更新：一是amd64平台完全支持AVX512高性能的指令集；二是Go1.11开始支持模块化的特性；三是Go语言开始WebAssembly平台。这几个个改进将成为后Go1时代最大的亮点。\n首先AVX512高性能的指令集可以让Go语言榨干CPU的全部性能，为Go2进军运算密集型应用做好准备（如果对Go汇编语言感兴趣，可以参考作者的《Go语言高级编程》中汇编语言相关的章节）。而模块是管理任何大型工程必备的工具，但是Go语言发布十年来一直缺乏官方的模块化工具。模块化的特性将彻底解决大型Go语言工程的管理问题，至此Go1除了缺少泛型等特性已经近乎完美。最后，WebAssembly作为一个Web汇编语言和虚拟机标准，Go语言可能为Web开发打开一个崭新的领域。\n关于模块和WebAssembly都是较大的主题，它们目前都还是作为实验特性，希望在后序版本中逐步完成。在本书将有专门的章节讨论模块和WebAssembly相关的技术。\n1.3.2 Go1.12（2019年2月） Go1.12并没有增加新的语言特性，但是官方正式决定在下个Go1.13版本中删除对二进制包的支持。二进制包的是在Go1.7版本作为实验性的特性引入的，一个包可以以类似C语言静态库的方式采用二进制包发布，从而避免公布源代码。在Go语言不支持二进制包特性的时候，社区对这个需求呼声甚高，但是当官方真正支持了之后却根本没有人使用。Go语言官方删除二进制包的决定也是Go的“少即是多”的哲学决定的，而正是这种极度的克制的基因才造就了目前的Go语言成功。\n1.3.3 Go1.13（2019年8月） 从Go1.13开始，从Go1.11开始酝酿的诸多决定终于开始逐个生效：首先是模块化将成为默认的特性，彻底告别GOPATH时代；其次是不是太重要的二进制特性将被废除；最后是语言的进化将再次启动，一些细微的语言特性将在Go2到来之前被提前实现。\n最有可能被优先实现的特性有：数字支持下划线分割的特性，以便于书写更容易阅读的数字，比如100000000可以写为1_0000_0000；其次Go语言将引入二进制的数字字面值，比如0b00001111是以二进制格式书写的整数。这虽然是很小的语法糖改进，但是标志了Go2语言的开发工作正逐步进入开发计划。","title":"1.3 Go1.10过渡到Go2"},{"content":"1.4 Go2诞生 在2018年官方已经发布了Go2的设计草案，其中包含了令人惊喜的泛型和错误等诸多改进，在后Go1时代过去之后将是新兴的Go2时代。需要说明的是，Go2的诞生并不表示Go1被抛弃！如何避免Py3k的笑话正是Go2第一要考虑的问题，因此才会有Go1.11到Go2逐步过段的阶段。而Go语言官方也已经通过博文承诺Go2将保持对Go1软件资产的最大兼容，鉴于Go1诺言被忠实地执行的参考，我们有理由相信Go2会处理好Go1资产的兼容性问题。\n大约在2012年前后，作者曾乐观估计Go2将在2020年前后到来，并可能带来大家期盼已久的泛型特性。作者在此预测Go2将在2020年正式进入开发流程，并在2022年前后进入工业生产环境使用，而Go1将在2030年前后逐渐退出历史。为了在Go2正式到来时轻装上阵，我们需要提前把握Go语言的发展动向，而本书正是为此目标准备。\n","permalink":"https://haokiu.com/blog/4f9267cc85a647979aa3803c5c435407/","summary":"1.4 Go2诞生 在2018年官方已经发布了Go2的设计草案，其中包含了令人惊喜的泛型和错误等诸多改进，在后Go1时代过去之后将是新兴的Go2时代。需要说明的是，Go2的诞生并不表示Go1被抛弃！如何避免Py3k的笑话正是Go2第一要考虑的问题，因此才会有Go1.11到Go2逐步过段的阶段。而Go语言官方也已经通过博文承诺Go2将保持对Go1软件资产的最大兼容，鉴于Go1诺言被忠实地执行的参考，我们有理由相信Go2会处理好Go1资产的兼容性问题。\n大约在2012年前后，作者曾乐观估计Go2将在2020年前后到来，并可能带来大家期盼已久的泛型特性。作者在此预测Go2将在2020年正式进入开发流程，并在2022年前后进入工业生产环境使用，而Go1将在2030年前后逐渐退出历史。为了在Go2正式到来时轻装上阵，我们需要提前把握Go语言的发展动向，而本书正是为此目标准备。","title":"1.4 Go2诞生"},{"content":"2.1 Go1的包机制 同⽬录Go源⽂件的集合构成包，而同⽬录下⼦⽬录对应的包的集合构成模块（暂不考虑子模块）。因此，要了解模块之前需要先了解包。\n2.1.1 包是最小链接单位 Go语言是一种编译型的语言，链接的最小单位是包，对应go/ast.Package类型，多个包链接为一个可执行程序。在当前的官方实现中，一个包一般对应一个路径目录下的全部的Go语言源文件，而目录的路径包含了表示包的唯一路径名。Go语言的规范中包只是一个抽象的概念，并不要求包一定是以目录的方式展现，在未来包或者是模块也可能以压缩文件的方式展现。\n包是Go语言应用编译和链接的基本单位，因此模块最终的目的是为了管理这些包的版本。\n2.1.2 包目录布局的演变 在Go语言刚刚开源、还没有GOPATH环境变量之前，Go语言标准库的包全部是放在$(GOROOT)/src目录之下的，比如标准库中的image/png包对应$(GOROOT)/src/image/png目录。而第三方的包也可以放在$(GOROOT)/src目录，这时候Go语言的构建工具是不区分标准库的包和第三方包的。此外第三方或自己的应用对应的包，可以放在$(GOROOT)目录之外的任意目录。\n比如可以在任意目录创建一个hello.go文件：\npackage hello import \u0026#34;fmt\u0026#34; func PrintHello() { fmt.Printf(\u0026#34;Hello, 世界\\n\u0026#34;) } 然后在同级的目录创建一个Makefile文件用于管理构建工作：\ninclude $(GOROOT)/src/Make.inc TARG=github.com/chai2010/go2-book/ch2/hello GOFILES=./hello.go include $(GOROOT)/src/Make.pkg 第一个语句包含构建环境，最后的语句表示这是一个包。最重要的TARG变量定义了包的路径，而GOFILES则表示了包由哪些Go文件组成。然后执行make nuke就可以编译生成$(GOROOT)/pkg/github.com/chai2010/go2-book/ch2/hello.a文件。当另一个包要导入hello包时，实际上是从$(GOROOT)/pkg/github.com/chai2010/go2-book/ch2/hello.a文件读取包的信息。\n在Go1之前的史前时代，一切包都是手工构建安装的，因此包的版本管理也是手工的方式进行。如果需要使用社区开源的第三方包，需要手工下载代码放到合适的目录正确编译并安装之后才可以使用。\n为了将标准库的包和第三方的包分开管理，避免第三方包代码污染$(GOROOT)/src和$(GOROOT)/pkg目录，Go语言引入了GOPATH环境变量。GOPATH环境变量对应的目录用于管理非标准库的包，其中src用户存放Go代码，pkg用于存放编译后的.a文件，bin用于存放编译后的可执行程序。此后直到Go1.10，Go语言所有和包版本管理相关的工作都是基于GOPATH特性展开。\n2.1.3 GOPATH特性的扩展 扩展GOPATH的目标都是为了更方便管理包。Go语言的包有三种类型：首先是叶子包，此类包最多依赖标准库，不依赖第三方包；其次是main包表示一个应用，它不能被其它包导入（单元测试除外）；最后是普通的依赖第三方包的非main包。比较特殊的main包同时也是一个叶子包。\n叶子包自身很少会遇到版本管理问题，因为不会遇到因为依赖第三方包产生的各种问题，因此叶子包的开发者很少关注版本管理的问题。稍微复杂一点的是main包，main包是包依赖中的根包。main包不担心被其它包依赖，因此它其实是可以通过一个独占的GOPATH来维护所有依赖的第三方包的。最复杂的是既不是main包，也不是普通的叶子包，因为普通包需要管理其依赖的第三方包，同时一般又不能单独管理GOAPTH。在vendor出现之前的版本管理实践中，普通包的版本比较简陋，很多普通包甚至都没有版本管理，只有master一个最新版本。\nGOPATH的扩展主要分为横向和纵向两个方向。横向就是同时并列维护多个GOPATH目录，通过手工方式调整其中某些目录来实现目录中包版本切换的目的。纵向扩展一般在管理main包对应的应用程序中使用，通过在包内部创建临时的GOPATH子目录，在GOPATH子目录中包含全部第三方依赖的拷贝来实现外部依赖包版本的管理。\n社区中早期出现的Godeps工具就是通过在当前目录下创建Godeps/_workspace子目录来管理维护依赖的第三方包的版本。Godeps的实践成果最终被吸收到来Go语言中，通过vendor机制实现来main包的依赖管理（不是版本管理）。但是最终vendor机制也带来了各种问题（稍后的章节会讨论），最终官方完全重新设计了模块化的特性。\n2.1.4 模块化之后的包目录路径 通过vendor机制来实现版本管理的尝试虽然失败了，但是通过横向扩展GOPATH的来维护同一个包的不同版本的思路却在模块中复活了。模块化通过重新组织目录结构，实现了同时管理同一个包的不同版本需求。\n比如之前$(GOPATH)/src/github.com/chai2010/pbgo包的1.0.0版本，在模块化之后将对应$(HOME)/go/pkg/mod/github.com/chai2010/pbgo@1.0.0。模块化通过$(HOME)/go/pkg/mod目录管理第三方的依赖包，同时通过pkg@x.y.z的版本后缀来区分同一个包的不同版本。这其实和多个GOPATH并列存放的思路是类似，不过模块化对多版本支持的更加完美。\n","permalink":"https://haokiu.com/blog/e07062bd3a82483893b16c9a014f22dc/","summary":"2.1 Go1的包机制 同⽬录Go源⽂件的集合构成包，而同⽬录下⼦⽬录对应的包的集合构成模块（暂不考虑子模块）。因此，要了解模块之前需要先了解包。\n2.1.1 包是最小链接单位 Go语言是一种编译型的语言，链接的最小单位是包，对应go/ast.Package类型，多个包链接为一个可执行程序。在当前的官方实现中，一个包一般对应一个路径目录下的全部的Go语言源文件，而目录的路径包含了表示包的唯一路径名。Go语言的规范中包只是一个抽象的概念，并不要求包一定是以目录的方式展现，在未来包或者是模块也可能以压缩文件的方式展现。\n包是Go语言应用编译和链接的基本单位，因此模块最终的目的是为了管理这些包的版本。\n2.1.2 包目录布局的演变 在Go语言刚刚开源、还没有GOPATH环境变量之前，Go语言标准库的包全部是放在$(GOROOT)/src目录之下的，比如标准库中的image/png包对应$(GOROOT)/src/image/png目录。而第三方的包也可以放在$(GOROOT)/src目录，这时候Go语言的构建工具是不区分标准库的包和第三方包的。此外第三方或自己的应用对应的包，可以放在$(GOROOT)目录之外的任意目录。\n比如可以在任意目录创建一个hello.go文件：\npackage hello import \u0026#34;fmt\u0026#34; func PrintHello() { fmt.Printf(\u0026#34;Hello, 世界\\n\u0026#34;) } 然后在同级的目录创建一个Makefile文件用于管理构建工作：\ninclude $(GOROOT)/src/Make.inc TARG=github.com/chai2010/go2-book/ch2/hello GOFILES=./hello.go include $(GOROOT)/src/Make.pkg 第一个语句包含构建环境，最后的语句表示这是一个包。最重要的TARG变量定义了包的路径，而GOFILES则表示了包由哪些Go文件组成。然后执行make nuke就可以编译生成$(GOROOT)/pkg/github.com/chai2010/go2-book/ch2/hello.a文件。当另一个包要导入hello包时，实际上是从$(GOROOT)/pkg/github.com/chai2010/go2-book/ch2/hello.a文件读取包的信息。\n在Go1之前的史前时代，一切包都是手工构建安装的，因此包的版本管理也是手工的方式进行。如果需要使用社区开源的第三方包，需要手工下载代码放到合适的目录正确编译并安装之后才可以使用。\n为了将标准库的包和第三方的包分开管理，避免第三方包代码污染$(GOROOT)/src和$(GOROOT)/pkg目录，Go语言引入了GOPATH环境变量。GOPATH环境变量对应的目录用于管理非标准库的包，其中src用户存放Go代码，pkg用于存放编译后的.a文件，bin用于存放编译后的可执行程序。此后直到Go1.10，Go语言所有和包版本管理相关的工作都是基于GOPATH特性展开。\n2.1.3 GOPATH特性的扩展 扩展GOPATH的目标都是为了更方便管理包。Go语言的包有三种类型：首先是叶子包，此类包最多依赖标准库，不依赖第三方包；其次是main包表示一个应用，它不能被其它包导入（单元测试除外）；最后是普通的依赖第三方包的非main包。比较特殊的main包同时也是一个叶子包。\n叶子包自身很少会遇到版本管理问题，因为不会遇到因为依赖第三方包产生的各种问题，因此叶子包的开发者很少关注版本管理的问题。稍微复杂一点的是main包，main包是包依赖中的根包。main包不担心被其它包依赖，因此它其实是可以通过一个独占的GOPATH来维护所有依赖的第三方包的。最复杂的是既不是main包，也不是普通的叶子包，因为普通包需要管理其依赖的第三方包，同时一般又不能单独管理GOAPTH。在vendor出现之前的版本管理实践中，普通包的版本比较简陋，很多普通包甚至都没有版本管理，只有master一个最新版本。\nGOPATH的扩展主要分为横向和纵向两个方向。横向就是同时并列维护多个GOPATH目录，通过手工方式调整其中某些目录来实现目录中包版本切换的目的。纵向扩展一般在管理main包对应的应用程序中使用，通过在包内部创建临时的GOPATH子目录，在GOPATH子目录中包含全部第三方依赖的拷贝来实现外部依赖包版本的管理。\n社区中早期出现的Godeps工具就是通过在当前目录下创建Godeps/_workspace子目录来管理维护依赖的第三方包的版本。Godeps的实践成果最终被吸收到来Go语言中，通过vendor机制实现来main包的依赖管理（不是版本管理）。但是最终vendor机制也带来了各种问题（稍后的章节会讨论），最终官方完全重新设计了模块化的特性。\n2.1.4 模块化之后的包目录路径 通过vendor机制来实现版本管理的尝试虽然失败了，但是通过横向扩展GOPATH的来维护同一个包的不同版本的思路却在模块中复活了。模块化通过重新组织目录结构，实现了同时管理同一个包的不同版本需求。\n比如之前$(GOPATH)/src/github.com/chai2010/pbgo包的1.0.0版本，在模块化之后将对应$(HOME)/go/pkg/mod/github.com/chai2010/pbgo@1.0.0。模块化通过$(HOME)/go/pkg/mod目录管理第三方的依赖包，同时通过pkg@x.y.z的版本后缀来区分同一个包的不同版本。这其实和多个GOPATH并列存放的思路是类似，不过模块化对多版本支持的更加完美。","title":"2.1 Go1的包机制"},{"content":"2.2 基于vendor的版本管理 2.2.1 vendor的工作机制 2.2.1 vendor的优势 TODO\n2.2.1 vendor的问题 ","permalink":"https://haokiu.com/blog/ba3f4751a98a484f995283b9377b90d1/","summary":"2.2 基于vendor的版本管理 2.2.1 vendor的工作机制 2.2.1 vendor的优势 TODO\n2.2.1 vendor的问题 ","title":"2.2 基于vendor的版本管理"},{"content":"2.3 模块的设计⽬标 2.3.1 模块的概念 2.3.2 不同时间可重现构建 2.3.3 不同环境可重现构建 2.3.4 语义化版本号 2.3.5 最⼩化版本选择 TODO\n","permalink":"https://haokiu.com/blog/0ade9d480b954dbc96381d011208c5f1/","summary":"2.3 模块的设计⽬标 2.3.1 模块的概念 2.3.2 不同时间可重现构建 2.3.3 不同环境可重现构建 2.3.4 语义化版本号 2.3.5 最⼩化版本选择 TODO","title":"2.3 模块的设计⽬标"},{"content":"2.4 模块快速⼊⻔ 2.4.1 快速入门 2.4.2 go get重新⼊⻔ 2.4.3 go.mod⽂件 2.4.4 go.sum⽂件 2.4.5 版本切换 2.4.3 go mod命令 TODO\n","permalink":"https://haokiu.com/blog/99154ed6163e4a40bcfdc5e7d5956c7d/","summary":"2.4 模块快速⼊⻔ 2.4.1 快速入门 2.4.2 go get重新⼊⻔ 2.4.3 go.mod⽂件 2.4.4 go.sum⽂件 2.4.5 版本切换 2.4.3 go mod命令 TODO","title":"2.4 模块快速⼊⻔"},{"content":"2.5 子模块和多版本共存 2.5.1 子模块 2.5.2 多版本共存 TODO\n","permalink":"https://haokiu.com/blog/c868302e70ab472280a428d5583e15d2/","summary":"2.5 子模块和多版本共存 2.5.1 子模块 2.5.2 多版本共存 TODO","title":"2.5 子模块和多版本共存"},{"content":"2.6 镜像和私有仓库 2.6.1 Fork的仓库 2.6.2 私有仓库 TODO\n","permalink":"https://haokiu.com/blog/3681abb2d5e34af2be2ea2f170c6226f/","summary":"2.6 镜像和私有仓库 2.6.1 Fork的仓库 2.6.2 私有仓库 TODO","title":"2.6 镜像和私有仓库"},{"content":"2.7 模块化实践中的一些问题 2.7.1 和GOPATH不兼容 2.7.2 pkg目录复杂化 TODO\n","permalink":"https://haokiu.com/blog/1fbab86b16734c59b0bff743e512dfb2/","summary":"2.7 模块化实践中的一些问题 2.7.1 和GOPATH不兼容 2.7.2 pkg目录复杂化 TODO","title":"2.7 模块化实践中的一些问题"},{"content":"Go2编程指南 本书重点讲解Go2新特性，以及Go1教程中较少涉及的特性。本书适合对Go语言有一定基础的用户学习。对于刚学习Go语言的读者，建议先从《Go语言圣经》开始系统学习Go语言的基础知识。如果希望了解Go语言CGO或汇编语言的细节，可以参考《Go语言高级编程》。\n作者：柴树杉，Github @chai2010，Twitter @chaishushan 网址：https://github.com/chai2010/go2-book 在线阅读 https://chai2010.cn/go2-book/ 版权声明 Go2编程指南 由 柴树杉 采用 知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议进行许可。\n严禁任何商业行为使用或引用该文档的全部或部分内容！\n捐助支持 支付宝 微信 前言 TODO\n","permalink":"https://haokiu.com/blog/5c22f69800184d7a8705059ee3773333/","summary":"Go2编程指南 本书重点讲解Go2新特性，以及Go1教程中较少涉及的特性。本书适合对Go语言有一定基础的用户学习。对于刚学习Go语言的读者，建议先从《Go语言圣经》开始系统学习Go语言的基础知识。如果希望了解Go语言CGO或汇编语言的细节，可以参考《Go语言高级编程》。\n作者：柴树杉，Github @chai2010，Twitter @chaishushan 网址：https://github.com/chai2010/go2-book 在线阅读 https://chai2010.cn/go2-book/ 版权声明 Go2编程指南 由 柴树杉 采用 知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议进行许可。\n严禁任何商业行为使用或引用该文档的全部或部分内容！\n捐助支持 支付宝 微信 前言 TODO","title":"Go2编程指南"},{"content":"目录1.1 Go1的诺言1.2 Go1到Go1.101.3 Go1.10过渡到Go21.4 Go2诞生第1章 语法变迁2.1 Go1的包机制2.2 基于vendor的版本管理2.3 模块的设计⽬标2.4 模块快速⼊⻔2.5 子模块和多版本共存2.6 镜像和私有仓库2.7 模块化实践中的一些问题第2章 模块化第3章 错误处理Go2编程指南\n","permalink":"https://haokiu.com/blog/bk-3/","summary":"目录1.1 Go1的诺言1.2 Go1到Go1.101.3 Go1.10过渡到Go21.4 Go2诞生第1章 语法变迁2.1 Go1的包机制2.2 基于vendor的版本管理2.3 模块的设计⽬标2.4 模块快速⼊⻔2.5 子模块和多版本共存2.6 镜像和私有仓库2.7 模块化实践中的一些问题第2章 模块化第3章 错误处理Go2编程指南","title":"Go2编程指南"},{"content":"Go2编程指南 Go语言QQ群: 102319854, 1055927514 光谷码农课堂: https://study.163.com/provider/480000001914454/index.htm 凹语言(凹读音“Wa”)(The Wa Programming Language): https://github.com/wa-lang/wa 蚂蚁金服招聘云原生方向和编程语言方向岗位(杭州/P7)：云原生方向要求熟悉k8s配套工具，如kubectl、kustomize、kubebuilder，operator；编程语言方向要求对语言对语言解释器（如py/js/lua/wasm等）、工具链、配套SDK有一定兴趣和实践经验。欢迎各位同学咨询或推荐（推荐成功独享全额推荐红包）。联系方式 chaishushan@gmail.com, shushan.css@alibaba-inc.com\n本书重点讲解Go2新特性，以及Go1教程中较少涉及的特性。本书适合对Go语言有一定基础的用户学习。对于刚学习Go语言的读者，建议先从《Go语言圣经》开始系统学习Go语言的基础知识。如果希望了解Go语言CGO或汇编语言的细节，可以参考《Go语言高级编程》。如果希望深入学习Go语言语法树结构，可以参考《Go语法树入门——开启自制编程语言和编译器之旅》。\n作者：柴树杉，Github @chai2010，Twitter @chaishushan 网址：https://github.com/chai2010/go2-book Star历史：https://starcharts.herokuapp.com/chai2010/go2-book.svg 在线阅读 SUMMARY.md https://chai2010.cn/go2-book/ 网易云课堂·光谷码农课堂 https://study.163.com/provider/480000001914454/index.htm\n加入QQ群：102319854 中国最早的Go语言QQ群\n关注微信公众号(光谷码农/guanggu-coder) 加入微信群：从公众号底部菜单扫码进群。\n相关报告 GIAC: 2018 - Go 语言将要走向何方？(PDF) - 上海·GIAC全球互联网架构大会 2018/11/23 版权声明 Go2编程指南 由 柴树杉 采用 知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议进行许可。\n严禁任何商业行为使用或引用该文档的全部或部分内容！\n欢迎大家提供建议！\n","permalink":"https://haokiu.com/blog/e2e79e399c5b464295e2703c5db5739b/","summary":"Go2编程指南 Go语言QQ群: 102319854, 1055927514 光谷码农课堂: https://study.163.com/provider/480000001914454/index.htm 凹语言(凹读音“Wa”)(The Wa Programming Language): https://github.com/wa-lang/wa 蚂蚁金服招聘云原生方向和编程语言方向岗位(杭州/P7)：云原生方向要求熟悉k8s配套工具，如kubectl、kustomize、kubebuilder，operator；编程语言方向要求对语言对语言解释器（如py/js/lua/wasm等）、工具链、配套SDK有一定兴趣和实践经验。欢迎各位同学咨询或推荐（推荐成功独享全额推荐红包）。联系方式 chaishushan@gmail.com, shushan.css@alibaba-inc.com\n本书重点讲解Go2新特性，以及Go1教程中较少涉及的特性。本书适合对Go语言有一定基础的用户学习。对于刚学习Go语言的读者，建议先从《Go语言圣经》开始系统学习Go语言的基础知识。如果希望了解Go语言CGO或汇编语言的细节，可以参考《Go语言高级编程》。如果希望深入学习Go语言语法树结构，可以参考《Go语法树入门——开启自制编程语言和编译器之旅》。\n作者：柴树杉，Github @chai2010，Twitter @chaishushan 网址：https://github.com/chai2010/go2-book Star历史：https://starcharts.herokuapp.com/chai2010/go2-book.svg 在线阅读 SUMMARY.md https://chai2010.cn/go2-book/ 网易云课堂·光谷码农课堂 https://study.163.com/provider/480000001914454/index.htm\n加入QQ群：102319854 中国最早的Go语言QQ群\n关注微信公众号(光谷码农/guanggu-coder) 加入微信群：从公众号底部菜单扫码进群。\n相关报告 GIAC: 2018 - Go 语言将要走向何方？(PDF) - 上海·GIAC全球互联网架构大会 2018/11/23 版权声明 Go2编程指南 由 柴树杉 采用 知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议进行许可。\n严禁任何商业行为使用或引用该文档的全部或部分内容！\n欢迎大家提供建议！","title":"Go2编程指南"},{"content":"目录 第1章 语法变迁 1.1 Go1的诺言 1.2 Go1到Go1.10 1.3 Go1.10过渡到Go2 1.4 Go2诞生 第2章 模块化 2.1 Go1的包机制 2.2 基于vendor的版本管理(TODO) 2.3 模块的设计⽬标(TODO) 2.4 模块快速⼊⻔(TODO) 2.5 子模块和多版本共存(TODO) 2.6 镜像和私有仓库(TODO) 2.7 模块化实践中的一些问题(TODO) 第3章 错误处理(TODO) ","permalink":"https://haokiu.com/blog/1f4511a4eff2422184945a24e32887e2/","summary":"目录 第1章 语法变迁 1.1 Go1的诺言 1.2 Go1到Go1.10 1.3 Go1.10过渡到Go2 1.4 Go2诞生 第2章 模块化 2.1 Go1的包机制 2.2 基于vendor的版本管理(TODO) 2.3 模块的设计⽬标(TODO) 2.4 模块快速⼊⻔(TODO) 2.5 子模块和多版本共存(TODO) 2.6 镜像和私有仓库(TODO) 2.7 模块化实践中的一些问题(TODO) 第3章 错误处理(TODO) ","title":"目录"},{"content":"第1章 语法变迁 Go语言语法变化非常少，主要发生在Go1.10之前。Go1.10主要的开发工作在2017年下半年完成，在2018年初正式发布。Go1.10版可以说是Go1和Go2的分水岭，虽然语言本身没有大的变化，但是Go语言官方正式开始准备Go2的前期设计工作。在Go1.10以前，很多关于语言细节修改的建议绝大部分都被冻结了。但是在Go1.10以后，语言改进的工作又重新纳入日程。本章重点回顾Go1.0发布以来，语言发生了哪些细微的变化。\n","permalink":"https://haokiu.com/blog/c3984397f8e5480f81aaaeaf1b82ac23/","summary":"第1章 语法变迁 Go语言语法变化非常少，主要发生在Go1.10之前。Go1.10主要的开发工作在2017年下半年完成，在2018年初正式发布。Go1.10版可以说是Go1和Go2的分水岭，虽然语言本身没有大的变化，但是Go语言官方正式开始准备Go2的前期设计工作。在Go1.10以前，很多关于语言细节修改的建议绝大部分都被冻结了。但是在Go1.10以后，语言改进的工作又重新纳入日程。本章重点回顾Go1.0发布以来，语言发生了哪些细微的变化。","title":"第1章 语法变迁"},{"content":"第2章 模块化 模块化也称为包依赖管理，是管理任何大型工程必备的工具。Go语言发布十年来一直缺乏官方的模块化工具。同样在2018年，作为Go语言团队的技术领导人Russ Cox终于出手，重新发明了称为最小版本选择的包依赖管理的规则并提交了提案。模块特性已经被实验性地集成到Go1.11中，并将在后续版本中逐渐转化为正式特性。模块化的特性将彻底解决大型Go语言工程的管理问题，至此Go1除了缺少泛型等特性已经近乎完美。本章讨论模块相关的使用。\n","permalink":"https://haokiu.com/blog/8ef2da522892434187a81439c5d1dc2d/","summary":"第2章 模块化 模块化也称为包依赖管理，是管理任何大型工程必备的工具。Go语言发布十年来一直缺乏官方的模块化工具。同样在2018年，作为Go语言团队的技术领导人Russ Cox终于出手，重新发明了称为最小版本选择的包依赖管理的规则并提交了提案。模块特性已经被实验性地集成到Go1.11中，并将在后续版本中逐渐转化为正式特性。模块化的特性将彻底解决大型Go语言工程的管理问题，至此Go1除了缺少泛型等特性已经近乎完美。本章讨论模块相关的使用。","title":"第2章 模块化"},{"content":"第3章 错误处理 ","permalink":"https://haokiu.com/blog/615b0dd45d2e4323805039e0ffb41808/","summary":"第3章 错误处理 ","title":"第3章 错误处理"},{"content":"beego的url路径有多个变量的设置和获取方法。\n在 router.go 注册 url beego.Router(\u0026#34;/type/:type/?:page\u0026#34;, \u0026amp;controllers.WebController{}, \u0026#34;get:Type\u0026#34;) 获取变量 typeID, err := self.GetInt(\u0026#34;:type\u0026#34;) func (c *Controller) GetInt(key string, def ...int) (int, error) { strv := c.Ctx.Input.Query(key) if len(strv) == 0 \u0026amp;\u0026amp; len(def) \u0026gt; 0 { return def[0], nil } return strconv.Atoi(strv) } ","permalink":"https://haokiu.com/blog/RNbgLz/","summary":"beego的url路径有多个变量的设置和获取方法。\n在 router.go 注册 url beego.Router(\u0026#34;/type/:type/?:page\u0026#34;, \u0026amp;controllers.WebController{}, \u0026#34;get:Type\u0026#34;) 获取变量 typeID, err := self.GetInt(\u0026#34;:type\u0026#34;) func (c *Controller) GetInt(key string, def ...int) (int, error) { strv := c.Ctx.Input.Query(key) if len(strv) == 0 \u0026amp;\u0026amp; len(def) \u0026gt; 0 { return def[0], nil } return strconv.Atoi(strv) } ","title":"beego restful path variable"},{"content":"什么是 Vim？ Vim 是一个历史悠久的文本编辑器，可以追溯到 qed。 Bram Moolenaar 于 1991 年发布初始版本。\nLinux、Mac 用户，可以使用包管理器安装 Vim，对于 Windows 用户，可以从 我的网盘 下载。 该版本可轻易添加 python 、python3 、lua 等支持，只需要安装 python、lua 即可。\n项目在 Github 上开发，项目讨论请订阅 vim_dev 邮件列表。\n通过阅读 Why, oh WHY, do those #?@! nutheads use vi? 来对 Vim 进行大致的了解。\nVim 哲学 Vim 采用模式编辑的理念，即它提供了多种模式，按键在不同的模式下作用不同。 你可以在普通模式 下浏览文件，在插入模式下插入文本， 在可视模式下选择行，在命令模式下执行命令等等。起初这听起来可能很复杂， 但是这有一个很大的优点：不需要通过同时按住多个键来完成操作， 大多数时候你只需要依次按下这些按键即可。越常用的操作，所需要的按键数量越少。\n和模式编辑紧密相连的概念是 操作符 和 动作。操作符 指的是开始某个行为， 例如：修改、删除或者选择文本，之后你要用一个 动作 来指定需要操作的文本区域。 比如，要改变括号内的文本，需要执行 ci( （读做 change inner parentheses）； 删除整个段落的内容，需要执行 dap （读做：delete around paragraph）。\n如果你能看见 Vim 老司机操作，你会发现他们使用 Vim 脚本语言就如同钢琴师弹钢琴一样。复杂的操作只需要几个按键就能完成。他们甚至不用刻意去想，因为这已经成为肌肉记忆了。这减少认识负荷并帮助人们专注于实际任务。\n入门 Vim 自带一个交互式的教程，内含你需要了解的最基础的信息，你可以通过终端运行以下命令打开教程：\n$ vimtutor 不要因为这个看上去很无聊而跳过，按照此教程多练习。你以前用的 IDE 或者其他编辑器很少是有“模式”概念的，因此一开始你会很难适应模式切换。但是你 Vim 使用的越多，肌肉记忆 将越容易形成。\nVim 基于一个 vi 克隆，叫做 Stevie，支持两种运行模式：\u0026ldquo;compatible\u0026rdquo; 和 \u0026ldquo;nocompatible\u0026rdquo;。在兼容模式下运行 Vim 意味着使用 vi 的默认设置，而不是 Vim 的默认设置。除非你新建一个用户的 vimrc 或者使用 vim -N 命令启动 Vim，否则就是在兼容模式下运行 Vim！请大家不要在兼容模式下运行 Vim。\n下一步\n创建你自己的 vimrc。 在第一周准备备忘录。 通读基础章节了解 Vim 还有哪些功能。 按需学习！Vim 是学不完的。如果你遇到了问题，先上网寻找解决方案，你的问题可能已经被解决了。Vim 拥有大量的参考文档，知道如何利用这些参考文档很有必要：获取离线帮助。 浏览附加资源。 最后一个建议：使用插件之前，请先掌握 Vim 的基本操作。很多插件都只是对 Vim 自带功能的封装。\n返回主目录 ⤴️\n精简的 vimrc Vim 启动是会按照一定的优先顺序来搜索配置文件，这个顺序，可以通过 :version 命令查看。下面分 Windows 系统， 和 *niux 系统分别来说明 Vim 是如何载入配置文件的。\nWindows 系统 system vimrc file: \u0026#34;$VIM\\vimrc\u0026#34; user vimrc file: \u0026#34;$HOME\\_vimrc\u0026#34; 2nd user vimrc file: \u0026#34;$HOME\\vimfiles\\vimrc\u0026#34; 3rd user vimrc file: \u0026#34;$VIM\\_vimrc\u0026#34; user exrc file: \u0026#34;$HOME\\_exrc\u0026#34; 2nd user exrc file: \u0026#34;$VIM\\_exrc\u0026#34; system gvimrc file: \u0026#34;$VIM\\gvimrc\u0026#34; user gvimrc file: \u0026#34;$HOME\\_gvimrc\u0026#34; 2nd user gvimrc file: \u0026#34;$HOME\\vimfiles\\gvimrc\u0026#34; 3rd user gvimrc file: \u0026#34;$VIM\\_gvimrc\u0026#34; defaults file: \u0026#34;$VIMRUNTIME\\defaults.vim\u0026#34; system menu file: \u0026#34;$VIMRUNTIME\\menu.vim\u0026#34; 我们只看上面这一段，Vim 会优先读取 user vimrc file: $HOME\\_vimrc, 当这一文件不存在是， Vim 再去寻找 2nd user vimrc file: $HOME\\vimfiles\\vimrc; 倘若这个文件还是不存在，那么 Vim 会去继续寻找 3rd user vimrc file: $VIM\\_vimrc。 了解以上顺序后，就不会再因为 Vim 总是不读取配置文件而感到烦恼了。\nLinux 或者 Mac OS 同 Windows 系统类似，也可以使用 :version 命令查看 vim 载入配置的优先顺序。\n系统 vimrc 文件: \u0026#34;/etc/vimrc\u0026#34; 用户 vimrc 文件: \u0026#34;$HOME/.vimrc\u0026#34; 第二用户 vimrc 文件: \u0026#34;~/.vim/vimrc\u0026#34; 用户 exrc 文件: \u0026#34;$HOME/.exrc\u0026#34; defaults file: \u0026#34;$VIMRUNTIME/defaults.vim\u0026#34; $VIM 预设值: \u0026#34;/etc\u0026#34; $VIMRUNTIME 预设值: \u0026#34;/usr/share/vim/vim81\u0026#34; 你可以在网上找到许多精简的 vimrc 配置文件，我的版本可能并不是最简单的版本，但是我的版本提供了一套我认为良好的，非常适合入门的设置。\n最终你需要阅读完那些设置，然后自行决定需要使用哪些。:-)\n精简的 vimrc 地址：minimal-vimrc\n如果你有兴趣，这里是我（原作者）的 vimrc。\n建议：大多数插件作者都维护不止一个插件并且将他们的 vimrc 放在 Github 上展示（通常放在叫做 \u0026ldquo;vim-config\u0026rdquo; 或者 \u0026ldquo;dotfiles\u0026rdquo; 的仓库中），所以当你发现你喜欢的插件时，去插件维护者的 Github 主页看看有没有这样的仓库。\n返回主目录 ⤴️\n我正在使用什么样的 Vim 使用 :version 命令将向你展示当前正在运行的 Vim 的所有相关信息，包括它是如何编译的。\n第一行告诉你这个二进制文件的编译时间和版本号，比如：7.4。接下来的一行呈现 Included patches: 1-1051，这是补丁版本包。因此你 Vim 确切的版本号是 7.4.1051。\n另一行显示着一些像 Tiny version without GUI 或者 Huge version with GUI 的信息。很显然这些信息告诉你当前的 Vim 是否支持 GUI，例如：从终端中运行 gvim 或者从终端模拟器中的 Vim 内运行 :gui 命令。另一个重要的信息是 Tiny 和 Huge。Vim 的特性集区分被叫做 tiny，small，normal，big and huge，所有的都实现不同的功能子集。\n:version 主要的输出内容是特性列表。+clipboard 意味这剪贴板功能被编译支持了，-clipboard 意味着剪贴板特性没有被编译支持。\n一些功能特性需要编译支持才能正常工作。例如：为了让 :prof 工作，你需要使用 huge 模式编译的 Vim，因为那种模式启用了 +profile 特性。\n如果你的输出情况并不是那样，并且你是从包管理器安装 Vim 的，确保你安装了 vim-x，vim-x11，vim-gtk，vim-gnome 这些包或者相似的，因为这些包通常都是 huge 模式编译的。\n你也可以运行下面这段代码来测试 Vim 版本以及功能支持：\n\u0026#34; Do something if running at least Vim 7.4.42 with +profile enabled. if (v:version \u0026gt; 704 || v:version == 704 \u0026amp;\u0026amp; has(\u0026#39;patch42\u0026#39;)) \u0026amp;\u0026amp; has(\u0026#39;profile\u0026#39;) \u0026#34; do stuff endif 相关帮助：\n:h :version :h feature-list :h +feature-list :h has-patch 返回主目录 ⤴️\n备忘录 为了避免版权问题，我只贴出链接：\nhttp://people.csail.mit.edu/vgod/vim/vim-cheat-sheet-en.png https://cdn.shopify.com/s/files/1/0165/4168/files/preview.png http://www.nathael.org/Data/vi-vim-cheat-sheet.svg http://michael.peopleofhonoronly.com/vim/vim_cheat_sheet_for_programmers_screen.png http://www.rosipov.com/images/posts/vim-movement-commands-cheatsheet.png 或者在 Vim 中快速打开备忘录：vim-cheat40。\n返回主目录 ⤴️\n基础 缓冲区，窗口，标签 Vim 是一个文本编辑器。每次文本都是作为缓冲区的一部分显示的。每一份文件都是在他们自己独有的缓冲区打开的，插件显示的内容也在它们自己的缓冲区中。\n缓冲区有很多属性，比如这个缓冲区的内容是否可以修改，或者这个缓冲区是否和文件相关联，是否需要同步保存到磁盘上。\n窗口 是缓冲区上一层的视窗。如果你想同时查看几个文件或者查看同一文件的不同位置，那样你会需要窗口。\n请别把他们叫做 分屏 。你可以把一个窗口分割成两个，但是这并没有让这两个窗口完全 分离 。\n窗口可以水平或者竖直分割并且现有窗口的高度和宽度都是可以被调节设置的，因此，如果你需要多种窗口布局，请考虑使用标签。\n标签页 （标签）是窗口的集合。因此当你想使用多种窗口布局时候请使用标签。\n简单的说，如果你启动 Vim 的时候没有附带任何参数，你会得到一个包含着一个呈现一个缓冲区的窗口的标签。\n顺带提一下，缓冲区列表是全局可见的，你可以在任何标签中访问任何一个缓冲区。\n返回主目录 ⤴️\n已激活、已载入、已列出、已命名的缓冲区 用类似 vim file1 的命令启动 Vim 。这个文件的内容将会被加载到缓冲区中，你现在有一个已载入的缓冲区。如果你在 Vim 中保存这个文件，缓冲区内容将会被同步到磁盘上（写回文件中）。\n由于这个缓冲区也在一个窗口上显示，所以他也是一个已激活的缓冲区。如果你现在通过 :e file2 命令加载另一个文件，file1 将会变成一个隐藏的缓冲区，并且 file2 变成已激活缓冲区。\n使用 :ls 我们能够列出所有可以列出的缓冲区。插件缓冲区和帮助缓冲区通常被标记为不可以列出的缓冲区，因为那并不是你经常需要在编辑器中编辑的常规文件。通过 :ls! 命令可以显示被放入缓冲区列表的和未被放入列表的缓冲区。\n未命名的缓冲区是一种没有关联特定文件的缓冲区，这种缓冲区经常被插件使用。比如 :enew 将会创建一个无名临时缓冲区。添加一些文本然后使用 :w /tmp/foo 将他写入到磁盘，这样这个缓冲区就会变成一个已命名的缓冲区。\n返回主目录 ⤴️\n参数列表 全局缓冲区列表是 Vim 的特性。在这之前的 vi 中，仅仅只有参数列表，参数列表在 Vim 中依旧可以使用。\n每一个通过 shell 命令传递给 Vim 的文件名都被记录在一个参数列表中。可以有多个参数列表：默认情况下所有参数都被放在全局参数列表下，但是你可以使用 :arglocal 命令去创建一个新的本地窗口的参数列表。\n使用 :args 命令可以列出当前参数。使用 :next，:previous，:first，:last 命令可以在切换在参数列表中的文件。通过使用 :argadd，:argdelete 或者 :args 等命令加上一个文件列表可以改变参数列表。\n偏爱缓冲区列表还是参数列表完全是个人选择，我的印象中大多数人都是使用缓冲区列表的。\n然而参数列表在有些情况下被大量使用：批处理 使用 :argdo！ 一个简单的重构例子：\n:args **/*.[ch] :argdo %s/foo/bar/ge | update 这条命令将替换掉当前目录下以及当前目录的子目录中所有的 C 源文件和头文件中的“foo”，并用“bar”代替。\n相关帮助：:h argument-list\n返回主目录 ⤴️\n按键映射 使用 :map 命令家族你可以定义属于你自己的快捷键。该家族的每一个命令都限定在特定的模式下。从技术上来说 Vim 自带高达 12 中模式，其中 6 种可以被映射。另外一些命令作用于多种模式：\n递归 非递归 模式 :map :noremap normal, visual, operator-pending :nmap :nnoremap normal :xmap :xnoremap visual :cmap :cnoremap command-line :omap :onoremap operator-pending :imap :inoremap insert 例如：这个自定义的快捷键只在普通模式下工作。\n:nmap \u0026lt;space\u0026gt; :echo \u0026#34;foo\u0026#34;\u0026lt;cr\u0026gt; 使用 :nunmap \u0026lt;space\u0026gt; 可以取消这个映射。\n对于更少数，不常见的模式（或者他们的组合），查看 :h map-modes。\n到现在为止还好，对新手而言有一个问题会困扰他们：:nmap 是递归执行的！结果是，右边执行可能的映射。\n你自定义了一个简单的映射去输出“Foo”：\n:nmap b :echo \u0026#34;Foo\u0026#34;\u0026lt;cr\u0026gt; 但是如果你想要映射 b （回退一个单词）的默认功能到一个键上呢？\n:nmap a b 如果你敲击a，我们期望着光标回退到上一个单词，但是实际情况是“Foo”被输出到命令行里！因为在右边，b 已经被映射到别的行为上了，换句话说就是 :echo \u0026quot;Foo\u0026quot;\u0026lt;cr\u0026gt;。\n解决此问题的正确方法是使用一种 非递归 的映射代替：\n:nnoremap a b 经验法则：除递归映射是必须的，否则总是使用非递归映射。\n通过不给一个右值来检查你的映射。比如:nmap 显示所以普通模式下的映射，:nmap \u0026lt;leader\u0026gt; 显示所有以 \u0026lt;leader\u0026gt; 键开头的普通模式下的映射。\n如果你想禁止用标准映射，把他们映射到特殊字符 \u0026lt;nop\u0026gt; 上，例如：:noremap \u0026lt;left\u0026gt; \u0026lt;nop\u0026gt;。\n相关帮助：\n:h key-notation :h mapping :h 05.3 返回主目录 ⤴️\n映射前置键 映射前置键（Leader 键）本身就是一个按键映射，默认为 \\。我们可以通过在 map 中调用 \u0026lt;leader\u0026gt; 来为把它添加到其他按键映射中。\nnnoremap \u0026lt;leader\u0026gt;h :helpgrep\u0026lt;space\u0026gt; 这样，我们只需要先按 \\ 然后按 h 就可以激活这个映射 :helpgrep\u0026lt;space\u0026gt;。如果你想通过先按 空格 键来触发，只需要这样做：\nlet g:mapleader = \u0026#39; \u0026#39; nnoremap \u0026lt;leader\u0026gt;h :helpgrep\u0026lt;space\u0026gt; 此处建议使用 g:mapleader，因为在 Vim 脚本中，函数外的变量缺省的作用域是全局变量，但是在函数内缺省作用域是局部变量，而设置快捷键前缀需要修改全局变量 g:mapleader 的值。\n另外，还有一个叫 \u0026lt;localleader\u0026gt; 的，可以把它理解为局部环境中的 \u0026lt;leader\u0026gt;，默认值依然为 \\。当我们需要只对某一个条件下（比如，特定文件类型的插件）的缓冲区设置特别的 \u0026lt;leader\u0026gt; 键，那么我们就可以通过修改当前环境下的 \u0026lt;localleader\u0026gt; 来实现。\n注意：如果你打算设置 Leader 键，请确保在设置按键映射之前，先设置好 Leader 键。如果你先设置了含有 Leader 键的映射，然后又修改了 Leader 键，那么之前映射内的 Leader 键是不会因此而改变的。你可以通过执行 :nmap \u0026lt;leader\u0026gt; 来查看普通模式中已绑定给 Leader 键的所有映射。\n请参阅 :h mapleader 与 :h maploacalleader 来获取更多帮助。\n返回主目录 ⤴️\n寄存器 寄存器就是存储文本的地方。我们常用的「复制」操作就是把文本存储到寄存器，「 粘贴」 操作就是把文本从寄存器中读出来。顺便，在 Vim 中复制的快捷键是 y，粘贴的快捷键是 p。\nVim 为我们提供了如下的寄存器：\n类型 标识 读写者 是否为只读 包含的字符来源 Unnamed \u0026quot; vim 否 最近一次的复制或删除操作 (d, c, s, x, y) Numbered 0至9 vim 否 寄存器 0: 最近一次复制。寄存器 1: 最近一次删除。寄存器 2: 倒数第二次删除，以此类推。对于寄存器 1 至 9，他们其实是只读的最多包含 9 个元素的队列。这里的队列即为数据类型 queue Small delete - vim 否 最近一次行内删除 Named a至z, A至Z 用户 否 如果你通过复制操作存储文本至寄存器 a，那么 a 中的文本就会被完全覆盖。如果你存储至 A，那么会将文本添加给寄存器 a，不会覆盖之前已有的文本 Read-only :与.和% vim 是 :: 最近一次使用的命令，.: 最近一次添加的文本，%: 当前的文件名 Alternate buffer # vim 否 大部分情况下，这个寄存器是当前窗口中，上一次访问的缓冲区。请参阅 :h alternate-file 来获取更多帮助 Expression = 用户 否 复制 VimL 代码时，这个寄存器用于存储代码片段的执行结果。比如，在插入模式下复制 \u0026lt;c-r\u0026gt;=5+5\u0026lt;cr\u0026gt;，那么这个寄存器就会存入 10 Selection +和* vim 否 * 和 + 是 剪贴板 寄存器 Drop ~ vim 是 最后一次拖拽添加至 Vim 的文本（需要 \u0026ldquo;+dnd\u0026rdquo; 支持，暂时只支持 GTK GUI。请参阅 :help dnd 及 :help quote~） Black hole _ vim 否 一般称为黑洞寄存器。对于当前操作，如果你不希望在其他寄存器中保留文本，那就在命令前加上 _。比如，\u0026quot;_dd 命令不会将文本放到寄存器 \u0026quot;、1、+ 或 * 中 Last search pattern / vim 否 最近一次通过 /、? 或 :global 等命令调用的匹配条件 只要不是只读的寄存器，用户都有权限修改它的内容，比如：\n:let @/ = \u0026#39;register\u0026#39; 这样，我们按 n 的时候就会跳转到单词\u0026quot;register\u0026quot; 出现的地方。\n有些时候，你的操作可能已经修改了寄存器，而你没有察觉到。请参阅 :h registers 获取更多帮助。\n上面提到过，复制的命令是 y，粘贴的命令是 p 或者 P。但请注意，Vim 会区分「字符选取」与「行选取」。请参阅 :h linewise 获取更多帮助。\n行选取： 命令 yy 或 Y 都是复制当前行。这时移动光标至其他位置，按下 p 就可以在光标下方粘贴复制的行，按下 P 就可以在光标上方粘贴至复制的行。\n字符选取： 命令 0yw 可以复制第一个单词。这时移动光标至其他位置，按下 p 就可以在当前行、光标后的位置粘贴单词，按下 P 就可以在当前行、光标前的位置粘贴单词。\n将文本存到指定的寄存器中： 命令 \u0026quot;aY 可以将当前行复制，并存储到寄存器 a 中。这时移动光标至其他位置，通过命令 \u0026quot;AY 就可以把这一行的内容扩展到寄存器 a 中，而之前存储的内容也不会丢失。\n为了便于理解和记忆，建议大家现在就试一试上面提到的这些操作。操作过程中，你可以随时通过 :reg 来查看寄存器的变化。\n有趣的是： 在 Vim 中，y 是复制命令，源于单词 \u0026ldquo;yanking\u0026rdquo;。而在 Emacs 中，\u0026ldquo;yanking\u0026rdquo; 代表的是粘贴（或者说，重新插入刚才删掉的内容），而并不是复制。\n返回主目录 ⤴️\n范围 范围 (Ranges) 其实很好理解，但很多 Vim 用户的理解不到位。\n很多命令都可以加一个数字，用于指明操作范围 范围可以是一个行号，用于指定某一行 范围也可以是一对通过 , 或 ; 分割的行号 大部分命令，默认只作用于当前行 只有 :write 和 :global 是默认作用于所有行的 范围的使用是十分直观的。以下为一些例子（其中，:d 为 :delete 的缩写）：\n命令 操作的行 :d 当前行 :.d 当前行 :1d 第一行 :$d 最后一行 :1,$d 所有行 :%d 所有行（这是 1,$ 的语法糖） :.,5d 当前行至第 5 行 :,5d 同样是当前行至第 5 行 :,+3d 当前行及接下来的 3 行 :1,+3d 第一行至当前行再加 3 行 :,-3d 当前行及向上的 3 行（Vim 会弹出提示信息，因为这是一个保留的范围） :3,'xdelete 第三行至标注 为 x 的那一行 :/^foo/,$delete 当前行以下，以字符 \u0026ldquo;foo\u0026rdquo; 开头的那一行至结尾 :/^foo/+1,$delete 当前行以下，以字符 \u0026ldquo;foo\u0026rdquo; 开头的那一行的下一行至结尾 需要注意的是，; 也可以用于表示范围。区别在于，a,b 的 b 是以当前行作为参考的。而 a;b 的 b 是以 a 行作为参考的。举个例子，现在你的光标在第 5 行。这时 :1,+1d 会删除第 1 行至第 6 行，而 :1;+1d 会删除第 1 行和第 2 行。\n如果你想设置多个寻找条件，只需要在条件前加上 /，比如：\n:/foo//bar//quux/d 这就会删除当前行之后的某一行。定位方式是，先在当前行之后寻找第一个包含 \u0026ldquo;foo\u0026rdquo; 字符的那一行，然后在找到的这一行之后寻找第一个包含 \u0026ldquo;bar\u0026rdquo; 字符的那一行，然后再在找到的这一行之后寻找第一个包含 \u0026ldquo;quux\u0026rdquo; 的那一行。删除的就是最后找到的这一行。\n有时，Vim 会在命令前自动添加范围。举个例子，如果你先通过 V 命令进入行选取模式，选中一些行后按下 : 进入命令模式，这时候你会发现 Vim 自动添加了 '\u0026lt;,'\u0026gt; 范围。这表示，接下来的命令会使用之前选取的行号作为范围。但如果后续命令不支持范围，Vim 就会报错。为了避免这样的情况发生，有些人会设置这样的按键映射：:vnoremap foo :\u0026lt;c-u\u0026gt;command，组合键 Ctrl + u 可以清除当前命令行中的内容。\n另一个例子是在普通模式中按下 !!，命令行中会出现 :.!。如果这时你如果输入一个外部命令，那么当前行的内容就会被这个外部命令的输出替换。你也可以通过命令 :?^$?+1,/^$/-1!ls 把当前段落的内容替换成外部命令 ls 的输出，原理是向前和向后各搜索一个空白行，删除这两个空白行之间的内容，并将外部命令 ls 的输出放到这两个空白行之间。\n请参阅以下两个命令来获取更多帮助：\n:h cmdline-ranges :h 10.3 返回主目录 ⤴️\n标注 你可以使用标注功能来标记一个位置，也就是记录文件某行的某个位置。\n标注 设置者 使用 a-z 用户 仅对当前的一个文件生效，也就意味着只可以在当前文件中跳转 A-Z 用户 全局标注，可以作用于不同文件。大写标注也称为「文件标注」。跳转时有可能会切换到另一个缓冲区 0-9 viminfo 0 代表 viminfo 最后一次被写入的位置。实际使用中，就代表 Vim 进程最后一次结束的位置。1 代表 Vim 进程倒数第二次结束的位置，以此类推 如果想跳转到指定的标注，你可以先按下 ' / g' 或者 ` / g` 然后按下标注名。\n如果你想定义当前文件中的标注，可以先按下 m 再按下标注名。比如，按下 mm 就可以把当前位置标注为 m。在这之后，如果你的光标切换到了文件的其他位置，只需要通过 'm 或者 `m即可回到刚才标注的行。区别在于，'m会跳转回被标记行的第一个非空字符，而`m会跳转回被标记行的被标记列。根据 viminfo 的设置，你可以在退出 Vim 的时候保留小写字符标注。请参阅:h viminfo-' 来获取更多帮助。\n如果你想定义全局的标注，可以先按下 m 再按下大写英文字符。比如，按下 mM 就可以把当前文件的当前位置标注为 M。在这之后，就算你切换到其他的缓冲区，依然可以通过 'M 或 `M 跳转回来。\n关于跳转，还有以下的方式：\n按键 跳转至 '[ 与 `[ 上一次修改或复制的第一行或第一个字符 '] 与 `] 上一次修改或复制的最后一行或最后一个字符 '\u0026lt; 与 `\u0026lt; 上一次在可视模式下选取的第一行或第一个字符 '\u0026gt; 与 `\u0026gt; 上一次在可视模式下选取的最后一行或最后一个字符 '' 与 `' 上一次跳转之前的光标位置 '\u0026quot; 与 `\u0026quot; 上一次关闭当前缓冲区时的光标位置 '^ 与 `^ 上一次插入字符后的光标位置 '. 与 `. 上一次修改文本后的光标位置 '( 与 `( 当前句子的开头 ') 与 `) 当前句子的结尾 '{ 与 `{ 当前段落的开头 '} 与 `} 当前段落的结尾 标注也可以搭配 范围 一起使用。前面提到过，如果你在可视模式下选取一些文本，然后按下 :，这时候你会发现命令行已经被填充了 :'\u0026lt;,'\u0026gt;。对照上面的表格，现在你应该明白了，这段代表的就是可视模式下选取的范围。\n请使用 :marks 命令来显示所有的标注，参阅 :h mark-motions 来获取关于标注的更多帮助。\n返回主目录 ⤴️\n补全 Vim 在插入模式中为我们提供了多种补全方案。如果有多个补全结果，Vim 会弹出一个菜单供你选择。\n常见的补全有标签、项目中引入的模块或库中的方法名、文件名、字典及当前缓冲区的字段。\n针对不同的补全方案，Vim 为我们提供了不同的按键映射。这些映射都是在插入模式中通过 Ctrl + x 来触发：\n映射 类型 帮助文档 \u0026lt;c-x\u0026gt;\u0026lt;c-l\u0026gt; 整行 :h i^x^l \u0026lt;c-x\u0026gt;\u0026lt;c-n\u0026gt; 当前缓冲区中的关键字 :h i^x^n \u0026lt;c-x\u0026gt;\u0026lt;c-k\u0026gt; 字典（请参阅 :h 'dictionary'）中的关键字 :h i^x^k \u0026lt;c-x\u0026gt;\u0026lt;c-t\u0026gt; 同义词字典（请参阅 :h 'thesaurus'）中的关键字 :h i^x^t \u0026lt;c-x\u0026gt;\u0026lt;c-i\u0026gt; 当前文件以及包含的文件中的关键字 :h i^x^i \u0026lt;c-x\u0026gt;\u0026lt;c-]\u0026gt; 标签 :h i^x^] \u0026lt;c-x\u0026gt;\u0026lt;c-f\u0026gt; 文件名 :h i^x^f \u0026lt;c-x\u0026gt;\u0026lt;c-d\u0026gt; 定义或宏定义 :h i^x^d \u0026lt;c-x\u0026gt;\u0026lt;c-v\u0026gt; Vim 命令 :h i^x^v \u0026lt;c-x\u0026gt;\u0026lt;c-u\u0026gt; 用户自定义补全（通过 'completefunc' 定义） :h i^x^u \u0026lt;c-x\u0026gt;\u0026lt;c-o\u0026gt; Omni Completion（通过 'omnifunc' 定义） :h i^x^o \u0026lt;c-x\u0026gt;s 拼写建议 :h i^Xs 尽管用户自定义补全与 Omni Completion 是不同的，但他们做的事情基本一致。共同点在于，他们都是一个监听当前光标位置的函数，返回值为一系列的补全建议。用户自定义补全是由用户定义的，基于用户的个人用途，因此你可以根据自己的喜好和需求随意定制。而 Omni Completion 是针对文件类型的补全，比如在 C 语言中补全一个结构体（struct）的成员（members），或者补全一个类的方法，因而它通常都是由文件类型插件设置和调用的。\n如果你设置了 'complete' 选项，那么你就可以在一次操作中采用多种补全方案。这个选项默认包含了多种可能性，因此请按照自己的需求来配置。你可以通过 \u0026lt;c-n\u0026gt; 来调用下一个补全建议，或通过 \u0026lt;c-p\u0026gt; 来调用上一个补全建议。当然，这两个映射同样可以直接调用补全函数。请参阅 :h i^n 与 :h 'complete' 来获得更多帮助。\n如果你想配置弹出菜单的行为，请一定要看一看 :h 'completeopt' 这篇帮助文档。默认的配置已经不错了，但我个人（原作者）更倾向于把 \u0026ldquo;noselect\u0026rdquo; 加上。\n请参阅以下文档获取更多帮助：\n:h ins-completion :h popupmenu-keys :h new-omni-completion 返回主目录 ⤴️\n动作，操作符，文本对象 动作也就是指移动光标的操作，你肯定很熟悉 h、j、k 和 l，以及 w 和 b。但其实，/ 也是一个动作。他们都可以搭配数字使用，比如 2?the\u0026lt;cr\u0026gt; 可以将光标移动到倒数第二个 \u0026ldquo;the\u0026rdquo; 出现的位置。\n以下会列出一些常用的动作。你也可以通过 :h navigation 来获取更多的帮助。\n操作符是对某个区域文本执行的操作。比如，d、~、gU 和 \u0026gt; 都是操作符。这些操作符既可以在普通模式下使用，也可以在可视模式下使用。在普通模式中，顺序是先按操作符，再按动作指令，比如 \u0026gt;j。在可视模式中，选中区域后直接按操作符就可以，比如 Vjd。\n与动作一样，操作符也可以搭配数字使用，比如 2gUw 可以将当前单词以及下一个单词转成大写。由于动作和操作符都可以搭配数字使用，因此 2gU2w 与执行两次 gU2w 效果是相同的。\n请参阅 :h operator 来查看所有的操作符。你也可以通过 :set tildeop 命令把 ~ 也变成一个操作符\n值得注意的是，动作是单向的，而文本对象是双向的。文本对象不仅作用于符号（比如括号、中括号和大括号等）标记的范围内，也作用于整个单词、整个句子等其他情况。\n文本对象不能用于普通模式中移动光标的操作，因为光标还没有智能到可以向两个方向同时跳转。但这个功能可以在可视模式中实现，因为在对象的一端选中的情况下，光标只需要跳转到另一端就可以了。\n文本对象操作一般用 i 或 a 加上对象标识符操作，其中 i 表示在对象内（英文 inner）操作，a 表示对整个对象（英文 around）操作，这时开头和结尾的空格都会被考虑进来。举个例子，diw 可以删除当前单词，ci( 可以改变括号中的内容。\n文本对象同样可以与数字搭配使用。比如，像 ((( ))) 这样的文本，假如光标位于最内层的括号上或最内层的括号内，那么 d2a( 将会删除从最内层开始的两对括号，以及他们之间的所有内容。其实，d2a( 这个操作等同于 2da(。在 Vim 的命令中，如果有两处都可以接收数字作为参数，那么最终结果就等同于两个数字相乘。在这里，d 与 a( 都是可以接收参数的，一个参数是 1，另一个是 2，我们可以把它们相乘然后放到最前面。\n请参阅 :h text-objects 来获取更多关于文本对象的帮助。\n返回主目录 ⤴️\n自动命令 在特定的情况下，Vim 会传出事件。如果你想针对这些事件执行回调方法，那么就需要用到自动命令这个功能。\n如果没有了自动命令，那你基本上是用不了 Vim 的。自动命令一直都在执行，只是很多时候你没有注意到。不信的话，可以执行命令 :au ，不要被结果吓到，这些是当前有效的所有自动命令。\n请使用 :h {event} 来查看 Vim 中所有事件的列表，你也可以参考 :h autocmd-events-abc 来获取关于事件的更多帮助。\n一个很常用的例子，就是针对文件类型执行某些设置：\nautocmd FileType ruby setlocal shiftwidth=2 softtabstop=2 comments-=:# 但是缓冲区是如何知道当前的文件中包含 Ruby 代码呢？这其实是另一个自动命令检测的到的，然后把文件类型设置成为 Ruby，这样就触发了上面的 FileType 事件。\n在配置 vimrc 的时候，一般第一行加进去的就是 filetype on。这就意味着，Vim 启动时会读取 filetype.vim 文件，然后根据文件类型来触发相应的自动命令。\n如果你勇于尝试，可以查看下 :e $VIMRUNTIME/filetype.vim，然后在输出中搜索 \u0026ldquo;Ruby\u0026rdquo;。这样，你就会发现其实 Vim 只是通过文件扩展名 .rb 判断某个文件是不是 Ruby 的。\n注意：对于相同事件，如果有多个自动命令，那么自动命令会按照定义时的顺序执行。通过 :au 就可以查看它们的执行顺序。\nau BufNewFile,BufRead *.rb,*.rbw setf ruby BufNewFile 与 BufRead 事件是被写在 Vim 源文件中的。因此，每当你通过 :e 或者类似的命令打开文件，这两个事件都会触发。然后，就是读取 filetype.vim 文件来判断打开的文件类型。\n简单来说，事件和自动命令在 Vim 中的应用十分广泛。而且，Vim 为我们留出了一些易用的接口，方便用户配置适合自己的事件驱动回调。\n请参阅 :h autocommand 来获取更多帮助\n返回主目录 ⤴️\n变更历史，跳转历史 在 Vim 中，用户最近 100 次的文字改动都会被保存在变更历史中。如果在同一行有多个小改动，那么 Vim 会把它们合并成一个。尽管内容改动会合并，但作用的位置还是会只记录下最后一次改动的位置。\n在你移动光标或跳转的时候，每一次的移动或跳转前的位置会被记录到跳转历史中。类似地，跳转历史也可以最多保存 100 条记录。对于每个窗口，跳转记录是独立的。但当你分离窗口时（比如使用 :split 命令），跳转历史会被复制过去。\nVim 中的跳转命令，包括 '、`、G、/、?、n、N、%、(、)、[[、]]、{、}、:s、:tag、L、M、H 以及开始编辑一个新文件的命令。\n列表 显示所有条目 跳转到上一个位置 跳转到下一个位置 跳转历史 :jumps [count]\u0026lt;c-o\u0026gt; [count]\u0026lt;c-i\u0026gt; 变更历史 :changes [count]g; [count]g, 如果你执行第二列的命令显示所有条目，这时 Vim 会用 \u0026gt; 标记来为你指示当前位置。通常这个标记位于 1 的下方，也就代表最后一次的位置。\n如果你希望关闭 Vim 之后还保留这些条目，请参阅 :h viminfo-' 来获取更多帮助。\n注意：上面提到过，最后一次跳转前的位置也会记录在标注中，也可以通过连按 `` 或 \u0026rsquo;\u0026rsquo; 跳转到那个位置\n请参阅以下两个命令来获取更多帮助：\n:h changelist :h jumplist 返回主目录 ⤴️\n内容变更历史记录 Vim 会记录文本改变之前的状态。因此，你可以使用「撤销」操作 u 来取消更改，也可以通过「重做」操作 Ctrl + r 来恢复更改。\n值得注意的是，Vim 采用 tree 数据结构来存储内容变更的历史记录，而不是采用 queue。你的每次改动都会成为存储为树的节点。而且，除了第一次改动（根节点），之后的每次改动都可以找到一个对应的父节点。每一个节点都会记录改动的内容和时间。其中，「分支」代表从任一节点到根节点的路径。当你进行了撤销操作，然后又输入了新的内容，这时候就相当于创建了分支。这个原理和 git 中的 branch（分支）十分类似。\n考虑以下这一系列按键操作：\nifoo\u0026lt;esc\u0026gt; obar\u0026lt;esc\u0026gt; obaz\u0026lt;esc\u0026gt; u oquux\u0026lt;exc\u0026gt; 那么现在，Vim 中会显示三行文本，分别是 \u0026ldquo;foo\u0026rdquo;、\u0026ldquo;bar\u0026rdquo; 和 \u0026ldquo;quux\u0026rdquo;。这时候，存储的树形结构如下：\nfoo(1) / bar(2) / \\ baz(3) quux(4) 这个树形结构共包含四次改动，括号中的数字就代表时间顺序。\n现在，我们有两种方式遍历这个树结构。一种叫「按分支遍历」，一种叫「按时间遍历」。\n撤销 u 与重做 Ctrl + r 操作是按分支遍历。对于上面的例子，现在我们有三行字符。这时候按 u 会回退到 \u0026ldquo;bar\u0026rdquo; 节点，如果再按一次 u 则会回退到 \u0026ldquo;foo\u0026rdquo; 节点。这时，如果我们按下 Ctrl + r 就会前进至 \u0026ldquo;bar\u0026rdquo; 节点，再按一次就回前进至 \u0026ldquo;quux\u0026rdquo; 节点。在这种方式下，我们无法访问到兄弟节点（即 \u0026ldquo;baz\u0026rdquo; 节点）。\n与之对应的是按时间遍历，对应的按键是 g- 和 g+。对于上面的例子，按下 g- 会首先回退到 \u0026ldquo;baz\u0026rdquo; 节点。再次按下 g- 会回退到 \u0026ldquo;bar\u0026rdquo; 节点。\n命令/按键 执行效果 [count]u 或 :undo [count] 回退到 [count] 次改动之前 [count]\u0026lt;c-r\u0026gt; 或 :redo [count] 重做 [count] 次改动 U 回退至最新的改动 [count]g- 或 :earlier [count]? 根据时间回退到 [count] 次改动之前。\u0026quot;?\u0026quot; 为 \u0026ldquo;s\u0026rdquo;、\u0026ldquo;m\u0026rdquo;、\u0026ldquo;h\u0026rdquo;、\u0026ldquo;d\u0026rdquo; 或 \u0026ldquo;f\u0026quot;之一。例如，:earlier 2d 会回退到两天之前。:earlier 1f 则会回退到最近一次文件保存时的内容 [count]g+ 或 :later [count]? 类似 g-，但方向相反 内容变更记录会储存在内存中，当 Vim 退出时就会清空。如果需要持久化存储内容变更记录，请参阅备份文件，交换文件，撤销文件以及 viminfo 文件的处理章节的内容。\n如果你觉得这一部分的内容难以理解，请参阅 undotree，这是一个可视化管理内容变更历史记录的插件。类似的还有 vim-mundo。\n请参阅以下链接获取更多帮助：\n:h undo.txt :h usr_32 返回主目录 ⤴️\n全局位置信息表，局部位置信息表 在某一个动作返回一系列「位置」的时候，我们可以利用「全局位置信息表」和「局部位置信息表」来存储这些位置信息，方便以后跳转回对应的位置。每一个存储的位置包括文件名、行号和列号。\n比如，编译代码是出现错误，这时候我们就可以把错误的位置直接显示在全局位置信息表，或者通过外部抓取工具使位置显示在局部位置信息表中。\n尽管我们也可以把这些信息显示到一个空格缓冲区中，但用这两个信息表显示的好处在于接口调用很方便，而且也便于浏览输出。\nVim 中，全局位置信息表只能有一个，但每一个窗口都可以有自己的局部位置信息表。这两个信息表的外观看上去很类似，但在操作上会稍有不同。\n以下为两者的操作比较：\n动作 全局位置信息表 局部位置信息表 打开窗口 :copen :lopen 关闭窗口 :cclose :lclose 下一个条目 :cnext :lnext 上一个条目 :cprevious :lprevious 第一个条目 :cfirst :lfirst 最后一个条目 :clast :llast 请参阅 :h :cc 以及底下的内容，来获取更多命令的帮助。\n应用实例： 如果我们想用 grep 递归地在当前文件夹中寻找某个关键词，然后把输出结果放到全局位置信息表中，只需要这样：\n:let \u0026amp;grepprg = \u0026#39;grep -Rn $* .\u0026#39; :grep! foo \u0026lt;grep output - hit enter\u0026gt; :copen 执行了上面的代码，你就能看到所有包含字符串 \u0026ldquo;foo\u0026rdquo; 的文件名以及匹配到的相关字段都会显示在全局位置信息表中。\n返回主目录 ⤴️\n宏 你可以在 Vim 中录制一系列按键，并把他们存储到寄存器中。对于一些需要临时使用多次的一系列操作，把它们作为宏保存起来会显著地提升效率。对于一些复杂的操作，建议使用 Vim 脚本来实现。\n首先，按下 q，然后按下你想要保存的寄存器，任何小写字母都可以。比如我们来把它保存到 q 这个寄存器中。按下 qq，你会发现命令行里已经显示了 \u0026ldquo;recording @q\u0026rdquo;。 如果你已经录制完成，那么只需要再按一次 q 就可以结束录制。 如果你想调用刚才录制的宏，只需要 [count]@q 如果你想调用上一次使用的宏，只需要 [count]@@ 实例 1：\n一个插入字符串 \u0026ldquo;abc\u0026rdquo; 后换行的宏，重复调用十次：\nqq iabc\u0026lt;cr\u0026gt;\u0026lt;esc\u0026gt; q 10@q （对于上面这个功能，你同样可以通过如下的按键： oabc 然后 ESC 然后 10. 来实现）。\n实例 2：\n一个在每行前都加上行号的宏。从第一行开始，行号为 1，后面依次递增。我们可以通过 Ctrl + a 来实现递增的行号，在定义宏的时候，它会显示成 ^A。\nqq 0yf jP0^A q 1000 @q 这里能实现功能，是因为我们假定了文件最多只有 1000 行。但更好的方式是使用「递归」宏，它会一直执行，知道不能执行为止：\nqq 0yf jP0^A@q q @q （对于上面这个插入行号的功能，如果你不愿意使用宏，同样可以通过这段按键操作来实现：:%s/^/\\=line('.') . '. '）。\n这里向大家展示了如何不用宏来达到相应的效果，但要注意，这些不用宏的实现方式只适用于这些简单的示例。对于一些比较复杂的自动化操作，你确实应该考虑使用宏。\n请参阅以下文档获取更多帮助：\n:h recording :h \u0026#39;lazyredraw\u0026#39; 返回主目录 ⤴️\n颜色主题 颜色主题可以把你的 Vim 变得更漂亮。Vim 是由多个组件构成的，我们可以给每一个组件都设置不同的文字颜色、背景颜色以及文字加粗等等。比如，我们可以通过这个命令来设置背景颜色：\n:highlight Normal ctermbg=1 guibg=red 执行后你会发现，现在背景颜色变成红色了。请参阅 :h :highlight 来获取更多帮助。\n其实，颜色主题就是一系列的 :highlight 命令的集合。\n事实上，大部分颜色主题都包含两套配置。一套适用于例如 xterm 和 iTerm 这样的终端环境（使用前缀 cterm），另一套适用于例如 gvim 和 MacVim 的图形界面环境（使用前缀 gui）。对于上面的例子，ctermbg 就是针对终端环境的，而 guibg 就是针对图形界面环境的。\n如果你下载了一个颜色主题，并且在终端环境中打开了 Vim，然后发现显示的颜色与主题截图中差别很大，那很可能是配置文件只设置了图形界面环境的颜色。反之同理，如果你使用的是图形界面环境，发现显示颜色有问题，那就很可能是配置文件只设置了终端环境的颜色。\n第二种情况（图形界面环境的显示问题）其实不难解决。如果你使用的是 Neovim 或者 Vim 7.4.1830 的后续版本，可以通过打开真彩色设置来解决显示问题。这就可以让终端环境的 Vim 使用 GUI 的颜色定义，但首先，你要确认一下你的终端环境和环境内的组件（比如 tmux）是否都支持真彩色。可以看一下这篇文档，描述的十分详细。\n请参阅以下文档或链接来获取更多帮助：\n:h 'termguicolors' 主题列表 自定义主题中的颜色 返回主目录 ⤴️\n折叠 每一部分文字（或者代码）都会有特定的结构。对于存在结构的文字和代码，也就意味着它们可以按照一定的逻辑分割成不同区域。Vim 中的折叠功能，就是按照特定的逻辑把文字和代码折叠成一行，并显示一些简短的描述。折叠功能涉及到很多操作，而且折叠功能可以嵌套使用。\n在 Vim 中，有以下 6 中折叠类型：\n折叠方式 概述 diff 在「比较窗口」中折叠未改变的文本 expr 使用 'foldexpr' 来创建新的折叠逻辑 indent 基于缩进折叠 manual 使用 zf、zF 或 :fold 来自定义折叠 marker 根据特定的文本标记折叠（通常用于代码注释） syntax 根据语法折叠，比如折叠 if 代码块 注意：折叠功能可能会显著地影响性能。如果你在使用折叠功能的时候出现了打字卡顿之类的问题，请考虑使用 FastFold 插件。这个插件可以让 Vim 按需更新折叠内容，而不是一直调用。\n请参阅以下文档获取更多帮助：\n:h usr_28 :h folds 会话 如果你保存了当前的「视图」（请参阅 :h :mkview），那么当前窗口、配置和按键映射都会被保存下来（请参阅 :h :loadview）。\n「会话」就是存储所有窗口的相关设置，以及全局设置。简单来说，就是给当前的 Vim 运行实例拍个照，然后把相关信息存储到会话文件中。存储之后的改动就不会在会话文件中显示，你只需要在改动后更新一下会话文件就可以了。\n你可以把当前工作的「项目」存储起来，然后可以在不同的「项目」之间切换。\n现在就来试试吧。打开几个窗口和标签，然后执行 :mksession Foo.vim。如果你没有指定文件名，那就会默认保存为 Session.vim。这个文件会保存在当前的目录下，你可以通过 :pwd 来显示当前路径。重启 Vim 之后，你只需要执行 :source Foo.vim，就可以恢复刚才的会话了。所有的缓冲区、窗口布局、按键映射以及工作路径都会恢复到保存时的状态。\n其实 Vim 的会话文件就只是 Vim 命令的集合。你可以通过命令 :vs Foo.vim 来看看会话文件中究竟有什么。\n你可以决定 Vim 会话中究竟要保存哪些配置，只需要设置一下 'sessionoptions' 就可以了。\n为了方便开发，Vim 把最后一次调用或写入的会话赋值给了一个内部变量 v:this_session。\n请参阅以下文档来获取更多帮助：\n:h Session :h \u0026#39;sessionoptions\u0026#39; :h v:this_session 局部化 以上提到的很多概念，都有一个局部化（非全局）的版本：\n全局 局部 作用域 帮助文档 :set :setlocal 缓冲区或窗口 :h local-options :map :map \u0026lt;buffer\u0026gt; 缓冲区 :h :map-local :autocmd :autocmd * \u0026lt;buffer\u0026gt; 缓冲区 :h autocmd-buflocal :cd :lcd 窗口 :h :lcd :\u0026lt;leader\u0026gt; :\u0026lt;localleader\u0026gt; 缓冲区 :h maploacalleader 变量也有不同的作用域，详细内容请参考 Vim scripting 的文档。\n用法 获取离线帮助 Vim 自带了一套很完善的帮助文档，它们是一个个有固定排版格式的文本文件，通过标签可以访问这些文件的特定位置。\n在开始之前先读一下这个章节：:help :help。执行这个命令以后会在新窗口打开 $VIMRUNTIME/doc/helphelp.txt 文件并跳转到这个文件中 :help 标签的位置。\n一些关于帮助主题的简单规则：\n用单引号把文本包起来表示选项，如：:h 'textwidth' 以小括号结尾表示 VimL 函数，如：:h reverse() 以英文冒号开头表示命令，如：:h :echo 使用快捷键 \u0026lt;c-d\u0026gt; （这是 ctrl+d）来列出所有包含你当前输入的内容的帮助主题。如：:h tab\u0026lt;c-d\u0026gt; 会列出所有包含 tab 主题，从 softtabstop 到 setting-guitablabel （译者注：根据安装的插件不同列出的选项也会不同）。\n你想查看所有的 VimL 方法吗？很简单，只要输入：:h ()\u0026lt;c-d\u0026gt; 就可以了。你想查看所有与窗口相关的函数吗？输入 :h win*()\u0026lt;c-d\u0026gt;。\n相信你很快就能掌握这些技巧，但是在刚开始的时候，你可能对于该通过什么进行查找一点线索都没有。这时你可以想象一些与要查找的内容相关的关键字，再让 :helpgrep 来帮忙。\n:helpgrep backwards 上面的命令会在所有的帮助文件中搜索“backwards”，然后跳转到第一个匹配的位置。所有的匹配位置都会被添加到全局位置信息表，用 :cp / :cn 可以在匹配位置之间进行切换。或者用 :copen 命令来打开全局位置信息表，将光标定位到你想要的位置，再按 回车就可以跳转到该匹配项。详细说明请参考 :h quickfix。\n获取离线帮助（补充） 这个列表最初发表在 vim_dev，由 @chrisbra 编辑的，他是 Vim 开发人员中最活跃的一个。\n经过一些微小的改动后，重新发布到了这里。\n如果你知道你想要找什么，使用帮助系统的搜索会更简单一些，因为搜索出的主题都带有固定的格式。\n而且帮助系统中的主题包含了你当前使用的 Vim 版本的所特有特性，而网上那些已经过时或者是早期发布的话题是不会包含这些的。\n因此学习使用帮助系统以及它所用的语言是很有必要的。这里是一些例子（不一定全，我有可能忘了一些什么）。\n（译者注：下面列表中提及的都是如何指定搜索主题以便快速准确的找到你想要的帮助）\n选项要用单引号引起来。用 :h 'list' 来查看列表选项帮助。只有你明确的知道你要找这么一个选项的时候才可以这么做，不然的话你可以用 :h options.txt 来打开所有选项的帮助页面，再用正则表达式进行搜索，如：/width。某些选项有它们自己的命名空间，如：:h cpo-a，:h cpo-A， :h cpo-b 等等。\n普通模式的命令不能用冒号作为前缀。使用 :h gt 来转到“gt”命令的帮助页面。\n正则表达式以“/”开头，所以 :h /\\+ 会带你到正则表达式中量词“+”的帮助页面。\n组合键经常以一个字母开头表示它们可以在哪些模式中使用。如：:h i_CTRL-X 会带你到插入模式下的 CTRL-X 命令的用法帮助页面，这是一个自动完成类的组合键。需要注意的是某些键是有固定写法的，如 Control 键写成 CTRL。还有，查找普通模式下的组合键帮助时，可以省略开头的字母“n”，如：:h CTRL-A。而 :h c_CTRL-A（译者注：原文为 :h c_CRTL-R，感觉改为 A 更符合上下文语境）会解释 CTRL-A 在命令模式下输入命令时的作用；:h v_CTRL-A 说的是在可见模式下把光标所在处的数字加 1；:h g_CTRL-A 则说的是 g 命令（你需要先按 \u0026ldquo;g\u0026rdquo; 的命令）。这里的 \u0026ldquo;g\u0026rdquo; 代表一个普通的命令，这个命令总是与其它的按键组合使用才生效，与 \u0026ldquo;z\u0026rdquo; 开始的命令相似。\n寄存器是以 \u0026ldquo;quote\u0026rdquo; 开头的。如：:h quote: （译者注：原文为:h quote，感觉作者想以\u0026rdquo;:\u0026ldquo;来举例）来查看关于\u0026rdquo;:\u0026ldquo;寄存器的说明。\n关于 Vim 脚本（VimL）的帮助都在 :h eval.txt 里。而某些方面的语言可以使用 :h expr-X 获取帮助，其中的 \u0026lsquo;X\u0026rsquo; 是一个特定的字符，如：:h expr-! 会跳转到描述 VimL 中\u0026rsquo;!\u0026rsquo;（非）的章节。另外一个重要提示，可以使用 :h function-list 来查看所有函数的简要描述，列表中包括函数名和一句话描述。\n关于映射都可以在 :h map.txt 中找到。通过 :h mapmode-i 来查找 :imap 命令的相关信息；通过 :h map-topic 来查找专门针对映射的帮助（译者注：topic 为一个占位符，正如上面的字符 \u0026lsquo;X\u0026rsquo; 一样，在实际使用中需要替换成相应的单词）（如：:h :map-local 查询本地 buffer 的映射，:h map-bar 查询如何在映射中处理\u0026rsquo;|\u0026rsquo;)。\n命令定义用 \u0026ldquo;command-\u0026rdquo; 开头，如用 :h command-bar 来查看自定义命令中\u0026rsquo;!\u0026lsquo;的作用。\n窗口管理类的命令是以 \u0026ldquo;CTRL-W\u0026rdquo; 开头的，所以你可以用 :h CTRL-W_* 来查找相应的帮助（译者注：\u0026rsquo;*\u0026lsquo;同样为占位符）（如：:h CTRL-W_p 查看切换到之前访问的窗口命令的解释）。如果你想找窗口处理的命令，还可以通过访问 :h windows.txt 并逐行向下浏览，所有窗口管理的命令都在这里了。\n执行类的命令以\u0026rdquo;:\u0026ldquo;开头，即：:h :s 讲的是 \u0026ldquo;:s\u0026rdquo; 命令。\n在输入某个话题时按 CTRL-D，让 Vim 列出所有的近似项辅助你输入。\n用 :helpgrep 在所有的帮助页面（通常还包括了已安装的插件的帮助页面）中进行搜索。参考 :h :helpgrep 来了解如何使用。当你搜索了一个话题之后，所有的匹配结果都被保存到了全局位置信息表（或局部位置信息表）当中，可以通过 :copen 或 :lopen 打开。在打开的窗口中可能通过 / 对搜索结果进行进一步的过滤。\n:h helphelp 里介绍了如何使用帮助系统。\n用户手册。它采用了一种对初学者更加友好的方式来展示帮助话题。用 :h usr_toc.txt 打开目录（你可能已经猜到这个命令的用处了）。浏览用户手册能帮助你找出某些你想了解的话题，如你可以在第 24 章看到关于“复合字符”以及“输入特殊字符”的讲解（用 :h usr_24.txt 可以快速打开相关章节）。\n高亮分组的帮助以 hl- 开头。如：:h hl-WarningMsg 说的是警告信息分组的高亮。\n语法高亮以:syc- 开头，如：:h :syn-conceal 讲的是 :syn 命令的对于隐藏字符是如何显示的。\n快速修复命令以 :c 开头，而位置列表命令以 :l 开头。\n:h BufWinLeave 讲的是 BufWinLeave 自动命令。还有，:h autocommand-events （译者注：原文是 :h autocommands-events，但是没有该帮助）讲的是所有可用的事件。\n启动参数都以“-”开头，如：:h -f 会告诉你 Vim 中 “-f” 参数的作用。\n额外的特性都以“+”开头，如：:h +conceal 讲的是关于隐藏字符的支持。\n错误代码可以在帮助系统中直接查到。:h E297 会带你到关于这一错误的详细解释。但是有时并没有转到错误描述，而是列出了经常导出这一错误的 Vim 命令，如 :h E128 （译者注：原文为:h hE128，但是并没有该帮助）会直接跳转到 :function 命令。\n关于包含的语法文件的文档的帮助话题格式是 :h ft-*-syntax。如：:h ft-c-syntax 说的就是 C 语言语法文件以及它所提供的选项。有的语法文件还会带有自动完成（:h ft-php-omni）或文件类型插件（:h ft-tex-plugin）相关的章节可以查看。\n另外在每个帮助页的顶端通常会包含一个用户文档链接（更多的从从用户的角度出发来主角命令的功能和用法，不涉及那么多细节）。如：:h pattern.txt 里包含了 :h 03.9 和 :h usr_27 两个章节的链接。\n获取在线帮助 如果你遇到了无法解决的问题，或者需要指引的话，可以参考 Vim 使用邮件列表。 IRC 也是一个很不错的资源。 Freenode 上的 #vim 频道很庞大，并且里面有许多乐于助人的人。\n如果你想给 Vim 提交 Bug 的话，可以使用 vim_dev 邮件列表。\n执行自动命令 你可以触发任何事件，如：:doautocmd BufRead。\n用户自定义事件 对于插件而言，创建你自己的自定义事件有时非常有用。\nfunction! Chibby() \u0026#34; A lot of stuff is happening here. \u0026#34; And at last.. doautocmd User ChibbyExit endfunction 现在你插件的用户可以在 Chibby 执行完成之后做任何他想做的事情：\nautocmd User ChibbyExit call ChibbyCleanup() 顺便提一句，如果在使用 :autocmd 或 :doautocmd 时没有捕捉异常，那么会输出 \u0026ldquo;No matching autocommands\u0026rdquo; 信息。这也是为什么许多插件用 silent doautocmd ... 的原因。但是这也会有不足，那就是你不能再在 :autocmd 中使用 echo \u0026quot;foo\u0026quot; 了，取而代之的是你要使用 unsilent echo \u0026quot;foo\u0026quot; 来输出。\n这就是为什么要在触发事件之前先判断事件是否存在的原因，\nif exists(\u0026#39;#User#ChibbyExit\u0026#39;) doautocmd User ChibbyExit endif 帮助文档：:h User\n事件嵌套 默认情况下，自动命令不能嵌套！如果某个自动命令执行了一个命令，这个命令再依次触发其它的事件，这是不可能的。\n例如你想在每次启动 Vim 的时候自动打开你的 vimrc 文件：\nautocmd VimEnter * edit $MYVIMRC 当你启动 Vim 的时候，它会帮你打开你的 vimrc 文件，但是你很快会注意到这个文件没有任何的高亮，尽管平时它是正常可以高亮的。\n问题在于你的非嵌套自动命令 :edit 不会触发“BufRead”事件，所以并不会把文件类型设置成“vim”，进而 $VIMRUNTIME/syntax/vim.vim 永远不会被引入。详细信息请参考：:au BufRead *.vim。要想完成上面所说的需求，使用下面这个命令：\nautocmd VimEnter * nested edit $MYVIMRC 帮助文档：:h autocmd-nested\n剪切板 如果你想在没有 GUI 支持的 Unix 系统中使用 Vim 的 'clipboard' 选项，则需要 +clipboard 以及可选的 +xterm_clipboard 两个特性支持。\n帮助文档：\n:h \u0026#39;clipboard\u0026#39; :h gui-clipboard :h gui-selections 另外请参考：持续粘贴（为什么我每次都要设置 \u0026lsquo;paste\u0026rsquo; 模式\n剪贴板的使用（Windows, OSX） Windows 自带了剪贴板，OSX 则带了一个粘贴板\n在这两个系统中都可以用大家习惯用的 ctrl+c / cmd+c 复制选择的文本，然后在另外一个应用中用 ctrl+v / cmd+v 进行粘贴。\n需要注意的是复制的文本已经被发送到了剪贴板，所以你在粘贴复制的内容之前关闭这个应用是没有任何问题的。\n每次复制的时候，都会向剪贴板寄存器 * 中写入数据。 而在 Vim 中分别使用 \u0026quot;*y 和 \u0026quot;*p 来进行复制（yank) 和 粘贴（paste)。\n如果你不想每次操作都要指定 * 寄存器，可以在你的 vimrc 中添加如下配置：\nset clipboard=unnamed 通常情况下复制/删除/放入操作会往 \u0026quot; 寄存器中写入数据，而加上了上面的配置之后 * 寄存器也会被写入同样数据，因此简单的使用 y 和 p 就可以复制粘贴了。\n我再说一遍：使用上面的选项意味着每一次的复制/粘贴，即使在同一个 Vim 窗口里，都会修改剪贴板的内容。你自己决定上面的选项是否适合。\n如果你觉得输入 y 还是太麻烦的话，可以使用下面的设置把在可视模式下选择的内容发送到剪贴板：\nset clipboard=unnamed,autoselect set guioptions+=a 帮助文档：\n:h clipboard-unnamed :h autoselect :h \u0026#39;go_a\u0026#39; 剪贴板的使用（Linux, BSD, \u0026hellip;） 如果你的系统使用了 X 图形界面，事情会变得有一点不同。X 图形界面实现了 X 窗口系统协议, 这个协议在 1987 年发布的主版本 11，因此 X 也通常被称为 X11。\n在 X10 版本中，剪贴缓冲区被用来实现像 clipboard 一样由 X 来复制文本，并且可以被所有的程序访问。现在这个机制在 X 中还存在，但是已经过时了，很多程序都不再使用这一机制。\n近年来数据在程序之间是通过选择进行传递的。一共有三种选择，经常用到的有两种：PRIMARY 和 CLIPBOARD。\n选择的工作工模大致是这样的：\nProgram A：\u0026lt;ctrl+c\u0026gt; Program A：声称对 CLIPBOARD 的所有权 Program B：\u0026lt;ctrl+v\u0026gt; Program B：发现CLIPBOARD的所有权被Program A持有 Program B：从Program A请求数据 Program A：响应这个请求并发送数据给Program B Program B：从Program A接收数据并插入到窗口中 选择 何时使用 如何粘贴 如何在 Vim 中访问 PRIMARY 选择文本 鼠标中键, shift+insert * 寄存器 CLIPBOARD 选择文本并按 ctrl+c ctrl+v +寄存器 注意：X 服务器并不会保存选择（不仅仅是 CLIPBOARD 选择）！因此在关闭了相应的程序后，你用 ctrl+c 复制的内容将丢失。\n使用 \u0026quot;*p 来贴粘 PRIMARY 选择中的内容，或者使用 \u0026quot;+y1G 来将整个文件的内容复制到 CLIPBOARD 选择。\n如果你需要经常访问这两个寄存器，可以考虑使用如下配置：\nset clipboard^=unnamed \u0026#34; * 寄存器 \u0026#34; 或者 set clipboard^=unnamedplus \u0026#34; + 寄存器 （^= 用来将设置的值加到默认值之前，详见：:h :set^=）\n这会使得所有复制/删除/放入操作使用 * 或 + 寄存器代替默认的未命令寄存器 \u0026quot;。之后你就可以直接使用 y 或 p 访问你的 X 选择了。\n帮助文档：\n:h clipboard-unnamed :h clipboard-unnamedplus 打开文件时恢复光标位置 如果没有这个设置，每次打开文件时光标都将定位在第一行。而加入了这个设置以后，你就可以恢复到上次关闭文件时光标所在的位置了。\n将下面的配置添加到你的 vimrc 文件：\nautocmd BufReadPost * \\ if line(\u0026#34;\u0026#39;\\\u0026#34;\u0026#34;) \u0026gt; 1 \u0026amp;\u0026amp; line(\u0026#34;\u0026#39;\\\u0026#34;\u0026#34;) \u0026lt;= line(\u0026#34;$\u0026#34;) | \\ exe \u0026#34;normal! g`\\\u0026#34;\u0026#34; | \\ endif 这是通过判断之前的光标位置是否存在（文件可能被其它程序修改而导致所记录的位置已经不存在了），如果存在的话就执行 g`\u0026quot; （转到你离开时的光标位置但是不更改跳转列表）。\n这需要使用 viminfo 文件：:h viminfo-。\n临时文件 根据选项的不同， Vim 最多会创建 4 种工作文件。\n备份文件 你可以让 Vim 在将修改写入到文件之前先备份原文件。默认情况下， Vim 会保存一个备份文件但是当修改成功写入后会立即删除它（:set writebackup）。如果你想一直保留这个备份文件的话，可以使用 :set backup。而如果你想禁用备份功能的话，可以使用 :set nobackup nowritebackup。\n咱们来看一下上次我在 vimrc 中改了什么：\n$ diff ~/.vim/vimrc ~/.vim/files/backup/vimrc-vimbackup 390d389 \u0026lt; command! -bar -nargs=* -complete=help H helpgrep \u0026lt;args\u0026gt; 帮助文档：:h backup\n交换文件 假设你有一个非常棒的科幻小说的构思。在按照故事情节已经写了好几个小时几十万字的时候..忽然停电了！而那时你才想起来你上次保存 ~/来自外太空的邪恶入侵者.txt 是在.. 好吧，你从来没有保存过。\n但是并非没有希望了！在编辑某个文件的时候， Vim 会创建一个交换文件，里面保存的是对当前文件所有未保存的修改。自己试一下，打开任意的文件，并使用 :swapname 获得当前的交换文件的保存路径。你也可以将 :set noswapfile 加入到 vimrc 中来禁用交换文件。\n默认情况下，交换文件会自动保存在被编辑文件所在的目录下，文件名以 .file.swp 后缀结尾，每当你修改了超过 200 个字符或是在之前 4 秒内没有任何动作时更新它的内容，在你不再编辑这个文件的时候会被删除。你可以自己修改这些数字，详见：:h 'updatecount' 和 :h 'updatetime'。\n而在断电时，交换文件并不会被删除。当你再次打开 vim ~/来自外太空的邪恶入侵者.txt 时， Vim 会提示你恢复这个文件。\n帮助文档：:h swap-file 和 :h usr_11\n撤销文件 内容变更历史记录是保存在内存中的，并且会在 Vim 退出时清空。如果你想让它持久化到磁盘中，可以设置 :set undofile。这会把文件 ~/foo.c 的撤销文件保存在 ~/foo.c.un~。\n帮助文档：:h 'undofile' 和 :h undo-persistence\nviminfo 文件 备份文件、交换文件和撤销文件都是与文本状态相关的，而 viminfo 文件是用来保存在 Vim 退出时可能会丢失的其它的信息的。包括历史记录（命令历史、搜索历史、输入历史）、寄存器内容、标注、缓冲区列表、全局变量等等。\n默认情况下，viminfo 被保存在 ~/.viminfo。\n帮助文档：:h viminfo 和 :h 'viminfo'\n临时文件管理设置示例 如果你跟我一样，也喜欢把这些文件放到一个位置（如：~/.vim/files）的话，可以使用下面的配置：\n\u0026#34; 如果文件夹不存在，则新建文件夹 if !isdirectory($HOME.\u0026#39;/.vim/files\u0026#39;) \u0026amp;\u0026amp; exists(\u0026#39;*mkdir\u0026#39;) call mkdir($HOME.\u0026#39;/.vim/files\u0026#39;) endif \u0026#34; 备份文件 set backup set backupdir =$HOME/.vim/files/backup/ set backupext =-vimbackup set backupskip = \u0026#34; 交换文件 set directory =$HOME/.vim/files/swap// set updatecount =100 \u0026#34; 撤销文件 set undofile set undodir =$HOME/.vim/files/undo/ \u0026#34; viminfo 文件 set viminfo =\u0026#39;100,n$HOME/.vim/files/info/viminfo 注意：如果你在一个多用户系统中编辑某个文件时， Vim 提示你交换文件已经存在的话，可能是因为有其他的用户此时正在编辑这个文件。而如果将交换文件放到自己的 home 目录的话，这个功能就失效了。因此服务器非常不建议将这些文件修改到 HOME 目录，避免多人同时编辑一个文件，却没有任何警告。\n编辑远程文件 Vim 自带的 netrw 插件支持对远程文件的编辑。实际上它将远程的文件通过 scp 复制到本地的临时文件中，再用那个文件打开一个缓冲区，然后在保存时把文件再复制回远程位置。\n下面的命令在你本地的 VIM 配置与 SSH 远程服务器上管理员想让你使用的配置有冲突时尤其有用：\n:e scp://bram@awesome.site.com/.vimrc 如果你已经设置了 ~/.ssh/config，SSH 会自动读取这里的配置：\nHost awesome HostName awesome.site.com Port 1234 User bram 如果你的 ~/.ssh/config 中有以上的内容，那么下面的命令就可以正常执行了：\n:e scp://awesome/.vimrc 可以用同样的方法编辑 ~/.netrc, 详见：:h netrc-netrc。\n确保你已经看过了 :h netrw-ssh-hack 和 :h g:netrw_ssh_cmd。\n另外一种编辑远程文件的方法是使用 sshfs，它会用 FUSE 来挂载远程的文件系统到你本地的系统当中。\n插件管理 Pathogen是第一个比较流行的插件管理工具。实际上它只是修改了 runtimepath （:h 'rtp'） 来引入所有放到该目录下的文件。你需要自己克隆插件的代码仓库到那个目录。\n真正的插件管理工具会在 Vim 中提供帮助你安装或更新插件的命令。以下是一些常用的插件管理工具：\ndein plug vim-addon-manager vundle 多行编辑 这是一种可以同时输入多行连续文本的技术。参考这个示例。\n用 \u0026lt;c-v\u0026gt; 切换到可视块模式。然后向下选中几行，按 I 或 A （译者注：大写字母，即 shift+i 或 shift+a）然后开始输入你想要输入的文本。\n在刚开始的时候可能会有些迷惑，因为文本只出现在了当前编辑的行，只有在当前的插入动作结束后，之前选中的其它行才会出现插入的文本。\n举一个简单的例子：\u0026lt;c-v\u0026gt;3jItext\u0026lt;esc\u0026gt;。\n如果你要编辑的行长度不同，但是你想在他们后面追加相同的内容的话，可以试一下这个：\u0026lt;c-v\u0026gt;3j$Atext\u0026lt;esc\u0026gt;。\n有时你可能需要把光标放到当前行末尾之后，默认情况下你是不可能做到的，但是可能通过设置 virtualedit 选项达到目的：\nset virtualedit=all 设置之后 $10l 或 90| 都会生效，即使超过了行尾的长度。\n详见 :h blockwise-examples。在开始的时候可能会觉得有些复杂，但是它很快就会成为你的第二天性的。\n如果你想探索更有趣的事情，可以看看多光标\n使用外部程序和过滤器 免责声明：Vim 是单线程的，因此在 Vim 中以前端进程执行其它的程序时会阻止其它的一切。当然你可以使用 Vim 程序接口，如 Lua，并且使用它的多线程支持，但是在那期间， Vim 的处理还是被阻止了。Neovim 添加了任务 API 解决了此问题。\n（据说 Bram 正在考虑在 Vim 中也添加任务控制。如果你使用了较新版本的的 Vim ，可以看一下 :helpgrep startjob。）\n使用 :! 启动一个新任务。如果你想列出当前工作目录下的所有文件，可以使用 :!ls。 用 | 来将结果通过管道重定向，如：:!ls -l | sort | tail -n5。\n没有使用范围时（译者注：范围就是 : 和 ! 之间的内容，. 表示当前行，+4 表示向下偏移 4 行，$ 表示最末行等，多行时用 , 将它们分开，如 .,$ 表示从当前行到末行），:! 会显示在一个可滚动的窗口中（译者注：在 GVim 和在终端里运行的结果稍有不同）。相反的，如果指定了范围，这些行会被过滤。这意味着它们会通过管道被重定向到过滤程序的 stdin，在处理后再通过过滤程序的 stdout 输出，用输出结果替换范围内的文本。例如：为接下来的 5 行文本添加行号，可以使用：\n:.,+4!nl -ba -w1 -s\u0026#39; \u0026#39; 由于手动添加范围很麻烦， Vim 提供了一些辅助方法以方便的添加范围。如果需要经常带着范围的话，你可以在可见模式中先选择，然后再按 : （译者注：选中后再按 ! 更方便）。还可以使用 ! 来取用一个 motion 的范围，如 !ipsort （译者注：原文为 !ip!sort ，但经过实验发现该命令执行报错，可能是因为 Vim 版本的原因造成的，新版本使用 ip 选择当前段落后自动在命令后添加了 ! ，按照作者的写法来看，可能之前的版本没有自动添加 ! ）可以将当前段落的所有行按字母表顺序进行排序。\n一个使用过滤器比较好的案例是Go 语言。它的缩进语法非常个性，甚至还专门提供了一个名为 gofmt 的过滤器来对 Go 语言的源文件进行正确的缩进。Go 语言的插件通常会提供一个名为 :Fmt 的函数，这个函数就是执行了 :%!gofmt 来对整个文件进行缩进。\n人们常用 :r !prog 将 prog 程序的插入放到当前行的下面，这对于脚本来说是很不错的选择，但是在使用的过程中我发现 !!ls 更加方便，它会用输出结果替换当前行的内容。（译者注：前面命令中的 prog 只是个占位符，在实际使用中需要替换成其它的程序，如 :r !ls，这就与后面的 !!ls 相对应了，两者唯一的不同是第一个命令不会覆盖当前行内容，但是第二个命令会）\n帮助文档：\n:h filter :h :read! Cscope Cscope 的功能比 ctags 要完善，但是只支持 C（通过设置 cscope.files 后同样支持 C++以及 Java）。\n鉴于 Tag 文件只是知道某个符号是在哪里定义的，cscope 的数据库里的数据信息就多的多了：\n符号是在哪里定义的？ 符号是在哪里被使用的？ 这个全局符号定义了什么？ 这个变量是在哪里被赋值的？ 这个函数在源文件的哪个位置？ 哪些函数调用了这个函数？ 这个函数调用了哪些函数？ \u0026ldquo;out of space\u0026quot;消息是从哪来的？ 在目录结构中当前的源文件在哪个位置？ 哪些文件引用了这个头文件？ 1. 构建数据库 在你项目的根目录执行下面的命令：\n$ cscope -bqR 这条命令会在当前目录下创建三个文件：cscope{,.in,.po}.out 。把它们想象成你的数据库。\n不幸的时 cscope 默认只分析 *.[c|h|y|l] 文件。如果你想在 Java 项目中使用 cscope ，需要这样做：\n$ find . -name \u0026#34;*.java\u0026#34; \u0026gt; cscope.files $ cscope -bq 2. 添加数据库 打开你新创建的数据库连接：\n:cs add cscope.out 检查连接已经创建成功：\n:cs show （当然你可以添加多个连接。）\n3. 查询数据库 :cs find \u0026lt;kind\u0026gt; \u0026lt;query\u0026gt; 如：:cs find d foo 会列出 foo(...) 调用的所有函数。\nKind 说明 s symbol：查找使用该符号的引用 g global：查找该全局符号的定义 c calls：查找调用当前方法的位置 t text：查找出现该文本的位置 e egrep：使用 egrep 搜索当前单词 f file：打开文件名 i includes：查询引入了当前文件的文件 d depends：查找当前方法调用的方法 推荐一些比较方便的映射，如：\nnnoremap \u0026lt;buffer\u0026gt; \u0026lt;leader\u0026gt;cs :cscope find s \u0026lt;c-r\u0026gt;=expand(\u0026#39;\u0026lt;cword\u0026gt;\u0026#39;)\u0026lt;cr\u0026gt;\u0026lt;cr\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;leader\u0026gt;cg :cscope find g \u0026lt;c-r\u0026gt;=expand(\u0026#39;\u0026lt;cword\u0026gt;\u0026#39;)\u0026lt;cr\u0026gt;\u0026lt;cr\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;leader\u0026gt;cc :cscope find c \u0026lt;c-r\u0026gt;=expand(\u0026#39;\u0026lt;cword\u0026gt;\u0026#39;)\u0026lt;cr\u0026gt;\u0026lt;cr\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;leader\u0026gt;ct :cscope find t \u0026lt;c-r\u0026gt;=expand(\u0026#39;\u0026lt;cword\u0026gt;\u0026#39;)\u0026lt;cr\u0026gt;\u0026lt;cr\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;leader\u0026gt;ce :cscope find e \u0026lt;c-r\u0026gt;=expand(\u0026#39;\u0026lt;cword\u0026gt;\u0026#39;)\u0026lt;cr\u0026gt;\u0026lt;cr\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;leader\u0026gt;cf :cscope find f \u0026lt;c-r\u0026gt;=expand(\u0026#39;\u0026lt;cfile\u0026gt;\u0026#39;)\u0026lt;cr\u0026gt;\u0026lt;cr\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;leader\u0026gt;ci :cscope find i ^\u0026lt;c-r\u0026gt;=expand(\u0026#39;\u0026lt;cfile\u0026gt;\u0026#39;)\u0026lt;cr\u0026gt;$\u0026lt;cr\u0026gt; nnoremap \u0026lt;buffer\u0026gt; \u0026lt;leader\u0026gt;cd :cscope find d \u0026lt;c-r\u0026gt;=expand(\u0026#39;\u0026lt;cword\u0026gt;\u0026#39;)\u0026lt;cr\u0026gt;\u0026lt;cr\u0026gt; 所以 :tag （或 \u0026lt;c-]\u0026gt;）跳转到标签定义的文件，而 :cstag 可以达到同样的目的，同时还会打开 cscope 的数据库连接。'cscopetag' 选项使得 :tag 命令自动的像 :cstag 一样工作。这在你已经使用了基于标签的映射时会非常方便。\n帮助文档：:h cscope\nMatchIt 由于 Vim 是用 C 语言编写的，因此许多功能都假设使用类似 C 语言的语法。默认情况下，如果你的光标在 { 或 #endif , 就可以使用 % 跳转到与之匹配的 } 或 #ifdef。\nVim 自带了一个名为 matchit.vim 的插件，但是默认没有启用。启用后可以用 % 在 HTML 相匹配的标签或 VimL 的 if/else/endif 块之间进行跳转，它还带来了一些新的命令。\n在 Vim 8 中安装 \u0026#34; vimrc packadd! matchit 在 Vim 7 或者更早的版本中安装 \u0026#34;vimrc runtime macros/matchit.vim 由于 matchit 的文档很全面，我建议安装以后执行一次下面的命令：\n:!mkdir -p ~/.vim/doc :!cp $VIMRUNTIME/macros/matchit.vim ~/.vim/doc :helptags ~/.vim/doc 简短的介绍 至此这个插件已经可以使用了。 参考 :h matchit-intro 来获得支持的命令以及 :h matchit-languages 来获得支持的语言。\n你可以很方便的定义自己的匹配对，如：\nautocmd FileType python let b:match_words = \u0026#39;\\\u0026lt;if\\\u0026gt;:\\\u0026lt;elif\\\u0026gt;:\\\u0026lt;else\\\u0026gt;\u0026#39; 之后你就可以在任何的 Python 文件中使用 % （向前）或 g% （向后）在这三个片断之间跳转了。\n帮助文档：\n:h matchit-install :h matchit :h b:match_words 技巧 跳至选择的区域另一端 在使用 v 或者 V 选择某段文字后，可以用 o 或者 O 按键跳至选择区域的开头或者结尾。\n:h v_o :h v_O 聪明地使用 n 和 N n 与 N 的实际跳转方向取决于使用 / 还是 ? 来执行搜索，其中 / 是向后搜索，? 是向前搜索。一开始我（原作者）觉得这里很难理解。\n如果你希望 n 始终为向后搜索，N 始终为向前搜索，那么只需要这样设置：\nnnoremap \u0026lt;expr\u0026gt; n \u0026#39;Nn\u0026#39;[v:searchforward] nnoremap \u0026lt;expr\u0026gt; N \u0026#39;nN\u0026#39;[v:searchforward] 聪明地使用命令行历史 我（原作者）习惯用 Ctrl + p 和 Ctrl + n 来跳转到上一个/下一个条目。其实这个操作也可以用在命令行中，快速调出之前执行过的命令。\n不仅如此，你会发现 上 和 下 其实更智能。如果命令行中已经存在了一些文字，我们可以通过按方向键来匹配已经存在的内容。比如，命令行中现在是 :echo，这时候我们按 上，就会帮我们补全成 :echo \u0026quot;Vim rocks!\u0026quot;（前提是，之前输入过这段命令）。\n当然，Vim 用户都不愿意去按方向键，事实上我们也不需要去按，只需要设置这样的映射：\ncnoremap \u0026lt;c-n\u0026gt; \u0026lt;down\u0026gt; cnoremap \u0026lt;c-p\u0026gt; \u0026lt;up\u0026gt; 这个功能，我（原作者）每天都要用很多次。\n智能 Ctrl-l Ctrl + l 的默认功能是清空并「重新绘制」当前的屏幕，就和 :redraw! 的功能一样。下面的这个映射就是执行重新绘制，并且取消通过 / 和 ? 匹配字符的高亮，而且还可以修复代码高亮问题（有时候，由于多个代码高亮的脚本重叠，或者规则过于复杂，Vim 的代码高亮显示会出现问题）。不仅如此，还可以刷新「比较模式」（请参阅 :help diff-mode）的代码高亮：\nnnoremap \u0026lt;leader\u0026gt;l :nohlsearch\u0026lt;cr\u0026gt;:diffupdate\u0026lt;cr\u0026gt;:syntax sync fromstart\u0026lt;cr\u0026gt;\u0026lt;c-l\u0026gt; 禁用错误报警声音和图标 set noerrorbells set novisualbell set t_vb= 请参阅 Vim Wiki: Disable beeping。\n快速移动当前行 有时，我（原作者）想要快速把当前行上移或下移一行，只需要这样设置映射：\nnnoremap [e :\u0026lt;c-u\u0026gt;execute \u0026#39;move -1-\u0026#39;. v:count1\u0026lt;cr\u0026gt; nnoremap ]e :\u0026lt;c-u\u0026gt;execute \u0026#39;move +\u0026#39;. v:count1\u0026lt;cr\u0026gt; 这个映射，同样可以搭配数字使用，比如连续按下 2 ] e 就可以把当前行向下移动两行。\n快速添加空行 nnoremap [\u0026lt;space\u0026gt; :\u0026lt;c-u\u0026gt;put! =repeat(nr2char(10), v:count1)\u0026lt;cr\u0026gt;\u0026#39;[ nnoremap ]\u0026lt;space\u0026gt; :\u0026lt;c-u\u0026gt;put =repeat(nr2char(10), v:count1)\u0026lt;cr\u0026gt; 设置之后，连续按下 5 [ 空格 在当前行上方插入 5 个空行。\n运行时检测 需要的特性：+profile\nVim 提供了一个内置的运行时检查功能，能够找出运行慢的代码。\n:profile 命令后面跟着子命令来确定要查看什么。\n如果你想查看所有的：\n:profile start /tmp/profile.log :profile file * :profile func * \u0026lt;do something in Vim\u0026gt; \u0026lt;quit Vim\u0026gt; Vim 不断地在内存中检查信息，只在退出的时候输出出来。（Neovim 已经解决了这个问题用 :profile dump 命令）\n看一下 /tmp/profile.log 文件，检查时运行的所有代码都会被显示出来，包括每一行代码运行的频率和时间。\n大多数代码都是用户不熟悉的插件代码，如果你是在解决一个确切的问题， 直接跳到这个日志文件的末尾，那里有 FUNCTIONS SORTED ON TOTAL TIME 和 FUNCTIONS SORTED ON SELF TIME 两个部分，如果某个 function 运行时间过长一眼就可以看到。\n查看启动时间 感觉 Vim 启动的慢？到了研究几个数字的时候了：\nvim --startuptime /tmp/startup.log +q \u0026amp;\u0026amp; vim /tmp/startup.log 第一栏是最重要的因为它显示了绝对运行时间，如果在前后两行之间时间差有很大的跳跃，那么是第二个文件太大或者含有需要检查的错误的 VimL 代码。\nNUL 符用新行表示 文件中的 NUL 符 （\\0），在内存中被以新行（\\n）保存，在缓存空间中显示为 ^@。\n更多信息请参看 man 7 ascii 和 :h NL-used-for-Nul 。\n快速编辑自定义宏 这个功能真的很实用！下面的映射，就是在一个新的命令行窗口中读取某一个寄存器（默认为 *）。当你设置完成后，只需要按下 回车 即可让它生效。\n在录制宏的时候，我经常用这个来更改拼写错误。\nnnoremap \u0026lt;leader\u0026gt;m :\u0026lt;c-u\u0026gt;\u0026lt;c-r\u0026gt;\u0026lt;c-r\u0026gt;=\u0026#39;let @\u0026#39;. v:register .\u0026#39; = \u0026#39;. string(getreg(v:register))\u0026lt;cr\u0026gt;\u0026lt;c-f\u0026gt;\u0026lt;left\u0026gt; 只需要连续按下 leader m 或者 \u0026quot; leader m 就可以调用了。\n请注意，这里之所以要写成 \u0026lt;c-r\u0026gt;\u0026lt;c-r\u0026gt; 是为了确保 \u0026lt;c-r\u0026gt; 执行了。请参阅 :h c_^R^R\n快速跳转到源(头)文件 这个技巧可以用在多种文件类型中。当你从源文件或者头文件中切换到其他文件的时候，这个技巧可以设置「文件标记」（请参阅 :h marks），然后你就可以通过连续按下 \u0026rsquo; C 或者 \u0026rsquo; H 快速跳转回去（请参阅 :h 'A）。\nautocmd BufLeave *.{c,cpp} mark C autocmd BufLeave *.h mark H 注意：由于这个标记是设置在 viminfo 文件中，因此请先确认 :set viminfo? 中包含了 :h viminfo-'。\n在 GUI 中快速改变字体大小 印象中，我（原作者）记得一下代码是来自 tpope\u0026rsquo;s 的配置文件：\ncommand! Bigger :let \u0026amp;guifont = substitute(\u0026amp;guifont, \u0026#39;\\d\\+$\u0026#39;, \u0026#39;\\=submatch(0)+1\u0026#39;, \u0026#39;\u0026#39;) command! Smaller :let \u0026amp;guifont = substitute(\u0026amp;guifont, \u0026#39;\\d\\+$\u0026#39;, \u0026#39;\\=submatch(0)-1\u0026#39;, \u0026#39;\u0026#39;) 根据模式改变光标类型 我（原作者）习惯在普通模式下用块状光标，在插入模式下用条状光标（形状类似英文 \u0026ldquo;I\u0026rdquo; 的样子），然后在替换模式中使用下划线形状的光标。\nif empty($TMUX) let \u0026amp;t_SI = \u0026#34;\\\u0026lt;Esc\u0026gt;]50;CursorShape=1\\x7\u0026#34; let \u0026amp;t_EI = \u0026#34;\\\u0026lt;Esc\u0026gt;]50;CursorShape=0\\x7\u0026#34; let \u0026amp;t_SR = \u0026#34;\\\u0026lt;Esc\u0026gt;]50;CursorShape=2\\x7\u0026#34; else let \u0026amp;t_SI = \u0026#34;\\\u0026lt;Esc\u0026gt;Ptmux;\\\u0026lt;Esc\u0026gt;\\\u0026lt;Esc\u0026gt;]50;CursorShape=1\\x7\\\u0026lt;Esc\u0026gt;\\\\\u0026#34; let \u0026amp;t_EI = \u0026#34;\\\u0026lt;Esc\u0026gt;Ptmux;\\\u0026lt;Esc\u0026gt;\\\u0026lt;Esc\u0026gt;]50;CursorShape=0\\x7\\\u0026lt;Esc\u0026gt;\\\\\u0026#34; let \u0026amp;t_SR = \u0026#34;\\\u0026lt;Esc\u0026gt;Ptmux;\\\u0026lt;Esc\u0026gt;\\\u0026lt;Esc\u0026gt;]50;CursorShape=2\\x7\\\u0026lt;Esc\u0026gt;\\\\\u0026#34; endif 原理很简单，就是让 Vim 在进入和离开插入模式的时候，输出一些序列，请参考 escape sequence。Vim 与终端之间的中间层，比如 tmux 会处理并执行上面的代码。\n但上面这个还是有一个缺点的。终端环境的内部原理不尽相同，对于序列的处理方式也稍有不同。因此，上面的代码可能无法在你的环境中运行。甚至，你的运行环境也有可能不支持其他光标形状，请参阅你的 Vim 运行环境的文档。\n好消息是，上面这个代码，可以在 iTerm2 中完美运行。\n防止水平滑动的时候失去选择 如果你选中了一行或多行，那么你可以用 \u0026lt; 或 \u0026gt; 来调整他们的缩进。但在调整之后就不会保持选中状态了。\n你可以连续按下 g v 来重新选中他们，请参考 :h gv。因此，你可以这样来配置映射：\nxnoremap \u0026lt; \u0026lt;gv xnoremap \u0026gt; \u0026gt;gv 设置好之后，在可视模式中使用 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; 就不会再出现上面提到的问题了。\n选择当前行至结尾，排除换行符 在 Vim 里，我们可以同过 v$ 选择当前行至结尾，但此时会把最后一个换行符也选中，通常需要按额外的 h 来取消最后选中最后一个换行符号。 Vim 提供了一个 g_ 快捷键，可以移动光标至最后一个非空字符。因此，为达到次效果，可以使用 vg_。当然，如果觉得按三个键比较麻烦， 可以添加一个映射：\nnnoremap L g_ 这样就可以通过 vL 达到一样的效果了。\n重新载入保存文件 通过自动命令，你可以在保存文件的同时触发一些其他功能。比如，如果这个文件是一个配置文件，那么就重新载入；或者你还可以对这个文件进行代码风格检查。\nautocmd BufWritePost $MYVIMRC source $MYVIMRC autocmd BufWritePost ~/.Xdefaults call system(\u0026#39;xrdb ~/.Xdefaults\u0026#39;) 更加智能的当前行高亮 我（原作者）很喜欢「当前行高亮」（请参阅 :h cursorline）这个功能，但我只想让这个效果出现在当前窗口，而且在插入模式中关闭这个效果：\nautocmd InsertLeave,WinEnter * set cursorline autocmd InsertEnter,WinLeave * set nocursorline 更快的关键字补全 关键字补全（\u0026lt;c-n\u0026gt; 或 \u0026lt;c-p\u0026gt;）功能的工作方式是，无论 'complete' 设置中有什么，它都会尝试着去补全。这样，一些我们用不到的标签也会出现在补全列表中。而且，它会扫描很多文件，有时候运行起来非常慢。如果你不需要这些，那么完全可以像这样把它们禁用掉：\nset complete-=i \u0026#34; disable scanning included files set complete-=t \u0026#34; disable searching tags 改变颜色主题的默认外观 如果你想让状态栏在颜色主题更改后依然保持灰色，那么只需要这样设置：\nautocmd ColorScheme * highlight StatusLine ctermbg=darkgray cterm=NONE guibg=darkgray gui=NONE 同理，如果你想让某一个颜色主题（比如 \u0026ldquo;lucius\u0026rdquo;）的状态栏为灰色（请使用 :echo color_name 来查看当前可用的所有颜色主题）：\nautocmd ColorScheme lucius highlight StatusLine ctermbg=darkgray cterm=NONE guibg=darkgray gui=NONE 命令 下面的命令都比较有用，最好了解一下。用 :h :\u0026lt;command name\u0026gt; 来了解更多关于它们的信息，如：:h :global。\n:global 和 :vglobal - 在所有匹配行执行命令 在所有符合条件的行上执行某个命令。如： :global /regexp/ print 会在所有包含 \u0026ldquo;regexp\u0026rdquo; 的行上执行 print 命令（译者注：regexp 有正则表达式的意思，该命令同样支持正则表达式，在所有符合正则表达式的行上执行指定的命令）。\n趣闻：你们可能都知道老牌的 grep 命令，一个由 Ken Thompson 编写的过滤程序。它是干什么用的呢？它会输出所有匹配指定正则表达式的行！现在猜一下 :global /regexp/ print 的简写形式是什么？没错！就是 :g/re/p 。 Ken Thompsom 在编写 grep 程序的时候是受了 vi :global 的启发。（译者注： https://robots.thoughtbot.com/how-grep-got-its-name）\n既然它的名字是 :global，理应仅作用在所有行上，但是它也是可以带范围限制的。假设你想使用 :delete 命令删除从当前行到下一个空行（由正则表达式 ^$ 匹配）范围内所有包含 \u0026ldquo;foo\u0026rdquo; 的行：\n:,/^$/g/foo/d 如果要在所有 不 匹配的行上执行命令的话，可以使用 :global! 或是它的别名 :vglobal （ V 代表的是 inVerse ）。\n:normal 和 :execute - 脚本梦之队 这两个命令经常在 Vim 的脚本里使用。\n借助于 :normal 可以在命令行里进行普通模式的映射。如：:normal! 4j 会令光标下移 4 行（由于加了\u0026rdquo;!\u0026quot;，所以不会使用自定义的映射 \u0026ldquo;j\u0026rdquo;）。\n需要注意的是 :normal 同样可以使用范围数（译者注：参考 :h range 和 :h :normal-range 了解更多），故 :%norm! Iabc 会在所有行前加上 \u0026ldquo;abc\u0026rdquo;。\n借助于 :execute 可以将命令和表达式混合在一起使用。假设你正在编辑一个 C 语言的文件，想切换到它的头文件：\n:execute \u0026#39;edit\u0026#39; fnamemodify(expand(\u0026#39;%\u0026#39;), \u0026#39;:r\u0026#39;) . \u0026#39;.h\u0026#39; （译者注：头文件为与与源文件同名但是扩展名为 .h 的文件。上面的命令中 expand 获得当前文件的名称，fnamemodify 获取不带扩展名的文件名，再连上 \u0026lsquo;.h\u0026rsquo; 就是头文件的文件名了，最后在使用 edit 命令打开这个头文件。）\n这两个命令经常一起使用。假设你想让光标下移 n 行：\n:let n = 4 :execute \u0026#39;normal!\u0026#39; n . \u0026#39;j\u0026#39; 重定向消息 许多命令都会输出消息，:redir 用来重定向这些消息。它可以将消息输出到文件、寄存器或是某个变量中。\n\u0026#34; 将消息重定向到变量 `neatvar` 中 :redir =\u0026gt; neatvar \u0026#34; 打印所有寄存器的内容 :reg \u0026#34; 结束重定向 :redir END \u0026#34; 输出变量 :echo neatvar \u0026#34; 恶搞一下，我们把它输出到当前缓冲区 :put =neatvar 再 Vim 8 中，可以更简单的方式即位：\n:put =execute('reg') （译者注：原文最后一条命令是 :put =nicevar 但是实际会报变量未定义的错误） （实测 neovim/vim8 下没问题）\n帮助文档：:h :redir\n调试 常规建议 如果你遇到了奇怪的行为，尝试用这个命令重现它：\nvim -u NONE -N 这样会在不引用 vimrc（默认设置）的情况下重启 vim，并且在 nocompatible 模式下（使用 vim 默认设置而不是 vi 的）。（搜索 :h --noplugin 命令了解更多启动加载方式）\n如果仍旧能够出现该错误，那么这极有可能是 vim 本身的 bug，请给 vim_dev 发送邮件反馈错误，多数情况下问题不会立刻解决，你还需要进一步研究\n许多插件经常会提供新的（默认的/自动的）操作。如果在保存的时候发生了，那么请用 :verb au BufWritePost 命令检查潜在的问题\n如果你在使用一个插件管理工具，将插件行注释调，再进行调试。\n问题还没有解决？如果不是插件的问题，那么肯定是你的自定义的设置的问题，可能是你的 options 或 autocmd 等等。\n到了一行行代码检查的时候了，不断地排除缩小检查范围知道你找出错误，根据二分法的原理你不会花费太多时间的。\n在实践过程中，可能就是这样，把 :finish 放在你的 vimrc 文件中间，Vim 会跳过它之后的设置。如果问题还在，那么问题就出在:finish之前的设置中，再把:finish放到前一部分设置的中间位置。否则问题就出现在它后面的半部分设置，那么就把:finish放到后半部分的中间位置。不断的重复即可找到。\n调整日志等级 Vim 现在正在使用的另一个比较有用的方法是增加 debug 信息输出详细等级。现在 Vim 支持 9 个等级，可以用:h 'verbose'命令查看。\n:e /tmp/foo :set verbose=2 :w :set verbose=0 这可以显示出所有引用的文件、没有变化的文件或者各种各样的作用于保存的插件。\n如果你只是想用简单的命令来提高等级，也是用 :verbose ，放在其他命令之前，通过计数来指明等级，默认是 1.\n:verb set verbose \u0026#34; verbose=1 :10verb set verbose \u0026#34; verbose=10 通常用等级 1 来显示上次从哪里设置的选项\n:verb set ai? \u0026#34; Last set from ~/.vim/vimrc 一般等级越高输出信息月详细。但是不要害怕，亦可以把输出导入到文件中：\n:set verbosefile=/tmp/foo | 15verbose echo \u0026#34;foo\u0026#34; | vsplit /tmp/foo 你可以一开始的时候就打开 verbosity，用 -V 选项，它默认设置调试等级为 10。 例如：vim -V5\n查看启动日志 查看运行时日志 Vim 脚本调试 如果你以前使用过命令行调试器的话，对于:debug命令你很快就会感到熟悉。\n只需要在任何其他命令之前加上:debug就会让你进入调试模式。也就是，被调试的 Vim 脚本会在第一行停止运行，同时该行会被显示出来。\n想了解可用的 6 个调试命令，可以查阅:h \u0026gt;cont和阅读下面内容。需要指出的是，类似 gdb 和其他相似调试器，调试命令可以使用它们的简短形式：c、 q、n、s、 i和 f。\n除了上面的之外，你还可以自由地使用任何 Vim 的命令。比如，:echo myvar，该命令会在当前的脚本代码位置和上下文上被执行。\n只需要简单使用:debug 1，你就获得了REPL调试特性。\n当然，调试模式下是可以定义断点的，不然的话每一行都去单步调试就会十分痛苦。（断点之所以被叫做断点，是因为运行到它们的时候，运行就会停止下来。因此，你可以利用断点跳过自己不感兴趣的代码区域）。请查阅:h :breakadd、 :h :breakdel和 :h :breaklist获取更多细节。\n假设你需要知道你每次在保存一个文件的时候有哪些代码在运行：\n:au BufWritePost \u0026#34; signify BufWritePost \u0026#34; * call sy#start() :breakadd func *start :w \u0026#34; Breakpoint in \u0026#34;sy#start\u0026#34; line 1 \u0026#34; Entering Debug mode. Type \u0026#34;cont\u0026#34; to continue. \u0026#34; function sy#start \u0026#34; line 1: if g:signify_locked \u0026gt;s \u0026#34; function sy#start \u0026#34; line 3: endif \u0026gt; \u0026#34; function sy#start \u0026#34; line 5: let sy_path = resolve(expand(\u0026#39;%:p\u0026#39;)) \u0026gt;q :breakdel * 正如你所见，使用\u0026lt;cr\u0026gt;命令会重复之前的调试命令，也就是在该例子中的s命令。\n:debug命令可以和verbose选项一起使用。\n语法文件调试 语法文件由于包含错误的或者复制的正则表达式，常常会使得 Vim 的运行较慢。如果 Vim 在编译的时候包含了+profile feature特性，就可以给用户提供一个超级好用的:syntime命令。\n:syntime on \u0026#34; 多次敲击\u0026lt;c-l\u0026gt;来重绘窗口，这样的话就会使得相应的语法规则被重新应用一次 :syntime off :syntime report 输出结果包含了很多的度量维度。比如，你可以通过结果知道哪些正则表达式耗时太久需要被优化；哪些正则表达式一直在别使用但重来没有一次成功匹配。\n请查阅:h :syntime。\n杂项 附加资源 资源名称 简介 七个高效的文本编辑习惯 作者：Bram Moolenaar（即 Vim 的作者） 七个高效的文本编辑习惯 2.0（PDF 版） 同上 IBM DeveloperWorks: 使用脚本编写 Vim 编辑器 Vim 脚本编写五辑 《漫漫 Vim 路》 使用魔抓定制 Vim 插件 《 Vim 实践 (第 2 版)》 轻取 Vim 最佳书籍 Vimcasts.org Vim 录屏演示 为什么是个脚本都用 vi？ 常见误区释疑 你不爱 vi，所以你不懂 Vim 简明,扼要,准确的干货 Vim 配置集合 目前，网上有很多流行 Vim 配置集合，对于 Vim 配置集合，个人认为有利有弊。 对于维护的比较好的配置，比如 SpaceVim 还是值得尝试的，可以节省很多自行配置的时间。 当然，网上还有很多其他很流行的配置，比如：\nk-vim amix\u0026rsquo;s vimrc janus 常见问题 编辑小文件时很慢 有两个因素对性能影响非常大：\n过于复杂的 正则表达式 。尤其是 Ruby 的语法文件，以前会造成性能下降。（见调试语法文件）\n屏幕重绘 。有一些功能会强制重绘所有行。\n典型肇事者 原因 解决方案 :set cursorline 会导致所有行重绘 :set nocursorline :set cursorcolumn 会导致所有行重绘 :set nocursorcolumn :set relativenumber 会导致所有行重绘 :set norelativenumber :set foldmethod=syntax 如果语法文件已经很慢了，这只会变得更慢 :set foldmethod=manual，:set foldmethod=marker 或者使用快速折叠插件 :set synmaxcol=3000 由于内部表示法，Vim 处理比较长的行时会有问题。让它高亮到 3000 列…… :set synmaxcol=200 matchparen.vim Vim 默认加载的插件，用正则表达式查找配对的括号 禁用插件：:h matchparen 注意：只有在你真正遇到性能问题的时候才需要做上面的调整。在大多数情况下使用上面提到的选项是完全没有问题的。\n编辑大文件的时候很慢 Vim 处理大文件最大的问题就是它会一次性读取整个文件。这么做是由于缓冲区的内部机理导致的（在 vim_dev 中讨论）。\n如果只是想查看的话，tail hugefile | vim - 是一个不错的选择。\n如果你能接受没有语法高亮，并且禁用所有插件和设置的话，使用：\n$ vim -u NONE -N 这将会使得跳转变快很多，尤其是省去了基于很耗费资源的正则表达式的语法高亮。你还可以告诉 Vim 不要使用交换文件和 viminfo 文件，以避免由于写这些文件而造成的延时：\n$ vim -n -u NONE -i NONE -N 简而言之，尽量避免使用 Vim 写过大的文件。\n持续粘贴（为什么我每次都要设置 \u0026lsquo;paste\u0026rsquo; 模式） 持续粘贴模式让终端模拟器可以区分输入内容与粘贴内容。\n你有没有遇到过往 Vim 里粘贴代码之后被搞的一团糟？\n这在你使用 cmd+v、shirt-insert、middle-click 等进行粘贴的时候才会发生。 因为那样的话你只是向终端模拟器扔了一大堆的文本。 Vim 并不知道你刚刚是粘贴的文本，它以为你在飞速的输入。 于是它想缩进这些行但是失败了。\n这明显不是个问题，如果你用 Vim 的寄存器粘贴，如：\u0026quot;+p ，这时 Vim 就知道了你在粘贴，就不会导致格式错乱了。\n使用 :set paste 就可以解决这个问题正常进行粘贴。见 :h 'paste' 和 :h 'pastetoggle' 获取更多信息。\n如果你受够了每次都要设置 'paste' 的话，看看这个能帮你自动设置的插件：bracketed-paste。\n点此查看该作者对于这个插件的更多描述。\nNeovim 尝试把这些变得更顺畅，如果终端支持的话，它会自动开启持续粘贴模式，无须再手动进行切换。\n在终端中按 ESC 后有延时 如果你经常使用命令行，那么肯定要接触 终端模拟器 ，如 xterm、gnome-terminal、iTerm2 等等（与实际的终端不同）。\n终端模拟器与他们的祖辈一样，使用 转义序列 （也叫 控制序列 ）来控制光标移动、改变文本颜色等。转义序列就是以转义字符开头的 ASCII 字符串（用脱字符表示法表示成 ^[ ）。当遇到这样的字符串后，终端模拟器会从终端信息数据库中查找对应的动作。\n为了使用问题更加清晰，我会先来解释一下什么是映射超时。在映射存在歧义的时候就会产生映射超时：\n:nnoremap ,a :echo \u0026#39;foo\u0026#39;\u0026lt;cr\u0026gt; :nnoremap ,ab :echo \u0026#39;bar\u0026#39;\u0026lt;cr\u0026gt; 上面的例子中两个映射都能正常工作，但是当输入 ,a 之后，Vim 会延时 1 秒，因为它要确认用户是否还要输入那个 b。\n转义序列会产生同样的问题：\n\u0026lt;esc\u0026gt; 作为返回普通模式或取消某个动作的按键而被大量使用 光标键使用转义序列进行的编码 Vim 期望 Alt （也叫作 Mate Key ）会发送一个正确的 8-bit 编码的高位，但是许多终端模拟器并不支持这个（也可能默认没有启用），而只是发送一个转义序列作为代替。 你可以这样测试上面所提到的事情： vim -u NONE -N 然后输入 i\u0026lt;c-v\u0026gt;\u0026lt;left\u0026gt; ，你会看到一个以 ^[ 开头的字符串，表明这是一个转义序列，^[ 就是转义字符。\n简而言之，Vim 在区分录入的 \u0026lt;esc\u0026gt; 和转义序列的时候需要一定的时间。\n默认情况下，Vim 用 :set timeout timeoutlen=1000，就是说它会用 1 秒的时间来区分有歧义的映射 以及 按键编码。这对于映射来说是一个比较合理的值，但是你可以自行定义按键延时的长短，这是解决该问题最根本的办法：\nset timeout \u0026#34; for mappings set timeoutlen=1000 \u0026#34; default value set ttimeout \u0026#34; for key codes set ttimeoutlen=10 \u0026#34; unnoticeable small value 在 :h ttimeout 里你可以找到一个关于这些选项之间关系的小表格。\n而如果你在 tmux 中使用 Vim 的话，别忘了把下面的配置加入到你的 ~/.tmux.conf文件中：\nset -sg escape-time 0 无法重复函数中执行的搜索 在命令中的搜索（/、:substitute 等）内容会改变“上次使用的搜索内容”。（它保存在/寄存器中，用 :echo @/ 可以输出它里面的内容） 简单的文本变化可以通过 . 重做。（它保存在 . 寄存器，用 :echo @. 可以输出它的内容） 而在你在函数中进行这些操作的时候，一切就会变得不同。因此你不能用 N/n 查找某个函数刚刚查找的内容，也不能重做函数中对文本的修改。\n帮助文档：:h function-search-undo。\n进阶阅读 Vim 插件开发指南 参考资料 Nifty Little Nvim Techniques to Make My Life Easier \u0026ndash; Series 1 整理自：https://github.com/wsdjeg/vim-galore-zh_cn\n","permalink":"https://haokiu.com/blog/fhRygg/","summary":"什么是 Vim？ Vim 是一个历史悠久的文本编辑器，可以追溯到 qed。 Bram Moolenaar 于 1991 年发布初始版本。\nLinux、Mac 用户，可以使用包管理器安装 Vim，对于 Windows 用户，可以从 我的网盘 下载。 该版本可轻易添加 python 、python3 、lua 等支持，只需要安装 python、lua 即可。\n项目在 Github 上开发，项目讨论请订阅 vim_dev 邮件列表。\n通过阅读 Why, oh WHY, do those #?@! nutheads use vi? 来对 Vim 进行大致的了解。\nVim 哲学 Vim 采用模式编辑的理念，即它提供了多种模式，按键在不同的模式下作用不同。 你可以在普通模式 下浏览文件，在插入模式下插入文本， 在可视模式下选择行，在命令模式下执行命令等等。起初这听起来可能很复杂， 但是这有一个很大的优点：不需要通过同时按住多个键来完成操作， 大多数时候你只需要依次按下这些按键即可。越常用的操作，所需要的按键数量越少。\n和模式编辑紧密相连的概念是 操作符 和 动作。操作符 指的是开始某个行为， 例如：修改、删除或者选择文本，之后你要用一个 动作 来指定需要操作的文本区域。 比如，要改变括号内的文本，需要执行 ci( （读做 change inner parentheses）； 删除整个段落的内容，需要执行 dap （读做：delete around paragraph）。\n如果你能看见 Vim 老司机操作，你会发现他们使用 Vim 脚本语言就如同钢琴师弹钢琴一样。复杂的操作只需要几个按键就能完成。他们甚至不用刻意去想，因为这已经成为肌肉记忆了。这减少认识负荷并帮助人们专注于实际任务。\n入门 Vim 自带一个交互式的教程，内含你需要了解的最基础的信息，你可以通过终端运行以下命令打开教程：\n$ vimtutor 不要因为这个看上去很无聊而跳过，按照此教程多练习。你以前用的 IDE 或者其他编辑器很少是有“模式”概念的，因此一开始你会很难适应模式切换。但是你 Vim 使用的越多，肌肉记忆 将越容易形成。\nVim 基于一个 vi 克隆，叫做 Stevie，支持两种运行模式：\u0026ldquo;compatible\u0026rdquo; 和 \u0026ldquo;nocompatible\u0026rdquo;。在兼容模式下运行 Vim 意味着使用 vi 的默认设置，而不是 Vim 的默认设置。除非你新建一个用户的 vimrc 或者使用 vim -N 命令启动 Vim，否则就是在兼容模式下运行 Vim！请大家不要在兼容模式下运行 Vim。","title":"Vim 从入门到精通"},{"content":"数字货币的交易所有很多。\n比特儿 邀请注册：https://www.gate.io/signup/633017 ，点击这个链接注册的用户可以获取90$的交易点卡哦。\ngate.io 8年长期稳定运营，行业口碑品牌，安全可靠，注册即可获得手续费优惠!\nGate.io 作为前十的交易所它最吸引人的地方是秒充秒提，在速度上要比其他交易所好很多。同时它还独有地址共享技术，充错币的情况也不会发生。除此之外他们平台的活动也很多，不是只有交易才能获得奖励，写一句话写篇文章都是可以获得奖励的，类似的活动非常多。所以总的来说，Gate.io交易所还是很不错的。\nGate.io 上可以购买的币种也非常多，可以购买比特币、购买eth，购买dot，所有主流的数字货币都可以购买。\n最后一句提醒各位，数字货币价格波动很大，投资须谨慎！\n","permalink":"https://haokiu.com/blog/0PyB8g/","summary":"数字货币的交易所有很多。\n比特儿 邀请注册：https://www.gate.io/signup/633017 ，点击这个链接注册的用户可以获取90$的交易点卡哦。\ngate.io 8年长期稳定运营，行业口碑品牌，安全可靠，注册即可获得手续费优惠!\nGate.io 作为前十的交易所它最吸引人的地方是秒充秒提，在速度上要比其他交易所好很多。同时它还独有地址共享技术，充错币的情况也不会发生。除此之外他们平台的活动也很多，不是只有交易才能获得奖励，写一句话写篇文章都是可以获得奖励的，类似的活动非常多。所以总的来说，Gate.io交易所还是很不错的。\nGate.io 上可以购买的币种也非常多，可以购买比特币、购买eth，购买dot，所有主流的数字货币都可以购买。\n最后一句提醒各位，数字货币价格波动很大，投资须谨慎！","title":"购买比特币"},{"content":"2020 年好好读一读开源代码吧 2019 年就这么结束了，2020 年也来临了，虽然我曾对过去 2019 年做了一份总结，但是认真的来说，其实我对自己的 2019 年的收获并不太满意，一个主要的原因是计划好好研读的几个开源项目的源码都没有去做。好在，2020 新的一年，不再像 2019 年创业一般忙碌，终于可以静下心来认真去把这些未完成的计划好好做完。\n其实，我一直想找个机会和我的读者，好好讨论一下阅读开源项目源码这个话题的，我这里观点无任何含糊或者模棱两可，我旗帜鲜明的亮出我的观点——想在技术上有所造诣或者想成为某一技术领域的专家的同学一定要认认真真的研读几个开源软件的源码。下面我会具体来展开说下这个问题。\n知识付费与阅读源码 大家都知道，时下\u0026quot;知识付费\u0026quot;这个词非常火热，各大平台各个领域都推出了许多基于知识付费的课程，有图文版、语音版和视频版（包括在线实时教育直播）。当然，知识付费是一个好东西。众所周知，互联网信息的特点是信息量大、有用信息少、信息质量良莠不齐，各大平台推出的各种付费课程，精心制作，用心分类和梳理，读者只要花费一定的费用，就能省去大量搜索、查找和遴选信息的时间，直接专注于获得相关知识本身。\n在各类知识付费课程中，有一类课程是介绍业界或者大家平常工作中用到的一些开源软件的原理的，进一步说，有的是分析这类软件的源码的，如 nginx、netty、Spring Boot。\n我个人觉得，虽然你可以购买一些这样那样的开源软件的教程或者图书（包括电子书）去学习，但一定不要以这些学习材料为主要的学习这些开源软件的方法和途径，有机会的话，或者说如果你要学习的开源软件所使用的开发语言正好是你熟悉或者使用的编程语言，那么你应该尽量多去以阅读这些开源项目的源码本身为主。举个例子，如果你是 C/C++ 后端开发者，那么像 redis、nginx（它们都是使用 C 编写的）这样的开源项目的源码你应该认真的去研读一下；如果你是做 Windows C/C++ 客户端或者一名 QT 客户端开发人员，那么像 MFC、DUILIB、金山卫士等源码，你可以拿来读一读；如果你是 Java 程序员，netty、Spring 等源码是你进阶路上必须迈过去的一关。\n为什么建议以阅读相关源码为主，而不是其他相关教程呢？\n首先，任何其他相关教程介绍的内容都是基于这个软件的源码实现创作出来的，虽然能帮助你快速理解一些东西，但是不同的教程作者在阅读同样一份代码时的注意点和侧重点不一样，加上如果作者在某些地方有理解偏差的，这种偏差会被引入你所学习的教程或者图书里面，也就是说，你学习的这些东西其实不是第一手的，而是经过别人加工或者理解意译过的，在这个过程中如果别人理解有偏差，那么你或多或少的会受一点影响。所以，为了\u0026quot;不受制于人”，亲自去阅读一些源码时非常有必要的。\n其次，如果你按照别人的教程大纲，那么你的学习该软件的开源项目时，可能会受限于别人的视野和侧重点，通俗的说，假设一个开源项目其可以学习和借鉴的内容有 A、B、C、D、E 五个大的点，别人的教程可能只写了 A、B、C、D 四个点，如果你只局限于别人的教程，你就错过 E 这个点了。\n这里可以给读者讲一个具体的例子。我最初开始走上工作岗位时做的是 C/C++ 客户端开发，我无意中找到了一份完整的电驴源码，但是开始阅读这份代码比较吃力，于是我就在网上找相关的电驴源码分析教程来看。但是呢，网上的这方面的教程都是关于电驴的网络通信模块和通信协议介绍的，很多做客户端的读者是知道的，做客户端开发很大一部分工作是在开发 UI 界面方面的逻辑和布局，其实电驴源码中关于界面设计逻辑写的也是很精彩的，也非常值得当时的我去借鉴和学习。如果我只按照网上的教程去学习，那么就错过这方面的学习了。也就是同样一份电驴源码，不同的学习者汲取的其源码中的营养成分是不一样的。需要电驴源码的同学可以在公众号后台回复关键字【电驴源码】获取下载链接。\n如何去阅读源码呢？ 这应该是很多读者想知道的问题，先讨论几种老生常谈的阅读源码的方式。\n第一种方式就是所谓的精读和粗读。很多读者应该听说过这种所谓的阅读源代码的方式，有些人认为有些源码只需要搞清楚其主要结构和流程就可以了，而另外一些源码需要逐行认真去研读其某个或者某几个模块的源码。或者，只阅读自己感兴趣或者需要的模块。\n第二种方式，说的是先熟悉代码的整体结构，再去依次搞清楚各个模块的代码细节。\n第三种方式是所谓的调试法，通过开源项目的一个或几个典型的流程，去调试跟踪信息流，然后逐步搞清楚整个项目的结构。\n以上三种方式都是不错的阅读源码的方式，读者可以根据自己的水平、目的和阶段去使用。但是，我这里想说的并不是这些东西。\n我个人觉得，一个技术人员如果想通过源码去提高自己，应该以一种\u0026quot;闲登小阁看新晴\u0026quot;的心境去阅读源码，这也许是在某个节假日的清晨，某个下过雨的午后，某个夜黑人静的深夜。看源码尤其是看高质量源码本来就是一种享受，像品茗。闲暇时间去细细品味一些开源软件的源码，和锻炼身体一样，都是人生中重要不紧急的事情，这类事情做的越多，坚持的越久，越能提高你的人生厚度。虽然阅读源码的最终目的是功利性的，但是阅读源码的心态不建议是功利性的，喜欢做一件事本身的过程，比把这件事做好的目标更快乐。\n我从学生时代开始，就喜欢看一些开源软件的源码，当然，从现在的标准来看，看的很多源码都不是\u0026quot;高质量\u0026quot;的，择其善者而从之其不善者而改之，不是吗？有些源码可以学习其架构、结构设计，有些源码则可以学习其细节设计（如变量命名、编码风格等）。\n看过的这些源码对我的技术视野影响很大。我上大学的时候，迷恋 Flash 编程，当时非常崇拜 Flash 界的两位前辈——鼠标炸弹（https://mousebomb.org/）和寂寞火山（现在已成币圈有名的大佬），另外还有淘沙网的沙子。多年后再看他们的代码可能质量没有那么高，但是我从他们开源出来的代码中学到了很多东西。举个例子，我喜欢在一些成对结束的花括号后面加上明显的成对结束的注释就是从沙子的代码那里学来的。虽然，现在的 IDE 会清楚的标示出来各个花括号的范围，但是这种注释风格在某些时候大大方便了代码阅读和 review。\n//实例 class A { public: void someFunc() { for (int i = 0; i \u0026lt; n; ++i) { for (int j = 0; j \u0026lt; m; ++j) { //some codes... }// end inner-for-loop\t}// end outer-for-loop }// end method someFunc }; // end class A 给大家阅读源码的一些建议 很多人阅读源码存在以下不当的习惯或者认知方式：\n很多人阅读源码其实是随波逐流的，今天有人推荐阅读 A 项目的源码，他就去阅读 A 项目的源码，明天有人推荐阅读 B 项目的源码，他就去阅读 B 项目的源码。天下源码何其多呀，找到自己感兴趣的或者对自己有用的，不要随波逐流，适合别人的不一定适合你。 有些人阅读源码非要满足了\u0026quot;天时地利人和\u0026quot;才会去阅读。例如，有些人觉得自己不懂网络编程，所以就不方便阅读 nginx 的源码，有些人听别人说阅读某个项目的源码前必须先做 XX，而自己又不熟悉 XX，所以就放弃了阅读该项目。或者觉得当下时机不适合阅读某个项目的源码。再或者在阅读几个源码文件或者模块的代码时，因为看不懂就放弃了。其实这些做法都不可取，任何源码和你刚进入公司去接触一个新的业务项目的源码一样，只要慢慢熟悉，在这过程中针对性的补缺补差，坚持下来总会有所收获的。尤其是对那些走上工作岗位的读者来说，成年人的世界事情那么多，此生余年应该不会再有什么时间可以同时满足\u0026quot;天时地利人和\u0026quot;了吧。 代码的质量高低是相对的，不要因为一些项目的源码质量低或者不符合你的 style 就放弃。大多数完整的项目代码总有其可取之处，要学会吸取其有用之处。举个例子，很多做 Windows C++ 客户端开发的同学，应该会在网络的各个地方看到很多人抨击 MFC 的，然后一堆建议不要学习 MFC 的。从我个人的经历和感受来看，MFC 的源码还是很值得做 Windows C++ 客户端的同学学习的，尤其是其设计思想。当然，MFC 之所以被很多人抨击，是因为其臃肿笨拙，这有很多历史原因，MFC 不仅封装 Windows 界面逻辑那一套，同时实现了一套常用软件文档、视图模型的程序框架结构，同时自己实现了一套 STL 相关功能，以及其他一些常用功能（如对象的序列化和反序列化）。这些设计思想都被后来的各种软件框架借鉴和继承，例如 QT 和 Java 中的序列化和反序列化。一个开发者如果想成为架构师，其心中一定要对某个场景有一套可行的技术方案，如果你经验不足或者水平不够，拿不出来这样的方案，那就去借鉴和学习这些开源的软件。而不是只会抨击这些软件源码的缺点，而自己又无更好的解决方案。旧的方案虽然不好，但是我们需要去学习、熟悉，只有熟悉了之后，我们才能基于其去改造和优化。 最后，阅读源码不是做给别人看的，如果你之前从未意识到阅读各种大大小小的开源项目的源码的重要性，2020 年循序渐进，少买点在线课程，少囤点书，多读些源码吧。\n","permalink":"https://haokiu.com/blog/ea1d963411184ea88648b092380ee687/","summary":"2020 年好好读一读开源代码吧 2019 年就这么结束了，2020 年也来临了，虽然我曾对过去 2019 年做了一份总结，但是认真的来说，其实我对自己的 2019 年的收获并不太满意，一个主要的原因是计划好好研读的几个开源项目的源码都没有去做。好在，2020 新的一年，不再像 2019 年创业一般忙碌，终于可以静下心来认真去把这些未完成的计划好好做完。\n其实，我一直想找个机会和我的读者，好好讨论一下阅读开源项目源码这个话题的，我这里观点无任何含糊或者模棱两可，我旗帜鲜明的亮出我的观点——想在技术上有所造诣或者想成为某一技术领域的专家的同学一定要认认真真的研读几个开源软件的源码。下面我会具体来展开说下这个问题。\n知识付费与阅读源码 大家都知道，时下\u0026quot;知识付费\u0026quot;这个词非常火热，各大平台各个领域都推出了许多基于知识付费的课程，有图文版、语音版和视频版（包括在线实时教育直播）。当然，知识付费是一个好东西。众所周知，互联网信息的特点是信息量大、有用信息少、信息质量良莠不齐，各大平台推出的各种付费课程，精心制作，用心分类和梳理，读者只要花费一定的费用，就能省去大量搜索、查找和遴选信息的时间，直接专注于获得相关知识本身。\n在各类知识付费课程中，有一类课程是介绍业界或者大家平常工作中用到的一些开源软件的原理的，进一步说，有的是分析这类软件的源码的，如 nginx、netty、Spring Boot。\n我个人觉得，虽然你可以购买一些这样那样的开源软件的教程或者图书（包括电子书）去学习，但一定不要以这些学习材料为主要的学习这些开源软件的方法和途径，有机会的话，或者说如果你要学习的开源软件所使用的开发语言正好是你熟悉或者使用的编程语言，那么你应该尽量多去以阅读这些开源项目的源码本身为主。举个例子，如果你是 C/C++ 后端开发者，那么像 redis、nginx（它们都是使用 C 编写的）这样的开源项目的源码你应该认真的去研读一下；如果你是做 Windows C/C++ 客户端或者一名 QT 客户端开发人员，那么像 MFC、DUILIB、金山卫士等源码，你可以拿来读一读；如果你是 Java 程序员，netty、Spring 等源码是你进阶路上必须迈过去的一关。\n为什么建议以阅读相关源码为主，而不是其他相关教程呢？\n首先，任何其他相关教程介绍的内容都是基于这个软件的源码实现创作出来的，虽然能帮助你快速理解一些东西，但是不同的教程作者在阅读同样一份代码时的注意点和侧重点不一样，加上如果作者在某些地方有理解偏差的，这种偏差会被引入你所学习的教程或者图书里面，也就是说，你学习的这些东西其实不是第一手的，而是经过别人加工或者理解意译过的，在这个过程中如果别人理解有偏差，那么你或多或少的会受一点影响。所以，为了\u0026quot;不受制于人”，亲自去阅读一些源码时非常有必要的。\n其次，如果你按照别人的教程大纲，那么你的学习该软件的开源项目时，可能会受限于别人的视野和侧重点，通俗的说，假设一个开源项目其可以学习和借鉴的内容有 A、B、C、D、E 五个大的点，别人的教程可能只写了 A、B、C、D 四个点，如果你只局限于别人的教程，你就错过 E 这个点了。\n这里可以给读者讲一个具体的例子。我最初开始走上工作岗位时做的是 C/C++ 客户端开发，我无意中找到了一份完整的电驴源码，但是开始阅读这份代码比较吃力，于是我就在网上找相关的电驴源码分析教程来看。但是呢，网上的这方面的教程都是关于电驴的网络通信模块和通信协议介绍的，很多做客户端的读者是知道的，做客户端开发很大一部分工作是在开发 UI 界面方面的逻辑和布局，其实电驴源码中关于界面设计逻辑写的也是很精彩的，也非常值得当时的我去借鉴和学习。如果我只按照网上的教程去学习，那么就错过这方面的学习了。也就是同样一份电驴源码，不同的学习者汲取的其源码中的营养成分是不一样的。需要电驴源码的同学可以在公众号后台回复关键字【电驴源码】获取下载链接。\n如何去阅读源码呢？ 这应该是很多读者想知道的问题，先讨论几种老生常谈的阅读源码的方式。\n第一种方式就是所谓的精读和粗读。很多读者应该听说过这种所谓的阅读源代码的方式，有些人认为有些源码只需要搞清楚其主要结构和流程就可以了，而另外一些源码需要逐行认真去研读其某个或者某几个模块的源码。或者，只阅读自己感兴趣或者需要的模块。\n第二种方式，说的是先熟悉代码的整体结构，再去依次搞清楚各个模块的代码细节。\n第三种方式是所谓的调试法，通过开源项目的一个或几个典型的流程，去调试跟踪信息流，然后逐步搞清楚整个项目的结构。\n以上三种方式都是不错的阅读源码的方式，读者可以根据自己的水平、目的和阶段去使用。但是，我这里想说的并不是这些东西。\n我个人觉得，一个技术人员如果想通过源码去提高自己，应该以一种\u0026quot;闲登小阁看新晴\u0026quot;的心境去阅读源码，这也许是在某个节假日的清晨，某个下过雨的午后，某个夜黑人静的深夜。看源码尤其是看高质量源码本来就是一种享受，像品茗。闲暇时间去细细品味一些开源软件的源码，和锻炼身体一样，都是人生中重要不紧急的事情，这类事情做的越多，坚持的越久，越能提高你的人生厚度。虽然阅读源码的最终目的是功利性的，但是阅读源码的心态不建议是功利性的，喜欢做一件事本身的过程，比把这件事做好的目标更快乐。\n我从学生时代开始，就喜欢看一些开源软件的源码，当然，从现在的标准来看，看的很多源码都不是\u0026quot;高质量\u0026quot;的，择其善者而从之其不善者而改之，不是吗？有些源码可以学习其架构、结构设计，有些源码则可以学习其细节设计（如变量命名、编码风格等）。\n看过的这些源码对我的技术视野影响很大。我上大学的时候，迷恋 Flash 编程，当时非常崇拜 Flash 界的两位前辈——鼠标炸弹（https://mousebomb.org/）和寂寞火山（现在已成币圈有名的大佬），另外还有淘沙网的沙子。多年后再看他们的代码可能质量没有那么高，但是我从他们开源出来的代码中学到了很多东西。举个例子，我喜欢在一些成对结束的花括号后面加上明显的成对结束的注释就是从沙子的代码那里学来的。虽然，现在的 IDE 会清楚的标示出来各个花括号的范围，但是这种注释风格在某些时候大大方便了代码阅读和 review。\n//实例 class A { public: void someFunc() { for (int i = 0; i \u0026lt; n; ++i) { for (int j = 0; j \u0026lt; m; ++j) { //some codes... }// end inner-for-loop\t}// end outer-for-loop }// end method someFunc }; // end class A 给大家阅读源码的一些建议 很多人阅读源码存在以下不当的习惯或者认知方式：","title":"2020 年好好读一读开源代码吧"},{"content":"C++ 高性能服务器网络框架设计细节 这篇文章我们将介绍服务器的开发，并从多个方面探究如何开发一款高性能高并发的服务器程序。需要注意的是一般大型服务器，其复杂程度在于其业务，而不是在于其代码工程的基本框架。大型服务器一般有多个服务组成，可能会支持CDN，或者支持所谓的“分布式”等，这篇文章不会介绍这些东西，因为不管结构多么复杂的服务器，都是由单个服务器组成的。所以这篇文章的侧重点是讨论单个服务程序的结构，而且这里的结构指的也是单个服务器的网络通信层结构，如果你能真正地理解了我所说的，那么在这个基础的结构上面开展任何业务都是可以的，也可以将这种结构扩展成复杂的多个服务器组，例如“分布式”服务。文中的代码示例虽然是以C++为例，但同样适合Java（我本人也是Java开发者），原理都是一样的，只不过Java可能在基本的操作系统网络通信API的基础上用虚拟机包裹了一层接口而已（Java甚至可能基于一些常用的网络通信框架思想提供了一些现成的API，例如NIO）。有鉴于此，这篇文章不讨论那些大而空、泛泛而谈的技术术语，而是讲的是实实在在的能指导读者在实际工作中实践的编码方案或优化已有编码的方法。另外这里讨论的技术同时涉及windows和linux两个平台。\n所谓高性能就是服务器能流畅地处理各个客户端的连接并尽量低延迟地应答客户端的请求；所谓高并发，不仅指的是服务器可以同时支持多的客户端连接，而且这些客户端在连接期间内会不断与服务器有数据来往。网络上经常有各种网络库号称单个服务能同时支持百万甚至千万的并发，然后我实际去看了下，结果发现只是能同时支持很多的连接而已。如果一个服务器能单纯地接受ｎ个连接（ｎ可能很大），但是不能有条不紊地处理与这些连接之间的数据来往也没有任何意义，这种服务器框架只是“玩具型”的，对实际生产和应用没有任何意义。\n这篇文章将从两个方面来介绍，一个是服务器中的基础的网络通信部件；另外一个是，如何利用这些基础通信部件整合成一个完整的高效的服务器框架。注意：本文以下内容中的客户端是相对概念，指的是连接到当前讨论的服务程序的终端，所以这里的客户端既可能是我们传统意义上的客户端程序，也可能是连接该服务的其他服务器程序。\n一、网络通信部件 按上面介绍的思路，我们先从服务程序的网络通信部件开始介绍。\n（一）、需要解决的问题 既然是服务器程序肯定会涉及到网络通信部分，那么服务器程序的网络通信模块要解决哪些问题？目前，网络上有很多网络通信框架，如libevent、boost asio、ACE，但都网络通信的常见的技术手段都大同小异，至少要解决以下问题：\n如何检测有新客户端连接？ 如何接受客户端连接？ 如何检测客户端是否有数据发来？ 如何收取客户端发来的数据？ 如何检测连接异常？发现连接异常之后，如何处理？ 如何给客户端发送数据？ 如何在给客户端发完数据后关闭连接？ 稍微有点网络基础的人，都能回答上面说的其中几个问题，比如接收客户端连接用socket API的accept函数，收取客户端数据用recv函数，给客户端发送数据用send函数，检测客户端是否有新连接和客户端是否有新数据可以用IO multiplexing技术（IO复用）的select、poll、epoll等socket API。确实是这样的，这些基础的socket API构成了服务器网络通信的地基，不管网络通信框架设计的如何巧妙，都是在这些基础的socket API的基础上构建的。但是如何巧妙地组织这些基础的socket API，才是问题的关键。我们说服务器很高效，支持高并发，实际上只是一个技术实现手段，不管怎样，从软件开发的角度来讲无非就是一个程序而已，所以，只要程序能最大可能地满足“尽量减少等待或者不等待”这一原则就是高效的，也就是说高效不是“忙的忙死，闲的闲死”，而是大家都可以闲着，但是如果有活要干，大家尽量一起干，而不是一部分忙着依次做事情123456789，另外一部分闲在那里无所事事。说的可能有点抽象，下面我们来举一些例子具体来说明一下。 例如：\n默认情况下，recv函数如果没有数据的时候，线程就会阻塞在那里； 默认情况下，send函数，如果tcp窗口不是足够大，数据发不出去也会阻塞在那里； connect函数默认连接另外一端的时候，也会阻塞在那里； 又或者是给对端发送一份数据，需要等待对端回答，如果对方一直不应答，当前线程就阻塞在这里。 以上都不是高效服务器的开发思维方式，因为上面的例子都不满足“尽量减少等待”的原则，为什么一定要等待呢？有没用一种方法，这些过程不需要等待，最好是不仅不需要等待，而且这些事情完成之后能通知我。这样在这些本来用于等待的cpu时间片内，我就可以做一些其他的事情。有，也就是我们下文要讨论的IO Multiplexing技术（IO复用技术）。\n（二）、几种IO复用机制的比较 目前windows系统支持select、WSAAsyncSelect、WSAEventSelect、完成端口（IOCP），linux系统支持select、poll、epoll。这里我们不具体介绍每个具体的函数的用法，我们来讨论一点深层次的东西，以上列举的API函数可以分为两个层次：\n层次一 select和poll 层次二 WSAAsyncSelect、WSAEventSelect、完成端口（IOCP）、epoll 为什么这么分呢？先来介绍第一层次，select和poll函数本质上还是在一定时间内主动去查询socket句柄（可能是一个也可能是多个）上是否有事件，比如可读事件，可写事件或者出错事件，也就是说我们还是需要每隔一段时间内去主动去做这些检测，如果在这段时间内检测出一些事件来，我们这段时间就算没白花，但是倘若这段时间内没有事件呢？我们只能是做无用功了，说白了，还是在浪费时间，因为假如一个服务器有多个连接，在cpu时间片有限的情况下，我们花费了一定的时间检测了一部分socket连接，却发现它们什么事件都没有，而在这段时间内我们却有一些事情需要处理，那我们为什么要花时间去做这个检测呢？把这个时间用在做我们需要做的事情不好吗？所以对于服务器程序来说，要想高效，我们应该尽量避免花费时间主动去查询一些socket是否有事件，而是等这些socket有事件的时候告诉我们去处理。这也就是层次二的各个函数做的事情，它们实际相当于变主动查询是否有事件为当有事件时，系统会告诉我们，此时我们再去处理，也就是“好钢用在刀刃”上了。只不过层次二的函数通知我们的方式是各不相同，比如WSAAsyncSelect是利用windows窗口消息队列的事件机制来通知我们设定的窗口过程函数，IOCP是利用GetQueuedCompletionStatus返回正确的状态，epoll是epoll_wait函数返回而已。\n例如，connect函数连接另外一端，如果用于连接socket是非阻塞的，那么connect虽然不能立刻连接完成，但是也是会立刻返回，无需等待，等连接完成之后，WSAAsyncSelect会返回FD_CONNECT事件告诉我们连接成功，epoll会产生EPOLLOUT事件，我们也能知道连接完成。甚至socket有数据可读时，WSAAsyncSelect产生FD_READ事件，epoll产生EPOLLIN事件，等等。所以有了上面的讨论，我们就可以得到网络通信检测可读可写或者出错事件的正确姿势。这是我这里提出的第二个原则：尽量减少做无用功的时间。这个在服务程序资源够用的情况下可能体现不出来什么优势，但是如果有大量的任务要处理，这里就成了性能的一个瓶颈。\n（三）、检测网络事件的正确姿势 根据上面的介绍，第一，为了避免无意义的等待时间，第二，不采用主动查询各个socket的事件，而是采用等待操作系统通知我们有事件的状态的策略。我们的socket都要设置成非阻塞的。在此基础上我们回到栏目（一）中提到的七个问题：\n如何检测有新客户端连接？\n如何接受客户端连接？ 默认accept函数会阻塞在那里，如果epoll检测到侦听socket上有EPOLLIN事件，或者WSAAsyncSelect检测到有FD_ACCEPT事件，那么就表明此时有新连接到来，这个时候调用accept函数，就不会阻塞了。当然产生的新socket你应该也设置成非阻塞的。这样我们就能在新socket上收发数据了。 如何检测客户端是否有数据发来？\n如何收取客户端发来的数据？ 同理，我们也应该在socket上有可读事件的时候才去收取数据，这样我们调用recv或者read函数时不用等待，至于一次性收多少数据好呢？我们可以根据自己的需求来决定，甚至你可以在一个循环里面反复recv或者read，对于非阻塞模式的socket，如果没有数据了，recv或者read也会立刻返回，错误码EWOULDBLOCK会表明当前已经没有数据了。示例：\nbool CIUSocket::Recv() { int nRet = 0; while(true) { char buff[512]; nRet = ::recv(m_hSocket, buff, 512, 0); if(nRet == SOCKET_ERROR) { if (::WSAGetLastError() == WSAEWOULDBLOCK) break; else return false; } else if(nRet \u0026lt; 1) return false;\nm_strRecvBuf.append(buff, nRet); ::Sleep(1); } return true; }\n如何检测连接异常？发现连接异常之后，如何处理？ 同样当我们收到异常事件后例如EPOLLERR或关闭事件FD_CLOSE，我们就知道了有异常产生，我们对异常的处理一般就是关闭对应的socket。另外，如果send/recv或者read/write函数对一个socket进行操作时，如果返回0，那说明对端已经关闭了socket，此时这路连接也没必要存在了，我们也可以关闭对应的socket。\n如何给客户端发送数据？ 这也是一道常见的网络通信面试题，某一年的腾讯后台开发职位就问到过这样的问题。给客户端发送数据，比收数据要稍微麻烦一点，也是需要讲点技巧的。首先我们不能像注册检测数据可读事件一样一开始就注册检测数据可写事件，因为如果检测可写的话，一般情况下只要对端正常收取数据，我们的socket就都是可写的，如果我们设置监听可写事件，会导致频繁地触发可写事件，但是我们此时并不一定有数据需要发送。所以正确的做法是：如果有数据要发送，则先尝试着去发送，如果发送不了或者只发送出去部分，剩下的我们需要将其缓存起来，然后再设置检测该socket上可写事件，下次可写事件产生时，再继续发送，如果还是不能完全发出去，则继续设置侦听可写事件，如此往复，一直到所有数据都发出去为止。一旦所有数据都发出去以后，我们要移除侦听可写事件，避免无用的可写事件通知。不知道你注意到没有，如果某次只发出去部分数据，剩下的数据应该暂且存起来，这个时候我们就需要一个缓冲区来存放这部分数据，这个缓冲区我们称为“发送缓冲区”。发送缓冲区不仅存放本次没有发完的数据，还用来存放在发送过程中，上层又传来的新的需要发送的数据。为了保证顺序，新的数据应该追加在当前剩下的数据的后面，发送的时候从发送缓冲区的头部开始发送。也就是说先来的先发送，后来的后发送。 如何在给客户端发完数据后关闭连接？ 这个问题比较难处理，因为这里的“发送完”不一定是真正的发送完，我们调用send或者write函数即使成功，也只是向操作系统的协议栈里面成功写入数据，至于能否被发出去、何时被发出去很难判断，发出去对方是否收到就更难判断了。所以，我们目前只能简单地认为send或者write返回我们发出数据的字节数大小，我们就认为“发完数据”了。然后调用close等socket API关闭连接。当然，你也可以调用shutdown函数来实现所谓的“半关闭”。关于关闭连接的话题，我们再单独开一个小的标题来专门讨论一下。\n（四）被动关闭连接和主动关闭连接 在实际的应用中，被动关闭连接是由于我们检测到了连接的异常事件，比如EPOLLERR，或者对端关闭连接，send或recv返回0，这个时候这路连接已经没有存在必要的意义了，我们被迫关闭连接。\n而主动关闭连接，是我们主动调用close/closesocket来关闭连接。比如客户端给我们发送非法的数据，比如一些网络攻击的尝试性数据包。这个时候出于安全考虑，我们关闭socket连接。\n（五）发送缓冲区和接收缓冲区 上面已经介绍了发送缓冲区了，并说明了其存在的意义。接收缓冲区也是一样的道理，当收到数据以后，我们可以直接进行解包，但是这样并不好，理由一：除非一些约定俗称的协议格式，比如http协议，大多数服务器的业务的协议都是不同的，也就是说一个数据包里面的数据格式的解读应该是业务层的事情，和网络通信层应该解耦，为了网络层更加通用，我们无法知道上层协议长成什么样子，因为不同的协议格式是不一样的，它们与具体的业务有关。理由二：即使知道协议格式，我们在网络层进行解包处理对应的业务，如果这个业务处理比较耗时，比如需要进行复杂的运算，或者连接数据库进行账号密码验证，那么我们的网络线程会需要大量时间来处理这些任务，这样其它网络事件可能没法及时处理。鉴于以上二点，我们确实需要一个接收缓冲区，将收取到的数据放到该缓冲区里面去，并由专门的业务线程或者业务逻辑去从接收缓冲区中取出数据，并解包处理业务。\n说了这么多，那发送缓冲区和接收缓冲区该设计成多大的容量？这是一个老生常谈的问题了，因为我们经常遇到这样的问题：预分配的内存太小不够用，太大的话可能会造成浪费。怎么办呢？答案就是像string、vector一样，设计出一个可以动态增长的缓冲区，按需分配，不够还可以扩展。\n需要特别注意的是，这里说的发送缓冲区和接收缓冲区是每一个socket连接都存在一个。这是我们最常见的设计方案。\n（六）协议的设计 除了一些通用的协议，如http、ftp协议以外，大多数服务器协议都是根据业务制定的。协议设计好了，数据包的格式就根据协议来设置。我们知道tcp/ip协议是流式数据，所以流式数据就是像流水一样，数据包与数据包之间没有明显的界限。比如A端给B端连续发了三个数据包，每个数据包都是50个字节，B端可能先收到10个字节，再收到140个字节；或者先收到20个字节，再收到20个字节，再收到110个字节；也可能一次性收到150个字节。这150个字节可以以任何字节数目组合和次数被B收到。所以我们讨论协议的设计第一个问题就是如何界定包的界限，也就是接收端如何知道每个包数据的大小。目前常用有如下三种方法： １. 固定大小，这种方法就是假定每一个包的大小都是固定字节数目，例如上文中讨论的每个包大小都是50个字节，接收端每收气50个字节就当成一个包。 ２. 指定包结束符，例如以一个\\r\\n(换行符和回车符)结束，这样对端只要收到这样的结束符，就可以认为收到了一个包，接下来的数据是下一个包的内容。 ３. 指定包的大小，这种方法结合了上述两种方法，一般包头是固定大小，包头中有一个字段指定包体或者整个大的大小，对端收到数据以后先解析包头中的字段得到包体或者整个包的大小，然后根据这个大小去界定数据的界线。\n协议要讨论的第二个问题是，设计协议的时候要尽量方便解包，也就是说协议的格式字段应该尽量清晰明了。\n协议要讨论的第三个问题是，根据协议组装的单个数据包应该尽量小，注意这里指的是单个数据包，这样有如下好处：第一、对于一些移动端设备来说，其数据处理能力和带宽能力有限，小的数据不仅能加快处理速度，同时节省大量流量费用；第二、如果单个数据包足够小的话，对频繁进行网络通信的服务器端来说，可以大大减小其带宽压力，其所在的系统也能使用更少的内存。试想：假如一个股票服务器，如果一只股票的数据包是100个字节或者1000个字节，那同样是10000只股票区别呢？\n协议要讨论的第四个问题是，对于数值类型，我们应该显式地指定数值的长度，比如long型，在32位机器上是32位4个字节，但是如果在64位机器上，就变成了64位8个字节了。这样同样是一个long型，发送方和接收方可能因为机器位数的不同会用不同的长度去解码。所以建议最好，在涉及到跨平台使用的协议最好显式地指定协议中整型字段的长度，比如int32、int64等等。下面是一个协议的接口的例子，当然java程序员应该很熟悉这样的接口：\nclass BinaryReadStream { private: const char* const ptr; const size_t len; const char* cur; BinaryReadStream(const BinaryReadStream\u0026amp;); BinaryReadStream\u0026amp; operator=(const BinaryReadStream\u0026amp;); public: BinaryReadStream(const char* ptr, size_t len); virtual const char* GetData() const; virtual size_t GetSize() const; bool IsEmpty() const; bool ReadString(string* str, size_t maxlen, size_t\u0026amp; outlen); bool ReadCString(char* str, size_t strlen, size_t\u0026amp; len); bool ReadCCString(const char** str, size_t maxlen, size_t\u0026amp; outlen); bool ReadInt32(int32_t\u0026amp; i); bool ReadInt64(int64_t\u0026amp; i); bool ReadShort(short\u0026amp; i); bool ReadChar(char\u0026amp; c); size_t ReadAll(char* szBuffer, size_t iLen) const; bool IsEnd() const; const char* GetCurrent() const{ return cur; } public: bool ReadLength(size_t \u0026amp; len); bool ReadLengthWithoutOffset(size_t \u0026amp;headlen, size_t \u0026amp; outlen); }; class BinaryWriteStream { public: BinaryWriteStream(string* data); virtual const char* GetData() const; virtual size_t GetSize() const; bool WriteCString(const char* str, size_t len); bool WriteString(const string\u0026amp; str); bool WriteDouble(double value, bool isNULL = false); bool WriteInt64(int64_t value, bool isNULL = false); bool WriteInt32(int32_t i, bool isNULL = false); bool WriteShort(short i, bool isNULL = false); bool WriteChar(char c, bool isNULL = false); size_t GetCurrentPos() const{ return m_data-\u0026gt;length(); } void Flush(); void Clear(); private: string* m_data; }; 其中BinaryWriteStream是编码协议的类，BinaryReadStream是解码协议的类。可以按下面这种方式来编码和解码。 编码：\nstd::string outbuf; BinaryWriteStream writeStream(\u0026amp;outbuf); writeStream.WriteInt32(msg_type_register); writeStream.WriteInt32(m_seq); writeStream.WriteString(retData); writeStream.Flush(); 解码：\nBinaryReadStream readStream(strMsg.c_str(), strMsg.length()); int32_t cmd; if (!readStream.ReadInt32(cmd)) { return false; } //int seq; if (!readStream.ReadInt32(m_seq)) { return false; } std::string data; size_t datalength; if (!readStream.ReadString(\u0026amp;data, 0, datalength)) { return false; } 二、服务器程序结构的组织\n上面的六个标题，我们讨论了很多具体的细节问题，现在是时候讨论将这些细节组织起来了。根据我的个人经验，目前主流的思想是one thread one loop+reactor模式（也有proactor模式）的策略。通俗点说就是一个线程一个循环，即在一个线程的函数里面不断地循环依次做一些事情，这些事情包括检测网络事件、解包数据产生业务逻辑。我们先从最简单地来说，设定一些线程在一个循环里面做网络通信相关的事情，伪码如下：\nwhile(退出标志) { //IO复用技术检测socket可读事件、出错事件 //（如果有数据要发送，则也检测可写事件） //如果有可读事件，对于侦听socket则接收新连接； //对于普通socket则收取该socket上的数据，收取的数据存入对应的接收缓冲区，如果出错则关闭连接； //如果有数据要发送，有可写事件，则发送数据 //如果有出错事件，关闭该连接 } 另外设定一些线程去处理接收到的数据，并解包处理业务逻辑，这些线程可以认为是业务线程了，伪码如下：\n//从接收缓冲区中取出数据解包，分解成不同的业务来处理 上面的结构是目前最通用的服务器逻辑结构，但是能不能再简化一下或者说再综合一下呢？我们试试，你想过这样的问题没有：假如现在的机器有两个cpu（准确的来说应该是两个核），我们的网络线程数量是2个，业务逻辑线程也是2个，这样可能存在的情况就是：业务线程运行的时候，网络线程并没有运行，它们必须等待，如果是这样的话，干嘛要多建两个线程呢？除了程序结构上可能稍微清楚一点，对程序性能没有任何实质性提高，而且白白浪费cpu时间片在线程上下文切换上。所以，我们可以将网络线程与业务逻辑线程合并，合并后的伪码看起来是这样子的：\nwhile(退出标志) { //IO复用技术检测socket可读事件、出错事件 //（如果有数据要发送，则也检测可写事件） //如果有可读事件，对于侦听socket则接收新连接； //对于普通socket则收取该socket上的数据，收取的数据存入对应的接收缓冲区，如果出错则关闭连接； //如果有数据要发送，有可写事件，则发送数据 //如果有出错事件，关闭该连接 //从接收缓冲区中取出数据解包，分解成不同的业务来处理 } 你没看错，其实就是简单的合并，合并之后和不仅可以达到原来合并前的效果，而且在没有网络IO事件的时候，可以及时处理我们想处理的一些业务逻辑，并且减少了不必要的线程上下文切换时间。\n我们再更进一步，甚至我们可以在这个while循环增加其它的一些任务的处理，比如程序的逻辑任务队列、定时器事件等等，伪码如下：\nwhile(退出标志) { //定时器事件处理 //IO复用技术检测socket可读事件、出错事件 //（如果有数据要发送，则也检测可写事件） //如果有可读事件，对于侦听socket则接收新连接； //对于普通socket则收取该socket上的数据，收取的数据存入对应的接收缓冲区，如果出错则关闭连接； //如果有数据要发送，有可写事件，则发送数据 //如果有出错事件，关闭该连接 //从接收缓冲区中取出数据解包，分解成不同的业务来处理 //程序自定义任务1 //程序自定义任务2 } 注意：之所以将定时器事件的处理放在网络IO事件的检测之前，是因为避免定时器事件过期时间太长。假如放在后面的话，可能前面的处理耗费了一点时间，等到处理定时器事件时，时间间隔已经过去了不少时间。虽然这样处理，也没法保证定时器事件百分百精确，但是能尽量保证。当然linux系统下提供eventfd这样的定时器对象，所有的定时器对象就能像处理socket这样的fd一样统一成处理。这也是网络库libevent的思想很像，libevent将socket、定时器、信号封装成统一的对象进行处理。\n说了这么多理论性的东西，我们来一款流行的开源网络库muduo来说明吧（作者：陈硕），原库是基于boost的，我改成了C++11的版本，并修改了一些bug，在此感谢原作者陈硕。\n上文介绍的核心线程函数的while循环位于eventloop.cpp中：\nvoid EventLoop::loop() { assert(!looping_); assertInLoopThread(); looping_ = true; quit_ = false; LOG_TRACE \u0026lt;\u0026lt; \u0026quot;EventLoop \u0026quot; \u0026lt;\u0026lt; this \u0026lt;\u0026lt; \u0026quot; start looping\u0026quot;; while (!quit_) { activeChannels_.clear(); pollReturnTime_ = poller_-\u0026gt;poll(kPollTimeMs, \u0026amp;activeChannels_); ++iteration_; if (Logger::logLevel() \u0026lt;= Logger::TRACE) { printActiveChannels(); } // TODO sort channel by priority eventHandling_ = true; for (ChannelList::iterator it = activeChannels_.begin(); it != activeChannels_.end(); ++it) { currentActiveChannel_ = *it; currentActiveChannel_-\u0026gt;handleEvent(pollReturnTime_); } currentActiveChannel_ = NULL; eventHandling_ = false; doPendingFunctors(); if (frameFunctor_) { frameFunctor_(); }\t} LOG_TRACE \u0026lt;\u0026lt; \u0026quot;EventLoop \u0026quot; \u0026lt;\u0026lt; this \u0026lt;\u0026lt; \u0026quot; stop looping\u0026quot;; looping_ = false; } poller_-\u0026gt;poll利用epoll分离网络事件，然后接着处理分离出来的网络事件，每一个客户端socket对应一个连接，即一个TcpConnection和Channel通道对象。currentActiveChannel_-\u0026gt;handleEvent(pollReturnTime_)根据是可读、可写、出错事件来调用对应的处理函数，这些函数都是回调函数，程序初始化阶段设置进来的：\nvoid Channel::handleEvent(Timestamp receiveTime) { std::shared_ptr\u0026lt;void\u0026gt; guard; if (tied_) { guard = tie_.lock(); if (guard) { handleEventWithGuard(receiveTime); } } else { handleEventWithGuard(receiveTime); } } void Channel::handleEventWithGuard(Timestamp receiveTime) { eventHandling_ = true; LOG_TRACE \u0026lt;\u0026lt; reventsToString(); if ((revents_ \u0026amp; POLLHUP) \u0026amp;\u0026amp; !(revents_ \u0026amp; POLLIN)) { if (logHup_) { LOG_WARN \u0026lt;\u0026lt; \u0026quot;Channel::handle_event() POLLHUP\u0026quot;; } if (closeCallback_) closeCallback_(); } if (revents_ \u0026amp; POLLNVAL) { LOG_WARN \u0026lt;\u0026lt; \u0026quot;Channel::handle_event() POLLNVAL\u0026quot;; } if (revents_ \u0026amp; (POLLERR | POLLNVAL)) { if (errorCallback_) errorCallback_(); } if (revents_ \u0026amp; (POLLIN | POLLPRI | POLLRDHUP)) { //当是侦听socket时，readCallback_指向Acceptor::handleRead //当是客户端socket时，调用TcpConnection::handleRead if (readCallback_) readCallback_(receiveTime); } if (revents_ \u0026amp; POLLOUT) { //如果是连接状态服的socket，则writeCallback_指向Connector::handleWrite() if (writeCallback_) writeCallback_(); } eventHandling_ = false; } 当然，这里利用了Channel对象的“多态性”，如果是普通socket，可读事件就会调用预先设置的回调函数；但是如果是侦听socket，则调用Aceptor对象的handleRead() 来接收新连接：\nvoid Acceptor::handleRead() { loop_-\u0026gt;assertInLoopThread(); InetAddress peerAddr; //FIXME loop until no more int connfd = acceptSocket_.accept(\u0026amp;peerAddr); if (connfd \u0026gt;= 0) { // string hostport = peerAddr.toIpPort(); // LOG_TRACE \u0026lt;\u0026lt; \u0026#34;Accepts of \u0026#34; \u0026lt;\u0026lt; hostport; //newConnectionCallback_实际指向TcpServer::newConnection(int sockfd, const InetAddress\u0026amp; peerAddr) if (newConnectionCallback_) { newConnectionCallback_(connfd, peerAddr); } else { sockets::close(connfd); } } else { LOG_SYSERR \u0026lt;\u0026lt; \u0026#34;in Acceptor::handleRead\u0026#34;; // Read the section named \u0026#34;The special problem of // accept()ing when you can\u0026#39;t\u0026#34; in libev\u0026#39;s doc. // By Marc Lehmann, author of livev. if (errno == EMFILE) { ::close(idleFd_); idleFd_ = ::accept(acceptSocket_.fd(), NULL, NULL); ::close(idleFd_); idleFd_ = ::open(\u0026#34;/dev/null\u0026#34;, O_RDONLY | O_CLOEXEC); } } } 主循环里面的业务逻辑处理对应：\ndoPendingFunctors(); if (frameFunctor_) { frameFunctor_(); } void EventLoop::doPendingFunctors() { std::vector\u0026lt;Functor\u0026gt; functors; callingPendingFunctors_ = true; { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex_); functors.swap(pendingFunctors_); } for (size_t i = 0; i \u0026lt; functors.size(); ++i) { functors[i](); } callingPendingFunctors_ = false; } 这里增加业务逻辑是增加执行任务的函数指针的，增加的任务保存在成员变量pendingFunctors_中，这个变量是一个函数指针数组（vector对象），执行的时候，调用每个函数就可以了。上面的代码先利用一个栈变量将成员变量pendingFunctors_里面的函数指针换过来，接下来对这个栈变量进行操作就可以了，这样减少了锁的粒度。因为成员变量pendingFunctors_在增加任务的时候，也会被用到，设计到多个线程操作，所以要加锁，增加任务的地方是：\nvoid EventLoop::queueInLoop(const Functor\u0026amp; cb) { { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex_); pendingFunctors_.push_back(cb); } if (!isInLoopThread() || callingPendingFunctors_) { wakeup(); } } 而frameFunctor_就更简单了，就是通过设置一个函数指针就可以了。当然这里有个技巧性的东西，即增加任务的时候，为了能够立即执行，使用唤醒机制，通过往一个fd里面写入简单的几个字节，来唤醒epoll，使其立刻返回，因为此时没有其它的socke有事件，这样接下来就执行刚才添加的任务了。\n我们看一下数据收取的逻辑：\nvoid TcpConnection::handleRead(Timestamp receiveTime) { loop_-\u0026gt;assertInLoopThread(); int savedErrno = 0; ssize_t n = inputBuffer_.readFd(channel_-\u0026gt;fd(), \u0026amp;savedErrno); if (n \u0026gt; 0) { messageCallback_(shared_from_this(), \u0026amp;inputBuffer_, receiveTime); } else if (n == 0) { handleClose(); } else { errno = savedErrno; LOG_SYSERR \u0026lt;\u0026lt; \u0026#34;TcpConnection::handleRead\u0026#34;; handleError(); } } 将收到的数据放到接收缓冲区里面，将来我们来解包：\nvoid ClientSession::OnRead(const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn, Buffer* pBuffer, Timestamp receivTime) { while (true) { //不够一个包头大小 if (pBuffer-\u0026gt;readableBytes() \u0026lt; (size_t)sizeof(msg)) { LOG_INFO \u0026lt;\u0026lt; \u0026#34;buffer is not enough for a package header, pBuffer-\u0026gt;readableBytes()=\u0026#34; \u0026lt;\u0026lt; pBuffer-\u0026gt;readableBytes() \u0026lt;\u0026lt; \u0026#34;, sizeof(msg)=\u0026#34; \u0026lt;\u0026lt; sizeof(msg); return; } //不够一个整包大小 msg header; memcpy(\u0026amp;header, pBuffer-\u0026gt;peek(), sizeof(msg)); if (pBuffer-\u0026gt;readableBytes() \u0026lt; (size_t)header.packagesize + sizeof(msg)) return; pBuffer-\u0026gt;retrieve(sizeof(msg)); std::string inbuf; inbuf.append(pBuffer-\u0026gt;peek(), header.packagesize); pBuffer-\u0026gt;retrieve(header.packagesize); if (!Process(conn, inbuf.c_str(), inbuf.length())) { LOG_WARN \u0026lt;\u0026lt; \u0026#34;Process error, close TcpConnection\u0026#34;; conn-\u0026gt;forceClose(); } }// end while-loop } 先判断接收缓冲区里面的数据是否够一个包头大小，如果够再判断够不够包头指定的包体大小，如果还是够的话，接着在Process函数里面处理该包。\n再看看发送数据的逻辑：\nvoid TcpConnection::sendInLoop(const void* data, size_t len) { loop_-\u0026gt;assertInLoopThread(); ssize_t nwrote = 0; size_t remaining = len; bool faultError = false; if (state_ == kDisconnected) { LOG_WARN \u0026lt;\u0026lt; \u0026#34;disconnected, give up writing\u0026#34;; return; } // if no thing in output queue, try writing directly if (!channel_-\u0026gt;isWriting() \u0026amp;\u0026amp; outputBuffer_.readableBytes() == 0) { nwrote = sockets::write(channel_-\u0026gt;fd(), data, len); if (nwrote \u0026gt;= 0) { remaining = len - nwrote; if (remaining == 0 \u0026amp;\u0026amp; writeCompleteCallback_) { loop_-\u0026gt;queueInLoop(std::bind(writeCompleteCallback_, shared_from_this())); } } else // nwrote \u0026lt; 0 { nwrote = 0; if (errno != EWOULDBLOCK) { LOG_SYSERR \u0026lt;\u0026lt; \u0026#34;TcpConnection::sendInLoop\u0026#34;; if (errno == EPIPE || errno == ECONNRESET) // FIXME: any others? { faultError = true; } } } } assert(remaining \u0026lt;= len); if (!faultError \u0026amp;\u0026amp; remaining \u0026gt; 0) { size_t oldLen = outputBuffer_.readableBytes(); if (oldLen + remaining \u0026gt;= highWaterMark_ \u0026amp;\u0026amp; oldLen \u0026lt; highWaterMark_ \u0026amp;\u0026amp; highWaterMarkCallback_) { loop_-\u0026gt;queueInLoop(std::bind(highWaterMarkCallback_, shared_from_this(), oldLen + remaining)); } outputBuffer_.append(static_cast\u0026lt;const char*\u0026gt;(data)+nwrote, remaining); if (!channel_-\u0026gt;isWriting()) { channel_-\u0026gt;enableWriting(); } } } 如果剩余的数据remaining大于则调用channel_-\u0026gt;enableWriting();开始监听可写事件，可写事件处理如下：\nvoid TcpConnection::handleWrite() { loop_-\u0026gt;assertInLoopThread(); if (channel_-\u0026gt;isWriting()) { ssize_t n = sockets::write(channel_-\u0026gt;fd(), outputBuffer_.peek(), outputBuffer_.readableBytes()); if (n \u0026gt; 0) { outputBuffer_.retrieve(n); if (outputBuffer_.readableBytes() == 0) { channel_-\u0026gt;disableWriting(); if (writeCompleteCallback_) { loop_-\u0026gt;queueInLoop(std::bind(writeCompleteCallback_, shared_from_this())); } if (state_ == kDisconnecting) { shutdownInLoop(); } } } else { LOG_SYSERR \u0026lt;\u0026lt; \u0026#34;TcpConnection::handleWrite\u0026#34;; // if (state_ == kDisconnecting) // { // shutdownInLoop(); // } } } else { LOG_TRACE \u0026lt;\u0026lt; \u0026#34;Connection fd = \u0026#34; \u0026lt;\u0026lt; channel_-\u0026gt;fd() \u0026lt;\u0026lt; \u0026#34; is down, no more writing\u0026#34;; } } 如果发送完数据以后调用channel_-\u0026gt;disableWriting();移除监听可写事件。\n很多读者可能一直想问，文中不是说解包数据并处理逻辑是业务代码而非网络通信的代码，你这里貌似都混在一起了，其实没有，这里实际的业务代码处理都是框架曾提供的回调函数里面处理的，具体怎么处理，由框架使用者——业务层自己定义。\n总结起来，实际上就是一个线程函数里一个loop那么点事情，不信你再看我曾经工作上的一个交易系统服务器项目代码：\nvoid CEventDispatcher::Run() { m_bShouldRun = true; while(m_bShouldRun) { DispatchIOs(); SyncTime(); CheckTimer(); DispatchEvents(); } } void CEpollReactor::DispatchIOs() { DWORD dwSelectTimeOut = SR_DEFAULT_EPOLL_TIMEOUT; if (HandleOtherTask()) { dwSelectTimeOut = 0; } struct epoll_event ev; CEventHandlerIdMap::iterator itor = m_mapEventHandlerId.begin(); for(; itor!=m_mapEventHandlerId.end(); itor++) { CEventHandler *pEventHandler = (CEventHandler *)(*itor).first; if(pEventHandler == NULL){ continue; } ev.data.ptr = pEventHandler; ev.events = 0; int nReadID, nWriteID; pEventHandler-\u0026gt;GetIds(\u0026amp;nReadID, \u0026amp;nWriteID); if (nReadID \u0026gt; 0) { ev.events |= EPOLLIN; } if (nWriteID \u0026gt; 0) { ev.events |= EPOLLOUT; } epoll_ctl(m_fdEpoll, EPOLL_CTL_MOD, (*itor).second, \u0026amp;ev); } struct epoll_event events[EPOLL_MAX_EVENTS]; int nfds = epoll_wait(m_fdEpoll, events, EPOLL_MAX_EVENTS, dwSelectTimeOut/1000); for (int i=0; i\u0026lt;nfds; i++) { struct epoll_event \u0026amp;evref = events[i]; CEventHandler *pEventHandler = (CEventHandler *)evref.data.ptr; if ((evref.events|EPOLLIN)!=0 \u0026amp;\u0026amp; m_mapEventHandlerId.find(pEventHandler)!=m_mapEventHandlerId.end()) { pEventHandler-\u0026gt;HandleInput(); } if ((evref.events|EPOLLOUT)!=0 \u0026amp;\u0026amp; m_mapEventHandlerId.find(pEventHandler)!=m_mapEventHandlerId.end()) { pEventHandler-\u0026gt;HandleOutput(); } } } void CEventDispatcher::DispatchEvents() { CEvent event; CSyncEvent *pSyncEvent; while(m_queueEvent.PeekEvent(event)) { int nRetval; if(event.pEventHandler != NULL) { nRetval = event.pEventHandler-\u0026gt;HandleEvent(event.nEventID, event.dwParam, event.pParam); } else { nRetval = HandleEvent(event.nEventID, event.dwParam, event.pParam); } if(event.pAdd != NULL) //同步消息 { pSyncEvent=(CSyncEvent *)event.pAdd; pSyncEvent-\u0026gt;nRetval = nRetval; pSyncEvent-\u0026gt;sem.UnLock(); } } } 再看看蘑菇街开源的TeamTalk的源码（代码下载地址：https://github.com/baloonwj/TeamTalk）：\nvoid CEventDispatch::StartDispatch(uint32_t wait_timeout) { fd_set read_set, write_set, excep_set; timeval timeout; timeout.tv_sec = 0; timeout.tv_usec = wait_timeout * 1000; // 10 millisecond if(running) return; running = true; while (running) { _CheckTimer(); _CheckLoop(); if (!m_read_set.fd_count \u0026amp;\u0026amp; !m_write_set.fd_count \u0026amp;\u0026amp; !m_excep_set.fd_count) { Sleep(MIN_TIMER_DURATION); continue; } m_lock.lock(); memcpy(\u0026amp;read_set, \u0026amp;m_read_set, sizeof(fd_set)); memcpy(\u0026amp;write_set, \u0026amp;m_write_set, sizeof(fd_set)); memcpy(\u0026amp;excep_set, \u0026amp;m_excep_set, sizeof(fd_set)); m_lock.unlock(); int nfds = select(0, \u0026amp;read_set, \u0026amp;write_set, \u0026amp;excep_set, \u0026amp;timeout); if (nfds == SOCKET_ERROR) { log(\u0026quot;select failed, error code: %d\u0026quot;, GetLastError()); Sleep(MIN_TIMER_DURATION); continue; // select again } if (nfds == 0) { continue; } for (u_int i = 0; i \u0026lt; read_set.fd_count; i++) { //log(\u0026quot;select return read count=%d\\n\u0026quot;, read_set.fd_count); SOCKET fd = read_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnRead(); pSocket-\u0026gt;ReleaseRef(); } } for (u_int i = 0; i \u0026lt; write_set.fd_count; i++) { //log(\u0026quot;select return write count=%d\\n\u0026quot;, write_set.fd_count); SOCKET fd = write_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnWrite(); pSocket-\u0026gt;ReleaseRef(); } } for (u_int i = 0; i \u0026lt; excep_set.fd_count; i++) { //log(\u0026quot;select return exception count=%d\\n\u0026quot;, excep_set.fd_count); SOCKET fd = excep_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnClose(); pSocket-\u0026gt;ReleaseRef(); } } } } 再看filezilla，一款ftp工具的服务器端，它采用的是Windows的WSAAsyncSelect模型（代码下载地址：https://github.com/baloonwj/filezilla）：\n//Processes event notifications sent by the sockets or the layers static LRESULT CALLBACK WindowProc(HWND hWnd, UINT message, WPARAM wParam, LPARAM lParam) { if (message\u0026gt;=WM_SOCKETEX_NOTIFY) { //Verify parameters ASSERT(hWnd); CAsyncSocketExHelperWindow *pWnd=(CAsyncSocketExHelperWindow *)GetWindowLongPtr(hWnd, GWLP_USERDATA); ASSERT(pWnd); if (!pWnd) return 0; if (message \u0026lt; static_cast\u0026lt;UINT\u0026gt;(WM_SOCKETEX_NOTIFY+pWnd-\u0026gt;m_nWindowDataSize)) //Index is within socket storage { //Lookup socket and verify if it's valid CAsyncSocketEx *pSocket=pWnd-\u0026gt;m_pAsyncSocketExWindowData[message - WM_SOCKETEX_NOTIFY].m_pSocket; SOCKET hSocket = wParam; if (!pSocket) return 0; if (hSocket == INVALID_SOCKET) return 0; if (pSocket-\u0026gt;m_SocketData.hSocket != hSocket) return 0; int nEvent = lParam \u0026amp; 0xFFFF; int nErrorCode = lParam \u0026gt;\u0026gt; 16; //Dispatch notification if (!pSocket-\u0026gt;m_pFirstLayer) { //Dispatch to CAsyncSocketEx instance switch (nEvent) { case FD_READ: #ifndef NOSOCKETSTATES if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) { pSocket-\u0026gt;m_nPendingEvents |= FD_READ; break; } else if (pSocket-\u0026gt;GetState() == attached) pSocket-\u0026gt;SetState(connected); if (pSocket-\u0026gt;GetState() != connected) break; // Ignore further FD_READ events after FD_CLOSE has been received if (pSocket-\u0026gt;m_SocketData.onCloseCalled) break; #endif //NOSOCKETSTATES #ifndef NOSOCKETSTATES if (nErrorCode) pSocket-\u0026gt;SetState(aborted); #endif //NOSOCKETSTATES if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ) { pSocket-\u0026gt;OnReceive(nErrorCode); } break; case FD_FORCEREAD: //Forceread does not check if there's data waiting #ifndef NOSOCKETSTATES if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) { pSocket-\u0026gt;m_nPendingEvents |= FD_FORCEREAD; break; } else if (pSocket-\u0026gt;GetState() == attached) pSocket-\u0026gt;SetState(connected); if (pSocket-\u0026gt;GetState() != connected) break; #endif //NOSOCKETSTATES if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ) { #ifndef NOSOCKETSTATES if (nErrorCode) pSocket-\u0026gt;SetState(aborted); #endif //NOSOCKETSTATES pSocket-\u0026gt;OnReceive(nErrorCode); } break; case FD_WRITE: #ifndef NOSOCKETSTATES if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) { pSocket-\u0026gt;m_nPendingEvents |= FD_WRITE; break; } else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) pSocket-\u0026gt;SetState(connected); if (pSocket-\u0026gt;GetState() != connected) break; #endif //NOSOCKETSTATES if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_WRITE) { #ifndef NOSOCKETSTATES if (nErrorCode) pSocket-\u0026gt;SetState(aborted); #endif //NOSOCKETSTATES pSocket-\u0026gt;OnSend(nErrorCode); } break; case FD_CONNECT: #ifndef NOSOCKETSTATES if (pSocket-\u0026gt;GetState() == connecting) { if (nErrorCode \u0026amp;\u0026amp; pSocket-\u0026gt;m_SocketData.nextAddr) { if (pSocket-\u0026gt;TryNextProtocol()) break; } pSocket-\u0026gt;SetState(connected); } else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) pSocket-\u0026gt;SetState(connected); #endif //NOSOCKETSTATES if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_CONNECT) pSocket-\u0026gt;OnConnect(nErrorCode); #ifndef NOSOCKETSTATES if (!nErrorCode) { if ((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_READ) \u0026amp;\u0026amp; pSocket-\u0026gt;GetState() == connected) pSocket-\u0026gt;OnReceive(0); if ((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_FORCEREAD) \u0026amp;\u0026amp; pSocket-\u0026gt;GetState() == connected) pSocket-\u0026gt;OnReceive(0); if ((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_WRITE) \u0026amp;\u0026amp; pSocket-\u0026gt;GetState() == connected) pSocket-\u0026gt;OnSend(0); } pSocket-\u0026gt;m_nPendingEvents = 0; #endif break; case FD_ACCEPT: #ifndef NOSOCKETSTATES if (pSocket-\u0026gt;GetState() != listening \u0026amp;\u0026amp; pSocket-\u0026gt;GetState() != attached) break; #endif //NOSOCKETSTATES if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_ACCEPT) pSocket-\u0026gt;OnAccept(nErrorCode); break; case FD_CLOSE: #ifndef NOSOCKETSTATES if (pSocket-\u0026gt;GetState() != connected \u0026amp;\u0026amp; pSocket-\u0026gt;GetState() != attached) break; // If there are still bytes left to read, call OnReceive instead of // OnClose and trigger a new OnClose DWORD nBytes = 0; if (!nErrorCode \u0026amp;\u0026amp; pSocket-\u0026gt;IOCtl(FIONREAD, \u0026amp;nBytes)) { if (nBytes \u0026gt; 0) { // Just repeat message. pSocket-\u0026gt;ResendCloseNotify(); pSocket-\u0026gt;m_SocketData.onCloseCalled = true; pSocket-\u0026gt;OnReceive(WSAESHUTDOWN); break; } } pSocket-\u0026gt;SetState(nErrorCode ? aborted : closed); #endif //NOSOCKETSTATES pSocket-\u0026gt;OnClose(nErrorCode); break; } } else //Dispatch notification to the lowest layer { if (nEvent == FD_READ) { // Ignore further FD_READ events after FD_CLOSE has been received if (pSocket-\u0026gt;m_SocketData.onCloseCalled) return 0; DWORD nBytes; if (!pSocket-\u0026gt;IOCtl(FIONREAD, \u0026amp;nBytes)) nErrorCode = WSAGetLastError(); if (pSocket-\u0026gt;m_pLastLayer) pSocket-\u0026gt;m_pLastLayer-\u0026gt;CallEvent(nEvent, nErrorCode); } else if (nEvent == FD_CLOSE) { // If there are still bytes left to read, call OnReceive instead of // OnClose and trigger a new OnClose DWORD nBytes = 0; if (!nErrorCode \u0026amp;\u0026amp; pSocket-\u0026gt;IOCtl(FIONREAD, \u0026amp;nBytes)) { if (nBytes \u0026gt; 0) { // Just repeat message. pSocket-\u0026gt;ResendCloseNotify(); if (pSocket-\u0026gt;m_pLastLayer) pSocket-\u0026gt;m_pLastLayer-\u0026gt;CallEvent(FD_READ, 0); return 0; } } pSocket-\u0026gt;m_SocketData.onCloseCalled = true; if (pSocket-\u0026gt;m_pLastLayer) pSocket-\u0026gt;m_pLastLayer-\u0026gt;CallEvent(nEvent, nErrorCode); } else if (pSocket-\u0026gt;m_pLastLayer) pSocket-\u0026gt;m_pLastLayer-\u0026gt;CallEvent(nEvent, nErrorCode); } } return 0; } else if (message == WM_USER) //Notification event sent by a layer { //Verify parameters, lookup socket and notification message //Verify parameters ASSERT(hWnd); CAsyncSocketExHelperWindow *pWnd=(CAsyncSocketExHelperWindow *)GetWindowLongPtr(hWnd, GWLP_USERDATA); ASSERT(pWnd); if (!pWnd) return 0; if (wParam \u0026gt;= static_cast\u0026lt;UINT\u0026gt;(pWnd-\u0026gt;m_nWindowDataSize)) //Index is within socket storage { return 0; } CAsyncSocketEx *pSocket = pWnd-\u0026gt;m_pAsyncSocketExWindowData[wParam].m_pSocket; CAsyncSocketExLayer::t_LayerNotifyMsg *pMsg = (CAsyncSocketExLayer::t_LayerNotifyMsg *)lParam; if (!pMsg || !pSocket || pSocket-\u0026gt;m_SocketData.hSocket != pMsg-\u0026gt;hSocket) { delete pMsg; return 0; } int nEvent=pMsg-\u0026gt;lEvent\u0026amp;0xFFFF; int nErrorCode=pMsg-\u0026gt;lEvent\u0026gt;\u0026gt;16; //Dispatch to layer if (pMsg-\u0026gt;pLayer) pMsg-\u0026gt;pLayer-\u0026gt;CallEvent(nEvent, nErrorCode); else { //Dispatch to CAsyncSocketEx instance switch (nEvent) { case FD_READ: #ifndef NOSOCKETSTATES if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) { pSocket-\u0026gt;m_nPendingEvents |= FD_READ; break; } else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) pSocket-\u0026gt;SetState(connected); if (pSocket-\u0026gt;GetState() != connected) break; #endif //NOSOCKETSTATES if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ) { #ifndef NOSOCKETSTATES if (nErrorCode) pSocket-\u0026gt;SetState(aborted); #endif //NOSOCKETSTATES pSocket-\u0026gt;OnReceive(nErrorCode); } break; case FD_FORCEREAD: //Forceread does not check if there's data waiting #ifndef NOSOCKETSTATES if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) { pSocket-\u0026gt;m_nPendingEvents |= FD_FORCEREAD; break; } else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) pSocket-\u0026gt;SetState(connected); if (pSocket-\u0026gt;GetState() != connected) break; #endif //NOSOCKETSTATES if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ) { #ifndef NOSOCKETSTATES if (nErrorCode) pSocket-\u0026gt;SetState(aborted); #endif //NOSOCKETSTATES pSocket-\u0026gt;OnReceive(nErrorCode); } break; case FD_WRITE: #ifndef NOSOCKETSTATES if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) { pSocket-\u0026gt;m_nPendingEvents |= FD_WRITE; break; } else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) pSocket-\u0026gt;SetState(connected); if (pSocket-\u0026gt;GetState() != connected) break; #endif //NOSOCKETSTATES if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_WRITE) { #ifndef NOSOCKETSTATES if (nErrorCode) pSocket-\u0026gt;SetState(aborted); #endif //NOSOCKETSTATES pSocket-\u0026gt;OnSend(nErrorCode); } break; case FD_CONNECT: #ifndef NOSOCKETSTATES if (pSocket-\u0026gt;GetState() == connecting) pSocket-\u0026gt;SetState(connected); else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) pSocket-\u0026gt;SetState(connected); #endif //NOSOCKETSTATES if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_CONNECT) pSocket-\u0026gt;OnConnect(nErrorCode); #ifndef NOSOCKETSTATES if (!nErrorCode) { if (((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_READ) \u0026amp;\u0026amp; pSocket-\u0026gt;GetState() == connected) \u0026amp;\u0026amp; (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ)) pSocket-\u0026gt;OnReceive(0); if (((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_FORCEREAD) \u0026amp;\u0026amp; pSocket-\u0026gt;GetState() == connected) \u0026amp;\u0026amp; (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ)) pSocket-\u0026gt;OnReceive(0); if (((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_WRITE) \u0026amp;\u0026amp; pSocket-\u0026gt;GetState() == connected) \u0026amp;\u0026amp; (pSocket-\u0026gt;m_lEvent \u0026amp; FD_WRITE)) pSocket-\u0026gt;OnSend(0); } pSocket-\u0026gt;m_nPendingEvents = 0; #endif //NOSOCKETSTATES break; case FD_ACCEPT: #ifndef NOSOCKETSTATES if ((pSocket-\u0026gt;GetState() == listening || pSocket-\u0026gt;GetState() == attached) \u0026amp;\u0026amp; (pSocket-\u0026gt;m_lEvent \u0026amp; FD_ACCEPT)) #endif //NOSOCKETSTATES { pSocket-\u0026gt;OnAccept(nErrorCode); } break; case FD_CLOSE: #ifndef NOSOCKETSTATES if ((pSocket-\u0026gt;GetState() == connected || pSocket-\u0026gt;GetState() == attached) \u0026amp;\u0026amp; (pSocket-\u0026gt;m_lEvent \u0026amp; FD_CLOSE)) { pSocket-\u0026gt;SetState(nErrorCode?aborted:closed); #else { #endif //NOSOCKETSTATES pSocket-\u0026gt;OnClose(nErrorCode); } break; } } delete pMsg; return 0; } else if (message == WM_USER+1) { // WSAAsyncGetHostByName reply // Verify parameters ASSERT(hWnd); CAsyncSocketExHelperWindow *pWnd = (CAsyncSocketExHelperWindow *)GetWindowLongPtr(hWnd, GWLP_USERDATA); ASSERT(pWnd); if (!pWnd) return 0; CAsyncSocketEx *pSocket = NULL; for (int i = 0; i \u0026lt; pWnd-\u0026gt;m_nWindowDataSize; ++i) { pSocket = pWnd-\u0026gt;m_pAsyncSocketExWindowData[i].m_pSocket; if (pSocket \u0026amp;\u0026amp; pSocket-\u0026gt;m_hAsyncGetHostByNameHandle \u0026amp;\u0026amp; pSocket-\u0026gt;m_hAsyncGetHostByNameHandle == (HANDLE)wParam \u0026amp;\u0026amp; pSocket-\u0026gt;m_pAsyncGetHostByNameBuffer) break; } if (!pSocket || !pSocket-\u0026gt;m_pAsyncGetHostByNameBuffer) return 0; int nErrorCode = lParam \u0026gt;\u0026gt; 16; if (nErrorCode) { pSocket-\u0026gt;OnConnect(nErrorCode); return 0; } SOCKADDR_IN sockAddr{}; sockAddr.sin_family = AF_INET; sockAddr.sin_addr.s_addr = ((LPIN_ADDR)((LPHOSTENT)pSocket-\u0026gt;m_pAsyncGetHostByNameBuffer)-\u0026gt;h_addr)-\u0026gt;s_addr; sockAddr.sin_port = htons(pSocket-\u0026gt;m_nAsyncGetHostByNamePort); BOOL res = pSocket-\u0026gt;Connect((SOCKADDR*)\u0026amp;sockAddr, sizeof(sockAddr)); delete [] pSocket-\u0026gt;m_pAsyncGetHostByNameBuffer; pSocket-\u0026gt;m_pAsyncGetHostByNameBuffer = 0; pSocket-\u0026gt;m_hAsyncGetHostByNameHandle = 0; if (!res) if (GetLastError() != WSAEWOULDBLOCK) pSocket-\u0026gt;OnConnect(GetLastError()); return 0; } else if (message == WM_USER + 2) { //Verify parameters, lookup socket and notification message //Verify parameters if (!hWnd) return 0; CAsyncSocketExHelperWindow *pWnd=(CAsyncSocketExHelperWindow *)GetWindowLongPtr(hWnd, GWLP_USERDATA); if (!pWnd) return 0; if (wParam \u0026gt;= static_cast\u0026lt;UINT\u0026gt;(pWnd-\u0026gt;m_nWindowDataSize)) //Index is within socket storage return 0; CAsyncSocketEx *pSocket = pWnd-\u0026gt;m_pAsyncSocketExWindowData[wParam].m_pSocket; if (!pSocket) return 0; // Process pending callbacks std::list\u0026lt;t_callbackMsg\u0026gt; tmp; tmp.swap(pSocket-\u0026gt;m_pendingCallbacks); pSocket-\u0026gt;OnLayerCallback(tmp); for (auto \u0026amp; cb : tmp) { delete [] cb.str; } } else if (message == WM_TIMER) { if (wParam != 1) return 0; ASSERT(hWnd); CAsyncSocketExHelperWindow *pWnd=(CAsyncSocketExHelperWindow *)GetWindowLongPtr(hWnd, GWLP_USERDATA); ASSERT(pWnd \u0026amp;\u0026amp; pWnd-\u0026gt;m_pThreadData); if (!pWnd || !pWnd-\u0026gt;m_pThreadData) return 0; if (pWnd-\u0026gt;m_pThreadData-\u0026gt;layerCloseNotify.empty()) { KillTimer(hWnd, 1); return 0; } CAsyncSocketEx* socket = pWnd-\u0026gt;m_pThreadData-\u0026gt;layerCloseNotify.front(); pWnd-\u0026gt;m_pThreadData-\u0026gt;layerCloseNotify.pop_front(); if (pWnd-\u0026gt;m_pThreadData-\u0026gt;layerCloseNotify.empty()) KillTimer(hWnd, 1); if (socket) PostMessage(hWnd, socket-\u0026gt;m_SocketData.nSocketIndex + WM_SOCKETEX_NOTIFY, socket-\u0026gt;m_SocketData.hSocket, FD_CLOSE); return 0; } return DefWindowProc(hWnd, message, wParam, lParam); }\t上面截取的代码段，如果你对这些项目不是很熟悉的话，估计你也没有任何兴趣去细细看每一行代码逻辑。但是你一定要明白我所说的这个结构的逻辑，基本上目前主流的网络框架都是这套原理。比如filezilla的网络通信层同样也被用在大名鼎鼎的电驴（easyMule）中。\n关于单个服务程序的框架，我已经介绍完了，如果你能完全理解我要表达的意思，我相信你也能构建出一套高性能服务程序来。\n另外，服务器框架也可以在上面的设计思路的基础上增加很多有意思的细节，比如流量控制。举另外 一个我实际做过的项目中的例子吧：\n一般实际项目中，当客户端连接数目比较多的时候，服务器在处理网络数据的时候，如果同时有多个socket上有数据要处理，由于cpu核数有限，根据上面先检测iO事件再处理IO事件可能会出现工作线程一直处理前几个socket的事件，直到前几个socket处理完毕后再处理后面几个socket的数据。这就相当于，你去饭店吃饭，大家都点了菜，但是有些桌子上一直在上菜，而有些桌子上一直没有菜。这样肯定不好，我们来看下如何避免这种现象：\nint CFtdEngine::HandlePackage(CFTDCPackage *pFTDCPackage, CFTDCSession *pSession) { //NET_IO_LOG0(\u0026quot;CFtdEngine::HandlePackage\\n\u0026quot;); FTDC_PACKAGE_DEBUG(pFTDCPackage); if (pFTDCPackage-\u0026gt;GetTID() != FTD_TID_ReqUserLogin) { if (!IsSessionLogin(pSession-\u0026gt;GetSessionID())) { SendErrorRsp(pFTDCPackage, pSession, 1, \u0026quot;客户未登录\u0026quot;); return 0; } } CalcFlux(pSession, pFTDCPackage-\u0026gt;Length());\t//统计流量 REPORT_EVENT(LOG_DEBUG, \u0026quot;Front/Fgateway\u0026quot;, \u0026quot;登录请求%0x\u0026quot;, pFTDCPackage-\u0026gt;GetTID()); int nRet = 0; switch(pFTDCPackage-\u0026gt;GetTID()) { case FTD_TID_ReqUserLogin: ///huwp：20070608：检查过高版本的API将被禁止登录 if (pFTDCPackage-\u0026gt;GetVersion()\u0026gt;FTD_VERSION) { SendErrorRsp(pFTDCPackage, pSession, 1, \u0026quot;Too High FTD Version\u0026quot;); return 0; } nRet = OnReqUserLogin(pFTDCPackage, (CFTDCSession *)pSession); FTDRequestIndex.incValue(); break; case FTD_TID_ReqCheckUserLogin: nRet = OnReqCheckUserLogin(pFTDCPackage, (CFTDCSession *)pSession); FTDRequestIndex.incValue(); break; case FTD_TID_ReqSubscribeTopic: nRet = OnReqSubscribeTopic(pFTDCPackage, (CFTDCSession *)pSession); FTDRequestIndex.incValue(); break;\t} return 0; } 当有某个socket上有数据可读时，接着接收该socket上的数据，对接收到的数据进行解包，然后调用CalcFlux(pSession, pFTDCPackage-\u0026gt;Length())进行流量统计：\nvoid CFrontEngine::CalcFlux(CSession *pSession, const int nFlux) { TFrontSessionInfo *pSessionInfo = m_mapSessionInfo.Find(pSession-\u0026gt;GetSessionID()); if (pSessionInfo != NULL) { //流量控制改为计数 pSessionInfo-\u0026gt;nCommFlux ++; ///若流量超过规定，则挂起该会话的读操作 if (pSessionInfo-\u0026gt;nCommFlux \u0026gt;= pSessionInfo-\u0026gt;nMaxCommFlux) { pSession-\u0026gt;SuspendRead(true); } } } 该函数会先让某个连接会话（Session）处理的包数量递增，接着判断是否超过最大包数量，则设置读挂起标志：\nvoid CSession::SuspendRead(bool bSuspend) { m_bSuspendRead = bSuspend; } 这样下次将会从检测的socket列表中排除该socket：\nvoid CEpollReactor::RegisterIO(CEventHandler *pEventHandler) { int nReadID, nWriteID; pEventHandler-\u0026gt;GetIds(\u0026amp;nReadID, \u0026amp;nWriteID); if (nWriteID != 0 \u0026amp;\u0026amp; nReadID ==0) { nReadID = nWriteID; } if (nReadID != 0) { m_mapEventHandlerId[pEventHandler] = nReadID; struct epoll_event ev; ev.data.ptr = pEventHandler; if(epoll_ctl(m_fdEpoll, EPOLL_CTL_ADD, nReadID, \u0026amp;ev) != 0) { perror(\u0026#34;epoll_ctl EPOLL_CTL_ADD\u0026#34;); } } } void CSession::GetIds(int *pReadId, int *pWriteId) { m_pChannelProtocol-\u0026gt;GetIds(pReadId,pWriteId); if (m_bSuspendRead) { *pReadId = 0; } } 也就是说不再检测该socket上是否有数据可读。然后在定时器里1秒后重置该标志，这样这个socket上有数据的话又可以重新检测到了：\nconst int SESSION_CHECK_TIMER_ID = 9; const int SESSION_CHECK_INTERVAL = 1000; SetTimer(SESSION_CHECK_TIMER_ID, SESSION_CHECK_INTERVAL); void CFrontEngine::OnTimer(int nIDEvent) { if (nIDEvent == SESSION_CHECK_TIMER_ID) { CSessionMap::iterator itor = m_mapSession.Begin(); while (!itor.IsEnd()) { TFrontSessionInfo *pFind = m_mapSessionInfo.Find((*itor)-\u0026gt;GetSessionID()); if (pFind != NULL) { CheckSession(*itor, pFind); } itor++; } } } void CFrontEngine::CheckSession(CSession *pSession, TFrontSessionInfo *pSessionInfo) { ///重新开始计算流量 pSessionInfo-\u0026gt;nCommFlux -= pSessionInfo-\u0026gt;nMaxCommFlux; if (pSessionInfo-\u0026gt;nCommFlux \u0026lt; 0) { pSessionInfo-\u0026gt;nCommFlux = 0; } ///若流量超过规定，则挂起该会话的读操作 pSession-\u0026gt;SuspendRead(pSessionInfo-\u0026gt;nCommFlux \u0026gt;= pSessionInfo-\u0026gt;nMaxCommFlux); } 这就相当与饭店里面先给某一桌客人上一些菜，让他们先吃着，等上了一些菜之后不会再给这桌继续上菜了，而是给其它空桌上菜，大家都吃上后，继续回来给原先的桌子继续上菜。实际上我们的饭店都是这么做的。上面的例子是单服务流量控制的实现的一个非常好的思路，它保证了每个客户端都能均衡地得到服务，而不是一些客户端等很久才有响应。当然，这样的技术不能适用于有顺序要求的业务，例如销售系统，这些系统一般是先下单先得到的。\n另外现在的服务器为了加快ＩＯ操作，大量使用缓存技术，缓存实际上是以空间换取时间的策略。对于一些反复使用的，但是不经常改变的信息，如果从原始地点加载这些信息就比较耗时的数据（比如从磁盘中、从数据库中），我们就可以使用缓存。所以时下像redis、leveldb、fastdb等各种内存数据库大行其道。如果你要从事服务器开发，你至少需要掌握它们中的几种。\n鉴于笔者能力和经验有限，文中难免有错漏之处，欢迎提意见。\n","permalink":"https://haokiu.com/blog/10dc93cb0ce148d1906354635024bb25/","summary":"C++ 高性能服务器网络框架设计细节 这篇文章我们将介绍服务器的开发，并从多个方面探究如何开发一款高性能高并发的服务器程序。需要注意的是一般大型服务器，其复杂程度在于其业务，而不是在于其代码工程的基本框架。大型服务器一般有多个服务组成，可能会支持CDN，或者支持所谓的“分布式”等，这篇文章不会介绍这些东西，因为不管结构多么复杂的服务器，都是由单个服务器组成的。所以这篇文章的侧重点是讨论单个服务程序的结构，而且这里的结构指的也是单个服务器的网络通信层结构，如果你能真正地理解了我所说的，那么在这个基础的结构上面开展任何业务都是可以的，也可以将这种结构扩展成复杂的多个服务器组，例如“分布式”服务。文中的代码示例虽然是以C++为例，但同样适合Java（我本人也是Java开发者），原理都是一样的，只不过Java可能在基本的操作系统网络通信API的基础上用虚拟机包裹了一层接口而已（Java甚至可能基于一些常用的网络通信框架思想提供了一些现成的API，例如NIO）。有鉴于此，这篇文章不讨论那些大而空、泛泛而谈的技术术语，而是讲的是实实在在的能指导读者在实际工作中实践的编码方案或优化已有编码的方法。另外这里讨论的技术同时涉及windows和linux两个平台。\n所谓高性能就是服务器能流畅地处理各个客户端的连接并尽量低延迟地应答客户端的请求；所谓高并发，不仅指的是服务器可以同时支持多的客户端连接，而且这些客户端在连接期间内会不断与服务器有数据来往。网络上经常有各种网络库号称单个服务能同时支持百万甚至千万的并发，然后我实际去看了下，结果发现只是能同时支持很多的连接而已。如果一个服务器能单纯地接受ｎ个连接（ｎ可能很大），但是不能有条不紊地处理与这些连接之间的数据来往也没有任何意义，这种服务器框架只是“玩具型”的，对实际生产和应用没有任何意义。\n这篇文章将从两个方面来介绍，一个是服务器中的基础的网络通信部件；另外一个是，如何利用这些基础通信部件整合成一个完整的高效的服务器框架。注意：本文以下内容中的客户端是相对概念，指的是连接到当前讨论的服务程序的终端，所以这里的客户端既可能是我们传统意义上的客户端程序，也可能是连接该服务的其他服务器程序。\n一、网络通信部件 按上面介绍的思路，我们先从服务程序的网络通信部件开始介绍。\n（一）、需要解决的问题 既然是服务器程序肯定会涉及到网络通信部分，那么服务器程序的网络通信模块要解决哪些问题？目前，网络上有很多网络通信框架，如libevent、boost asio、ACE，但都网络通信的常见的技术手段都大同小异，至少要解决以下问题：\n如何检测有新客户端连接？ 如何接受客户端连接？ 如何检测客户端是否有数据发来？ 如何收取客户端发来的数据？ 如何检测连接异常？发现连接异常之后，如何处理？ 如何给客户端发送数据？ 如何在给客户端发完数据后关闭连接？ 稍微有点网络基础的人，都能回答上面说的其中几个问题，比如接收客户端连接用socket API的accept函数，收取客户端数据用recv函数，给客户端发送数据用send函数，检测客户端是否有新连接和客户端是否有新数据可以用IO multiplexing技术（IO复用）的select、poll、epoll等socket API。确实是这样的，这些基础的socket API构成了服务器网络通信的地基，不管网络通信框架设计的如何巧妙，都是在这些基础的socket API的基础上构建的。但是如何巧妙地组织这些基础的socket API，才是问题的关键。我们说服务器很高效，支持高并发，实际上只是一个技术实现手段，不管怎样，从软件开发的角度来讲无非就是一个程序而已，所以，只要程序能最大可能地满足“尽量减少等待或者不等待”这一原则就是高效的，也就是说高效不是“忙的忙死，闲的闲死”，而是大家都可以闲着，但是如果有活要干，大家尽量一起干，而不是一部分忙着依次做事情123456789，另外一部分闲在那里无所事事。说的可能有点抽象，下面我们来举一些例子具体来说明一下。 例如：\n默认情况下，recv函数如果没有数据的时候，线程就会阻塞在那里； 默认情况下，send函数，如果tcp窗口不是足够大，数据发不出去也会阻塞在那里； connect函数默认连接另外一端的时候，也会阻塞在那里； 又或者是给对端发送一份数据，需要等待对端回答，如果对方一直不应答，当前线程就阻塞在这里。 以上都不是高效服务器的开发思维方式，因为上面的例子都不满足“尽量减少等待”的原则，为什么一定要等待呢？有没用一种方法，这些过程不需要等待，最好是不仅不需要等待，而且这些事情完成之后能通知我。这样在这些本来用于等待的cpu时间片内，我就可以做一些其他的事情。有，也就是我们下文要讨论的IO Multiplexing技术（IO复用技术）。\n（二）、几种IO复用机制的比较 目前windows系统支持select、WSAAsyncSelect、WSAEventSelect、完成端口（IOCP），linux系统支持select、poll、epoll。这里我们不具体介绍每个具体的函数的用法，我们来讨论一点深层次的东西，以上列举的API函数可以分为两个层次：\n层次一 select和poll 层次二 WSAAsyncSelect、WSAEventSelect、完成端口（IOCP）、epoll 为什么这么分呢？先来介绍第一层次，select和poll函数本质上还是在一定时间内主动去查询socket句柄（可能是一个也可能是多个）上是否有事件，比如可读事件，可写事件或者出错事件，也就是说我们还是需要每隔一段时间内去主动去做这些检测，如果在这段时间内检测出一些事件来，我们这段时间就算没白花，但是倘若这段时间内没有事件呢？我们只能是做无用功了，说白了，还是在浪费时间，因为假如一个服务器有多个连接，在cpu时间片有限的情况下，我们花费了一定的时间检测了一部分socket连接，却发现它们什么事件都没有，而在这段时间内我们却有一些事情需要处理，那我们为什么要花时间去做这个检测呢？把这个时间用在做我们需要做的事情不好吗？所以对于服务器程序来说，要想高效，我们应该尽量避免花费时间主动去查询一些socket是否有事件，而是等这些socket有事件的时候告诉我们去处理。这也就是层次二的各个函数做的事情，它们实际相当于变主动查询是否有事件为当有事件时，系统会告诉我们，此时我们再去处理，也就是“好钢用在刀刃”上了。只不过层次二的函数通知我们的方式是各不相同，比如WSAAsyncSelect是利用windows窗口消息队列的事件机制来通知我们设定的窗口过程函数，IOCP是利用GetQueuedCompletionStatus返回正确的状态，epoll是epoll_wait函数返回而已。\n例如，connect函数连接另外一端，如果用于连接socket是非阻塞的，那么connect虽然不能立刻连接完成，但是也是会立刻返回，无需等待，等连接完成之后，WSAAsyncSelect会返回FD_CONNECT事件告诉我们连接成功，epoll会产生EPOLLOUT事件，我们也能知道连接完成。甚至socket有数据可读时，WSAAsyncSelect产生FD_READ事件，epoll产生EPOLLIN事件，等等。所以有了上面的讨论，我们就可以得到网络通信检测可读可写或者出错事件的正确姿势。这是我这里提出的第二个原则：尽量减少做无用功的时间。这个在服务程序资源够用的情况下可能体现不出来什么优势，但是如果有大量的任务要处理，这里就成了性能的一个瓶颈。\n（三）、检测网络事件的正确姿势 根据上面的介绍，第一，为了避免无意义的等待时间，第二，不采用主动查询各个socket的事件，而是采用等待操作系统通知我们有事件的状态的策略。我们的socket都要设置成非阻塞的。在此基础上我们回到栏目（一）中提到的七个问题：\n如何检测有新客户端连接？\n如何接受客户端连接？ 默认accept函数会阻塞在那里，如果epoll检测到侦听socket上有EPOLLIN事件，或者WSAAsyncSelect检测到有FD_ACCEPT事件，那么就表明此时有新连接到来，这个时候调用accept函数，就不会阻塞了。当然产生的新socket你应该也设置成非阻塞的。这样我们就能在新socket上收发数据了。 如何检测客户端是否有数据发来？\n如何收取客户端发来的数据？ 同理，我们也应该在socket上有可读事件的时候才去收取数据，这样我们调用recv或者read函数时不用等待，至于一次性收多少数据好呢？我们可以根据自己的需求来决定，甚至你可以在一个循环里面反复recv或者read，对于非阻塞模式的socket，如果没有数据了，recv或者read也会立刻返回，错误码EWOULDBLOCK会表明当前已经没有数据了。示例：\nbool CIUSocket::Recv() { int nRet = 0; while(true) { char buff[512]; nRet = ::recv(m_hSocket, buff, 512, 0); if(nRet == SOCKET_ERROR) { if (::WSAGetLastError() == WSAEWOULDBLOCK) break; else return false; } else if(nRet \u0026lt; 1) return false;\nm_strRecvBuf.append(buff, nRet); ::Sleep(1); } return true; }\n如何检测连接异常？发现连接异常之后，如何处理？ 同样当我们收到异常事件后例如EPOLLERR或关闭事件FD_CLOSE，我们就知道了有异常产生，我们对异常的处理一般就是关闭对应的socket。另外，如果send/recv或者read/write函数对一个socket进行操作时，如果返回0，那说明对端已经关闭了socket，此时这路连接也没必要存在了，我们也可以关闭对应的socket。\n如何给客户端发送数据？ 这也是一道常见的网络通信面试题，某一年的腾讯后台开发职位就问到过这样的问题。给客户端发送数据，比收数据要稍微麻烦一点，也是需要讲点技巧的。首先我们不能像注册检测数据可读事件一样一开始就注册检测数据可写事件，因为如果检测可写的话，一般情况下只要对端正常收取数据，我们的socket就都是可写的，如果我们设置监听可写事件，会导致频繁地触发可写事件，但是我们此时并不一定有数据需要发送。所以正确的做法是：如果有数据要发送，则先尝试着去发送，如果发送不了或者只发送出去部分，剩下的我们需要将其缓存起来，然后再设置检测该socket上可写事件，下次可写事件产生时，再继续发送，如果还是不能完全发出去，则继续设置侦听可写事件，如此往复，一直到所有数据都发出去为止。一旦所有数据都发出去以后，我们要移除侦听可写事件，避免无用的可写事件通知。不知道你注意到没有，如果某次只发出去部分数据，剩下的数据应该暂且存起来，这个时候我们就需要一个缓冲区来存放这部分数据，这个缓冲区我们称为“发送缓冲区”。发送缓冲区不仅存放本次没有发完的数据，还用来存放在发送过程中，上层又传来的新的需要发送的数据。为了保证顺序，新的数据应该追加在当前剩下的数据的后面，发送的时候从发送缓冲区的头部开始发送。也就是说先来的先发送，后来的后发送。 如何在给客户端发完数据后关闭连接？ 这个问题比较难处理，因为这里的“发送完”不一定是真正的发送完，我们调用send或者write函数即使成功，也只是向操作系统的协议栈里面成功写入数据，至于能否被发出去、何时被发出去很难判断，发出去对方是否收到就更难判断了。所以，我们目前只能简单地认为send或者write返回我们发出数据的字节数大小，我们就认为“发完数据”了。然后调用close等socket API关闭连接。当然，你也可以调用shutdown函数来实现所谓的“半关闭”。关于关闭连接的话题，我们再单独开一个小的标题来专门讨论一下。\n（四）被动关闭连接和主动关闭连接 在实际的应用中，被动关闭连接是由于我们检测到了连接的异常事件，比如EPOLLERR，或者对端关闭连接，send或recv返回0，这个时候这路连接已经没有存在必要的意义了，我们被迫关闭连接。\n而主动关闭连接，是我们主动调用close/closesocket来关闭连接。比如客户端给我们发送非法的数据，比如一些网络攻击的尝试性数据包。这个时候出于安全考虑，我们关闭socket连接。","title":"C++ 高性能服务器网络框架设计细节"},{"content":"Part IC++ 17 结构化绑定pimpl 惯用法C++必知必会的知识点不定参数函数实现var_arg系列的宏你一定要搞明白的C函数调用方式与栈原理利用 cmake 工具生成 Visual Studio 工程文件如何使用 Visual Studio 管理和阅读开源项目代码如何成为一名合格的 C/C++ 开发者？深入理解C/C++中的指针用Visual Studio调试Linux程序详解 C++ 11 中的智能指针Memcached源码阅读序 服务器资源调整Memcached源码阅读一 初始化参数解析Memcached源码阅读二 网络监听的建立Memcached源码分析三 网络连接建立Memcached源码阅读四 内存初始化Memcached源码阅读五 资源初始化Memcached源码阅读六 get过程Memcached源码阅读七 cas属性Memcached源码阅读八 内存池Memcached源码阅读九 连接队列Memcached源码阅读十 Hash表操作Memcached源码阅读十一 LRU操作Memcached源码阅读十二 set操作Memcached源码阅读十三 do_item_alloc操作Memcached源码阅读十四 item结构Memcached阅读十五 Hash表扩容Memcached源码阅读十六 线程交互Memcached源码阅读十七 状态机Memcached源码分析01 TeamTalk介绍02 服务器端的程序的编译与部署03 服务器端的程序架构介绍04 服务器端db_proxy_server源码分析05 服务器端msg_server源码分析06 服务器端login_server源码分析07 服务器端msfs源码分析08 服务器端file_server源码分析09 服务器端route_server源码分析10 开放一个TeamTalk测试服务器地址和几个测试账号11 pc客户端源码分析TeamTalk源码解析Leveldb源码分析16leveldb源码分析leveldb源码分析1leveldb源码分析10leveldb源码分析11leveldb源码分析12leveldb源码分析13leveldb源码分析14leveldb源码分析15leveldb源码分析17leveldb源码分析18leveldb源码分析19leveldb源码分析2leveldb源码分析20leveldb源码分析21leveldb源码分析22leveldb源码分析3leveldb源码分析4leveldb源码分析5leveldb源码分析6leveldb源码分析7leveldb源码分析8leveldb源码分析9libevent源码深度剖析libevent源码深度剖析一libevent源码深度剖析02libevent源码深度剖析03libevent源码深度剖析04libevent源码深度剖析05libevent源码深度剖析06libevent源码深度剖析07libevent源码深度剖析08libevent源码深度剖析09libevent源码深度剖析10libevent源码深度剖析11libevent源码深度剖析12libevent源码深度剖析13作者的故事我是如何年薪五十万的我的 2019后端开发相关的书籍后台开发应该读的书多线程后台C++开发你一定要知道的条件变量整型变量赋值是原子操作吗？从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始从零学习开源项目系列（二） 最后一战概况从零学习开源项目系列（三） CSBattleMgr服务源码研究从零学习开源项目系列（四）LogServer源码探究服务器开发案例实战从零实现一个http服务器从零实现一个邮件收发客户端从零实现一款12306刷票软件从零开发一个WebSocket服务器10 十万在线的WebGame的数据库设计思路11 一种高性能网络游戏服务器架构设计12 经典游戏服务器端架构概述13 游戏跨服架构进化之路1 游戏服务器开发的基本体系与服务器端开发的一些建议2 网络游戏服务器开发框架设计介绍3 游戏后端开发需要掌握的知识4 关于游戏服务端架构的整理5 各类游戏对应的服务端架构6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则7 QQ游戏百万人同时在线服务器架构实现8 大型多人在线游戏服务器架构设计9 百万用户级游戏服务器架构设计游戏开发专题Linux tcpdump 使用介绍Linux 网络故障排查的瑞士军刀程序员必知必会的网络命令从抓包的角度分析connect()函数的连接过程做 Java 或者 C++ 开发都应该知道的 lsof 命令利用 telnet 命令发电子邮件服务器开发中网络数据分析与故障排查经验漫谈程序员的烦心事我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？为什么你的简历没人看程序员如何写简历程序员的薪资与年终奖那些事儿技术面试与HR谈薪资技巧聊一聊程序员如何增加收入谈一谈年终奖Linux C/C++后端开发面试问哪些问题程序员面试题精讲我面试后端开发经理的经历网络通信面试题集锦聊聊如何拿大厂的 offer腾讯后台开发实习生技能要求Linux epoll 模型（含LT 模式和 ET 模式详解）网络编程TCP 协议如何解决粘包、半包问题bind 函数重难点解析connect 函数在阻塞和非阻塞模式下的行为select 函数重难点解析socket 的阻塞模式和非阻塞模式服务器开发通信协议设计介绍服务器端发数据时，如果对端一直不收，怎么办？网络通信中收发数据的正确姿势非阻塞模式下 send 和 recv 函数的返回值职业规划写给那些傻傻想做服务器开发的朋友给工作 4 年迷茫的程序员们的一点建议聊聊技术人员的常见的职业问题2020 年好好读一读开源代码吧自我提升与开源代码C++ 高性能服务器网络框架设计细节高性能服务器框架设计Reactor模式业务数据处理一定要单独开线程吗主线程与工作线程的分工如何设计断线自动重连机制实例：一个服务器程序的架构介绍心跳包机制设计详解日志系统的设计错误码系统的设计高性能服务器架构设计总结\n","permalink":"https://haokiu.com/blog/bk-1/","summary":"Part IC++ 17 结构化绑定pimpl 惯用法C++必知必会的知识点不定参数函数实现var_arg系列的宏你一定要搞明白的C函数调用方式与栈原理利用 cmake 工具生成 Visual Studio 工程文件如何使用 Visual Studio 管理和阅读开源项目代码如何成为一名合格的 C/C++ 开发者？深入理解C/C++中的指针用Visual Studio调试Linux程序详解 C++ 11 中的智能指针Memcached源码阅读序 服务器资源调整Memcached源码阅读一 初始化参数解析Memcached源码阅读二 网络监听的建立Memcached源码分析三 网络连接建立Memcached源码阅读四 内存初始化Memcached源码阅读五 资源初始化Memcached源码阅读六 get过程Memcached源码阅读七 cas属性Memcached源码阅读八 内存池Memcached源码阅读九 连接队列Memcached源码阅读十 Hash表操作Memcached源码阅读十一 LRU操作Memcached源码阅读十二 set操作Memcached源码阅读十三 do_item_alloc操作Memcached源码阅读十四 item结构Memcached阅读十五 Hash表扩容Memcached源码阅读十六 线程交互Memcached源码阅读十七 状态机Memcached源码分析01 TeamTalk介绍02 服务器端的程序的编译与部署03 服务器端的程序架构介绍04 服务器端db_proxy_server源码分析05 服务器端msg_server源码分析06 服务器端login_server源码分析07 服务器端msfs源码分析08 服务器端file_server源码分析09 服务器端route_server源码分析10 开放一个TeamTalk测试服务器地址和几个测试账号11 pc客户端源码分析TeamTalk源码解析Leveldb源码分析16leveldb源码分析leveldb源码分析1leveldb源码分析10leveldb源码分析11leveldb源码分析12leveldb源码分析13leveldb源码分析14leveldb源码分析15leveldb源码分析17leveldb源码分析18leveldb源码分析19leveldb源码分析2leveldb源码分析20leveldb源码分析21leveldb源码分析22leveldb源码分析3leveldb源码分析4leveldb源码分析5leveldb源码分析6leveldb源码分析7leveldb源码分析8leveldb源码分析9libevent源码深度剖析libevent源码深度剖析一libevent源码深度剖析02libevent源码深度剖析03libevent源码深度剖析04libevent源码深度剖析05libevent源码深度剖析06libevent源码深度剖析07libevent源码深度剖析08libevent源码深度剖析09libevent源码深度剖析10libevent源码深度剖析11libevent源码深度剖析12libevent源码深度剖析13作者的故事我是如何年薪五十万的我的 2019后端开发相关的书籍后台开发应该读的书多线程后台C++开发你一定要知道的条件变量整型变量赋值是原子操作吗？从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始从零学习开源项目系列（二） 最后一战概况从零学习开源项目系列（三） CSBattleMgr服务源码研究从零学习开源项目系列（四）LogServer源码探究服务器开发案例实战从零实现一个http服务器从零实现一个邮件收发客户端从零实现一款12306刷票软件从零开发一个WebSocket服务器10 十万在线的WebGame的数据库设计思路11 一种高性能网络游戏服务器架构设计12 经典游戏服务器端架构概述13 游戏跨服架构进化之路1 游戏服务器开发的基本体系与服务器端开发的一些建议2 网络游戏服务器开发框架设计介绍3 游戏后端开发需要掌握的知识4 关于游戏服务端架构的整理5 各类游戏对应的服务端架构6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则7 QQ游戏百万人同时在线服务器架构实现8 大型多人在线游戏服务器架构设计9 百万用户级游戏服务器架构设计游戏开发专题Linux tcpdump 使用介绍Linux 网络故障排查的瑞士军刀程序员必知必会的网络命令从抓包的角度分析connect()函数的连接过程做 Java 或者 C++ 开发都应该知道的 lsof 命令利用 telnet 命令发电子邮件服务器开发中网络数据分析与故障排查经验漫谈程序员的烦心事我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？为什么你的简历没人看程序员如何写简历程序员的薪资与年终奖那些事儿技术面试与HR谈薪资技巧聊一聊程序员如何增加收入谈一谈年终奖Linux C/C++后端开发面试问哪些问题程序员面试题精讲我面试后端开发经理的经历网络通信面试题集锦聊聊如何拿大厂的 offer腾讯后台开发实习生技能要求Linux epoll 模型（含LT 模式和 ET 模式详解）网络编程TCP 协议如何解决粘包、半包问题bind 函数重难点解析connect 函数在阻塞和非阻塞模式下的行为select 函数重难点解析socket 的阻塞模式和非阻塞模式服务器开发通信协议设计介绍服务器端发数据时，如果对端一直不收，怎么办？网络通信中收发数据的正确姿势非阻塞模式下 send 和 recv 函数的返回值职业规划写给那些傻傻想做服务器开发的朋友给工作 4 年迷茫的程序员们的一点建议聊聊技术人员的常见的职业问题2020 年好好读一读开源代码吧自我提升与开源代码C++ 高性能服务器网络框架设计细节高性能服务器框架设计Reactor模式业务数据处理一定要单独开线程吗主线程与工作线程的分工如何设计断线自动重连机制实例：一个服务器程序的架构介绍心跳包机制设计详解日志系统的设计错误码系统的设计高性能服务器架构设计总结","title":"CppGuide"},{"content":"Reactor模式 最近一直在看游双的《高性能Linux服务器编程》一书，下载链接： http://download.csdn.net/detail/analogous_love/9673008\n书上是这么介绍Reactor模式的：\n按照这个思路，我写个简单的练习：\n/** *@desc: 用reactor模式练习服务器程序，main.cpp *@author: zhangyl *@date: 2016.11.23 */ #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; //for htonl() and htons() #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; #include \u0026lt;signal.h\u0026gt; //for signal() #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;semaphore.h\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;sstream\u0026gt; #include \u0026lt;iomanip\u0026gt; //for std::setw()/setfill() #include \u0026lt;stdlib.h\u0026gt; #define WORKER_THREAD_NUM 5 #define min(a, b) ((a \u0026lt;= b) ? (a) : (b)) int g_epollfd = 0; bool g_bStop = false; int g_listenfd = 0; pthread_t g_acceptthreadid = 0; pthread_t g_threadid[WORKER_THREAD_NUM] = { 0 }; pthread_cond_t g_acceptcond; pthread_mutex_t g_acceptmutex; pthread_cond_t g_cond /*= PTHREAD_COND_INITIALIZER*/; pthread_mutex_t g_mutex /*= PTHREAD_MUTEX_INITIALIZER*/; pthread_mutex_t g_clientmutex; std::list\u0026lt;int\u0026gt; g_listClients; void prog_exit(int signo) { ::signal(SIGINT, SIG_IGN); //::signal(SIGKILL, SIG_IGN);//该信号不能被阻塞、处理或者忽略 ::signal(SIGTERM, SIG_IGN); std::cout \u0026lt;\u0026lt; \u0026#34;program recv signal \u0026#34; \u0026lt;\u0026lt; signo \u0026lt;\u0026lt; \u0026#34; to exit.\u0026#34; \u0026lt;\u0026lt; std::endl; g_bStop = true; ::epoll_ctl(g_epollfd, EPOLL_CTL_DEL, g_listenfd, NULL); //TODO: 是否需要先调用shutdown()一下？ ::shutdown(g_listenfd, SHUT_RDWR); ::close(g_listenfd); ::close(g_epollfd); ::pthread_cond_destroy(\u0026amp;g_acceptcond); ::pthread_mutex_destroy(\u0026amp;g_acceptmutex); ::pthread_cond_destroy(\u0026amp;g_cond); ::pthread_mutex_destroy(\u0026amp;g_mutex); ::pthread_mutex_destroy(\u0026amp;g_clientmutex); } bool create_server_listener(const char* ip, short port) { g_listenfd = ::socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, 0); if (g_listenfd == -1) return false; int on = 1; ::setsockopt(g_listenfd, SOL_SOCKET, SO_REUSEADDR, (char *)\u0026amp;on, sizeof(on)); ::setsockopt(g_listenfd, SOL_SOCKET, SO_REUSEPORT, (char *)\u0026amp;on, sizeof(on)); struct sockaddr_in servaddr; memset(\u0026amp;servaddr, 0, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = inet_addr(ip); servaddr.sin_port = htons(port); if (::bind(g_listenfd, (sockaddr *)\u0026amp;servaddr, sizeof(servaddr)) == -1) return false; if (::listen(g_listenfd, 50) == -1) return false; g_epollfd = ::epoll_create(1); if (g_epollfd == -1) return false; struct epoll_event e; memset(\u0026amp;e, 0, sizeof(e)); e.events = EPOLLIN | EPOLLRDHUP; e.data.fd = g_listenfd; if (::epoll_ctl(g_epollfd, EPOLL_CTL_ADD, g_listenfd, \u0026amp;e) == -1) return false; return true; } void release_client(int clientfd) { if (::epoll_ctl(g_epollfd, EPOLL_CTL_DEL, clientfd, NULL) == -1) std::cout \u0026lt;\u0026lt; \u0026#34;release client socket failed as call epoll_ctl failed\u0026#34; \u0026lt;\u0026lt; std::endl; ::close(clientfd); } void* accept_thread_func(void* arg) { while (!g_bStop) { ::pthread_mutex_lock(\u0026amp;g_acceptmutex); ::pthread_cond_wait(\u0026amp;g_acceptcond, \u0026amp;g_acceptmutex); //::pthread_mutex_lock(\u0026amp;g_acceptmutex); //std::cout \u0026lt;\u0026lt; \u0026#34;run loop in accept_thread_func\u0026#34; \u0026lt;\u0026lt; std::endl; struct sockaddr_in clientaddr; socklen_t addrlen; int newfd = ::accept(g_listenfd, (struct sockaddr *)\u0026amp;clientaddr, \u0026amp;addrlen); ::pthread_mutex_unlock(\u0026amp;g_acceptmutex); if (newfd == -1) continue; std::cout \u0026lt;\u0026lt; \u0026#34;new client connected: \u0026#34; \u0026lt;\u0026lt; ::inet_ntoa(clientaddr.sin_addr) \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; ::ntohs(clientaddr.sin_port) \u0026lt;\u0026lt; std::endl; //将新socket设置为non-blocking int oldflag = ::fcntl(newfd, F_GETFL, 0); int newflag = oldflag | O_NONBLOCK; if (::fcntl(newfd, F_SETFL, newflag) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;fcntl error, oldflag =\u0026#34; \u0026lt;\u0026lt; oldflag \u0026lt;\u0026lt; \u0026#34;, newflag = \u0026#34; \u0026lt;\u0026lt; newflag \u0026lt;\u0026lt; std::endl; continue; } struct epoll_event e; memset(\u0026amp;e, 0, sizeof(e)); e.events = EPOLLIN | EPOLLRDHUP | EPOLLET; e.data.fd = newfd; if (::epoll_ctl(g_epollfd, EPOLL_CTL_ADD, newfd, \u0026amp;e) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;epoll_ctl error, fd =\u0026#34; \u0026lt;\u0026lt; newfd \u0026lt;\u0026lt; std::endl; } } return NULL; } void* worker_thread_func(void* arg) { while (!g_bStop) { int clientfd; ::pthread_mutex_lock(\u0026amp;g_clientmutex); while (g_listClients.empty()) ::pthread_cond_wait(\u0026amp;g_cond, \u0026amp;g_clientmutex); clientfd = g_listClients.front(); g_listClients.pop_front(); pthread_mutex_unlock(\u0026amp;g_clientmutex); //gdb调试时不能实时刷新标准输出，用这个函数刷新标准输出，使信息在屏幕上实时显示出来 std::cout \u0026lt;\u0026lt; std::endl; std::string strclientmsg; char buff[256]; bool bError = false; while (true) { memset(buff, 0, sizeof(buff)); int nRecv = ::recv(clientfd, buff, 256, 0); if (nRecv == -1) { if (errno == EWOULDBLOCK) break; else { std::cout \u0026lt;\u0026lt; \u0026#34;recv error, client disconnected, fd = \u0026#34; \u0026lt;\u0026lt; clientfd \u0026lt;\u0026lt; std::endl; release_client(clientfd); bError = true; break; } } //对端关闭了socket，这端也关闭。 else if (nRecv == 0) { std::cout \u0026lt;\u0026lt; \u0026#34;peer closed, client disconnected, fd = \u0026#34; \u0026lt;\u0026lt; clientfd \u0026lt;\u0026lt; std::endl; release_client(clientfd); bError = true; break; } strclientmsg += buff; } //出错了，就不要再继续往下执行了 if (bError) continue; std::cout \u0026lt;\u0026lt; \u0026#34;client msg: \u0026#34; \u0026lt;\u0026lt; strclientmsg; //将消息加上时间标签后发回 time_t now = time(NULL); struct tm* nowstr = localtime(\u0026amp;now); std::ostringstream ostimestr; ostimestr \u0026lt;\u0026lt; \u0026#34;[\u0026#34; \u0026lt;\u0026lt; nowstr-\u0026gt;tm_year + 1900 \u0026lt;\u0026lt; \u0026#34;-\u0026#34; \u0026lt;\u0026lt; std::setw(2) \u0026lt;\u0026lt; std::setfill(\u0026#39;0\u0026#39;) \u0026lt;\u0026lt; nowstr-\u0026gt;tm_mon + 1 \u0026lt;\u0026lt; \u0026#34;-\u0026#34; \u0026lt;\u0026lt; std::setw(2) \u0026lt;\u0026lt; std::setfill(\u0026#39;0\u0026#39;) \u0026lt;\u0026lt; nowstr-\u0026gt;tm_mday \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::setw(2) \u0026lt;\u0026lt; std::setfill(\u0026#39;0\u0026#39;) \u0026lt;\u0026lt; nowstr-\u0026gt;tm_hour \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; std::setw(2) \u0026lt;\u0026lt; std::setfill(\u0026#39;0\u0026#39;) \u0026lt;\u0026lt; nowstr-\u0026gt;tm_min \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; std::setw(2) \u0026lt;\u0026lt; std::setfill(\u0026#39;0\u0026#39;) \u0026lt;\u0026lt; nowstr-\u0026gt;tm_sec \u0026lt;\u0026lt; \u0026#34;]server reply: \u0026#34;; strclientmsg.insert(0, ostimestr.str()); while (true) { int nSent = ::send(clientfd, strclientmsg.c_str(), strclientmsg.length(), 0); if (nSent == -1) { if (errno == EWOULDBLOCK) { ::sleep(10); continue; } else { std::cout \u0026lt;\u0026lt; \u0026#34;send error, fd = \u0026#34; \u0026lt;\u0026lt; clientfd \u0026lt;\u0026lt; std::endl; release_client(clientfd); break; } } std::cout \u0026lt;\u0026lt; \u0026#34;send: \u0026#34; \u0026lt;\u0026lt; strclientmsg; strclientmsg.erase(0, nSent); if (strclientmsg.empty()) break; } } return NULL; } void daemon_run() { int pid; signal(SIGCHLD, SIG_IGN); //1）在父进程中，fork返回新创建子进程的进程ID； //2）在子进程中，fork返回0； //3）如果出现错误，fork返回一个负值； pid = fork(); if (pid \u0026lt; 0) { std:: cout \u0026lt;\u0026lt; \u0026#34;fork error\u0026#34; \u0026lt;\u0026lt; std::endl; exit(-1); } //父进程退出，子进程独立运行 else if (pid \u0026gt; 0) { exit(0); } //之前parent和child运行在同一个session里,parent是会话（session）的领头进程, //parent进程作为会话的领头进程，如果exit结束执行的话，那么子进程会成为孤儿进程，并被init收养。 //执行setsid()之后,child将重新获得一个新的会话(session)id。 //这时parent退出之后,将不会影响到child了。 setsid(); int fd; fd = open(\u0026#34;/dev/null\u0026#34;, O_RDWR, 0); if (fd != -1) { dup2(fd, STDIN_FILENO); dup2(fd, STDOUT_FILENO); dup2(fd, STDERR_FILENO); } if (fd \u0026gt; 2) close(fd); } int main(int argc, char* argv[]) { short port = 0; int ch; bool bdaemon = false; while ((ch = getopt(argc, argv, \u0026#34;p:d\u0026#34;)) != -1) { switch (ch) { case \u0026#39;d\u0026#39;: bdaemon = true; break; case \u0026#39;p\u0026#39;: port = atol(optarg); break; } } if (bdaemon) daemon_run(); if (port == 0) port = 12345; if (!create_server_listener(\u0026#34;0.0.0.0\u0026#34;, port)) { std::cout \u0026lt;\u0026lt; \u0026#34;Unable to create listen server: ip=0.0.0.0, port=\u0026#34; \u0026lt;\u0026lt; port \u0026lt;\u0026lt; \u0026#34;.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //设置信号处理 signal(SIGCHLD, SIG_DFL); signal(SIGPIPE, SIG_IGN); signal(SIGINT, prog_exit); //signal(SIGKILL, prog_exit);//该信号不能被阻塞、处理或者忽略 signal(SIGTERM, prog_exit); ::pthread_cond_init(\u0026amp;g_acceptcond, NULL); ::pthread_mutex_init(\u0026amp;g_acceptmutex, NULL); ::pthread_cond_init(\u0026amp;g_cond, NULL); ::pthread_mutex_init(\u0026amp;g_mutex, NULL); ::pthread_mutex_init(\u0026amp;g_clientmutex, NULL); ::pthread_create(\u0026amp;g_acceptthreadid, NULL, accept_thread_func, NULL); //启动工作线程 for (int i = 0; i \u0026lt; WORKER_THREAD_NUM; ++i) { ::pthread_create(\u0026amp;g_threadid[i], NULL, worker_thread_func, NULL); } while (!g_bStop) { struct epoll_event ev[1024]; int n = ::epoll_wait(g_epollfd, ev, 1024, 10); if (n == 0) continue; else if (n \u0026lt; 0) { std::cout \u0026lt;\u0026lt; \u0026#34;epoll_wait error\u0026#34; \u0026lt;\u0026lt; std::endl; continue; } int m = min(n, 1024); for (int i = 0; i \u0026lt; m; ++i) { //通知接收连接线程接收新连接 if (ev[i].data.fd == g_listenfd) pthread_cond_signal(\u0026amp;g_acceptcond); //通知普通工作线程接收数据 else { pthread_mutex_lock(\u0026amp;g_clientmutex); g_listClients.push_back(ev[i].data.fd); pthread_mutex_unlock(\u0026amp;g_clientmutex); pthread_cond_signal(\u0026amp;g_cond); //std::cout \u0026lt;\u0026lt; \u0026#34;signal\u0026#34; \u0026lt;\u0026lt; std::endl; } } } return 0; } 程序的功能一个简单的echo服务：客户端连接上服务器之后，给服务器发送信息，服务器加上时间戳等信息后返回给客户端。\n使用到的知识点有：\n条件变量\nepoll的边缘触发模式\n程序的大致框架是：\n主线程只负责监听侦听socket上是否有新连接，如果有新连接到来，交给一个叫accept的工作线程去接收新连接，并将新连接socket绑定到主线程使用epollfd上去。 主线程如果侦听到客户端的socket上有可读事件，则通知另外五个工作线程去接收处理客户端发来的数据，并将数据加上时间戳后发回给客户端。 可以通过传递-p port来设置程序的监听端口号；可以通过传递-d来使程序以daemon模式运行在后台。这也是标准linux daemon模式的书写方法。 程序难点和需要注意的地方是：\n条件变量为了防止虚假唤醒，一定要在一个循环里面调用pthread_cond_wait()函数，我在worker_thread_func()中使用了： while (g_listClients.empty()) ::pthread_cond_wait(\u0026amp;g_cond, \u0026amp;g_clientmutex); 在accept_thread_func()函数里面我没有使用循环，这样会有问题吗？\n使用条件变量pthread_cond_wait()函数的时候一定要先获得与该条件变量相关的mutex，即像下面这样的结构： mutex_lock(...); while (condition is true) ::pthread_cond_wait(...); //这里可以有其他代码... mutex_unlock(...); //这里可以有其他代码... 因为pthread_cond_wait()如果阻塞的话，它解锁相关mutex和阻塞当前线程这两个动作加在一起是原子的。\n作为服务器端程序最好对侦听socket调用setsocketopt()设置SO_REUSEADDR和SO_REUSEPORT两个标志，因为服务程序有时候会需要重启（比如调试的时候就会不断重启），如果不设置这两个标志的话，绑定端口时就会调用失败。因为一个端口使用后，即使不再使用，因为四次挥手该端口处于TIME_WAIT状态，有大约2min的MSL（Maximum Segment Lifetime，最大存活期）。这2min内，该端口是不能被重复使用的。你的服务器程序上次使用了这个端口号，接着重启，因为这个缘故，你再次绑定这个端口就会失败（bind函数调用失败）。要不你就每次重启时需要等待2min后再试（这在频繁重启程序调试是难以接收的），或者设置这种SO_REUSEADDR和SO_REUSEPORT立即回收端口使用。 其实，SO_REUSEADDR在Windows上和Unix平台上还有些细微的区别，我在libevent源码中看到这样的描述：\nint evutil_make_listen_socket_reuseable(evutil_socket_t sock) { #ifndef WIN32 int one = 1; /* REUSEADDR on Unix means, \u0026#34;don\u0026#39;t hang on to this address after the * listener is closed.\u0026#34; On Windows, though, it means \u0026#34;don\u0026#39;t keep other * processes from binding to this address while we\u0026#39;re using it. */ return setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, (void*) \u0026amp;one, (ev_socklen_t)sizeof(one)); #else return 0; #endif } 注意注释部分，在Unix平台上设置这个选项意味着，任意进程可以复用该地址；而在windows，不要阻止其他进程复用该地址。也就是在在Unix平台上，如果不设置这个选项，任意进程在一定时间内，不能bind该地址；在windows平台上，在一定时间内，其他进程不能bind该地址，而本进程却可以再次bind该地址。\nepoll_wait对新连接socket使用的是边缘触发模式EPOLLET（edge trigger），而不是默认的水平触发模式（level trigger)。因为如果采取水平触发模式的话，主线程检测到某个客户端socket数据可读时，通知工作线程去收取该socket上的数据，这个时候主线程继续循环，只要在工作线程没有将该socket上数据全部收完，或者在工作线程收取数据的过程中，客户端有新数据到来，主线程会继续发通知（通过pthread_cond_signal()）函数，再次通知工作线程收取数据。这样会可能导致多个工作线程同时调用recv函数收取该客户端socket上的数据，这样产生的结果将会导致数据错乱。 相反，采取边缘触发模式，只有等某个工作线程将那个客户端socket上数据全部收取完毕，主线程的epoll_wait才可能会再次触发来通知工作线程继续收取那个客户端socket新来的数据。\n代码中有这样一行：\n//gdb调试时不能实时刷新标准输出，用这个函数刷新标准输出，使信息在屏幕上实时显示出来 std::cout \u0026lt;\u0026lt; std::endl; 如果不加上这一行，正常运行服务器程序，程序中要打印到控制台的信息都会打印出来，但是如果用gdb调试状态下，程序的所有输出就不显示了。我不知道这是不是gdb的一个bug，所以这里加上std::endl来输出一个换行符并flush标准输出，让输出显示出来。（std::endl不仅是输出一个换行符而且是同时刷新输出，相当于fflush()函数）。\n程序我部署起来了，你可以使用linux的nc命令或自己写程序连接服务器来查看程序效果，当然也可以使用telnet命令，方法：\nLinux:\nnc 120.55.94.78 12345 或\ntelnet 120.55.94.78 12345 然后就可以给服务器自由发送数据了，服务器会给你发送的信息加上时间戳返回给你。效果如图：\n另外我将这个代码改写了成纯C++11版本，使用CMake编译，为了支持编译必须加上这-std=c++11：\nCMakeLists.txt代码如下：\ncmake_minimum_required(VERSION 2.8) PROJECT(myreactorserver) AUX_SOURCE_DIRECTORY(./ SRC_LIST) SET(EXECUTABLE_OUTPUT_PATH ./) ADD_DEFINITIONS(-g -W -Wall -Wno-deprecated -DLINUX -D_REENTRANT -D_FILE_OFFSET_BITS=64 -DAC_HAS_INFO -DAC_HAS_WARNING -DAC_HAS_ERROR -DAC_HAS_CRITICAL -DTIXML_USE_STL -DHAVE_CXX_STDHEADERS NULL -std=c++11) INCLUDE_DIRECTORIES( ./ ) LINK_DIRECTORIES( ./ ) set( main.cpp myreator.cpp ) ADD_EXECUTABLE(myreactorserver NULL) TARGET_LINK_LIBRARIES(myreactorserver pthread) myreactor.h文件内容：\n/** *@desc: myreactor头文件, myreactor.h *@author: zhangyl *@date: 2016.12.03 */ #ifndef __MYREACTOR_H__ #define __MYREACTOR_H__ #include \u0026lt;list\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;thread\u0026gt; #include \u0026lt;mutex\u0026gt; #include \u0026lt;condition_variable\u0026gt; #define WORKER_THREAD_NUM 5 class CMyReactor { public: CMyReactor(); ~CMyReactor(); bool init(const char* ip, short nport); bool uninit(); bool close_client(int clientfd); static void* main_loop(void* p); private: //no copyable CMyReactor(const CMyReactor\u0026amp; rhs); CMyReactor\u0026amp; operator = (const CMyReactor\u0026amp; rhs); bool create_server_listener(const char* ip, short port); static void accept_thread_proc(CMyReactor* pReatcor); static void worker_thread_proc(CMyReactor* pReatcor); private: //C11语法可以在这里初始化 int\tm_listenfd = 0; int\tm_epollfd = 0; bool\tm_bStop = false; std::shared_ptr\u0026lt;std::thread\u0026gt; m_acceptthread; std::shared_ptr\u0026lt;std::thread\u0026gt; m_workerthreads[WORKER_THREAD_NUM]; std::condition_variable\tm_acceptcond; std::mutex\tm_acceptmutex; std::condition_variable\tm_workercond ; std::mutex\tm_workermutex; std::list\u0026lt;int\u0026gt;\tm_listClients; }; #endif //!__MYREACTOR_H__ myreactor.cpp文件内容：\n/** *@desc: myreactor实现文件, myreactor.cpp *@author: zhangyl *@date: 2016.12.03 */ #include \u0026#34;myreactor.h\u0026#34; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; //for htonl() and htons() #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;sstream\u0026gt; #include \u0026lt;iomanip\u0026gt; //for std::setw()/setfill() #include \u0026lt;unistd.h\u0026gt; #define min(a, b) ((a \u0026lt;= b) ? (a) : (b)) CMyReactor::CMyReactor() { //m_listenfd = 0; //m_epollfd = 0; //m_bStop = false; } CMyReactor::~CMyReactor() { } bool CMyReactor::init(const char* ip, short nport) { if (!create_server_listener(ip, nport)) { std::cout \u0026lt;\u0026lt; \u0026#34;Unable to bind: \u0026#34; \u0026lt;\u0026lt; ip \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; nport \u0026lt;\u0026lt; \u0026#34;.\u0026#34; \u0026lt;\u0026lt; std::endl; return false; } std::cout \u0026lt;\u0026lt; \u0026#34;main thread id = \u0026#34; \u0026lt;\u0026lt; std::this_thread::get_id() \u0026lt;\u0026lt; std::endl; //启动接收新连接的线程 m_acceptthread.reset(new std::thread(CMyReactor::accept_thread_proc, this)); //启动工作线程 for (auto\u0026amp; t : m_workerthreads) { t.reset(new std::thread(CMyReactor::worker_thread_proc, this)); } return true; } bool CMyReactor::uninit() { m_bStop = true; m_acceptcond.notify_one(); m_workercond.notify_all(); m_acceptthread-\u0026gt;join(); for (auto\u0026amp; t : m_workerthreads) { t-\u0026gt;join(); } ::epoll_ctl(m_epollfd, EPOLL_CTL_DEL, m_listenfd, NULL); //TODO: 是否需要先调用shutdown()一下？ ::shutdown(m_listenfd, SHUT_RDWR); ::close(m_listenfd); ::close(m_epollfd); return true; } bool CMyReactor::close_client(int clientfd) { if (::epoll_ctl(m_epollfd, EPOLL_CTL_DEL, clientfd, NULL) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;close client socket failed as call epoll_ctl failed\u0026#34; \u0026lt;\u0026lt; std::endl; //return false; } ::close(clientfd); return true; } void* CMyReactor::main_loop(void* p) { std::cout \u0026lt;\u0026lt; \u0026#34;main thread id = \u0026#34; \u0026lt;\u0026lt; std::this_thread::get_id() \u0026lt;\u0026lt; std::endl; CMyReactor* pReatcor = static_cast\u0026lt;CMyReactor*\u0026gt;(p); while (!pReatcor-\u0026gt;m_bStop) { struct epoll_event ev[1024]; int n = ::epoll_wait(pReatcor-\u0026gt;m_epollfd, ev, 1024, 10); if (n == 0) continue; else if (n \u0026lt; 0) { std::cout \u0026lt;\u0026lt; \u0026#34;epoll_wait error\u0026#34; \u0026lt;\u0026lt; std::endl; continue; } int m = min(n, 1024); for (int i = 0; i \u0026lt; m; ++i) { //通知接收连接线程接收新连接 if (ev[i].data.fd == pReatcor-\u0026gt;m_listenfd) pReatcor-\u0026gt;m_acceptcond.notify_one(); //通知普通工作线程接收数据 else { { std::unique_lock\u0026lt;std::mutex\u0026gt; guard(pReatcor-\u0026gt;m_workermutex); pReatcor-\u0026gt;m_listClients.push_back(ev[i].data.fd); } pReatcor-\u0026gt;m_workercond.notify_one(); //std::cout \u0026lt;\u0026lt; \u0026#34;signal\u0026#34; \u0026lt;\u0026lt; std::endl; }// end if }// end for-loop }// end while std::cout \u0026lt;\u0026lt; \u0026#34;main loop exit ...\u0026#34; \u0026lt;\u0026lt; std::endl; return NULL; } void CMyReactor::accept_thread_proc(CMyReactor* pReatcor) { std::cout \u0026lt;\u0026lt; \u0026#34;accept thread, thread id = \u0026#34; \u0026lt;\u0026lt; std::this_thread::get_id() \u0026lt;\u0026lt; std::endl; while (true) { int newfd; struct sockaddr_in clientaddr; socklen_t addrlen; { std::unique_lock\u0026lt;std::mutex\u0026gt; guard(pReatcor-\u0026gt;m_acceptmutex); pReatcor-\u0026gt;m_acceptcond.wait(guard); if (pReatcor-\u0026gt;m_bStop) break; //std::cout \u0026lt;\u0026lt; \u0026#34;run loop in accept_thread_proc\u0026#34; \u0026lt;\u0026lt; std::endl; newfd = ::accept(pReatcor-\u0026gt;m_listenfd, (struct sockaddr *)\u0026amp;clientaddr, \u0026amp;addrlen); } if (newfd == -1) continue; std::cout \u0026lt;\u0026lt; \u0026#34;new client connected: \u0026#34; \u0026lt;\u0026lt; ::inet_ntoa(clientaddr.sin_addr) \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; ::ntohs(clientaddr.sin_port) \u0026lt;\u0026lt; std::endl; //将新socket设置为non-blocking int oldflag = ::fcntl(newfd, F_GETFL, 0); int newflag = oldflag | O_NONBLOCK; if (::fcntl(newfd, F_SETFL, newflag) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;fcntl error, oldflag =\u0026#34; \u0026lt;\u0026lt; oldflag \u0026lt;\u0026lt; \u0026#34;, newflag = \u0026#34; \u0026lt;\u0026lt; newflag \u0026lt;\u0026lt; std::endl; continue; } struct epoll_event e; memset(\u0026amp;e, 0, sizeof(e)); e.events = EPOLLIN | EPOLLRDHUP | EPOLLET; e.data.fd = newfd; if (::epoll_ctl(pReatcor-\u0026gt;m_epollfd, EPOLL_CTL_ADD, newfd, \u0026amp;e) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;epoll_ctl error, fd =\u0026#34; \u0026lt;\u0026lt; newfd \u0026lt;\u0026lt; std::endl; } } std::cout \u0026lt;\u0026lt; \u0026#34;accept thread exit ...\u0026#34; \u0026lt;\u0026lt; std::endl; } void CMyReactor::worker_thread_proc(CMyReactor* pReatcor) { std::cout \u0026lt;\u0026lt; \u0026#34;new worker thread, thread id = \u0026#34; \u0026lt;\u0026lt; std::this_thread::get_id() \u0026lt;\u0026lt; std::endl; while (true) { int clientfd; { std::unique_lock\u0026lt;std::mutex\u0026gt; guard(pReatcor-\u0026gt;m_workermutex); while (pReatcor-\u0026gt;m_listClients.empty()) { if (pReatcor-\u0026gt;m_bStop) { std::cout \u0026lt;\u0026lt; \u0026#34;worker thread exit ...\u0026#34; \u0026lt;\u0026lt; std::endl; return; } pReatcor-\u0026gt;m_workercond.wait(guard); } clientfd = pReatcor-\u0026gt;m_listClients.front(); pReatcor-\u0026gt;m_listClients.pop_front(); } //gdb调试时不能实时刷新标准输出，用这个函数刷新标准输出，使信息在屏幕上实时显示出来 std::cout \u0026lt;\u0026lt; std::endl; std::string strclientmsg; char buff[256]; bool bError = false; while (true) { memset(buff, 0, sizeof(buff)); int nRecv = ::recv(clientfd, buff, 256, 0); if (nRecv == -1) { if (errno == EWOULDBLOCK) break; else { std::cout \u0026lt;\u0026lt; \u0026#34;recv error, client disconnected, fd = \u0026#34; \u0026lt;\u0026lt; clientfd \u0026lt;\u0026lt; std::endl; pReatcor-\u0026gt;close_client(clientfd); bError = true; break; } } //对端关闭了socket，这端也关闭。 else if (nRecv == 0) { std::cout \u0026lt;\u0026lt; \u0026#34;peer closed, client disconnected, fd = \u0026#34; \u0026lt;\u0026lt; clientfd \u0026lt;\u0026lt; std::endl; pReatcor-\u0026gt;close_client(clientfd); bError = true; break; } strclientmsg += buff; } //出错了，就不要再继续往下执行了 if (bError) continue; std::cout \u0026lt;\u0026lt; \u0026#34;client msg: \u0026#34; \u0026lt;\u0026lt; strclientmsg; //将消息加上时间标签后发回 time_t now = time(NULL); struct tm* nowstr = localtime(\u0026amp;now); std::ostringstream ostimestr; ostimestr \u0026lt;\u0026lt; \u0026#34;[\u0026#34; \u0026lt;\u0026lt; nowstr-\u0026gt;tm_year + 1900 \u0026lt;\u0026lt; \u0026#34;-\u0026#34; \u0026lt;\u0026lt; std::setw(2) \u0026lt;\u0026lt; std::setfill(\u0026#39;0\u0026#39;) \u0026lt;\u0026lt; nowstr-\u0026gt;tm_mon + 1 \u0026lt;\u0026lt; \u0026#34;-\u0026#34; \u0026lt;\u0026lt; std::setw(2) \u0026lt;\u0026lt; std::setfill(\u0026#39;0\u0026#39;) \u0026lt;\u0026lt; nowstr-\u0026gt;tm_mday \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; std::setw(2) \u0026lt;\u0026lt; std::setfill(\u0026#39;0\u0026#39;) \u0026lt;\u0026lt; nowstr-\u0026gt;tm_hour \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; std::setw(2) \u0026lt;\u0026lt; std::setfill(\u0026#39;0\u0026#39;) \u0026lt;\u0026lt; nowstr-\u0026gt;tm_min \u0026lt;\u0026lt; \u0026#34;:\u0026#34; \u0026lt;\u0026lt; std::setw(2) \u0026lt;\u0026lt; std::setfill(\u0026#39;0\u0026#39;) \u0026lt;\u0026lt; nowstr-\u0026gt;tm_sec \u0026lt;\u0026lt; \u0026#34;]server reply: \u0026#34;; strclientmsg.insert(0, ostimestr.str()); while (true) { int nSent = ::send(clientfd, strclientmsg.c_str(), strclientmsg.length(), 0); if (nSent == -1) { if (errno == EWOULDBLOCK) { std::this_thread::sleep_for(std::chrono::milliseconds(10)); continue; } else { std::cout \u0026lt;\u0026lt; \u0026#34;send error, fd = \u0026#34; \u0026lt;\u0026lt; clientfd \u0026lt;\u0026lt; std::endl; pReatcor-\u0026gt;close_client(clientfd); break; } } std::cout \u0026lt;\u0026lt; \u0026#34;send: \u0026#34; \u0026lt;\u0026lt; strclientmsg; strclientmsg.erase(0, nSent); if (strclientmsg.empty()) break; } } } bool CMyReactor::create_server_listener(const char* ip, short port) { m_listenfd = ::socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, 0); if (m_listenfd == -1) return false; int on = 1; ::setsockopt(m_listenfd, SOL_SOCKET, SO_REUSEADDR, (char *)\u0026amp;on, sizeof(on)); ::setsockopt(m_listenfd, SOL_SOCKET, SO_REUSEPORT, (char *)\u0026amp;on, sizeof(on)); struct sockaddr_in servaddr; memset(\u0026amp;servaddr, 0, sizeof(servaddr)); servaddr.sin_family = AF_INET; servaddr.sin_addr.s_addr = inet_addr(ip); servaddr.sin_port = htons(port); if (::bind(m_listenfd, (sockaddr *)\u0026amp;servaddr, sizeof(servaddr)) == -1) return false; if (::listen(m_listenfd, 50) == -1) return false; m_epollfd = ::epoll_create(1); if (m_epollfd == -1) return false; struct epoll_event e; memset(\u0026amp;e, 0, sizeof(e)); e.events = EPOLLIN | EPOLLRDHUP; e.data.fd = m_listenfd; if (::epoll_ctl(m_epollfd, EPOLL_CTL_ADD, m_listenfd, \u0026amp;e) == -1) return false; return true; } main.cpp文件内容：\n/** *@desc: 用reactor模式练习服务器程序 *@author: zhangyl *@date: 2016.12.03 */ #include \u0026lt;iostream\u0026gt; #include \u0026lt;signal.h\u0026gt; //for signal() #include\u0026lt;unistd.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt;\t//for exit() #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026#34;myreactor.h\u0026#34; CMyReactor g_reator; void prog_exit(int signo) { std::cout \u0026lt;\u0026lt; \u0026#34;program recv signal \u0026#34; \u0026lt;\u0026lt; signo \u0026lt;\u0026lt; \u0026#34; to exit.\u0026#34; \u0026lt;\u0026lt; std::endl; g_reator.uninit(); } void daemon_run() { int pid; signal(SIGCHLD, SIG_IGN); //1）在父进程中，fork返回新创建子进程的进程ID； //2）在子进程中，fork返回0； //3）如果出现错误，fork返回一个负值； pid = fork(); if (pid \u0026lt; 0) { std:: cout \u0026lt;\u0026lt; \u0026#34;fork error\u0026#34; \u0026lt;\u0026lt; std::endl; exit(-1); } //父进程退出，子进程独立运行 else if (pid \u0026gt; 0) { exit(0); } //之前parent和child运行在同一个session里,parent是会话（session）的领头进程, //parent进程作为会话的领头进程，如果exit结束执行的话，那么子进程会成为孤儿进程，并被init收养。 //执行setsid()之后,child将重新获得一个新的会话(session)id。 //这时parent退出之后,将不会影响到child了。 setsid(); int fd; fd = open(\u0026#34;/dev/null\u0026#34;, O_RDWR, 0); if (fd != -1) { dup2(fd, STDIN_FILENO); dup2(fd, STDOUT_FILENO); dup2(fd, STDERR_FILENO); } if (fd \u0026gt; 2) close(fd); } int main(int argc, char* argv[]) { //设置信号处理 signal(SIGCHLD, SIG_DFL); signal(SIGPIPE, SIG_IGN); signal(SIGINT, prog_exit); signal(SIGKILL, prog_exit); signal(SIGTERM, prog_exit); short port = 0; int ch; bool bdaemon = false; while ((ch = getopt(argc, argv, \u0026#34;p:d\u0026#34;)) != -1) { switch (ch) { case \u0026#39;d\u0026#39;: bdaemon = true; break; case \u0026#39;p\u0026#39;: port = atol(optarg); break; } } if (bdaemon) daemon_run(); if (port == 0) port = 12345; if (!g_reator.init(\u0026#34;0.0.0.0\u0026#34;, 12345)) return -1; g_reator.main_loop(\u0026amp;g_reator); return 0; } 完整实例代码下载地址：\n普通版本：https://pan.baidu.com/s/1o82Mkno\nC++11版本：https://pan.baidu.com/s/1dEJdrih\n","permalink":"https://haokiu.com/blog/23cb111095cb47f3b6115efccd11086d/","summary":"Reactor模式 最近一直在看游双的《高性能Linux服务器编程》一书，下载链接： http://download.csdn.net/detail/analogous_love/9673008\n书上是这么介绍Reactor模式的：\n按照这个思路，我写个简单的练习：\n/** *@desc: 用reactor模式练习服务器程序，main.cpp *@author: zhangyl *@date: 2016.11.23 */ #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; //for htonl() and htons() #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; #include \u0026lt;signal.h\u0026gt; //for signal() #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;semaphore.h\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;sstream\u0026gt; #include \u0026lt;iomanip\u0026gt; //for std::setw()/setfill() #include \u0026lt;stdlib.h\u0026gt; #define WORKER_THREAD_NUM 5 #define min(a, b) ((a \u0026lt;= b) ? (a) : (b)) int g_epollfd = 0; bool g_bStop = false; int g_listenfd = 0; pthread_t g_acceptthreadid = 0; pthread_t g_threadid[WORKER_THREAD_NUM] = { 0 }; pthread_cond_t g_acceptcond; pthread_mutex_t g_acceptmutex; pthread_cond_t g_cond /*= PTHREAD_COND_INITIALIZER*/; pthread_mutex_t g_mutex /*= PTHREAD_MUTEX_INITIALIZER*/; pthread_mutex_t g_clientmutex; std::list\u0026lt;int\u0026gt; g_listClients; void prog_exit(int signo) { ::signal(SIGINT, SIG_IGN); //::signal(SIGKILL, SIG_IGN);//该信号不能被阻塞、处理或者忽略 ::signal(SIGTERM, SIG_IGN); std::cout \u0026lt;\u0026lt; \u0026#34;program recv signal \u0026#34; \u0026lt;\u0026lt; signo \u0026lt;\u0026lt; \u0026#34; to exit.","title":"Reactor模式"},{"content":"业务数据处理一定要单独开线程吗 在 《one thread one loop 思想》一文我们介绍了一个 loop 的主要结构一般如下所示：\nwhile (!m_bQuitFlag) { epoll_or_select_func(); handle_io_events(); handle_other_things(); } 对于一些业务逻辑处理比较简单、不会太耗时的应用来说，handle_io_events() 方法除了收发数据也可以直接用来直接做业务的处理，即其结构如下：\nvoid handle_io_events() { //收发数据 recv_or_send_data(); //解包并处理数据 decode_packages_and_process(); } 其中 recv_or_send_data() 方法中调用 send/recv API 进行实际的网络数据收发。以收数据为例，收完数据存入接收缓冲区后，接下来进行解包处理，然后进行业务处理，例如一个登陆数据包，其业务就是验证登陆的账户密码是否正确、记录其登陆行为等等。从程序函数调用堆栈来看，这些业务处理逻辑其实是直接在网络收发数据线程中处理的。我的意思是：网络线程调用 handle_io_events() 方法，handle_io_events() 方法调用 decode_packages_and_process() 方法，decode_packages_and_process() 方法做具体的业务逻辑处理。\n需要注意的是，为了让网络层与业务层脱耦，网络层中通常会提供一些回调函数的接口，这些回调函数我们将其指向具体的业务处理函数。以 libevent 网络库的用法为例：\nint main(int argc, char **argv) { struct event_base *base; struct evconnlistener *listener; struct event *signal_event; struct sockaddr_in sin; base = event_base_new(); memset(\u0026amp;sin, 0, sizeof(sin)); sin.sin_family = AF_INET; sin.sin_port = htons(PORT); //listener_cb是我们自定义回调函数 listener = evconnlistener_new_bind(base, listener_cb, (void *)base, LEV_OPT_REUSEABLE|LEV_OPT_CLOSE_ON_FREE, -1, (struct sockaddr*)\u0026amp;sin, sizeof(sin)); if (!listener) { fprintf(stderr, \u0026#34;Could not create a listener!\\n\u0026#34;); return 1; } //signal_cb是我们自定义回调函数 signal_event = evsignal_new(base, SIGINT, signal_cb, (void *)base); if (!signal_event || event_add(signal_event, NULL)\u0026lt;0) { fprintf(stderr, \u0026#34;Could not create/add a signal event!\\n\u0026#34;); return 1; } //启动loop event_base_dispatch(base); evconnlistener_free(listener); event_free(signal_event); event_base_free(base); printf(\u0026#34;done\\n\u0026#34;); return 0; } 上述代码根据 libevent 自带的 helloworld 示例修改而来，其中 listener_cb 和 signal_cb 是自定义的回调函数，有相应的事件触发后，libevent 的事件循环会调用我们设置的回调，在这些回调函数中，我们可以编写自己的业务逻辑代码。\n这种基本的服务器结构，我们可以绘制成如下流程图：\n这是这个结构的最基本逻辑，在这基础上可以延伸出很多变体。不知道读者有没有发现，上述流程图中第三步解包和业务逻辑处理这一步中（位于 handle_io_events() 中的 decode_packages_and_process() 方法中），如果业务逻辑处理过程比较耗时（例如，从数据库取大量数据、写文件），那么会导致 网络线程在这个步骤停留时间很长，导致很久以后才能执行下一次循环，影响网络数据的检测和收发，最终导致整个程序的效率低下。\n因此，对于这种情形，我们需要将业务处理逻辑单独拆出来交给另外的业务工作线程处理，业务工作线程可以是一个线程池，这个过程业务数据从网络线程组流向业务线程组。\n这样的程序结构图如下图所示：\n上图中，对于网络线程将业务数据包交给业务线程，可以使用一个共享的业务数据队列来实现，此时网络线程是生产者，业务线程从业务数据队列中取出任务去处理，业务线程是消费者。业务线程处理完成后如果需要将结果数据发出去，则再将数据交给网络线程。这里处理后的数据从业务线程再次流向网络线程，那么如何将数据从业务线程交给网络线程呢？这里以发数据为例，一般有三种方法：\n方法一\n直接调用相应的的发数据的方法，如果你的网络线程本身也会调用这些发数据的方法，那么此时就可能会出现网络线程和业务线程同时对发方法进行调用，相当于多个线程同时调用 socket send 函数，这样可能会导致同一个连接上的数据顺序有问题，此时的做法时，利用锁机制，同一时刻只有一个线程可以调用 socket send 方法。这里给出一段伪代码，假设 TcpConnection 对象表示某路连接，无论网络线程还是业务线程处理完数据后需要发送数据，则使用：\nvoid TcpConnection::sendData(const std::string\u0026amp; data) { //加上锁 std::lock_guard\u0026lt;std::mutex\u0026gt; scoped_lock(m_mutexForConnection); //在这里调用 send } 方法一的做法在设计上来说，存在让人不满意的地方，即数据发送应该属于网络层自己的事情，而不是其他模块（这里指的是业务线程）强行抢夺过来越俎代庖。\n方法二\n前面章节介绍了存在定时器结构的情况，网络线程结构变成如下流程：\nwhile (!m_bQuitFlag) { check_and_handle_timers(); epoll_or_select_func(); handle_io_events(); } 业务线程可以将需要发送的数据放入另外一个共享区域中（例如相应的 TcpConnection 对象的一个成员变量中），定时器定时从这个共享区域取出来，再发送出去，这种方案的优点是网络线程做了它该做的事情，缺点是需要添加定时器，让程序逻辑变得复杂，且定时器是每隔一段时间才会触发，发送的数据可能会有一定的延迟。\n方法三\n利用线程执行流中的 handle_other_things() 方法，再来看下前面章节中介绍的基本结构：\nwhile (!m_bQuitFlag) { epoll_or_select_func(); handle_io_events(); handle_other_things(); } 我们在《one thread one loop 思想》章节介绍了 handle_other_things() 函数可以做一些“其他事情”，这个函数可以在需要执行时通过前面章节介绍的唤醒机制立即被唤醒执行。业务线程将数据放入某个共享区域中（这一步和方法二介绍的一样），然后添加 \u0026ldquo;other_things\u0026rdquo; ，在 handle_other_things() 中执行数据的发送。\n如果读者能清晰明白地看到这里，说明您大致明白了一个不错的服务器框架是怎么回事了。上面介绍的服务器结构是目前主流的基于 Reactor 模式的服务程序的通用结构，例如 libevent、libuv。\n如果读者有兴趣，咱们可以再进一步深入讨论一下。\n实际应用中，很多程序的业务逻辑处理其实是不耗时的，也就是说这些业务逻辑处理速度很快。由于 CPU 核数有限，当线程数量超过 CPU 数量时，各个线程（网络线程和业务线程）也不是真正地并行执行，那么即使开了一组业务线程也不一定能真正地并发执行，而业务逻辑处理并不耗时，不会影响网络线程的执行效率，那么我们不如就在网络线程里面直接处理。\n上文介绍了在 handle_io_events() 方法中直接处理，如果处理的业务逻辑会产生新的其他任务，那么我们可以投递 \u0026ldquo;other_things\u0026rdquo;，最终交给 handle_other_things() 方法来处理。此时的服务器程序结构如下：\n特别说明一下：这种方式仅限于 handle_io_events() 或 handle_other_things() 里面不会有耗时的逻辑，才可以替代专门开业务线程，如果有耗时操作还得老老实实单独开业务线程。虽然线程数量超过 CPU 数量时，各个线程不会得到真正的并行，但那是操作系统线程调度的事情了，应用层开发不必关心这点。\n","permalink":"https://haokiu.com/blog/d7e436585f754029be5279a858049912/","summary":"业务数据处理一定要单独开线程吗 在 《one thread one loop 思想》一文我们介绍了一个 loop 的主要结构一般如下所示：\nwhile (!m_bQuitFlag) { epoll_or_select_func(); handle_io_events(); handle_other_things(); } 对于一些业务逻辑处理比较简单、不会太耗时的应用来说，handle_io_events() 方法除了收发数据也可以直接用来直接做业务的处理，即其结构如下：\nvoid handle_io_events() { //收发数据 recv_or_send_data(); //解包并处理数据 decode_packages_and_process(); } 其中 recv_or_send_data() 方法中调用 send/recv API 进行实际的网络数据收发。以收数据为例，收完数据存入接收缓冲区后，接下来进行解包处理，然后进行业务处理，例如一个登陆数据包，其业务就是验证登陆的账户密码是否正确、记录其登陆行为等等。从程序函数调用堆栈来看，这些业务处理逻辑其实是直接在网络收发数据线程中处理的。我的意思是：网络线程调用 handle_io_events() 方法，handle_io_events() 方法调用 decode_packages_and_process() 方法，decode_packages_and_process() 方法做具体的业务逻辑处理。\n需要注意的是，为了让网络层与业务层脱耦，网络层中通常会提供一些回调函数的接口，这些回调函数我们将其指向具体的业务处理函数。以 libevent 网络库的用法为例：\nint main(int argc, char **argv) { struct event_base *base; struct evconnlistener *listener; struct event *signal_event; struct sockaddr_in sin; base = event_base_new(); memset(\u0026amp;sin, 0, sizeof(sin)); sin.sin_family = AF_INET; sin.sin_port = htons(PORT); //listener_cb是我们自定义回调函数 listener = evconnlistener_new_bind(base, listener_cb, (void *)base, LEV_OPT_REUSEABLE|LEV_OPT_CLOSE_ON_FREE, -1, (struct sockaddr*)\u0026amp;sin, sizeof(sin)); if (!listener) { fprintf(stderr, \u0026#34;Could not create a listener!\\n\u0026#34;); return 1; } //signal_cb是我们自定义回调函数 signal_event = evsignal_new(base, SIGINT, signal_cb, (void *)base); if (!","title":"业务数据处理一定要单独开线程吗"},{"content":"主线程与工作线程的分工 服务器端为了能流畅处理多个客户端链接，一般在某个线程A里面accept新的客户端连接并生成新连接的socket fd，然后将这些新连接的socketfd给另外开的数个工作线程B1、B2、B3、B4，这些工作线程处理这些新连接上的网络IO事件（即收发数据），同时，还处理系统中的另外一些事务。这里我们将线程A称为主线程，B1、B2、B3、B4等称为工作线程。工作线程的代码框架一般如下：\nwhile (!m_bQuit) { epoll_or_select_func(); handle_io_events(); handle_other_things(); } 在epoll_or_select_func()中通过select()或者poll/epoll()去检测socket fd上的io事件，若存在这些事件则下一步handle_io_events()来处理这些事件（收发数据），做完之后可能还要做一些系统其他的任务，即调用handle_other_things()。\n这样做有三个好处：\n线程A只需要处理新连接的到来即可，不用处理网络IO事件。由于网络IO事件处理一般相对比较慢，如果在线程A里面既处理新连接又处理网络IO，则可能由于线程忙于处理IO事件，而无法及时处理客户端的新连接，这是很不好的。\n线程A接收的新连接，可以根据一定的负载均衡原则将新的socket fd分配给工作线程。常用的算法，比如round robin，即轮询机制，即，假设不考虑中途有连接断开的情况，一个新连接来了分配给B1，又来一个分配给B2，再来一个分配给B3，再来一个分配给B4。如此反复，也就是说线程A记录了各个工作线程上的socket fd数量，这样可以最大化地来平衡资源，避免一些工作线程“忙死”，另外一些工作线程“闲死”的现象。\n即使工作线程不满载的情况下，也可以让工作线程做其他的事情。比如现在有四个工作线程，但只有三个连接。那么线程B4就可以在handle_other_thing()做一些其他事情。\n下面讨论一个很重要的效率问题：\n在上述while循环里面，epoll_or_selec_func()中的epoll_wait/poll/select等函数一般设置了一个超时时间。如果设置超时时间为0，那么在没有任何网络IO时间和其他任务处理的情况下，这些工作线程实际上会空转，白白地浪费cpu时间片。如果设置的超时时间大于0，在没有网络IO时间的情况，epoll_wait/poll/select仍然要挂起指定时间才能返回，导致handle_other_thing()不能及时执行，影响其他任务不能及时处理，也就是说其他任务一旦产生，其处理起来具有一定的延时性。这样也不好。那如何解决该问题呢？\n其实我们想达到的效果是，如果没有网络IO时间和其他任务要处理，那么这些工作线程最好直接挂起而不是空转；如果有其他任务要处理，这些工作线程要立刻能处理这些任务而不是在epoll_wait/poll/selec挂起指定时间后才开始处理这些任务。\n我们采取如下方法来解决该问题，以linux为例，不管epoll_fd上有没有文件描述符fd，我们都给它绑定一个默认的fd，这个fd被称为唤醒fd。当我们需要处理其他任务的时候，向这个唤醒fd上随便写入1个字节的，这样这个fd立即就变成可读的了，epoll_wait()/poll()/select()函数立即被唤醒，并返回，接下来马上就能执行handle_other_thing()，其他任务得到处理。反之，没有其他任务也没有网络IO事件时，epoll_or_select_func()就挂在那里什么也不做。\n这个唤醒fd，在linux平台上可以通过以下几种方法实现：\n管道pipe，创建一个管道，将管道绑定到epoll_fd上。需要时，向管道一端写入一个字节，工作线程立即被唤醒。\nlinux 2.6新增的eventfd：\nint eventfd(unsigned int initval, int flags); 步骤也是一样，将生成的eventfd绑定到epoll_fd上。需要时，向这个eventfd上写入一个字节，工作线程立即被唤醒。\n第三种方法最方便。即linux特有的socketpair，socketpair是一对相互连接的socket，相当于服务器端和客户端的两个端点，每一端都可以读写数据。 int socketpair(int domain, int type, int protocol, int sv[2]); 调用这个函数返回的两个socket句柄就是sv[0]，和sv[1]，在一个其中任何一个写入字节，在另外一个收取字节。\n将收取的字节的socket绑定到epoll_fd上。需要时，向另外一个写入的socket上写入一个字节，工作线程立即被唤醒。如果是使用socketpair，那么domain参数一定要设置成AFX_UNIX。\n由于在windows，select函数只支持检测socket这一种fd，所以Windows上一般只能用方法3的原理。而且需要手动创建两个socket，然后一个连接另外一个，将读取的那一段绑定到select的fd上去。这在写跨两个平台代码时，需要注意的地方。\n","permalink":"https://haokiu.com/blog/450c6c7995774bec88a383c0ce41cfdc/","summary":"主线程与工作线程的分工 服务器端为了能流畅处理多个客户端链接，一般在某个线程A里面accept新的客户端连接并生成新连接的socket fd，然后将这些新连接的socketfd给另外开的数个工作线程B1、B2、B3、B4，这些工作线程处理这些新连接上的网络IO事件（即收发数据），同时，还处理系统中的另外一些事务。这里我们将线程A称为主线程，B1、B2、B3、B4等称为工作线程。工作线程的代码框架一般如下：\nwhile (!m_bQuit) { epoll_or_select_func(); handle_io_events(); handle_other_things(); } 在epoll_or_select_func()中通过select()或者poll/epoll()去检测socket fd上的io事件，若存在这些事件则下一步handle_io_events()来处理这些事件（收发数据），做完之后可能还要做一些系统其他的任务，即调用handle_other_things()。\n这样做有三个好处：\n线程A只需要处理新连接的到来即可，不用处理网络IO事件。由于网络IO事件处理一般相对比较慢，如果在线程A里面既处理新连接又处理网络IO，则可能由于线程忙于处理IO事件，而无法及时处理客户端的新连接，这是很不好的。\n线程A接收的新连接，可以根据一定的负载均衡原则将新的socket fd分配给工作线程。常用的算法，比如round robin，即轮询机制，即，假设不考虑中途有连接断开的情况，一个新连接来了分配给B1，又来一个分配给B2，再来一个分配给B3，再来一个分配给B4。如此反复，也就是说线程A记录了各个工作线程上的socket fd数量，这样可以最大化地来平衡资源，避免一些工作线程“忙死”，另外一些工作线程“闲死”的现象。\n即使工作线程不满载的情况下，也可以让工作线程做其他的事情。比如现在有四个工作线程，但只有三个连接。那么线程B4就可以在handle_other_thing()做一些其他事情。\n下面讨论一个很重要的效率问题：\n在上述while循环里面，epoll_or_selec_func()中的epoll_wait/poll/select等函数一般设置了一个超时时间。如果设置超时时间为0，那么在没有任何网络IO时间和其他任务处理的情况下，这些工作线程实际上会空转，白白地浪费cpu时间片。如果设置的超时时间大于0，在没有网络IO时间的情况，epoll_wait/poll/select仍然要挂起指定时间才能返回，导致handle_other_thing()不能及时执行，影响其他任务不能及时处理，也就是说其他任务一旦产生，其处理起来具有一定的延时性。这样也不好。那如何解决该问题呢？\n其实我们想达到的效果是，如果没有网络IO时间和其他任务要处理，那么这些工作线程最好直接挂起而不是空转；如果有其他任务要处理，这些工作线程要立刻能处理这些任务而不是在epoll_wait/poll/selec挂起指定时间后才开始处理这些任务。\n我们采取如下方法来解决该问题，以linux为例，不管epoll_fd上有没有文件描述符fd，我们都给它绑定一个默认的fd，这个fd被称为唤醒fd。当我们需要处理其他任务的时候，向这个唤醒fd上随便写入1个字节的，这样这个fd立即就变成可读的了，epoll_wait()/poll()/select()函数立即被唤醒，并返回，接下来马上就能执行handle_other_thing()，其他任务得到处理。反之，没有其他任务也没有网络IO事件时，epoll_or_select_func()就挂在那里什么也不做。\n这个唤醒fd，在linux平台上可以通过以下几种方法实现：\n管道pipe，创建一个管道，将管道绑定到epoll_fd上。需要时，向管道一端写入一个字节，工作线程立即被唤醒。\nlinux 2.6新增的eventfd：\nint eventfd(unsigned int initval, int flags); 步骤也是一样，将生成的eventfd绑定到epoll_fd上。需要时，向这个eventfd上写入一个字节，工作线程立即被唤醒。\n第三种方法最方便。即linux特有的socketpair，socketpair是一对相互连接的socket，相当于服务器端和客户端的两个端点，每一端都可以读写数据。 int socketpair(int domain, int type, int protocol, int sv[2]); 调用这个函数返回的两个socket句柄就是sv[0]，和sv[1]，在一个其中任何一个写入字节，在另外一个收取字节。\n将收取的字节的socket绑定到epoll_fd上。需要时，向另外一个写入的socket上写入一个字节，工作线程立即被唤醒。如果是使用socketpair，那么domain参数一定要设置成AFX_UNIX。\n由于在windows，select函数只支持检测socket这一种fd，所以Windows上一般只能用方法3的原理。而且需要手动创建两个socket，然后一个连接另外一个，将读取的那一段绑定到select的fd上去。这在写跨两个平台代码时，需要注意的地方。","title":"主线程与工作线程的分工"},{"content":"写给那些傻傻想做服务器开发的朋友 很久以前看过一篇标题为《写给那些傻傻的，想做服务器开发的应届生》文章，无意中看到知乎上也对这篇文章进行了激烈的讨论。下面谈谈我的看法。\n写在前面的话 我在七八年前就看过这篇文章，那个时候我还是一名学生，它深深地影响了我学生时代以及后来的人生轨迹。(所以原文绝对不是首次发表于2015年，我猜想可能是后来的作者2015年修改了原作者的一些内容，并增加了一些自己的东西，让它\u0026quot;与时俱进\u0026quot;)。我学生时代深受这篇文章的影响，以至于我印象中的服务器开发的样子和地位就是这篇文章中所描述的。\n我的工作经历 我毕业的时候，一心想做出Windows C/C++客户端开发，当时为了做这个开发放弃了我熟悉的flash编程和web开发，当然薪资也是比较低的。做了几年Windows客户端后，我毅然以一定的代价转到了linux服务器开发。到今天为止，大致做过股票资讯、交易系统、游戏服务器、即时通讯系统和直播类型的服务器，架构的能力也由最初的千人到后来的百万在线。我从不后悔我当初转行服务器开发，甚至很庆幸当初的抉择，然而我可能更喜欢的还是客户端开发。\n《写给那些傻傻的，想做服务器开发的应届生》一文中的有些观点，根据我的经历，我不敢赞同，或者说我的感受与之大相径庭。\n加班的情况 首先说下加班的情况，不管是大公司还是小公司，由于现在的各种测试、预警机制、监控策略和公司发布流程的不断完善，一个月内经常为各种服务器bug、和应急的情况加班的现状已经大为改善不少，当然偶尔发版或者赶项目加班还是有的，不过一个月的频率也就那么一两次。如果你们团队频繁地为了修正紧急bug、解决服务器稳定性问题，那么你们真要好好考虑你们的方法是不是有问题了。\n服务器开发与轮子 其次，服务器开发，不仅仅如文中所说的，利用或者组装各种轮子。一个稳定的服务器架构，必须是建立在设计师良好的基础知识和见多识广的经验基础上，即使是使用现有的轮子，也是对这个轮子足够熟悉的基础上，才能让轮子最大地适用自己的公司的业务。也就是说，服务器核心项目人员虽然不一定要造轮子，但一定要具备造轮子的能力。开源的东西好用是好用，但是要么不出问题，一旦出问题往往很难修改。我们去年做类似“冲顶大会”、“百万英雄”这类直播答题应用，由于这类游戏是从美国HQ刮过来的风，国内各大公司为了迅速抢占市场与用户，都想着要比别人早点做出来上线，所以我们公司当时deadline压得比较紧。我们那个时候，最不想看到的人就是项目经理，天天跟着我们后面催项目的进度。项目进度紧不说，另外还有一个技术挑战，由于节目比较火热，同一个房间里面可能会达到百万人同时在线，而这百万人可能同时都会发弹幕消息。假设某个时刻，房间里面有n个人，某个人发一条消息，其他n-1个人收到，服务器需要推送n-1次。如果n个人同时发消息，那么服务器同一时间就要推送n*n，如果n等于1百万的时候，那么单秒的数据量将非常恐怖，这个是我们需要解决的一个技术难题，解决目标是最少延迟的情况下，弹幕最多的送达率；另外一个难题就是，保证出题和答案不能有太多的延时（小于1秒），并在用户给出答案后，服务器能够迅速统计出答案结果并应答客户端。（没办法，所以此时主持人的作用就发挥了，万一延迟太厉害，主持人可以和观众各种唠嗑，当然这是下下策，如果频繁出现这种情况，领导的脸色肯定也不好看，我们做技术的脸上也没有光彩。）那段时间基本上是周六周日都要加班，甚至连周末都可能要到凌晨才能回去。注意：我把这段经历并没有放在上面的关于服务器开发是否频繁地加班的栏目下，这里我想说明的并不是服务器开发要经常加班，我想说的是，如果你平常只会用轮子，而不注重基础内功的修养，这种场景你是很难应对的，首先是单机服务性能要做到极致，其次是多个服务之间的高效配合。很多人可能觉得这种场景也不难，甚至有的人号称单机服务就能解决，这些都是站着说话不腰疼了。像熊猫tv的“冲顶大会”和西瓜视频的“百万英雄”前几次的答题活动中，也出现了服务中断或者题目延迟厉害，甚至“百万英雄”还出现过一次因技术问题答题活动被迫延期的事故。\n技术与产品思维 接着说下，技术和产品方面的，服务器开发与客户端开发的思维方式和理念其实是不一样的，如果说客户端产品是一个产品的脸面，那么服务器端就是产品的灵魂。这里可能比喻有点不恰当，与客户端开发相比，优秀的服务器开发应该尽量在单机服务上的性能做到极致，必须尽量利用少的资源给尽可能多的客户端服务（在资源总量有限的情况下，你为单个客户端服务使用的资源越少，你才可能为越多的客户服务）。而服务器开发必须有条不紊地处理与每个客户端的交互，不能纠结或把资源花费在某一个客户端上。但是客户端不一样，客户端只需要管理好自己的一亩三分地就可以了，而且客户端的大多数逻辑和细节在界面（UI）逻辑上。但是我不赞成文中作者所说的客户端代码比服务器代码少很多，相反，我经历过的项目，都是客户度代码比服务器代码多很多。因为客户端代码往往有大量的界面逻辑，如果服务器端没有UI的话，其核心除了网路通信部分，剩下的就是各种业务逻辑（包括存储逻辑，也就是业务逻辑服务器和客户端都有，但是客户端还有界面逻辑）。而从开发团队的人数配比上来说，一般单个端（比如pc、安卓、ios中的一端）的人数要小于服务器开发人员的数量，因为一般一个高级客户端开发，往往可以一个人搞定一个客户端，但是一般很少有一个高级服务器开发可以单独搞定一套服务开发的。（说的是通常情形，请不要走极端）。服务器开发的核心字眼体现在“服务”上，如何为客户端提供稳定的、高效的服务，这是关键的地方。这里“稳定”也包括容灾容错。大凡有一定规模的用户群体的产品，如果服务器不稳定，那后果将是灾难性的，试想QQ或者微信服务器中断一两个小时，后果会怎样？而客户端更侧重的就是产品的细节、用户的体验，当然尽管有些用户体验可能是由服务器端决定的，但是最终还是由客户端反映出来。我不赞同文章中说，客户端更能积累除了技术以外的其他知识，服务器开发也一样的，不管是客户端还是服务器，只有具有产品思维的开发才是好的开发，而功能的设计与规划服务器端的开发在时间点上一般先于客户端开发的。而具体的功能点，也是需要服务器开发人员与产品人员乃至客户沟通的。\n薪资方面 最后说下，薪资方面。一般大于两年且同样的工作年限的服务器开发人员要比客户端开发人员高至少三分之一左右。当然不排除一些非常优秀的客户端开发人员可能不在这个规则内。\n结语 总结起来，选择了哪条路就选择了什么样的生活。做服务器开发的可以在高并发、高可用方向进一步努力，而做客户端开发可以在用户体验、设计细节方面下功夫。不管怎样，都是我们想要的生活，那里倾洒了我们的汗水，也收获了我们自己的成就感。\n","permalink":"https://haokiu.com/blog/7f969a868ee54e84982aa97c89e7cdbd/","summary":"写给那些傻傻想做服务器开发的朋友 很久以前看过一篇标题为《写给那些傻傻的，想做服务器开发的应届生》文章，无意中看到知乎上也对这篇文章进行了激烈的讨论。下面谈谈我的看法。\n写在前面的话 我在七八年前就看过这篇文章，那个时候我还是一名学生，它深深地影响了我学生时代以及后来的人生轨迹。(所以原文绝对不是首次发表于2015年，我猜想可能是后来的作者2015年修改了原作者的一些内容，并增加了一些自己的东西，让它\u0026quot;与时俱进\u0026quot;)。我学生时代深受这篇文章的影响，以至于我印象中的服务器开发的样子和地位就是这篇文章中所描述的。\n我的工作经历 我毕业的时候，一心想做出Windows C/C++客户端开发，当时为了做这个开发放弃了我熟悉的flash编程和web开发，当然薪资也是比较低的。做了几年Windows客户端后，我毅然以一定的代价转到了linux服务器开发。到今天为止，大致做过股票资讯、交易系统、游戏服务器、即时通讯系统和直播类型的服务器，架构的能力也由最初的千人到后来的百万在线。我从不后悔我当初转行服务器开发，甚至很庆幸当初的抉择，然而我可能更喜欢的还是客户端开发。\n《写给那些傻傻的，想做服务器开发的应届生》一文中的有些观点，根据我的经历，我不敢赞同，或者说我的感受与之大相径庭。\n加班的情况 首先说下加班的情况，不管是大公司还是小公司，由于现在的各种测试、预警机制、监控策略和公司发布流程的不断完善，一个月内经常为各种服务器bug、和应急的情况加班的现状已经大为改善不少，当然偶尔发版或者赶项目加班还是有的，不过一个月的频率也就那么一两次。如果你们团队频繁地为了修正紧急bug、解决服务器稳定性问题，那么你们真要好好考虑你们的方法是不是有问题了。\n服务器开发与轮子 其次，服务器开发，不仅仅如文中所说的，利用或者组装各种轮子。一个稳定的服务器架构，必须是建立在设计师良好的基础知识和见多识广的经验基础上，即使是使用现有的轮子，也是对这个轮子足够熟悉的基础上，才能让轮子最大地适用自己的公司的业务。也就是说，服务器核心项目人员虽然不一定要造轮子，但一定要具备造轮子的能力。开源的东西好用是好用，但是要么不出问题，一旦出问题往往很难修改。我们去年做类似“冲顶大会”、“百万英雄”这类直播答题应用，由于这类游戏是从美国HQ刮过来的风，国内各大公司为了迅速抢占市场与用户，都想着要比别人早点做出来上线，所以我们公司当时deadline压得比较紧。我们那个时候，最不想看到的人就是项目经理，天天跟着我们后面催项目的进度。项目进度紧不说，另外还有一个技术挑战，由于节目比较火热，同一个房间里面可能会达到百万人同时在线，而这百万人可能同时都会发弹幕消息。假设某个时刻，房间里面有n个人，某个人发一条消息，其他n-1个人收到，服务器需要推送n-1次。如果n个人同时发消息，那么服务器同一时间就要推送n*n，如果n等于1百万的时候，那么单秒的数据量将非常恐怖，这个是我们需要解决的一个技术难题，解决目标是最少延迟的情况下，弹幕最多的送达率；另外一个难题就是，保证出题和答案不能有太多的延时（小于1秒），并在用户给出答案后，服务器能够迅速统计出答案结果并应答客户端。（没办法，所以此时主持人的作用就发挥了，万一延迟太厉害，主持人可以和观众各种唠嗑，当然这是下下策，如果频繁出现这种情况，领导的脸色肯定也不好看，我们做技术的脸上也没有光彩。）那段时间基本上是周六周日都要加班，甚至连周末都可能要到凌晨才能回去。注意：我把这段经历并没有放在上面的关于服务器开发是否频繁地加班的栏目下，这里我想说明的并不是服务器开发要经常加班，我想说的是，如果你平常只会用轮子，而不注重基础内功的修养，这种场景你是很难应对的，首先是单机服务性能要做到极致，其次是多个服务之间的高效配合。很多人可能觉得这种场景也不难，甚至有的人号称单机服务就能解决，这些都是站着说话不腰疼了。像熊猫tv的“冲顶大会”和西瓜视频的“百万英雄”前几次的答题活动中，也出现了服务中断或者题目延迟厉害，甚至“百万英雄”还出现过一次因技术问题答题活动被迫延期的事故。\n技术与产品思维 接着说下，技术和产品方面的，服务器开发与客户端开发的思维方式和理念其实是不一样的，如果说客户端产品是一个产品的脸面，那么服务器端就是产品的灵魂。这里可能比喻有点不恰当，与客户端开发相比，优秀的服务器开发应该尽量在单机服务上的性能做到极致，必须尽量利用少的资源给尽可能多的客户端服务（在资源总量有限的情况下，你为单个客户端服务使用的资源越少，你才可能为越多的客户服务）。而服务器开发必须有条不紊地处理与每个客户端的交互，不能纠结或把资源花费在某一个客户端上。但是客户端不一样，客户端只需要管理好自己的一亩三分地就可以了，而且客户端的大多数逻辑和细节在界面（UI）逻辑上。但是我不赞成文中作者所说的客户端代码比服务器代码少很多，相反，我经历过的项目，都是客户度代码比服务器代码多很多。因为客户端代码往往有大量的界面逻辑，如果服务器端没有UI的话，其核心除了网路通信部分，剩下的就是各种业务逻辑（包括存储逻辑，也就是业务逻辑服务器和客户端都有，但是客户端还有界面逻辑）。而从开发团队的人数配比上来说，一般单个端（比如pc、安卓、ios中的一端）的人数要小于服务器开发人员的数量，因为一般一个高级客户端开发，往往可以一个人搞定一个客户端，但是一般很少有一个高级服务器开发可以单独搞定一套服务开发的。（说的是通常情形，请不要走极端）。服务器开发的核心字眼体现在“服务”上，如何为客户端提供稳定的、高效的服务，这是关键的地方。这里“稳定”也包括容灾容错。大凡有一定规模的用户群体的产品，如果服务器不稳定，那后果将是灾难性的，试想QQ或者微信服务器中断一两个小时，后果会怎样？而客户端更侧重的就是产品的细节、用户的体验，当然尽管有些用户体验可能是由服务器端决定的，但是最终还是由客户端反映出来。我不赞同文章中说，客户端更能积累除了技术以外的其他知识，服务器开发也一样的，不管是客户端还是服务器，只有具有产品思维的开发才是好的开发，而功能的设计与规划服务器端的开发在时间点上一般先于客户端开发的。而具体的功能点，也是需要服务器开发人员与产品人员乃至客户沟通的。\n薪资方面 最后说下，薪资方面。一般大于两年且同样的工作年限的服务器开发人员要比客户端开发人员高至少三分之一左右。当然不排除一些非常优秀的客户端开发人员可能不在这个规则内。\n结语 总结起来，选择了哪条路就选择了什么样的生活。做服务器开发的可以在高并发、高可用方向进一步努力，而做客户端开发可以在用户体验、设计细节方面下功夫。不管怎样，都是我们想要的生活，那里倾洒了我们的汗水，也收获了我们自己的成就感。","title":"写给那些傻傻想做服务器开发的朋友"},{"content":"如何设计断线自动重连机制 在有连接依赖关系的服务与服务之间，或客户端与服务器之间，无论是出于方便使用、降低运维成本、提高工作效率（服务与服务之间），还是优化用户体验（客户端与服务器之间）自动重连机制通常都是一个非常重要的功能。\n情景一 对于一组服务之间，如果其中一些服务（主动连接方，下文以 A 代称）需要与另外一些服务（被连接方，下文以 B 代称）建立 TCP 长连接，如果 A 没有自动连接 B 的功能，那么在部署或者测试这些服务的时候，必须先启动 B，再启动 A，因为一旦先启动 A，A 此时去尝试连接 B（由于 B 还没有启动）会失败，之后 A 再也不会去连接 B了（即使随后 B 被启动了），从而导致整个系统不能正常工作。这是缺点一。\n情景二 即使部署或测试的时候，先启动了 B，再启动 A，A 与 B 之间的连接在运行期间内，可能由于网络波动等原因导致 A 与 B 之间连接断开，之后整个系统也不能再正常工作了。这是缺点二。\n情景三 如果我们想升级 B，更新完程序后，重启 B，也必须重启 A。如果这种依赖链比较长（例如 A 连接 B，B 连接 C，C 连接 D，D 连接 E，等等），那么更新某个程序的效率和成本会非常高。这是缺点三。\n情景四 对于客户端软件来说，如果因为用户的网络短暂故障导致客户端与服务器失去连接，等网络恢复后，较好的用户体验是客户端能检测到用户网络变化后，自动与服务器重连，以便用户能及时收到最新的消息。\n以上四个情景说明了断线自动重连功能的重要性，那如何去设计好的断线重连机制呢？\n重连本身的功能开发很简单，其实就是调用 socket 函数 connect 函数，不断去“重试”。这里的“重试”我使用了双引号，是为了说明重试的技巧非常有讲究：\n对于服务器端程序，例如 A 连接 B，如果连接不上，整个系统将无法工作，那么我们开发 A 服务时，重连的逻辑可以很简单，即 A 一旦发现与 B 断开了连接，就立即尝试与 B 重新连接，如果连接不上，隔一段时间再重试（一般设置为 3 秒或 5 秒即可），一直到连接成功为止。当然，期间可以不断发送报警邮件或者持续输出错误日志，来引起开发或者运维人员的尽快干预，以便尽早排查和解决连接不上的原因。 对于客户端软件，以上做法也是可以的，但是不是最优的。客户端所处的网络环境比服务器程序所处的网络环境一般要恶劣的多，等间隔的定时去重连，一般作用不大（例如用户拔掉了网线）。因此，对于客户端软件，一般出现断线，会尝试去重连，如果连接不上，会隔个比前一次时间更长的时间间隔去重连，例如这个时间间隔可以是 2 秒、4 秒、8 秒、16秒等等。但是，这样也存在一个问题，随着重连次数的变多，重连的时间间隔会越来越大（当然，你也可以设置一个最大重连时间间隔，之后恢复到之前较小的时间间隔）。如果网络此时已经恢复（例如用户重新插上网线），我们的程序需要等待一个很长的时间间隔（如 16 秒）才能恢复连接，这同样不利于用户体验。一般情况下，如果网络发生波动，我们的程序可以检测网络状态，如果网络状态恢复正常此时应该立即进行一次重连，而不是一成不变地按照设置的时间间隔去重连。 操作系统提供了检测网络状态变化的 API 函数，例如对于 Windows 可以使用 IsNetworkAlive() 函数去检测，对于 Android，网络变化时会发送消息类型是 WifiManager.NETWORK_STATE_CHANGED_ACTION 的广播通知。\n另外，还需要注意的是，如果客户端网络断开，一般会在界面某个地方显式地告诉用户当前连接状态，并提醒当前正在进行断线重连，且应该有一个可以让用户放弃断线重连或者立即进行一次断线重连的功能。\n综上所述，总结起来，对于服务器程序之间的重连可以设计成等时间间隔的定时重连，对于客户端程序要结合依次放大重连时间间隔、网络状态变化立即重连或用户主动发起重连这三个因素来设计。\n不需要重连的情形 不需要重连一般有以下情形：\n用户使用客户端主动放弃重连；\n因为一些业务上的规定，禁止客户端重连；\n举个例子，如果某个系统同一时刻同一个账户只允许登陆一个，某个账户在机器 A 上登陆，此时接着又在机器 B 上登陆，此时 A 将被服务器踢下线，那么此时 A 客户端的逻辑就应该禁止自动重连。\n技术上的断线重连和业务上的断线重连 这里说的技术上的重连，指的是调用 connect 函数连接，在实际开发中，大多数系统光有技术上的重连成功（即 connect 连接成功）是没有任何意义的，网络连接成功以后，接下来还得再次向服务器发送账号验证信息等等（如登陆数据包），只有这些数据验签成功后，才能算是真正的重连成功，这里说的发送账号验证信息并验签成功就是业务上的重连成功。复杂的系统可能会需要连续好几道验签流程。因此，我们在设计断线重连机制的时候，不仅要考虑技术上的重连，还要考虑业务上的重连。只有完整地包含这两个流程，才算是较优的断线自动重连功能。\n本节介绍的知识点主要是思路性的内容，一旦搞清楚了思路，技术上实现起来并不会存在什么困难，因此本节没有给出具体的代码示例。\n欢迎关注公众号『easyserverdev』，本公众号推崇基础学习与原理理解，不谈大而空的架构与技术术语，分享接地气的服务器开发实战技巧与项目经验，实实在在分享可用于实际编码的编程知识。同时，您也可以加入我的 QQ 群578019391。\n文章已于2019-08-12修改\n","permalink":"https://haokiu.com/blog/1469709fbebd462cb012819cdfb07156/","summary":"如何设计断线自动重连机制 在有连接依赖关系的服务与服务之间，或客户端与服务器之间，无论是出于方便使用、降低运维成本、提高工作效率（服务与服务之间），还是优化用户体验（客户端与服务器之间）自动重连机制通常都是一个非常重要的功能。\n情景一 对于一组服务之间，如果其中一些服务（主动连接方，下文以 A 代称）需要与另外一些服务（被连接方，下文以 B 代称）建立 TCP 长连接，如果 A 没有自动连接 B 的功能，那么在部署或者测试这些服务的时候，必须先启动 B，再启动 A，因为一旦先启动 A，A 此时去尝试连接 B（由于 B 还没有启动）会失败，之后 A 再也不会去连接 B了（即使随后 B 被启动了），从而导致整个系统不能正常工作。这是缺点一。\n情景二 即使部署或测试的时候，先启动了 B，再启动 A，A 与 B 之间的连接在运行期间内，可能由于网络波动等原因导致 A 与 B 之间连接断开，之后整个系统也不能再正常工作了。这是缺点二。\n情景三 如果我们想升级 B，更新完程序后，重启 B，也必须重启 A。如果这种依赖链比较长（例如 A 连接 B，B 连接 C，C 连接 D，D 连接 E，等等），那么更新某个程序的效率和成本会非常高。这是缺点三。\n情景四 对于客户端软件来说，如果因为用户的网络短暂故障导致客户端与服务器失去连接，等网络恢复后，较好的用户体验是客户端能检测到用户网络变化后，自动与服务器重连，以便用户能及时收到最新的消息。\n以上四个情景说明了断线自动重连功能的重要性，那如何去设计好的断线重连机制呢？\n重连本身的功能开发很简单，其实就是调用 socket 函数 connect 函数，不断去“重试”。这里的“重试”我使用了双引号，是为了说明重试的技巧非常有讲究：\n对于服务器端程序，例如 A 连接 B，如果连接不上，整个系统将无法工作，那么我们开发 A 服务时，重连的逻辑可以很简单，即 A 一旦发现与 B 断开了连接，就立即尝试与 B 重新连接，如果连接不上，隔一段时间再重试（一般设置为 3 秒或 5 秒即可），一直到连接成功为止。当然，期间可以不断发送报警邮件或者持续输出错误日志，来引起开发或者运维人员的尽快干预，以便尽早排查和解决连接不上的原因。 对于客户端软件，以上做法也是可以的，但是不是最优的。客户端所处的网络环境比服务器程序所处的网络环境一般要恶劣的多，等间隔的定时去重连，一般作用不大（例如用户拔掉了网线）。因此，对于客户端软件，一般出现断线，会尝试去重连，如果连接不上，会隔个比前一次时间更长的时间间隔去重连，例如这个时间间隔可以是 2 秒、4 秒、8 秒、16秒等等。但是，这样也存在一个问题，随着重连次数的变多，重连的时间间隔会越来越大（当然，你也可以设置一个最大重连时间间隔，之后恢复到之前较小的时间间隔）。如果网络此时已经恢复（例如用户重新插上网线），我们的程序需要等待一个很长的时间间隔（如 16 秒）才能恢复连接，这同样不利于用户体验。一般情况下，如果网络发生波动，我们的程序可以检测网络状态，如果网络状态恢复正常此时应该立即进行一次重连，而不是一成不变地按照设置的时间间隔去重连。 操作系统提供了检测网络状态变化的 API 函数，例如对于 Windows 可以使用 IsNetworkAlive() 函数去检测，对于 Android，网络变化时会发送消息类型是 WifiManager.NETWORK_STATE_CHANGED_ACTION 的广播通知。\n另外，还需要注意的是，如果客户端网络断开，一般会在界面某个地方显式地告诉用户当前连接状态，并提醒当前正在进行断线重连，且应该有一个可以让用户放弃断线重连或者立即进行一次断线重连的功能。\n综上所述，总结起来，对于服务器程序之间的重连可以设计成等时间间隔的定时重连，对于客户端程序要结合依次放大重连时间间隔、网络状态变化立即重连或用户主动发起重连这三个因素来设计。\n不需要重连的情形 不需要重连一般有以下情形：\n用户使用客户端主动放弃重连；\n因为一些业务上的规定，禁止客户端重连；\n举个例子，如果某个系统同一时刻同一个账户只允许登陆一个，某个账户在机器 A 上登陆，此时接着又在机器 B 上登陆，此时 A 将被服务器踢下线，那么此时 A 客户端的逻辑就应该禁止自动重连。","title":"如何设计断线自动重连机制"},{"content":"实例：一个服务器程序的架构介绍 本文将介绍我曾经做过的一个项目的服务器架构和服务器编程的一些重要细节。\n一、程序运行环境 操作系统：Centos 7.0\n编译器：gcc/g++ 4.8.3、cmake 2.8.11\nmysql数据库：5.5.47\n项目代码管理工具：Visual Studio 2013\n一、程序结构 该程序总共有 17 个线程，其中分为 9 个数据库工作线程 D 和一个日志线程 L，6 个普通工作线程 W，一个主线程 M。（以下会用这些字母来代指这些线程）\n（一）、数据库工作线程的用途 9 个数据库工作线程在线程启动之初，与 mysql 建立连接，也就是说每个线程都与 mysql 保持一路连接，共 9 个数据库连接。\n每个数据库工作线程同时存在两个任务队列，第一个队列 A 存放需要执行数据库增删查改操作的任务 sqlTask，第二个队列 B 存放 sqlTask 执行完成后的结果。sqlTask 执行完成后立即放入结果队列中，因而结果队列中任务也是一个个的需要执行的任务。大致伪代码如下：\nvoid db_thread_func() { while (!m_bExit) { if (NULL != (pTask = m_sqlTask.Pop())) { //从m_sqlTask中取出的任务先执行完成后，pTask将携带结果数据 pTask-\u0026gt;Execute(); //得到结果后，立刻将该任务放入结果任务队列 m_resultTask.Push(pTask); continue; } sleep(1000); }//end while-loop } 现在的问题来了：\n任务队列 A 中的任务从何而来，目前只有消费者，没有生产者，那么生产者是谁？ 任务队列 B 中的任务将去何方，目前只有生产者没有消费者。 这两个问题先放一会儿，等到后面我再来回答。\n（二）工作线程和主线程 在介绍主线程和工作线程具体做什么时，我们介绍下服务器编程中常常抽象出来的几个概念（这里以 tcp 连接为例）：\nTcpServer 即 Tcp 服务，服务器需要绑定ip地址和端口号，并在该端口号上侦听客户端的连接（往往由一个成员变量 TcpListener 来管理侦听细节）。所以一个 TcpServer 要做的就是这些工作。除此之外，每当有新连接到来时，TcpServer 需要接收新连接，当多个新连接存在时，TcpServer 需要有条不紊地管理这些连接：连接的建立、断开等，即产生和管理下文中说的 TcpConnection 对象。 一个连接对应一个 TcpConnection 对象，TcpConnection 对象管理着这个连接的一些信息：如连接状态、本端和对端的 ip 地址和端口号等。 数据通道对象 Channel，Channel 记录了 socket 的句柄，因而是一个连接上执行数据收发的真正执行者，Channel 对象一般作为 TcpConnection 的成员变量。 TcpSession 对象，是将 Channel 收取的数据进行解包，或者对准备好的数据进行装包，并传给 Channel 发送。 归纳起来：一个 TcpServer 依靠 TcpListener 对新连接的侦听和处理，依靠 TcpConnection 对象对连接上的数据进行管理，TcpConnection 实际依靠 Channel 对数据进行收发，依靠 TcpSession 对数据进行装包和解包。也就是说一个 TcpServer 存在一个 TcpListener，对应多个 TcpConnection，有几个TcpConnection 就有几个 TcpSession，同时也就有几个 Channel。\n以上说的 TcpServer、TcpListener、TcpConnection、Channel 和 TcpSession 是服务器框架的网络层。一个好的网络框架，应该做到与业务代码脱耦。即上层代码只需要拿到数据，执行业务逻辑，而不用关注数据的收发和网络数据包的封包和解包以及网络状态的变化（比如网络断开与重连）。\n拿数据的发送来说：\n当业务逻辑将数据交给 TcpSession，TcpSession 将数据装好包后（装包过程后可以有一些加密或压缩操作），交给 TcpConnection::SendData()，而TcpConnection::SendData() 实际是调用 Channel::SendData()，因为 Channel 含有 socket 句柄，所以 Channel::SendData() 真正调用send()/sendto()/write() 方法将数据发出去。\n对于数据的接收，稍微有一点不同：\n通过 select()/poll()/epoll() 等IO multiplex技术，确定好了哪些 TcpConnection 上有数据到来后，激活该 TcpConnection 的 Channel 对象去调用recv()/recvfrom()/read() 来收取数据。数据收到以后，将数据交由 TcpSession来处理，最终交给业务层。注意数据收取、解包乃至交给业务层是一定要分开的。我的意思是：最好不要解包并交给业务层和数据收取的逻辑放在一起。因为数据收取是 IO 操作，而解包和交给业务层是逻辑计算操作。IO 操作一般比逻辑计算要慢。到底如何安排要根据服务器业务来取舍，也就是说你要想好你的服务器程序的性能瓶颈在网络 IO 还是逻辑计算，即使是网络 IO，也可以分为上行操作和下行操作，上行操作即客户端发数据给服务器，下行即服务器发数据给客户端。有时候数据上行少，下行大。（如游戏服务器，一个 npc 移动了位置，上行是该客户端通知服务器自己最新位置，而下行确是服务器要告诉在场的每个客户端）。\n在我的文章《主线程与工作线程的分工》中介绍了，工作线程的流程：\nwhile (!m_bQuit) { epoll_or_select_func(); handle_io_events(); handle_other_things(); } 其中 epoll_or_select_func() 即是上文所说的通过 select()/poll()/epoll() 等 IO multiplex 技术，确定好了哪些 TcpConnection 上有数据到来。我的服务器代码中一般只会监测 socket 可读事件，而不会监测 socket 可写事件。至于如何发数据，文章后面会介绍。所以对于可读事件，以 epoll 为例，这里需要设置的标识位是：\nEPOLLIN 普通可读事件（当连接正常时，产生这个事件，recv()/read()函数返回收到的字节数；当连接关闭，这两个函数返回0，也就是说我们设置这个标识已经可以监测到新来数据和对端关闭事件） EPOLLRDHUP 对端关闭事件（linux man 手册上说这个事件可以监测对端关闭，但我实际调试时发送即使对端关闭也没触发这个事件，仍然是EPOLLIN，只不过此时调用recv()/read()函数，返回值会为0，所以实际项目中是否可以通过设置这个标识来监测对端关闭，仍然待考证） EPOLLPRI 带外数据 muduo 里面将 epoll_wait 的超时事件设置为 1 毫秒，我的另一个项目将 epoll_wait 超时时间设置为 10 毫秒。这两个数值供大家参考。\n这个项目中，工作线程和主线程都是上文代码中的逻辑，主线程监听侦听socket 上的可读事件，也就是监测是否有新连接来了。主线程和每个工作线程上都存在一个 epollfd。如果新连接来了，则在主线程的 handle_io_events() 中接受新连接。产生的新连接的socket句柄挂接到哪个线程的 epollfd 上呢？这里采取的做法是 round-robin 算法，即存在一个对象 CWorkerThreadManager 记录了各个工作线程上工作状态。伪码大致如下：\nvoid attach_new_fd(int newsocketfd) { workerthread = get_next_worker_thread(next); workerthread.attach_to_epollfd(newsocketfd); ++next; if (next \u0026gt; max_worker_thread_num) next = 0; } 即先从第一个工作线程的 epollfd 开始挂接新来 socket，接着累加索引，这样下次就是第二个工作线程了。如果所以超出工作线程数目，则从第一个工作重新开始。这里解决了新连接 socket “负载均衡”的问题。在实际代码中还有个需要注意的细节就是：epoll_wait 的函数中的 struct epoll_event 数量开始到底要设置多少个才合理？存在的顾虑是，多了浪费，少了不够用，我在曾经一个项目中直接用的是 4096：\nconst int EPOLL_MAX_EVENTS = 4096; const int dwSelectTimeout = 10000; struct epoll_event events[EPOLL_MAX_EVENTS]; int nfds = epoll_wait(m_fdEpoll, events, EPOLL_MAX_EVENTS, dwSelectTimeout / 1000); 我在陈硕的 muduo 网络库中发现作者才用了一个比较好的思路，即动态扩张数量：开始是 n 个，当发现有事件的 fd 数量已经到达 n 个后，将 struct epoll_event 数量调整成 2n 个，下次如果还不够，则变成 4n 个，以此类推，作者巧妙地利用 stl::vector 在内存中的连续性来实现了这种思路：\n//初始化代码 std::vector\u0026lt;struct epoll_event\u0026gt; events_(16); //线程循环里面的代码 while (m_bExit) { int numEvents = ::epoll_wait(epollfd_, \u0026amp;*events_.begin(), static_cast\u0026lt;int\u0026gt;(events_.size()), 1); if (numEvents \u0026gt; 0) { if (static_cast\u0026lt;size_t\u0026gt;(numEvents) == events_.size()) { events_.resize(events_.size() * 2); } } } 读到这里，你可能觉得工作线程所做的工作也不过就是调用 handle_io_events() 来接收网络数据，其实不然，工作线程也可以做程序业务逻辑上的一些工作。也就是在 handle_other_things() 里面。那如何将这些工作加到 handle_other_things() 中去做呢？写一个队列，任务先放入队列，再让 handle_other_things() 从队列中取出来做？我在该项目中也借鉴了muduo库的做法。即 handle_other_things() 中调用一系列函数指针，伪码如下：\nvoid do_other_things() { somefunc(); } //m_functors是一个stl::vector,其中每一个元素为一个函数指针 void somefunc() { for (size_t i = 0; i \u0026lt; m_functors.size(); ++i) { m_functors[i](); } m_functors.clear(); } 当任务产生时，只要我们将执行任务的函数 push_back 到 m_functors 这个 stl::vector 对象中即可。但是问题来了，如果是其他线程产生的任务，两个线程同时操作 m_functors，必然要加锁，这也会影响效率。muduo 是这样做的：\nvoid add_task(const Functor\u0026amp; cb) { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex_); m_functors.push_back(cb); } void do_task() { std::vector\u0026lt;Functor\u0026gt; functors; { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex_); functors.swap(m_functors); } for (size_t i = 0; i \u0026lt; functors.size(); ++i) { functors[i](); } } 看到没有，利用一个栈变量 functors 将 m_functors 中的任务函数指针倒换（swap）过来了，这样大大减小了对 m_functors 操作时的加锁粒度。前后变化：变化前，相当于原来 A 给 B 多少东西，B 消耗多少，A 给的时候，B 不能消耗；B 消耗的时候A不能给。现在变成A将东西放到篮子里面去，B 从篮子里面拿，B 如果拿去一部分后，只有消耗完了才会来拿，或者 A 通知 B 去篮子里面拿，而 B 忙碌时，A 是不会通知 B 来拿，这个时候 A 只管将东西放在篮子里面就可以了。\nbool bBusy = false; void add_task(const Functor\u0026amp; cb) { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex_); m_functors_.push_back(cb); //B不忙碌时只管往篮子里面加，不要通知B if (!bBusy) { wakeup_to_do_task(); } } void do_task() { bBusy = true; std::vector\u0026lt;Functor\u0026gt; functors; { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex_); functors.swap(pendingFunctors_); } for (size_t i = 0; i \u0026lt; functors.size(); ++i) { functors[i](); } bBusy = false; } 看，多巧妙的做法！\n因为每个工作线程都存在一个 m_functors，现在问题来了，如何将产生的任务均衡地分配给每个工作线程。这个做法类似上文中如何将新连接的 socket 句柄挂载到工作线程的 epollfd 上，也是 round-robin 算法。上文已经描述，此处不再赘述。\n还有种情况，就是希望任务产生时，工作线程能够立马执行这些任务，而不是等 epoll_wait 超时返回之后。这个时候的做法，就是使用一些技巧唤醒epoll_wait，Linux 系统可以使用 socketpair 或 timerevent、eventfd 等技巧。\n上文中留下三个问题：\n数据库线程任务队列A中的任务从何而来，目前只有消费者，没有生产者，那么生产者是谁？ 数据库线程任务队列B中的任务将去何方，目前只有生产者没有消费者。 业务层的数据如何发送出去？ 问题 1 的答案是：业务层产生任务可能会交给数据库任务队列A，这里的业务层代码可能就是工作线程中 do_other_things() 函数执行体中的调用。至于交给这个 9 个数据库线程的哪一个的任务队列，同样采用了 round-robin 算法。所以就存在一个对象 CDbThreadManager 来管理这九个数据库线程。下面的伪码是向数据库工作线程中加入任务：\nbool CDbThreadManager::AddTask(IMysqlTask* poTask ) { if (m_index \u0026gt;= m_dwThreadsCount) { m_index = 0; } return m_aoMysqlThreads[m_index++].AddTask(poTask); } 同理问题 2 中的消费者也可能就是 do_other_things() 函数执行体中的调用。\n现在来说问题 3，业务层的数据产生后，经过 TcpSession 装包后，需要发送的话，产生任务丢给工作线程的 do_other_things()，然后在相关的 Channel 里面发送，因为没有监测该 socket 上的可写事件，所以该数据可能调用 send() 或者 write() 时会阻塞，没关系，sleep() 一会儿，继续发送，一直尝试，到数据发出去。伪码如下：\nbool Channel::Send() { int offset = 0; while (true) { int n = ::send(socketfd, buf + offset, length - offset); if (n == -1) { if (errno == EWOULDBLOCK) { ::sleep(100); continue; } } //对方关闭了socket，这端建议也关闭 else if (n == 0) { close(socketfd); return false; } offset += n; if (offset \u0026gt;= length) break; } return true; } ","permalink":"https://haokiu.com/blog/f6db032966024846bbd5dbc28868bb17/","summary":"实例：一个服务器程序的架构介绍 本文将介绍我曾经做过的一个项目的服务器架构和服务器编程的一些重要细节。\n一、程序运行环境 操作系统：Centos 7.0\n编译器：gcc/g++ 4.8.3、cmake 2.8.11\nmysql数据库：5.5.47\n项目代码管理工具：Visual Studio 2013\n一、程序结构 该程序总共有 17 个线程，其中分为 9 个数据库工作线程 D 和一个日志线程 L，6 个普通工作线程 W，一个主线程 M。（以下会用这些字母来代指这些线程）\n（一）、数据库工作线程的用途 9 个数据库工作线程在线程启动之初，与 mysql 建立连接，也就是说每个线程都与 mysql 保持一路连接，共 9 个数据库连接。\n每个数据库工作线程同时存在两个任务队列，第一个队列 A 存放需要执行数据库增删查改操作的任务 sqlTask，第二个队列 B 存放 sqlTask 执行完成后的结果。sqlTask 执行完成后立即放入结果队列中，因而结果队列中任务也是一个个的需要执行的任务。大致伪代码如下：\nvoid db_thread_func() { while (!m_bExit) { if (NULL != (pTask = m_sqlTask.Pop())) { //从m_sqlTask中取出的任务先执行完成后，pTask将携带结果数据 pTask-\u0026gt;Execute(); //得到结果后，立刻将该任务放入结果任务队列 m_resultTask.Push(pTask); continue; } sleep(1000); }//end while-loop } 现在的问题来了：\n任务队列 A 中的任务从何而来，目前只有消费者，没有生产者，那么生产者是谁？ 任务队列 B 中的任务将去何方，目前只有生产者没有消费者。 这两个问题先放一会儿，等到后面我再来回答。\n（二）工作线程和主线程 在介绍主线程和工作线程具体做什么时，我们介绍下服务器编程中常常抽象出来的几个概念（这里以 tcp 连接为例）：\nTcpServer 即 Tcp 服务，服务器需要绑定ip地址和端口号，并在该端口号上侦听客户端的连接（往往由一个成员变量 TcpListener 来管理侦听细节）。所以一个 TcpServer 要做的就是这些工作。除此之外，每当有新连接到来时，TcpServer 需要接收新连接，当多个新连接存在时，TcpServer 需要有条不紊地管理这些连接：连接的建立、断开等，即产生和管理下文中说的 TcpConnection 对象。 一个连接对应一个 TcpConnection 对象，TcpConnection 对象管理着这个连接的一些信息：如连接状态、本端和对端的 ip 地址和端口号等。 数据通道对象 Channel，Channel 记录了 socket 的句柄，因而是一个连接上执行数据收发的真正执行者，Channel 对象一般作为 TcpConnection 的成员变量。 TcpSession 对象，是将 Channel 收取的数据进行解包，或者对准备好的数据进行装包，并传给 Channel 发送。 归纳起来：一个 TcpServer 依靠 TcpListener 对新连接的侦听和处理，依靠 TcpConnection 对象对连接上的数据进行管理，TcpConnection 实际依靠 Channel 对数据进行收发，依靠 TcpSession 对数据进行装包和解包。也就是说一个 TcpServer 存在一个 TcpListener，对应多个 TcpConnection，有几个TcpConnection 就有几个 TcpSession，同时也就有几个 Channel。","title":"实例：一个服务器程序的架构介绍"},{"content":"心跳包机制设计详解 存在下面两种情形：\n情形一：一个客户端连接服务器以后，如果长期没有和服务器有数据来往，可能会被防火墙程序关闭连接，有时候我们并不想要被关闭连接。例如，对于一个即时通讯软件，如果服务器没有消息时，我们确实不会和服务器有任何数据交换，但是如果连接被关闭了，有新消息来时，我们再也没法收到了，这就违背了“即时通讯”的设计要求。\n情形二：通常情况下，服务器与某个客户端一般不是位于同一个网络，其之间可能经过数个路由器和交换机，如果其中某个必经路由器或者交换器出现了故障，并且一段时间内没有恢复，导致这之间的链路不再畅通，而此时服务器与客户端之间也没有数据进行交换，由于 TCP 连接是状态机，对于这种情况，无论是客户端或者服务器都无法感知与对方的连接是否正常，这类连接我们一般称之为“死链”。\n情形一中的应用场景要求必须保持客户端与服务器之间的连接正常，就是我们通常所说的“保活“。如上文所述，当服务器与客户端一定时间内没有有效业务数据来往时，我们只需要给对端发送心跳包即可实现保活。\n情形二中的死链，只要我们此时任意一端给对端发送一个数据包即可检测链路是否正常，这类数据包我们也称之为”心跳包”，这种操作我们称之为“心跳检测”。顾名思义，如果一个人没有心跳了，可能已经死亡了；一个连接长时间没有正常数据来往，也没有心跳包来往，就可以认为这个连接已经不存在，为了节约服务器连接资源，我们可以通过关闭 socket，回收连接资源。\n根据上面的分析，让我再强调一下，心跳检测一般有两个作用：\n保活 检测死链 TCP keepalive 选项 操作系统的 TCP/IP 协议栈其实提供了这个的功能，即 keepalive 选项。在 Linux 操作系统中，我们可以通过代码启用一个 socket 的心跳检测（即每隔一定时间间隔发送一个心跳检测包给对端），代码如下：\n//on 是 1 表示打开 keepalive 选项，为 0 表示关闭，0 是默认值 int on = 1; setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, \u0026amp;on, sizeof(on)); 但是，即使开启了这个选项，这个选项默认发送心跳检测数据包的时间间隔是 7200 秒（2 小时），这时间间隔实在是太长了，不具有实用性。\n我们可以通过继续设置 keepalive 相关的三个选项来改变这个时间间隔，它们分别是 TCP_KEEPIDLE、TCP_KEEPINTVL 和 TCP_KEEPCNT，示例代码如下：\n//发送 keepalive 报文的时间间隔 int val = 7200; setsockopt(fd, IPPROTO_TCP, TCP_KEEPIDLE, \u0026amp;val, sizeof(val)); //两次重试报文的时间间隔 int interval = 75; setsockopt(fd, IPPROTO_TCP, TCP_KEEPINTVL, \u0026amp;interval, sizeof(interval)); int cnt = 9; setsockopt(fd, IPPROTO_TCP, TCP_KEEPCNT, \u0026amp;cnt, sizeof(cnt)); TCP_KEEPIDLE 选项设置了发送 keepalive 报文的时间间隔，发送时如果对端回复 ACK。则本端 TCP 协议栈认为该连接依然存活，继续等 7200 秒后再发送 keepalive 报文；如果对端回复 RESET，说明对端进程已经重启，本端的应用程序应该关闭该连接。\n如果对端没有任何回复，则本端做重试，如果重试 9 次（TCP_KEEPCNT 值）（前后重试间隔为 75 秒（TCP_KEEPINTVL 值））仍然不可达，则向应用程序返回 ETIMEOUT（无任何应答）或 EHOST 错误信息。\n我们可以使用如下命令查看 Linux 系统上的上述三个值的设置情况：\n[root@iZ238vnojlyZ ~]# sysctl -a | grep keepalive net.ipv4.tcp_keepalive_intvl = 75 net.ipv4.tcp_keepalive_probes = 9 net.ipv4.tcp_keepalive_time = 7200 在 Windows 系统设置 keepalive 及对应选项的代码略有不同：\n//开启 keepalive 选项 const char on = 1; setsockopt(socket, SOL_SOCKET, SO_KEEPALIVE, (char *)\u0026amp;on, sizeof(on); // 设置超时详细信息 DWORD cbBytesReturned; tcp_keepalive klive; // 启用保活 klive.onoff = 1; klive.keepalivetime = 7200; // 重试间隔为10秒 klive.keepaliveinterval = 1000 * 10; WSAIoctl(socket, SIO_KEEPALIVE_VALS, \u0026amp;klive, sizeof(tcp_keepalive), NULL, 0, \u0026amp;cbBytesReturned, NULL, NULL); 应用层的心跳包机制设计 由于 keepalive 选项需要为每个连接中的 socket 开启，这不一定是必须的，可能会产生大量无意义的带宽浪费，且 keepalive 选项不能与应用层很好地交互，因此一般实际的服务开发中，还是建议读者在应用层设计自己的心跳包机制。那么如何设计呢？\n从技术来讲，心跳包其实就是一个预先规定好格式的数据包，在程序中启动一个定时器，定时发送即可，这是最简单的实现思路。但是，如果通信的两端有频繁的数据来往，此时到了下一个发心跳包的时间点了，此时发送一个心跳包。这其实是一个流量的浪费，既然通信双方不断有正常的业务数据包来往，这些数据包本身就可以起到保活作用，为什么还要浪费流量去发送这些心跳包呢？所以，对于用于保活的心跳包，我们最佳做法是，设置一个上次包时间，每次收数据和发数据时，都更新一下这个包时间，而心跳检测计时器每次检测时，将这个包时间与当前系统时间做一个对比，如果时间间隔大于允许的最大时间间隔（实际开发中根据需求设置成 15 ~ 45 秒不等），则发送一次心跳包。总而言之，就是在与对端之间，没有数据来往达到一定时间间隔时才发送一次心跳包。\n发心跳包的伪码：\nbool CIUSocket::Send() { int nSentBytes = 0; int nRet = 0; while (true) { nRet = ::send(m_hSocket, m_strSendBuf.c_str(), m_strSendBuf.length(), 0); if (nRet == SOCKET_ERROR) { if (::WSAGetLastError() == WSAEWOULDBLOCK) break; else { LOG_ERROR(\u0026#34;Send data error, disconnect server:%s, port:%d.\u0026#34;, m_strServer.c_str(), m_nPort); Close(); return false; } } else if (nRet \u0026lt; 1) { //一旦出现错误就立刻关闭Socket LOG_ERROR(\u0026#34;Send data error, disconnect server:%s, port:%d.\u0026#34;, m_strServer.c_str(), m_nPort); Close(); return false; } m_strSendBuf.erase(0, nRet); if (m_strSendBuf.empty()) break; ::Sleep(1); } { //记录一下最近一次发包时间 std::lock_guard\u0026lt;std::mutex\u0026gt; guard(m_mutexLastDataTime); m_nLastDataTime = (long)time(NULL); } return true; } bool CIUSocket::Recv() { int nRet = 0; char buff[10 * 1024]; while (true) { nRet = ::recv(m_hSocket, buff, 10 * 1024, 0); if (nRet == SOCKET_ERROR) //一旦出现错误就立刻关闭Socket { if (::WSAGetLastError() == WSAEWOULDBLOCK) break; else { LOG_ERROR(\u0026#34;Recv data error, errorNO=%d.\u0026#34;, ::WSAGetLastError()); //Close(); return false; } } else if (nRet \u0026lt; 1) { LOG_ERROR(\u0026#34;Recv data error, errorNO=%d.\u0026#34;, ::WSAGetLastError()); //Close(); return false; } m_strRecvBuf.append(buff, nRet); ::Sleep(1); } { std::lock_guard\u0026lt;std::mutex\u0026gt; guard(m_mutexLastDataTime); //记录一下最近一次收包时间 m_nLastDataTime = (long)time(NULL); } return true; } void CIUSocket::RecvThreadProc() { LOG_INFO(\u0026#34;Recv data thread start...\u0026#34;); int nRet; //上网方式 DWORD dwFlags; BOOL bAlive; while (!m_bStop) { //检测到数据则收数据 nRet = CheckReceivedData(); //出错 if (nRet == -1) { m_pRecvMsgThread-\u0026gt;NotifyNetError(); } //无数据 else if (nRet == 0) { long nLastDataTime = 0; { std::lock_guard\u0026lt;std::mutex\u0026gt; guard(m_mutexLastDataTime); nLastDataTime = m_nLastDataTime; } if (m_nHeartbeatInterval \u0026gt; 0) { //当前系统时间与上一次收发数据包的时间间隔超过了m_nHeartbeatInterval //则发一次心跳包 if (time(NULL) - nLastDataTime \u0026gt;= m_nHeartbeatInterval) SendHeartbeatPackage(); } } //有数据 else if (nRet == 1) { if (!Recv()) { m_pRecvMsgThread-\u0026gt;NotifyNetError(); continue; } DecodePackages(); }// end if }// end while-loop LOG_INFO(\u0026#34;Recv data thread finish...\u0026#34;); } 同理，检测心跳包的一端，应该是在与对端没有数据来往达到一定时间间隔时才做一次心跳检测。\n心跳检测一端的伪码如下：\nvoid BusinessSession::send(const char* pData, int dataLength) { bool sent = TcpSession::send(pData, dataLength); //发送完数据更新下发包时间 updateHeartbeatTime(); } void BusinessSession::handlePackge(char* pMsg, int msgLength, bool\u0026amp; closeSession, std::vector\u0026lt;std::string\u0026gt;\u0026amp; vectorResponse) { //对数据合法性进行校验 if (pMsg == NULL || pMsg[0] == 0 || msgLength \u0026lt;= 0 || msgLength \u0026gt; MAX_DATA_LENGTH) { //非法刺探请求，不做任何应答，直接关闭连接 closeSession = true; return; } //更新下收包时间 updateHeartbeatTime(); //省略包处理代码... } void BusinessSession::updateHeartbeatTime() { std::lock_guard\u0026lt;std::mutex\u0026gt; scoped_guard(m_mutexForlastPackageTime); m_lastPackageTime = (int64_t)time(nullptr); } bool BusinessSession::doHeartbeatCheck() { const Config\u0026amp; cfg = Singleton\u0026lt;Config\u0026gt;::Instance(); int64_t now = (int64_t)time(nullptr); std::lock_guard\u0026lt;std::mutex\u0026gt; lock_guard(m_mutexForlastPackageTime); if (now - m_lastPackageTime \u0026gt;= cfg.m_nMaxClientDataInterval) { //心跳包检测，超时，关闭连接 LOGE(\u0026#34;heartbeat expired, close session\u0026#34;); shutdown(); return true; } return false; } void TcpServer::checkSessionHeartbeat() { int64_t now = (int64_t)time(nullptr); if (now - m_nLastCheckHeartbeatTime \u0026gt;= m_nHeartbeatCheckInterval) { m_spSessionManager-\u0026gt;checkSessionHeartbeat(); m_nLastCheckHeartbeatTime = (int64_t)time(nullptr); } } void SessionManager::checkSessionHeartbeat() { std::lock_guard\u0026lt;std::mutex\u0026gt; scoped_lock(m_mutexForSession); for (const auto\u0026amp; iter : m_mapSessions) { //这里调用 BusinessSession::doHeartbeatCheck() iter.second-\u0026gt;doHeartbeatCheck(); } } 需要注意的是：一般是客户端主动给服务器端发送心跳包，服务器端做心跳检测决定是否断开连接。而不是反过来，从客户端的角度来说，客户端为了让自己得到服务器端的正常服务有必要主动和服务器保持连接状态正常，而服务器端不会局限于某个特定的客户端，如果客户端不能主动和其保持连接，那么就会主动回收与该客户端的连接。当然，服务器端在收到客户端的心跳包时应该给客户端一个心跳应答。\n带业务数据的心跳包 上面介绍的心跳包是从纯技术的角度来说的，在实际应用中，有时候我们需要定时或者不定时从服务器端更新一些数据，我们可以把这类数据放在心跳包中，定时或者不定时更新。\n这类带业务数据的心跳包，就不再是纯粹技术上的作用了（这里说的技术的作用指的上文中介绍的心跳包起保活和检测死链作用）。\n这类心跳包实现也很容易，即在心跳包数据结构里面加上需要的业务字段信息，然后在定时器中定时发送，客户端发给服务器，服务器在应答心跳包中填上约定的业务数据信息即可。\n心跳包与流量 通常情况下，多数应用场景下，与服务器端保持连接的多个客户端中，同一时间段活跃用户（这里指的是与服务器有频繁数据来往的客户端）一般不会太多。当连接数较多时，进出服务器程序的数据包通常都是心跳包（为了保活）。所以为了减轻网络代码压力，节省流量，尤其是针对一些 3/4 G 手机应用，我们在设计心跳包数据格式时应该尽量减小心跳包的数据大小。\n心跳包与调试 如前文所述，对于心跳包，服务器端的逻辑一般是在一定时间间隔内没有收到客户端心跳包时会主动断开连接。在我们开发调试程序过程中，我们可能需要将程序通过断点中断下来，这个过程可能是几秒到几十秒不等。等程序恢复执行时，连接可能因为心跳检测逻辑已经被断开。\n调试过程中，我们更多的关注的是业务数据处理的逻辑是否正确，不想被一堆无意义的心跳包数据干扰实线。\n鉴于以上两点原因，我们一般在调试模式下关闭或者禁用心跳包检测机制。代码大致如下：\nChatSession::ChatSession(const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn, int sessionid) : TcpSession(conn), m_id(sessionid), m_seq(0), m_isLogin(false) { m_userinfo.userid = 0; m_lastPackageTime = time(NULL); //这里设置了非调试模式下才开启心跳包检测功能 #ifndef _DEBUG EnableHearbeatCheck(); #endif } 当然，你也可以将开启心跳检测的开关做成配置信息放入程序配置文件中。\n心跳包与日志 实际生产环境，我们一般会将程序收到的和发出去的数据包写入日志中，但是无业务信息的心跳包信息是个例外，一般会刻意不写入日志，这是因为心跳包数据一般比较多，如果写入日志会导致日志文件变得很大，且充斥大量无意义的心跳包日志，所以一般在写日志时会屏蔽心跳包信息写入。\n我这里的建议是，可以将心跳包信息是否写入日志做成一个配置开关，一般处于关闭状态，有需要时再开启。例如，对于一个 WebSocket 服务，ping 和 pong 是心跳包数据，下面示例代码按需输出心跳日志信息：\nvoid BusinessSession::send(std::string_view strResponse) { bool success = WebSocketSession::send(strResponse); if (success) { bool enablePingPongLog = Singleton\u0026lt;Config\u0026gt;::Instance().m_bPingPongLogEnabled; //其他消息正常打印，心跳消息按需打印 if (strResponse != \u0026#34;pong\u0026#34; || enablePingPongLog) { LOGI(\u0026#34;msg sent to client [%s], sessionId: %s, session: 0x%0x, clientId: %s, accountId: %s, frontId: %s, msg: %s\u0026#34;, getClientInfo(), m_strSessionId.c_str(), (int64_t)this, m_strClientID.c_str(), m_strAccountID.c_str(), BusinessSession::m_strFrontId.c_str(), strResponse.data()); } } } 需要说明的是，以上示例代码使用 C/C++ 语言编写，但是本节介绍的心跳包机制设计思路和注意事项是普适性原理，同样适用于其他编程语言。\n","permalink":"https://haokiu.com/blog/82046162d4f74d3b9745ef1e8f8cdf57/","summary":"心跳包机制设计详解 存在下面两种情形：\n情形一：一个客户端连接服务器以后，如果长期没有和服务器有数据来往，可能会被防火墙程序关闭连接，有时候我们并不想要被关闭连接。例如，对于一个即时通讯软件，如果服务器没有消息时，我们确实不会和服务器有任何数据交换，但是如果连接被关闭了，有新消息来时，我们再也没法收到了，这就违背了“即时通讯”的设计要求。\n情形二：通常情况下，服务器与某个客户端一般不是位于同一个网络，其之间可能经过数个路由器和交换机，如果其中某个必经路由器或者交换器出现了故障，并且一段时间内没有恢复，导致这之间的链路不再畅通，而此时服务器与客户端之间也没有数据进行交换，由于 TCP 连接是状态机，对于这种情况，无论是客户端或者服务器都无法感知与对方的连接是否正常，这类连接我们一般称之为“死链”。\n情形一中的应用场景要求必须保持客户端与服务器之间的连接正常，就是我们通常所说的“保活“。如上文所述，当服务器与客户端一定时间内没有有效业务数据来往时，我们只需要给对端发送心跳包即可实现保活。\n情形二中的死链，只要我们此时任意一端给对端发送一个数据包即可检测链路是否正常，这类数据包我们也称之为”心跳包”，这种操作我们称之为“心跳检测”。顾名思义，如果一个人没有心跳了，可能已经死亡了；一个连接长时间没有正常数据来往，也没有心跳包来往，就可以认为这个连接已经不存在，为了节约服务器连接资源，我们可以通过关闭 socket，回收连接资源。\n根据上面的分析，让我再强调一下，心跳检测一般有两个作用：\n保活 检测死链 TCP keepalive 选项 操作系统的 TCP/IP 协议栈其实提供了这个的功能，即 keepalive 选项。在 Linux 操作系统中，我们可以通过代码启用一个 socket 的心跳检测（即每隔一定时间间隔发送一个心跳检测包给对端），代码如下：\n//on 是 1 表示打开 keepalive 选项，为 0 表示关闭，0 是默认值 int on = 1; setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, \u0026amp;on, sizeof(on)); 但是，即使开启了这个选项，这个选项默认发送心跳检测数据包的时间间隔是 7200 秒（2 小时），这时间间隔实在是太长了，不具有实用性。\n我们可以通过继续设置 keepalive 相关的三个选项来改变这个时间间隔，它们分别是 TCP_KEEPIDLE、TCP_KEEPINTVL 和 TCP_KEEPCNT，示例代码如下：\n//发送 keepalive 报文的时间间隔 int val = 7200; setsockopt(fd, IPPROTO_TCP, TCP_KEEPIDLE, \u0026amp;val, sizeof(val)); //两次重试报文的时间间隔 int interval = 75; setsockopt(fd, IPPROTO_TCP, TCP_KEEPINTVL, \u0026amp;interval, sizeof(interval)); int cnt = 9; setsockopt(fd, IPPROTO_TCP, TCP_KEEPCNT, \u0026amp;cnt, sizeof(cnt)); TCP_KEEPIDLE 选项设置了发送 keepalive 报文的时间间隔，发送时如果对端回复 ACK。则本端 TCP 协议栈认为该连接依然存活，继续等 7200 秒后再发送 keepalive 报文；如果对端回复 RESET，说明对端进程已经重启，本端的应用程序应该关闭该连接。\n如果对端没有任何回复，则本端做重试，如果重试 9 次（TCP_KEEPCNT 值）（前后重试间隔为 75 秒（TCP_KEEPINTVL 值））仍然不可达，则向应用程序返回 ETIMEOUT（无任何应答）或 EHOST 错误信息。","title":"心跳包机制设计详解"},{"content":"日志系统的设计 为什么需要日志 实际的软件项目产出都有一个流程，即先开发、测试，再发布生产，由于人的因素，既然是软件产品就不可能百分百没有 bug 或者逻辑错误，对于已经发布到生产的项目，一旦某个时刻产生非预期的结果，我们就需要去定位和排查问题。但是一般正式的生产环境的服务器或者产品是不允许开发人员通过附加调试器去排查问题的，主要有如下可能原因：\n在很多互联网企业，开发部门、测试部分和产品运维部门是分工明确的，软件产品一旦发布到生产环境以后，将全部交由运维部门人员去管理和维护，而原来开发此产品的开发人员不再拥有相关的操作程序的权限。 对于已经上了生产环境的服务，其数据和程序稳定性是公司的核心产值所在，一般不敢或不允许被开发人员随意调试或者操作，以免造成损失。 发布到生产环境的服务，一般为了让程序执行效率更高、文件体积更小，都是去掉调试符号后的版本，不方便也不利于调试。 既然我们无法通过调试器去调试，这个时候为了跟踪和回忆当时的程序行为进而定位问题，我们就需要日志系统。\n退一步说，即使在开发或者测试环境，我们可以把程序附加到调试器上去调试，但是对于一些特定的程序行为，我们无法通过设置断点，让程序在某个时刻暂停下来进行调试。例如，对于某些网络通信功能，如果暂停时间过长（相对于某些程序逻辑来说），通信的对端可能由于彼端没有在规定时间内响应而断开连接，导致程序逻辑无法进入我们想要的执行流中去；再例如，对于一些高频操作（如心跳包、定时器、界面绘制下的某些高频重复行为），可能在少量次数下无法触发我们想要的行为，而通过断点的暂停方式，我们不得不重复操作几十次、上百次甚至更多，这样排查问题效率是非常低下的。对于这类操作，我们可以通过打印日志，将当时的程序行为上下文现场记录下来，然后从日志系统中找到某次不正常的行为的上下文信息。这也是日志的另外一个作用。\n本文将从技术和业务上两个方面来介绍日志系统相关的设计与开发，所谓技术上，就是如何从程序开发的角度设计一款功能强大、性能优越、使用方便的日志系统；而业务上，是指我们在使用日志系统时，应该去记录哪些行为和数据，既简洁、不啰嗦，又方便需要时快速准确地定位到问题。\n日志系统的技术上的实现 日志的最初的原型即将程序运行的状态打印出来，对于 C/C++ 这门语言来说，即可以利用 printf、std::cout 等控制台输出函数，将日志信息输出到控制台，这类简单的情形我们不在此过多赘述。\n对于商业项目，为了方便排查问题，我们一般不将日志写到控制台，而是输出到文件或者数据库系统。不管哪一种，其思路基本上一致，我们这里以写文件为例来详细介绍。\n同步写日志 所谓同步写日志，指的是在输出日志的地方，将日志即时写入到文件中去。根据笔者的经验，这种设计广泛地用于相当多的的客户端软件。笔者曾从事过数年的客户端开发（包括 PC、安卓软件），设计过一些功能复杂的金融客户端产品，在这些系统中采用的就是这种同步写日志的方式。之所以使用这种方式其主要原因就是设计简单，而又不会影响用户使用体验。说到这里读者可能有这样一个疑问：一般的客户端软件，一般存在界面，而界面部分所属的逻辑就是程序的主线程，如果采取这种同步写日志的方式，当写日志时，写文件是磁盘 IO 操作，相比较程序其他部分是 CPU 操作，前者要慢很多，这样势必造成CPU等待，进而导致主线程“卡”在写文件处，进而造成界面卡顿，从而导致用户使用软件的体验不好。读者的这种顾虑确实是存在的。但是，很多时候我们不用担心这种问题，主要有两个原因：\n对于客户端程序，即使在主线程（UI 线程）中同步写文件，其单次或者几次磁盘操作累加时间，与人（用户）的可感知时间相比，也是非常小的，也就是说用户根本感觉不到这种同步写文件造成的延迟。当然，这里也给您一个提醒就是，如果在 UI 线程里面写日志，尤其是在一些高频操作中（如 Windows 的界面绘制消息 WM_PAINT 处理逻辑中），一定要控制写日志的长度和次数，否则就会因频繁写文件或一次写入数据过大而对界面造成卡顿。 客户端程序除了 UI 线程，还有其他与界面无关的工作线程，在这些线程中直接写文件，一般不会对用户的体验产生什么影响。 说了这么多，我们给出一个具体的例子。\n日志类的 .h 文件\n/** *@desc: IULog.h *@author: zhangyl *@date: 2014.12.25 */ #ifndef __LOG_H__ #define __LOG_H__ enum LOG_LEVEL { LOG_LEVEL_INFO, LOG_LEVEL_WARNING, LOG_LEVEL_ERROR }; //注意：如果打印的日志信息中有中文，则格式化字符串要用_T()宏包裹起来， #define LOG_INFO(...) CIULog::Log(LOG_LEVEL_INFO, __FUNCSIG__,__LINE__, __VA_ARGS__) #define LOG_WARNING(...) CIULog::Log(LOG_LEVEL_WARNING, __FUNCSIG__, __LINE__,__VA_ARGS__) #define LOG_ERROR(...) CIULog::Log(LOG_LEVEL_ERROR, __FUNCSIG__,__LINE__, __VA_ARGS__) class CIULog { public: static bool Init(bool bToFile, bool bTruncateLongLog, PCTSTR pszLogFileName); static void Uninit(); static void SetLevel(LOG_LEVEL nLevel); //不输出线程ID号和所在函数签名、行号 static bool Log(long nLevel, PCTSTR pszFmt, ...); //输出线程ID号和所在函数签名、行号 static bool Log(long nLevel, PCSTR pszFunctionSig, int nLineNo, PCTSTR pszFmt, ...); //注意:pszFunctionSig参数为Ansic版本 static bool Log(long nLevel, PCSTR pszFunctionSig, int nLineNo, PCSTR pszFmt, ...); private: CIULog() = delete; ~CIULog() = delete; CIULog(const CIULog\u0026amp; rhs) = delete; CIULog\u0026amp; operator=(const CIULog\u0026amp; rhs) = delete; static void GetTime(char* pszTime, int nTimeStrLength); private: static bool m_bToFile; //日志写入文件还是写到控制台 static HANDLE m_hLogFile; static bool m_bTruncateLongLog; //长日志是否截断 static LOG_LEVEL m_nLogLevel; //日志级别 }; #endif // !__LOG_H__ 日志的 cpp 文件\n/** *@desc: IULog.cpp *@author: zhangyl *@date: 2014.12.25 */ #include \u0026#34;stdafx.h\u0026#34; #include \u0026#34;IULog.h\u0026#34; #include \u0026#34;EncodingUtil.h\u0026#34; #include \u0026lt;tchar.h\u0026gt; #ifndef LOG_OUTPUT #define LOG_OUTPUT #endif #define MAX_LINE_LENGTH 256 bool CIULog::m_bToFile = false; bool CIULog::m_bTruncateLongLog = false; HANDLE CIULog::m_hLogFile = INVALID_HANDLE_VALUE; LOG_LEVEL CIULog::m_nLogLevel = LOG_LEVEL_INFO; bool CIULog::Init(bool bToFile, bool bTruncateLongLog, PCTSTR pszLogFileName) { #ifdef LOG_OUTPUT m_bToFile = bToFile; m_bTruncateLongLog = bTruncateLongLog; if (pszLogFileName == NULL || pszLogFileName[0] == NULL) return FALSE; TCHAR szHomePath[MAX_PATH] = {0}; ::GetModuleFileName(NULL, szHomePath, MAX_PATH); for (int i = _tcslen(szHomePath); i \u0026gt;= 0; --i) { if (szHomePath[i] == _T(\u0026#39;\\\\\u0026#39;)) { szHomePath[i] = _T(\u0026#39;\\0\u0026#39;); break; } } TCHAR szLogDirectory[MAX_PATH] = { 0 }; _stprintf_s(szLogDirectory, _T(\u0026#34;%s\\\\Logs\\\\\u0026#34;), szHomePath); DWORD dwAttr = ::GetFileAttributes(szLogDirectory); if (!((dwAttr != 0xFFFFFFFF) \u0026amp;\u0026amp; (dwAttr \u0026amp; FILE_ATTRIBUTE_DIRECTORY))) { TCHAR cPath[MAX_PATH] = { 0 }; TCHAR cTmpPath[MAX_PATH] = { 0 }; TCHAR* lpPos = NULL; TCHAR cTmp = _T(\u0026#39;\\0\u0026#39;); _tcsncpy_s(cPath, szLogDirectory, MAX_PATH); for (int i = 0; i \u0026lt; (int)_tcslen(cPath); i++) { if (_T(\u0026#39;\\\\\u0026#39;) == cPath[i]) cPath[i] = _T(\u0026#39;/\u0026#39;); } lpPos = _tcschr(cPath, _T(\u0026#39;/\u0026#39;)); while (lpPos != NULL) { if (lpPos == cPath) { lpPos++; } else { cTmp = *lpPos; *lpPos = _T(\u0026#39;\\0\u0026#39;); _tcsncpy_s(cTmpPath, cPath, MAX_PATH); ::CreateDirectory(cTmpPath, NULL); *lpPos = cTmp; lpPos++; } lpPos = _tcschr(lpPos, _T(\u0026#39;/\u0026#39;)); } } m_hLogFile = ::CreateFile(pszLogFileName, GENERIC_READ | GENERIC_WRITE, FILE_SHARE_READ, NULL, CREATE_NEW, FILE_ATTRIBUTE_NORMAL, NULL); if (m_hLogFile == INVALID_HANDLE_VALUE) return false; #endif // end LOG_OUTPUT return true; } void CIULog::Uninit() { #ifdef LOG_OUTPUT if(m_hLogFile != INVALID_HANDLE_VALUE) { ::CloseHandle(m_hLogFile); m_hLogFile = INVALID_HANDLE_VALUE; } #endif //end LOG_OUTPUT } void CIULog::SetLevel(LOG_LEVEL nLevel) { m_nLogLevel = nLevel; } bool CIULog::Log(long nLevel, PCTSTR pszFmt, ...) { #ifdef LOG_OUTPUT if (nLevel \u0026lt; m_nLogLevel) return false; char szTime[64] = { 0 }; GetTime(szTime,ARRAYSIZE(szTime)); std::string strDebugInfo(szTime); std::string strLevel(\u0026#34;[INFO]\u0026#34;); if (nLevel == LOG_LEVEL_WARNING) strLevel = \u0026#34;[Warning]\u0026#34;; else if (nLevel == LOG_LEVEL_ERROR) strLevel = \u0026#34;[Error]\u0026#34;; strDebugInfo += strLevel; //当前线程信息 char szThreadID[32] = { 0 }; DWORD dwThreadID = ::GetCurrentThreadId(); sprintf_s(szThreadID, ARRAYSIZE(szThreadID), \u0026#34;[ThreadID: %u]\u0026#34;, dwThreadID); strDebugInfo += szThreadID; //log正文 std::wstring strLogMsg; va_list ap; va_start(ap, pszFmt); int nLogMsgLength = _vsctprintf(pszFmt, ap); //容量必须算上最后一个\\0 if ((int)strLogMsg.capacity() \u0026lt; nLogMsgLength + 1) { strLogMsg.resize(nLogMsgLength + 1); } _vstprintf_s((TCHAR*)strLogMsg.data(), strLogMsg.capacity(), pszFmt, ap); va_end(ap); //string内容正确但length不对，恢复一下其length std::wstring strMsgFormal; strMsgFormal.append(strLogMsg.c_str(), nLogMsgLength); //如果日志开启截断，长日志只取前MAX_LINE_LENGTH个字符 if (m_bTruncateLongLog) strMsgFormal = strMsgFormal.substr(0, MAX_LINE_LENGTH); std::string strLogMsgAscii; strLogMsgAscii = EncodeUtil::UnicodeToAnsi(strMsgFormal); strDebugInfo += strLogMsgAscii; strDebugInfo += \u0026#34;\\r\\n\u0026#34;; if(m_bToFile) { if(m_hLogFile == INVALID_HANDLE_VALUE) return false; ::SetFilePointer(m_hLogFile, 0, NULL, FILE_END); DWORD dwBytesWritten = 0; ::WriteFile(m_hLogFile, strDebugInfo.c_str(), strDebugInfo.length(), \u0026amp;dwBytesWritten, NULL); ::FlushFileBuffers(m_hLogFile); return true; } ::OutputDebugStringA(strDebugInfo.c_str()); #endif // end LOG_OUTPUT return true; } bool CIULog::Log(long nLevel, PCSTR pszFunctionSig, int nLineNo, PCTSTR pszFmt, ...) { #ifdef LOG_OUTPUT if (nLevel \u0026lt; m_nLogLevel) return false; //时间 char szTime[64] = { 0 }; GetTime(szTime, ARRAYSIZE(szTime)); std::string strDebugInfo(szTime); //错误级别 std::string strLevel(\u0026#34;[INFO]\u0026#34;); if (nLevel == LOG_LEVEL_WARNING) strLevel = \u0026#34;[Warning]\u0026#34;; else if (nLevel == LOG_LEVEL_ERROR) strLevel = \u0026#34;[Error]\u0026#34;; strDebugInfo += strLevel; //当前线程信息 char szThreadID[32] = {0}; DWORD dwThreadID = ::GetCurrentThreadId(); sprintf_s(szThreadID, ARRAYSIZE(szThreadID), \u0026#34;[ThreadID: %u]\u0026#34;, dwThreadID); strDebugInfo += szThreadID; //函数签名 char szFuncSig[512] = { 0 }; sprintf_s(szFuncSig, \u0026#34;[%s:%d]\u0026#34;, pszFunctionSig, nLineNo); strDebugInfo += szFuncSig; //log正文 std::wstring strLogMsg; va_list ap; va_start(ap, pszFmt); int nLogMsgLength = _vsctprintf(pszFmt, ap); //容量必须算上最后一个\\0 if ((int)strLogMsg.capacity() \u0026lt; nLogMsgLength + 1) { strLogMsg.resize(nLogMsgLength + 1); } _vstprintf_s((TCHAR*)strLogMsg.data(), strLogMsg.capacity(), pszFmt, ap); va_end(ap); //string内容正确但length不对，恢复一下其length std::wstring strMsgFormal; strMsgFormal.append(strLogMsg.c_str(), nLogMsgLength); //如果日志开启截断，长日志只取前MAX_LINE_LENGTH个字符 if (m_bTruncateLongLog) strMsgFormal = strMsgFormal.substr(0, MAX_LINE_LENGTH); std::string strLogMsgAscii; strLogMsgAscii = EncodeUtil::UnicodeToAnsi(strMsgFormal); strDebugInfo += strLogMsgAscii; strDebugInfo += \u0026#34;\\r\\n\u0026#34;; if(m_bToFile) { if(m_hLogFile == INVALID_HANDLE_VALUE) return false; ::SetFilePointer(m_hLogFile, 0, NULL, FILE_END); DWORD dwBytesWritten = 0; ::WriteFile(m_hLogFile, strDebugInfo.c_str(), strDebugInfo.length(), \u0026amp;dwBytesWritten, NULL); ::FlushFileBuffers(m_hLogFile); return true; } ::OutputDebugStringA(strDebugInfo.c_str()); #endif // end LOG_OUTPUT return true; } bool CIULog::Log(long nLevel, PCSTR pszFunctionSig, int nLineNo, PCSTR pszFmt, ...) { #ifdef LOG_OUTPUT if (nLevel \u0026lt; m_nLogLevel) return false; //时间 char szTime[64] = { 0 }; GetTime(szTime, ARRAYSIZE(szTime)); std::string strDebugInfo(szTime); //错误级别 std::string strLevel(\u0026#34;[INFO]\u0026#34;); if (nLevel == LOG_LEVEL_WARNING) strLevel = \u0026#34;[Warning]\u0026#34;; else if (nLevel == LOG_LEVEL_ERROR) strLevel = \u0026#34;[Error]\u0026#34;; strDebugInfo += strLevel; //当前线程信息 char szThreadID[32] = {0}; DWORD dwThreadID = ::GetCurrentThreadId(); sprintf_s(szThreadID, ARRAYSIZE(szThreadID), \u0026#34;[ThreadID: %u]\u0026#34;, dwThreadID); strDebugInfo += szThreadID; //函数签名 char szFuncSig[512] = { 0 }; sprintf_s(szFuncSig, \u0026#34;[%s:%d]\u0026#34;, pszFunctionSig, nLineNo); strDebugInfo += szFuncSig; //日志正文 std::string strLogMsg; va_list ap; va_start(ap, pszFmt); int nLogMsgLength = _vscprintf(pszFmt, ap); //容量必须算上最后一个\\0 if ((int)strLogMsg.capacity() \u0026lt; nLogMsgLength + 1) { strLogMsg.resize(nLogMsgLength + 1); } vsprintf_s((char*)strLogMsg.data(), strLogMsg.capacity(), pszFmt, ap); va_end(ap); //string内容正确但length不对，恢复一下其length std::string strMsgFormal; strMsgFormal.append(strLogMsg.c_str(), nLogMsgLength); //如果日志开启截断，长日志只取前MAX_LINE_LENGTH个字符 if (m_bTruncateLongLog) strMsgFormal = strMsgFormal.substr(0, MAX_LINE_LENGTH); strDebugInfo += strMsgFormal; strDebugInfo += \u0026#34;\\r\\n\u0026#34;; if(m_bToFile) { if(m_hLogFile == INVALID_HANDLE_VALUE) return false; ::SetFilePointer(m_hLogFile, 0, NULL, FILE_END); DWORD dwBytesWritten = 0; ::WriteFile(m_hLogFile, strDebugInfo.c_str(), strDebugInfo.length(), \u0026amp;dwBytesWritten, NULL); ::FlushFileBuffers(m_hLogFile); return true; } ::OutputDebugStringA(strDebugInfo.c_str()); #endif // end LOG_OUTPUT return true; } void CIULog::GetTime(char* pszTime, int nTimeStrLength) { SYSTEMTIME st = {0}; ::GetLocalTime(\u0026amp;st); sprintf_s(pszTime, nTimeStrLength, \u0026#34;[%04d-%02d-%02d %02d:%02d:%02d:%04d]\u0026#34;, st.wYear, st.wMonth, st.wDay, st.wHour, st.wMinute, st.wSecond, st.wMilliseconds); } 上述代码中根据日志级别定义了三个宏 LOG_INFO、LOG_WARNING、LOG_ERROR，如果要使用该日志模块，只需要在程序启动处的地方调用 CIULog::Init 函数初始化日志：\nSYSTEMTIME st = {0}; ::GetLocalTime(\u0026amp;st); TCHAR szLogFileName[MAX_PATH] = {0}; _stprintf_s(szLogFileName, MAX_PATH, _T(\u0026#34;%s\\\\Logs\\\\%04d%02d%02d%02d%02d%02d.log\u0026#34;), g_szHomePath, st.wYear, st.wMonth, st.wDay, st.wHour, st.wMinute, st.wSecond); CIULog::Init(true, false, szLogFileName); 当然，最佳的做法，在程序退出的地方，调用 CIULog::Uninit 回收日志模块相关的资源：\nCIULog::Uninit(); 在做好这些准备工作以后，如果你想在程序的某个地方写一条日志，只需要这样写：\n//打印一条 INFO 级别的日志 LOG_INFO(\u0026#34;Request logon: Account=%s, Password=*****, Status=%d, LoginType=%d.\u0026#34;, pLoginRequest-\u0026gt;m_szAccountName, pLoginRequest-\u0026gt;m_szPassword, pLoginRequest-\u0026gt;m_nStatus, (long)pLoginRequest-\u0026gt;m_nLoginType); //打印一条 WARNING 级别的日志 LOG_WARN(\u0026#34;Some warning...\u0026#34;); //打印一条 ERROR 级别的日志 LOG_ERROR(\u0026#34;Recv data error, errorNO=%d.\u0026#34;, ::WSAGetLastError()); 关于 CIULog 这个日志模块类，如果读者要想实际运行查看效果，可以从链接（https://github.com/baloonwj/flamingo/tree/master/flamingoclient ）下载完整的项目代码来运行。该日志输出效果如下：\n[2018-11-09 23:52:54:0826][INFO][ThreadID: 7252][bool __thiscall CIUSocket::Login(const char *,const char *,int,int,int,class std::basic_string\u0026lt;char,struct std::char_traits\u0026lt;char\u0026gt;,class std::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026amp;):1107]Request logon: Account=zhangy, Password=*****, Status=76283204, LoginType=1. [2018-11-09 23:52:56:0352][INFO][ThreadID: 5828][void __thiscall CIUSocket::SendThreadProc(void):794]Recv data thread start... [2018-11-09 23:52:56:0385][INFO][ThreadID: 6032][void __thiscall CSendMsgThread::HandleUserBasicInfo(const class CUserBasicInfoRequest *):298]Request to get userinfo. [2018-11-09 23:52:56:0355][INFO][ThreadID: 7140][void __thiscall CIUSocket::RecvThreadProc(void):842]Recv data thread start... [2018-11-09 23:52:57:0254][INFO][ThreadID: 7220][int __thiscall CRecvMsgThread::HandleFriendListInfo(const class std::basic_string\u0026lt;char,struct std::char_traits\u0026lt;char\u0026gt;,class std::allocator\u0026lt;char\u0026gt; \u0026gt; \u0026amp;):593]Recv user basic info, info count=1. 多线程同步写日志出现的问题一 从上面的日志输出来看，这种同步的日志输出方式，也存在时间顺序不正确的问题（时间戳大的日志比时间戳小的日志靠前）。这是由于多线程同时写日志到同一个文件时，产生日志的时间和实际写入磁盘的时间不是一个原子操作。下图解释了该现象出现的根源：\n多线程写同一个日志文件出现先产生的日志后写入到文件中的现象\n好在这种时间顺序不正确只会出现在不同线程之间，对于同一个线程的不同时间的日志记录顺序肯定是正确的。所以这种日期错乱现象，并不影响我们使用日志。\n多线程同步写日志出现的问题二 多线程同时写入同一个日志文件还有一个问题，就是假设线程 A 写某一个时刻追加日志内容为 “AAAAA” ，线程 B 在同一时刻追加日志内容为 “BBBBB” ，线程 C 在同一时刻追加日志内容为 “CCCCC” ，那么最终的日志文件中的内容会不会出现 “AABBCCABCAACCBB” 这种格式？\n在类 Unix 系统上（包括 Linux），同一个进程内针对同一个 FILE* 的操作是线程安全的，也就是说，在这类操作系统上得到的日志结果 A、B、C 各个字母组一定是连续在一起，也就是说最终得到的日志内容可能是 “AAAAACCCCCBBBBB” 或 “AAAAABBBBBCCCCC” 等这种连续的格式，绝不会出现 A、B、C 字母交错相间的现象。\n而在Windows系统上，对于 FILE* 的操作并不是线程安全的。但是笔者做了大量实验，在 Windows 系统上也没有出现这种 A、B、C 字母相间的现象。（关于这个问题的讨论，可以参考这里：https://www.zhihu.com/question/40472431 ）\n这种同步日志的实现方式，一般用于低频写日志的软件系统中（如客户端软件），所以我可以认为这种多线程同时写日志到一个文件中是可行的。\n异步写日志 当然，对于性能要求不高的应用（如大多数客户端程序、某些并发数量不高的服务）来说，这种同步写日志的实现方式是可以满足要求的。但是对于 QPS 要求很高或者对性能有一定要求的服务器程序，同步写日志等待磁盘 IO 的完成对于服务的关键性逻辑的快速执行和及时响应性会造成一定的性能损失。为了减小这种损失，我们可以采用异步日志。\n所谓异步写日志，与同步写日志相反，即产生日志的地方，不会将日志实时写入到文件中去，而是通过一些线程同步技术将日志先暂存下来，然后再通过一个或多个专门的日志写入线程去将这些缓存的日志写入到磁盘中去，这样的话，原来输出日志的线程就不存在等待写日志到磁盘这样的效率损耗了。这本质上，其实就是一个生产者和消费者，产生日志的线程是生产者，将日志写入文件的线程是消费者。当然，对于日志的消费者线程，我这里提到“一个”或“多个”日志线程，在实际开发中，如果多个日志消费线程，我们又要考虑多个线程可能会造成写日志的时间顺序错位（时间较晚的日志写在时间较早的日志前面），这在上文中已经讨论过，这里不再赘述。\n总结起来，为了方便读者理解和编码，我们可以认为异步写日志的逻辑一般存在一组专门写日志的线程（一个或多个），程序的其他线程为这些日志线程生产日志。\n至于其他线程如何将产生的日志交给日志线程，这就是多线程之间资源同步的问题了。我们可以使用一个队列来存储其他线程产生的日志，日志线程从该队列中取出日志，然后将日志内容写入文件。最简单的方式是日志生产线程将每次产生的日志信息放入一个队列时、日志写入线程从队列中取出日志时，都使用一个**互斥体( mutex )**保护起来。代码示例如下（C++11 代码）：\n/** *@desc: AsyncLogger.cpp *@author: zhangyl *@date: 2018.11.10 */ #include \u0026#34;stdafx.h\u0026#34; #include \u0026lt;thread\u0026gt; #include \u0026lt;mutex\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;sstream\u0026gt; #include \u0026lt;iostream\u0026gt; //保护队列的互斥体 std::mutex log_mutex; std::list\u0026lt;std::string\u0026gt; cached_logs; FILE* log_file = NULL; bool init_log_file() { //以追加内容的形式写入文件内容，如果文件不存在，则创建 log_file = fopen(\u0026#34;my.log\u0026#34;, \u0026#34;a+\u0026#34;); return log_file != NULL; } void uninit_log_file() { if (log_file != NULL) fclose(log_file); } bool write_log_tofile(const std::string\u0026amp; line) { if (log_file == NULL) return false; if (fwrite((void*)line.c_str(), 1, line.length(), log_file) != line.length()) return false; //将日志立即冲刷到文件中去 fflush(log_file); return true; } void log_producer() { int index = 0; while (true) { ++ index; std::ostringstream os; os \u0026lt;\u0026lt; \u0026#34;This is log, index: \u0026#34; \u0026lt;\u0026lt; index \u0026lt;\u0026lt; \u0026#34;, producer threadID: \u0026#34; \u0026lt;\u0026lt; std::this_thread::get_id() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; //使用花括号括起来为的是减小锁的粒度 { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(log_mutex); cached_logs.emplace_back(os.str()); } std::chrono::milliseconds duration(100); std::this_thread::sleep_for(duration); } } void log_consumer() { std::string line; while (true) { //使用花括号括起来为的是减小锁的粒度 { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(log_mutex); if (!cached_logs.empty()) { line = cached_logs.front(); cached_logs.pop_front(); } } if (line.empty()) { std::chrono::milliseconds duration(1000); std::this_thread::sleep_for(duration); continue; } write_log_tofile(line); line.clear(); } } int main(int argc, char* argv[]) { if (!init_log_file()) { std::cout \u0026lt;\u0026lt; \u0026#34;init log file error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } std::thread log_producer1(log_producer); std::thread log_producer2(log_producer); std::thread log_producer3(log_producer); std::thread log_consumer1(log_consumer); std::thread log_consumer2(log_consumer); std::thread log_consumer3(log_consumer); log_producer1.join(); log_producer2.join(); log_producer3.join(); log_consumer1.join(); log_consumer2.join(); log_consumer3.join(); uninit_log_file(); return 0; } 上述代码分别模拟了三个生产日志的线程（log_producer1～3）和三个消费日志线程（log_consumer1～3）。当然上述代码可以继续优化，如果当前缓存队列中没有日志记录，那么消费日志线程会做无用功。\n优化方法一 可以使用条件变量，如果当前队列中没有日志记录，则将日志消费线程挂起；当生产日志的线程产生了新的日志后，**置信（signal）**条件变量，这样日志消费线程会被唤醒，以将日志从队列中取出来并写入文件。我们来看下代码：\n/** *@desc: AsyncLoggerLinux.cpp *@author: zhangyl *@date: 2018.11.10 */ #include \u0026#34;stdafx.h\u0026#34; #include \u0026lt;thread\u0026gt; #include \u0026lt;mutex\u0026gt; #include \u0026lt;condition_variable\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;sstream\u0026gt; #include \u0026lt;iostream\u0026gt; std::mutex log_mutex; std::condition_variable log_cv; std::list\u0026lt;std::string\u0026gt; cached_logs; FILE* log_file = NULL; bool init_log_file() { //以追加内容的形式写入文件内容，如果文件不存在，则创建 log_file = fopen(\u0026#34;my.log\u0026#34;, \u0026#34;a+\u0026#34;); return log_file != NULL; } void uninit_log_file() { if (log_file != NULL) fclose(log_file); } bool write_log_tofile(const std::string\u0026amp; line) { if (log_file == NULL) return false; if (fwrite((void*)line.c_str(), 1, line.length(), log_file) != line.length()) return false; //将日志立即冲刷到文件中去 fflush(log_file); return true; } void log_producer() { int index = 0; while (true) { ++ index; std::ostringstream os; os \u0026lt;\u0026lt; \u0026#34;This is log, index: \u0026#34; \u0026lt;\u0026lt; index \u0026lt;\u0026lt; \u0026#34;, producer threadID: \u0026#34; \u0026lt;\u0026lt; std::this_thread::get_id() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; //使用花括号括起来为的是减小锁的粒度 { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(log_mutex); cached_logs.emplace_back(os.str()); log_cv.notify_one(); } std::chrono::milliseconds duration(100); std::this_thread::sleep_for(duration); } } void log_consumer() { std::string line; while (true) { //使用花括号括起来为的是减小锁的粒度 { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(log_mutex); if (cached_logs.empty()) { //无限等待 log_cv.wait(lock); } line = cached_logs.front(); cached_logs.pop_front(); } if (line.empty()) { std::chrono::milliseconds duration(1000); std::this_thread::sleep_for(duration); continue; } write_log_tofile(line); line.clear(); } } int main(int argc, char* argv[]) { if (!init_log_file()) { std::cout \u0026lt;\u0026lt; \u0026#34;init log file error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } std::thread log_producer1(log_producer); std::thread log_producer2(log_producer); std::thread log_producer3(log_producer); std::thread log_consumer1(log_consumer); std::thread log_consumer2(log_consumer); std::thread log_consumer3(log_consumer); log_producer1.join(); log_producer2.join(); log_producer3.join(); log_consumer1.join(); log_consumer2.join(); log_consumer3.join(); uninit_log_file(); return 0; } 优化方法二 除了条件变量以外，我们还可以使用信号量来设计我们的异步日志系统，信号量是带有资源计数的线程同步对象，当每产生一条日志时，我们将信号量资源计数自增1，日志消费线程默认是等待这个信号量是否受信，如果受信，每唤醒一个日志消费线程，信号量字数计数将自动减1。通俗地说就是生成者每生产一个资源，就将资源计数加1，而消费者每消费一个资源数量，就将资源计数减一；如果当前资源计数已经为0，则消费者将自动挂起。\n由于 C++ 11 没有提供对不同平台的信号量对象的封装，我们这里分别给出 Windows 和 Linux 两个平台的实现代码，读者可以根据需要来学习其中一个或两个同时学习。注意，为了保持代码风格一致，对于线程和读写文件相关函数，在不同的操作系统平台，我们使用该系统平台相关的 API 接口，而不再使用 C++ 11 的相关函数和类库。\nWindows 平台代码\n/** *@desc: AsyncLogger.cpp，Windows版本 *@author: zhangyl *@date: 2018.11.10 */ #include \u0026#34;stdafx.h\u0026#34; #include \u0026lt;windows.h\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;sstream\u0026gt; std::list\u0026lt;std::string\u0026gt; cached_logs; CRITICAL_SECTION g_cs; HANDLE g_hSemaphore = NULL; HANDLE g_hLogFile = INVALID_HANDLE_VALUE; bool Init() { InitializeCriticalSection(\u0026amp;g_cs); //假设资源数量上限是0xFFFFFFFF g_hSemaphore = CreateSemaphore(NULL, 0, 0xFFFFFFFF, NULL); //如果文件不存在，则创建 g_hLogFile = CreateFile(_T(\u0026#34;my.log\u0026#34;), GENERIC_WRITE, FILE_SHARE_READ, NULL, CREATE_ALWAYS, FILE_ATTRIBUTE_NORMAL, NULL); if (g_hLogFile == INVALID_HANDLE_VALUE) return false; return true; } void Uninit() { DeleteCriticalSection(\u0026amp;g_cs); if (g_hSemaphore != NULL) CloseHandle(g_hSemaphore); if (g_hLogFile != INVALID_HANDLE_VALUE) CloseHandle(g_hLogFile); } bool WriteLogToFile(const std::string\u0026amp; line) { if (g_hLogFile == INVALID_HANDLE_VALUE) return false; DWORD dwBytesWritten; //如果对于比较长的日志，应该分段写入，因为单次写入可能只能写入部分，这里为了演示方便，逻辑从简 if (!WriteFile(g_hLogFile, line.c_str(), line.length(), \u0026amp;dwBytesWritten, NULL) || dwBytesWritten != line.length()) return false; //将日志立即冲刷到文件中去 FlushFileBuffers(g_hLogFile); return true; } DWORD CALLBACK LogProduceThreadProc(LPVOID lpThreadParameter) { int index = 0; while (true) { ++ index; std::ostringstream os; os \u0026lt;\u0026lt; \u0026#34;This is log, index: \u0026#34; \u0026lt;\u0026lt; index \u0026lt;\u0026lt; \u0026#34;, producer threadID: \u0026#34; \u0026lt;\u0026lt; GetCurrentThreadId() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; EnterCriticalSection(\u0026amp;g_cs); cached_logs.emplace_back(os.str()); LeaveCriticalSection(\u0026amp;g_cs); ReleaseSemaphore(g_hSemaphore, 1, NULL); Sleep(100); } return 0; } DWORD CALLBACK LogConsumeThreadProc(LPVOID lpThreadParameter) { std::string line; while (true) { //无限等待 WaitForSingleObject(g_hSemaphore, INFINITE); EnterCriticalSection(\u0026amp;g_cs); if (!cached_logs.empty()) { line = cached_logs.front(); cached_logs.pop_front(); } LeaveCriticalSection(\u0026amp;g_cs); if (line.empty()) { Sleep(1000); continue; } WriteLogToFile(line); line.clear(); } } int main(int argc, char* argv[]) { if (!Init()) { std::cout \u0026lt;\u0026lt; \u0026#34;init log file error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } HANDLE hProducers[3]; for (int i = 0; i \u0026lt; sizeof(hProducers) / sizeof(hProducers[0]); ++i) { hProducers[i] = CreateThread(NULL, 0, LogProduceThreadProc, NULL, 0, NULL); } HANDLE hConsumers[3]; for (int i = 0; i \u0026lt; sizeof(hConsumers) / sizeof(hConsumers[0]); ++i) { hConsumers[i] = CreateThread(NULL, 0, LogConsumeThreadProc, NULL, 0, NULL); } //等待消费者线程退出 for (int i = 0; i \u0026lt; sizeof(hProducers) / sizeof(hProducers[0]); ++i) { WaitForSingleObject(hProducers[i], INFINITE); } //等待生产者线程退出 for (int i = 0; i \u0026lt; sizeof(hConsumers) / sizeof(hConsumers[0]); ++i) { WaitForSingleObject(hConsumers[i], INFINITE); } Uninit(); return 0; } 上述代码，在多线程向队列中增加日志记录和从队列中取出日志记录使用了Windows的上的**临界区（CRITICAL_SECTION，有的书上译作“关键段”）**对象来对队列进行保护。\nLinux 平台代码\n/** *@desc: AsyncLogger.cpp，linux版本 *@author: zhangyl *@date: 2018.11.10 */ #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;semaphore.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;sstream\u0026gt; std::list\u0026lt;std::string\u0026gt; cached_logs; pthread_mutex_t log_mutex = PTHREAD_MUTEX_INITIALIZER; sem_t log_semphore; FILE* plogfile = NULL; bool init() { pthread_mutex_init(\u0026amp;log_mutex, NULL); //初始信号量资源数目是0 sem_init(\u0026amp;log_semphore, 0, 0); //如果文件不存在，则创建 plogfile = fopen(\u0026#34;my.log\u0026#34;, \u0026#34;a++\u0026#34;); return plogfile != NULL; } void uninit() { pthread_mutex_destroy(\u0026amp;log_mutex); sem_destroy(\u0026amp;log_semphore); if (plogfile != NULL) fclose(plogfile); } bool write_log_to_file(const std::string\u0026amp; line) { if (plogfile == NULL) return false; //如果对于比较长的日志，应该分段写入，因为单次写入可能只能写入部分，这里为了演示方便，逻辑从简 if (fwrite((void*)line.c_str(), 1, line.length(), plogfile) != line.length()) return false; //将日志立即冲刷到文件中去 fflush(plogfile); return true; } void* producer_thread_proc(void* arg) { int index = 0; while (true) { ++ index; std::ostringstream os; os \u0026lt;\u0026lt; \u0026#34;This is log, index: \u0026#34; \u0026lt;\u0026lt; index \u0026lt;\u0026lt; \u0026#34;, producer threadID: \u0026#34; \u0026lt;\u0026lt; pthread_self() \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; pthread_mutex_lock(\u0026amp;log_mutex); cached_logs.push_back(os.str()); pthread_mutex_unlock(\u0026amp;log_mutex); sem_post(\u0026amp;log_semphore); usleep(100000); } } void* consumer_thread_proc(void* arg) { std::string line; while (true) { //无限等待 sem_wait(\u0026amp;log_semphore); pthread_mutex_lock(\u0026amp;log_mutex); if (!cached_logs.empty()) { line = cached_logs.front(); cached_logs.pop_front(); } pthread_mutex_unlock(\u0026amp;log_mutex); if (line.empty()) { sleep(1); continue; } write_log_to_file(line); line.clear(); } } int main(int argc, char* argv[]) { if (!init()) { std::cout \u0026lt;\u0026lt; \u0026#34;init log file error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } pthread_t producer_thread_id[3]; for (int i = 0; i \u0026lt; sizeof(producer_thread_id) / sizeof(producer_thread_id[0]); ++i) { pthread_create(\u0026amp;producer_thread_id[i], NULL, producer_thread_proc, NULL); } pthread_t consumer_thread_id[3]; for (int i = 0; i \u0026lt; sizeof(consumer_thread_id) / sizeof(consumer_thread_id[0]); ++i) { pthread_create(\u0026amp;consumer_thread_id[i], NULL, consumer_thread_proc, NULL); } //等待消费者线程退出 for (int i = 0; i \u0026lt; sizeof(producer_thread_id) / sizeof(producer_thread_id[0]); ++i) { pthread_join(producer_thread_id[i], NULL); } //等待生产者线程退出 for (int i = 0; i \u0026lt; sizeof(consumer_thread_id) / sizeof(consumer_thread_id[0]); ++i) { pthread_join(consumer_thread_id[i], NULL); } uninit(); return 0; } 我们使用 g++ 编译器编译上述代码，使用如下命令生成可移植性文件 AsyncLoggerLinux：\ng++ -g -o AsyncLoggerLinux AsyncLoggerLinux.cpp -lpthread 接着执行生成的 AsyncLoggerLinux 文件，然后生成的日志效果如下：\nThis is log, index: 1, producer threadID: 140512358795008 This is log, index: 1, producer threadID: 140512367187712 This is log, index: 1, producer threadID: 140512375580416 This is log, index: 2, producer threadID: 140512358795008 This is log, index: 2, producer threadID: 140512367187712 This is log, index: 2, producer threadID: 140512375580416 This is log, index: 3, producer threadID: 140512358795008 This is log, index: 3, producer threadID: 140512367187712 This is log, index: 3, producer threadID: 140512375580416 This is log, index: 4, producer threadID: 140512358795008 This is log, index: 4, producer threadID: 140512367187712 This is log, index: 4, producer threadID: 140512375580416 This is log, index: 5, producer threadID: 140512358795008 This is log, index: 5, producer threadID: 140512367187712 This is log, index: 5, producer threadID: 140512375580416 //省略... 当然，您可能需要同时能在 Windows 和 Linux 同时运行的代码，我们自然而然想到用 C++11 语法的信号量，由于 C++ 11 本身没有提供现成的信号量库，我们可以自己利用std::mutex、std::condition_variable模拟一下信号量的功能，这里就不再详细介绍了，有兴趣的可以自行尝试一下。\n以上就是异步日志的基本原理，在这个原理的基础上，我们可以增加很多的特性。\n","permalink":"https://haokiu.com/blog/1549ab1669fe40dda14c41a84df83415/","summary":"日志系统的设计 为什么需要日志 实际的软件项目产出都有一个流程，即先开发、测试，再发布生产，由于人的因素，既然是软件产品就不可能百分百没有 bug 或者逻辑错误，对于已经发布到生产的项目，一旦某个时刻产生非预期的结果，我们就需要去定位和排查问题。但是一般正式的生产环境的服务器或者产品是不允许开发人员通过附加调试器去排查问题的，主要有如下可能原因：\n在很多互联网企业，开发部门、测试部分和产品运维部门是分工明确的，软件产品一旦发布到生产环境以后，将全部交由运维部门人员去管理和维护，而原来开发此产品的开发人员不再拥有相关的操作程序的权限。 对于已经上了生产环境的服务，其数据和程序稳定性是公司的核心产值所在，一般不敢或不允许被开发人员随意调试或者操作，以免造成损失。 发布到生产环境的服务，一般为了让程序执行效率更高、文件体积更小，都是去掉调试符号后的版本，不方便也不利于调试。 既然我们无法通过调试器去调试，这个时候为了跟踪和回忆当时的程序行为进而定位问题，我们就需要日志系统。\n退一步说，即使在开发或者测试环境，我们可以把程序附加到调试器上去调试，但是对于一些特定的程序行为，我们无法通过设置断点，让程序在某个时刻暂停下来进行调试。例如，对于某些网络通信功能，如果暂停时间过长（相对于某些程序逻辑来说），通信的对端可能由于彼端没有在规定时间内响应而断开连接，导致程序逻辑无法进入我们想要的执行流中去；再例如，对于一些高频操作（如心跳包、定时器、界面绘制下的某些高频重复行为），可能在少量次数下无法触发我们想要的行为，而通过断点的暂停方式，我们不得不重复操作几十次、上百次甚至更多，这样排查问题效率是非常低下的。对于这类操作，我们可以通过打印日志，将当时的程序行为上下文现场记录下来，然后从日志系统中找到某次不正常的行为的上下文信息。这也是日志的另外一个作用。\n本文将从技术和业务上两个方面来介绍日志系统相关的设计与开发，所谓技术上，就是如何从程序开发的角度设计一款功能强大、性能优越、使用方便的日志系统；而业务上，是指我们在使用日志系统时，应该去记录哪些行为和数据，既简洁、不啰嗦，又方便需要时快速准确地定位到问题。\n日志系统的技术上的实现 日志的最初的原型即将程序运行的状态打印出来，对于 C/C++ 这门语言来说，即可以利用 printf、std::cout 等控制台输出函数，将日志信息输出到控制台，这类简单的情形我们不在此过多赘述。\n对于商业项目，为了方便排查问题，我们一般不将日志写到控制台，而是输出到文件或者数据库系统。不管哪一种，其思路基本上一致，我们这里以写文件为例来详细介绍。\n同步写日志 所谓同步写日志，指的是在输出日志的地方，将日志即时写入到文件中去。根据笔者的经验，这种设计广泛地用于相当多的的客户端软件。笔者曾从事过数年的客户端开发（包括 PC、安卓软件），设计过一些功能复杂的金融客户端产品，在这些系统中采用的就是这种同步写日志的方式。之所以使用这种方式其主要原因就是设计简单，而又不会影响用户使用体验。说到这里读者可能有这样一个疑问：一般的客户端软件，一般存在界面，而界面部分所属的逻辑就是程序的主线程，如果采取这种同步写日志的方式，当写日志时，写文件是磁盘 IO 操作，相比较程序其他部分是 CPU 操作，前者要慢很多，这样势必造成CPU等待，进而导致主线程“卡”在写文件处，进而造成界面卡顿，从而导致用户使用软件的体验不好。读者的这种顾虑确实是存在的。但是，很多时候我们不用担心这种问题，主要有两个原因：\n对于客户端程序，即使在主线程（UI 线程）中同步写文件，其单次或者几次磁盘操作累加时间，与人（用户）的可感知时间相比，也是非常小的，也就是说用户根本感觉不到这种同步写文件造成的延迟。当然，这里也给您一个提醒就是，如果在 UI 线程里面写日志，尤其是在一些高频操作中（如 Windows 的界面绘制消息 WM_PAINT 处理逻辑中），一定要控制写日志的长度和次数，否则就会因频繁写文件或一次写入数据过大而对界面造成卡顿。 客户端程序除了 UI 线程，还有其他与界面无关的工作线程，在这些线程中直接写文件，一般不会对用户的体验产生什么影响。 说了这么多，我们给出一个具体的例子。\n日志类的 .h 文件\n/** *@desc: IULog.h *@author: zhangyl *@date: 2014.12.25 */ #ifndef __LOG_H__ #define __LOG_H__ enum LOG_LEVEL { LOG_LEVEL_INFO, LOG_LEVEL_WARNING, LOG_LEVEL_ERROR }; //注意：如果打印的日志信息中有中文，则格式化字符串要用_T()宏包裹起来， #define LOG_INFO(...) CIULog::Log(LOG_LEVEL_INFO, __FUNCSIG__,__LINE__, __VA_ARGS__) #define LOG_WARNING(...) CIULog::Log(LOG_LEVEL_WARNING, __FUNCSIG__, __LINE__,__VA_ARGS__) #define LOG_ERROR(...) CIULog::Log(LOG_LEVEL_ERROR, __FUNCSIG__,__LINE__, __VA_ARGS__) class CIULog { public: static bool Init(bool bToFile, bool bTruncateLongLog, PCTSTR pszLogFileName); static void Uninit(); static void SetLevel(LOG_LEVEL nLevel); //不输出线程ID号和所在函数签名、行号 static bool Log(long nLevel, PCTSTR pszFmt, .","title":"日志系统的设计"},{"content":"给工作 4 年迷茫的程序员们的一点建议 有公众号读者在后台向我提问：\nJAVA 程序员，4 年了，迷茫了，希望由前辈可以给指出一个技术路线5年左右程序员必须要掌握的知识技能树?\n工作了很久了，对于目前自己的技术程度不满意，但是不知道如何梳理。学习一些技术是不知道是否有用。希望前辈可以指点迷津。不以年限轮英雄，希望可以给出您的见解。修改一次。。。。。。项目设计都是我来做。。。数据库设计也是我来做。。。我的意思是。。感觉目前自己的知识储备不足以支撑我架构以及设计。。求个知识树。。。。\n以下是我的回答：\n先举两个真实的例子。\n例子一： 前两天我在给我们部门做服务器网络故障排查经验分享时，我问了一个问题关于 java.io.DataOutputStream 的问题，如果从一个 socket 输出流中读取数据，如果当前流中没有数据，读方法是否会阻塞。我又问，假如阻塞，会阻塞多久？我们如何避免这个问题。很多人回答不上来，更不用说，Java 中的 AIO、NIO 的使用细节了。\n例子二： 我归纳一下，情况大致如下： 有不少朋友通过我的公众号『高性能服务器开发』中的『职业指导』模块找到我，来意大致是：做 java 开发工作了三五年了，月收入不到二万，现在因为人到中年，经济压力比较大; 但是工作上只能做做模块，写写业务代码，所以即使跳槽也不会拿到满意的薪资，所以只好维持现状(但又特别苦闷、迷茫)。\n我来说一下我的观点，说的现实一点，题主所谓的迷茫其实因知识能力的不足导致的成就感、收入水平与日益增长的工作年限的矛盾。\n越是高薪的职位，其对人的要求也越高。诸如上面的例子，工作有几年的 java 开发者，连 jdk 中基本的输入输出流的细节都搞不清楚，一问到就是各种摇头，然后说各种 java 框架，这样的开发者其实并不合格，因为他们离开了框架就啥也做不了，那么在工作安排上这样的人不天天也业务代码，谁来写呢？(核心的技术框架是不能让他们写的，由于基础水平不扎实，写出来的框架稳定性和性能会不好)。说的悲观一点，这样的开发者公司是从来不缺的，铁打的营盘，流水的兵，走了再招一批罢了，这也就是所谓的千军易得一将难求，我们要努力做将才乃至帅才，而不是小兵。\n在面试某些 java 开发者时，我问的比较多的一个问题就是，java 多线程之间的同步技术有哪些，然后不少面试者就病急乱投医了，甚至连 ConcurrentHashMap 都说上了。这也是典型的基础概念模糊不清，ConcurrentHashMap 是一个线程安全性容器，但绝不是一个线程同步技术。\n再比如问面试者 java.lang.Object 有哪些常用方法时，不少面试者能说出来的也不多。\n我举这些例子并不是为了要教大家具体的 java 知识，而是为了说明基础知识的重要性。如果你的java基础足够好(熟悉 jdk 的常用类，知道常用接口的各种坑和注意事项)，那么开发一个东西时即使不用框架你也能顺畅地写出来。这样的人才具备进一步发展的潜力。退一步说，不管多么复杂的java框架，都是基于jdk那些类库的。你jdk的基础知识都学不好，我不相信那些上层框架你能搞的透彻。\n说一千道一万，核心的还是基础知识不扎实的问题。就和刘备当年成就帝业一样，诸葛亮给的策略就是先谋取荆州，再进军西蜀，最后三分天下。同理jdk的基础知识就是你应该要首先谋取的“荆州”，进一步的各种框架、架构设计是你的“蜀地”。基础不牢，想其他的东西都是好高骛远，不切实际。最后日复一日，年复一年，在恨自己生不逢时，领导不是伯乐的嗟叹中蹉跎了岁月。\n对于上面这个注重基础的问题上，实际情形中，我遇到三种人。\n第一类：意识不到基础知识的重要性，这类人就不提了。\n第二类，意识到基础知识的重要性，但是总是在各种理由和借口中麻痹自己，温水煮青蛙把自己“煮死”。很多咨询我的人，也是这种情况，说什么自己工作忙，家庭琐事多。我其实不想多说啥，为失败找借口的人太多，为成功找方法的人太少。你工作五年了，每个月抽一天时间来补一下基础，你现在都不是这样了，这个时间也抽不出来？自我麻痹而已。这类人其实是有想法没啥行动。\n第三类，意识到基础的重要性，同时在各种闲暇时间去补充，去积累。这样的人学的最快，最后达到的高度也很高（当然收入也不菲）。\n扎实的基础知识 + 见多识广的框架经验，让你在职场上变得无可替代，这才是你的核心竞争力。答案可能有点跑题了，但是我觉得先解决思想上的问题，行动上就容易许多了。\n如果你想和我聊聊职业上的困惑，可以在『高性能服务器开发』公众号后台回复关键字『职业指导』，我们可以针对性地聊一聊。\n","permalink":"https://haokiu.com/blog/049d41c798c54956b4c2b094aacec413/","summary":"给工作 4 年迷茫的程序员们的一点建议 有公众号读者在后台向我提问：\nJAVA 程序员，4 年了，迷茫了，希望由前辈可以给指出一个技术路线5年左右程序员必须要掌握的知识技能树?\n工作了很久了，对于目前自己的技术程度不满意，但是不知道如何梳理。学习一些技术是不知道是否有用。希望前辈可以指点迷津。不以年限轮英雄，希望可以给出您的见解。修改一次。。。。。。项目设计都是我来做。。。数据库设计也是我来做。。。我的意思是。。感觉目前自己的知识储备不足以支撑我架构以及设计。。求个知识树。。。。\n以下是我的回答：\n先举两个真实的例子。\n例子一： 前两天我在给我们部门做服务器网络故障排查经验分享时，我问了一个问题关于 java.io.DataOutputStream 的问题，如果从一个 socket 输出流中读取数据，如果当前流中没有数据，读方法是否会阻塞。我又问，假如阻塞，会阻塞多久？我们如何避免这个问题。很多人回答不上来，更不用说，Java 中的 AIO、NIO 的使用细节了。\n例子二： 我归纳一下，情况大致如下： 有不少朋友通过我的公众号『高性能服务器开发』中的『职业指导』模块找到我，来意大致是：做 java 开发工作了三五年了，月收入不到二万，现在因为人到中年，经济压力比较大; 但是工作上只能做做模块，写写业务代码，所以即使跳槽也不会拿到满意的薪资，所以只好维持现状(但又特别苦闷、迷茫)。\n我来说一下我的观点，说的现实一点，题主所谓的迷茫其实因知识能力的不足导致的成就感、收入水平与日益增长的工作年限的矛盾。\n越是高薪的职位，其对人的要求也越高。诸如上面的例子，工作有几年的 java 开发者，连 jdk 中基本的输入输出流的细节都搞不清楚，一问到就是各种摇头，然后说各种 java 框架，这样的开发者其实并不合格，因为他们离开了框架就啥也做不了，那么在工作安排上这样的人不天天也业务代码，谁来写呢？(核心的技术框架是不能让他们写的，由于基础水平不扎实，写出来的框架稳定性和性能会不好)。说的悲观一点，这样的开发者公司是从来不缺的，铁打的营盘，流水的兵，走了再招一批罢了，这也就是所谓的千军易得一将难求，我们要努力做将才乃至帅才，而不是小兵。\n在面试某些 java 开发者时，我问的比较多的一个问题就是，java 多线程之间的同步技术有哪些，然后不少面试者就病急乱投医了，甚至连 ConcurrentHashMap 都说上了。这也是典型的基础概念模糊不清，ConcurrentHashMap 是一个线程安全性容器，但绝不是一个线程同步技术。\n再比如问面试者 java.lang.Object 有哪些常用方法时，不少面试者能说出来的也不多。\n我举这些例子并不是为了要教大家具体的 java 知识，而是为了说明基础知识的重要性。如果你的java基础足够好(熟悉 jdk 的常用类，知道常用接口的各种坑和注意事项)，那么开发一个东西时即使不用框架你也能顺畅地写出来。这样的人才具备进一步发展的潜力。退一步说，不管多么复杂的java框架，都是基于jdk那些类库的。你jdk的基础知识都学不好，我不相信那些上层框架你能搞的透彻。\n说一千道一万，核心的还是基础知识不扎实的问题。就和刘备当年成就帝业一样，诸葛亮给的策略就是先谋取荆州，再进军西蜀，最后三分天下。同理jdk的基础知识就是你应该要首先谋取的“荆州”，进一步的各种框架、架构设计是你的“蜀地”。基础不牢，想其他的东西都是好高骛远，不切实际。最后日复一日，年复一年，在恨自己生不逢时，领导不是伯乐的嗟叹中蹉跎了岁月。\n对于上面这个注重基础的问题上，实际情形中，我遇到三种人。\n第一类：意识不到基础知识的重要性，这类人就不提了。\n第二类，意识到基础知识的重要性，但是总是在各种理由和借口中麻痹自己，温水煮青蛙把自己“煮死”。很多咨询我的人，也是这种情况，说什么自己工作忙，家庭琐事多。我其实不想多说啥，为失败找借口的人太多，为成功找方法的人太少。你工作五年了，每个月抽一天时间来补一下基础，你现在都不是这样了，这个时间也抽不出来？自我麻痹而已。这类人其实是有想法没啥行动。\n第三类，意识到基础的重要性，同时在各种闲暇时间去补充，去积累。这样的人学的最快，最后达到的高度也很高（当然收入也不菲）。\n扎实的基础知识 + 见多识广的框架经验，让你在职场上变得无可替代，这才是你的核心竞争力。答案可能有点跑题了，但是我觉得先解决思想上的问题，行动上就容易许多了。\n如果你想和我聊聊职业上的困惑，可以在『高性能服务器开发』公众号后台回复关键字『职业指导』，我们可以针对性地聊一聊。","title":"给工作 4 年迷茫的程序员们的一点建议"},{"content":"聊聊技术人员的常见的职业问题 由于时间有限，很多读者提出的问题，不能一一解答，因此这篇文章，来系统地就各类型的读者遇到的一些常见职业问题回答一下：\nQ1 应届生如何选择自己的第一份工作？\nQ2 作为一个程序员，是进入大厂好，还是进入创业公司好？\nQ3 我专科（或二本）毕业，学历不行，如何进大厂工作？\nQ4 我非科班出身，如何进大厂工作？\nQ5 有没有人能分享一下大厂的面经？\nA1 答案点 这里 和 这里。\nQ6 我工作了几年，技术不行，如何提高？\nQ7 我非科班出身，应该看哪些书才能补上计算机专业的基础？\nQ8 我想成为一名技术高手，应该如何提高？\nQ9 天天写业务代码，如何能有机会做一些底层的设计和开发？\nA2 答案点 这里。\nQ10 服务器端开发与前端开发有什么差别？哪个发展潜力好一点？哪个薪资高一点？\nA3 答案点 这里。\nQ11 我想成为一名 C++ 程序员，该如何入门、进阶以及升华？\nQ12 C++ 后端开发需要掌握哪些东西？\nQ13 C++ 面试应该准备哪些东西？\nA4 答案点 这里 和 这里 以及 这里。\nQ15 我是一名 Java 程序员，天天增删改查数据库，我如何实质性的提高自己？\nQ16 Java 技术栈的所谓的基础在哪里？\nA5 答案点 这里。\nQ17 程序员真的很难找女朋友吗？\nQ18 大厂加班严重，在大厂上班的程序员真的没有女朋友吗？\nA6 这是一个忧伤的话题，答案戳 这里 和 这里 以及 **这里****。\nQ20 如何通过技术面试来确定面试官的职级？如何确定自己面试职位所对应的职级？\nA7 答案看 这里。\nQ21 技术面试中，面试官问我薪资，我该不该告诉他？\nQ22 技术面试过了，如何和 HR 谈薪水？\nQ23 我报了一个薪水之后，HR 爽快的答应了，我是不是报低了？我能不能再找他们提高一点？\nA8 答案看 这里。\nQ24 年薪五十万的技术岗位做些什么工作？\nQ25 做技术岗位如何年薪五十万呢？\nQ26 年薪五十万的程序员是不是真的头发很少？\nA9 别害怕，答案戳 这里。\nQ26 年终奖是如何发的？什么时候发？\nQ27 年终奖还没发，我跳槽是不是就没有年终奖了？\nQ28 入职时人事说月薪低一点，年终奖多很多，我要不要同意？\nA10 答案点 这里。\nQ29 结婚有娃了，生活压力大，工资入不敷出，如何改变？\nQ30 钱不够花，作为一名只会写代码的码农，我如何赚点外快呢？\nA11 答案看 这里。\nQ31 工资爆炸式的增长是一种什么体验**？**\nA12 答案\n在\u0026hellip;\n*在知乎的故事里 T_T。*\n","permalink":"https://haokiu.com/blog/1908cdb9f5c747b996136e3b3e408b8d/","summary":"聊聊技术人员的常见的职业问题 由于时间有限，很多读者提出的问题，不能一一解答，因此这篇文章，来系统地就各类型的读者遇到的一些常见职业问题回答一下：\nQ1 应届生如何选择自己的第一份工作？\nQ2 作为一个程序员，是进入大厂好，还是进入创业公司好？\nQ3 我专科（或二本）毕业，学历不行，如何进大厂工作？\nQ4 我非科班出身，如何进大厂工作？\nQ5 有没有人能分享一下大厂的面经？\nA1 答案点 这里 和 这里。\nQ6 我工作了几年，技术不行，如何提高？\nQ7 我非科班出身，应该看哪些书才能补上计算机专业的基础？\nQ8 我想成为一名技术高手，应该如何提高？\nQ9 天天写业务代码，如何能有机会做一些底层的设计和开发？\nA2 答案点 这里。\nQ10 服务器端开发与前端开发有什么差别？哪个发展潜力好一点？哪个薪资高一点？\nA3 答案点 这里。\nQ11 我想成为一名 C++ 程序员，该如何入门、进阶以及升华？\nQ12 C++ 后端开发需要掌握哪些东西？\nQ13 C++ 面试应该准备哪些东西？\nA4 答案点 这里 和 这里 以及 这里。\nQ15 我是一名 Java 程序员，天天增删改查数据库，我如何实质性的提高自己？\nQ16 Java 技术栈的所谓的基础在哪里？\nA5 答案点 这里。\nQ17 程序员真的很难找女朋友吗？\nQ18 大厂加班严重，在大厂上班的程序员真的没有女朋友吗？\nA6 这是一个忧伤的话题，答案戳 这里 和 这里 以及 **这里****。\nQ20 如何通过技术面试来确定面试官的职级？如何确定自己面试职位所对应的职级？\nA7 答案看 这里。\nQ21 技术面试中，面试官问我薪资，我该不该告诉他？\nQ22 技术面试过了，如何和 HR 谈薪水？\nQ23 我报了一个薪水之后，HR 爽快的答应了，我是不是报低了？我能不能再找他们提高一点？\nA8 答案看 这里。\nQ24 年薪五十万的技术岗位做些什么工作？\nQ25 做技术岗位如何年薪五十万呢？\nQ26 年薪五十万的程序员是不是真的头发很少？\nA9 别害怕，答案戳 这里。\nQ26 年终奖是如何发的？什么时候发？\nQ27 年终奖还没发，我跳槽是不是就没有年终奖了？","title":"聊聊技术人员的常见的职业问题"},{"content":"职业规划 给工作 4 年迷茫的程序员们的一点建议\n聊聊技术人员的常见的职业问题\n写给那些傻傻想做服务器开发的朋友\n","permalink":"https://haokiu.com/blog/01f6fc4ce7c54057a2379aab6b98843f/","summary":"职业规划 给工作 4 年迷茫的程序员们的一点建议\n聊聊技术人员的常见的职业问题\n写给那些傻傻想做服务器开发的朋友","title":"职业规划"},{"content":"自我提升与开源代码 2020 年好好读一读开源代码吧 ","permalink":"https://haokiu.com/blog/e50a72b7fb4e47a9904a05621e5b692f/","summary":"自我提升与开源代码 2020 年好好读一读开源代码吧 ","title":"自我提升与开源代码"},{"content":"错误码系统的设计 本文介绍服务器开发中一组服务中错误码系统的设计理念与实践，如果读者从来没想过或者没接触过这种设计理念，建议认真体会一下这种设计思路的优点。\n错误码的作用 读者如果有使用过中国电信的宽带账号上网的经历，如果我们登陆不成功，一般服务器会返回一个错误码，如651、678。然后，我们打中国电信的客服电话，客服会询问我们错误码是多少，通过错误码他们的技术人员就大致知道了错误原因；并且通过错误码，他们就知道到底是电信的服务器问题还是宽带用户自己的设备或者操作问题，如果是用户自己的问题，他们一般会尝试教用户如何操作，而不是冒然就派遣维修人员上门，这样不仅能尽早解决问题同时也节约了人力成本。\n再举另外一个例子，我们日常浏览网页，当Web服务器正常返回页面时，状态码一般是200(OK)，而当页面不存在时，错误码一般是404，另外像503等错误都是比较常见的。\n通过以上两个例子，读者应该能明白，对于服务器系统来说，设计一套好的错误码是非常有必要的，可以在用户请求出问题时迅速定位并解决问题。具体包括两个方面：\n可以迅速定位是用户“输入”问题还是服务器自身的问题。 所谓的用户“输入”问题，是指用户的不当操作，这里的“用户的不当操作”可能是因为客户端软件本身的逻辑错误或漏洞，也可能是使用客户端的人的非法操作，而客户端软件在设计上因为考虑不周而缺乏有效性校验，这两类情形都可能会产生非法的数据，并且直接发给服务器。一个好的服务端系统不能假设客户端的请求数据一定是合法的，必须对传过来的数据做有效性校验。服务器没有义务一定给非法的请求做出应答，因此请求的最终结果是服务器不应答或给客户端不想要的应答。\n以上面的例子为例，宽带用户输入了无效的用户名或者密码造成服务器拒绝访问；用户在浏览器中输入了一个无效的网址等。这类错误，都是需要用户自己解决或者用户可以自己解决的。如果错误码可以反映出这类错误，那么在实际服务器运维的过程中，当用户反馈这一类故障时，我们通过服务器内部产生的错误码或者应答给客户端的错误码，准确快速地确定问题原因。如果是用户非法请求造成的，可以让用户自行解决。注意，这里的“用户”，可以代指人，也可以代指使用某个服务器的所有下游服务和客户端。\n可以快速定位哪个步骤或哪个服务出了问题。\n对于单个服务，假设收到某个“客户端”请求时，需要经历多个步骤才能完成，而这中间任何一个步骤都可能出问题，在不同步骤出错时返回不同的错误码，那么就可以知道是哪个步骤出了问题。\n其次，一般稍微复杂一点的系统，都不是单个服务，往往是由一组服务构成。如果将错误码分段，每个服务的错误码都有各自的范围，那么通过错误码，我们也能准确地知道是哪个服务出了问题。\n错误码系统设计实践 前面介绍了太多的理论知识，我们来看一个具体的例子。假设如下一个“智能邮件系统”，其结构如下所示：\n上图中的服务**“智能邮件坐席站点”和“配置站点”是客户端，”智能邮件操作综合接口“和”邮件配置服务“**是对客户端提供服务的前置服务，这两个前置服务后面还依赖后面的数个服务。由于这里我们要说明的是技术问题，而不是业务问题，所以具体每个服务作何用途这里就不一一介绍了。在这个系统中，当客户端得到前置服务某个不正确应答时，会得到一个错误码，我们按以下规则来设计错误码：\n服务名称 正值错误码范围 负值错误码范围 智能邮件综合操作接口 100~199 -100~-199 ES数据同步服务 200~299 -200~-299 邮件配置服务 300~399 -300~-399 邮件基础服务 400~499 -400~-499 我们在设计这套系统时，做如下规定：\n所有的正值错误码表示所在服务的上游服务发来的请求不满足业务要求。举个例子，假设某次智能邮件坐席站点客户端得到了一个错误码101，我们可以先确定错误产生的服务器是智能邮件综合操作接口服务；其次，产生该错误的原因是智能邮件坐席站点客户端发送给智能邮件综合操作接口服务的请求不满足要求，通过这个错误码我们甚至可以进一步确定发送的请求哪里不符合要求。如我们可以这样定义： 100 用户名不存在\n101 密码无效\n102 发送的邮件收件人非法\n103 邮件正文含有非法字符\n其他从略，此处就不一一列举了。\n所有的负值错误码表示程序内部错误。如： -100 数据库操作错误\n-101 网络错误\n-102 内存分配失败\n-103 ES数据同步服务连接不上\n其他从略，此处就不一一列举了。\n对负值错误码的特殊处理 通过前面的介绍，读者应该能看出正值错误码与负值错误码的区别，即正值错误码一般是由请求服务的客户产生，如果出现这样的错误，应该由客户自己去解决问题；而负值错误码，则一般是服务内部产生的错误。因此，如果是正值错误码，错误码和错误信息一般可以直接返回给客户端；而对于负值错误，我们一般只将错误码返回给客户端，而不带上具体的错误信息，这也是读者在使用很多软件产品时，经常会得到“网络错误”这类万能错误提示。也就是说对于负值错误码的错误信息，我们可以统一显示成“网络错误”或者其他比较友好的错误提示。\n这样做的原因有二：\n客户端即使拿到这样的错误信息，也不能对排查和解决问题提供任何帮助，因为这些错误是程序内部错误或者bug。 这类错误有可能是企业内部的设计缺陷，直接暴露给客户，除了让客户对企业的技术实力产生质疑以外，没有任何其他正面效应。 而之所以带上错误码，是为了方便内部排查和定位问题。当然，现在的企业服务，内部也有大量监控系统，可能也不会再暴露这样的错误码了。\n扩展 上文介绍了利用错误码的分段来定位问题的技术思想，其实不仅仅是错误码可以分段，我们在开发一组服务时，业务类型也可以通过编号来分段，这样通过业务号就能知道归属哪个服务了。\n如果读者以前没接触过这种设计思想，希望可以好好的思考和体会一下。\n","permalink":"https://haokiu.com/blog/32ba3bce20124dd380cdde0bba6ef5b9/","summary":"错误码系统的设计 本文介绍服务器开发中一组服务中错误码系统的设计理念与实践，如果读者从来没想过或者没接触过这种设计理念，建议认真体会一下这种设计思路的优点。\n错误码的作用 读者如果有使用过中国电信的宽带账号上网的经历，如果我们登陆不成功，一般服务器会返回一个错误码，如651、678。然后，我们打中国电信的客服电话，客服会询问我们错误码是多少，通过错误码他们的技术人员就大致知道了错误原因；并且通过错误码，他们就知道到底是电信的服务器问题还是宽带用户自己的设备或者操作问题，如果是用户自己的问题，他们一般会尝试教用户如何操作，而不是冒然就派遣维修人员上门，这样不仅能尽早解决问题同时也节约了人力成本。\n再举另外一个例子，我们日常浏览网页，当Web服务器正常返回页面时，状态码一般是200(OK)，而当页面不存在时，错误码一般是404，另外像503等错误都是比较常见的。\n通过以上两个例子，读者应该能明白，对于服务器系统来说，设计一套好的错误码是非常有必要的，可以在用户请求出问题时迅速定位并解决问题。具体包括两个方面：\n可以迅速定位是用户“输入”问题还是服务器自身的问题。 所谓的用户“输入”问题，是指用户的不当操作，这里的“用户的不当操作”可能是因为客户端软件本身的逻辑错误或漏洞，也可能是使用客户端的人的非法操作，而客户端软件在设计上因为考虑不周而缺乏有效性校验，这两类情形都可能会产生非法的数据，并且直接发给服务器。一个好的服务端系统不能假设客户端的请求数据一定是合法的，必须对传过来的数据做有效性校验。服务器没有义务一定给非法的请求做出应答，因此请求的最终结果是服务器不应答或给客户端不想要的应答。\n以上面的例子为例，宽带用户输入了无效的用户名或者密码造成服务器拒绝访问；用户在浏览器中输入了一个无效的网址等。这类错误，都是需要用户自己解决或者用户可以自己解决的。如果错误码可以反映出这类错误，那么在实际服务器运维的过程中，当用户反馈这一类故障时，我们通过服务器内部产生的错误码或者应答给客户端的错误码，准确快速地确定问题原因。如果是用户非法请求造成的，可以让用户自行解决。注意，这里的“用户”，可以代指人，也可以代指使用某个服务器的所有下游服务和客户端。\n可以快速定位哪个步骤或哪个服务出了问题。\n对于单个服务，假设收到某个“客户端”请求时，需要经历多个步骤才能完成，而这中间任何一个步骤都可能出问题，在不同步骤出错时返回不同的错误码，那么就可以知道是哪个步骤出了问题。\n其次，一般稍微复杂一点的系统，都不是单个服务，往往是由一组服务构成。如果将错误码分段，每个服务的错误码都有各自的范围，那么通过错误码，我们也能准确地知道是哪个服务出了问题。\n错误码系统设计实践 前面介绍了太多的理论知识，我们来看一个具体的例子。假设如下一个“智能邮件系统”，其结构如下所示：\n上图中的服务**“智能邮件坐席站点”和“配置站点”是客户端，”智能邮件操作综合接口“和”邮件配置服务“**是对客户端提供服务的前置服务，这两个前置服务后面还依赖后面的数个服务。由于这里我们要说明的是技术问题，而不是业务问题，所以具体每个服务作何用途这里就不一一介绍了。在这个系统中，当客户端得到前置服务某个不正确应答时，会得到一个错误码，我们按以下规则来设计错误码：\n服务名称 正值错误码范围 负值错误码范围 智能邮件综合操作接口 100~199 -100~-199 ES数据同步服务 200~299 -200~-299 邮件配置服务 300~399 -300~-399 邮件基础服务 400~499 -400~-499 我们在设计这套系统时，做如下规定：\n所有的正值错误码表示所在服务的上游服务发来的请求不满足业务要求。举个例子，假设某次智能邮件坐席站点客户端得到了一个错误码101，我们可以先确定错误产生的服务器是智能邮件综合操作接口服务；其次，产生该错误的原因是智能邮件坐席站点客户端发送给智能邮件综合操作接口服务的请求不满足要求，通过这个错误码我们甚至可以进一步确定发送的请求哪里不符合要求。如我们可以这样定义： 100 用户名不存在\n101 密码无效\n102 发送的邮件收件人非法\n103 邮件正文含有非法字符\n其他从略，此处就不一一列举了。\n所有的负值错误码表示程序内部错误。如： -100 数据库操作错误\n-101 网络错误\n-102 内存分配失败\n-103 ES数据同步服务连接不上\n其他从略，此处就不一一列举了。\n对负值错误码的特殊处理 通过前面的介绍，读者应该能看出正值错误码与负值错误码的区别，即正值错误码一般是由请求服务的客户产生，如果出现这样的错误，应该由客户自己去解决问题；而负值错误码，则一般是服务内部产生的错误。因此，如果是正值错误码，错误码和错误信息一般可以直接返回给客户端；而对于负值错误，我们一般只将错误码返回给客户端，而不带上具体的错误信息，这也是读者在使用很多软件产品时，经常会得到“网络错误”这类万能错误提示。也就是说对于负值错误码的错误信息，我们可以统一显示成“网络错误”或者其他比较友好的错误提示。\n这样做的原因有二：\n客户端即使拿到这样的错误信息，也不能对排查和解决问题提供任何帮助，因为这些错误是程序内部错误或者bug。 这类错误有可能是企业内部的设计缺陷，直接暴露给客户，除了让客户对企业的技术实力产生质疑以外，没有任何其他正面效应。 而之所以带上错误码，是为了方便内部排查和定位问题。当然，现在的企业服务，内部也有大量监控系统，可能也不会再暴露这样的错误码了。\n扩展 上文介绍了利用错误码的分段来定位问题的技术思想，其实不仅仅是错误码可以分段，我们在开发一组服务时，业务类型也可以通过编号来分段，这样通过业务号就能知道归属哪个服务了。\n如果读者以前没接触过这种设计思想，希望可以好好的思考和体会一下。","title":"错误码系统的设计"},{"content":"非阻塞模式下 send 和 recv 函数的返回值 我们来总结一下 send 和 recv 函数的各种返回值意义：\n返回值 n 返回值含义 大于 0 成功发送 n 个字节 0 对端关闭连接 小于 0（ -1） 出错或者被信号中断或者对端 TCP 窗口太小数据发不出去（send）或者当前网卡缓冲区已无数据可收（recv） 我们来逐一介绍下这三种情况：\n返回值大于 0\n对于 send 和 recv 函数返回值大于 0，表示发送或接收多少字节，需要注意的是，在这种情形下，我们一定要判断下 send 函数的返回值是不是我们期望发送的缓冲区长度，而不是简单判断其返回值大于 0。举个例子：\n1int n = send(socket, buf, buf_length, 0)； 2if (n \u0026gt; 0) 3{ 4 printf(\u0026#34;send data successfully\\n\u0026#34;); 5} 很多新手会写出上述代码，虽然返回值 n 大于 0，但是实际情形下，由于对端的 TCP 窗口可能因为缺少一部分字节就满了，所以返回值 n 的值可能在 (0, buf_length] 之间，当 0 \u0026lt; n \u0026lt; buf_length 时，虽然此时 send 函数是调用成功了，但是业务上并不算正确，因为有部分数据并没发出去。你可能在一次测试中测不出 n 不等于 buf_length 的情况，但是不代表实际中不存在。所以，建议要么认为返回值 n 等于 buf_length 才认为正确，要么在一个循环中调用 send 函数，如果数据一次性发不完，记录偏移量，下一次从偏移量处接着发，直到全部发送完为止。\n1 //推荐的方式一 2 int n = send(socket, buf, buf_length, 0)； 3 if (n == buf_length) 4 { 5 printf(\u0026#34;send data successfully\\n\u0026#34;); 6 } 1//推荐的方式二：在一个循环里面根据偏移量发送数据 2bool SendData(const char* buf , int buf_length) 3{ 4 //已发送的字节数目 5 int sent_bytes = 0; 6 int ret = 0; 7 while (true) 8 { 9 ret = send(m_hSocket, buf + sent_bytes, buf_length - sent_bytes, 0); 10 if (nRet == -1) 11 { 12 if (errno == EWOULDBLOCK) 13 { 14 //严谨的做法，这里如果发不出去，应该缓存尚未发出去的数据，后面介绍 15 break; 16 } 17 else if (errno == EINTR) 18 continue; 19 else 20 return false; 21 } 22 else if (nRet == 0) 23 { 24 return false; 25 } 26 27 sent_bytes += ret; 28 if (sent_bytes == buf_length) 29 break; 30 31 //稍稍降低 CPU 的使用率 32 usleep(1); 33 } 34 35 return true; 36} 返回值等于 0\n通常情况下，如果 send 或者 recv 函数返回 0，我们就认为对端关闭了连接，我们这端也关闭连接即可，这是实际开发时最常见的处理逻辑。\n但是，现在还有一种情形就是，假设调用 send 函数传递的数据长度就是 0 呢？send 函数会是什么行为？对端会 recv 到一个 0 字节的数据吗？需要强调的是，在实际开发中，你不应该让你的程序有任何机会去 send 0 字节的数据，这是一种不好的做法。 这里仅仅用于实验性讨论，我们来通过一个例子，来看下 send 一个长度为 0 的数据，send 函数的返回值是什么？对端会 recv 到 0 字节的数据吗？\nserver 端代码：\n1 /** 2 * 验证recv函数接受0字节的行为，server端，server_recv_zero_bytes.cpp 3 * zhangyl 2018.12.17 4 */ 5 #include \u0026lt;sys/types.h\u0026gt; 6 #include \u0026lt;sys/socket.h\u0026gt; 7 #include \u0026lt;arpa/inet.h\u0026gt; 8 #include \u0026lt;unistd.h\u0026gt; 9 #include \u0026lt;iostream\u0026gt; 10 #include \u0026lt;string.h\u0026gt; 11 #include \u0026lt;vector\u0026gt; 12 13 int main(int argc, char* argv[]) 14 { 15 //1.创建一个侦听socket 16 int listenfd = socket(AF_INET, SOCK_STREAM, 0); 17 if (listenfd == -1) 18 { 19 std::cout \u0026lt;\u0026lt; \u0026#34;create listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; 20 return -1; 21 } 22 23 //2.初始化服务器地址 24 struct sockaddr_in bindaddr; 25 bindaddr.sin_family = AF_INET; 26 bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); 27 bindaddr.sin_port = htons(3000); 28 if (bind(listenfd, (struct sockaddr *)\u0026amp;bindaddr, sizeof(bindaddr)) == -1) 29 { 30 std::cout \u0026lt;\u0026lt; \u0026#34;bind listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; 31 close(listenfd); 32 return -1; 33 } 34 35 //3.启动侦听 36 if (listen(listenfd, SOMAXCONN) == -1) 37 { 38 std::cout \u0026lt;\u0026lt; \u0026#34;listen error.\u0026#34; \u0026lt;\u0026lt; std::endl; 39 close(listenfd); 40 return -1; 41 } 42 43 int clientfd; 44 45 struct sockaddr_in clientaddr; 46 socklen_t clientaddrlen = sizeof(clientaddr); 47 //4. 接受客户端连接 48 clientfd = accept(listenfd, (struct sockaddr *)\u0026amp;clientaddr, \u0026amp;clientaddrlen); 49 if (clientfd != -1) 50 { 51 while (true) 52 { 53 char recvBuf[32] = {0}; 54 //5. 从客户端接受数据,客户端没有数据来的时候会在recv函数处阻塞 55 int ret = recv(clientfd, recvBuf, 32, 0); 56 if (ret \u0026gt; 0) 57 { 58 std::cout \u0026lt;\u0026lt; \u0026#34;recv data from client, data: \u0026#34; \u0026lt;\u0026lt; recvBuf \u0026lt;\u0026lt; std::endl; 59 } 60 else if (ret == 0) 61 { 62 std::cout \u0026lt;\u0026lt; \u0026#34;recv 0 byte data.\u0026#34; \u0026lt;\u0026lt; std::endl; 63 continue; 64 } 65 else 66 { 67 //出错 68 std::cout \u0026lt;\u0026lt; \u0026#34;recv data error.\u0026#34; \u0026lt;\u0026lt; std::endl; 69 break; 70 } 71 } 72 } 73 74 75 //关闭客户端socket 76 close(clientfd); 77 //7.关闭侦听socket 78 close(listenfd); 79 80 return 0; 81 } 上述代码侦听端口号是 3000，代码 55 行调用了 recv 函数，如果客户端一直没有数据，程序会阻塞在这里。\nclient 端代码：\n1/** 2 * 验证非阻塞模式下send函数发送0字节的行为，client端，nonblocking_client_send_zero_bytes.cpp 3 * zhangyl 2018.12.17 4 */ 5#include \u0026lt;sys/types.h\u0026gt; 6#include \u0026lt;sys/socket.h\u0026gt; 7#include \u0026lt;arpa/inet.h\u0026gt; 8#include \u0026lt;unistd.h\u0026gt; 9#include \u0026lt;iostream\u0026gt; 10#include \u0026lt;string.h\u0026gt; 11#include \u0026lt;stdio.h\u0026gt; 12#include \u0026lt;fcntl.h\u0026gt; 13#include \u0026lt;errno.h\u0026gt; 14 15#define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; 16#define SERVER_PORT 3000 17#define SEND_DATA \u0026#34;\u0026#34; 18 19int main(int argc, char* argv[]) 20{ 21 //1.创建一个socket 22 int clientfd = socket(AF_INET, SOCK_STREAM, 0); 23 if (clientfd == -1) 24 { 25 std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; 26 return -1; 27 } 28 29 //2.连接服务器 30 struct sockaddr_in serveraddr; 31 serveraddr.sin_family = AF_INET; 32 serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); 33 serveraddr.sin_port = htons(SERVER_PORT); 34 if (connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)) == -1) 35 { 36 std::cout \u0026lt;\u0026lt; \u0026#34;connect socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; 37 close(clientfd); 38 return -1; 39 } 40 41 //连接成功以后，我们再将 clientfd 设置成非阻塞模式， 42 //不能在创建时就设置，这样会影响到 connect 函数的行为 43 int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); 44 int newSocketFlag = oldSocketFlag | O_NONBLOCK; 45 if (fcntl(clientfd, F_SETFL, newSocketFlag) == -1) 46 { 47 close(clientfd); 48 std::cout \u0026lt;\u0026lt; \u0026#34;set socket to nonblock error.\u0026#34; \u0026lt;\u0026lt; std::endl; 49 return -1; 50 } 51 52 //3. 不断向服务器发送数据，或者出错退出 53 int count = 0; 54 while (true) 55 { 56 //发送 0 字节的数据 57 int ret = send(clientfd, SEND_DATA, 0, 0); 58 if (ret == -1) 59 { 60 //非阻塞模式下send函数由于TCP窗口太小发不出去数据，错误码是EWOULDBLOCK 61 if (errno == EWOULDBLOCK) 62 { 63 std::cout \u0026lt;\u0026lt; \u0026#34;send data error as TCP Window size is too small.\u0026#34; \u0026lt;\u0026lt; std::endl; 64 continue; 65 } 66 else if (errno == EINTR) 67 { 68 //如果被信号中断，我们继续重试 69 std::cout \u0026lt;\u0026lt; \u0026#34;sending data interrupted by signal.\u0026#34; \u0026lt;\u0026lt; std::endl; 70 continue; 71 } 72 else 73 { 74 std::cout \u0026lt;\u0026lt; \u0026#34;send data error.\u0026#34; \u0026lt;\u0026lt; std::endl; 75 break; 76 } 77 } 78 else if (ret == 0) 79 { 80 //对端关闭了连接，我们也关闭 81 std::cout \u0026lt;\u0026lt; \u0026#34;send 0 byte data.\u0026#34; \u0026lt;\u0026lt; std::endl; 82 } 83 else 84 { 85 count ++; 86 std::cout \u0026lt;\u0026lt; \u0026#34;send data successfully, count = \u0026#34; \u0026lt;\u0026lt; count \u0026lt;\u0026lt; std::endl; 87 } 88 89 //每三秒发一次 90 sleep(3); 91 } 92 93 //5. 关闭socket 94 close(clientfd); 95 96 return 0; 97} client 端连接服务器成功以后，每隔 3 秒调用 send 一次发送一个 0 字节的数据。除了先启动 server 以外，我们使用 tcpdump 抓一下经过端口 3000 上的数据包，使用如下命令：\n1tcpdump -i any \u0026#39;tcp port 3000\u0026#39; 然后启动 client ，我们看下结果：\n客户端确实是每隔 3 秒 send 一次数据。此时我们使用 lsof -i -Pn 命令查看连接状态，也是正常的：\n然后，tcpdump 抓包结果输出中，除了连接时的三次握手数据包，再也无其他数据包，也就是说，send 函数发送 0 字节数据，client 的协议栈并不会把这些数据发出去。\n1[root@localhost ~]# tcpdump -i any \u0026#39;tcp port 3000\u0026#39; 2tcpdump: verbose output suppressed, use -v or -vv for full protocol decode 3listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 417:37:03.028449 IP localhost.48820 \u0026gt; localhost.hbci: Flags [S], seq 1632283330, win 43690, options [mss 65495,sackOK,TS val 201295556 ecr 0,nop,wscale 7], length 0 517:37:03.028479 IP localhost.hbci \u0026gt; localhost.48820: Flags [S.], seq 3669336158, ack 1632283331, win 43690, options [mss 65495,sackOK,TS val 201295556 ecr 201295556,nop,wscale 7], length 0 617:37:03.028488 IP localhost.48820 \u0026gt; localhost.hbci: Flags [.], ack 1, win 342, options [nop,nop,TS val 201295556 ecr 201295556], length 0 因此，server 端也会一直没有输出，如果你用的是 gdb 启动 server，此时中断下来会发现，server 端由于没有数据会一直阻塞在 recv 函数调用处（55 行）。\n上述示例再次验证了，send 一个 0 字节的数据没有任何意思，希望读者在实际开发时，避免写出这样的代码。\n","permalink":"https://haokiu.com/blog/7050b3d426bf44b29c25c3d30ae77006/","summary":"非阻塞模式下 send 和 recv 函数的返回值 我们来总结一下 send 和 recv 函数的各种返回值意义：\n返回值 n 返回值含义 大于 0 成功发送 n 个字节 0 对端关闭连接 小于 0（ -1） 出错或者被信号中断或者对端 TCP 窗口太小数据发不出去（send）或者当前网卡缓冲区已无数据可收（recv） 我们来逐一介绍下这三种情况：\n返回值大于 0\n对于 send 和 recv 函数返回值大于 0，表示发送或接收多少字节，需要注意的是，在这种情形下，我们一定要判断下 send 函数的返回值是不是我们期望发送的缓冲区长度，而不是简单判断其返回值大于 0。举个例子：\n1int n = send(socket, buf, buf_length, 0)； 2if (n \u0026gt; 0) 3{ 4 printf(\u0026#34;send data successfully\\n\u0026#34;); 5} 很多新手会写出上述代码，虽然返回值 n 大于 0，但是实际情形下，由于对端的 TCP 窗口可能因为缺少一部分字节就满了，所以返回值 n 的值可能在 (0, buf_length] 之间，当 0 \u0026lt; n \u0026lt; buf_length 时，虽然此时 send 函数是调用成功了，但是业务上并不算正确，因为有部分数据并没发出去。你可能在一次测试中测不出 n 不等于 buf_length 的情况，但是不代表实际中不存在。所以，建议要么认为返回值 n 等于 buf_length 才认为正确，要么在一个循环中调用 send 函数，如果数据一次性发不完，记录偏移量，下一次从偏移量处接着发，直到全部发送完为止。\n1 //推荐的方式一 2 int n = send(socket, buf, buf_length, 0)； 3 if (n == buf_length) 4 { 5 printf(\u0026#34;send data successfully\\n\u0026#34;); 6 } 1//推荐的方式二：在一个循环里面根据偏移量发送数据 2bool SendData(const char* buf , int buf_length) 3{ 4 //已发送的字节数目 5 int sent_bytes = 0; 6 int ret = 0; 7 while (true) 8 { 9 ret = send(m_hSocket, buf + sent_bytes, buf_length - sent_bytes, 0); 10 if (nRet == -1) 11 { 12 if (errno == EWOULDBLOCK) 13 { 14 //严谨的做法，这里如果发不出去，应该缓存尚未发出去的数据，后面介绍 15 break; 16 } 17 else if (errno == EINTR) 18 continue; 19 else 20 return false; 21 } 22 else if (nRet == 0) 23 { 24 return false; 25 } 26 27 sent_bytes += ret; 28 if (sent_bytes == buf_length) 29 break; 30 31 //稍稍降低 CPU 的使用率 32 usleep(1); 33 } 34 35 return true; 36} 返回值等于 0","title":"非阻塞模式下 send 和 recv 函数的返回值"},{"content":"高性能服务器架构设计总结 系列目录\n第01篇 主线程与工作线程的分工\n第02篇 Reactor模式\n第03篇 一个服务器程序的架构介绍\n第04篇 如何将socket设置为非阻塞模式\n第05篇 如何编写高性能日志\n第06篇 关于网络编程的一些实用技巧和细节\n第07篇 开源一款即时通讯软件的源码\n第08篇 高性能服务器架构设计总结1\n第09篇 高性能服务器架构设计总结2\n第10篇 高性能服务器架构设计总结3\n第11篇 高性能服务器架构设计总结4\n这篇文章算是对这个系列的一个系统性地总结。我们将介绍服务器的开发，并从多个方面探究如何开发一款高性能高并发的服务器程序。\n所谓高性能就是服务器能流畅地处理各个客户端的连接并尽量低延迟地应答客户端的请求；所谓高并发，指的是服务器可以同时支持多的客户端连接，且这些客户端在连接期间内会不断与服务器有数据来往。\n这篇文章将从两个方面来介绍，一个是服务器的框架，即单个服务器程序的代码组织结构；另外一个是一组服务程序的如何组织与交互，即架构。注意：本文以下内容中的客户端是相对概念，指的是连接到当前讨论的服务程序的终端，所以这里的客户端既可能是我们传统意义上的客户端程序，也可能是连接该服务的其他服务器程序。\n一、框架篇 按上面介绍的思路，我们先从单个服务程序的组织结构开始介绍。\n（一）、网络通信 既然是服务器程序肯定会涉及到网络通信部分，那么服务器程序的网络通信模块要解决哪些问题？\n笔者认为至少要解决以下问题：\n如何检测有新客户端连接？ 如何接受客户端连接？ 如何检测客户端是否有数据发来？ 如何收取客户端发来的数据？ 如何检测连接异常？发现连接异常之后，如何处理？ 如何给客户端发送数据？ 如何在给客户端发完数据后关闭连接？ 稍微有点网络基础的人，都能回答上面说的其中几个问题，比如接收客户端连接用socket API的accept函数，收取客户端数据用recv函数，给客户端发送数据用send函数，检测客户端是否有新连接和客户端是否有新数据可以用IO multiplexing技术（IO复用）的select、poll、epoll等socket API。确实是这样的，这些基础的socket API构成了服务器网络通信的地基，不管网络通信框架设计的如何巧妙，都是在这些基础的socket API的基础上构建的。但是如何巧妙地组织这些基础的socket API，才是问题的关键。我们说服务器很高效，支持高并发，实际上只是一个技术实现手段，不管怎样从软件开发的角度来讲无非就是一个程序而已，所以，只要程序能最大可能地满足“尽量减少等待”就是高效。也就是说高效不是“忙的忙死，闲的闲死”，而是大家都可以闲着，但是如果有活要干，大家尽量一起干，而不是一部分忙着依次做事情123456789，另外一部分闲在那里无所事事。说的可能有点抽象，下面我们来举一些例子具体来说明一下。\n比如默认recv函数如果没有数据的时候，线程就会阻塞在那里； 默认send函数，如果tcp窗口不是足够大，数据发不出去也会阻塞在那里； connect函数默认连接另外一端的时候，也会阻塞在那里； 又或者是给对端发送一份数据，需要等待对端回答，如果对方一直不应答，当前线程就阻塞在这里。 以上都不是高效服务器的开发思维方式，因为上面的例子都不满足“尽量减少等待”的原则，为什么一定要等待呢？有没用一种方法，这些过程不需要等待，最好是不仅不需要等待，而且这些事情完成之后能通知我。这样在这些本来用于等待的cpu时间片内，我就可以做一些其他的事情。有，也就是我们下文要讨论的IO Multiplexing技术（IO复用技术）。\n（二）、几种IO复用机制的比较 目前windows系统支持select、WSAAsyncSelect、WSAEventSelect、完成端口（IOCP），linux系统支持select、poll、epoll。这里我们不具体介绍每个具体的函数的用法，我们来讨论一点深层次的东西，以上列举的API函数可以分为两个层次：\n层次一 select和poll 层次二 WSAAsyncSelect、WSAEventSelect、完成端口（IOCP）、epoll 为什么这么分呢？先来介绍第一层次，select和poll函数本质上还是在一定时间内主动去查询socket句柄（可能是一个也可能是多个）上是否有事件，比如可读事件，可写事件或者出错事件，也就是说我们还是需要每隔一段时间内去主动去做这些检测，如果在这段时间内检测出一些事件来，我们这段时间就算没白花，但是倘若这段时间内没有事件呢？我们只能是做无用功了，说白了，还是在浪费时间，因为假如一个服务器有多个连接，在cpu时间片有限的情况下，我们花费了一定的时间检测了一部分socket连接，却发现它们什么事件都没有，而在这段时间内我们却有一些事情需要处理，那我们为什么要花时间去做这个检测呢？把这个时间用在做我们需要做的事情不好吗？所以对于服务器程序来说，要想高效，我们应该尽量避免花费时间主动去查询一些socket是否有事件，而是等这些socket有事件的时候告诉我们去处理。这也就是层次二的各个函数做的事情，它们实际相当于变主动查询是否有事件为当有事件时，系统会告诉我们，此时我们再去处理，也就是“好钢用在刀刃”上了。只不过层次二的函数通知我们的方式是各不相同，比如WSAAsyncSelect是利用windows消息队列的事件机制来通知我们设定的窗口过程函数，IOCP是利用GetQueuedCompletionStatus返回正确的状态，epoll是epoll_wait函数返回而已。\n比如connect函数连接另外一端，如果连接socket是异步的，那么connect虽然不能立刻连接完成，但是也是会立刻返回，无需等待，等连接完成之后，WSAAsyncSelect会返回FD_CONNECT事件告诉我们连接成功，epoll会产生EPOLLOUT事件，我们也能知道连接完成。甚至socket有数据可读时，WSAAsyncSelect产生FD_READ事件，epoll产生EPOLLIN事件，等等。\n所以有了上面的讨论，我们就可以得到网络通信检测可读可写或者出错事件的正确姿势。这是我这里提出的第二个原则：尽量减少做无用功的时间。这个在服务程序资源够用的情况下可能体现不出来什么优势，但是如果有大量的任务要处理，个人觉得这个可能带来无用。\n（三）、检测网络事件的正确姿势 根据上面的介绍，第一，为了避免无意义的等待时间，第二，不采用主动查询各个socket的事件，而是采用等待操作系统通知我们有事件的状态的策略。我们的**socket都要设置成异步的。**在此基础上我们回到栏目（一）中提到的七个问题：\n如何检测有新客户端连接？\n如何接受客户端连接？\n默认accept函数会阻塞在那里，如果epoll检测到侦听socket上有EPOLLIN事件，或者WSAAsyncSelect检测到有FD_ACCEPT事件，那么就表明此时有新连接到来，这个时候调用accept函数，就不会阻塞了。当然产生的新socket你应该也设置成非阻塞的。这样我们就能在新socket上收发数据了。\n如何检测客户端是否有数据发来？\n如何收取客户端发来的数据？\n同理，我们也应该在socket上有可读事件的时候才去收取数据，这样我们调用recv或者read函数时不用等待。\n至于一次性收多少数据好呢？\n我们可以根据自己的需求来决定，甚至你可以在一个循环里面反复recv或者read，对于非阻塞模式的socket，如果没有数据了，recv或者read也会立刻返回，错误码EWOULDBLOCK会表明当前已经没有数据了。示例：\n1bool CIUSocket::Recv() 2{ 3 int nRet = 0; 4 5 while(true) 6 { 7 char buff[512]; 8 nRet = ::recv(m_hSocket, buff, 512, 0); 9 //一旦出现错误就立刻关闭Socket 10 if(nRet == SOCKET_ERROR) 11 { 12 if (::WSAGetLastError() == WSAEWOULDBLOCK) 13 break; 14 else 15 return false; 16 } 17 else if(nRet \u0026lt; 1) 18 return false; 19 20 m_strRecvBuf.append(buff, nRet); 21 22 ::Sleep(1); 23 } 24 25 return true; 26} 如何检测连接异常？发现连接异常之后，如何处理？\n同样当我们收到异常事件后例如EPOLLERR或关闭事件FD_CLOSE，我们就知道了有异常产生，我们对异常的处理一般就是关闭对应的socket。另外，如果send/recv或者read/write函数对一个socket进行操作时，如果返回0，那说明对端已经关闭了socket，此时这路连接也没必要存在了，我们也可以关闭对应的socket。\n如何给客户端发送数据？\n给客户端发送数据，比收数据要稍微麻烦一点，也是需要讲点技巧的。首先我们不能像检测数据可读一样检测数据可写，因为如果检测可写的话，一般情况下只要对端正常收取数据，我们的socket就都是可写的，如果我们设置监听可写事件，会导致频繁地触发可写事件，但是我们此时并不一定有数据需要发送。所以正确的做法是：如果有数据要发送，则先尝试着去发送，如果发送不了或者只发送出去部分，剩下的我们需要将其缓存起来，然后设置检测该socket上可写事件，下次可写事件产生时，再继续发送，如果还是不能完全发出去，则继续设置侦听可写事件，如此往复，一直到所有数据都发出去为止。一旦所有数据都发出去以后，我们要移除侦听可写事件，避免无用的可写事件通知。不知道你注意到没有，如果某次只发出去部分数据，剩下的数据应该暂且存起来，这个时候我们就需要一个缓冲区来存放这部分数据，这个缓冲区我们称为“发送缓冲区”。发送缓冲区不仅存放本次没有发完的数据，还用来存放在发送过程中，上层又传来的新的需要发送的数据。为了保证顺序，新的数据应该追加在当前剩下的数据的后面，发送的时候从发送缓冲区的头部开始发送。也就是说先来的先发送，后来的后发送。\n如何在给客户端发完数据后关闭连接？\n这个问题比较难处理，因为这里的“发送完”不一定是真正的发送完，我们调用send或者write函数即使成功，也只是向操作系统的协议栈里面成功写入数据，至于能否被发出去、何时被发出去很难判断，发出去对方是否收到就更难判断了。所以，我们目前只能简单地认为send或者write返回我们发出数据的字节数大小，我们就认为“发完数据”了。然后调用close等socket API关闭连接。关闭连接的话题，我们再单独开一个小的标题来专门讨论一下。\n（四）被动关闭连接和主动关闭连接 在实际的应用中，被动关闭连接是由于我们检测到了连接的异常事件，比如EPOLLERR，或者对端关闭连接，send或recv返回0，这个时候这路连接已经没有存在必要的意义了，我们被迫关闭连接。\n而主动关闭连接，是我们主动调用close/closesocket来关闭连接。比如客户端给我们发送非法的数据，比如一些网络攻击的尝试性数据包。这个时候出于安全考虑，我们关闭socket连接。\n（五）发送缓冲区和接收缓冲区 上面已经介绍了发送缓冲区了，并说明了其存在的意义。接收缓冲区也是一样的道理，当收到数据以后，我们可以直接进行解包，但是这样并不好，\n理由一：除非一些约定俗称的协议格式，比如http协议，大多数服务器的业务的协议都是不同的，也就是说一个数据包里面的数据格式的解读应该是业务层的事情，和网络通信层应该解耦，为了网络层更加通用，我们无法知道上层协议长成什么样子，因为不同的协议格式是不一样的，它们与具体的业务有关。 理由二：即使知道协议格式，我们在网络层进行解包处理对应的业务，如果这个业务处理比较耗时，比如读取磁盘文件，或者连接数据库进行账号密码验证，那么我们的网络线程会需要大量时间来处理这些任务，这样其它网络事件可能没法及时处理。鉴于以上二点，我们确实需要一个接收缓冲区，将收取到的数据放到该缓冲区里面去，并由专门的业务线程或者业务逻辑去从接收缓冲区中取出数据，并解包处理业务。 说了这么多，那发送缓冲区和接收缓冲区该设计成多大的容量？这是一个老生常谈的问题了，因为我们经常遇到这样的问题：预分配的内存太小不够用，太大的话可能会造成浪费。怎么办呢？答案就是像string、vector一样，设计出一个可以动态增长的缓冲区，按需分配，不够还可以扩展。\n需要特别注意的是，这里说的发送缓冲区和接收缓冲区是每一个socket连接都存在一个。这是我们最常见的设计方案。\n（六）协议的设计 除了一些通用的协议，如http、ftp协议以外，大多数服务器协议都是根据业务制定的。协议设计好了，数据包的格式就根据协议来设置。我们知道tcp/ip协议是流式数据，所以流式数据就是像流水一样，数据包与数据包之间没有明显的界限。比如A端给B端连续发了三个数据包，每个数据包都是50个字节，B端可能先收到10个字节，再收到140个字节；或者先收到20个字节，再收到20个字节，再收到110个字节；也可能一次性收到150个字节。这150个字节可以以任何字节数目组合和次数被B收到。\n所以我们讨论协议的设计第一个问题就是如何界定包的界线，也就是接收端如何知道每个包数据的大小。目前常用有如下三种方法：\n固定大小，这种方法就是假定每一个包的大小都是固定字节数目，比如上文中讨论的每个包大小都是50个字节，接收端每收气50个字节就当成一个包； 指定包结束符，比如以一个\\r\\n(换行符和回车符)结束，这样对端只要收到这样的结束符，就可以认为收到了一个包，接下来的数据是下一个包的内容； 指定包的大小，这种方法结合了上述两种方法，一般包头是固定大小，包头中有一个字段指定包体或者整个大的大小，对端收到数据以后先解析包头中的字段得到包体或者整个包的大小，然后根据这个大小去界定数据的界线。 协议要讨论的第二个问题是，设计协议的时候要尽量方便解包，也就是说协议的格式字段应该尽量清晰明了。\n协议要讨论的第三个问题是，根据协议组装的数据包应该尽量小，这样有如下好处：\n第一、对于一些移动端设备来说，其数据处理能力和带宽能力有限，小的数据不仅能加快处理速度，同时节省大量流量费用； 第二、如果单个数据包足够小的话，对频繁进行网络通信的服务器端来说，可以大大减小其带宽压力，其所在的系统也能使用更少的内存。试想：假如一个股票服务器，如果一只股票的数据包是100个字节或者1000个字节，那100只股票和10000只股票区别呢？ 协议要讨论的第四个问题是，对于数值类型，我们应该显式地指定数值的长度，比如long型，如果在32位机器上是32位的4个字节，但是如果在64位机器上，就变成了64位8个字节了。这样同样是一个long型，发送方和接收方可能会用不同的长度去解码。所以**建议最好在涉及到跨平台使用的协议最好显式地指定协议中整型字段的长度，**比如int32,int64等等。下面是一个协议的接口的例子：\n1class BinaryReadStream 2{ 3 private: 4 const char* const ptr; 5 const size_t len; 6 const char* cur; 7 BinaryReadStream(const BinaryReadStream\u0026amp;); 8 BinaryReadStream\u0026amp; operator=(const BinaryReadStream\u0026amp;); 9 10 public: 11 BinaryReadStream(const char* ptr, size_t len); 12 virtual const char* GetData() const; 13 virtual size_t GetSize() const; 14 bool IsEmpty() const; 15 bool ReadString(string* str, 16 size_t maxlen, 17 size_t\u0026amp; outlen); 18 bool ReadCString(char* str, 19 size_t strlen, 20 size_t\u0026amp; len); 21 bool ReadCCString(const char** str, 22 size_t maxlen, 23 size_t\u0026amp; outlen); 24 bool ReadInt32(int32_t\u0026amp; i); 25 bool ReadInt64(int64_t\u0026amp; i); 26 bool ReadShort(short\u0026amp; i); 27 bool ReadChar(char\u0026amp; c); 28 size_t ReadAll(char* szBuffer, size_t iLen) const; 29 bool IsEnd() const; 30 const char* GetCurrent() const{ return cur; } 31 32 public: 33 bool ReadLength(size_t \u0026amp; len); 34 bool ReadLengthWithoutOffset(size_t \u0026amp;headlen, 35 size_t \u0026amp; outlen); 36 }; 37 38 class BinaryWriteStream 39 { 40 public: 41 BinaryWriteStream(string* data); 42 virtual const char* GetData() const; 43 virtual size_t GetSize() const; 44 bool WriteCString(const char* str, size_t len); 45 bool WriteString(const string\u0026amp; str); 46 bool WriteDouble(double value, bool isNULL = false); 47 bool WriteInt64(int64_t value, bool isNULL = false); 48 bool WriteInt32(int32_t i, bool isNULL = false); 49 bool WriteShort(short i, bool isNULL = false); 50 bool WriteChar(char c, bool isNULL = false); 51 size_t GetCurrentPos() const{ return m_data-\u0026gt;length(); } 52 void Flush(); 53 void Clear(); 54 private: 55 string* m_data; 56 }; 其中BinaryWriteStream是编码协议的类，BinaryReadStream是解码协议的类。可以按下面这种方式来编码和解码。\n编码：\n1std::string outbuf; 2BinaryWriteStream writeStream(\u0026amp;outbuf); 3writeStream.WriteInt32(msg_type_register); 4writeStream.WriteInt32(m_seq); 5writeStream.WriteString(retData); 6writeStream.Flush(); 解码：\n1BinaryReadStream readStream(strMsg.c_str(), 2 strMsg.length()); 3int32_t cmd; 4if (!readStream.ReadInt32(cmd)) 5{ 6 return false; 7} 8 9//int seq; 10if (!readStream.ReadInt32(m_seq)) 11{ 12 return false; 13} 14 15std::string data; 16size_t datalength; 17if (!readStream.ReadString(\u0026amp;data, 0, datalength)) 18{ 19 return false; 20} （七）、服务器程序结构的组织 上面的六个标题，我们讨论了很多具体的细节问题，现在是时候讨论将这些细节组织起来了。根据我的个人经验，目前主流的思想是one thread one loop的策略。通俗点说就是在一个线程的函数里面不断地循环依次做一些事情，这些事情包括检测网络事件、解包数据产生业务逻辑。我们先从最简单地来说，设定一些线程在一个循环里面做网络通信相关的事情，伪码如下：\n1while(退出标志) 2{ 3 //IO复用技术检测socket可读事件、出错事件 4 //（如果有数据要发送，则也检测可写事件） 5 6 //如果有可读事件，对于侦听socket则接收新连接； 7 //对于普通socket则收取该socket上的数据，收取的数据存入对应的接收缓冲区，如果出错则关闭连接； 8 9 //如果有数据要发送，有可写事件，则发送数据 10 11 //如果有出错事件，关闭该连接 12} ` 另外设定一些线程去处理接收到的数据，并解包处理业务逻辑，这些线程可以认为是业务线程了，伪码如下：\n1//从接收缓冲区中取出数据解包，分解成不同的业务来处理 上面的结构是目前最通用的服务器逻辑结构，但是**能不能再简化一下或者说再综合一下呢？**我们试试，你想过这样的问题没有：假如现在的机器有两个cpu，我们的网络线程数量是2个，业务逻辑线程也是2个，这样可能存在的情况就是：业务线程运行的时候，网络线程并没有运行，它们必须等待，如果是这样的话，干嘛要多建两个线程呢？除了程序结构上可能稍微清楚一点，对程序性能没有任何实质性提高，而且白白浪费cpu时间片在线程上下文切换上。所以，**我们可以将网络线程与业务逻辑线程合并，**合并后的伪码看起来是这样子的：\n1while(退出标志) 2{ 3 //IO复用技术检测socket可读事件、出错事件 4 //（如果有数据要发送，则也检测可写事件） 5 6 //如果有可读事件，对于侦听socket则接收新连接； 7 //对于普通socket则收取该socket上的数据， 8 //收取的数据存入对应的接收缓冲区，如果出错则关闭连接； 9 10 //如果有数据要发送，有可写事件，则发送数据 11 12 //如果有出错事件，关闭该连接 13 14 //从接收缓冲区中取出数据解包，分解成不同的业务来处理 15} `你没看错，其实就是简单的合并，合并之后和不仅可以达到原来合并前的效果，而且在没有网络IO事件的时候，可以及时处理我们想处理的一些业务逻辑，并且减少了不必要的线程上下文切换时间。\n我们再更进一步，甚至我们可以在这个while循环增加其它的一些任务的处理，比如程序的逻辑任务队列、定时器事件等等，伪码如下：\n1while(退出标志) 2{ 3 //定时器事件处理 4 5 //IO复用技术检测socket可读事件、出错事件 6 //（如果有数据要发送，则也检测可写事件） 7 8 //如果有可读事件，对于侦听socket则接收新连接； 9 //对于普通socket则收取该socket上的数据， 10 //收取的数据存入对应的接收缓冲区，如果出错则关闭连接； 11 12 //如果有数据要发送，有可写事件，则发送数据 13 14 //如果有出错事件，关闭该连接 15 16 //从接收缓冲区中取出数据解包，分解成不同的业务来处理 17 18 //程序自定义任务1 19 20 //程序自定义任务2 21} 注意：之所以将定时器事件的处理放在网络IO事件的检测之前，是因为避免定时器事件过期时间太长。假如放在后面的话，可能前面的处理耗费了一点时间，等到处理定时器事件时，时间间隔已经过去了不少时间。虽然这样处理，也没法保证定时器事件百分百精确，但是能尽量保证。\n（八）高性能服务器架构设计总结2——以flamigo服务器代码为例 系列目录\n第01篇 主线程与工作线程的分工\n第02篇 Reactor模式\n第03篇 一个服务器程序的架构介绍\n第04篇 如何将socket设置为非阻塞模式\n第05篇 如何编写高性能日志\n第06篇 关于网络编程的一些实用技巧和细节\n第07篇 开源一款即时通讯软件的源码\n第08篇 高性能服务器架构设计总结1\n第09篇 高性能服务器架构设计总结2\n第10篇 高性能服务器架构设计总结3\n第11篇 高性能服务器架构设计总结4\n说了这么多，我们来以flamingo的服务器程序的网络框架设计为例来验证上述介绍的理论。flamingo的网络框架是基于陈硕的muduo库，改成C++11的版本，并修改了一些bug。在此感谢原作者陈硕。flamingo的源码可以在这里下载：https://github.com/baloonwj/flamingo，打不开github的可以移步csdn：http://download.csdn.net/detail/analogous_love/9805797。\n上文介绍的核心线程函数的while循环位于eventloop.cpp中：\n1void EventLoop::loop() 2{ 3 assert(!looping_); 4 assertInLoopThread(); 5 looping_ = true; 6 quit_ = false; 7 // FIXME: what if someone calls quit() before loop() ? 8 LOG_TRACE \u0026lt;\u0026lt; \u0026#34;EventLoop \u0026#34; \u0026lt;\u0026lt; this \u0026lt;\u0026lt; \u0026#34; start looping\u0026#34;; 9 10 while (!quit_) 11 { 12 activeChannels_.clear(); 13 pollReturnTime_ = poller_-\u0026gt;poll(kPollTimeMs, 14 \u0026amp;activeChannels_); 15 ++iteration_; 16 if (Logger::logLevel() \u0026lt;= Logger::TRACE) 17 { 18 printActiveChannels(); 19 } 20 // TODO sort channel by priority 21 eventHandling_ = true; 22 for (ChannelList::iterator it = activeChannels_.begin(); 23 it != activeChannels_.end(); ++it) 24 { 25 currentActiveChannel_ = *it; 26 currentActiveChannel_-\u0026gt;handleEvent(pollReturnTime_); 27 } 28 currentActiveChannel_ = NULL; 29 eventHandling_ = false; 30 doPendingFunctors(); 31 32 if (frameFunctor_) 33 { 34 frameFunctor_(); 35 } 36 } 37 38 LOG_TRACE \u0026lt;\u0026lt; \u0026#34;EventLoop \u0026#34; \u0026lt;\u0026lt; this \u0026lt;\u0026lt; \u0026#34; stop looping\u0026#34;; 39 looping_ = false; 40} poller_-\u0026gt;poll利用epoll分离网络事件，然后接着处理分离出来的网络事件，每一个客户端socket对应一个连接，即一个TcpConnection和Channel通道对象。**currentActiveChannel_-\u0026gt;handleEvent(pollReturnTime_)**根据是可读、可写、出错事件来调用对应的处理函数，这些函数都是回调函数，程序初始化阶段设置进来的：\n1void Channel::handleEvent(Timestamp receiveTime) 2{ 3 std::shared_ptr\u0026lt;void\u0026gt; guard; 4 if (tied_) 5 { 6 guard = tie_.lock(); 7 if (guard) 8 { 9 handleEventWithGuard(receiveTime); 10 } 11 } 12 else 13 { 14 handleEventWithGuard(receiveTime); 15 } 16} 17 18void Channel::handleEventWithGuard(Timestamp receiveTime) 19{ 20 eventHandling_ = true; 21 LOG_TRACE \u0026lt;\u0026lt; reventsToString(); 22 if ((revents_ \u0026amp; POLLHUP) \u0026amp;\u0026amp; !(revents_ \u0026amp; POLLIN)) 23 { 24 if (logHup_) 25 { 26 LOG_WARN \u0026lt;\u0026lt; \u0026#34;Channel::handle_event() POLLHUP\u0026#34;; 27 } 28 if (closeCallback_) closeCallback_(); 29 } 30 31 if (revents_ \u0026amp; POLLNVAL) 32 { 33 LOG_WARN \u0026lt;\u0026lt; \u0026#34;Channel::handle_event() POLLNVAL\u0026#34;; 34 } 35 36 if (revents_ \u0026amp; (POLLERR | POLLNVAL)) 37 { 38 if (errorCallback_) errorCallback_(); 39 } 40 if (revents_ \u0026amp; (POLLIN | POLLPRI | POLLRDHUP)) 41 { 42 //当是侦听socket时，readCallback_指向Acceptor::handleRead 43 //当是客户端socket时，调用TcpConnection::handleRead 44 if (readCallback_) readCallback_(receiveTime); 45 } 46 if (revents_ \u0026amp; POLLOUT) 47 { 48 //如果是连接状态服的socket， 49 //则writeCallback_指向Connector::handleWrite() 50 if (writeCallback_) writeCallback_(); 51 } 52 eventHandling_ = false; 53} 当然，这里利用了Channel对象的“多态性”\n如果是普通socket，可读事件就会调用预先设置的回调函数； 但是如果是侦听socket，则调用Aceptor对象的handleRead()来接收新连接： 1void Acceptor::handleRead() 2{ 3 loop_-\u0026gt;assertInLoopThread(); 4 InetAddress peerAddr; 5 //FIXME loop until no more 6 int connfd = acceptSocket_.accept(\u0026amp;peerAddr); 7 if (connfd \u0026gt;= 0) 8 { 9 // string hostport = peerAddr.toIpPort(); 10 // LOG_TRACE \u0026lt;\u0026lt; \u0026#34;Accepts of \u0026#34; \u0026lt;\u0026lt; hostport; 11 //newConnectionCallback_实际指向: 12 //TcpServer::newConnection(int sockfd, const InetAddress\u0026amp; peerAddr) 13 if (newConnectionCallback_) 14 { 15 newConnectionCallback_(connfd, peerAddr); 16 } 17 else 18 { 19 sockets::close(connfd); 20 } 21 } 22 else 23 { 24 LOG_SYSERR \u0026lt;\u0026lt; \u0026#34;in Acceptor::handleRead\u0026#34;; 25 // Read the section named \u0026#34;The special problem of 26 // accept()ing when you can\u0026#39;t\u0026#34; in libev\u0026#39;s doc. 27 // By Marc Lehmann, author of livev. 28 if (errno == EMFILE) 29 { 30 ::close(idleFd_); 31 idleFd_ = ::accept(acceptSocket_.fd(), NULL, NULL); 32 ::close(idleFd_); 33 idleFd_ = ::open(\u0026#34;/dev/null\u0026#34;, O_RDONLY | O_CLOEXEC); 34 } 35 } 36} 主循环里面的业务逻辑处理对应：\n1doPendingFunctors(); 2 3if (frameFunctor_) 4{ 5 frameFunctor_(); 6} 7 8 9void EventLoop::doPendingFunctors() 10{ 11 std::vector\u0026lt;Functor\u0026gt; functors; 12 callingPendingFunctors_ = true; 13 14 { 15 std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex_); 16 functors.swap(pendingFunctors_); 17 } 18 19 for (size_t i = 0; i \u0026lt; functors.size(); ++i) 20 { 21 functors[i](); 22 } 23 callingPendingFunctors_ = false; 24} 这里增加业务逻辑是增加执行任务的函数指针的，增加的任务保存在成员变量pendingFunctors_中，这个变量是一个函数指针数组（vector对象），执行的时候，调用每个函数就可以了。上面的代码先利用一个栈变量将成员变量pendingFunctors_里面的函数指针换过来，接下来对这个栈变量进行操作就可以了，这样减少了锁的粒度。\n因为成员变量pendingFunctors_在增加任务的时候，也会被用到，设计到多个线程操作，所以要加锁，增加任务的地方是：\n1void EventLoop::queueInLoop(const Functor\u0026amp; cb) 2{ 3 { 4 std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mutex_); 5 pendingFunctors_.push_back(cb); 6 } 7 8 if (!isInLoopThread() || callingPendingFunctors_) 9 { 10 wakeup(); 11 } 12} 而**frameFunctor_**就更简单了，就是通过设置一个函数指针就可以了。当然这里有个技巧性的东西，即增加任务的时候，为了能够立即执行，使用唤醒机制，通过往一个fd里面写入简单的几个字节，来唤醒epoll，使其立刻返回，因为此时没有其它的socke有事件，这样接下来就执行刚才添加的任务了。\n我们看一下数据收取的逻辑：\n1void TcpConnection::handleRead(Timestamp receiveTime) 2{ 3 loop_-\u0026gt;assertInLoopThread(); 4 int savedErrno = 0; 5 ssize_t n = inputBuffer_.readFd(channel_-\u0026gt;fd(), \u0026amp;savedErrno); 6 if (n \u0026gt; 0) 7 { 8 /*messageCallback_指向 9 CTcpSession::OnRead(const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn, 10 Buffer* pBuffer, 11 Timestamp receiveTime)*/ 12 messageCallback_(shared_from_this(), 13 \u0026amp;inputBuffer_, receiveTime); 14 } 15 else if (n == 0) 16 { 17 handleClose(); 18 } 19 else 20 { 21 errno = savedErrno; 22 LOG_SYSERR \u0026lt;\u0026lt; \u0026#34;TcpConnection::handleRead\u0026#34;; 23 handleError(); 24 } 25} 将收到的数据放到接收缓冲区里面，将来我们来解包：\n1void ClientSession::OnRead(const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn, Buffer* pBuffer, Timestamp receivTime) 2{ 3 while (true) 4 { 5 //不够一个包头大小 6 if (pBuffer-\u0026gt;readableBytes() \u0026lt; (size_t)sizeof(msg)) 7 { 8 LOG_INFO \u0026lt;\u0026lt; \u0026#34;buffer is not enough for a package header, pBuffer-\u0026gt;readableBytes()=\u0026#34; \u0026lt;\u0026lt; pBuffer-\u0026gt;readableBytes() \u0026lt;\u0026lt; \u0026#34;, sizeof(msg)=\u0026#34; \u0026lt;\u0026lt; sizeof(msg); 9 return; 10 } 11 12 //不够一个整包大小 13 msg header; 14 memcpy(\u0026amp;header, pBuffer-\u0026gt;peek(), sizeof(msg)); 15 if (pBuffer-\u0026gt;readableBytes() \u0026lt; (size_t)header.packagesize + sizeof(msg)) 16 return; 17 18 pBuffer-\u0026gt;retrieve(sizeof(msg)); 19 std::string inbuf; 20 inbuf.append(pBuffer-\u0026gt;peek(), header.packagesize); 21 pBuffer-\u0026gt;retrieve(header.packagesize); 22 if (!Process(conn, inbuf.c_str(), inbuf.length())) 23 { 24 LOG_WARN \u0026lt;\u0026lt; \u0026#34;Process error, close TcpConnection\u0026#34;; 25 conn-\u0026gt;forceClose(); 26 } 27 }// end while-loop 28 29} 先判断接收缓冲区里面的数据是否够一个包头大小，如果够再判断够不够包头指定的包体大小，如果还是够的话，接着在Process函数里面处理该包。\n再看看发送数据的逻辑：\n1void TcpConnection::sendInLoop(const void* data, 2 size_t len) 3{ 4 loop_-\u0026gt;assertInLoopThread(); 5 ssize_t nwrote = 0; 6 size_t remaining = len; 7 bool faultError = false; 8 if (state_ == kDisconnected) 9 { 10 LOG_WARN \u0026lt;\u0026lt; \u0026#34;disconnected, give up writing\u0026#34;; 11 return; 12 } 13 // if no thing in output queue, try writing directly 14 if (!channel_-\u0026gt;isWriting() \u0026amp;\u0026amp; outputBuffer_.readableBytes() == 0) 15 { 16 nwrote = sockets::write(channel_-\u0026gt;fd(), data, len); 17 if (nwrote \u0026gt;= 0) 18 { 19 remaining = len - nwrote; 20 if (remaining == 0 \u0026amp;\u0026amp; writeCompleteCallback_) 21 { 22 loop_-\u0026gt;queueInLoop(std::bind(writeCompleteCallback_, 23 shared_from_this())); 24 } 25 } 26 else // nwrote \u0026lt; 0 27 { 28 nwrote = 0; 29 if (errno != EWOULDBLOCK) 30 { 31 LOG_SYSERR \u0026lt;\u0026lt; \u0026#34;TcpConnection::sendInLoop\u0026#34;; 32 // FIXME: any others? 33 if (errno == EPIPE || errno == ECONNRESET) 34 { 35 faultError = true; 36 } 37 } 38 } 39 } 40 41 assert(remaining \u0026lt;= len); 42 if (!faultError \u0026amp;\u0026amp; remaining \u0026gt; 0) 43 { 44 size_t oldLen = outputBuffer_.readableBytes(); 45 if (oldLen + remaining \u0026gt;= highWaterMark_ 46 \u0026amp;\u0026amp; oldLen \u0026lt; highWaterMark_ 47 \u0026amp;\u0026amp; highWaterMarkCallback_) 48 { 49 loop_-\u0026gt;queueInLoop(std::bind(highWaterMarkCallback_, 50 shared_from_this(), 51 oldLen + remaining)); 52 } 53 outputBuffer_.append(static_cast\u0026lt;const char*\u0026gt;(data)+nwrote, 54 remaining); 55 if (!channel_-\u0026gt;isWriting()) 56 { 57 channel_-\u0026gt;enableWriting(); 58 } 59 } 60} 如果剩余的数据remaining大于则调用**channel_-\u0026gt;enableWriting();**开始监听可写事件，可写事件处理如下：\n1void TcpConnection::handleWrite() 2{ 3 loop_-\u0026gt;assertInLoopThread(); 4 if (channel_-\u0026gt;isWriting()) 5 { 6 ssize_t n = sockets::write(channel_-\u0026gt;fd(), 7 outputBuffer_.peek(), 8 outputBuffer_.readableBytes()); 9 if (n \u0026gt; 0) 10 { 11 outputBuffer_.retrieve(n); 12 if (outputBuffer_.readableBytes() == 0) 13 { 14 channel_-\u0026gt;disableWriting(); 15 if (writeCompleteCallback_) 16 { 17 loop_-\u0026gt;queueInLoop(std::bind(writeCompleteCallback_, 18 shared_from_this())); 19 } 20 if (state_ == kDisconnecting) 21 { 22 shutdownInLoop(); 23 } 24 } 25 } 26 else 27 { 28 LOG_SYSERR \u0026lt;\u0026lt; \u0026#34;TcpConnection::handleWrite\u0026#34;; 29 // if (state_ == kDisconnecting) 30 // { 31 // shutdownInLoop(); 32 // } 33 } 34 } 35 else 36 { 37 LOG_TRACE \u0026lt;\u0026lt; \u0026#34;Connection fd = \u0026#34; \u0026lt;\u0026lt; channel_-\u0026gt;fd() 38 \u0026lt;\u0026lt; \u0026#34; is down, no more writing\u0026#34;; 39 } 40} 如果发送完数据以后调用channel_-\u0026gt;disableWriting();移除监听可写事件。\n很多读者可能一直想问，文中不是说解包数据并处理逻辑是业务代码而非网络通信的代码，你这里貌似都混在一起了，其实没有，这里实际的业务代码处理都是框架曾提供的回调函数里面处理的，具体怎么处理，由框架使用者——业务层自己定义。\n总结起来，实际上就是一个线程函数里一个loop那么点事情，不信你再看我曾经工作上的一个交易系统项目代码：\n1void CEventDispatcher::Run() 2{ 3 m_bShouldRun = true; 4 while(m_bShouldRun) 5 { 6 DispatchIOs(); 7 SyncTime(); 8 CheckTimer(); 9 DispatchEvents(); 10 } 11} 12 13 14void CEpollReactor::DispatchIOs() 15{ 16 DWORD dwSelectTimeOut = SR_DEFAULT_EPOLL_TIMEOUT; 17 if (HandleOtherTask()) 18 { 19 dwSelectTimeOut = 0; 20 } 21 22 struct epoll_event ev; 23 CEventHandlerIdMap::iterator itor = m_mapEventHandlerId.begin(); 24 for(; itor!=m_mapEventHandlerId.end(); itor++) 25 { 26 CEventHandler *pEventHandler = (CEventHandler *)(*itor).first; 27 if(pEventHandler == NULL){ 28 continue; 29 } 30 ev.data.ptr = pEventHandler; 31 ev.events = 0; 32 int nReadID, nWriteID; 33 pEventHandler-\u0026gt;GetIds(\u0026amp;nReadID, \u0026amp;nWriteID); 34 if (nReadID \u0026gt; 0) 35 { 36 ev.events |= EPOLLIN; 37 } 38 if (nWriteID \u0026gt; 0) 39 { 40 ev.events |= EPOLLOUT; 41 } 42 43 epoll_ctl(m_fdEpoll, EPOLL_CTL_MOD, (*itor).second, \u0026amp;ev); 44 } 45 46 struct epoll_event events[EPOLL_MAX_EVENTS]; 47 48 int nfds = epoll_wait(m_fdEpoll, events, 49 EPOLL_MAX_EVENTS, 50 dwSelectTimeOut/1000); 51 52 for (int i=0; i\u0026lt;nfds; i++) 53 { 54 struct epoll_event \u0026amp;evref = events[i]; 55 CEventHandler *pEventHandler = (CEventHandler *)evref.data.ptr; 56 if ((evref.events|EPOLLIN)!=0 \u0026amp;\u0026amp; 57 m_mapEventHandlerId.find(pEventHandler)!=m_mapEventHandlerId.end()) 58 { 59 pEventHandler-\u0026gt;HandleInput(); 60 } 61 if ((evref.events|EPOLLOUT)!=0 \u0026amp;\u0026amp; 62 m_mapEventHandlerId.find(pEventHandler)!=m_mapEventHandlerId.end()) 63 { 64 pEventHandler-\u0026gt;HandleOutput(); 65 } 66 } 67} 68 69 70void CEventDispatcher::DispatchEvents() 71{ 72 CEvent event; 73 CSyncEvent *pSyncEvent; 74 while(m_queueEvent.PeekEvent(event)) 75 { 76 int nRetval; 77 78 if(event.pEventHandler != NULL) 79 { 80 nRetval = event.pEventHandler-\u0026gt;HandleEvent(event.nEventID, 81 event.dwParam, 82 event.pParam); 83 } 84 else 85 { 86 nRetval = HandleEvent(event.nEventID, 87 event.dwParam, 88 event.pParam); 89 } 90 91 if(event.pAdd != NULL) //同步消息 92 { 93 pSyncEvent=(CSyncEvent *)event.pAdd; 94 pSyncEvent-\u0026gt;nRetval = nRetval; 95 pSyncEvent-\u0026gt;sem.UnLock(); 96 } 97 } 98} 再看看蘑菇街开源的TeamTalk的源码（代码下载地址：https://github.com/baloonwj/TeamTalk）：\n1void CEventDispatch::StartDispatch(uint32_t wait_timeout) 2{ 3 fd_set read_set, write_set, excep_set; 4 timeval timeout; 5 timeout.tv_sec = 0; 6 // 10 millisecond 7 timeout.tv_usec = wait_timeout * 1000; 8 9 if(running) 10 return; 11 running = true; 12 13 while (running) 14 { 15 _CheckTimer(); 16 _CheckLoop(); 17 18 if (!m_read_set.fd_count \u0026amp;\u0026amp; 19 !m_write_set.fd_count \u0026amp;\u0026amp; 20 !m_excep_set.fd_count) 21 { 22 Sleep(MIN_TIMER_DURATION); 23 continue; 24 } 25 26 m_lock.lock(); 27 memcpy(\u0026amp;read_set, \u0026amp;m_read_set, 28 sizeof(fd_set)); 29 memcpy(\u0026amp;write_set, \u0026amp;m_write_set, 30 sizeof(fd_set)); 31 memcpy(\u0026amp;excep_set, \u0026amp;m_excep_set, 32 sizeof(fd_set)); 33 m_lock.unlock(); 34 35 int nfds = select(0, \u0026amp;read_set, 36 \u0026amp;write_set, 37 \u0026amp;excep_set, 38 \u0026amp;timeout); 39 40 if (nfds == SOCKET_ERROR) 41 { 42 log(\u0026#34;select failed, error code: %d\u0026#34;, GetLastError()); 43 Sleep(MIN_TIMER_DURATION); 44 continue; // select again 45 } 46 47 if (nfds == 0) 48 { 49 continue; 50 } 51 52 for (u_int i = 0; i \u0026lt; read_set.fd_count; i++) 53 { 54 //log(\u0026#34;select return read count=%d\\n\u0026#34;, read_set.fd_count); 55 SOCKET fd = read_set.fd_array[i]; 56 CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); 57 if (pSocket) 58 { 59 pSocket-\u0026gt;OnRead(); 60 pSocket-\u0026gt;ReleaseRef(); 61 } 62 } 63 64 for (u_int i = 0; i \u0026lt; write_set.fd_count; i++) 65 { 66 //log(\u0026#34;select return write count=%d\\n\u0026#34;, write_set.fd_count); 67 SOCKET fd = write_set.fd_array[i]; 68 CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); 69 if (pSocket) 70 { 71 pSocket-\u0026gt;OnWrite(); 72 pSocket-\u0026gt;ReleaseRef(); 73 } 74 } 75 76 for (u_int i = 0; i \u0026lt; excep_set.fd_count; i++) 77 { 78 //log(\u0026#34;select return exception count=%d\\n\u0026#34;, excep_set.fd_count); 79 SOCKET fd = excep_set.fd_array[i]; 80 CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); 81 if (pSocket) 82 { 83 pSocket-\u0026gt;OnClose(); 84 pSocket-\u0026gt;ReleaseRef(); 85 } 86 } 87 88 } 89} *由于公众号文章字数有限，您可以接着阅读下******一篇:*《服务器端编程心得（八）——高性能服务器架构设计总结3——以flamigo服务器代码为例》。**\n系列目录\n第01篇 主线程与工作线程的分工\n第02篇 Reactor模式\n第03篇 一个服务器程序的架构介绍\n第04篇 如何将socket设置为非阻塞模式\n第05篇 如何编写高性能日志\n第06篇 关于网络编程的一些实用技巧和细节\n第07篇 开源一款即时通讯软件的源码\n第08篇 高性能服务器架构设计总结1\n第09篇 高性能服务器架构设计总结2\n第10篇 高性能服务器架构设计总结3\n第11篇 高性能服务器架构设计总结4\n（八）高性能服务器架构设计总结3——以flamigo服务器代码为例 系列目录\n第01篇 主线程与工作线程的分工\n第02篇 Reactor模式\n第03篇 一个服务器程序的架构介绍\n第04篇 如何将socket设置为非阻塞模式\n第05篇 如何编写高性能日志\n第06篇 关于网络编程的一些实用技巧和细节\n第07篇 开源一款即时通讯软件的源码\n第08篇 高性能服务器架构设计总结1\n第09篇 高性能服务器架构设计总结2\n第10篇 高性能服务器架构设计总结3\n第11篇 高性能服务器架构设计总结4\n再看filezilla，一款ftp工具的服务器端，它采用的是Windows的WSAAsyncSelect模型（代码下载地址：https://github.com/baloonwj/filezilla）：\n1//Processes event notifications sent by the sockets or the layers 2 static LRESULT CALLBACK WindowProc(HWND hWnd, 3 UINT message, 4 WPARAM wParam, 5 LPARAM lParam) 6 { 7 if (message\u0026gt;=WM_SOCKETEX_NOTIFY) 8 { 9 //Verify parameters 10 ASSERT(hWnd); 11 CAsyncSocketExHelperWindow *pWnd=(CAsyncSocketExHelperWindow *) 12 GetWindowLongPtr(hWnd, GWLP_USERDATA); 13 ASSERT(pWnd); 14 if (!pWnd) 15 return 0; 16 //Index is within socket storage 17 if (message \u0026lt; static_cast\u0026lt;UINT\u0026gt;(WM_SOCKETEX_NOTIFY+pWnd-\u0026gt;m_nWindowDataSize)) 18 { 19 //Lookup socket and verify if it\u0026#39;s valid 20 CAsyncSocketEx *pSocket=pWnd-\u0026gt;m_pAsyncSocketExWindowData[message - WM_SOCKETEX_NOTIFY].m_pSocket; 21 SOCKET hSocket = wParam; 22 if (!pSocket) 23 return 0; 24 if (hSocket == INVALID_SOCKET) 25 return 0; 26 if (pSocket-\u0026gt;m_SocketData.hSocket != hSocket) 27 return 0; 28 29 int nEvent = lParam \u0026amp; 0xFFFF; 30 int nErrorCode = lParam \u0026gt;\u0026gt; 16; 31 32 //Dispatch notification 33 if (!pSocket-\u0026gt;m_pFirstLayer) { 34 //Dispatch to CAsyncSocketEx instance 35 switch (nEvent) 36 { 37 case FD_READ: 38#ifndef NOSOCKETSTATES 39 if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) 40 { 41 pSocket-\u0026gt;m_nPendingEvents |= FD_READ; 42 break; 43 } 44 else if (pSocket-\u0026gt;GetState() == attached) 45 pSocket-\u0026gt;SetState(connected); 46 if (pSocket-\u0026gt;GetState() != connected) 47 break; 48 49 // Ignore further FD_READ events after FD_CLOSE has been received 50 if (pSocket-\u0026gt;m_SocketData.onCloseCalled) 51 break; 52#endif //NOSOCKETSTATES 53 54#ifndef NOSOCKETSTATES 55 if (nErrorCode) 56 pSocket-\u0026gt;SetState(aborted); 57#endif //NOSOCKETSTATES 58 if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ) { 59 pSocket-\u0026gt;OnReceive(nErrorCode); 60 } 61 break; 62 case FD_FORCEREAD: //Forceread does not check if there\u0026#39;s data waiting 63#ifndef NOSOCKETSTATES 64 if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) 65 { 66 pSocket-\u0026gt;m_nPendingEvents |= FD_FORCEREAD; 67 break; 68 } 69 else if (pSocket-\u0026gt;GetState() == attached) 70 pSocket-\u0026gt;SetState(connected); 71 if (pSocket-\u0026gt;GetState() != connected) 72 break; 73#endif //NOSOCKETSTATES 74 if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ) 75 { 76#ifndef NOSOCKETSTATES 77 if (nErrorCode) 78 pSocket-\u0026gt;SetState(aborted); 79#endif //NOSOCKETSTATES 80 pSocket-\u0026gt;OnReceive(nErrorCode); 81 } 82 break; 83 case FD_WRITE: 84#ifndef NOSOCKETSTATES 85 if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) 86 { 87 pSocket-\u0026gt;m_nPendingEvents |= FD_WRITE; 88 break; 89 } 90 else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) 91 pSocket-\u0026gt;SetState(connected); 92 if (pSocket-\u0026gt;GetState() != connected) 93 break; 94#endif //NOSOCKETSTATES 95 if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_WRITE) 96 { 97#ifndef NOSOCKETSTATES 98 if (nErrorCode) 99 pSocket-\u0026gt;SetState(aborted); 100#endif //NOSOCKETSTATES 101 pSocket-\u0026gt;OnSend(nErrorCode); 102 } 103 break; 104 case FD_CONNECT: 105#ifndef NOSOCKETSTATES 106 if (pSocket-\u0026gt;GetState() == connecting) 107 { 108 if (nErrorCode \u0026amp;\u0026amp; pSocket-\u0026gt;m_SocketData.nextAddr) 109 { 110 if (pSocket-\u0026gt;TryNextProtocol()) 111 break; 112 } 113 pSocket-\u0026gt;SetState(connected); 114 } 115 else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) 116 pSocket-\u0026gt;SetState(connected); 117#endif //NOSOCKETSTATES 118 if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_CONNECT) 119 pSocket-\u0026gt;OnConnect(nErrorCode); 120#ifndef NOSOCKETSTATES 121 if (!nErrorCode) 122 { 123 if ((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_READ) \u0026amp;\u0026amp; 124 pSocket-\u0026gt;GetState() == connected) 125 pSocket-\u0026gt;OnReceive(0); 126 if ((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_FORCEREAD) \u0026amp;\u0026amp; 127 pSocket-\u0026gt;GetState() == connected) 128 pSocket-\u0026gt;OnReceive(0); 129 if ((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_WRITE) \u0026amp;\u0026amp; 130 pSocket-\u0026gt;GetState() == connected) 131 pSocket-\u0026gt;OnSend(0); 132 } 133 pSocket-\u0026gt;m_nPendingEvents = 0; 134#endif 135 break; 136 case FD_ACCEPT: 137#ifndef NOSOCKETSTATES 138 if (pSocket-\u0026gt;GetState() != listening \u0026amp;\u0026amp; 139 pSocket-\u0026gt;GetState() != attached) 140 break; 141#endif //NOSOCKETSTATES 142 if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_ACCEPT) 143 pSocket-\u0026gt;OnAccept(nErrorCode); 144 break; 145 case FD_CLOSE: 146#ifndef NOSOCKETSTATES 147 if (pSocket-\u0026gt;GetState() != connected \u0026amp;\u0026amp; 148 pSocket-\u0026gt;GetState() != attached) 149 break; 150 151 // If there are still bytes left to read, 152 // call OnReceive instead of 153 // OnClose and trigger a new OnClose 154 DWORD nBytes = 0; 155 if (!nErrorCode \u0026amp;\u0026amp; pSocket-\u0026gt;IOCtl(FIONREAD, \u0026amp;nBytes)) 156 { 157 if (nBytes \u0026gt; 0) 158 { 159 // Just repeat message. 160 pSocket-\u0026gt;ResendCloseNotify(); 161 pSocket-\u0026gt;m_SocketData.onCloseCalled = true; 162 pSocket-\u0026gt;OnReceive(WSAESHUTDOWN); 163 break; 164 } 165 } 166 167 pSocket-\u0026gt;SetState(nErrorCode ? aborted : closed); 168#endif //NOSOCKETSTATES 169 pSocket-\u0026gt;OnClose(nErrorCode); 170 break; 171 } 172 } 173 else //Dispatch notification to the lowest layer 174 { 175 if (nEvent == FD_READ) 176 { 177 // Ignore further FD_READ events after FD_CLOSE has been received 178 if (pSocket-\u0026gt;m_SocketData.onCloseCalled) 179 return 0; 180 181 DWORD nBytes; 182 if (!pSocket-\u0026gt;IOCtl(FIONREAD, \u0026amp;nBytes)) 183 nErrorCode = WSAGetLastError(); 184 if (pSocket-\u0026gt;m_pLastLayer) 185 pSocket-\u0026gt;m_pLastLayer-\u0026gt;CallEvent(nEvent, nErrorCode); 186 } 187 else if (nEvent == FD_CLOSE) 188 { 189 // If there are still bytes left to read, 190 // call OnReceive instead of 191 // OnClose and trigger a new OnClose 192 DWORD nBytes = 0; 193 if (!nErrorCode \u0026amp;\u0026amp; pSocket-\u0026gt;IOCtl(FIONREAD, \u0026amp;nBytes)) 194 { 195 if (nBytes \u0026gt; 0) 196 { 197 // Just repeat message. 198 pSocket-\u0026gt;ResendCloseNotify(); 199 if (pSocket-\u0026gt;m_pLastLayer) 200 pSocket-\u0026gt;m_pLastLayer-\u0026gt;CallEvent(FD_READ, 0); 201 return 0; 202 } 203 } 204 pSocket-\u0026gt;m_SocketData.onCloseCalled = true; 205 if (pSocket-\u0026gt;m_pLastLayer) 206 pSocket-\u0026gt;m_pLastLayer-\u0026gt;CallEvent(nEvent, nErrorCode); 207 } 208 else if (pSocket-\u0026gt;m_pLastLayer) 209 pSocket-\u0026gt;m_pLastLayer-\u0026gt;CallEvent(nEvent, nErrorCode); 210 } 211 } 212 return 0; 213 } 214 else if (message == WM_USER) //Notification event sent by a layer 215 { 216 //Verify parameters, lookup socket and notification message 217 //Verify parameters 218 ASSERT(hWnd); 219 CAsyncSocketExHelperWindow *pWnd=(CAsyncSocketExHelperWindow *) 220 GetWindowLongPtr(hWnd, GWLP_USERDATA); 221 ASSERT(pWnd); 222 if (!pWnd) 223 return 0; 224 //Index is within socket storage 225 if (wParam \u0026gt;= static_cast\u0026lt;UINT\u0026gt;(pWnd-\u0026gt;m_nWindowDataSize)) 226 { 227 return 0; 228 } 229 230 CAsyncSocketEx *pSocket = pWnd-\u0026gt;m_pAsyncSocketExWindowData[wParam].m_pSocket; 231 CAsyncSocketExLayer::t_LayerNotifyMsg *pMsg = (CAsyncSocketExLayer::t_LayerNotifyMsg *)lParam; 232 if (!pMsg || !pSocket || pSocket-\u0026gt;m_SocketData.hSocket != pMsg-\u0026gt;hSocket) 233 { 234 delete pMsg; 235 return 0; 236 } 237 int nEvent=pMsg-\u0026gt;lEvent\u0026amp;0xFFFF; 238 int nErrorCode=pMsg-\u0026gt;lEvent\u0026gt;\u0026gt;16; 239 240 //Dispatch to layer 241 if (pMsg-\u0026gt;pLayer) 242 pMsg-\u0026gt;pLayer-\u0026gt;CallEvent(nEvent, nErrorCode); 243 else 244 { 245 //Dispatch to CAsyncSocketEx instance 246 switch (nEvent) 247 { 248 case FD_READ: 249#ifndef NOSOCKETSTATES 250 if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) 251 { 252 pSocket-\u0026gt;m_nPendingEvents |= FD_READ; 253 break; 254 } 255 else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) 256 pSocket-\u0026gt;SetState(connected); 257 if (pSocket-\u0026gt;GetState() != connected) 258 break; 259#endif //NOSOCKETSTATES 260 if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ) 261 { 262#ifndef NOSOCKETSTATES 263 if (nErrorCode) 264 pSocket-\u0026gt;SetState(aborted); 265#endif //NOSOCKETSTATES 266 pSocket-\u0026gt;OnReceive(nErrorCode); 267 } 268 break; 269 //Forceread does not check if there\u0026#39;s data waiting 270 case FD_FORCEREAD: 271#ifndef NOSOCKETSTATES 272 if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) 273 { 274 pSocket-\u0026gt;m_nPendingEvents |= FD_FORCEREAD; 275 break; 276 } 277 else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) 278 pSocket-\u0026gt;SetState(connected); 279 if (pSocket-\u0026gt;GetState() != connected) 280 break; 281#endif //NOSOCKETSTATES 282 if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ) 283 { 284#ifndef NOSOCKETSTATES 285 if (nErrorCode) 286 pSocket-\u0026gt;SetState(aborted); 287#endif //NOSOCKETSTATES 288 pSocket-\u0026gt;OnReceive(nErrorCode); 289 } 290 break; 291 case FD_WRITE: 292#ifndef NOSOCKETSTATES 293 if (pSocket-\u0026gt;GetState() == connecting \u0026amp;\u0026amp; !nErrorCode) 294 { 295 pSocket-\u0026gt;m_nPendingEvents |= FD_WRITE; 296 break; 297 } 298 else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) 299 pSocket-\u0026gt;SetState(connected); 300 if (pSocket-\u0026gt;GetState() != connected) 301 break; 302#endif //NOSOCKETSTATES 303 if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_WRITE) 304 { 305#ifndef NOSOCKETSTATES 306 if (nErrorCode) 307 pSocket-\u0026gt;SetState(aborted); 308#endif //NOSOCKETSTATES 309 pSocket-\u0026gt;OnSend(nErrorCode); 310 } 311 break; 312 case FD_CONNECT: 313#ifndef NOSOCKETSTATES 314 if (pSocket-\u0026gt;GetState() == connecting) 315 pSocket-\u0026gt;SetState(connected); 316 else if (pSocket-\u0026gt;GetState() == attached \u0026amp;\u0026amp; !nErrorCode) 317 pSocket-\u0026gt;SetState(connected); 318#endif //NOSOCKETSTATES 319 if (pSocket-\u0026gt;m_lEvent \u0026amp; FD_CONNECT) 320 pSocket-\u0026gt;OnConnect(nErrorCode); 321#ifndef NOSOCKETSTATES 322 if (!nErrorCode) 323 { 324 if (((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_READ) \u0026amp;\u0026amp; 325 pSocket-\u0026gt;GetState() == connected) \u0026amp;\u0026amp; 326 (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ)) 327 pSocket-\u0026gt;OnReceive(0); 328 if (((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_FORCEREAD) \u0026amp;\u0026amp; 329 pSocket-\u0026gt;GetState() == connected) \u0026amp;\u0026amp; 330 (pSocket-\u0026gt;m_lEvent \u0026amp; FD_READ)) 331 pSocket-\u0026gt;OnReceive(0); 332 if (((pSocket-\u0026gt;m_nPendingEvents\u0026amp;FD_WRITE) \u0026amp;\u0026amp; 333 pSocket-\u0026gt;GetState() == connected) \u0026amp;\u0026amp; 334 (pSocket-\u0026gt;m_lEvent \u0026amp; FD_WRITE)) 335 pSocket-\u0026gt;OnSend(0); 336 } 337 pSocket-\u0026gt;m_nPendingEvents = 0; 338#endif //NOSOCKETSTATES 339 break; 340 case FD_ACCEPT: 341#ifndef NOSOCKETSTATES 342 if ((pSocket-\u0026gt;GetState() == listening || pSocket-\u0026gt;GetState() == attached) \u0026amp;\u0026amp; (pSocket-\u0026gt;m_lEvent \u0026amp; FD_ACCEPT)) 343#endif //NOSOCKETSTATES 344 { 345 pSocket-\u0026gt;OnAccept(nErrorCode); 346 } 347 break; 348 case FD_CLOSE: 349#ifndef NOSOCKETSTATES 350 if ((pSocket-\u0026gt;GetState() == connected || 351 pSocket-\u0026gt;GetState() == attached) \u0026amp;\u0026amp; 352 (pSocket-\u0026gt;m_lEvent \u0026amp; FD_CLOSE)) 353 { 354 pSocket-\u0026gt;SetState(nErrorCode?aborted:closed); 355#else 356 { 357#endif //NOSOCKETSTATES 358 pSocket-\u0026gt;OnClose(nErrorCode); 359 } 360 break; 361 } 362 } 363 delete pMsg; 364 return 0; 365 } 366 else if (message == WM_USER+1) 367 { 368 // WSAAsyncGetHostByName reply 369 370 // Verify parameters 371 ASSERT(hWnd); 372 CAsyncSocketExHelperWindow *pWnd = (CAsyncSocketExHelperWindow *) 373 GetWindowLongPtr(hWnd, GWLP_USERDATA); 374 ASSERT(pWnd); 375 if (!pWnd) 376 return 0; 377 378 CAsyncSocketEx *pSocket = NULL; 379 for (int i = 0; i \u0026lt; pWnd-\u0026gt;m_nWindowDataSize; ++i) { 380 pSocket = pWnd-\u0026gt;m_pAsyncSocketExWindowData[i].m_pSocket; 381 if (pSocket \u0026amp;\u0026amp; pSocket-\u0026gt;m_hAsyncGetHostByNameHandle \u0026amp;\u0026amp; 382 pSocket-\u0026gt;m_hAsyncGetHostByNameHandle == (HANDLE)wParam \u0026amp;\u0026amp; 383 pSocket-\u0026gt;m_pAsyncGetHostByNameBuffer) 384 break; 385 } 386 if (!pSocket || !pSocket-\u0026gt;m_pAsyncGetHostByNameBuffer) 387 return 0; 388 389 int nErrorCode = lParam \u0026gt;\u0026gt; 16; 390 if (nErrorCode) { 391 pSocket-\u0026gt;OnConnect(nErrorCode); 392 return 0; 393 } 394 395 SOCKADDR_IN sockAddr{}; 396 sockAddr.sin_family = AF_INET; 397 sockAddr.sin_addr.s_addr = ((LPIN_ADDR)((LPHOSTENT)pSocket-\u0026gt;m_pAsyncGetHostByNameBuffer)-\u0026gt;h_addr)-\u0026gt;s_addr; 398 399 sockAddr.sin_port = htons(pSocket-\u0026gt;m_nAsyncGetHostByNamePort); 400 401 BOOL res = pSocket-\u0026gt;Connect((SOCKADDR*)\u0026amp;sockAddr, sizeof(sockAddr)); 402 delete [] pSocket-\u0026gt;m_pAsyncGetHostByNameBuffer; 403 pSocket-\u0026gt;m_pAsyncGetHostByNameBuffer = 0; 404 pSocket-\u0026gt;m_hAsyncGetHostByNameHandle = 0; 405 406 if (!res) 407 if (GetLastError() != WSAEWOULDBLOCK) 408 pSocket-\u0026gt;OnConnect(GetLastError()); 409 return 0; 410 } 411 else if (message == WM_USER + 2) 412 { 413 //Verify parameters, lookup socket and notification message 414 //Verify parameters 415 if (!hWnd) 416 return 0; 417 418 CAsyncSocketExHelperWindow *pWnd=(CAsyncSocketExHelperWindow *) 419 GetWindowLongPtr(hWnd, GWLP_USERDATA); 420 if (!pWnd) 421 return 0; 422 423 if (wParam \u0026gt;= static_cast\u0026lt;UINT\u0026gt;(pWnd-\u0026gt;m_nWindowDataSize)) //Index is within socket storage 424 return 0; 425 426 CAsyncSocketEx *pSocket = pWnd-\u0026gt;m_pAsyncSocketExWindowData[wParam].m_pSocket; 427 if (!pSocket) 428 return 0; 429 430 // Process pending callbacks 431 std::list\u0026lt;t_callbackMsg\u0026gt; tmp; 432 tmp.swap(pSocket-\u0026gt;m_pendingCallbacks); 433 pSocket-\u0026gt;OnLayerCallback(tmp); 434 435 for (auto \u0026amp; cb : tmp) { 436 delete [] cb.str; 437 } 438 } 439 else if (message == WM_TIMER) 440 { 441 if (wParam != 1) 442 return 0; 443 444 ASSERT(hWnd); 445 CAsyncSocketExHelperWindow *pWnd=(CAsyncSocketExHelperWindow *) 446 GetWindowLongPtr(hWnd, GWLP_USERDATA); 447 ASSERT(pWnd \u0026amp;\u0026amp; pWnd-\u0026gt;m_pThreadData); 448 if (!pWnd || !pWnd-\u0026gt;m_pThreadData) 449 return 0; 450 451 if (pWnd-\u0026gt;m_pThreadData-\u0026gt;layerCloseNotify.empty()) 452 { 453 KillTimer(hWnd, 1); 454 return 0; 455 } 456 CAsyncSocketEx* socket = pWnd-\u0026gt;m_pThreadData-\u0026gt;layerCloseNotify.front(); 457 pWnd-\u0026gt;m_pThreadData-\u0026gt;layerCloseNotify.pop_front(); 458 if (pWnd-\u0026gt;m_pThreadData-\u0026gt;layerCloseNotify.empty()) 459 KillTimer(hWnd, 1); 460 461 if (socket) 462 PostMessage(hWnd, 463 socket-\u0026gt;m_SocketData.nSocketIndex + WM_SOCKETEX_NOTIFY, 464 socket-\u0026gt;m_SocketData.hSocket, 465 FD_CLOSE); 466 return 0; 467 } 468 return DefWindowProc(hWnd, message, wParam, lParam); 469 } 关于单个服务程序的框架，我已经介绍完了，如果你能完全理解我要表达的意思，我相信你也能构建出一套高性能服务程序来。\n（八）高性能服务器架构设计总结4——以flamigo服务器代码为例 系列目录\n第01篇 主线程与工作线程的分工\n第02篇 Reactor模式\n第03篇 一个服务器程序的架构介绍\n第04篇 如何将socket设置为非阻塞模式\n第05篇 如何编写高性能日志\n第06篇 关于网络编程的一些实用技巧和细节\n第07篇 开源一款即时通讯软件的源码\n第08篇 高性能服务器架构设计总结1\n第09篇 高性能服务器架构设计总结2\n第10篇 高性能服务器架构设计总结3\n第11篇 高性能服务器架构设计总结4\n二、架构篇 一个项目的服务器端往往由很多服务组成，就算单个服务在性能上做到极致，支持的并发数量也是有限的。举个简单的例子，假如一个聊天服务器，每个用户的信息是1k，那对于一个8G的内存的机器，在不考虑其它的情况下810241024*1024 / 100 = 1024，实际有838万，但实际这只是非常理想的情况。所以我们有时候需要需要某个服务部署多套，就单个服务的实现来讲还是《框架篇》中介绍的。\n1\n我们举个例子： 这是蘑菇街TeamTalk的服务器架构。\nMsgServer是聊天服务，可以部署多套，每个聊天服务器启动时都会告诉loginSever和routeSever自己的ip地址和端口号，当有用户上线或者下线的时候，MsgServer也会告诉loginSever和routeSever自己上面最新的用户数量和用户id列表。\n现在一个用户需要登录，先连接loginServer，loginServer根据记录的各个MsgServer上的用户情况，返回一个最小负载的MsgServer的ip地址和端口号给客户端，客户端再利用这个ip地址和端口号去登录MsgServer。当聊天时，位于A MsgServer上的用户给另外一个用户发送消息，如果该用户不在同一个MsgServer上，MsgServer将消息转发给RouteServer，RouteServer根据自己记录的用户id信息找到目标用户所在的MsgServer并转发给对应的MsgServer。\n2\n**上面是分布式部署的一个例子，我们再来看另外一个例子。**这个例子是单个服务的策略，实际服务器在处理网络数据的时候，如果同时有多个socket上有数据要处理，可能会出现一直服务前几个socket，直到前几个socket处理完毕后再处理后面几个socket的数据。这就相当于，你去饭店吃饭，大家都点了菜，但是有些桌子上一直在上菜，而有些桌子上一直没有菜。这样肯定不好，我们来看下如何避免这种现象：\n1int CFtdEngine::HandlePackage(CFTDCPackage *pFTDCPackage, 2 CFTDCSession *pSession) 3{ 4 //NET_IO_LOG0(\u0026#34;CFtdEngine::HandlePackage\\n\u0026#34;); 5 FTDC_PACKAGE_DEBUG(pFTDCPackage); 6 7 if (pFTDCPackage-\u0026gt;GetTID() != FTD_TID_ReqUserLogin) 8 { 9 if (!IsSessionLogin(pSession-\u0026gt;GetSessionID())) 10 { 11 SendErrorRsp(pFTDCPackage, pSession, 1, \u0026#34;客户未登录\u0026#34;); 12 return 0; 13 } 14 } 15 16 CalcFlux(pSession, pFTDCPackage-\u0026gt;Length()); //统计流量 17 18 REPORT_EVENT(LOG_DEBUG, \u0026#34;Front/Fgateway\u0026#34;, \u0026#34;登录请求%0x\u0026#34;, 19 pFTDCPackage-\u0026gt;GetTID()); 20 21 int nRet = 0; 22 switch(pFTDCPackage-\u0026gt;GetTID()) 23 { 24 25 case FTD_TID_ReqUserLogin: 26 ///huwp：20070608：检查过高版本的API将被禁止登录 27 if (pFTDCPackage-\u0026gt;GetVersion()\u0026gt;FTD_VERSION) 28 { 29 SendErrorRsp(pFTDCPackage, pSession, 1, 30 \u0026#34;Too High FTD Version\u0026#34;); 31 return 0; 32 } 33 nRet = OnReqUserLogin(pFTDCPackage, 34 (CFTDCSession *)pSession); 35 FTDRequestIndex.incValue(); 36 break; 37 case FTD_TID_ReqCheckUserLogin: 38 nRet = OnReqCheckUserLogin(pFTDCPackage, 39 (CFTDCSession *)pSession); 40 FTDRequestIndex.incValue(); 41 break; 42 case FTD_TID_ReqSubscribeTopic: 43 nRet = OnReqSubscribeTopic(pFTDCPackage, 44 (CFTDCSession *)pSession); 45 FTDRequestIndex.incValue(); 46 break; 47 } 48 49 return 0; 50} 当有某个socket上有数据可读时，接着接收该socket上的数据，对接收到的数据进行解包，然后调用CalcFlux(pSession, pFTDCPackage-\u0026gt;Length())进行流量统计：\n1void CFrontEngine::CalcFlux(CSession *pSession, const int nFlux) 2{ 3 TFrontSessionInfo *pSessionInfo = m_mapSessionInfo.Find(pSession-\u0026gt;GetSessionID()); 4 if (pSessionInfo != NULL) 5 { 6 //流量控制改为计数 7 pSessionInfo-\u0026gt;nCommFlux ++; 8 ///若流量超过规定，则挂起该会话的读操作 9 if (pSessionInfo-\u0026gt;nCommFlux \u0026gt;= pSessionInfo-\u0026gt;nMaxCommFlux) 10 { 11 pSession-\u0026gt;SuspendRead(true); 12 } 13 } 14} 该函数会先让某个连接会话（Session）处理的包数量递增，接着判断是否超过最大包数量，则设置读挂起标志：\n1void CSession::SuspendRead(bool bSuspend) 2{ 3 m_bSuspendRead = bSuspend; 4} 这样下次将会从检测的socket列表中排除该socket：\n1void CEpollReactor::RegisterIO(CEventHandler *pEventHandler) 2{ 3 int nReadID, nWriteID; 4 pEventHandler-\u0026gt;GetIds(\u0026amp;nReadID, \u0026amp;nWriteID); 5 if (nWriteID != 0 \u0026amp;\u0026amp; nReadID ==0) 6 { 7 nReadID = nWriteID; 8 } 9 if (nReadID != 0) 10 { 11 m_mapEventHandlerId[pEventHandler] = nReadID; 12 struct epoll_event ev; 13 ev.data.ptr = pEventHandler; 14 if(epoll_ctl(m_fdEpoll, EPOLL_CTL_ADD, nReadID, \u0026amp;ev) != 0) 15 { 16 perror(\u0026#34;epoll_ctl EPOLL_CTL_ADD\u0026#34;); 17 } 18 } 19} 20 21 22void CSession::GetIds(int *pReadId, int *pWriteId) 23{ 24 m_pChannelProtocol-\u0026gt;GetIds(pReadId,pWriteId); 25 if (m_bSuspendRead) 26 { 27 *pReadId = 0; 28 } 29} 也就是说不再检测该socket上是否有数据可读。然后在定时器里1秒后重置该标志，这样这个socket上有数据的话又可以重新检测到了：\n1const int SESSION_CHECK_TIMER_ID = 9; 2const int SESSION_CHECK_INTERVAL = 1000; 3 4 5SetTimer(SESSION_CHECK_TIMER_ID, SESSION_CHECK_INTERVAL); 6 7 8void CFrontEngine::OnTimer(int nIDEvent) 9{ 10 if (nIDEvent == SESSION_CHECK_TIMER_ID) 11 { 12 CSessionMap::iterator itor = m_mapSession.Begin(); 13 while (!itor.IsEnd()) 14 { 15 TFrontSessionInfo *pFind = m_mapSessionInfo.Find((*itor)-\u0026gt;GetSessionID()); 16 if (pFind != NULL) 17 { 18 CheckSession(*itor, pFind); 19 } 20 itor++; 21 } 22 } 23} 24 25void CFrontEngine::CheckSession(CSession *pSession, 26 TFrontSessionInfo *pSessionInfo) 27{ 28 ///重新开始计算流量 29 pSessionInfo-\u0026gt;nCommFlux -= pSessionInfo-\u0026gt;nMaxCommFlux; 30 if (pSessionInfo-\u0026gt;nCommFlux \u0026lt; 0) 31 { 32 pSessionInfo-\u0026gt;nCommFlux = 0; 33 } 34 ///若流量超过规定，则挂起该会话的读操作 35 pSession-\u0026gt;SuspendRead(pSessionInfo-\u0026gt;nCommFlux \u0026gt;= pSessionInfo-\u0026gt;nMaxCommFlux); 36} 这就相当与饭店里面先给某一桌客人上一些菜，让他们先吃着，等上了一些菜之后不会再给这桌继续上菜了，而是给其它空桌上菜，大家都吃上后，继续回来给原先的桌子继续上菜。实际上我们的饭店都是这么做的。上面的例子是单服务流量控制的实现的一个非常好的思路，它保证了每个客户端都能均衡地得到服务，而不是一些客户端等很久才有响应。\n3\n另外加快服务器处理速度的策略可能就是缓存了，缓存实际上是以空间换取时间的策略。对于一些反复使用的，但是不经常改变的信息，如果从原始地点加载这些信息就比较耗时的数据（比如从磁盘中、从数据库中），我们就可以使用缓存。\n所以时下像redis、leveldb、fastdb等各种内存数据库大行其道。我在flamingo中用户的基本信息都是缓存在聊天服务程序中的，而文件服务启动时会去加载指定目录里面的所有程序名称，这些文件的名称都是md5，为该文件内容的md5。这样当客户端上传了新文件请求时，如果其传上来的文件md5已经位于缓存中，则表明该文件在服务器上已经存在，这个时候服务器就不必再接收该文件了，而是告诉客户端文件已经上传成功了。\n说了这么多，一般来说，一个服务器的架构，往往更多取决于其具体的业务，我们要在结合当前的情况来实际去组织铺排，没有一套系统是万能的。多思考，多实践，多总结，相信很快你也能拥有很不错的架构能力。\n鉴于笔者能力和经验有限，文中难免有错漏之处，欢迎提意见。 交流QQ群：49114021\n本系列完\n系列目录\n第01篇 主线程与工作线程的分工\n第02篇 Reactor模式\n第03篇 一个服务器程序的架构介绍\n第04篇 如何将socket设置为非阻塞模式\n第05篇 如何编写高性能日志\n第06篇 关于网络编程的一些实用技巧和细节\n第07篇 开源一款即时通讯软件的源码\n第08篇 高性能服务器架构设计总结1\n第09篇 高性能服务器架构设计总结2\n第10篇 高性能服务器架构设计总结3\n第11篇 高性能服务器架构设计总结4\n欢迎关注公众号『easyserverdev』。如果有任何技术或者职业方面的问题需要我提供帮助，可通过这个公众号与我取得联系，此公众号不仅分享高性能服务器开发经验和故事，同时也免费为广大技术朋友提供技术答疑和职业解惑，您有任何问题都可以在微信公众号直接留言，我会尽快回复您。\n","permalink":"https://haokiu.com/blog/67da065d5a2a4917804acd4875f0f0a8/","summary":"高性能服务器架构设计总结 系列目录\n第01篇 主线程与工作线程的分工\n第02篇 Reactor模式\n第03篇 一个服务器程序的架构介绍\n第04篇 如何将socket设置为非阻塞模式\n第05篇 如何编写高性能日志\n第06篇 关于网络编程的一些实用技巧和细节\n第07篇 开源一款即时通讯软件的源码\n第08篇 高性能服务器架构设计总结1\n第09篇 高性能服务器架构设计总结2\n第10篇 高性能服务器架构设计总结3\n第11篇 高性能服务器架构设计总结4\n这篇文章算是对这个系列的一个系统性地总结。我们将介绍服务器的开发，并从多个方面探究如何开发一款高性能高并发的服务器程序。\n所谓高性能就是服务器能流畅地处理各个客户端的连接并尽量低延迟地应答客户端的请求；所谓高并发，指的是服务器可以同时支持多的客户端连接，且这些客户端在连接期间内会不断与服务器有数据来往。\n这篇文章将从两个方面来介绍，一个是服务器的框架，即单个服务器程序的代码组织结构；另外一个是一组服务程序的如何组织与交互，即架构。注意：本文以下内容中的客户端是相对概念，指的是连接到当前讨论的服务程序的终端，所以这里的客户端既可能是我们传统意义上的客户端程序，也可能是连接该服务的其他服务器程序。\n一、框架篇 按上面介绍的思路，我们先从单个服务程序的组织结构开始介绍。\n（一）、网络通信 既然是服务器程序肯定会涉及到网络通信部分，那么服务器程序的网络通信模块要解决哪些问题？\n笔者认为至少要解决以下问题：\n如何检测有新客户端连接？ 如何接受客户端连接？ 如何检测客户端是否有数据发来？ 如何收取客户端发来的数据？ 如何检测连接异常？发现连接异常之后，如何处理？ 如何给客户端发送数据？ 如何在给客户端发完数据后关闭连接？ 稍微有点网络基础的人，都能回答上面说的其中几个问题，比如接收客户端连接用socket API的accept函数，收取客户端数据用recv函数，给客户端发送数据用send函数，检测客户端是否有新连接和客户端是否有新数据可以用IO multiplexing技术（IO复用）的select、poll、epoll等socket API。确实是这样的，这些基础的socket API构成了服务器网络通信的地基，不管网络通信框架设计的如何巧妙，都是在这些基础的socket API的基础上构建的。但是如何巧妙地组织这些基础的socket API，才是问题的关键。我们说服务器很高效，支持高并发，实际上只是一个技术实现手段，不管怎样从软件开发的角度来讲无非就是一个程序而已，所以，只要程序能最大可能地满足“尽量减少等待”就是高效。也就是说高效不是“忙的忙死，闲的闲死”，而是大家都可以闲着，但是如果有活要干，大家尽量一起干，而不是一部分忙着依次做事情123456789，另外一部分闲在那里无所事事。说的可能有点抽象，下面我们来举一些例子具体来说明一下。\n比如默认recv函数如果没有数据的时候，线程就会阻塞在那里； 默认send函数，如果tcp窗口不是足够大，数据发不出去也会阻塞在那里； connect函数默认连接另外一端的时候，也会阻塞在那里； 又或者是给对端发送一份数据，需要等待对端回答，如果对方一直不应答，当前线程就阻塞在这里。 以上都不是高效服务器的开发思维方式，因为上面的例子都不满足“尽量减少等待”的原则，为什么一定要等待呢？有没用一种方法，这些过程不需要等待，最好是不仅不需要等待，而且这些事情完成之后能通知我。这样在这些本来用于等待的cpu时间片内，我就可以做一些其他的事情。有，也就是我们下文要讨论的IO Multiplexing技术（IO复用技术）。\n（二）、几种IO复用机制的比较 目前windows系统支持select、WSAAsyncSelect、WSAEventSelect、完成端口（IOCP），linux系统支持select、poll、epoll。这里我们不具体介绍每个具体的函数的用法，我们来讨论一点深层次的东西，以上列举的API函数可以分为两个层次：\n层次一 select和poll 层次二 WSAAsyncSelect、WSAEventSelect、完成端口（IOCP）、epoll 为什么这么分呢？先来介绍第一层次，select和poll函数本质上还是在一定时间内主动去查询socket句柄（可能是一个也可能是多个）上是否有事件，比如可读事件，可写事件或者出错事件，也就是说我们还是需要每隔一段时间内去主动去做这些检测，如果在这段时间内检测出一些事件来，我们这段时间就算没白花，但是倘若这段时间内没有事件呢？我们只能是做无用功了，说白了，还是在浪费时间，因为假如一个服务器有多个连接，在cpu时间片有限的情况下，我们花费了一定的时间检测了一部分socket连接，却发现它们什么事件都没有，而在这段时间内我们却有一些事情需要处理，那我们为什么要花时间去做这个检测呢？把这个时间用在做我们需要做的事情不好吗？所以对于服务器程序来说，要想高效，我们应该尽量避免花费时间主动去查询一些socket是否有事件，而是等这些socket有事件的时候告诉我们去处理。这也就是层次二的各个函数做的事情，它们实际相当于变主动查询是否有事件为当有事件时，系统会告诉我们，此时我们再去处理，也就是“好钢用在刀刃”上了。只不过层次二的函数通知我们的方式是各不相同，比如WSAAsyncSelect是利用windows消息队列的事件机制来通知我们设定的窗口过程函数，IOCP是利用GetQueuedCompletionStatus返回正确的状态，epoll是epoll_wait函数返回而已。\n比如connect函数连接另外一端，如果连接socket是异步的，那么connect虽然不能立刻连接完成，但是也是会立刻返回，无需等待，等连接完成之后，WSAAsyncSelect会返回FD_CONNECT事件告诉我们连接成功，epoll会产生EPOLLOUT事件，我们也能知道连接完成。甚至socket有数据可读时，WSAAsyncSelect产生FD_READ事件，epoll产生EPOLLIN事件，等等。\n所以有了上面的讨论，我们就可以得到网络通信检测可读可写或者出错事件的正确姿势。这是我这里提出的第二个原则：尽量减少做无用功的时间。这个在服务程序资源够用的情况下可能体现不出来什么优势，但是如果有大量的任务要处理，个人觉得这个可能带来无用。\n（三）、检测网络事件的正确姿势 根据上面的介绍，第一，为了避免无意义的等待时间，第二，不采用主动查询各个socket的事件，而是采用等待操作系统通知我们有事件的状态的策略。我们的**socket都要设置成异步的。**在此基础上我们回到栏目（一）中提到的七个问题：\n如何检测有新客户端连接？\n如何接受客户端连接？\n默认accept函数会阻塞在那里，如果epoll检测到侦听socket上有EPOLLIN事件，或者WSAAsyncSelect检测到有FD_ACCEPT事件，那么就表明此时有新连接到来，这个时候调用accept函数，就不会阻塞了。当然产生的新socket你应该也设置成非阻塞的。这样我们就能在新socket上收发数据了。\n如何检测客户端是否有数据发来？\n如何收取客户端发来的数据？\n同理，我们也应该在socket上有可读事件的时候才去收取数据，这样我们调用recv或者read函数时不用等待。\n至于一次性收多少数据好呢？\n我们可以根据自己的需求来决定，甚至你可以在一个循环里面反复recv或者read，对于非阻塞模式的socket，如果没有数据了，recv或者read也会立刻返回，错误码EWOULDBLOCK会表明当前已经没有数据了。示例：\n1bool CIUSocket::Recv() 2{ 3 int nRet = 0; 4 5 while(true) 6 { 7 char buff[512]; 8 nRet = ::recv(m_hSocket, buff, 512, 0); 9 //一旦出现错误就立刻关闭Socket 10 if(nRet == SOCKET_ERROR) 11 { 12 if (::WSAGetLastError() == WSAEWOULDBLOCK) 13 break; 14 else 15 return false; 16 } 17 else if(nRet \u0026lt; 1) 18 return false; 19 20 m_strRecvBuf.","title":"高性能服务器架构设计总结"},{"content":"高性能服务器框架设计 主线程与工作线程的分工\nReactor模式\n实例：一个服务器程序的架构介绍\n错误码系统的设计\n日志系统的设计\n如何设计断线自动重连机制\n心跳包机制设计详解\n业务数据处理一定要单独开线程吗\nC++ 高性能服务器网络框架设计细节\n","permalink":"https://haokiu.com/blog/95e6ea6c39e345bf8177b77fb2d24548/","summary":"高性能服务器框架设计 主线程与工作线程的分工\nReactor模式\n实例：一个服务器程序的架构介绍\n错误码系统的设计\n日志系统的设计\n如何设计断线自动重连机制\n心跳包机制设计详解\n业务数据处理一定要单独开线程吗\nC++ 高性能服务器网络框架设计细节","title":"高性能服务器框架设计"},{"content":"01 TeamTalk介绍 TeamTalk是蘑菇街开源的一款企业内部用的即时通讯软件（Enterprise IM），类似腾讯的RTX。网上也有很多的介绍，我这里也有写几遍关于这款产品的“流水账”，一方面对自己这段时间的阅读其代码做个总结，尽量做个既能宏观上从全局来介绍，又不缺少很多有价值的微观细节，另一方面如果对于作为读者的您有些许帮助，那就善莫大焉了。\n项目地址github：https://github.com/baloonwj/TeamTalk\n如果您打不开github，请移步至百度网盘下载：http://pan.baidu.com/s/1slbJVf3\n关于即时通讯软件本身，我相信使用过QQ的都知道是啥。\n下载项目解压后目录结构是这样的：\n这款即时通讯软件分为服务器端（linux）、pc端、web端、mac端和两个移动端（ios和安卓），源码中使用了大量的开源技术（用项目作者的话说，就是“拿来主义”）。例如通信协议使用了google protobuf，服务器端使用了内存数据库redis，pc端界面库使用的duilib，pc端的日志系统使用的是YAOLOG库、cximage、jsoncpp库等等。在接下来各个端的源码分析中，我们将会深入和细致地介绍。\n下一篇我将介绍首先介绍服务器端的程序的编译与部署。\n","permalink":"https://haokiu.com/blog/8c53924ed21041948dff215384cdb81d/","summary":"01 TeamTalk介绍 TeamTalk是蘑菇街开源的一款企业内部用的即时通讯软件（Enterprise IM），类似腾讯的RTX。网上也有很多的介绍，我这里也有写几遍关于这款产品的“流水账”，一方面对自己这段时间的阅读其代码做个总结，尽量做个既能宏观上从全局来介绍，又不缺少很多有价值的微观细节，另一方面如果对于作为读者的您有些许帮助，那就善莫大焉了。\n项目地址github：https://github.com/baloonwj/TeamTalk\n如果您打不开github，请移步至百度网盘下载：http://pan.baidu.com/s/1slbJVf3\n关于即时通讯软件本身，我相信使用过QQ的都知道是啥。\n下载项目解压后目录结构是这样的：\n这款即时通讯软件分为服务器端（linux）、pc端、web端、mac端和两个移动端（ios和安卓），源码中使用了大量的开源技术（用项目作者的话说，就是“拿来主义”）。例如通信协议使用了google protobuf，服务器端使用了内存数据库redis，pc端界面库使用的duilib，pc端的日志系统使用的是YAOLOG库、cximage、jsoncpp库等等。在接下来各个端的源码分析中，我们将会深入和细致地介绍。\n下一篇我将介绍首先介绍服务器端的程序的编译与部署。","title":"01 TeamTalk介绍"},{"content":"02 服务器端的程序的编译与部署 这篇我们来介绍下TeamTalk服务器端的编译与部署，部署文档在auto_setup下，这里我们只介绍下服务器程序的编译与部署，不包括管理后台的部署，其部署方法在auto_setup\\im_server文件夹，其实按官方介绍只要找一台干净的linux系统运行一下auto_setup\\im_server\\setup.sh程序就可以了，会自动安装mysql（maridb，mysql被oracle收购后，分为两个分支，继续开源的分支改名叫maridb）、nginx和redis。我们暂且不部署web端，所以不需要安装nginx。我这里是手动安装了mysql和redis。然后启动mysql和redis，并手动建立如下库和表。库名叫teamtalk，需要建立以下这些表：\n--后台管理员表 --password 密码,规则md5(md5(passwd)+salt) CREATE TABLE `IMAdmin` ( `id` mediumint(6) unsigned NOT NULL AUTO_INCREMENT, `uname` varchar(40) NOT NULL COMMENT \u0026#39;用户名\u0026#39;, `pwd` char(32) NOT NULL COMMENT \u0026#39;经过md5加密的密码\u0026#39;, `status` tinyint(2) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;用户状态 0 :正常 1:删除 可扩展\u0026#39;, `created` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 --存储语音地址 CREATE TABLE `IMAudio` ( `id` int(11) NOT NULL AUTO_INCREMENT, `fromId` int(11) unsigned NOT NULL COMMENT \u0026#39;发送者Id\u0026#39;, `toId` int(11) unsigned NOT NULL COMMENT \u0026#39;接收者Id\u0026#39;, `path` varchar(255) COLLATE utf8mb4_bin DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;语音存储的地址\u0026#39;, `size` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;文件大小\u0026#39;, `duration` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;语音时长\u0026#39;, `created` int(11) unsigned NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_fromId_toId` (`fromId`,`toId`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --存储部门信息 CREATE TABLE `IMDepart` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;部门id\u0026#39;, `departName` varchar(64) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;部门名称\u0026#39;, `priority` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;显示优先级,相同优先级按拼音顺序排列\u0026#39;, `parentId` int(11) unsigned NOT NULL COMMENT \u0026#39;上级部门id\u0026#39;, `status` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;状态\u0026#39;, `created` int(11) unsigned NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_departName` (`departName`), KEY `idx_priority_status` (`priority`,`status`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --发现配置表 CREATE TABLE `IMDiscovery` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `itemName` varchar(64) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;名称\u0026#39;, `itemUrl` varchar(64) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;URL\u0026#39;, `itemPriority` int(11) unsigned NOT NULL COMMENT \u0026#39;显示优先级\u0026#39;, `status` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;状态\u0026#39;, `created` int(11) unsigned NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_itemName` (`itemName`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --群组表 CREATE TABLE `IMGroup` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(256) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;群名称\u0026#39;, `avatar` varchar(256) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;群头像\u0026#39;, `creator` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建者用户id\u0026#39;, `type` tinyint(3) unsigned NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;群组类型，1-固定;2-临时群\u0026#39;, `userCnt` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;成员人数\u0026#39;, `status` tinyint(3) unsigned NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;是否删除,0-正常，1-删除\u0026#39;, `version` int(11) unsigned NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;群版本号\u0026#39;, `lastChated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;最后聊天时间\u0026#39;, `created` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_name` (`name`(191)), KEY `idx_creator` (`creator`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin COMMENT=\u0026#39;IM群信息\u0026#39; --群成员表 CREATE TABLE `IMGroupMember` ( `id` int(11) NOT NULL AUTO_INCREMENT, `groupId` int(11) unsigned NOT NULL COMMENT \u0026#39;群Id\u0026#39;, `userId` int(11) unsigned NOT NULL COMMENT \u0026#39;用户id\u0026#39;, `status` tinyint(4) unsigned NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;是否退出群，0-正常，1-已退出\u0026#39;, `created` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_groupId_userId_status` (`groupId`,`userId`,`status`), KEY `idx_userId_status_updated` (`userId`,`status`,`updated`), KEY `idx_groupId_updated` (`groupId`,`updated`) ) ENGINE=InnoDB AUTO_INCREMENT=68 DEFAULT CHARSET=utf8 COMMENT=\u0026#39;用户和群的关系表\u0026#39; --群消息表,x代表第几张表，目前做了分表有8张:0-7.消息具体在哪张表中，是groupId%IMGroupMessage表的数目 CREATE TABLE `IMGroupMessage_(x)` ( `id` int(11) NOT NULL AUTO_INCREMENT, `groupId` int(11) unsigned NOT NULL COMMENT \u0026#39;用户的关系id\u0026#39;, `userId` int(11) unsigned NOT NULL COMMENT \u0026#39;发送用户的id\u0026#39;, `msgId` int(11) unsigned NOT NULL COMMENT \u0026#39;消息ID\u0026#39;, `content` varchar(4096) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;消息内容\u0026#39;, `type` tinyint(3) unsigned NOT NULL DEFAULT \u0026#39;2\u0026#39; COMMENT \u0026#39;群消息类型,101为群语音,2为文本\u0026#39;, `status` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;消息状态\u0026#39;, `created` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_groupId_status_created` (`groupId`,`status`,`created`), KEY `idx_groupId_msgId_status_created` (`groupId`,`msgId`,`status`,`created`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin COMMENT=\u0026#39;IM群消息表\u0026#39; --消息表，x代表第几张表，目前做了分表有8张:0-7.具体在那张表，是relateId%IMMessage表数目. CREATE TABLE `IMMessage_0` ( `id` int(11) NOT NULL AUTO_INCREMENT, `relateId` int(11) unsigned NOT NULL COMMENT \u0026#39;用户的关系id\u0026#39;, `fromId` int(11) unsigned NOT NULL COMMENT \u0026#39;发送用户的id\u0026#39;, `toId` int(11) unsigned NOT NULL COMMENT \u0026#39;接收用户的id\u0026#39;, `msgId` int(11) unsigned NOT NULL COMMENT \u0026#39;消息ID\u0026#39;, `content` varchar(4096) COLLATE utf8mb4_bin DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;消息内容\u0026#39;, `type` tinyint(2) unsigned NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;消息类型\u0026#39;, `status` tinyint(1) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;0正常 1被删除\u0026#39;, `created` int(11) unsigned NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_relateId_status_created` (`relateId`,`status`,`created`), KEY `idx_relateId_status_msgId_created` (`relateId`,`status`,`msgId`,`created`), KEY `idx_fromId_toId_created` (`fromId`,`toId`,`status`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --最近联系人(会话)表。 CREATE TABLE `IMRecentSession` ( `id` int(11) NOT NULL AUTO_INCREMENT, `userId` int(11) unsigned NOT NULL COMMENT \u0026#39;用户id\u0026#39;, `peerId` int(11) unsigned NOT NULL COMMENT \u0026#39;对方id\u0026#39;, `type` tinyint(1) unsigned DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;类型，1-用户,2-群组\u0026#39;, `status` tinyint(1) unsigned DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;用户:0-正常, 1-用户A删除,群组:0-正常, 1-被删除\u0026#39;, `created` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_userId_peerId_status_updated` (`userId`,`peerId`,`status`,`updated`), KEY `idx_userId_peerId_type` (`userId`,`peerId`,`type`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 --用户关系表，标识两个用户之间的唯一关系id，用于消息分表。relationId % 消息表数目。 CREATE TABLE `IMRelationShip` ( `id` int(11) NOT NULL AUTO_INCREMENT, `smallId` int(11) unsigned NOT NULL COMMENT \u0026#39;用户A的id\u0026#39;, `bigId` int(11) unsigned NOT NULL COMMENT \u0026#39;用户B的id\u0026#39;, `status` tinyint(1) unsigned DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;用户:0-正常, 1-用户A删除,群组:0-正常, 1-被删除\u0026#39;, `created` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_smallId_bigId_status_updated` (`smallId`,`bigId`,`status`,`updated`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 --用户表 --password 密码,规则md5(md5(passwd)+salt) CREATE TABLE `IMUser` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;用户id\u0026#39;, `sex` tinyint(1) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;1男2女0未知\u0026#39;, `name` varchar(32) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;用户名\u0026#39;, `domain` varchar(32) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;拼音\u0026#39;, `nick` varchar(32) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;花名,绰号等\u0026#39;, `password` varchar(32) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;密码\u0026#39;, `salt` varchar(4) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;混淆码\u0026#39;, `phone` varchar(11) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;手机号码\u0026#39;, `email` varchar(64) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;email\u0026#39;, `avatar` varchar(255) COLLATE utf8mb4_bin DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;自定义用户头像\u0026#39;, `departId` int(11) unsigned NOT NULL COMMENT \u0026#39;所属部门Id\u0026#39;, `status` tinyint(2) unsigned DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;1. 试用期 2. 正式 3. 离职 4.实习\u0026#39;, `sign_info` varchar(32) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;个性签名\u0026#39;, `created` int(11) unsigned NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_domain` (`domain`), KEY `idx_name` (`name`), KEY `idx_phone` (`phone`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --离线文件传输表（同事建议的，待考证） CREATE TABLE `IMTransmitFile` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `fromId` int(11) unsigned NOT NULL COMMENT \u0026#39;发送用户的id\u0026#39;, `toId` int(11) unsigned NOT NULL COMMENT \u0026#39;接收用户的id\u0026#39;, `fileName` varchar(32) COLLATE utf8mb4_bin DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;文件名字\u0026#39;, `size` int(11) unsigned NOT NULL COMMENT \u0026#39;文件大小\u0026#39;, `taskId` varchar(256) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;任务id\u0026#39;, `status` tinyint(1) unsigned DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;状态\u0026#39;, `created` int(11) unsigned NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_taskId` (`taskId`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin; 因为这个企业内部的即时通讯软件，所以客户端不提供注册功能，要想增加新用户，必须通过在管理后台界面手动添加，这里由于我们目前没有部署管理后台界面（需要先安装nginx），所以我们就直接先在用户表IMUser里面添加几个测试用户吧。这个就是基本的sql语句了。但是由于这里用户密码的生成规则是：md5(md5(passwd)+salt)，而我们不知道salt到底是什么，这个现在不急，我们后面分析服务器代码时会介绍它。所以，我们就暂且在数据库里面随便写的密码，然后在程序里面修改代码，暂且不校验密码。修改的地方在这里：server\\src\\db_proxy_server\\business\\InterLogin.cpp的51行（CInterLoginStrategy::doLogin函数里面），将这个if语句注释掉：\n接下来就是如何编译程序了：\n编译程序需要用到cmake和make、gcc，由于程序用了部分C++11的东西，所以gcc的版本至少在4.7以上，我的部署环境是CentOS7、cmake 2.8，gcc 4.8.5。\n编译方法：\n编译说明 编译环境 TeamTalk编译需要依赖一些最新的c++标准, 建议使用CentOS 7.0, 如果使用的是CentOS 6.x,需要将g++版本升至支持c++11特性,升级脚本可以使用自动安装脚本目录下的gcc_setup\n第三方库 TeamTalk使用了许多第三方库，包括protobuf,hiredis,mariadb(mysql),log4cxx等等,在第一次编译TeamTalk之前,建议先执行目录下的：\nprotobuf: make_protobuf.sh hiredis: make_hiredis.sh mariadb: make_mariadb.sh log4cxx: make_log4cxx.sh 这些脚本执行完后会自动将头文件和库文件拷贝至指定的目录。如果你的机器上已经安装了相应的模块，可以不用执行相对应的脚本。\nmake_protobuf.sh会做以下工作：\n解压和编译protobuf目录下的protobuf-2.6.1.tar.gz文件，并在将编译后的文件拷贝到该目录，分别是bin、include和lib，还有一个protobuf-2.6.1是解压后的目录。protobuf目录结构如下：\n. |-- bin |-- include |-- lib |-- protobuf-2.6.1 `-- protobuf-2.6.1.tar.gz 同时会往server/src/base/pb目录下拷贝google和lib两个文件夹，protocol是原来就存在的存放protobuf的*.proto文件的目录，目录结构如下：\n. |-- google |-- lib `-- protocol make_log4cxx.sh 会做以下工作：\n\\1. 从网址 http://mirror.bit.edu.cn/apache/logging/log4cxx/0.10.0/apache-log4cxx-0.10.0.tar.gz 下载apache-log4cxx-0.10.0.tar.gz文件。下载好后解压安装，并在log4\ncxx目录下生成lib和include两个文件夹，目录结构如下：\n. |-- apache-log4cxx-0.10.0 |-- apache-log4cxx-0.10.0.tar.gz |-- console.cpp |-- include |-- inputstreamreader.cpp |-- lib `-- socketoutputstream.cpp 同样，apache-log4cxx-0.10.0是解压后的目录。\nmake_hiredis.sh和make_mariadb.sh原理一样，这里就不介绍了。\n编译TeamTalk服务器 当以上步骤都完成后，可以使用\u0026quot;./build.sh version 1\u0026quot;编译整个TeamTalk工程,一旦编译完成，会在上级目录生成im_server_x.tar.gz包，该压缩包包含的内容有: sync_lib_for_zip.sh: 将lib目录下的依赖库copy至各个服务器的目录下，启动服务前需要先执行一次该脚本 lib: 主要包含各个服务器依赖的第三方库 restart.sh: 启动脚本，启动方式为./restart.sh msg_server\nlogin_server: msg_server: route_server: db_proxy_server: file_server: push_server: msfs: 也可以进入各个服务目录下手动使用cmake . \u0026amp;\u0026amp; make去逐个编译。每个程序都有个配置文件，配置文件在auto_setup\\im_server\\conf目录下，手动编译时，请考到与与对应服务相同的目录下。\n注意最终生成的可执行文件，其配置文件必须和他们在同一个目录。另外可执行程序需要一个log4cxx.properties文件，这个文件是程序使用的日志库log4\ncxx的配置文件，必须也和可执行程序在同一个目录。如果没有，程序仍然能运行，但可能不能正常工作。你可以将\\server\\src\\slog\\log4cxx.properties下的该文件拷贝过去。\n生成程序后，你需要启动以上服务，当然在这前提下你必须能正常连接你的mysql和redis。可以按下列顺序启动服务：\ndb_proxy_server file_server msfs route_server http_server login_server msg_server 程序启动以后用lsof -i -Pn命令查看端口和连接情况：\nmysqld 2970 mysql 18u IPv6 26929 0t0 TCP *:3306 (LISTEN) mysqld 2970 mysql 40u IPv6 2347264 0t0 TCP 127.0.0.1:3306-\u0026gt;127.0.0.1:34780 (ESTABLISHED) mysqld 2970 mysql 41u IPv6 2347266 0t0 TCP 127.0.0.1:3306-\u0026gt;127.0.0.1:34782 (ESTABLISHED) mysqld 2970 mysql 42u IPv6 31596 0t0 TCP 127.0.0.1:3306-\u0026gt;127.0.0.1:33954 (ESTABLISHED) mysqld 2970 mysql 43u IPv6 31598 0t0 TCP 127.0.0.1:3306-\u0026gt;127.0.0.1:33956 (ESTABLISHED) mysqld 2970 mysql 50u IPv6 61604 0t0 TCP 127.0.0.1:3306-\u0026gt;127.0.0.1:34638 (ESTABLISHED) mysqld 2970 mysql 51u IPv6 108460 0t0 TCP 127.0.0.1:3306-\u0026gt;127.0.0.1:37204 (ESTABLISHED) redis-server 3772 zhangyl 4u IPv6 30711 0t0 TCP *:6379 (LISTEN) redis-server 3772 zhangyl 5u IPv4 30712 0t0 TCP *:6379 (LISTEN) redis-server 3772 zhangyl 6u IPv4 31560 0t0 TCP 127.0.0.1:6379-\u0026gt;127.0.0.1:39540 (ESTABLISHED) redis-server 3772 zhangyl 7u IPv4 31563 0t0 TCP 127.0.0.1:6379-\u0026gt;127.0.0.1:39542 (ESTABLISHED) redis-server 3772 zhangyl 8u IPv4 31566 0t0 TCP 127.0.0.1:6379-\u0026gt;127.0.0.1:39544 (ESTABLISHED) redis-server 3772 zhangyl 9u IPv4 31569 0t0 TCP 127.0.0.1:6379-\u0026gt;127.0.0.1:39546 (ESTABLISHED) redis-server 3772 zhangyl 10u IPv4 31572 0t0 TCP 127.0.0.1:6379-\u0026gt;127.0.0.1:39548 (ESTABLISHED) redis-server 3772 zhangyl 11u IPv4 31575 0t0 TCP 127.0.0.1:6379-\u0026gt;127.0.0.1:39550 (ESTABLISHED) redis-server 3772 zhangyl 12u IPv4 31578 0t0 TCP 127.0.0.1:6379-\u0026gt;127.0.0.1:39552 (ESTABLISHED) redis-server 3772 zhangyl 13u IPv4 31581 0t0 TCP 127.0.0.1:6379-\u0026gt;127.0.0.1:39554 (ESTABLISHED) redis-server 3772 zhangyl 14u IPv4 31584 0t0 TCP 127.0.0.1:6379-\u0026gt;127.0.0.1:39556 (ESTABLISHED) redis-server 3772 zhangyl 15u IPv4 31587 0t0 TCP 127.0.0.1:6379-\u0026gt;127.0.0.1:39558 (ESTABLISHED) db_proxy_server 3930 root 5u IPv4 31559 0t0 TCP 127.0.0.1:39540-\u0026gt;127.0.0.1:6379 (ESTABLISHED) db_proxy_server 3930 root 6u IPv4 31562 0t0 TCP 127.0.0.1:39542-\u0026gt;127.0.0.1:6379 (ESTABLISHED) db_proxy_server 3930 root 7u IPv4 31565 0t0 TCP 127.0.0.1:39544-\u0026gt;127.0.0.1:6379 (ESTABLISHED) db_proxy_server 3930 root 8u IPv4 31568 0t0 TCP 127.0.0.1:39546-\u0026gt;127.0.0.1:6379 (ESTABLISHED) db_proxy_server 3930 root 9u IPv4 31571 0t0 TCP 127.0.0.1:39548-\u0026gt;127.0.0.1:6379 (ESTABLISHED) db_proxy_server 3930 root 10u IPv4 31574 0t0 TCP 127.0.0.1:39550-\u0026gt;127.0.0.1:6379 (ESTABLISHED) db_proxy_server 3930 root 11u IPv4 31577 0t0 TCP 127.0.0.1:39552-\u0026gt;127.0.0.1:6379 (ESTABLISHED) db_proxy_server 3930 root 12u IPv4 31580 0t0 TCP 127.0.0.1:39554-\u0026gt;127.0.0.1:6379 (ESTABLISHED) db_proxy_server 3930 root 13u IPv4 31583 0t0 TCP 127.0.0.1:39556-\u0026gt;127.0.0.1:6379 (ESTABLISHED) db_proxy_server 3930 root 14u IPv4 31586 0t0 TCP 127.0.0.1:39558-\u0026gt;127.0.0.1:6379 (ESTABLISHED) db_proxy_server 3930 root 15u IPv4 2347263 0t0 TCP 127.0.0.1:34780-\u0026gt;127.0.0.1:3306 (ESTABLISHED) db_proxy_server 3930 root 16u IPv4 2347265 0t0 TCP 127.0.0.1:34782-\u0026gt;127.0.0.1:3306 (ESTABLISHED) db_proxy_server 3930 root 17u IPv4 31595 0t0 TCP 127.0.0.1:33954-\u0026gt;127.0.0.1:3306 (ESTABLISHED) db_proxy_server 3930 root 18u IPv4 31597 0t0 TCP 127.0.0.1:33956-\u0026gt;127.0.0.1:3306 (ESTABLISHED) db_proxy_server 3930 root 20u IPv4 31599 0t0 TCP *:10600 (LISTEN) db_proxy_server 3930 root 21u IPv4 2344452 0t0 TCP 127.0.0.1:10600-\u0026gt;127.0.0.1:41630 (ESTABLISHED) db_proxy_server 3930 root 22u IPv4 2344453 0t0 TCP 127.0.0.1:10600-\u0026gt;127.0.0.1:41632 (ESTABLISHED) db_proxy_server 3930 root 23u IPv4 2344454 0t0 TCP 127.0.0.1:10600-\u0026gt;127.0.0.1:41640 (ESTABLISHED) db_proxy_server 3930 root 24u IPv4 2344455 0t0 TCP 127.0.0.1:10600-\u0026gt;127.0.0.1:41642 (ESTABLISHED) db_proxy_server 3930 root 25u IPv4 2344456 0t0 TCP 127.0.0.1:10600-\u0026gt;127.0.0.1:41644 (ESTABLISHED) db_proxy_server 3930 root 26u IPv4 2344457 0t0 TCP 127.0.0.1:10600-\u0026gt;127.0.0.1:41646 (ESTABLISHED) db_proxy_server 3930 root 27u IPv4 2344458 0t0 TCP 127.0.0.1:10600-\u0026gt;127.0.0.1:41648 (ESTABLISHED) db_proxy_server 3930 root 28u IPv4 2344459 0t0 TCP 127.0.0.1:10600-\u0026gt;127.0.0.1:41650 (ESTABLISHED) db_proxy_server 3930 root 29u IPv4 2344460 0t0 TCP 127.0.0.1:10600-\u0026gt;127.0.0.1:41652 (ESTABLISHED) db_proxy_server 3930 root 30u IPv4 2344461 0t0 TCP 127.0.0.1:10600-\u0026gt;127.0.0.1:41654 (ESTABLISHED) db_proxy_server 3930 root 31u IPv4 61603 0t0 TCP 127.0.0.1:34638-\u0026gt;127.0.0.1:3306 (ESTABLISHED) db_proxy_server 3930 root 32u IPv4 108459 0t0 TCP 127.0.0.1:37204-\u0026gt;127.0.0.1:3306 (ESTABLISHED) file_server 3993 root 6u IPv4 32708 0t0 TCP *:8600 (LISTEN) file_server 3993 root 7u IPv4 32709 0t0 TCP 127.0.0.1:8601 (LISTEN) file_server 3993 root 8u IPv4 2344463 0t0 TCP 127.0.0.1:8600-\u0026gt;127.0.0.1:49172 (ESTABLISHED) http_msg_server 3998 root 5u IPv4 32765 0t0 TCP *:8400 (LISTEN) http_msg_server 3998 root 7u IPv4 2344443 0t0 TCP 127.0.0.1:41640-\u0026gt;127.0.0.1:10600 (ESTABLISHED) http_msg_server 3998 root 8u IPv4 2344444 0t0 TCP 127.0.0.1:41642-\u0026gt;127.0.0.1:10600 (ESTABLISHED) http_msg_server 3998 root 9u IPv4 2344445 0t0 TCP 127.0.0.1:41644-\u0026gt;127.0.0.1:10600 (ESTABLISHED) http_msg_server 3998 root 10u IPv4 2344446 0t0 TCP 127.0.0.1:41646-\u0026gt;127.0.0.1:10600 (ESTABLISHED) http_msg_server 3998 root 11u IPv4 2344447 0t0 TCP 127.0.0.1:41648-\u0026gt;127.0.0.1:10600 (ESTABLISHED) http_msg_server 3998 root 12u IPv4 2344448 0t0 TCP 127.0.0.1:41650-\u0026gt;127.0.0.1:10600 (ESTABLISHED) http_msg_server 3998 root 13u IPv4 2344449 0t0 TCP 127.0.0.1:41652-\u0026gt;127.0.0.1:10600 (ESTABLISHED) http_msg_server 3998 root 14u IPv4 2344450 0t0 TCP 127.0.0.1:41654-\u0026gt;127.0.0.1:10600 (ESTABLISHED) http_msg_server 3998 root 15u IPv4 2344451 0t0 TCP 127.0.0.1:37566-\u0026gt;127.0.0.1:8200 (ESTABLISHED) msg_server 4011 root 5u IPv4 32862 0t0 TCP *:8000 (LISTEN) msg_server 4011 root 7u IPv4 2344437 0t0 TCP 127.0.0.1:49172-\u0026gt;127.0.0.1:8600 (ESTABLISHED) msg_server 4011 root 8u IPv4 2344438 0t0 TCP 127.0.0.1:41630-\u0026gt;127.0.0.1:10600 (ESTABLISHED) msg_server 4011 root 9u IPv4 2344439 0t0 TCP 127.0.0.1:41632-\u0026gt;127.0.0.1:10600 (ESTABLISHED) msg_server 4011 root 10u IPv4 2344440 0t0 TCP 127.0.0.1:47294-\u0026gt;127.0.0.1:8100 (ESTABLISHED) msg_server 4011 root 11u IPv4 2344441 0t0 TCP 127.0.0.1:37546-\u0026gt;127.0.0.1:8200 (ESTABLISHED) msg_server 4011 root 13u IPv4 2347252 0t0 TCP 192.168.226.128:8000-\u0026gt;192.168.226.1:20801 (ESTABLISHED) push_server 4017 root 8u IPv4 32946 0t0 UDP 127.0.0.1:34870 route_server 4025 root 5u IPv4 32975 0t0 TCP *:8200 (LISTEN) route_server 4025 root 7u IPv4 2344467 0t0 TCP 127.0.0.1:8200-\u0026gt;127.0.0.1:37546 (ESTABLISHED) route_server 4025 root 8u IPv4 2344468 0t0 TCP 127.0.0.1:8200-\u0026gt;127.0.0.1:37566 (ESTABLISHED) msfs 4038 root 5u IPv4 33065 0t0 TCP 127.0.0.1:8700 (LISTEN) login_server 4075 root 5u IPv4 33115 0t0 TCP *:8008 (LISTEN) login_server 4075 root 7u IPv4 33116 0t0 TCP *:8100 (LISTEN) login_server 4075 root 8u IPv4 33117 0t0 TCP *:8080 (LISTEN) login_server 4075 root 9u IPv4 2344465 0t0 TCP 127.0.0.1:8100-\u0026gt;127.0.0.1:47294 (ESTABLISHED) 服务之间的拓扑图如下：\n各端口号在上面了。\n现在我们用pc端来连接一下服务器，假如我们在用户表里面建立个账号叫test和zhangyl。\n将登录服务器的地址设置为msg_server的监听端口号，如上图所示。输入用户名和密码（密码随意）。\n这样就可以进行聊天了，当然我这里同一台机器上开了两个pc客户端。实际使用的时候一台机器是不允许开两个终端的，为了测试方便，你需要取消这个限制。用VS2013或以上版本打开win-client\\solution\\teamtalk.sln，修改如下代码取消pc客户端单例限制：在teamtalk.cpp的CteamtalkApp::InitInstance()中，\npc端主程序用的是mfc框架，界面使用的duilib库。 我们将在下一篇文章中详细介绍pc端程序源码。\n这篇关于服务器端的部署就到这里了，个人觉得很不详尽，因为后面关于服务器的架构分析时会再次详细地介绍这一块，所以这里写的就比较简单了。\n如果你在实际部署时遇到任何问题都可以加我微信 easy_coder 交流。\n","permalink":"https://haokiu.com/blog/23af895a60264bfe949c3636689d3f83/","summary":"02 服务器端的程序的编译与部署 这篇我们来介绍下TeamTalk服务器端的编译与部署，部署文档在auto_setup下，这里我们只介绍下服务器程序的编译与部署，不包括管理后台的部署，其部署方法在auto_setup\\im_server文件夹，其实按官方介绍只要找一台干净的linux系统运行一下auto_setup\\im_server\\setup.sh程序就可以了，会自动安装mysql（maridb，mysql被oracle收购后，分为两个分支，继续开源的分支改名叫maridb）、nginx和redis。我们暂且不部署web端，所以不需要安装nginx。我这里是手动安装了mysql和redis。然后启动mysql和redis，并手动建立如下库和表。库名叫teamtalk，需要建立以下这些表：\n--后台管理员表 --password 密码,规则md5(md5(passwd)+salt) CREATE TABLE `IMAdmin` ( `id` mediumint(6) unsigned NOT NULL AUTO_INCREMENT, `uname` varchar(40) NOT NULL COMMENT \u0026#39;用户名\u0026#39;, `pwd` char(32) NOT NULL COMMENT \u0026#39;经过md5加密的密码\u0026#39;, `status` tinyint(2) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;用户状态 0 :正常 1:删除 可扩展\u0026#39;, `created` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8 --存储语音地址 CREATE TABLE `IMAudio` ( `id` int(11) NOT NULL AUTO_INCREMENT, `fromId` int(11) unsigned NOT NULL COMMENT \u0026#39;发送者Id\u0026#39;, `toId` int(11) unsigned NOT NULL COMMENT \u0026#39;接收者Id\u0026#39;, `path` varchar(255) COLLATE utf8mb4_bin DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;语音存储的地址\u0026#39;, `size` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;文件大小\u0026#39;, `duration` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;语音时长\u0026#39;, `created` int(11) unsigned NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_fromId_toId` (`fromId`,`toId`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --存储部门信息 CREATE TABLE `IMDepart` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;部门id\u0026#39;, `departName` varchar(64) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;部门名称\u0026#39;, `priority` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;显示优先级,相同优先级按拼音顺序排列\u0026#39;, `parentId` int(11) unsigned NOT NULL COMMENT \u0026#39;上级部门id\u0026#39;, `status` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;状态\u0026#39;, `created` int(11) unsigned NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_departName` (`departName`), KEY `idx_priority_status` (`priority`,`status`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --发现配置表 CREATE TABLE `IMDiscovery` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT COMMENT \u0026#39;id\u0026#39;, `itemName` varchar(64) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;名称\u0026#39;, `itemUrl` varchar(64) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;URL\u0026#39;, `itemPriority` int(11) unsigned NOT NULL COMMENT \u0026#39;显示优先级\u0026#39;, `status` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;状态\u0026#39;, `created` int(11) unsigned NOT NULL COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_itemName` (`itemName`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin --群组表 CREATE TABLE `IMGroup` ( `id` int(11) NOT NULL AUTO_INCREMENT, `name` varchar(256) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;群名称\u0026#39;, `avatar` varchar(256) COLLATE utf8mb4_bin NOT NULL DEFAULT \u0026#39;\u0026#39; COMMENT \u0026#39;群头像\u0026#39;, `creator` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建者用户id\u0026#39;, `type` tinyint(3) unsigned NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;群组类型，1-固定;2-临时群\u0026#39;, `userCnt` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;成员人数\u0026#39;, `status` tinyint(3) unsigned NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;是否删除,0-正常，1-删除\u0026#39;, `version` int(11) unsigned NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;群版本号\u0026#39;, `lastChated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;最后聊天时间\u0026#39;, `created` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_name` (`name`(191)), KEY `idx_creator` (`creator`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin COMMENT=\u0026#39;IM群信息\u0026#39; --群成员表 CREATE TABLE `IMGroupMember` ( `id` int(11) NOT NULL AUTO_INCREMENT, `groupId` int(11) unsigned NOT NULL COMMENT \u0026#39;群Id\u0026#39;, `userId` int(11) unsigned NOT NULL COMMENT \u0026#39;用户id\u0026#39;, `status` tinyint(4) unsigned NOT NULL DEFAULT \u0026#39;1\u0026#39; COMMENT \u0026#39;是否退出群，0-正常，1-已退出\u0026#39;, `created` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;创建时间\u0026#39;, `updated` int(11) unsigned NOT NULL DEFAULT \u0026#39;0\u0026#39; COMMENT \u0026#39;更新时间\u0026#39;, PRIMARY KEY (`id`), KEY `idx_groupId_userId_status` (`groupId`,`userId`,`status`), KEY `idx_userId_status_updated` (`userId`,`status`,`updated`), KEY `idx_groupId_updated` (`groupId`,`updated`) ) ENGINE=InnoDB AUTO_INCREMENT=68 DEFAULT CHARSET=utf8 COMMENT=\u0026#39;用户和群的关系表\u0026#39; --群消息表,x代表第几张表，目前做了分表有8张:0-7.","title":"02 服务器端的程序的编译与部署"},{"content":"03 服务器端的程序架构介绍 通过上一节的编译与部署，我们会得到TeamTalk服务器端以下部署程序：\ndb_proxy_server file_server http_msg_server login_server msfs msg_server push_server router_server 这些服务构成的拓扑图如下：\n各个服务程序的作用描述如下：\nLoginServer (C++): 负载均衡服务器，分配一个负载小的MsgServer给客户端使用 MsgServer (C++): 消息服务器，提供客户端大部分信令处理功能，包括私人聊天、群组聊天等 RouteServer (C++): 路由服务器，为登录在不同MsgServer的用户提供消息转发功能 FileServer (C++): 文件服务器，提供客户端之间得文件传输服务，支持在线以及离线文件传输 MsfsServer (C++): 图片存储服务器，提供头像，图片传输中的图片存储服务 DBProxy (C++): 数据库代理服务器，提供mysql以及redis的访问服务，屏蔽其他服务器与mysql与redis的直接交互 HttpMsgServer(C++) :对外接口服务器，提供对外接口功能。（目前只是框架） PushServer(C++): 消息推送服务器，提供IOS系统消息推送。（IOS消息推送必须走apns） 注意：上图中并没有push_server和http_push_server。如果你不调试ios版本的客户端，可以暂且不启动push_server，另外http_push_server也可以暂不启动。\n启动顺序：\n一般来说，前端的服务会依赖后端的服务，所以一般先启动后端服务，再启动前端服务。建议按以下顺序启动服务：\n1、启动db_proxy。 2、启动route_server，file_server，msfs 3、启动login_server 4、启动msg_server 那么我就按照服务端的启动顺序去讲解服务端的一个流程概述。 第一步:启动db_proxy后，db_proxy会去根据配置文件连接相应的MySQL实例，以及redis实例。 第二步:启动route_server,file_server,msfs后，各个服务端都会开始监听相应的端口。 第三步:启动login_server,login_server就开始监听相应的端口(8080)，等待客户端的连接，而分配一个负载相对较小的msg_server给客户端。 第四步:启动msg_server(端口8000)，msg_server启动后，会去主动连接route_server，login_server，db_proxy_server，会将自己的监听的端口信息注册到login_server去，同时在用户上线，下线的时候会将自己的负载情况汇报给login_server.\n各个服务的端口号 (注意：如果出现部署完成后但是服务进程启动有问题或者只有部分服务进程启动了，请查看相应的log日志，请查看相应的log日志，请查看相应的log日志。)\n服务 端口 login_server 8080/8008 msg_server 8000 db_proxy_server 10600 route_server 8200 http_msg_server 8400 file_server 8600/8601 服务网络通信框架介绍：\n上面介绍的每一个服务都使用了相同的网络通信框架，该通信框架可以单独拿出来做为一个通用的网络通信框架。该网络框架是在一个循环里面不断地检测IO事件，然后对检测到的事件进行处理。流程如下：\n使用IO复用技术（linux和windows平台用select、mac平台用kevent）分离网络IO。\n对分离出来的网络IO进行操作，分为socket句柄可读、可写和出错三种情况。\n当然再加上定时器事件，即检测一个定时器事件列表，如果有定时器到期，则执行该定时器事件。\n整个框架的伪码大致如下：\nwhile (running) { //处理定时器事件 _CheckTimer(); //IO multiplexing int n = select(socket集合, ...); //事件处理 **if** (某些socket可读) { pSocket-\u0026gt;OnRead(); } **if** (某些socket可写) { pSocket-\u0026gt;OnWrite(); } **if** (某些socket出错) { pSocket-\u0026gt;OnClose(); } } 处理定时器事件的代码如下：\nvoid CEventDispatch::_CheckTimer() { uint64_t curr_tick = get_tick_count(); list\u0026lt;TimerItem*\u0026gt;::iterator it; for (it = m_timer_list.begin(); it != m_timer_list.end(); ) { TimerItem* pItem = *it; // iterator maybe deleted in the callback, so we should increment it before callback it++; if(curr_tick \u0026gt;= pItem-\u0026gt;next_tick) { pItem-\u0026gt;next_tick += pItem-\u0026gt;interval; pItem-\u0026gt;callback(pItem-\u0026gt;user_data, NETLIB_MSG_TIMER, 0, NULL); } } } 即遍历一个定时器列表，将定时器对象与当前时间（curr_tick）做比较，如果当前时间已经大于或等于定时器设置的时间，则表明定时器时间已经到了，执行定时器对象对应的回调函数。\n在来看看OnRead、OnWrite和OnClose这三个函数。在TeamTalk源码中每一个socket连接被封装成一个CBaseSocket对象，该对象是一个使用引用计数的类的子类，通过这种方法来实现生存期自动管理。\nvoid CBaseSocket::OnRead() { if (m_state == SOCKET_STATE_LISTENING) { _AcceptNewSocket(); } else { u_long avail = 0; if ( (ioctlsocket(m_socket, FIONREAD, \u0026amp;avail) == SOCKET_ERROR) || (avail == 0) ) { m_callback(m_callback_data, NETLIB_MSG_CLOSE, (net_handle_t)m_socket, NULL); } else { m_callback(m_callback_data, NETLIB_MSG_READ, (net_handle_t)m_socket, NULL); } } } OnRead()方法根据状态标识m_state确定一个socket是侦听的socket还是普通与客户端连接的socket，如果是侦听sokcet则接收客户端的连接；如果是与客户端连接的socket，则先检测socket上有多少字节可读，如果没有字节可读或者检测字节数时出错，则关闭socket，反之调用设置的回调函数。\nvoid CBaseSocket::OnWrite() { \\#if ((defined _WIN32) || (defined __APPLE__)) CEventDispatch::Instance()-\u0026gt;RemoveEvent(m_socket, SOCKET_WRITE); \\#endif if (m_state == SOCKET_STATE_CONNECTING) { int error = 0; socklen_t len = sizeof(error); \\#ifdef _WIN32 getsockopt(m_socket, SOL_SOCKET, SO_ERROR, (**char***)\u0026amp;error, \u0026amp;len); \\#else getsockopt(m_socket, SOL_SOCKET, SO_ERROR, (**void***)\u0026amp;error, \u0026amp;len); \\#endif if (error) { m_callback(m_callback_data, NETLIB_MSG_CLOSE, (net_handle_t)m_socket, NULL); } else { m_state = SOCKET_STATE_CONNECTED; m_callback(m_callback_data, NETLIB_MSG_CONFIRM, (net_handle_t)m_socket, NULL); } } else { m_callback(m_callback_data, NETLIB_MSG_WRITE, (net_handle_t)m_socket, NULL); } } OnWrite()函数则根据m_state标识检测socket是否是尝试连接的socket（connect函数中的socket），用于判断socket是否已经连接成功，反之则是与客户端保持连接的socket，调用预先设置的回调函数。\nvoid CBaseSocket::OnClose() { m_state = SOCKET_STATE_CLOSING; m_callback(m_callback_data, NETLIB_MSG_CLOSE, (net_handle_t)m_socket, NULL); } OnClose()方法将标识m_state设置为需要关闭状态，并调用预先设置的回调函数。\n每个服务程序都使用一个stl hash_map来管理所有的socket，键是socket句柄，值是CBaseSocket对象指针：\ntypedef hash_map\u0026lt;net_handle_t, CBaseSocket*\u0026gt; SocketMap; SocketMap\tg_socket_map; 所以在删除或者新增socket时，实际上就是从这个hash_map中删除或者向这个hash_map中增加对象。多线程操作，需要一个锁来进行保护：\nvoid CEventDispatch::AddEvent(SOCKET fd, uint8_t socket_event) { CAutoLock func_lock(\u0026amp;m_lock); if ((socket_event \u0026amp; SOCKET_READ) != 0) { FD_SET(fd, \u0026amp;m_read_set); } if ((socket_event \u0026amp; SOCKET_WRITE) != 0) { FD_SET(fd, \u0026amp;m_write_set); } if ((socket_event \u0026amp; SOCKET_EXCEP) != 0) { FD_SET(fd, \u0026amp;m_excep_set); } } 代码CAutoLock func_lock(\u0026amp;m_lock);即保护该hash_map的锁对象。\n而管理以上功能的是一个单例类CEventDispatch，所以不难才出CEventDispatch提供的接口：\nclass CEventDispatch { public: virtual ~CEventDispatch(); void AddEvent(SOCKET fd, uint8_t socket_event); void RemoveEvent(SOCKET fd, uint8_t socket_event); void AddTimer(callback_t callback, void* user_data, uint64_t interval); void RemoveTimer(callback_t callback, void* user_data); void AddLoop(callback_t callback, void* user_data); void StartDispatch(uint32_t wait_timeout = 100); void StopDispatch(); bool isRunning() {return running;} static CEventDispatch* Instance(); protected: CEventDispatch(); private: void _CheckTimer(); void _CheckLoop(); typedef struct { callback_t\tcallback; void*\tuser_data; uint64_t\tinterval; uint64_t\tnext_tick; } TimerItem; private: #ifdef _WIN32 fd_set\tm_read_set; fd_set\tm_write_set; fd_set\tm_excep_set; #elif __APPLE__ int m_kqfd; #else int\tm_epfd; #endif CLock\tm_lock; list\u0026lt;TimerItem*\u0026gt;\tm_timer_list; list\u0026lt;TimerItem*\u0026gt;\tm_loop_list; static CEventDispatch* m_pEventDispatch; bool running; }; 其中StartDispatch()和StopDispatcher()分别用于启动和停止整个循环流程。一般在程序初始化的时候StartDispatch()，在程序退出时StopDispatcher()。\n下面我们以pc端登录为例来具体看一个数据包在服务器端各个服务之间走过的流程：\n步骤1：login_server初始化侦听socket，设置新连接到来的回调函数。8080端口，该端口是为http服务配置的。\n在login_server.cpp main函数中调用：\nnetlib_listen调用如下：\npSocket-\u0026gt;Listen调用：\nAddBaseSocket将该socket加入hash_map中。AddEvent设置需要关注的socket上的事件，这里只关注可读和出错事件。\n步骤2： 客户端调用connect()函数连接login_server的8080端口。\n步骤3：login_server收到连接请求后调用OnRead方法，OnRead()方法里面调用_AcceptNewSocket()，_AcceptNewSocket()接收新连接，创建新的socket，并调用之前初始化阶段netlib_listen设置的回调函数http_callback。\nvoid CBaseSocket::OnRead() { if (m_state == SOCKET_STATE_LISTENING) { _AcceptNewSocket(); } else { u_long avail = 0; if ( (ioctlsocket(m_socket, FIONREAD, \u0026amp;avail) == SOCKET_ERROR) || (avail == 0) ) { m_callback(m_callback_data, NETLIB_MSG_CLOSE, (net_handle_t)m_socket, NULL); } else { m_callback(m_callback_data, NETLIB_MSG_READ, (net_handle_t)m_socket, NULL); } } } void CBaseSocket::_AcceptNewSocket() { SOCKET fd = 0; sockaddr_in peer_addr; socklen_t addr_len = sizeof(sockaddr_in); char ip_str[64]; while ( (fd = accept(m_socket, (sockaddr*)\u0026amp;peer_addr, \u0026amp;addr_len)) != INVALID_SOCKET ) { CBaseSocket* pSocket = new CBaseSocket(); uint32_t ip = ntohl(peer_addr.sin_addr.s_addr); uint16_t port = ntohs(peer_addr.sin_port); snprintf(ip_str, sizeof(ip_str), \u0026#34;%d.%d.%d.%d\u0026#34;, ip \u0026gt;\u0026gt; 24, (ip \u0026gt;\u0026gt; 16) \u0026amp; 0xFF, (ip \u0026gt;\u0026gt; 8) \u0026amp; 0xFF, ip \u0026amp; 0xFF); log(\u0026#34;AcceptNewSocket, socket=%d from %s:%d\\n\u0026#34;, fd, ip_str, port); pSocket-\u0026gt;SetSocket(fd); pSocket-\u0026gt;SetCallback(m_callback); pSocket-\u0026gt;SetCallbackData(m_callback_data); pSocket-\u0026gt;SetState(SOCKET_STATE_CONNECTED); pSocket-\u0026gt;SetRemoteIP(ip_str); pSocket-\u0026gt;SetRemotePort(port); _SetNoDelay(fd); _SetNonblock(fd); AddBaseSocket(pSocket); CEventDispatch::Instance()-\u0026gt;AddEvent(fd, SOCKET_READ | SOCKET_EXCEP); m_callback(m_callback_data, NETLIB_MSG_CONNECT, (net_handle_t)fd, NULL); } } void http_callback(void* callback_data, uint8_t msg, uint32_t handle, void* pParam) { if (msg == NETLIB_MSG_CONNECT) { CHttpConn* pConn = new CHttpConn(); pConn-\u0026gt;OnConnect(handle); } else { log(\u0026#34;!!!error msg: %d \u0026#34;, msg); } } pConn-\u0026gt;OnConnect(handle)中设置http数据的回调函数httpconn_callback：\nvoid CHttpConn::OnConnect(net_handle_t handle) { printf(\u0026#34;OnConnect, handle=%d\\n\u0026#34;, handle); m_sock_handle = handle; m_state = CONN_STATE_CONNECTED; g_http_conn_map.insert(make_pair(m_conn_handle, this)); netlib_option(handle, NETLIB_OPT_SET_CALLBACK, (void*)httpconn_callback); netlib_option(handle, NETLIB_OPT_SET_CALLBACK_DATA, reinterpret_cast\u0026lt;void *\u0026gt;(m_conn_handle) ); netlib_option(handle, NETLIB_OPT_GET_REMOTE_IP, (void*)\u0026amp;m_peer_ip); } httpconn_callback中处理http可读可写出错事件：\nvoid httpconn_callback(void* callback_data, uint8_t msg, uint32_t handle, uint32_t uParam, void* pParam) { NOTUSED_ARG(uParam); NOTUSED_ARG(pParam); // convert void* to uint32_t, oops uint32_t conn_handle = *((uint32_t*)(\u0026amp;callback_data)); CHttpConn* pConn = FindHttpConnByHandle(conn_handle); if (!pConn) { return; } switch (msg) { case NETLIB_MSG_READ: pConn-\u0026gt;OnRead(); break; case NETLIB_MSG_WRITE: pConn-\u0026gt;OnWrite(); break; case NETLIB_MSG_CLOSE: pConn-\u0026gt;OnClose(); break; default: log(\u0026#34;!!!httpconn_callback error msg: %d \u0026#34;, msg); break; } } 步骤4：客户端连接成功以后，发送http请求，方法是get，请求url：http://192.168.226.128:8080/msg_server。（具体网址与你的机器配置的网址有关）\n步骤5：login_server检测到该socket可读，调用pConn-\u0026gt;OnRead()方法。\nvoid CHttpConn::OnRead() { for (;;) { uint32_t free_buf_len = m_in_buf.GetAllocSize() - m_in_buf.GetWriteOffset(); if (free_buf_len \u0026lt; READ_BUF_SIZE + 1) m_in_buf.Extend(READ_BUF_SIZE + 1); int ret = netlib_recv(m_sock_handle, m_in_buf.GetBuffer() + m_in_buf.GetWriteOffset(), READ_BUF_SIZE); if (ret \u0026lt;= 0) break; m_in_buf.IncWriteOffset(ret); m_last_recv_tick = get_tick_count(); } // 每次请求对应一个HTTP连接，所以读完数据后，不用在同一个连接里面准备读取下个请求 char* in_buf = (char*)m_in_buf.GetBuffer(); uint32_t buf_len = m_in_buf.GetWriteOffset(); in_buf[buf_len] = \u0026#39;\\0\u0026#39;; // 如果buf_len 过长可能是受到攻击，则断开连接 // 正常的url最大长度为2048，我们接受的所有数据长度不得大于1K if(buf_len \u0026gt; 1024) { log(\u0026#34;get too much data:%s \u0026#34;, in_buf); Close(); return; } //log(\u0026#34;OnRead, buf_len=%u, conn_handle=%u\\n\u0026#34;, buf_len, m_conn_handle); // for debug m_cHttpParser.ParseHttpContent(in_buf, buf_len); if (m_cHttpParser.IsReadAll()) { string url = m_cHttpParser.GetUrl(); if (strncmp(url.c_str(), \u0026#34;/msg_server\u0026#34;, 11) == 0) { string content = m_cHttpParser.GetBodyContent(); _HandleMsgServRequest(url, content); } else { log(\u0026#34;url unknown, url=%s \u0026#34;, url.c_str()); Close(); } } } CHttpConn::OnRead()先用recv收取数据，接着解析数据，如果出错或者非法数据就关闭连接。如果客户端发送的请求的http object正好是/msg_server，则调用_HandleMsgServRequest(url, content);进行处理：\nvoid CHttpConn::_HandleMsgServRequest(string\u0026amp; url, string\u0026amp; post_data) { msg_serv_info_t* pMsgServInfo; uint32_t min_user_cnt = (uint32_t)-1; map\u0026lt;uint32_t, msg_serv_info_t*\u0026gt;::iterator it_min_conn = g_msg_serv_info.end(); map\u0026lt;uint32_t, msg_serv_info_t*\u0026gt;::iterator it; if(g_msg_serv_info.size() \u0026lt;= 0) { Json::Value value; value[\u0026#34;code\u0026#34;] = 1; value[\u0026#34;msg\u0026#34;] = \u0026#34;没有msg_server\u0026#34;; string strContent = value.toStyledString(); char* szContent = new char[HTTP_RESPONSE_HTML_MAX]; snprintf(szContent, HTTP_RESPONSE_HTML_MAX, HTTP_RESPONSE_HTML, strContent.length(), strContent.c_str()); Send((void*)szContent, strlen(szContent)); delete [] szContent; return ; } for (it = g_msg_serv_info.begin() ; it != g_msg_serv_info.end(); it++) { pMsgServInfo = it-\u0026gt;second; if ( (pMsgServInfo-\u0026gt;cur_conn_cnt \u0026lt; pMsgServInfo-\u0026gt;max_conn_cnt) \u0026amp;\u0026amp; (pMsgServInfo-\u0026gt;cur_conn_cnt \u0026lt; min_user_cnt)) { it_min_conn = it; min_user_cnt = pMsgServInfo-\u0026gt;cur_conn_cnt; } } if (it_min_conn == g_msg_serv_info.end()) { log(\u0026#34;All TCP MsgServer are full \u0026#34;); Json::Value value; value[\u0026#34;code\u0026#34;] = 2; value[\u0026#34;msg\u0026#34;] = \u0026#34;负载过高\u0026#34;; string strContent = value.toStyledString(); char* szContent = new char[HTTP_RESPONSE_HTML_MAX]; snprintf(szContent, HTTP_RESPONSE_HTML_MAX, HTTP_RESPONSE_HTML, strContent.length(), strContent.c_str()); Send((void*)szContent, strlen(szContent)); delete [] szContent; return; } else { Json::Value value; value[\u0026#34;code\u0026#34;] = 0; value[\u0026#34;msg\u0026#34;] = \u0026#34;\u0026#34;; if(pIpParser-\u0026gt;isTelcome(GetPeerIP())) { value[\u0026#34;priorIP\u0026#34;] = string(it_min_conn-\u0026gt;second-\u0026gt;ip_addr1); value[\u0026#34;backupIP\u0026#34;] = string(it_min_conn-\u0026gt;second-\u0026gt;ip_addr2); value[\u0026#34;msfsPrior\u0026#34;] = strMsfsUrl; value[\u0026#34;msfsBackup\u0026#34;] = strMsfsUrl; } else { value[\u0026#34;priorIP\u0026#34;] = string(it_min_conn-\u0026gt;second-\u0026gt;ip_addr2); value[\u0026#34;backupIP\u0026#34;] = string(it_min_conn-\u0026gt;second-\u0026gt;ip_addr1); value[\u0026#34;msfsPrior\u0026#34;] = strMsfsUrl; value[\u0026#34;msfsBackup\u0026#34;] = strMsfsUrl; } value[\u0026#34;discovery\u0026#34;] = strDiscovery; value[\u0026#34;port\u0026#34;] = int2string(it_min_conn-\u0026gt;second-\u0026gt;port); string strContent = value.toStyledString(); char* szContent = new char[HTTP_RESPONSE_HTML_MAX]; uint32_t nLen = strContent.length(); snprintf(szContent, HTTP_RESPONSE_HTML_MAX, HTTP_RESPONSE_HTML, nLen, strContent.c_str()); Send((void*)szContent, strlen(szContent)); delete [] szContent; return; } } 该方法根据客户端ip地址将msg_server的地址组装成json格式，返回给客户端。json格式内容如下：\n{ \u0026#34;backupIP\u0026#34; : \u0026#34;localhost\u0026#34;, \u0026#34;code\u0026#34; : 0, \u0026#34;discovery\u0026#34; : \u0026#34;http://192.168.226.128/api/discovery\u0026#34;, \u0026#34;msfsBackup\u0026#34; : \u0026#34;http://192.168.226.128:8700/\u0026#34;, \u0026#34;msfsPrior\u0026#34; : \u0026#34;http://192.168.226.128:8700/\u0026#34;, \u0026#34;msg\u0026#34; : \u0026#34;\u0026#34;, \u0026#34;port\u0026#34; : \u0026#34;8000\u0026#34;, \u0026#34;priorIP\u0026#34; : \u0026#34;localhost\u0026#34; } 注意，发送数据给客户端调用的是Send方法，该方法会先尝试着调用底层的send()函数去发送，如果不能全部发送出去，则将剩余数据加入到对应的写数据缓冲区内。这样这些数据会在该socket可写时再继续发送。这是也是设计网络通信库一个通用的技巧，即先试着去send，如果send不了，将数据放入待发送缓冲区内，并设置检测可写标识位，当socket可写时，从待发送缓冲区取出数据发送出去。如果还是不能全部发送出去，继续设置检测可写标识位，下次再次发送，如此循环一直到所有数据都发送出去为止。\nint CHttpConn::Send(void* data, int len) { m_last_send_tick = get_tick_count(); if (m_busy) { m_out_buf.Write(data, len); return len; } int ret = netlib_send(m_sock_handle, data, len); if (ret \u0026lt; 0) ret = 0; if (ret \u0026lt; len) { m_out_buf.Write((char*)data + ret, len - ret); m_busy = true; //log(\u0026#34;not send all, remain=%d\\n\u0026#34;, m_out_buf.GetWriteOffset()); } else { OnWriteComlete(); } return len; } 当然，由于这里http设置成了短连接，每次应答完客户度之后立即关闭连接，在OnWriteComplete()里面：\nvoid CHttpConn::OnWriteComlete() { log(\u0026#34;write complete \u0026#34;); Close(); } 步骤6：客户端收到http请求的应答后，根据收到的json得到msg_server的ip地址，这里是ip地址是192.168.226.128，端口号是8000。客户端开始连接这个ip地址和端口号，连接过程与msg_server接收连接过程与上面的步骤相同。接着客户端给服务器发送登录数据包。\n步骤7：msg_server收到登录请求后，在CImConn::OnRead()收取数据，解包，调用子类CMsgConn重写的HandlePdu，处理登录请求，如何处理呢？处理如下：\n//MsgConn.cpp void CMsgConn::HandlePdu(CImPdu* pPdu) { // request authorization check if (pPdu-\u0026gt;GetCommandId() != CID_LOGIN_REQ_USERLOGIN \u0026amp;\u0026amp; !IsOpen() \u0026amp;\u0026amp; IsKickOff()) { log(\u0026#34;HandlePdu, wrong msg. \u0026#34;); throw CPduException(pPdu-\u0026gt;GetServiceId(), pPdu-\u0026gt;GetCommandId(), ERROR_CODE_WRONG_SERVICE_ID, \u0026#34;HandlePdu error, user not login. \u0026#34;); return; } switch (pPdu-\u0026gt;GetCommandId()) { case CID_OTHER_HEARTBEAT: _HandleHeartBeat(pPdu); break; case CID_LOGIN_REQ_USERLOGIN: _HandleLoginRequest(pPdu ); break; case CID_LOGIN_REQ_LOGINOUT: _HandleLoginOutRequest(pPdu); break; case CID_LOGIN_REQ_DEVICETOKEN: _HandleClientDeviceToken(pPdu); break; case CID_LOGIN_REQ_KICKPCCLIENT: _HandleKickPCClient(pPdu); break; case CID_LOGIN_REQ_PUSH_SHIELD: _HandlePushShieldRequest(pPdu); break; case CID_LOGIN_REQ_QUERY_PUSH_SHIELD: _HandleQueryPushShieldRequest(pPdu); break; case CID_MSG_DATA: _HandleClientMsgData(pPdu); break; case CID_MSG_DATA_ACK: _HandleClientMsgDataAck(pPdu); break; case CID_MSG_TIME_REQUEST: _HandleClientTimeRequest(pPdu); break; case CID_MSG_LIST_REQUEST: _HandleClientGetMsgListRequest(pPdu); break; case CID_MSG_GET_BY_MSG_ID_REQ: _HandleClientGetMsgByMsgIdRequest(pPdu); break; case CID_MSG_UNREAD_CNT_REQUEST: _HandleClientUnreadMsgCntRequest(pPdu ); break; case CID_MSG_READ_ACK: _HandleClientMsgReadAck(pPdu); break; case CID_MSG_GET_LATEST_MSG_ID_REQ: _HandleClientGetLatestMsgIDReq(pPdu); break; case CID_SWITCH_P2P_CMD: _HandleClientP2PCmdMsg(pPdu ); break; case CID_BUDDY_LIST_RECENT_CONTACT_SESSION_REQUEST: _HandleClientRecentContactSessionRequest(pPdu); break; case CID_BUDDY_LIST_USER_INFO_REQUEST: _HandleClientUserInfoRequest( pPdu ); break; case CID_BUDDY_LIST_REMOVE_SESSION_REQ: _HandleClientRemoveSessionRequest( pPdu ); break; case CID_BUDDY_LIST_ALL_USER_REQUEST: _HandleClientAllUserRequest(pPdu ); break; case CID_BUDDY_LIST_CHANGE_AVATAR_REQUEST: _HandleChangeAvatarRequest(pPdu); break; case CID_BUDDY_LIST_CHANGE_SIGN_INFO_REQUEST: _HandleChangeSignInfoRequest(pPdu); break; case CID_BUDDY_LIST_USERS_STATUS_REQUEST: _HandleClientUsersStatusRequest(pPdu); break; case CID_BUDDY_LIST_DEPARTMENT_REQUEST: _HandleClientDepartmentRequest(pPdu); break; // for group process case CID_GROUP_NORMAL_LIST_REQUEST: s_group_chat-\u0026gt;HandleClientGroupNormalRequest(pPdu, this); break; case CID_GROUP_INFO_REQUEST: s_group_chat-\u0026gt;HandleClientGroupInfoRequest(pPdu, this); break; case CID_GROUP_CREATE_REQUEST: s_group_chat-\u0026gt;HandleClientGroupCreateRequest(pPdu, this); break; case CID_GROUP_CHANGE_MEMBER_REQUEST: s_group_chat-\u0026gt;HandleClientGroupChangeMemberRequest(pPdu, this); break; case CID_GROUP_SHIELD_GROUP_REQUEST: s_group_chat-\u0026gt;HandleClientGroupShieldGroupRequest(pPdu, this); break; case CID_FILE_REQUEST: s_file_handler-\u0026gt;HandleClientFileRequest(this, pPdu); break; case CID_FILE_HAS_OFFLINE_REQ: s_file_handler-\u0026gt;HandleClientFileHasOfflineReq(this, pPdu); break; case CID_FILE_ADD_OFFLINE_REQ: s_file_handler-\u0026gt;HandleClientFileAddOfflineReq(this, pPdu); break; case CID_FILE_DEL_OFFLINE_REQ: s_file_handler-\u0026gt;HandleClientFileDelOfflineReq(this, pPdu); break; default: log(\u0026#34;wrong msg, cmd id=%d, user id=%u. \u0026#34;, pPdu-\u0026gt;GetCommandId(), GetUserId()); break; } } 分支case CID_LOGIN_REQ_USERLOGIN即处理登录请求：\n//在MsgConn.cpp中 void CMsgConn::_HandleLoginRequest(CImPdu* pPdu) { // refuse second validate request if (m_login_name.length() != 0) { log(\u0026#34;duplicate LoginRequest in the same conn \u0026#34;); return; } // check if all server connection are OK uint32_t result = 0; string result_string = \u0026#34;\u0026#34;; CDBServConn* pDbConn = get_db_serv_conn_for_login(); if (!pDbConn) { result = IM::BaseDefine::REFUSE_REASON_NO_DB_SERVER; result_string = \u0026#34;服务端异常\u0026#34;; } else if (!is_login_server_available()) { result = IM::BaseDefine::REFUSE_REASON_NO_LOGIN_SERVER; result_string = \u0026#34;服务端异常\u0026#34;; } else if (!is_route_server_available()) { result = IM::BaseDefine::REFUSE_REASON_NO_ROUTE_SERVER; result_string = \u0026#34;服务端异常\u0026#34;; } if (result) { IM::Login::IMLoginRes msg; msg.set_server_time(time(NULL)); msg.set_result_code((IM::BaseDefine::ResultType)result); msg.set_result_string(result_string); CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg); pdu.SetServiceId(SID_LOGIN); pdu.SetCommandId(CID_LOGIN_RES_USERLOGIN); pdu.SetSeqNum(pPdu-\u0026gt;GetSeqNum()); SendPdu(\u0026amp;pdu); Close(); return; } IM::Login::IMLoginReq msg; CHECK_PB_PARSE_MSG(msg.ParseFromArray(pPdu-\u0026gt;GetBodyData(), pPdu-\u0026gt;GetBodyLength())); //假如是汉字，则转成拼音 m_login_name = msg.user_name(); string password = msg.password(); uint32_t online_status = msg.online_status(); if (online_status \u0026lt; IM::BaseDefine::USER_STATUS_ONLINE || online_status \u0026gt; IM::BaseDefine::USER_STATUS_LEAVE) { log(\u0026#34;HandleLoginReq, online status wrong: %u \u0026#34;, online_status); online_status = IM::BaseDefine::USER_STATUS_ONLINE; } m_client_version = msg.client_version(); m_client_type = msg.client_type(); m_online_status = online_status; log(\u0026#34;HandleLoginReq, user_name=%s, status=%u, client_type=%u, client=%s, \u0026#34;, m_login_name.c_str(), online_status, m_client_type, m_client_version.c_str()); CImUser* pImUser = CImUserManager::GetInstance()-\u0026gt;GetImUserByLoginName(GetLoginName()); if (!pImUser) { pImUser = new CImUser(GetLoginName()); CImUserManager::GetInstance()-\u0026gt;AddImUserByLoginName(GetLoginName(), pImUser); } pImUser-\u0026gt;AddUnValidateMsgConn(this); CDbAttachData attach_data(ATTACH_TYPE_HANDLE, m_handle, 0); // continue to validate if the user is OK IM::Server::IMValidateReq msg2; msg2.set_user_name(msg.user_name()); msg2.set_password(password); msg2.set_attach_data(attach_data.GetBuffer(), attach_data.GetLength()); CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg2); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_VALIDATE_REQ); pdu.SetSeqNum(pPdu-\u0026gt;GetSeqNum()); pDbConn-\u0026gt;SendPdu(\u0026amp;pdu); } ","permalink":"https://haokiu.com/blog/74f8790b79af42ab856a668b8927b38a/","summary":"03 服务器端的程序架构介绍 通过上一节的编译与部署，我们会得到TeamTalk服务器端以下部署程序：\ndb_proxy_server file_server http_msg_server login_server msfs msg_server push_server router_server 这些服务构成的拓扑图如下：\n各个服务程序的作用描述如下：\nLoginServer (C++): 负载均衡服务器，分配一个负载小的MsgServer给客户端使用 MsgServer (C++): 消息服务器，提供客户端大部分信令处理功能，包括私人聊天、群组聊天等 RouteServer (C++): 路由服务器，为登录在不同MsgServer的用户提供消息转发功能 FileServer (C++): 文件服务器，提供客户端之间得文件传输服务，支持在线以及离线文件传输 MsfsServer (C++): 图片存储服务器，提供头像，图片传输中的图片存储服务 DBProxy (C++): 数据库代理服务器，提供mysql以及redis的访问服务，屏蔽其他服务器与mysql与redis的直接交互 HttpMsgServer(C++) :对外接口服务器，提供对外接口功能。（目前只是框架） PushServer(C++): 消息推送服务器，提供IOS系统消息推送。（IOS消息推送必须走apns） 注意：上图中并没有push_server和http_push_server。如果你不调试ios版本的客户端，可以暂且不启动push_server，另外http_push_server也可以暂不启动。\n启动顺序：\n一般来说，前端的服务会依赖后端的服务，所以一般先启动后端服务，再启动前端服务。建议按以下顺序启动服务：\n1、启动db_proxy。 2、启动route_server，file_server，msfs 3、启动login_server 4、启动msg_server 那么我就按照服务端的启动顺序去讲解服务端的一个流程概述。 第一步:启动db_proxy后，db_proxy会去根据配置文件连接相应的MySQL实例，以及redis实例。 第二步:启动route_server,file_server,msfs后，各个服务端都会开始监听相应的端口。 第三步:启动login_server,login_server就开始监听相应的端口(8080)，等待客户端的连接，而分配一个负载相对较小的msg_server给客户端。 第四步:启动msg_server(端口8000)，msg_server启动后，会去主动连接route_server，login_server，db_proxy_server，会将自己的监听的端口信息注册到login_server去，同时在用户上线，下线的时候会将自己的负载情况汇报给login_server.\n各个服务的端口号 (注意：如果出现部署完成后但是服务进程启动有问题或者只有部分服务进程启动了，请查看相应的log日志，请查看相应的log日志，请查看相应的log日志。)\n服务 端口 login_server 8080/8008 msg_server 8000 db_proxy_server 10600 route_server 8200 http_msg_server 8400 file_server 8600/8601 服务网络通信框架介绍：\n上面介绍的每一个服务都使用了相同的网络通信框架，该通信框架可以单独拿出来做为一个通用的网络通信框架。该网络框架是在一个循环里面不断地检测IO事件，然后对检测到的事件进行处理。流程如下：\n使用IO复用技术（linux和windows平台用select、mac平台用kevent）分离网络IO。\n对分离出来的网络IO进行操作，分为socket句柄可读、可写和出错三种情况。\n当然再加上定时器事件，即检测一个定时器事件列表，如果有定时器到期，则执行该定时器事件。\n整个框架的伪码大致如下：\nwhile (running) { //处理定时器事件 _CheckTimer(); //IO multiplexing int n = select(socket集合, ...); //事件处理 **if** (某些socket可读) { pSocket-\u0026gt;OnRead(); } **if** (某些socket可写) { pSocket-\u0026gt;OnWrite(); } **if** (某些socket出错) { pSocket-\u0026gt;OnClose(); } } 处理定时器事件的代码如下：\nvoid CEventDispatch::_CheckTimer() { uint64_t curr_tick = get_tick_count(); list\u0026lt;TimerItem*\u0026gt;::iterator it; for (it = m_timer_list.","title":"03 服务器端的程序架构介绍"},{"content":"04 服务器端db_proxy_server源码分析 从这篇文章开始，我将详细地分析TeamTalk服务器端每一个服务的源码和架构设计。\n这篇从db_proxy_server开始。db_proxy_server是TeamTalk服务器端最后端的程序，它连接着关系型数据库mysql和nosql内存数据库redis。其位置在整个服务架构中如图所示：\n我们从db_proxy_server的main()函数开始，main()函数其实就是做了以下初始化工作，我整理成如下伪码：\nint main() { //1. 初始化redis连接 //2. 初始化mysql连接 //3. 启动任务队列，用于处理任务 //4. 启动从mysql同步数据到redis工作 //5. 在端口10600上启动侦听，监听新连接 //6. 主线程进入循环，监听新连接的到来以及出来新连接上的数据收发 } 下面，我们将一一介绍以上步骤。\n一、初始化redis连接 CacheManager* pCacheManager = CacheManager::getInstance(); CacheManager* CacheManager::getInstance() { if (!s_cache_manager) { s_cache_manager = new CacheManager(); if (s_cache_manager-\u0026gt;Init()) { delete s_cache_manager; s_cache_manager = NULL; } } return s_cache_manager; } int CacheManager::Init() { CConfigFileReader config_file(\u0026#34;dbproxyserver.conf\u0026#34;); //CacheInstances=unread,group_set,token,sync,group_member char* cache_instances = config_file.GetConfigName(\u0026#34;CacheInstances\u0026#34;); if (!cache_instances) { log(\u0026#34;not configure CacheIntance\u0026#34;); return 1; } char host[64]; char port[64]; char db[64]; char maxconncnt[64]; CStrExplode instances_name(cache_instances, \u0026#39;,\u0026#39;); for (uint32_t i = 0; i \u0026lt; instances_name.GetItemCnt(); i++) { char* pool_name = instances_name.GetItem(i); //printf(\u0026#34;%s\u0026#34;, pool_name); snprintf(host, 64, \u0026#34;%s_host\u0026#34;, pool_name); snprintf(port, 64, \u0026#34;%s_port\u0026#34;, pool_name); snprintf(db, 64, \u0026#34;%s_db\u0026#34;, pool_name); snprintf(maxconncnt, 64, \u0026#34;%s_maxconncnt\u0026#34;, pool_name); char* cache_host = config_file.GetConfigName(host); char* str_cache_port = config_file.GetConfigName(port); char* str_cache_db = config_file.GetConfigName(db); char* str_max_conn_cnt = config_file.GetConfigName(maxconncnt); if (!cache_host || !str_cache_port || !str_cache_db || !str_max_conn_cnt) { log(\u0026#34;not configure cache instance: %s\u0026#34;, pool_name); return 2; } CachePool* pCachePool = new CachePool(pool_name, cache_host, atoi(str_cache_port), atoi(str_cache_db), atoi(str_max_conn_cnt)); if (pCachePool-\u0026gt;Init()) { log(\u0026#34;Init cache pool failed\u0026#34;); return 3; } m_cache_pool_map.insert(make_pair(pool_name, pCachePool)); } return 0; } 在pCachePool-\u0026gt;Init()中是实际连接redis的动作：\nint CachePool::Init() { for (int i = 0; i \u0026lt; m_cur_conn_cnt; i++) { CacheConn* pConn = new CacheConn(this); if (pConn-\u0026gt;Init()) { delete pConn; return 1; } m_free_list.push_back(pConn); } log(\u0026#34;cache pool: %s, list size: %lu\u0026#34;, m_pool_name.c_str(), m_free_list.size()); return 0; } pConn-\u0026gt;Init()调用如下：\nint CacheConn::Init() { if (m_pContext) { return 0; } // 4s 尝试重连一次 uint64_t cur_time = (uint64_t)time(NULL); if (cur_time \u0026lt; m_last_connect_time + 4) { return 1; } m_last_connect_time = cur_time; // 200ms超时 struct timeval timeout = {0, 200000}; m_pContext = redisConnectWithTimeout(m_pCachePool-\u0026gt;GetServerIP(), m_pCachePool-\u0026gt;GetServerPort(), timeout); if (!m_pContext || m_pContext-\u0026gt;err) { if (m_pContext) { log(\u0026#34;redisConnect failed: %s\u0026#34;, m_pContext-\u0026gt;errstr); redisFree(m_pContext); m_pContext = NULL; } else { log(\u0026#34;redisConnect failed\u0026#34;); } return 1; } redisReply* reply = (redisReply *)redisCommand(m_pContext, \u0026#34;SELECT %d\u0026#34;, m_pCachePool-\u0026gt;GetDBNum()); if (reply \u0026amp;\u0026amp; (reply-\u0026gt;type == REDIS_REPLY_STATUS) \u0026amp;\u0026amp; (strncmp(reply-\u0026gt;str, \u0026#34;OK\u0026#34;, 2) == 0)) { freeReplyObject(reply); return 0; } else { log(\u0026#34;select cache db failed\u0026#34;); return 2; } } 层级关系是这样的： CacheManager的成员变量m_cache_pool_map存储了配置文件配置的redis缓存池，这是一个map对象，key是缓存池的名字，value是缓存池CachePool对象的指针。\nmap\u0026lt;string, CachePool*\u0026gt;\tm_cache_pool_map; dbproxyserver.conf目前配置了如下几个redis缓存池：\nCacheInstances=unread,group_set,token,sync,group_member 每一个缓存池对象CachePool的成员变量m_free_list中存储着若干个与redis的连接对象，具体是多少个，根据配置文件来配置。m_free_list定义：\nlist\u0026lt;CacheConn*\u0026gt;\tm_free_list; 这些与redis连接对象后面会介绍在何处使用。\n二、初始化mysql连接 CDBManager* pDBManager = CDBManager::getInstance(); CDBManager* CDBManager::getInstance() { if (!s_db_manager) { s_db_manager = new CDBManager(); if (s_db_manager-\u0026gt;Init()) { delete s_db_manager; s_db_manager = NULL; } } return s_db_manager; } int CDBManager::Init() { CConfigFileReader config_file(\u0026#34;dbproxyserver.conf\u0026#34;); //DBInstances=teamtalk_master,teamtalk_slave char* db_instances = config_file.GetConfigName(\u0026#34;DBInstances\u0026#34;); if (!db_instances) { log(\u0026#34;not configure DBInstances\u0026#34;); return 1; } char host[64]; char port[64]; char dbname[64]; char username[64]; char password[64]; char maxconncnt[64]; CStrExplode instances_name(db_instances, \u0026#39;,\u0026#39;); for (uint32_t i = 0; i \u0026lt; instances_name.GetItemCnt(); i++) { char* pool_name = instances_name.GetItem(i); snprintf(host, 64, \u0026#34;%s_host\u0026#34;, pool_name); snprintf(port, 64, \u0026#34;%s_port\u0026#34;, pool_name); snprintf(dbname, 64, \u0026#34;%s_dbname\u0026#34;, pool_name); snprintf(username, 64, \u0026#34;%s_username\u0026#34;, pool_name); snprintf(password, 64, \u0026#34;%s_password\u0026#34;, pool_name); snprintf(maxconncnt, 64, \u0026#34;%s_maxconncnt\u0026#34;, pool_name); char* db_host = config_file.GetConfigName(host); char* str_db_port = config_file.GetConfigName(port); char* db_dbname = config_file.GetConfigName(dbname); char* db_username = config_file.GetConfigName(username); char* db_password = config_file.GetConfigName(password); char* str_maxconncnt = config_file.GetConfigName(maxconncnt); if (!db_host || !str_db_port || !db_dbname || !db_username || !db_password || !str_maxconncnt) { log(\u0026#34;not configure db instance: %s\u0026#34;, pool_name); return 2; } int db_port = atoi(str_db_port); int db_maxconncnt = atoi(str_maxconncnt); CDBPool* pDBPool = new CDBPool(pool_name, db_host, db_port, db_username, db_password, db_dbname, db_maxconncnt); if (pDBPool-\u0026gt;Init()) { log(\u0026#34;init db instance failed: %s\u0026#34;, pool_name); return 3; } m_dbpool_map.insert(make_pair(pool_name, pDBPool)); } return 0; } 同理pDBPool-\u0026gt;Init()中是实际连接mysql代码：\nint CDBPool::Init() { for (int i = 0; i \u0026lt; m_db_cur_conn_cnt; i++) { CDBConn* pDBConn = new CDBConn(this); int ret = pDBConn-\u0026gt;Init(); if (ret) { delete pDBConn; return ret; } m_free_list.push_back(pDBConn); } log(\u0026#34;db pool: %s, size: %d\u0026#34;, m_pool_name.c_str(), (int)m_free_list.size()); return 0; } int CDBConn::Init() { m_mysql = mysql_init(NULL); if (!m_mysql) { log(\u0026#34;mysql_init failed\u0026#34;); return 1; } my_bool reconnect = true; mysql_options(m_mysql, MYSQL_OPT_RECONNECT, \u0026amp;reconnect); mysql_options(m_mysql, MYSQL_SET_CHARSET_NAME, \u0026#34;utf8mb4\u0026#34;); if (!mysql_real_connect(m_mysql, m_pDBPool-\u0026gt;GetDBServerIP(), m_pDBPool-\u0026gt;GetUsername(), \u0026#34;\u0026#34;/*m_pDBPool-\u0026gt;GetPasswrod()*/, m_pDBPool-\u0026gt;GetDBName(), m_pDBPool-\u0026gt;GetDBServerPort(), NULL, 0)) { log(\u0026#34;mysql_real_connect failed: %s\u0026#34;, mysql_error(m_mysql)); return 2; } return 0; } 与redis连接对象类似，CDBManager的成员对象m_dbpool_map存储了mysql连接池，这也是一个stl map，key是池子的名字，value是连接池的对象CDBPool指针。配置文件中总共配置了名称为主从两个mysql连接池。\nDBInstances=teamtalk_master,teamtalk_slave 连接池对象CDBPool用一个成员变量存储自己的若干个mysql连接：\nlist\u0026lt;CDBConn*\u0026gt;\tm_free_list; //实际保存mysql连接的容器 具体每个连接池有多少个mysql连接，根据配置文件得到，这里主从两个库都是16个。\n这些mysql连接的用途后面介绍。\n三、启动任务队列，用于处理任务 初始化一：创建线程处理任务队列中的任务\ninit_proxy_conn(thread_num); int init_proxy_conn(uint32_t thread_num) { s_handler_map = CHandlerMap::getInstance(); g_thread_pool.Init(thread_num); netlib_add_loop(proxy_loop_callback, NULL); signal(SIGTERM, sig_handler); return netlib_register_timer(proxy_timer_callback, NULL, 1000); } 线程数量根据配置文件得到。g_thread_pool.Init(thread_num)中实际创建处理任务的线程。\nint CThreadPool::Init(uint32_t worker_size) { m_worker_size = worker_size; m_worker_list = new CWorkerThread [m_worker_size]; if (!m_worker_list) { return 1; } for (uint32_t i = 0; i \u0026lt; m_worker_size; i++) { m_worker_list[i].SetThreadIdx(i); m_worker_list[i].Start(); } return 0; } void CWorkerThread::Start() { (void)pthread_create(\u0026amp;m_thread_id, NULL, StartRoutine, this); } 线程函数调用序列如下：\nvoid* CWorkerThread::StartRoutine(void* arg) { CWorkerThread* pThread = (CWorkerThread*)arg; pThread-\u0026gt;Execute(); return NULL; } void CWorkerThread::Execute() { while (true) { m_thread_notify.Lock(); // put wait in while cause there can be spurious wake up (due to signal/ENITR) while (m_task_list.empty()) { m_thread_notify.Wait(); } CTask* pTask = m_task_list.front(); m_task_list.pop_front(); m_thread_notify.Unlock(); pTask-\u0026gt;run(); delete pTask; m_task_cnt++; //log(\u0026#34;%d have the execute %d task\\n\u0026#34;, m_thread_idx, m_task_cnt); } } 可以看到工作线程一直在等待一个条件变量，当向任务队列中添加任务时，条件变量被唤醒：\nvoid CWorkerThread::PushTask(CTask* pTask) { m_thread_notify.Lock(); m_task_list.push_back(pTask); m_thread_notify.Signal(); m_thread_notify.Unlock(); } 任务队列的用途，下文会介绍。\n初始化二：将各个任务id与对应的处理函数绑定起来：\ns_handler_map = CHandlerMap::getInstance(); CHandlerMap* CHandlerMap::getInstance() { if (!s_handler_instance) { s_handler_instance = new CHandlerMap(); s_handler_instance-\u0026gt;Init(); } return s_handler_instance; } void CHandlerMap::Init() { //DB_PROXY是命名空间，不是类名 // Login validate m_handler_map.insert(make_pair(uint32_t(CID_OTHER_VALIDATE_REQ), DB_PROXY::doLogin)); m_handler_map.insert(make_pair(uint32_t(CID_LOGIN_REQ_PUSH_SHIELD), DB_PROXY::doPushShield)); m_handler_map.insert(make_pair(uint32_t(CID_LOGIN_REQ_QUERY_PUSH_SHIELD), DB_PROXY::doQueryPushShield)); // recent session m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_RECENT_CONTACT_SESSION_REQUEST), DB_PROXY::getRecentSession)); m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_REMOVE_SESSION_REQ), DB_PROXY::deleteRecentSession)); // users m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_USER_INFO_REQUEST), DB_PROXY::getUserInfo)); m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_ALL_USER_REQUEST), DB_PROXY::getChangedUser)); m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_DEPARTMENT_REQUEST), DB_PROXY::getChgedDepart)); m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_CHANGE_SIGN_INFO_REQUEST), DB_PROXY::changeUserSignInfo)); // message content m_handler_map.insert(make_pair(uint32_t(CID_MSG_DATA), DB_PROXY::sendMessage)); m_handler_map.insert(make_pair(uint32_t(CID_MSG_LIST_REQUEST), DB_PROXY::getMessage)); m_handler_map.insert(make_pair(uint32_t(CID_MSG_UNREAD_CNT_REQUEST), DB_PROXY::getUnreadMsgCounter)); m_handler_map.insert(make_pair(uint32_t(CID_MSG_READ_ACK), DB_PROXY::clearUnreadMsgCounter)); m_handler_map.insert(make_pair(uint32_t(CID_MSG_GET_BY_MSG_ID_REQ), DB_PROXY::getMessageById)); m_handler_map.insert(make_pair(uint32_t(CID_MSG_GET_LATEST_MSG_ID_REQ), DB_PROXY::getLatestMsgId)); // device token m_handler_map.insert(make_pair(uint32_t(CID_LOGIN_REQ_DEVICETOKEN), DB_PROXY::setDevicesToken)); m_handler_map.insert(make_pair(uint32_t(CID_OTHER_GET_DEVICE_TOKEN_REQ), DB_PROXY::getDevicesToken)); //push 推送设置 m_handler_map.insert(make_pair(uint32_t(CID_GROUP_SHIELD_GROUP_REQUEST), DB_PROXY::setGroupPush)); m_handler_map.insert(make_pair(uint32_t(CID_OTHER_GET_SHIELD_REQ), DB_PROXY::getGroupPush)); // group m_handler_map.insert(make_pair(uint32_t(CID_GROUP_NORMAL_LIST_REQUEST), DB_PROXY::getNormalGroupList)); m_handler_map.insert(make_pair(uint32_t(CID_GROUP_INFO_REQUEST), DB_PROXY::getGroupInfo)); m_handler_map.insert(make_pair(uint32_t(CID_GROUP_CREATE_REQUEST), DB_PROXY::createGroup)); m_handler_map.insert(make_pair(uint32_t(CID_GROUP_CHANGE_MEMBER_REQUEST), DB_PROXY::modifyMember)); // file m_handler_map.insert(make_pair(uint32_t(CID_FILE_HAS_OFFLINE_REQ), DB_PROXY::hasOfflineFile)); m_handler_map.insert(make_pair(uint32_t(CID_FILE_ADD_OFFLINE_REQ), DB_PROXY::addOfflineFile)); m_handler_map.insert(make_pair(uint32_t(CID_FILE_DEL_OFFLINE_REQ), DB_PROXY::delOfflineFile)); }\tm_handler_map.insert(make_pair(uint32_t(CID_OTHER_VALIDATE_REQ), DB_PROXY::doLogin)); m_handler_map.insert(make_pair(uint32_t(CID_LOGIN_REQ_PUSH_SHIELD), DB_PROXY::doPushShield)); m_handler_map.insert(make_pair(uint32_t(CID_LOGIN_REQ_QUERY_PUSH_SHIELD), DB_PROXY::doQueryPushShield)); // recent session m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_RECENT_CONTACT_SESSION_REQUEST), DB_PROXY::getRecentSession)); m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_REMOVE_SESSION_REQ), DB_PROXY::deleteRecentSession)); // users m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_USER_INFO_REQUEST), DB_PROXY::getUserInfo)); m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_ALL_USER_REQUEST), DB_PROXY::getChangedUser)); m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_DEPARTMENT_REQUEST), DB_PROXY::getChgedDepart)); m_handler_map.insert(make_pair(uint32_t(CID_BUDDY_LIST_CHANGE_SIGN_INFO_REQUEST), DB_PROXY::changeUserSignInfo)); // message content m_handler_map.insert(make_pair(uint32_t(CID_MSG_DATA), DB_PROXY::sendMessage)); m_handler_map.insert(make_pair(uint32_t(CID_MSG_LIST_REQUEST), DB_PROXY::getMessage)); m_handler_map.insert(make_pair(uint32_t(CID_MSG_UNREAD_CNT_REQUEST), DB_PROXY::getUnreadMsgCounter)); m_handler_map.insert(make_pair(uint32_t(CID_MSG_READ_ACK), DB_PROXY::clearUnreadMsgCounter)); m_handler_map.insert(make_pair(uint32_t(CID_MSG_GET_BY_MSG_ID_REQ), DB_PROXY::getMessageById)); m_handler_map.insert(make_pair(uint32_t(CID_MSG_GET_LATEST_MSG_ID_REQ), DB_PROXY::getLatestMsgId)); // device token m_handler_map.insert(make_pair(uint32_t(CID_LOGIN_REQ_DEVICETOKEN), DB_PROXY::setDevicesToken)); m_handler_map.insert(make_pair(uint32_t(CID_OTHER_GET_DEVICE_TOKEN_REQ), DB_PROXY::getDevicesToken)); //push 推送设置 m_handler_map.insert(make_pair(uint32_t(CID_GROUP_SHIELD_GROUP_REQUEST), DB_PROXY::setGroupPush)); m_handler_map.insert(make_pair(uint32_t(CID_OTHER_GET_SHIELD_REQ), DB_PROXY::getGroupPush)); // group m_handler_map.insert(make_pair(uint32_t(CID_GROUP_NORMAL_LIST_REQUEST), DB_PROXY::getNormalGroupList)); m_handler_map.insert(make_pair(uint32_t(CID_GROUP_INFO_REQUEST), DB_PROXY::getGroupInfo)); m_handler_map.insert(make_pair(uint32_t(CID_GROUP_CREATE_REQUEST), DB_PROXY::createGroup)); m_handler_map.insert(make_pair(uint32_t(CID_GROUP_CHANGE_MEMBER_REQUEST), DB_PROXY::modifyMember)); // file m_handler_map.insert(make_pair(uint32_t(CID_FILE_HAS_OFFLINE_REQ), DB_PROXY::hasOfflineFile)); m_handler_map.insert(make_pair(uint32_t(CID_FILE_ADD_OFFLINE_REQ), DB_PROXY::addOfflineFile)); m_handler_map.insert(make_pair(uint32_t(CID_FILE_DEL_OFFLINE_REQ), DB_PROXY::delOfflineFile)); } 四、启动从mysql同步数据到redis工作 CSyncCenter::getInstance()-\u0026gt;init(); CSyncCenter::getInstance()-\u0026gt;startSync(); CSyncCenter::getInstance()-\u0026gt;init()是获得上次同步的数据位置，接下来同步从这个位置开始。\n/* * 初始化函数，从cache里面加载上次同步的时间信息等 */ void CSyncCenter::init() { // Load total update time CacheManager* pCacheManager = CacheManager::getInstance(); // increase message count CacheConn* pCacheConn = pCacheManager-\u0026gt;GetCacheConn(\u0026#34;unread\u0026#34;); if (pCacheConn) { string strTotalUpdate = pCacheConn-\u0026gt;get(\u0026#34;total_user_updated\u0026#34;); string strLastUpdateGroup = pCacheConn-\u0026gt;get(\u0026#34;last_update_group\u0026#34;); pCacheManager-\u0026gt;RelCacheConn(pCacheConn); if(strTotalUpdate != \u0026#34;\u0026#34;) { m_nLastUpdate = string2int(strTotalUpdate); } else { updateTotalUpdate(time(NULL)); } if(strLastUpdateGroup.empty()) { m_nLastUpdateGroup = string2int(strLastUpdateGroup); } else { updateLastUpdateGroup(time(NULL)); } } else { log(\u0026#34;no cache connection to get total_user_updated\u0026#34;); } } CSyncCenter::getInstance()-\u0026gt;startSync();新开启一个线程进行同步工作：\n/** * 开启内网数据同步以及群组聊天记录同步 */ void CSyncCenter::startSync() { #ifdef _WIN32 (void)CreateThread(NULL, 0, doSyncGroupChat, NULL, 0, \u0026amp;m_nGroupChatThreadId); #else (void)pthread_create(\u0026amp;m_nGroupChatThreadId, NULL, doSyncGroupChat, NULL); #endif } 线程函数doSyncGroupChat()如下：\n/** * 同步群组聊天信息 * * @param arg NULL * * @return NULL */ void* CSyncCenter::doSyncGroupChat(void* arg) { m_bSyncGroupChatRuning = true; CDBManager* pDBManager = CDBManager::getInstance(); map\u0026lt;uint32_t, uint32_t\u0026gt; mapChangedGroup; do{ mapChangedGroup.clear(); CDBConn* pDBConn = pDBManager-\u0026gt;GetDBConn(\u0026#34;teamtalk_slave\u0026#34;); if(pDBConn) { string strSql = \u0026#34;select id, lastChated from IMGroup where status=0 and lastChated \u0026gt;=\u0026#34; + int2string(m_pInstance-\u0026gt;getLastUpdateGroup()); CResultSet* pResult = pDBConn-\u0026gt;ExecuteQuery(strSql.c_str()); if(pResult) { while (pResult-\u0026gt;Next()) { uint32_t nGroupId = pResult-\u0026gt;GetInt(\u0026#34;id\u0026#34;); uint32_t nLastChat = pResult-\u0026gt;GetInt(\u0026#34;lastChated\u0026#34;); if(nLastChat != 0) { mapChangedGroup[nGroupId] = nLastChat; } } delete pResult; } pDBManager-\u0026gt;RelDBConn(pDBConn); } else { log(\u0026#34;no db connection for teamtalk_slave\u0026#34;); } m_pInstance-\u0026gt;updateLastUpdateGroup(time(NULL)); for (auto it=mapChangedGroup.begin(); it!=mapChangedGroup.end(); ++it) { uint32_t nGroupId =it-\u0026gt;first; list\u0026lt;uint32_t\u0026gt; lsUsers; uint32_t nUpdate = it-\u0026gt;second; CGroupModel::getInstance()-\u0026gt;getGroupUser(nGroupId, lsUsers); for (auto it1=lsUsers.begin(); it1!=lsUsers.end(); ++it1) { uint32_t nUserId = *it1; uint32_t nSessionId = INVALID_VALUE; nSessionId = CSessionModel::getInstance()-\u0026gt;getSessionId(nUserId, nGroupId, IM::BaseDefine::SESSION_TYPE_GROUP, true); if(nSessionId != INVALID_VALUE) { CSessionModel::getInstance()-\u0026gt;updateSession(nSessionId, nUpdate); } else { CSessionModel::getInstance()-\u0026gt;addSession(nUserId, nGroupId, IM::BaseDefine::SESSION_TYPE_GROUP); } } } // } while (!m_pInstance-\u0026gt;m_pCondSync-\u0026gt;waitTime(5*1000)); } while (m_pInstance-\u0026gt;m_bSyncGroupChatWaitting \u0026amp;\u0026amp; !(m_pInstance-\u0026gt;m_pCondGroupChat-\u0026gt;waitTime(5*1000))); // } while(m_pInstance-\u0026gt;m_bSyncGroupChatWaitting); m_bSyncGroupChatRuning = false; return NULL; } 可以看到流程就是先用sql从mysql取出数据，再用“sql”写到redis中去。操作mysql和redis时，并没有新建新连接，而是使用上文介绍的连接池和缓存池中已有的连接。我们上文说了，每个池中都有若干个连接，那使用哪个连接呢？由于保存mysql的连接是一个list对象，所以默认从list的头部取一个可用的。如果当前没有空闲连接可用，则新建一个：\nCDBConn* CDBPool::GetDBConn() { m_free_notify.Lock(); while (m_free_list.empty()) { if (m_db_cur_conn_cnt \u0026gt;= m_db_max_conn_cnt) { m_free_notify.Wait(); } else { CDBConn* pDBConn = new CDBConn(this); int ret = pDBConn-\u0026gt;Init(); if (ret) { log(\u0026#34;Init DBConnecton failed\u0026#34;); delete pDBConn; m_free_notify.Unlock(); return NULL; } else { m_free_list.push_back(pDBConn); m_db_cur_conn_cnt++; log(\u0026#34;new db connection: %s, conn_cnt: %d\u0026#34;, m_pool_name.c_str(), m_db_cur_conn_cnt); } } } CDBConn* pConn = m_free_list.front(); m_free_list.pop_front(); m_free_notify.Unlock(); return pConn; } 分配redis和mysql的一模一样，这里代码就不贴了。\n五、在端口10600上启动侦听，监听新连接 CStrExplode listen_ip_list(listen_ip, \u0026#39;;\u0026#39;); for (uint32_t i = 0; i \u0026lt; listen_ip_list.GetItemCnt(); i++) { ret = netlib_listen(listen_ip_list.GetItem(i), listen_port, proxy_serv_callback, NULL); if (ret == NETLIB_ERROR) return ret; } netlib_listen()创建CBaseSocket对象，并将回调函数指针proxy_serv_callback保存在CBaseSocket对象中。\nint netlib_listen( const char*\tserver_ip, uint16_t\tport, callback_t\tcallback, void*\tcallback_data) { CBaseSocket* pSocket = new CBaseSocket(); if (!pSocket) return NETLIB_ERROR; int ret = pSocket-\u0026gt;Listen(server_ip, port, callback, callback_data); if (ret == NETLIB_ERROR) delete pSocket; return ret; } pSocket-\u0026gt;Listen()是实际调用bind()和listen()函数创建侦听的地方。\nint CBaseSocket::Listen(const char* server_ip, uint16_t port, callback_t callback, void* callback_data) { m_local_ip = server_ip; m_local_port = port; m_callback = callback; m_callback_data = callback_data; m_socket = socket(AF_INET, SOCK_STREAM, 0); if (m_socket == INVALID_SOCKET) { printf(\u0026#34;socket failed, err_code=%d\\n\u0026#34;, _GetErrorCode()); return NETLIB_ERROR; } _SetReuseAddr(m_socket); _SetNonblock(m_socket); sockaddr_in serv_addr; _SetAddr(server_ip, port, \u0026amp;serv_addr); int ret = ::bind(m_socket, (sockaddr*)\u0026amp;serv_addr, sizeof(serv_addr)); if (ret == SOCKET_ERROR) { log(\u0026#34;bind failed, err_code=%d\u0026#34;, _GetErrorCode()); closesocket(m_socket); return NETLIB_ERROR; } ret = listen(m_socket, 64); if (ret == SOCKET_ERROR) { log(\u0026#34;listen failed, err_code=%d\u0026#34;, _GetErrorCode()); closesocket(m_socket); return NETLIB_ERROR; } m_state = SOCKET_STATE_LISTENING; log(\u0026#34;CBaseSocket::Listen on %s:%d\u0026#34;, server_ip, port); AddBaseSocket(this); CEventDispatch::Instance()-\u0026gt;AddEvent(m_socket, SOCKET_READ | SOCKET_EXCEP); return NETLIB_OK; } 这个函数有大量的细节需要注意：\nsocket被设置成非阻塞模式；\n将绑定的地址设置成reuse（具体原因，我在《服务器编程心得》系列已经介绍过）\n将socket的状态设置成SOCKET_STATE_LISTENING，这个状态将侦听的socket与普通客户端连接的socket区别开来。\nAddBaseSocket(this);将socket句柄和对应的CBaseSocket放到一个全局对象中管理起来。\ntypedef hash_map\u0026lt;net_handle_t, CBaseSocket*\u0026gt; SocketMap; SocketMap\tg_socket_map; void AddBaseSocket(CBaseSocket* pSocket) { g_socket_map.insert(make_pair((net_handle_t)pSocket-\u0026gt;GetSocket(), pSocket)); } 之所以不用map而用hash_map是因为STL的map底层是用红黑树实现的，查找时间复杂度是log(n)，而hash_map底层是用hash表存储的，查询时间复杂度是O(1)。后面会介绍将在这个hash_map中查找所有的socket。\n目前只关注socket的读和异常事件，侦听socket可读意味着有新连接到来，异常就意味着侦听出错。对于服务器程序一般要关闭或重启服务。 六、主线程进入循环，监听新连接的到来以及出来新连接上的数据收发 netlib_eventloop(10) 10是超时时间，用于select()函数的调用：\nvoid netlib_eventloop(uint32_t wait_timeout) { CEventDispatch::Instance()-\u0026gt;StartDispatch(wait_timeout); } void CEventDispatch::StartDispatch(uint32_t wait_timeout) { fd_set read_set, write_set, excep_set; timeval timeout; timeout.tv_sec = 0; timeout.tv_usec = wait_timeout * 1000;\t// 10 millisecond if(running) return; running = true; while (running) { _CheckTimer(); _CheckLoop(); if (!m_read_set.fd_count \u0026amp;\u0026amp; !m_write_set.fd_count \u0026amp;\u0026amp; !m_excep_set.fd_count) { Sleep(MIN_TIMER_DURATION); continue; } m_lock.lock(); memcpy(\u0026amp;read_set, \u0026amp;m_read_set, sizeof(fd_set)); memcpy(\u0026amp;write_set, \u0026amp;m_write_set, sizeof(fd_set)); memcpy(\u0026amp;excep_set, \u0026amp;m_excep_set, sizeof(fd_set)); m_lock.unlock(); int nfds = select(0, \u0026amp;read_set, \u0026amp;write_set, \u0026amp;excep_set, \u0026amp;timeout); if (nfds == SOCKET_ERROR) { log(\u0026#34;select failed, error code: %d\u0026#34;, GetLastError()); Sleep(MIN_TIMER_DURATION); continue;\t// select again } if (nfds == 0) { continue; } for (u_int i = 0; i \u0026lt; read_set.fd_count; i++) { //log(\u0026#34;select return read count=%d\\n\u0026#34;, read_set.fd_count); SOCKET fd = read_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnRead(); pSocket-\u0026gt;ReleaseRef(); } } for (u_int i = 0; i \u0026lt; write_set.fd_count; i++) { //log(\u0026#34;select return write count=%d\\n\u0026#34;, write_set.fd_count); SOCKET fd = write_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnWrite(); pSocket-\u0026gt;ReleaseRef(); } } for (u_int i = 0; i \u0026lt; excep_set.fd_count; i++) { //log(\u0026#34;select return exception count=%d\\n\u0026#34;, excep_set.fd_count); SOCKET fd = excep_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnClose(); pSocket-\u0026gt;ReleaseRef(); } } } } 这个函数是整个服务程序的动力和消息泵。我把它简化成如下伪码来重点介绍一下：\nwhile(退出条件) { //1. 遍历定时器队列，检测是否有定时器事件到期，有则执行定时器的回调函数 //2. 遍历其他任务队列，检测是否有其他任务需要执行，有，执行之 //3. 检测socket集合，分离可读、可写和异常事件 //4. 处理socket可读事件 //5. 处理socket可写事件 //6. 处理socket异常事件 } 我们先不说1、2两点，当程序初始化后，socket集合中，也只有一个socket，就是上文中说的侦听socket。当有新连接来的时候，该socket被检测到可读。执行\nfor (u_int i = 0; i \u0026lt; read_set.fd_count; i++) { //log(\u0026#34;select return read count=%d\\n\u0026#34;, read_set.fd_count); SOCKET fd = read_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnRead(); pSocket-\u0026gt;ReleaseRef(); } }\t//log(\u0026#34;select return read count=%d\\n\u0026#34;, read_set.fd_count); SOCKET fd = read_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnRead(); pSocket-\u0026gt;ReleaseRef(); } } FindBaseSocket()就是在上文提到的socket集合map中通过句柄查找socket：\nCBaseSocket* FindBaseSocket(net_handle_t fd) { CBaseSocket* pSocket = NULL; SocketMap::iterator iter = g_socket_map.find(fd); if (iter != g_socket_map.end()) { pSocket = iter-\u0026gt;second; pSocket-\u0026gt;AddRef(); } return pSocket; } 接着执行pSocket-\u0026gt;OnRead():\nvoid CBaseSocket::OnRead() { if (m_state == SOCKET_STATE_LISTENING) { _AcceptNewSocket(); } else { u_long avail = 0; if ( (ioctlsocket(m_socket, FIONREAD, \u0026amp;avail) == SOCKET_ERROR) || (avail == 0) ) { m_callback(m_callback_data, NETLIB_MSG_CLOSE, (net_handle_t)m_socket, NULL); } else { m_callback(m_callback_data, NETLIB_MSG_READ, (net_handle_t)m_socket, NULL); } } } 因为是侦听socket，其状态被设置成SOCKET_STATE_LISTENING(上文介绍了)。接着就接受新连接。\nvoid CBaseSocket::_AcceptNewSocket() { SOCKET fd = 0; sockaddr_in peer_addr; socklen_t addr_len = sizeof(sockaddr_in); char ip_str[64]; while ( (fd = accept(m_socket, (sockaddr*)\u0026amp;peer_addr, \u0026amp;addr_len)) != INVALID_SOCKET ) { CBaseSocket* pSocket = new CBaseSocket(); uint32_t ip = ntohl(peer_addr.sin_addr.s_addr); uint16_t port = ntohs(peer_addr.sin_port); snprintf(ip_str, sizeof(ip_str), \u0026#34;%d.%d.%d.%d\u0026#34;, ip \u0026gt;\u0026gt; 24, (ip \u0026gt;\u0026gt; 16) \u0026amp; 0xFF, (ip \u0026gt;\u0026gt; 8) \u0026amp; 0xFF, ip \u0026amp; 0xFF); log(\u0026#34;AcceptNewSocket, socket=%d from %s:%d\\n\u0026#34;, fd, ip_str, port); pSocket-\u0026gt;SetSocket(fd); pSocket-\u0026gt;SetCallback(m_callback); pSocket-\u0026gt;SetCallbackData(m_callback_data); pSocket-\u0026gt;SetState(SOCKET_STATE_CONNECTED); pSocket-\u0026gt;SetRemoteIP(ip_str); pSocket-\u0026gt;SetRemotePort(port); _SetNoDelay(fd); _SetNonblock(fd); AddBaseSocket(pSocket); CEventDispatch::Instance()-\u0026gt;AddEvent(fd, SOCKET_READ | SOCKET_EXCEP); m_callback(m_callback_data, NETLIB_MSG_CONNECT, (net_handle_t)fd, NULL); } } 接收新连接，需要注意以下事项：\n产生一个新的socket和对应的CBaseSocket对象。\n该socket和对应的CBaseSocket对象和侦听socket一样也被加入全局g_socket_map中进行管理。\n新socket同样被设置成非阻塞的。\n禁用该socket的nagle算法（_SetNoDelay(fd);）。\n关注该socket的读和异常事件（CEventDispatch::Instance()-\u0026gt;AddEvent(fd, SOCKET_READ | SOCKET_EXCEP);）。\n将socket的状态设置成SOCKET_STATE_CONNECTED。\n调用侦听socket的的回调函数m_callback(m_callback_data, NETLIB_MSG_CONNECT, (net_handle_t)fd, NULL)，并传入消息类型是NETLIB_MSG_CONNECT。\n这个回调函数在上面初始化侦听函数设置的，指向函数proxy_serv_callback。调用代码如下：\nvoid proxy_serv_callback(void* callback_data, uint8_t msg, uint32_t handle, void* pParam) { if (msg == NETLIB_MSG_CONNECT) { CProxyConn* pConn = new CProxyConn(); pConn-\u0026gt;OnConnect(handle); } else { log(\u0026#34;!!!error msg: %d\u0026#34;, msg); } } 接着调用CProxyConn的OnConnect()函数：\nvoid CProxyConn::OnConnect(net_handle_t handle) { m_handle = handle; g_proxy_conn_map.insert(make_pair(handle, this)); netlib_option(handle, NETLIB_OPT_SET_CALLBACK, (void*)imconn_callback); netlib_option(handle, NETLIB_OPT_SET_CALLBACK_DATA, (void*)\u0026amp;g_proxy_conn_map); netlib_option(handle, NETLIB_OPT_GET_REMOTE_IP, (void*)\u0026amp;m_peer_ip); netlib_option(handle, NETLIB_OPT_GET_REMOTE_PORT, (void*)\u0026amp;m_peer_port); log(\u0026#34;connect from %s:%d, handle=%d\u0026#34;, m_peer_ip.c_str(), m_peer_port, m_handle); } 注意！这里，已经悄悄地将该新socket的回调函数由proxy_serv_callback偷偷地换成了imconn_callback。同时，将该连接对象放入一个全局map g_proxy_conn_map中：\ntypedef hash_map\u0026lt;net_handle_t, CImConn*\u0026gt; ConnMap_t; static ConnMap_t g_proxy_conn_map; 同样，该map的key是socket句柄，value是连接对象基类的指针。\n至此，对于侦听socket，如果socket可读，则接收新连接，并置换其默认OnRead的回调函数为imconn_callback；而对于新socket，如果socket可读，则会调用imconn_callback。\n我们接着看新socket可读的处理流程：\nvoid CBaseSocket::OnRead() { if (m_state == SOCKET_STATE_LISTENING) { _AcceptNewSocket(); } else { u_long avail = 0; if ( (ioctlsocket(m_socket, FIONREAD, \u0026amp;avail) == SOCKET_ERROR) || (avail == 0) ) { m_callback(m_callback_data, NETLIB_MSG_CLOSE, (net_handle_t)m_socket, NULL); } else { m_callback(m_callback_data, NETLIB_MSG_READ, (net_handle_t)m_socket, NULL); } } } 上述OnRead函数会走else分支，先调用ioctlsocket获得可读的数据字节数。如果出错或者字节数为0，则以消息NETLIB_MSG_CLOSE调用回调函数imconn_callback,\n反之，以消息NETLIB_MSG_READ调用回调函数imconn_callback。\nvoid imconn_callback(void* callback_data, uint8_t msg, uint32_t handle, void* pParam) { NOTUSED_ARG(handle); NOTUSED_ARG(pParam); if (!callback_data) return; ConnMap_t* conn_map = (ConnMap_t*)callback_data; CImConn* pConn = FindImConn(conn_map, handle); if (!pConn) return; //log(\u0026#34;msg=%d, handle=%d \u0026#34;, msg, handle); switch (msg) { case NETLIB_MSG_CONFIRM: pConn-\u0026gt;OnConfirm(); break; case NETLIB_MSG_READ: pConn-\u0026gt;OnRead(); break; case NETLIB_MSG_WRITE: pConn-\u0026gt;OnWrite(); break; case NETLIB_MSG_CLOSE: pConn-\u0026gt;OnClose(); break; default: log(\u0026#34;!!!imconn_callback error msg: %d \u0026#34;, msg); break; } pConn-\u0026gt;ReleaseRef(); } 出错消息NETLIB_MSG_CLOSE没啥好看的，无非是关闭连接。我们来看NETLIB_MSG_READ消息，会调用pConn-\u0026gt;OnRead()，pConn是一个CImConn指针，但根据上文介绍我们知道，其实际是一个CImConn的子类CProxyConn对象：\nclass CProxyConn : public CImConn { 所以pConn-\u0026gt;OnRead()实际会调用CProxyConn的OnRead()：\nvoid CProxyConn::OnRead() { for (;;) { uint32_t free_buf_len = m_in_buf.GetAllocSize() - m_in_buf.GetWriteOffset(); if (free_buf_len \u0026lt; READ_BUF_SIZE) m_in_buf.Extend(READ_BUF_SIZE); int ret = netlib_recv(m_handle, m_in_buf.GetBuffer() + m_in_buf.GetWriteOffset(), READ_BUF_SIZE); if (ret \u0026lt;= 0) break; m_recv_bytes += ret; m_in_buf.IncWriteOffset(ret); m_last_recv_tick = get_tick_count(); } uint32_t pdu_len = 0; try { while ( CImPdu::IsPduAvailable(m_in_buf.GetBuffer(), m_in_buf.GetWriteOffset(), pdu_len) ) { HandlePduBuf(m_in_buf.GetBuffer(), pdu_len); m_in_buf.Read(NULL, pdu_len); } } catch (CPduException\u0026amp; ex) { log(\u0026#34;!!!catch exception, err_code=%u, err_msg=%s, close the connection \u0026#34;, ex.GetErrorCode(), ex.GetErrorMsg()); OnClose(); } } CImConn实际是代表一个连接，即每一个连接都有这样一个对象。具体被分化成它的各个子对象，如CProxyConn。每一个连接CImConn都存在一个读缓冲区和写缓冲区，读缓冲区用于存放从网络上收取的数据，写缓冲区用于存放即将发到网络中数据。CProxyConn::OnRead()先检测该对象的读缓冲区中还有多少可用空间，如果可用空间小于当前收到的字节数目，则将该读缓冲区的大小扩展到需要的大小READ_BUF_SIZE。接着收到的数据放入读缓冲区中。并记录下这次收取数据的时间到m_last_recv_tick变量中。接着开始解包，即调用CImPdu::IsPduAvailable()从读取缓冲区中取出数据处理，先判断现有数据是否大于一个包头的大小，如果不大于，退出。如果大于一个包头的大小，则接着根据包头中的信息得到整个包的大小：\nbool CImPdu::IsPduAvailable(uchar_t* buf, uint32_t len, uint32_t\u0026amp; pdu_len) { if (len \u0026lt; IM_PDU_HEADER_LEN) return false; pdu_len = CByteStream::ReadUint32(buf); if (pdu_len \u0026gt; len) { //log(\u0026#34;pdu_len=%d, len=%d\\n\u0026#34;, pdu_len, len); return false; } if(0 == pdu_len) { throw CPduException(1, \u0026#34;pdu_len is 0\u0026#34;); } return true; } 得到包的大小就可以正式处理包了，调用HandlePduBuf(m_in_buf.GetBuffer(), pdu_len);\nvoid CProxyConn::HandlePduBuf(uchar_t* pdu_buf, uint32_t pdu_len) { CImPdu* pPdu = NULL; pPdu = CImPdu::ReadPdu(pdu_buf, pdu_len); if (pPdu-\u0026gt;GetCommandId() == IM::BaseDefine::CID_OTHER_HEARTBEAT) { return; } pdu_handler_t handler = s_handler_map-\u0026gt;GetHandler(pPdu-\u0026gt;GetCommandId()); if (handler) { CTask* pTask = new CProxyTask(m_uuid, handler, pPdu); g_thread_pool.AddTask(pTask); } else { log(\u0026#34;no handler for packet type: %d\u0026#34;, pPdu-\u0026gt;GetCommandId()); } } 包的数据结构是CImPdu（Im 即Instant Message即时通讯软件的意思，teamtalk本来就是一款即时通讯，pdu，Protocol Data Unit 协议数据单元，通俗的说就是一个包单位），该数据结构分为包头和包体两部分。类CImPdu的两个成员变量：\nCSimpleBuffer\tm_buf; PduHeader_t m_pdu_header; 分别表示包头和包体，包头的定义PduHeader_t如下：\ntypedef struct { uint32_t length;\t// the whole pdu length uint16_t version;\t// pdu version number uint16_t\tflag;\t// not used uint16_t\tservice_id;\t// uint16_t\tcommand_id;\t// uint16_t\tseq_num; // 包序号 uint16_t reversed; // 保留 } PduHeader_t; 通过包头的command_id就知道该包是什么数据了。接着根据对应的命令号调用在程序初始化阶段绑定的包处理函数：\npdu_handler_t handler = s_handler_map-\u0026gt;GetHandler(pPdu-\u0026gt;GetCommandId()); 执行处理函数不是直接调用该函数，而是包装成一个任务放入前面介绍的任务队列中：\ndu_handler_t handler = s_handler_map-\u0026gt;GetHandler(pPdu-\u0026gt;GetCommandId()); if (handler) { CTask* pTask = new CProxyTask(m_uuid, handler, pPdu); g_thread_pool.AddTask(pTask); } else { log(\u0026#34;no handler for packet type: %d\u0026#34;, pPdu-\u0026gt;GetCommandId()); } 前面介绍过，处理任务的线程可能有多个，那么到底将任务加入到哪个工作线程呢？这里采取的策略是随机分配：\nvoid CThreadPool::AddTask(CTask* pTask) { /* * select a random thread to push task * we can also select a thread that has less task to do * but that will scan the whole thread list and use thread lock to get each task size */ uint32_t thread_idx = random() % m_worker_size; m_worker_list[thread_idx].PushTask(pTask); } 当然需要注意的是。如果数据包是心跳包的话，就直接不处理了。因为心跳包只是来保活通信的，与具体业务无关：\nif (pPdu-\u0026gt;GetCommandId() == IM::BaseDefine::CID_OTHER_HEARTBEAT) { return; } 该包处理完成以后，将该包的数据从连接的读缓冲区移除：\nm_in_buf.Read(NULL, pdu_len); 接着继续处理下一个包，因为收来的数据可能不够一个包大小，也可能是多个包的大小，所以要放在一个循环里面解包处理，直到读缓冲区中无数据或数据不够一个包的大小。\n我们将这个流程抽象出来，这个流程也是现在所有网络通信库都要做的工作：\nwhile(退出条件) { //1. 检测非侦听socket可读 //2. 处理可读事件 //3. 检测可读取的字节数，出错就关闭，不出错，将收取的字节放入连接的读缓冲区 //循环做以下处理 //4. 检测可读缓冲区数据大小是否大于等于一个包头大小: 否，数据不够一个包，跳出该循环; //\t是，从包头中得到一个包体的大小，检测读缓冲区是否够一个包头+包体的大小；否，数据不够一个包，跳出循环 //\t是，解包，根据包命令号，处理该包数据，可以产生一个任务，丢入任务队列。 //\t从可读缓冲区中移除刚才处理的包数据的字节数目。 //\t继续第4步。 } 当加入任务后，任务队列线程被唤醒，从任务队列的头部拿出该任务执行。这个上文介绍过了。\n到此，本文还没有完，因为上文只介绍了从客户端收取数据，然后解包。并没有介绍解完包，调用处理函数处理后如何应答客户端。下面以一个登录数据包的应答来叙述这个应答流程。登录任务从任务队列中取出来后，执行如下函数：\nvoid CHandlerMap::Init() { //DB_PROXY是命名空间，不是类名 // Login validate m_handler_map.insert(make_pair(uint32_t(CID_OTHER_VALIDATE_REQ), DB_PROXY::doLogin)); void doLogin(CImPdu* pPdu, uint32_t conn_uuid) { CImPdu* pPduResp = new CImPdu; IM::Server::IMValidateReq msg; IM::Server::IMValidateRsp msgResp; if(msg.ParseFromArray(pPdu-\u0026gt;GetBodyData(), pPdu-\u0026gt;GetBodyLength())) { string strDomain = msg.user_name(); string strPass = msg.password(); msgResp.set_user_name(strDomain); msgResp.set_attach_data(msg.attach_data()); do { CAutoLock cAutoLock(\u0026amp;g_cLimitLock); list\u0026lt;uint32_t\u0026gt;\u0026amp; lsErrorTime = g_hmLimits[strDomain]; uint32_t tmNow = time(NULL); //清理超过30分钟的错误时间点记录 /* 清理放在这里还是放在密码错误后添加的时候呢？ 放在这里，每次都要遍历，会有一点点性能的损失。 放在后面，可能会造成30分钟之前有10次错的，但是本次是对的就没办法再访问了。 */ auto itTime=lsErrorTime.begin(); for(; itTime!=lsErrorTime.end();++itTime) { if(tmNow - *itTime \u0026gt; 30*60) { break; } } if(itTime != lsErrorTime.end()) { lsErrorTime.erase(itTime, lsErrorTime.end()); } // 判断30分钟内密码错误次数是否大于10 if(lsErrorTime.size() \u0026gt; 10) { itTime = lsErrorTime.begin(); if(tmNow - *itTime \u0026lt;= 30*60) { msgResp.set_result_code(6); msgResp.set_result_string(\u0026#34;用户名/密码错误次数太多\u0026#34;); pPduResp-\u0026gt;SetPBMsg(\u0026amp;msgResp); pPduResp-\u0026gt;SetSeqNum(pPdu-\u0026gt;GetSeqNum()); pPduResp-\u0026gt;SetServiceId(IM::BaseDefine::SID_OTHER); pPduResp-\u0026gt;SetCommandId(IM::BaseDefine::CID_OTHER_VALIDATE_RSP); CProxyConn::AddResponsePdu(conn_uuid, pPduResp); return ; } } } while(false); log(\u0026#34;%s request login.\u0026#34;, strDomain.c_str()); IM::BaseDefine::UserInfo cUser; if(g_loginStrategy.doLogin(strDomain, strPass, cUser)) { IM::BaseDefine::UserInfo* pUser = msgResp.mutable_user_info(); pUser-\u0026gt;set_user_id(cUser.user_id()); pUser-\u0026gt;set_user_gender(cUser.user_gender()); pUser-\u0026gt;set_department_id(cUser.department_id()); pUser-\u0026gt;set_user_nick_name(cUser.user_nick_name()); pUser-\u0026gt;set_user_domain(cUser.user_domain()); pUser-\u0026gt;set_avatar_url(cUser.avatar_url()); pUser-\u0026gt;set_email(cUser.email()); pUser-\u0026gt;set_user_tel(cUser.user_tel()); pUser-\u0026gt;set_user_real_name(cUser.user_real_name()); pUser-\u0026gt;set_status(0); pUser-\u0026gt;set_sign_info(cUser.sign_info()); msgResp.set_result_code(0); msgResp.set_result_string(\u0026#34;成功\u0026#34;); //如果登陆成功，则清除错误尝试限制 CAutoLock cAutoLock(\u0026amp;g_cLimitLock); list\u0026lt;uint32_t\u0026gt;\u0026amp; lsErrorTime = g_hmLimits[strDomain]; lsErrorTime.clear(); } else { //密码错误，记录一次登陆失败 uint32_t tmCurrent = time(NULL); CAutoLock cAutoLock(\u0026amp;g_cLimitLock); list\u0026lt;uint32_t\u0026gt;\u0026amp; lsErrorTime = g_hmLimits[strDomain]; lsErrorTime.push_front(tmCurrent); log(\u0026#34;get result false\u0026#34;); msgResp.set_result_code(1); msgResp.set_result_string(\u0026#34;用户名/密码错误\u0026#34;); } } else { msgResp.set_result_code(2); msgResp.set_result_string(\u0026#34;服务端内部错误\u0026#34;); } pPduResp-\u0026gt;SetPBMsg(\u0026amp;msgResp); pPduResp-\u0026gt;SetSeqNum(pPdu-\u0026gt;GetSeqNum()); pPduResp-\u0026gt;SetServiceId(IM::BaseDefine::SID_OTHER); pPduResp-\u0026gt;SetCommandId(IM::BaseDefine::CID_OTHER_VALIDATE_RSP); CProxyConn::AddResponsePdu(conn_uuid, pPduResp); } 这段代码有点复杂，下面分析之：\n首先，将登录请求包数据通过函数参数（第一个参数）传入进来，其次是连接对象的id。前面已经介绍过了，每一个新的socket不仅对应一个CBaseSocket对象，同时也对应一个连接对象CImConn（可能会被具体化成对应的子类，如CProxyConn）。这些连接对象被放在另外一个全局map g_proxy_conn_map里面进行管理。\n通过包数据，我们能得到登录的用户名和密码等信息。接着检测30分钟之内，尝试登录的次数，如果30分钟之内密码错误次数超过10此。则不允许登录。组成一个提示“用户名或密码错误此时太多”的包：\nmsgResp.set_result_code(6); msgResp.set_result_string(\u0026#34;用户名/密码错误次数太多\u0026#34;); pPduResp-\u0026gt;SetPBMsg(\u0026amp;msgResp); pPduResp-\u0026gt;SetSeqNum(pPdu-\u0026gt;GetSeqNum()); pPduResp-\u0026gt;SetServiceId(IM::BaseDefine::SID_OTHER); pPduResp-\u0026gt;SetCommandId(IM::BaseDefine::CID_OTHER_VALIDATE_RSP); CProxyConn::AddResponsePdu(conn_uuid, pPduResp); 如果不存在这种情况，则接着调用g_loginStrategy.doLogin(strDomain, strPass, cUser)连接数据库进行用户名和密码校验：\nbool CInterLoginStrategy::doLogin(const std::string \u0026amp;strName, const std::string \u0026amp;strPass, IM::BaseDefine::UserInfo\u0026amp; user) { bool bRet = false; CDBManager* pDBManger = CDBManager::getInstance(); CDBConn* pDBConn = pDBManger-\u0026gt;GetDBConn(\u0026#34;teamtalk_slave\u0026#34;); if (pDBConn) { string strSql = \u0026#34;select * from IMUser where name=\u0026#39;\u0026#34; + strName + \u0026#34;\u0026#39; and status=0\u0026#34;; CResultSet* pResultSet = pDBConn-\u0026gt;ExecuteQuery(strSql.c_str()); if(pResultSet) { string strResult, strSalt; uint32_t nId, nGender, nDeptId, nStatus; string strNick, strAvatar, strEmail, strRealName, strTel, strDomain,strSignInfo; while (pResultSet-\u0026gt;Next()) { nId = pResultSet-\u0026gt;GetInt(\u0026#34;id\u0026#34;); strResult = pResultSet-\u0026gt;GetString(\u0026#34;password\u0026#34;); strSalt = pResultSet-\u0026gt;GetString(\u0026#34;salt\u0026#34;); strNick = pResultSet-\u0026gt;GetString(\u0026#34;nick\u0026#34;); nGender = pResultSet-\u0026gt;GetInt(\u0026#34;sex\u0026#34;); strRealName = pResultSet-\u0026gt;GetString(\u0026#34;name\u0026#34;); strDomain = pResultSet-\u0026gt;GetString(\u0026#34;domain\u0026#34;); strTel = pResultSet-\u0026gt;GetString(\u0026#34;phone\u0026#34;); strEmail = pResultSet-\u0026gt;GetString(\u0026#34;email\u0026#34;); strAvatar = pResultSet-\u0026gt;GetString(\u0026#34;avatar\u0026#34;); nDeptId = pResultSet-\u0026gt;GetInt(\u0026#34;departId\u0026#34;); nStatus = pResultSet-\u0026gt;GetInt(\u0026#34;status\u0026#34;); strSignInfo = pResultSet-\u0026gt;GetString(\u0026#34;sign_info\u0026#34;); } string strInPass = strPass + strSalt; char szMd5[33]; CMd5::MD5_Calculate(strInPass.c_str(), strInPass.length(), szMd5); string strOutPass(szMd5); //去掉密码校验 //if(strOutPass == strResult) { bRet = true; user.set_user_id(nId); user.set_user_nick_name(strNick); user.set_user_gender(nGender); user.set_user_real_name(strRealName); user.set_user_domain(strDomain); user.set_user_tel(strTel); user.set_email(strEmail); user.set_avatar_url(strAvatar); user.set_department_id(nDeptId); user.set_status(nStatus); user.set_sign_info(strSignInfo); } delete pResultSet; } pDBManger-\u0026gt;RelDBConn(pDBConn); } return bRet; } 这里也需要一个mysql连接，这个连接的分配方式在前面介绍过了。即在连接池中随机拿一个，如果池中不存在，则新建一个。用完还回去：\npDBManger-\u0026gt;RelDBConn(pDBConn); 接着通过用户名从数据库中取出该用户信息，如果记录存在，则接着校验密码。密码在数据库里面的存储形式是：密码+用户的salt值 组成的字符串的md5值。密码如果也校验正确，组装成一个正确应答数据包（附上命令号、序列号、提示信息等）：\npPduResp-\u0026gt;SetPBMsg(\u0026amp;msgResp); pPduResp-\u0026gt;SetSeqNum(pPdu-\u0026gt;GetSeqNum()); pPduResp-\u0026gt;SetServiceId(IM::BaseDefine::SID_OTHER); pPduResp-\u0026gt;SetCommandId(IM::BaseDefine::CID_OTHER_VALIDATE_RSP); CProxyConn::AddResponsePdu(conn_uuid, pPduResp); 现在不管登录成功与否，登录应答包也已经组装好了。接下来，就是如何发出去了？上述代码最后一行：\nCProxyConn::AddResponsePdu(conn_uuid, pPduResp) 其调用如下：\nvoid CProxyConn::AddResponsePdu(uint32_t conn_uuid, CImPdu* pPdu) { ResponsePdu_t* pResp = new ResponsePdu_t; pResp-\u0026gt;conn_uuid = conn_uuid; pResp-\u0026gt;pPdu = pPdu; s_list_lock.lock(); s_response_pdu_list.push_back(pResp); s_list_lock.unlock(); } 我们这里并没有直接将应答数据包通过连接对象CProxyConn发出去。因为直接发出去，未必能发出去。这会导致程序阻塞。（原因是：对方的tcp窗口太小，导致tcp窗口太小的常见原因是：对方无法收包或不及时收包，数据积压在对方网络协议栈里面）。我们这里是将应答数据包放入连接对象的一个应答链表s_response_pdu_list中。这是一个stl list容器：\nstatic list\u0026lt;ResponsePdu_t*\u0026gt;\ts_response_pdu_list;\t// 主线程发送回复消息 那么，包在这个链表中，何时被发出去呢？我们在介绍该服务的消息泵时介绍到如下流程：\nwhile(退出条件) { //1. 遍历定时器队列，检测是否有定时器事件到期，有则执行定时器的回调函数 //2. 遍历其他任务队列，检测是否有其他任务需要执行，有，执行之 //3. 检测socket集合，分离可读、可写和异常事件 //4. 处理socket可读事件 //5. 处理socket可写事件 //6. 处理socket异常事件 } 注意第2步：遍历其他任务队列，检测是否有其他任务需要执行，有，执行之。我们来看看这步具体做了什么。\n在main函数里面初始化任务队列线程时，同时也创建了一个其他任务：\ninit_proxy_conn(thread_num); int init_proxy_conn(uint32_t thread_num) { s_handler_map = CHandlerMap::getInstance(); g_thread_pool.Init(thread_num); netlib_add_loop(proxy_loop_callback, NULL); signal(SIGTERM, sig_handler); return netlib_register_timer(proxy_timer_callback, NULL, 1000); } 注意代码netlib_add_loop(proxy_loop_callback, NULL);该行加入了一个其他任务到其他任务队列。这样在主线程的消息泵中：2. 遍历其他任务队列，检测是否有其他任务需要执行，有，执行之。\n_CheckLoop(); void CEventDispatch::_CheckLoop() { for (list\u0026lt;TimerItem*\u0026gt;::iterator it = m_loop_list.begin(); it != m_loop_list.end(); it++) { TimerItem* pItem = *it; pItem-\u0026gt;callback(pItem-\u0026gt;user_data, NETLIB_MSG_LOOP, 0, NULL); } } 其他任务的回调函数目前只有一个，就是上面设置的proxy_loop_callback：\nvoid proxy_loop_callback(void* callback_data, uint8_t msg, uint32_t handle, void* pParam) { CProxyConn::SendResponsePduList(); } void CProxyConn::SendResponsePduList() { s_list_lock.lock(); while (!s_response_pdu_list.empty()) { ResponsePdu_t* pResp = s_response_pdu_list.front(); s_response_pdu_list.pop_front(); s_list_lock.unlock(); CProxyConn* pConn = get_proxy_conn_by_uuid(pResp-\u0026gt;conn_uuid); if (pConn) { if (pResp-\u0026gt;pPdu) { pConn-\u0026gt;SendPdu(pResp-\u0026gt;pPdu); } else { log(\u0026#34;close connection uuid=%d by parse pdu error\\b\u0026#34;, pResp-\u0026gt;conn_uuid); pConn-\u0026gt;Close(); } } if (pResp-\u0026gt;pPdu) delete pResp-\u0026gt;pPdu; delete pResp; s_list_lock.lock(); } s_list_lock.unlock(); } 看到这里，你应该明白了。原来应答数据包在这里从list中取出来。然后调用pConn-\u0026gt;SendPdu(pResp-\u0026gt;pPdu)“发出去”。这里需要解释两个问题：第一个就是一般服务器端会有多个连接对象，那么如何定位某个应答数据包对应的连接对象呢？这里就通过数据包本身的conn_uuid来确定：\nCProxyConn* pConn = get_proxy_conn_by_uuid(pResp-\u0026gt;conn_uuid); CProxyConn* get_proxy_conn_by_uuid(uint32_t uuid) { CProxyConn* pConn = NULL; UserMap_t::iterator it = g_uuid_conn_map.find(uuid); if (it != g_uuid_conn_map.end()) { pConn = (CProxyConn *)it-\u0026gt;second; } return pConn; } 全局对象g_uuid_conn_map里面存的是uuid与连接对象的对应关系。这个关系何时存入到这个全局g_uuid_conn_map对象的呢？在CProxyConn的构造函数中：\nCProxyConn::CProxyConn() { m_uuid = ++CProxyConn::s_uuid_alloctor; if (m_uuid == 0) { m_uuid = ++CProxyConn::s_uuid_alloctor; } g_uuid_conn_map.insert(make_pair(m_uuid, this)); } 这个uuid的基数是一个CProxyConn的静态变量：\nstatic uint32_t\ts_uuid_alloctor; 默认是0：\nuint32_t CProxyConn::s_uuid_alloctor = 0; 以后每产生一个新连接对象CProxyConn，在此基础上递增，因为没有用锁保护，所以只能在一个线程里面调用。而CProxyConn正好就是在主线程里面产生的，前面介绍过了，再次贴一下代码吧：\nvoid proxy_serv_callback(void* callback_data, uint8_t msg, uint32_t handle, void* pParam) { if (msg == NETLIB_MSG_CONNECT) { CProxyConn* pConn = new CProxyConn(); pConn-\u0026gt;OnConnect(handle); } else { log(\u0026#34;!!!error msg: %d\u0026#34;, msg); } } 这样uuid和连接对象CProxyConn还有CBaseSocket这三者的关系就唯一绑定了。\n接着说，通过uuid获得对应数据包的连接对象后，调用其方法pConn-\u0026gt;SendPdu(pResp-\u0026gt;pPdu); “发出去”？但是，还是不行，因为这还没有解决上文提出的该连接上对端的tcp窗口太小导致数据发不出的问题。所以pConn-\u0026gt;SendPdu()方法中一定不是调用send函数直接发送数据：\nint SendPdu(CImPdu* pPdu) { return Send(pPdu-\u0026gt;GetBuffer(), pPdu-\u0026gt;GetLength()); } 实际上是调用其基类CImConn类的Send方法，发送数据的时候，先记录一下发送数据的时间：m_last_send_tick = get_tick_count();\nint CImConn::Send(void* data, int len) { m_last_send_tick = get_tick_count(); //\t++g_send_pkt_cnt; if (m_busy) { m_out_buf.Write(data, len); return len; } int offset = 0; int remain = len; while (remain \u0026gt; 0) { int send_size = remain; if (send_size \u0026gt; NETLIB_MAX_SOCKET_BUF_SIZE) { send_size = NETLIB_MAX_SOCKET_BUF_SIZE; } int ret = netlib_send(m_handle, (char*)data + offset, send_size); if (ret \u0026lt;= 0) { ret = 0; break; } offset += ret; remain -= ret; } if (remain \u0026gt; 0) { m_out_buf.Write((char*)data + offset, remain); m_busy = true; log(\u0026#34;send busy, remain=%d \u0026#34;, m_out_buf.GetWriteOffset()); } else { OnWriteCompelete(); } return len; } 注意这段代码，也是特别的讲究：\n先试着调用底层send方法去发送，能发多少是多少，剩下发不完的，写入该连接的发送缓冲区中，并将忙碌标志m_busy置位（设置为ture）。反之，如果数据一次性发送完成，则调用数据发送完成函数OnWriteComplete（），这个函数目前为空，即不做任何事情。\nint ret = netlib_send(m_handle, (char*)data + offset , send_size); int netlib_send(net_handle_t handle, void* buf, int len) { CBaseSocket* pSocket = FindBaseSocket(handle); if (!pSocket) { return NETLIB_ERROR; } int ret = pSocket-\u0026gt;Send(buf, len); pSocket-\u0026gt;ReleaseRef(); return ret; } 上面的代码通过socket句柄找到具体的CBaseSocket对象。接着调用CBaseSocket::Send()方法：\nint CBaseSocket::Send(void* buf, int len) { if (m_state != SOCKET_STATE_CONNECTED) return NETLIB_ERROR; int ret = send(m_socket, (char*)buf, len, 0); if (ret == SOCKET_ERROR) { int err_code = _GetErrorCode(); if (_IsBlock(err_code)) { #if ((defined _WIN32) || (defined __APPLE__)) CEventDispatch::Instance()-\u0026gt;AddEvent(m_socket, SOCKET_WRITE); #endif ret = 0; //log(\u0026#34;socket send block fd=%d\u0026#34;, m_socket); } else { log(\u0026#34;!!!send failed, error code: %d\u0026#34;, err_code); } } return ret; } 该方法发送指定长度的数据，因为socket在创建的时候被设置成非阻塞的（上文介绍过）。所以，如果发送不了，底层send函数会立刻返回，并返回错误码EINPROGRESS（EWOULDBLOCK），表明对端tcp窗口太小，当前已经无法发出去：\nbool CBaseSocket::_IsBlock(int error_code) { #ifdef _WIN32 return ( (error_code == WSAEINPROGRESS) || (error_code == WSAEWOULDBLOCK) ); #else return ( (error_code == EINPROGRESS) || (error_code == EWOULDBLOCK) ); #endif } 这个时候，我们再设置关注该socket的可写事件。这样，下次对端tcp窗口大小增大时，本端的socket可写时，我们就能接着发送数据了。会在服务的消息泵中检测可写事件，接着调用CBaseSocket::OnWrite()， 该函数首先移除该socket的可写事件（这里为啥只有win32平台和mac机器移除可写事件，linux平台不需要吗？个人觉得是程序作者的疏忽）。\nvoid CBaseSocket::OnWrite() { #if ((defined _WIN32) || (defined __APPLE__)) CEventDispatch::Instance()-\u0026gt;RemoveEvent(m_socket, SOCKET_WRITE); #endif if (m_state == SOCKET_STATE_CONNECTING) { int error = 0; socklen_t len = sizeof(error); #ifdef _WIN32 getsockopt(m_socket, SOL_SOCKET, SO_ERROR, (char*)\u0026amp;error, \u0026amp;len); #else getsockopt(m_socket, SOL_SOCKET, SO_ERROR, (void*)\u0026amp;error, \u0026amp;len); #endif if (error) { m_callback(m_callback_data, NETLIB_MSG_CLOSE, (net_handle_t)m_socket, NULL); } else { m_state = SOCKET_STATE_CONNECTED; m_callback(m_callback_data, NETLIB_MSG_CONFIRM, (net_handle_t)m_socket, NULL); } } else { m_callback(m_callback_data, NETLIB_MSG_WRITE, (net_handle_t)m_socket, NULL); } } 走else分支，调用设置的回调函数imconn_callback：\nvoid imconn_callback(void* callback_data, uint8_t msg, uint32_t handle, void* pParam) { NOTUSED_ARG(handle); NOTUSED_ARG(pParam); if (!callback_data) return; ConnMap_t* conn_map = (ConnMap_t*)callback_data; CImConn* pConn = FindImConn(conn_map, handle); if (!pConn) return; //log(\u0026#34;msg=%d, handle=%d \u0026#34;, msg, handle); switch (msg) { case NETLIB_MSG_CONFIRM: pConn-\u0026gt;OnConfirm(); break; case NETLIB_MSG_READ: pConn-\u0026gt;OnRead(); break; case NETLIB_MSG_WRITE: pConn-\u0026gt;OnWrite(); break; case NETLIB_MSG_CLOSE: pConn-\u0026gt;OnClose(); break; default: log(\u0026#34;!!!imconn_callback error msg: %d \u0026#34;, msg); break; } pConn-\u0026gt;ReleaseRef(); } 因为这次传入的消息是NETLIB_MSG_WRITE，所以走pConn-\u0026gt;OnWrite分支，接着由于多态调用CImConn的子类CProxyConn的OnWrite()函数，但由于子类CProxyConn并没有改写OnWrite()方法，所以调用CImConn的OnWrite():\nvoid CImConn::OnWrite() { if (!m_busy) return; while (m_out_buf.GetWriteOffset() \u0026gt; 0) { int send_size = m_out_buf.GetWriteOffset(); if (send_size \u0026gt; NETLIB_MAX_SOCKET_BUF_SIZE) { send_size = NETLIB_MAX_SOCKET_BUF_SIZE; } int ret = netlib_send(m_handle, m_out_buf.GetBuffer(), send_size); if (ret \u0026lt;= 0) { ret = 0; break; } m_out_buf.Read(NULL, ret); } if (m_out_buf.GetWriteOffset() == 0) { m_busy = false; } log(\u0026#34;onWrite, remain=%d \u0026#34;, m_out_buf.GetWriteOffset()); } 接着继续从写缓冲区取出数据继续发送，如果还是只能发送出去，继续监听该socket可写事件，每次发送出去多少，就从写缓冲区中移除该部分字节。如果全部发送完了。将忙碌标志m_busy清零（false）。\n至此，应答数据包的流程也介绍完了。我们来总结下该流程：\n//1. 主消息泵检测到有其他任务需要做，做之。 //2. 该任务是从全局的链表中取出应答包数据，找到对应的连接对象，然后尝试直接发出去； //3. 如果发不出，则将该数据存入该连接的发送缓冲区（写缓冲区），并监听该连接的socket可写事件。 //4. 下次该socket触发可写事件时，接着发送该连接的写缓冲区中剩余的数据。如此循环直到所有数据都发送成功。 //5. 取消监听该socket可写事件，以避免无数据的情况下触发写事件（该事件大多数情况下很频繁） 上面的流程从第2步到第5步也是主流网络库的发数据的逻辑。总而言之，就是说，先试着发送数据，如果发不出去，存起来，监听可写事件，下次触发可写事件后接着发。一直到数据全部发出去后，移除监听可写事件。通常只要可写事件是不断会触发的，所以默认不监听可写事件，只有数据发不出的时候才会监听可写事件。这个原则，千万要记住。\n最后一个问题，是关于心跳包的，即db_proxy_server是如何发送心跳包的：\n程序初始化的时候，注册一个定时器函数：\ninit_proxy_conn(thread_num); int init_proxy_conn(uint32_t thread_num) { s_handler_map = CHandlerMap::getInstance(); g_thread_pool.Init(thread_num); netlib_add_loop(proxy_loop_callback, NULL); signal(SIGTERM, sig_handler); return netlib_register_timer(proxy_timer_callback, NULL, 1000); } 最后一行：return netlib_register_timer(proxy_timer_callback, NULL, 1000);\n然后在消息泵里面检测定时器：\n_CheckTimer(); void CEventDispatch::_CheckTimer() { uint64_t curr_tick = get_tick_count(); list\u0026lt;TimerItem*\u0026gt;::iterator it; for (it = m_timer_list.begin(); it != m_timer_list.end(); ) { TimerItem* pItem = *it; it++;\t// iterator maybe deleted in the callback, so we should increment it before callback if (curr_tick \u0026gt;= pItem-\u0026gt;next_tick) { pItem-\u0026gt;next_tick += pItem-\u0026gt;interval; pItem-\u0026gt;callback(pItem-\u0026gt;user_data, NETLIB_MSG_TIMER, 0, NULL); } } } uint64_t get_tick_count() { #ifdef _WIN32 LARGE_INTEGER liCounter; LARGE_INTEGER liCurrent; if (!QueryPerformanceFrequency(\u0026amp;liCounter)) return GetTickCount(); QueryPerformanceCounter(\u0026amp;liCurrent); return (uint64_t)(liCurrent.QuadPart * 1000 / liCounter.QuadPart); #else struct timeval tval; uint64_t ret_tick; gettimeofday(\u0026amp;tval, NULL); ret_tick = tval.tv_sec * 1000L + tval.tv_usec / 1000L; return ret_tick; #endif } 由上面的函数可以看出来定时器的单位是毫秒，当定时器时间到了后，调用回调函数proxy_timer_callback：\nvoid proxy_timer_callback(void* callback_data, uint8_t msg, uint32_t handle, void* pParam) { uint64_t cur_time = get_tick_count(); for (ConnMap_t::iterator it = g_proxy_conn_map.begin(); it != g_proxy_conn_map.end(); ) { ConnMap_t::iterator it_old = it; it++; CProxyConn* pConn = (CProxyConn*)it_old-\u0026gt;second; pConn-\u0026gt;OnTimer(cur_time); } } void CProxyConn::OnTimer(uint64_t curr_tick) { if (curr_tick \u0026gt; m_last_send_tick + SERVER_HEARTBEAT_INTERVAL) { CImPdu cPdu; IM::Other::IMHeartBeat msg; cPdu.SetPBMsg(\u0026amp;msg); cPdu.SetServiceId(IM::BaseDefine::SID_OTHER); cPdu.SetCommandId(IM::BaseDefine::CID_OTHER_HEARTBEAT); SendPdu(\u0026amp;cPdu); } if (curr_tick \u0026gt; m_last_recv_tick + SERVER_TIMEOUT) { log(\u0026#34;proxy connection timeout %s:%d\u0026#34;, m_peer_ip.c_str(), m_peer_port); Close(); } } m_last_send_tick是上一次发送数据的时间，我们上文中介绍过，如果当前时间距上一次发送数据的时间已经超过了指定的时间间隔，则发送一个心跳包（这里的时间间隔是5000毫秒）。\nm_last_recv_tick是上一次收取数据的时间，我们上文也介绍过，如果当前时间举例上一次接收时间已经超过了指定的时间间隔（相当于一段时间内，对端没有给当前服务发送任何数据），这个时候就关闭该连接（这里设置的时间间隔是30000毫秒，也就是30秒）。\n这种心跳包机制特别值得推崇，也是常见的心跳包策略。\n至此，db_proxy_server的框架和原理也就介绍完了。剩下的就是一些业务逻辑了。如果你感兴趣，可以自己查看对应的命令号绑定的处理函数的处理流程。\n文中如果有说错的地方，欢迎提出留言指正。\n","permalink":"https://haokiu.com/blog/5481b95ce7c64f8c99c98e3c59d74314/","summary":"04 服务器端db_proxy_server源码分析 从这篇文章开始，我将详细地分析TeamTalk服务器端每一个服务的源码和架构设计。\n这篇从db_proxy_server开始。db_proxy_server是TeamTalk服务器端最后端的程序，它连接着关系型数据库mysql和nosql内存数据库redis。其位置在整个服务架构中如图所示：\n我们从db_proxy_server的main()函数开始，main()函数其实就是做了以下初始化工作，我整理成如下伪码：\nint main() { //1. 初始化redis连接 //2. 初始化mysql连接 //3. 启动任务队列，用于处理任务 //4. 启动从mysql同步数据到redis工作 //5. 在端口10600上启动侦听，监听新连接 //6. 主线程进入循环，监听新连接的到来以及出来新连接上的数据收发 } 下面，我们将一一介绍以上步骤。\n一、初始化redis连接 CacheManager* pCacheManager = CacheManager::getInstance(); CacheManager* CacheManager::getInstance() { if (!s_cache_manager) { s_cache_manager = new CacheManager(); if (s_cache_manager-\u0026gt;Init()) { delete s_cache_manager; s_cache_manager = NULL; } } return s_cache_manager; } int CacheManager::Init() { CConfigFileReader config_file(\u0026#34;dbproxyserver.conf\u0026#34;); //CacheInstances=unread,group_set,token,sync,group_member char* cache_instances = config_file.GetConfigName(\u0026#34;CacheInstances\u0026#34;); if (!cache_instances) { log(\u0026#34;not configure CacheIntance\u0026#34;); return 1; } char host[64]; char port[64]; char db[64]; char maxconncnt[64]; CStrExplode instances_name(cache_instances, \u0026#39;,\u0026#39;); for (uint32_t i = 0; i \u0026lt; instances_name.GetItemCnt(); i++) { char* pool_name = instances_name.GetItem(i); //printf(\u0026#34;%s\u0026#34;, pool_name); snprintf(host, 64, \u0026#34;%s_host\u0026#34;, pool_name); snprintf(port, 64, \u0026#34;%s_port\u0026#34;, pool_name); snprintf(db, 64, \u0026#34;%s_db\u0026#34;, pool_name); snprintf(maxconncnt, 64, \u0026#34;%s_maxconncnt\u0026#34;, pool_name); char* cache_host = config_file.","title":"04 服务器端db_proxy_server源码分析"},{"content":"05 服务器端msg_server源码分析 在分析msg_server的源码之前，我们先简单地回顾一下msg_server在整个服务器系统中的位置和作用：\n各个服务程序的作用描述如下：\nLoginServer (C++): 负载均衡服务器，分配一个负载小的MsgServer给客户端使用 MsgServer (C++): 消息服务器，提供客户端大部分信令处理功能，包括私人聊天、群组聊天等 RouteServer (C++): 路由服务器，为登录在不同MsgServer的用户提供消息转发功能 FileServer (C++): 文件服务器，提供客户端之间得文件传输服务，支持在线以及离线文件传输 MsfsServer (C++): 图片存储服务器，提供头像，图片传输中的图片存储服务 DBProxy (C++): 数据库代理服务器，提供mysql以及redis的访问服务，屏蔽其他服务器与mysql与redis的直接交互 HttpMsgServer(C++) :对外接口服务器，提供对外接口功能。（目前只是框架） PushServer(C++): 消息推送服务器，提供IOS系统消息推送。（IOS消息推送必须走apns） 从上面的介绍中，我们可以看出TeamTalk是支持分布式部署的一套聊天服务器程序，通过分布式部署可以实现分流和支持高数量的用户同时在线。msg_server是整个服务体系的核心系统，可以部署多个，不同的用户可以登录不同的msg_server。这套体系有如下几大亮点：\nlogin_server可以根据当前各个msg_server上在线用户数量，来决定一个新用户登录到哪个msg_server，从而实现了负载平衡；\nroute_server可以将登录在不同的msg_server上的用户的聊天消息发给目标用户；\n通过单独的一个数据库操作服务器db_proxy_server，避免了msg_server直接操作数据库，将数据库操作的入口封装起来。\n在前一篇文章《服务器端db_proxy_server源码分析》中，我介绍了每个服务如何接收连接、读取数据并解包、以及组装数据包发包的操作，这篇文章我将介绍作为客户端，一个服务如何连接另外一个服务。这里msg_server在启动时会同时连接db_proxy_server，login_server，file_server，route_server，push_server。在msg_server服务main函数里面有如下初始化调用：\n//连接file_server init_file_serv_conn(file_server_list, file_server_count); //连接db_proxy_server init_db_serv_conn(db_server_list2, db_server_count2, concurrent_db_conn_cnt); //连接login_server init_login_serv_conn(login_server_list, login_server_count, ip_addr1, ip_addr2, listen_port, max_conn_cnt); //连接push_server init_route_serv_conn(route_server_list, route_server_count); //连接push_server init_push_serv_conn(push_server_list, push_server_count); 其中每个连接服务的流程都是一样的。我们这里以第一个连接file_server为例：\nvoid init_file_serv_conn(serv_info_t* server_list, uint32_t server_count) { g_file_server_list = server_list; g_file_server_count = server_count; serv_init\u0026lt;CFileServConn\u0026gt;(g_file_server_list, g_file_server_count); netlib_register_timer(file_server_conn_timer_callback, NULL, 1000); s_file_handler = CFileHandler::getInstance(); } template \u0026lt;class T\u0026gt; void serv_init(serv_info_t* server_list, uint32_t server_count) { for (uint32_t i = 0; i \u0026lt; server_count; i++) { T* pConn = new T(); pConn-\u0026gt;Connect(server_list[i].server_ip.c_str(), server_list[i].server_port, i); server_list[i].serv_conn = pConn; server_list[i].idle_cnt = 0; server_list[i].reconnect_cnt = MIN_RECONNECT_CNT / 2; } } 模板函数serv_init展开参数后实际上是调用CFileServConn-\u0026gt;Connect()，我们看这个函数的调用：\nvoid CFileServConn::Connect(const char* server_ip, uint16_t server_port, uint32_t idx) { log(\u0026#34;Connecting to FileServer %s:%d \u0026#34;, server_ip, server_port); m_serv_idx = idx; m_handle = netlib_connect(server_ip, server_port, imconn_callback, (void*)\u0026amp;g_file_server_conn_map); if (m_handle != NETLIB_INVALID_HANDLE) { g_file_server_conn_map.insert(make_pair(m_handle, this)); } } 在这个函数里面创建连接socket，将该socket加入全局map g_file_server_conn_map中保存，map的key是socket句柄值，值是当前连接对象CFileServConn的指针。注意这里设置了回调函数imconn_callback。我们来看netlib_connect()实际连接的代码：\nnet_handle_t netlib_connect( const char* server_ip, uint16_t\tport, callback_t\tcallback, void*\tcallback_data) { CBaseSocket* pSocket = new CBaseSocket(); if (!pSocket) return NETLIB_INVALID_HANDLE; net_handle_t handle = pSocket-\u0026gt;Connect(server_ip, port, callback, callback_data); if (handle == NETLIB_INVALID_HANDLE) delete pSocket; return handle; } net_handle_t CBaseSocket::Connect(const char* server_ip, uint16_t port, callback_t callback, void* callback_data) { log(\u0026#34;CBaseSocket::Connect, server_ip=%s, port=%d\u0026#34;, server_ip, port); m_remote_ip = server_ip; m_remote_port = port; m_callback = callback; m_callback_data = callback_data; m_socket = socket(AF_INET, SOCK_STREAM, 0); if (m_socket == INVALID_SOCKET) { log(\u0026#34;socket failed, err_code=%d\u0026#34;, _GetErrorCode()); return NETLIB_INVALID_HANDLE; } _SetNonblock(m_socket); _SetNoDelay(m_socket); sockaddr_in serv_addr; _SetAddr(server_ip, port, \u0026amp;serv_addr); int ret = connect(m_socket, (sockaddr*)\u0026amp;serv_addr, sizeof(serv_addr)); if ( (ret == SOCKET_ERROR) \u0026amp;\u0026amp; (!_IsBlock(_GetErrorCode())) ) {\tlog(\u0026#34;connect failed, err_code=%d\u0026#34;, _GetErrorCode()); closesocket(m_socket); return NETLIB_INVALID_HANDLE; } m_state = SOCKET_STATE_CONNECTING; AddBaseSocket(this); CEventDispatch::Instance()-\u0026gt;AddEvent(m_socket, SOCKET_ALL); return (net_handle_t)m_socket; } 注意这里有以下几点：\n将socket设置成非阻塞的。这样如果底层连接函数connect()不能立马完成，connect会立刻返回。\n将socket的状态设置成SOCKET_STATE_CONNECTING。\nAddBaseSocket(this)将该socket加入一个全局map中。\n关注该socket的所有事件（SOCKET_ALL）。\nenum { SOCKET_READ\t= 0x1, SOCKET_WRITE\t= 0x2, SOCKET_EXCEP\t= 0x4, SOCKET_ALL\t= 0x7 }; 因为socket是非阻塞，所以connect可能没连接成功，也会立即返回。那连接成功以后，我们如何得知呢？还记得上一篇文章中介绍的主线程的消息泵吗？TeamTalk每个服务的主线程都有一个这样的消息泵：\nwhile(退出条件) { //1. 遍历定时器队列，检测是否有定时器事件到期，有则执行定时器的回调函数 //2. 遍历其他任务队列，检测是否有其他任务需要执行，有，执行之 //3. 检测socket集合，分离可读、可写和异常事件 //4. 处理socket可读事件 //5. 处理socket可写事件 //6. 处理socket异常事件 } 当socket连接成功以后，该socket立马会变的可写。此时会触发第5步中的可写事件：\nvoid CBaseSocket::OnWrite() { #if ((defined _WIN32) || (defined __APPLE__)) CEventDispatch::Instance()-\u0026gt;RemoveEvent(m_socket, SOCKET_WRITE); #endif if (m_state == SOCKET_STATE_CONNECTING) { int error = 0; socklen_t len = sizeof(error); #ifdef _WIN32 getsockopt(m_socket, SOL_SOCKET, SO_ERROR, (char*)\u0026amp;error, \u0026amp;len); #else getsockopt(m_socket, SOL_SOCKET, SO_ERROR, (void*)\u0026amp;error, \u0026amp;len); #endif if (error) { m_callback(m_callback_data, NETLIB_MSG_CLOSE, (net_handle_t)m_socket, NULL); } else { m_state = SOCKET_STATE_CONNECTED; m_callback(m_callback_data, NETLIB_MSG_CONFIRM, (net_handle_t)m_socket, NULL); } } else { m_callback(m_callback_data, NETLIB_MSG_WRITE, (net_handle_t)m_socket, NULL); } } 由于该socket的状态是SOCKET_STATE_CONNECTING，会走第一个if分支。在不出错的情况下，以参数NETLIB_MSG_CONFIRM调用之前设置的回调函数imconn_callback。\nvoid imconn_callback(void* callback_data, uint8_t msg, uint32_t handle, void* pParam) { NOTUSED_ARG(handle); NOTUSED_ARG(pParam); if (!callback_data) return; ConnMap_t* conn_map = (ConnMap_t*)callback_data; CImConn* pConn = FindImConn(conn_map, handle); if (!pConn) return; //log(\u0026#34;msg=%d, handle=%d \u0026#34;, msg, handle); switch (msg) { case NETLIB_MSG_CONFIRM: pConn-\u0026gt;OnConfirm(); break; case NETLIB_MSG_READ: pConn-\u0026gt;OnRead(); break; case NETLIB_MSG_WRITE: pConn-\u0026gt;OnWrite(); break; case NETLIB_MSG_CLOSE: pConn-\u0026gt;OnClose(); break; default: log(\u0026#34;!!!imconn_callback error msg: %d \u0026#34;, msg); break; } pConn-\u0026gt;ReleaseRef(); } 这次走pConn-\u0026gt;OnConfirm();分支，由于pConn实际是CImConn的子类对象，根据C++多态性，会调用CFileServConn的OnConfirm()函数：\nvoid CFileServConn::OnConfirm() { log(\u0026#34;connect to file server success \u0026#34;); m_bOpen = true; m_connect_time = get_tick_count(); g_file_server_list[m_serv_idx].reconnect_cnt = MIN_RECONNECT_CNT / 2; //连上file_server以后，给file_server发送获取ip地址的数据包 IM::Server::IMFileServerIPReq msg; CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_FILE_SERVER_IP_REQ); SendPdu(\u0026amp;pdu); } 连接上file_server后，msg_server会立即给file_server发一个数据包，以获得file_server的ip地址等信息。\n这就是msg_server作为客户端连接其他服务的流程。与这些服务之间的连接都对应一个连接对象：\nfile_server CFileServConn db_proxy_server CDBServConn login_server CLoginServConn route_server CRouteServConn push_server CPushServConn 而且，和连接file_server一样，msg_server在连接这些服务成功以后，可能会需要将自己的一些状态信息告诉对方：\n连接file_server成功后，给对方发包获取对方的ip地址等信息 连接login_server成功以后,告诉login_server自己的ip地址、端口号和当前登录的用户数量和可容纳的最大用户数量，这样login_server将来对于一个需要登录的用户，会根据不同的msg_server的负载状态来决定用户到底登录哪个msg_server。 void CLoginServConn::OnConfirm() { log(\u0026#34;connect to login server success \u0026#34;); m_bOpen = true; g_login_server_list[m_serv_idx].reconnect_cnt = MIN_RECONNECT_CNT / 2; uint32_t cur_conn_cnt = 0; uint32_t shop_user_cnt = 0; //连接login_server成功以后,告诉login_server自己的ip地址、端口号 //和当前登录的用户数量和可容纳的最大用户数量 list\u0026lt;user_conn_t\u0026gt; user_conn_list; CImUserManager::GetInstance()-\u0026gt;GetUserConnCnt(\u0026amp;user_conn_list, cur_conn_cnt); char hostname[256] = {0}; gethostname(hostname, 256); IM::Server::IMMsgServInfo msg; msg.set_ip1(g_msg_server_ip_addr1); msg.set_ip2(g_msg_server_ip_addr2); msg.set_port(g_msg_server_port); msg.set_max_conn_cnt(g_max_conn_cnt); msg.set_cur_conn_cnt(cur_conn_cnt); msg.set_host_name(hostname); CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_MSG_SERV_INFO); SendPdu(\u0026amp;pdu); } 连接route_server成功以后，给route_server发包告诉当前登录在本msg_server上有哪些用户（用户id、用户状态、用户客户端类型）。这样将来A用户给B发聊天消息，msg_server将该聊天消息转给route_server，route_server就知道用户B在哪个msg_server上了，以便将该聊天消息发给B所在的msg_server。 void CRouteServConn::OnConfirm() { log(\u0026#34;connect to route server success \u0026#34;); m_bOpen = true; m_connect_time = get_tick_count(); g_route_server_list[m_serv_idx].reconnect_cnt = MIN_RECONNECT_CNT / 2; if (g_master_rs_conn == NULL) { update_master_route_serv_conn(); } //连接route_server成功以后，给route_server发包告诉当前登录在本msg_server上有哪些 //用户（用户id、用户状态、用户客户端类型） list\u0026lt;user_stat_t\u0026gt; online_user_list; CImUserManager::GetInstance()-\u0026gt;GetOnlineUserInfo(\u0026amp;online_user_list); IM::Server::IMOnlineUserInfo msg; for (list\u0026lt;user_stat_t\u0026gt;::iterator it = online_user_list.begin(); it != online_user_list.end(); it++) { user_stat_t user_stat = *it; IM::BaseDefine::ServerUserStat* server_user_stat = msg.add_user_stat_list(); server_user_stat-\u0026gt;set_user_id(user_stat.user_id); server_user_stat-\u0026gt;set_status((::IM::BaseDefine::UserStatType)user_stat.status); server_user_stat-\u0026gt;set_client_type((::IM::BaseDefine::ClientType)user_stat.client_type); } CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_ONLINE_USER_INFO); SendPdu(\u0026amp;pdu); } 再来提一下，心跳包机制，和上一篇文章中介绍个与db_proxy_server一样，都是在定时器里面做的，这里不再赘述了，简单地贴出与file_server的心跳包代码吧：\nvoid init_file_serv_conn(serv_info_t* server_list, uint32_t server_count) { g_file_server_list = server_list; g_file_server_count = server_count; serv_init\u0026lt;CFileServConn\u0026gt;(g_file_server_list, g_file_server_count); netlib_register_timer(file_server_conn_timer_callback, NULL, 1000); s_file_handler = CFileHandler::getInstance(); } void file_server_conn_timer_callback(void* callback_data, uint8_t msg, uint32_t handle, void* pParam) { ConnMap_t::iterator it_old; CFileServConn* pConn = NULL; uint64_t cur_time = get_tick_count(); for (ConnMap_t::iterator it = g_file_server_conn_map.begin(); it != g_file_server_conn_map.end(); ) { it_old = it; it++; pConn = (CFileServConn*)it_old-\u0026gt;second; pConn-\u0026gt;OnTimer(cur_time); } // reconnect FileServer serv_check_reconnect\u0026lt;CFileServConn\u0026gt;(g_file_server_list, g_file_server_count); } 在注册的定时器回调函数里面调用CFileServConn::OnTimer函数：\nvoid CFileServConn::OnTimer(uint64_t curr_tick) { if (curr_tick \u0026gt; m_last_send_tick + SERVER_HEARTBEAT_INTERVAL) { IM::Other::IMHeartBeat msg; CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_HEARTBEAT); SendPdu(\u0026amp;pdu); } if (curr_tick \u0026gt; m_last_recv_tick + SERVER_TIMEOUT) { log(\u0026#34;conn to file server timeout \u0026#34;); Close(); } } 接下来的就是每个连接上的业务处理代码了，主消息泵收到数据后触发OnRead函数，然后收取数据解包，然后根据包的命令号处理包，所以每个连接对象根据自己的业务都有一个HandlePdu()函数，例如CFileServConn的：\nvoid CFileServConn::HandlePdu(CImPdu* pPdu) { switch (pPdu-\u0026gt;GetCommandId()) { case CID_OTHER_HEARTBEAT: break; case CID_OTHER_FILE_TRANSFER_RSP: _HandleFileMsgTransRsp(pPdu); break; case CID_OTHER_FILE_SERVER_IP_RSP: _HandleFileServerIPRsp(pPdu); break; default: log(\u0026#34;unknown cmd id=%d \u0026#34;, pPdu-\u0026gt;GetCommandId()); break; } } 当然有些数据包，msg_server直接自己装包应答就可以了。有些必须发到其他服务进行进一步处理，比如登录请求，发给db_proxy_server拿到mysql中校验用户名和密码，db_proxy_server校验完成后，再应答msg_server，msg_server再应答客户端。\n这大概就是msg_server服务的结构和源码了吧。具体业务代码你可以查看每个连接对象的HandlePdu()函数来看具体的流程细节。\n需要指出的是：连接服务器、接受连接、收取数据解包、发送数据这四个模块是一个完整的网路库必须具有的东西。这篇文章和上一篇文章完整地介绍了这四个模块，而TeamTalk的实现手法也是目前主流网络库的通用做法。如果从事服务器开发，必须熟练掌握这里面的具体每个细节。而teamtalk服务器这种分布式架构设计的思想也是非常值得学习和借鉴的。\n","permalink":"https://haokiu.com/blog/27deab1b64f24c839058b60bd3826f79/","summary":"05 服务器端msg_server源码分析 在分析msg_server的源码之前，我们先简单地回顾一下msg_server在整个服务器系统中的位置和作用：\n各个服务程序的作用描述如下：\nLoginServer (C++): 负载均衡服务器，分配一个负载小的MsgServer给客户端使用 MsgServer (C++): 消息服务器，提供客户端大部分信令处理功能，包括私人聊天、群组聊天等 RouteServer (C++): 路由服务器，为登录在不同MsgServer的用户提供消息转发功能 FileServer (C++): 文件服务器，提供客户端之间得文件传输服务，支持在线以及离线文件传输 MsfsServer (C++): 图片存储服务器，提供头像，图片传输中的图片存储服务 DBProxy (C++): 数据库代理服务器，提供mysql以及redis的访问服务，屏蔽其他服务器与mysql与redis的直接交互 HttpMsgServer(C++) :对外接口服务器，提供对外接口功能。（目前只是框架） PushServer(C++): 消息推送服务器，提供IOS系统消息推送。（IOS消息推送必须走apns） 从上面的介绍中，我们可以看出TeamTalk是支持分布式部署的一套聊天服务器程序，通过分布式部署可以实现分流和支持高数量的用户同时在线。msg_server是整个服务体系的核心系统，可以部署多个，不同的用户可以登录不同的msg_server。这套体系有如下几大亮点：\nlogin_server可以根据当前各个msg_server上在线用户数量，来决定一个新用户登录到哪个msg_server，从而实现了负载平衡；\nroute_server可以将登录在不同的msg_server上的用户的聊天消息发给目标用户；\n通过单独的一个数据库操作服务器db_proxy_server，避免了msg_server直接操作数据库，将数据库操作的入口封装起来。\n在前一篇文章《服务器端db_proxy_server源码分析》中，我介绍了每个服务如何接收连接、读取数据并解包、以及组装数据包发包的操作，这篇文章我将介绍作为客户端，一个服务如何连接另外一个服务。这里msg_server在启动时会同时连接db_proxy_server，login_server，file_server，route_server，push_server。在msg_server服务main函数里面有如下初始化调用：\n//连接file_server init_file_serv_conn(file_server_list, file_server_count); //连接db_proxy_server init_db_serv_conn(db_server_list2, db_server_count2, concurrent_db_conn_cnt); //连接login_server init_login_serv_conn(login_server_list, login_server_count, ip_addr1, ip_addr2, listen_port, max_conn_cnt); //连接push_server init_route_serv_conn(route_server_list, route_server_count); //连接push_server init_push_serv_conn(push_server_list, push_server_count); 其中每个连接服务的流程都是一样的。我们这里以第一个连接file_server为例：\nvoid init_file_serv_conn(serv_info_t* server_list, uint32_t server_count) { g_file_server_list = server_list; g_file_server_count = server_count; serv_init\u0026lt;CFileServConn\u0026gt;(g_file_server_list, g_file_server_count); netlib_register_timer(file_server_conn_timer_callback, NULL, 1000); s_file_handler = CFileHandler::getInstance(); } template \u0026lt;class T\u0026gt; void serv_init(serv_info_t* server_list, uint32_t server_count) { for (uint32_t i = 0; i \u0026lt; server_count; i++) { T* pConn = new T(); pConn-\u0026gt;Connect(server_list[i].server_ip.c_str(), server_list[i].server_port, i); server_list[i].","title":"05 服务器端msg_server源码分析"},{"content":"06 服务器端login_server源码分析 login_server从严格意义上来说，是一个登录分流器，所以名字起的有点名不符实。该服务根据已知的msg_server上的在线用户数量来返回告诉一个即将登录的用户登录哪个msg_server比较合适。关于其程序框架的非业务代码我们已经在前面的两篇文章《服务器端db_proxy_server源码分析》和《服务器端msg_server源码分析》中介绍过了。这篇文章主要介绍下其业务代码。\n首先，程序初始化的时候，会初始化如下功能：\n//1. 在8008端口监听客户端连接 //2. 在8100端口上监听msg_server的连接 //3. 在8080端口上监听客户端http连接 其中连接对象CLoginConn代表着login_server与msg_server之间的连接；而CHttpConn代表着与客户端的http连接。我们先来看CLoginConn对象，上一篇文章中也介绍了其业务代码主要在其HandlePdu()函数中，可以看到这路连接主要处理哪些数据包：\nvoid CLoginConn::HandlePdu(CImPdu* pPdu) { switch (pPdu-\u0026gt;GetCommandId()) { case CID_OTHER_HEARTBEAT: break; case CID_OTHER_MSG_SERV_INFO: _HandleMsgServInfo(pPdu); break; case CID_OTHER_USER_CNT_UPDATE: _HandleUserCntUpdate(pPdu); break; case CID_LOGIN_REQ_MSGSERVER: _HandleMsgServRequest(pPdu); break; default: log(\u0026#34;wrong msg, cmd id=%d \u0026#34;, pPdu-\u0026gt;GetCommandId()); break; } } 命令号CID_OTHER_HEARTBEAT是与msg_server的心跳包。上一篇文章《服务器端msg_server源码分析》中介绍过，msg_server连上login_server后会立刻给login_server发一个数据包，该数据包里面含有该msg_server上的用户数量、最大可容纳的用户数量、自己的ip地址和端口号。\nlist\u0026lt;user_conn_t\u0026gt; user_conn_list; CImUserManager::GetInstance()-\u0026gt;GetUserConnCnt(\u0026amp;user_conn_list, cur_conn_cnt); char hostname[256] = {0}; gethostname(hostname, 256); IM::Server::IMMsgServInfo msg; msg.set_ip1(g_msg_server_ip_addr1); msg.set_ip2(g_msg_server_ip_addr2); msg.set_port(g_msg_server_port); msg.set_max_conn_cnt(g_max_conn_cnt); msg.set_cur_conn_cnt(cur_conn_cnt); msg.set_host_name(hostname); CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_MSG_SERV_INFO); SendPdu(\u0026amp;pdu); 命令号是CID_OTHER_MSG_SERV_INFO。我们来看下login_server如何处理这个命令的：\nvoid CLoginConn::_HandleMsgServInfo(CImPdu* pPdu) { msg_serv_info_t* pMsgServInfo = new msg_serv_info_t; IM::Server::IMMsgServInfo msg; msg.ParseFromArray(pPdu-\u0026gt;GetBodyData(), pPdu-\u0026gt;GetBodyLength()); pMsgServInfo-\u0026gt;ip_addr1 = msg.ip1(); pMsgServInfo-\u0026gt;ip_addr2 = msg.ip2(); pMsgServInfo-\u0026gt;port = msg.port(); pMsgServInfo-\u0026gt;max_conn_cnt = msg.max_conn_cnt(); pMsgServInfo-\u0026gt;cur_conn_cnt = msg.cur_conn_cnt(); pMsgServInfo-\u0026gt;hostname = msg.host_name(); g_msg_serv_info.insert(make_pair(m_handle, pMsgServInfo)); g_total_online_user_cnt += pMsgServInfo-\u0026gt;cur_conn_cnt; log(\u0026#34;MsgServInfo, ip_addr1=%s, ip_addr2=%s, port=%d, max_conn_cnt=%d, cur_conn_cnt=%d, \u0026#34;\\ \u0026#34;hostname: %s. \u0026#34;, pMsgServInfo-\u0026gt;ip_addr1.c_str(), pMsgServInfo-\u0026gt;ip_addr2.c_str(), pMsgServInfo-\u0026gt;port,pMsgServInfo-\u0026gt;max_conn_cnt, pMsgServInfo-\u0026gt;cur_conn_cnt, pMsgServInfo-\u0026gt;hostname.c_str()); } 其实所做的工作无非就是记录下的该msg_server上的ip、端口号、在线用户数量和最大可容纳用户数量等信息而已。存在一个全局map里面：\nmap\u0026lt;uint32_t, msg_serv_info_t*\u0026gt; g_msg_serv_info; typedef struct { string\tip_addr1;\t// 电信IP string\tip_addr2;\t// 网通IP uint16_t\tport; uint32_t\tmax_conn_cnt; uint32_t\tcur_conn_cnt; string hostname;\t// 消息服务器的主机名 } msg_serv_info_t; 另外一个命令号CID_OTHER_USER_CNT_UPDATE，是当msg_server上的用户上线或下线时，msg_server给login_server发该类型的命令号，让login_server更新保存的msg_server的上的在线用户数量：\nvoid CLoginConn::_HandleUserCntUpdate(CImPdu* pPdu) { map\u0026lt;uint32_t, msg_serv_info_t*\u0026gt;::iterator it = g_msg_serv_info.find(m_handle); if (it != g_msg_serv_info.end()) { msg_serv_info_t* pMsgServInfo = it-\u0026gt;second; IM::Server::IMUserCntUpdate msg; msg.ParseFromArray(pPdu-\u0026gt;GetBodyData(), pPdu-\u0026gt;GetBodyLength()); uint32_t action = msg.user_action(); if (action == USER_CNT_INC) { pMsgServInfo-\u0026gt;cur_conn_cnt++; g_total_online_user_cnt++; } else { pMsgServInfo-\u0026gt;cur_conn_cnt--; g_total_online_user_cnt--; } log(\u0026#34;%s:%d, cur_cnt=%u, total_cnt=%u \u0026#34;, pMsgServInfo-\u0026gt;hostname.c_str(), pMsgServInfo-\u0026gt;port, pMsgServInfo-\u0026gt;cur_conn_cnt, g_total_online_user_cnt); } } 命令号CID_LOGIN_REQ_MSGSERVER没用到。\n接着说login_server与客户端的http连接处理，这个连接收取数据和解包是直接在CHttpConn的OnRead函数里面处理的：\nvoid CHttpConn::OnRead() { for (;;) { uint32_t free_buf_len = m_in_buf.GetAllocSize() - m_in_buf.GetWriteOffset(); if (free_buf_len \u0026lt; READ_BUF_SIZE + 1) m_in_buf.Extend(READ_BUF_SIZE + 1); int ret = netlib_recv(m_sock_handle, m_in_buf.GetBuffer() + m_in_buf.GetWriteOffset(), READ_BUF_SIZE); if (ret \u0026lt;= 0) break; m_in_buf.IncWriteOffset(ret); m_last_recv_tick = get_tick_count(); } // 每次请求对应一个HTTP连接，所以读完数据后，不用在同一个连接里面准备读取下个请求 char* in_buf = (char*)m_in_buf.GetBuffer(); uint32_t buf_len = m_in_buf.GetWriteOffset(); in_buf[buf_len] = \u0026#39;\\0\u0026#39;; // 如果buf_len 过长可能是受到攻击，则断开连接 // 正常的url最大长度为2048，我们接受的所有数据长度不得大于1K if(buf_len \u0026gt; 1024) { log(\u0026#34;get too much data:%s \u0026#34;, in_buf); Close(); return; } //log(\u0026#34;OnRead, buf_len=%u, conn_handle=%u\\n\u0026#34;, buf_len, m_conn_handle); // for debug m_cHttpParser.ParseHttpContent(in_buf, buf_len); if (m_cHttpParser.IsReadAll()) { string url = m_cHttpParser.GetUrl(); if (strncmp(url.c_str(), \u0026#34;/msg_server\u0026#34;, 11) == 0) { string content = m_cHttpParser.GetBodyContent(); _HandleMsgServRequest(url, content); } else { log(\u0026#34;url unknown, url=%s \u0026#34;, url.c_str()); Close(); } } } 如果用户发送的http请求的地址形式是http://192.168.226.128:8080/msg_server，即路径是/msg_server，则调用_HandleMsgServRequest()函数处理：\nvoid CHttpConn::_HandleMsgServRequest(string\u0026amp; url, string\u0026amp; post_data) { msg_serv_info_t* pMsgServInfo; uint32_t min_user_cnt = (uint32_t)-1; map\u0026lt;uint32_t, msg_serv_info_t*\u0026gt;::iterator it_min_conn = g_msg_serv_info.end(); map\u0026lt;uint32_t, msg_serv_info_t*\u0026gt;::iterator it; if(g_msg_serv_info.size() \u0026lt;= 0) { Json::Value value; value[\u0026#34;code\u0026#34;] = 1; value[\u0026#34;msg\u0026#34;] = \u0026#34;没有msg_server\u0026#34;; string strContent = value.toStyledString(); char* szContent = new char[HTTP_RESPONSE_HTML_MAX]; snprintf(szContent, HTTP_RESPONSE_HTML_MAX, HTTP_RESPONSE_HTML, strContent.length(), strContent.c_str()); Send((void*)szContent, strlen(szContent)); delete [] szContent; return ; } for (it = g_msg_serv_info.begin() ; it != g_msg_serv_info.end(); it++) { pMsgServInfo = it-\u0026gt;second; if ( (pMsgServInfo-\u0026gt;cur_conn_cnt \u0026lt; pMsgServInfo-\u0026gt;max_conn_cnt) \u0026amp;\u0026amp; (pMsgServInfo-\u0026gt;cur_conn_cnt \u0026lt; min_user_cnt)) { it_min_conn = it; min_user_cnt = pMsgServInfo-\u0026gt;cur_conn_cnt; } } if (it_min_conn == g_msg_serv_info.end()) { log(\u0026#34;All TCP MsgServer are full \u0026#34;); Json::Value value; value[\u0026#34;code\u0026#34;] = 2; value[\u0026#34;msg\u0026#34;] = \u0026#34;负载过高\u0026#34;; string strContent = value.toStyledString(); char* szContent = new char[HTTP_RESPONSE_HTML_MAX]; snprintf(szContent, HTTP_RESPONSE_HTML_MAX, HTTP_RESPONSE_HTML, strContent.length(), strContent.c_str()); Send((void*)szContent, strlen(szContent)); delete [] szContent; return; } else { Json::Value value; value[\u0026#34;code\u0026#34;] = 0; value[\u0026#34;msg\u0026#34;] = \u0026#34;\u0026#34;; if(pIpParser-\u0026gt;isTelcome(GetPeerIP())) { value[\u0026#34;priorIP\u0026#34;] = string(it_min_conn-\u0026gt;second-\u0026gt;ip_addr1); value[\u0026#34;backupIP\u0026#34;] = string(it_min_conn-\u0026gt;second-\u0026gt;ip_addr2); value[\u0026#34;msfsPrior\u0026#34;] = strMsfsUrl; value[\u0026#34;msfsBackup\u0026#34;] = strMsfsUrl; } else { value[\u0026#34;priorIP\u0026#34;] = string(it_min_conn-\u0026gt;second-\u0026gt;ip_addr2); value[\u0026#34;backupIP\u0026#34;] = string(it_min_conn-\u0026gt;second-\u0026gt;ip_addr1); value[\u0026#34;msfsPrior\u0026#34;] = strMsfsUrl; value[\u0026#34;msfsBackup\u0026#34;] = strMsfsUrl; } value[\u0026#34;discovery\u0026#34;] = strDiscovery; value[\u0026#34;port\u0026#34;] = int2string(it_min_conn-\u0026gt;second-\u0026gt;port); string strContent = value.toStyledString(); char* szContent = new char[HTTP_RESPONSE_HTML_MAX]; uint32_t nLen = strContent.length(); snprintf(szContent, HTTP_RESPONSE_HTML_MAX, HTTP_RESPONSE_HTML, nLen, strContent.c_str()); Send((void*)szContent, strlen(szContent)); delete [] szContent; return; } } 其实就是根据记录的msg_server的负载情况，返回一个可用的msg_server ip和端口给客户端，这是一个json格式：\n{ \u0026#34;backupIP\u0026#34; : \u0026#34;localhost\u0026#34;, \u0026#34;code\u0026#34; : 0, \u0026#34;discovery\u0026#34; : \u0026#34;http://192.168.226.128\u0026lt;/span\u0026gt;/api/discovery\u0026#34;, \u0026#34;msfsBackup\u0026#34; : \u0026#34;http://127.0.0.1:8700/\u0026#34;, \u0026#34;msfsPrior\u0026#34; : \u0026#34;http://127.0.0.1:8700/\u0026#34;, \u0026#34;msg\u0026#34; : \u0026#34;\u0026#34;, \u0026#34;port\u0026#34; : \u0026#34;8000\u0026#34;, \u0026#34;priorIP\u0026#34; : \u0026#34;localhost\u0026#34; } 里面含有msg_server和聊天图片存放的服务器地址（msfsPrior）字段。这样客户端可以拿着这个地址去登录msg_server和图片服务器了。\n发出去这个json之后会调用OnWriteComplete()函数，这个函数立刻关闭该http连接，也就是说这个与客户端的http连接是短连接：\nvoid CHttpConn::OnWriteComlete() { log(\u0026#34;write complete \u0026#34;); Close(); } login_server就这么多内容了。\n","permalink":"https://haokiu.com/blog/1866caff3acc4baeb8666ea706d7ba7d/","summary":"06 服务器端login_server源码分析 login_server从严格意义上来说，是一个登录分流器，所以名字起的有点名不符实。该服务根据已知的msg_server上的在线用户数量来返回告诉一个即将登录的用户登录哪个msg_server比较合适。关于其程序框架的非业务代码我们已经在前面的两篇文章《服务器端db_proxy_server源码分析》和《服务器端msg_server源码分析》中介绍过了。这篇文章主要介绍下其业务代码。\n首先，程序初始化的时候，会初始化如下功能：\n//1. 在8008端口监听客户端连接 //2. 在8100端口上监听msg_server的连接 //3. 在8080端口上监听客户端http连接 其中连接对象CLoginConn代表着login_server与msg_server之间的连接；而CHttpConn代表着与客户端的http连接。我们先来看CLoginConn对象，上一篇文章中也介绍了其业务代码主要在其HandlePdu()函数中，可以看到这路连接主要处理哪些数据包：\nvoid CLoginConn::HandlePdu(CImPdu* pPdu) { switch (pPdu-\u0026gt;GetCommandId()) { case CID_OTHER_HEARTBEAT: break; case CID_OTHER_MSG_SERV_INFO: _HandleMsgServInfo(pPdu); break; case CID_OTHER_USER_CNT_UPDATE: _HandleUserCntUpdate(pPdu); break; case CID_LOGIN_REQ_MSGSERVER: _HandleMsgServRequest(pPdu); break; default: log(\u0026#34;wrong msg, cmd id=%d \u0026#34;, pPdu-\u0026gt;GetCommandId()); break; } } 命令号CID_OTHER_HEARTBEAT是与msg_server的心跳包。上一篇文章《服务器端msg_server源码分析》中介绍过，msg_server连上login_server后会立刻给login_server发一个数据包，该数据包里面含有该msg_server上的用户数量、最大可容纳的用户数量、自己的ip地址和端口号。\nlist\u0026lt;user_conn_t\u0026gt; user_conn_list; CImUserManager::GetInstance()-\u0026gt;GetUserConnCnt(\u0026amp;user_conn_list, cur_conn_cnt); char hostname[256] = {0}; gethostname(hostname, 256); IM::Server::IMMsgServInfo msg; msg.set_ip1(g_msg_server_ip_addr1); msg.set_ip2(g_msg_server_ip_addr2); msg.set_port(g_msg_server_port); msg.set_max_conn_cnt(g_max_conn_cnt); msg.set_cur_conn_cnt(cur_conn_cnt); msg.set_host_name(hostname); CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_MSG_SERV_INFO); SendPdu(\u0026amp;pdu); 命令号是CID_OTHER_MSG_SERV_INFO。我们来看下login_server如何处理这个命令的：\nvoid CLoginConn::_HandleMsgServInfo(CImPdu* pPdu) { msg_serv_info_t* pMsgServInfo = new msg_serv_info_t; IM::Server::IMMsgServInfo msg; msg.ParseFromArray(pPdu-\u0026gt;GetBodyData(), pPdu-\u0026gt;GetBodyLength()); pMsgServInfo-\u0026gt;ip_addr1 = msg.ip1(); pMsgServInfo-\u0026gt;ip_addr2 = msg.ip2(); pMsgServInfo-\u0026gt;port = msg.port(); pMsgServInfo-\u0026gt;max_conn_cnt = msg.max_conn_cnt(); pMsgServInfo-\u0026gt;cur_conn_cnt = msg.cur_conn_cnt(); pMsgServInfo-\u0026gt;hostname = msg.host_name(); g_msg_serv_info.","title":"06 服务器端login_server源码分析"},{"content":"07 服务器端msfs源码分析 这篇文章是对TeamTalk服务程序msfs的源码和架构设计分析。msfs作用是用来接受teamtalk聊天中产生的聊天图片的上传和下载。还是老规矩，把该服务在整个架构中的位置图贴一下吧。\n可以看到，msfs仅被客户端连接，客户端以http的方式来上传和下载聊天图片。\n可能很多同学对http协议不是很熟悉，或者说一知半解。这里大致介绍一下http协议，http协议其实也是一种应用层协议，建立在tcp/ip层之上，其由包头和包体两部分组成（不一定要有包体），看个例子：\n比如当我们用浏览器请求一个网址http://www.hootina.org/index.php，实际是浏览器给特定的服务器发送如下数据包，包头部分如下：\nGET /index.php HTTP/1.1\\r\\n Host: www.hootina.org\\r\\n Connection: keep-alive\\r\\n Cache-Control: max-age=0\\r\\n Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,/;q=0.8\\r\\n User-Agent: Mozilla/5.0\\r\\n \\r\\n 这个包没有包体。\n从上面我们可以看出一个http协议大致格式可以描述如下：\nGET或Post请求方法 请求的资源路径 http协议版本号\\r\\n 字段名1：值1\\r\\n 字段名2：值2\\r\\n 字段名3：值3\\r\\n 字段名4：值4\\r\\n 字段名5：值5\\r\\n 字段名6：值6\\r\\n \\r\\n 也就是是http协议的头部是一行一行的，每一行以\\r\\n表示该行结束，最后多出一个空行以\\r\\n结束表示头部的结束。接下来就是包体的大小了（如果有的话，上文的例子没有包体）。一般get方法会将参数放在请求的资源路径后面，像这样\nhttp://wwww.hootina.org/index.php?变量1=值1\u0026amp;变量2=值2\u0026amp;变量3=值3\u0026amp;变量4=值4\n网址后面的问号表示参数开始，每一个参数与参数之间用\u0026amp;隔开\n还有一种post的请求方法，这种数据就是将数据放在包体里面了，例如：\nPOST /otn/login/loginAysnSuggest HTTP/1.1\\r\\n Host: kyfw.12306.cn\\r\\n Connection: keep-alive\\r\\n Content-Length: 96\\r\\n Accept: */*\\r\\n Origin: https://kyfw.12306.cn\\r\\n X-Requested-With: XMLHttpRequest\\r\\n User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.75\\r\\n Content-Type: application/x-www-form-urlencoded; charset=UTF-8\\r\\n Referer: https://kyfw.12306.cn/otn/login/init\\r\\n Accept-Encoding: gzip, deflate, br\\r\\n Accept-Language: zh-CN,zh;q=0.8\\r\\n \\r\\n loginUserDTO.user_name=balloonwj%40qq.com\u0026amp;userDTO.password=xxxxgjqf\u0026amp;randCode=184%2C55%2C37%2C117 上述报文中loginUserDTO.user_name=balloonwj%40qq.com\u0026amp;userDTO.password=2032_scsgjqf\u0026amp;randCode=184%2C55%2C37%2C117 其实包体内容，这个包是我的一个12306买票软件发给12306服务器的报文。这里拿来做个例子。\n因为对方收到http报文的时候，如果包体有内容，那么必须告诉对方包体有多大。这个最常用的就是通过包头的Content-Length字段来指定大小。上面的例子中Content-Length等于96，正好就是字符串 loginUserDTO.user_name=balloonwj%40qq.com\u0026amp;userDTO.password=xxxxgjqf\u0026amp;randCode=184%2C55%2C37%2C117 的长度，也就是包体的大小。\n还有一种叫做http chunk的编码技术，通过对http包内容进行分块传输。这里就不介绍了（如果你感兴趣，可以私聊我）。\n常见的对http协议有如下几个误解：\nhtml文档的头就是http的头 这种认识是错误的，html文档的头部也是http数据包的包体的一部分。正确的http头是长的像上文介绍的那种。\n关于http头Connection:keep-alive字段 一端指定了这个字段后，发http包给另外一端。这个选项只是一种建议性的选项，对端不一定必须采纳，对方也可能在实际实现时，将http连接设置为短连接，即不采纳这个字段的建议。\n每个字段都是必须的吗？ 不是，大多数字段都不是必须的。但是特定的情况下，某些字段是必须的。比如，通过post发送的数据，就必须设置Content-Length。不然，收包的一端如何知道包体多大。又比如如果你的数据采取了gzip压缩格式，你就必须指定Accept-Encoding: gzip，然对方如何解包你的数据。\n好了，http协议就暂且介绍这么多，下面回到正题上来说msfs的源码。\nmsfs在main函数里面做了如下初始化工作，伪码如下：\n//1. 建立一个两个任务队列，分别处理http get请求和post请求 //2. 创建名称为000～255的文件夹，每个文件夹里面会有000～255个子目录，这些目录用于存放聊天图片 //3. 在8700端口上监听客户端连接 //4. 启动程序消息泵 第1点，建立任务队列我们前面系列的文章已经介绍过了。\n第2点，代码如下：\ng_fileManager = FileManager::getInstance(listen_ip, base_dir, fileCnt, filesPerDir); int ret = g_fileManager-\u0026gt;initDir(); int FileManager::initDir() { bool isExist = File::isExist(m_disk); if (!isExist) { u64 ret = File::mkdirNoRecursion(m_disk); if (ret) { log(\u0026#34;The dir[%s] set error for code[%d], \\ its parent dir may no exists\u0026#34;, m_disk, ret); return -1; } } //255 X 255 char first[10] = {0}; char second[10] = {0}; for (int i = 0; i \u0026lt;= FIRST_DIR_MAX; i++) { snprintf(first, 5, \u0026#34;%03d\u0026#34;, i); string tmp = string(m_disk) + \u0026#34;/\u0026#34; + string(first); int code = File::mkdirNoRecursion(tmp.c_str()); if (code \u0026amp;\u0026amp; (errno != EEXIST)) { log(\u0026#34;Create dir[%s] error[%d]\u0026#34;, tmp.c_str(), errno); return -1; } for (int j = 0; j \u0026lt;= SECOND_DIR_MAX; j++) { snprintf(second, 5, \u0026#34;%03d\u0026#34;, j); string tmp2 = tmp + \u0026#34;/\u0026#34; + string(second); code = File::mkdirNoRecursion(tmp2.c_str()); if (code \u0026amp;\u0026amp; (errno != EEXIST)) { log(\u0026#34;Create dir[%s] error[%d]\u0026#34;, tmp2.c_str(), errno); return -1; } memset(second, 0x0, 10); } memset(first, 0x0, 10); } return 0; } 下面，我们直接来看如何处理客户端的http请求，当连接对象CHttpConn收到客户端数据后，调用OnRead方法：\nvoid CHttpConn::OnRead() { for (;;) { uint32_t free_buf_len = m_in_buf.GetAllocSize() - m_in_buf.GetWriteOffset(); if (free_buf_len \u0026lt; READ_BUF_SIZE + 1) m_in_buf.Extend(READ_BUF_SIZE + 1); int ret = netlib_recv(m_sock_handle, m_in_buf.GetBuffer() + m_in_buf.GetWriteOffset(), READ_BUF_SIZE); if (ret \u0026lt;= 0) break; m_in_buf.IncWriteOffset(ret); m_last_recv_tick = get_tick_count(); } // 每次请求对应一个HTTP连接，所以读完数据后，不用在同一个连接里面准备读取下个请求 char* in_buf = (char*) m_in_buf.GetBuffer(); uint32_t buf_len = m_in_buf.GetWriteOffset(); in_buf[buf_len] = \u0026#39;\\0\u0026#39;; //log(\u0026#34;OnRead, buf_len=%u, conn_handle=%u\u0026#34;, buf_len, m_conn_handle); // for debug m_HttpParser.ParseHttpContent(in_buf, buf_len); if (m_HttpParser.IsReadAll()) { string strUrl = m_HttpParser.GetUrl(); log(\u0026#34;IP:%s access:%s\u0026#34;, m_peer_ip.c_str(), strUrl.c_str()); if (strUrl.find(\u0026#34;..\u0026#34;) != strUrl.npos) { Close(); return; } m_access_host = m_HttpParser.GetHost(); if (m_HttpParser.GetContentLen() \u0026gt; HTTP_UPLOAD_MAX) { // file is too big log(\u0026#34;content is too big\u0026#34;); char url[128]; snprintf(url, sizeof(url), \u0026#34;{\\\u0026#34;error_code\\\u0026#34;:1,\\\u0026#34;error_msg\\\u0026#34;: \\\u0026#34;上传文件过大\\\u0026#34;,\\\u0026#34;url\\\u0026#34;:\\\u0026#34;\\\u0026#34;}\u0026#34;); log(\u0026#34;%s\u0026#34;,url); uint32_t content_length = strlen(url); char pContent[1024]; snprintf(pContent, sizeof(pContent), HTTP_RESPONSE_HTML, content_length,url); Send(pContent, strlen(pContent)); return; } int nContentLen = m_HttpParser.GetContentLen(); char* pContent = NULL; if(nContentLen != 0) { try { pContent =new char[nContentLen]; memcpy(pContent, m_HttpParser.GetBodyContent(), nContentLen); } catch(...) { log(\u0026#34;not enough memory\u0026#34;); char szResponse[HTTP_RESPONSE_500_LEN + 1]; snprintf(szResponse, HTTP_RESPONSE_500_LEN, \u0026#34;%s\u0026#34;, HTTP_RESPONSE_500); Send(szResponse, HTTP_RESPONSE_500_LEN); return; } } Request_t request; request.conn_handle = m_conn_handle; request.method = m_HttpParser.GetMethod();; request.nContentLen = nContentLen; request.pContent = pContent; request.strAccessHost = m_HttpParser.GetHost(); request.strContentType = m_HttpParser.GetContentType(); request.strUrl = m_HttpParser.GetUrl() + 1; CHttpTask* pTask = new CHttpTask(request); if(HTTP_GET == m_HttpParser.GetMethod()) { g_GetThreadPool.AddTask(pTask); } else { g_PostThreadPool.AddTask(pTask); } } } 该方法先收取数据，接着解包，然后根据客户端发送的http请求到底是get还是post方法，分别往对应的get和post任务队列中丢一个任务CHttpTask。任务队列开始处理这个任务。我们以get请求的任务为例（Post请求与此类似）：\nvoid CHttpTask::run() { if(HTTP_GET == m_nMethod) { OnDownload(); } else if(HTTP_POST == m_nMethod) { OnUpload(); } else { char* pContent = new char[strlen(HTTP_RESPONSE_403)]; snprintf(pContent, strlen(HTTP_RESPONSE_403), HTTP_RESPONSE_403); CHttpConn::AddResponsePdu(m_ConnHandle, pContent, strlen(pContent)); } if(m_pContent != NULL) { delete [] m_pContent; m_pContent = NULL; } } 处理任务时，根据请求类型判断到底是客户端下载图片还是上传图片，如果是下载图片则从本机缓存的图片信息中找到该图片，并读取该图片数据，因为是聊天图片，所以一般不会很大，所以这里都是一次性读取图片字节内容，然后发出去。\nvoid CHttpTask::OnDownload() { uint32_t nFileSize = 0; int32_t nTmpSize = 0; string strPath; if(g_fileManager-\u0026gt;getAbsPathByUrl(m_strUrl, strPath ) == 0) { nTmpSize = File::getFileSize((char*)strPath.c_str()); if(nTmpSize != -1) { char szResponseHeader[1024]; size_t nPos = strPath.find_last_of(\u0026#34;.\u0026#34;); string strType = strPath.substr(nPos + 1, strPath.length() - nPos); if(strType == \u0026#34;jpg\u0026#34; || strType == \u0026#34;JPG\u0026#34; || strType == \u0026#34;jpeg\u0026#34; || strType == \u0026#34;JPEG\u0026#34; || strType == \u0026#34;png\u0026#34; || strType == \u0026#34;PNG\u0026#34; || strType == \u0026#34;gif\u0026#34; || strType == \u0026#34;GIF\u0026#34;) { snprintf(szResponseHeader, sizeof(szResponseHeader), HTTP_RESPONSE_IMAGE, nTmpSize, strType.c_str()); } else { snprintf(szResponseHeader,sizeof(szResponseHeader), HTTP_RESPONSE_EXTEND, nTmpSize); } int nLen = strlen(szResponseHeader); char* pContent = new char[nLen + nTmpSize]; memcpy(pContent, szResponseHeader, nLen); g_fileManager-\u0026gt;downloadFileByUrl((char*)m_strUrl.c_str(), pContent + nLen, \u0026amp;nFileSize); int nTotalLen = nLen + nFileSize; CHttpConn::AddResponsePdu(m_ConnHandle, pContent, nTotalLen); } else { int nTotalLen = strlen(HTTP_RESPONSE_404); char* pContent = new char[nTotalLen]; snprintf(pContent, nTotalLen, HTTP_RESPONSE_404); CHttpConn::AddResponsePdu(m_ConnHandle, pContent, nTotalLen); log(\u0026#34;File size is invalied\\n\u0026#34;); } } else { int nTotalLen = strlen(HTTP_RESPONSE_500); char* pContent = new char[nTotalLen]; snprintf(pContent, nTotalLen, HTTP_RESPONSE_500); CHttpConn::AddResponsePdu(m_ConnHandle, pContent, nTotalLen); } } 这里需要说明一下的就是FileManager::getAbsPathByUrl在获取本地文件时，用了一个锁，该锁是为了防止同一个进程同时读取同一个文件，这个锁是“建议性”的，必须自己主动检测有没有上锁：\nint FileManager::getAbsPathByUrl(const string \u0026amp;url, string \u0026amp;path) { string relate; if (getRelatePathByUrl(url, relate)) { log(\u0026#34;Get path from url[%s] error\u0026#34;, url.c_str()); return -1; } path = string(m_disk) + relate; return 0; } u64 File::open(bool directIo) { assert(!m_opened); int flags = O_RDWR; #ifdef __linux__\tm_file = open64(m_path, flags); #elif defined(__FREEBSD__) || defined(__APPLE__) m_file = ::open(m_path, flags); #endif\tif(-1 == m_file) { return errno; } #ifdef __LINUX__ if (directIo) if (-1 == fcntl(m_file, F_SETFL, O_DIRECT)) return errno; #endif\tstruct flock lock; lock.l_type = F_WRLCK; lock.l_start = 0; lock.l_whence = SEEK_SET; lock.l_len = 0; if(fcntl(m_file, F_SETLK, \u0026amp;lock) \u0026lt; 0) { ::close(m_file); return errno; } m_opened = true; u64 size = 0; u64 code = getSize(\u0026amp;size); if (code) { close(); return code; } m_size = size; m_directIo = directIo; return 0; } 注意上面的fcntl函数设置的flock锁。这个是linux特有的，应该学习掌握。\n图片上传的逻辑和下载逻辑大致类似，这里就不再分析了。\n当然，发送图片数据的包和前面的发送逻辑也是一样的，在OnWrite里面发送。发送完毕后会调用CHttpConn::OnSendComplete，在这个函数里面关闭http连接。这也就是说msfs与客户端的http连接也是短连接。\nvoid CHttpConn::OnSendComplete() { Close(); } 关于msfs也就这么多内容了。不知道你有没有发现，在搞清楚db_proxy_server和msg_server之后，每个程序框架其实都是一样的，只不过业务逻辑稍微有一点差别。后面介绍的file_server和route_server都是一样的。我们也着重分析其业务代码。\n好了，msfs服务就这么多啦。\n","permalink":"https://haokiu.com/blog/0055f7fa607b4b2180cd0eb3924eff5c/","summary":"07 服务器端msfs源码分析 这篇文章是对TeamTalk服务程序msfs的源码和架构设计分析。msfs作用是用来接受teamtalk聊天中产生的聊天图片的上传和下载。还是老规矩，把该服务在整个架构中的位置图贴一下吧。\n可以看到，msfs仅被客户端连接，客户端以http的方式来上传和下载聊天图片。\n可能很多同学对http协议不是很熟悉，或者说一知半解。这里大致介绍一下http协议，http协议其实也是一种应用层协议，建立在tcp/ip层之上，其由包头和包体两部分组成（不一定要有包体），看个例子：\n比如当我们用浏览器请求一个网址http://www.hootina.org/index.php，实际是浏览器给特定的服务器发送如下数据包，包头部分如下：\nGET /index.php HTTP/1.1\\r\\n Host: www.hootina.org\\r\\n Connection: keep-alive\\r\\n Cache-Control: max-age=0\\r\\n Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,/;q=0.8\\r\\n User-Agent: Mozilla/5.0\\r\\n \\r\\n 这个包没有包体。\n从上面我们可以看出一个http协议大致格式可以描述如下：\nGET或Post请求方法 请求的资源路径 http协议版本号\\r\\n 字段名1：值1\\r\\n 字段名2：值2\\r\\n 字段名3：值3\\r\\n 字段名4：值4\\r\\n 字段名5：值5\\r\\n 字段名6：值6\\r\\n \\r\\n 也就是是http协议的头部是一行一行的，每一行以\\r\\n表示该行结束，最后多出一个空行以\\r\\n结束表示头部的结束。接下来就是包体的大小了（如果有的话，上文的例子没有包体）。一般get方法会将参数放在请求的资源路径后面，像这样\nhttp://wwww.hootina.org/index.php?变量1=值1\u0026amp;变量2=值2\u0026amp;变量3=值3\u0026amp;变量4=值4\n网址后面的问号表示参数开始，每一个参数与参数之间用\u0026amp;隔开\n还有一种post的请求方法，这种数据就是将数据放在包体里面了，例如：\nPOST /otn/login/loginAysnSuggest HTTP/1.1\\r\\n Host: kyfw.12306.cn\\r\\n Connection: keep-alive\\r\\n Content-Length: 96\\r\\n Accept: */*\\r\\n Origin: https://kyfw.12306.cn\\r\\n X-Requested-With: XMLHttpRequest\\r\\n User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.75\\r\\n Content-Type: application/x-www-form-urlencoded; charset=UTF-8\\r\\n Referer: https://kyfw.12306.cn/otn/login/init\\r\\n Accept-Encoding: gzip, deflate, br\\r\\n Accept-Language: zh-CN,zh;q=0.8\\r\\n \\r\\n loginUserDTO.user_name=balloonwj%40qq.com\u0026amp;userDTO.password=xxxxgjqf\u0026amp;randCode=184%2C55%2C37%2C117 上述报文中loginUserDTO.user_name=balloonwj%40qq.com\u0026amp;userDTO.password=2032_scsgjqf\u0026amp;randCode=184%2C55%2C37%2C117 其实包体内容，这个包是我的一个12306买票软件发给12306服务器的报文。这里拿来做个例子。\n因为对方收到http报文的时候，如果包体有内容，那么必须告诉对方包体有多大。这个最常用的就是通过包头的Content-Length字段来指定大小。上面的例子中Content-Length等于96，正好就是字符串 loginUserDTO.user_name=balloonwj%40qq.com\u0026amp;userDTO.password=xxxxgjqf\u0026amp;randCode=184%2C55%2C37%2C117 的长度，也就是包体的大小。\n还有一种叫做http chunk的编码技术，通过对http包内容进行分块传输。这里就不介绍了（如果你感兴趣，可以私聊我）。\n常见的对http协议有如下几个误解：\nhtml文档的头就是http的头 这种认识是错误的，html文档的头部也是http数据包的包体的一部分。正确的http头是长的像上文介绍的那种。\n关于http头Connection:keep-alive字段 一端指定了这个字段后，发http包给另外一端。这个选项只是一种建议性的选项，对端不一定必须采纳，对方也可能在实际实现时，将http连接设置为短连接，即不采纳这个字段的建议。\n每个字段都是必须的吗？ 不是，大多数字段都不是必须的。但是特定的情况下，某些字段是必须的。比如，通过post发送的数据，就必须设置Content-Length。不然，收包的一端如何知道包体多大。又比如如果你的数据采取了gzip压缩格式，你就必须指定Accept-Encoding: gzip，然对方如何解包你的数据。\n好了，http协议就暂且介绍这么多，下面回到正题上来说msfs的源码。\nmsfs在main函数里面做了如下初始化工作，伪码如下：\n//1. 建立一个两个任务队列，分别处理http get请求和post请求 //2. 创建名称为000～255的文件夹，每个文件夹里面会有000～255个子目录，这些目录用于存放聊天图片 //3. 在8700端口上监听客户端连接 //4. 启动程序消息泵 第1点，建立任务队列我们前面系列的文章已经介绍过了。","title":"07 服务器端msfs源码分析"},{"content":"08 服务器端file_server源码分析 这篇文章我们来介绍file_server服务的功能和源码实现。TeamTalk支持离线在线文件和离线文件两种传送文件的方式。单纯地研究file_server的程序结构没多大意义，因为其程序结构和其他几个服务结构基本上一模一样，前面几篇文章已经介绍过了。 我们研究teamtalk的file_server是为了学习和借鉴teamtalk的文件传输功能实现思路，以内化为自己的知识，并加以应用。\n所以这篇文章，我们将pc客户端的文件传输功能、msg_server转发消息、file_server处理文件数据三个方面结合起来一起介绍。\n下面开始啦。\n一、连接状况介绍\nfileserver开始并不是和客户端连接的，客户端是按需连接file_server的。但是file_server与msg_server却是长连接。先启动file_server，再启动msg_server。msg_server初始化的时候，会去尝试连接file_server的8601端口。连接成功以后，会给file_server发送一个发包询问file_server侦听客户端连接的ip和端口号信息：\nvoid CFileServConn::OnConfirm() { log(\u0026#34;connect to file server success \u0026#34;); m_bOpen = true; m_connect_time = get_tick_count(); g_file_server_list[m_serv_idx].reconnect_cnt = MIN_RECONNECT_CNT / 2; //连上file_server以后，给file_server发送获取ip地址的数据包 IM::Server::IMFileServerIPReq msg; CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_FILE_SERVER_IP_REQ); SendPdu(\u0026amp;pdu); } file_server收到该数据包后，将自己的侦听客户端连接的ip地址和端口号发包告诉msg_server：\nvoid FileMsgServerConn::_HandleGetServerAddressReq(CImPdu* pPdu) { IM::Server::IMFileServerIPRsp msg; const std::list\u0026lt;IM::BaseDefine::IpAddr\u0026gt;\u0026amp; addrs = ConfigUtil::GetInstance()-\u0026gt;GetAddressList(); for (std::list\u0026lt;IM::BaseDefine::IpAddr\u0026gt;::const_iterator it=addrs.begin(); it!=addrs.end(); ++it) { IM::BaseDefine::IpAddr* addr = msg.add_ip_addr_list(); *addr = *it; log(\u0026#34;Upload file_client_conn addr info, ip=%s, port=%d\u0026#34;, addr-\u0026gt;ip().c_str(), addr-\u0026gt;port()); } SendMessageLite(this, SID_OTHER, CID_OTHER_FILE_SERVER_IP_RSP, pPdu-\u0026gt;GetSeqNum(), \u0026amp;msg); } 得到的信息是file_server侦听的ip地址和端口号，默认配置的端口号是8600。也就是说file_server的8600用于客户端连接，8601端口用于msg_server连接。这样，客户端需要传输文件（注意：不是聊天图片，聊天图片使用另外一个服务msfs进行传输），会先告诉msg_server它需要进行文件传输，msg_server收到消息后告诉客户端，你连file_server来传输文件吧，并把file_server的地址和端口号告诉客户端。客户端这个时候连接file_server进行文件传输。我们来具体看一看这个流程的细节信息：\n客户端发包给msg_server说要进行文件发送 然后选择一个文件：\npc客户端发送文件逻辑：\n//pc客户端代码(Modules工程SessionLayout.cpp) void SessionLayout::Notify(TNotifyUI\u0026amp; msg) { ... //省略无关代码 else if (msg.pSender == m_pBtnsendfile) //文件传输 { module::UserInfoEntity userInfo; if (!module::getUserListModule()-\u0026gt;getUserInfoBySId(m_sId, userInfo)) { LOG__(ERR, _T(\u0026#34;SendFile can\u0026#39;t find the sid\u0026#34;)); return; } CFileDialog\tfileDlg(TRUE, NULL, NULL, OFN_HIDEREADONLY | OFN_FILEMUSTEXIST , _T(\u0026#34;文件|*.*||\u0026#34;), AfxGetMainWnd()); fileDlg.m_ofn.Flags |= OFN_NOCHANGEDIR; fileDlg.DoModal(); CString sPathName; POSITION nPos = fileDlg.GetStartPosition(); if (nPos != NULL) { sPathName = fileDlg.GetNextPathName(nPos); } if (sPathName.IsEmpty()) return; module::getFileTransferModule()-\u0026gt;sendFile(sPathName, m_sId, userInfo.isOnlne()); } ... //省略无关代码 } sPathName是文件的全饰路径；m_sId是收取文件的用户id，userInfo.isOnlne()判断m_sId代表的用户是否在线，以此来决定这次文件传输是在线文件还是离线文件模式。\nBOOL FileTransferModule_Impl::sendFile(IN const CString\u0026amp; sFilePath, IN const std::string\u0026amp; sSendToSID,IN BOOL bOnlineMode) { if (TransferFileEntityManager::getInstance()-\u0026gt;checkIfIsSending(sFilePath)) { return FALSE; } TransferFileEntity fileEntity; //获取文件大小 struct __stat64 buffer; _wstat64(sFilePath, \u0026amp;buffer); fileEntity.nFileSize = (UInt32)buffer.st_size; if (0 != fileEntity.nFileSize) { CString strFileName = sFilePath; strFileName.Replace(_T(\u0026#34;\\\\\u0026#34;), _T(\u0026#34;/\u0026#34;));//mac上对于路径字符“\\”需要做特殊处理，windows上则可以识别 fileEntity.sFileName = util::cStringToString(strFileName); fileEntity.sFromID = module::getSysConfigModule()-\u0026gt;userID(); fileEntity.sToID = sSendToSID; uint32_t transMode = 0; transMode = bOnlineMode ? IM::BaseDefine::TransferFileType::FILE_TYPE_ONLINE : IM::BaseDefine::TransferFileType::FILE_TYPE_OFFLINE; LOG__(DEBG,_T(\u0026#34;FileTransferSevice_Impl::sendFile sTaskID = %s\u0026#34;), util::stringToCString(fileEntity.sTaskID)); imcore::IMLibCoreStartOperationWithLambda( [=]() { IM::File::IMFileReq imFileReq; LOG__(APP, _T(\u0026#34;imFileReq,name=%s,size=%d,toId=%s\u0026#34;),util::stringToCString(fileEntity.sFileName) ,fileEntity.nFileSize,util::stringToCString(fileEntity.sToID)); imFileReq.set_from_user_id(util::stringToInt32(fileEntity.sFromID)); imFileReq.set_to_user_id(util::stringToInt32(fileEntity.sToID)); imFileReq.set_file_name(fileEntity.sFileName); imFileReq.set_file_size(fileEntity.nFileSize); imFileReq.set_trans_mode(static_cast\u0026lt;IM::BaseDefine::TransferFileType\u0026gt;(transMode)); module::getTcpClientModule()-\u0026gt;sendPacket(IM::BaseDefine::ServiceID::SID_FILE , IM::BaseDefine::FileCmdID::CID_FILE_REQUEST , \u0026amp;imFileReq); }); return TRUE; } LOG__(ERR, _T(\u0026#34;fileEntity FileSize error,size = %d\u0026#34;), fileEntity.nFileSize); return FALSE; } 上面代码中组装的包信息中含有要传输的文件路径、文件大小、发送人id、接收方id、文件传输模式（在线还是离线），包的命令号是IM::BaseDefine::FileCmdID::CID_FILE_REQUEST。这个包发给msg_server以后，msg_server应答：\nvoid CMsgConn::HandlePdu(CImPdu* pPdu) { ... //省略无关代码 case CID_FILE_REQUEST: s_file_handler-\u0026gt;HandleClientFileRequest(this, pPdu); break; ... //省略无关代码 } void CFileHandler::HandleClientFileRequest(CMsgConn* pMsgConn, CImPdu* pPdu) { IM::File::IMFileReq msg; CHECK_PB_PARSE_MSG(msg.ParseFromArray(pPdu-\u0026gt;GetBodyData(), pPdu-\u0026gt;GetBodyLength())); uint32_t from_id = pMsgConn-\u0026gt;GetUserId(); uint32_t to_id = msg.to_user_id(); string file_name = msg.file_name(); uint32_t file_size = msg.file_size(); uint32_t trans_mode = msg.trans_mode(); log(\u0026#34;HandleClientFileRequest, %u-\u0026gt;%u, fileName: %s, trans_mode: %u.\u0026#34;, from_id, to_id, file_name.c_str(), trans_mode); CDbAttachData attach(ATTACH_TYPE_HANDLE, pMsgConn-\u0026gt;GetHandle()); CFileServConn* pFileConn = get_random_file_serv_conn(); if (pFileConn) { IM::Server::IMFileTransferReq msg2; msg2.set_from_user_id(from_id); msg2.set_to_user_id(to_id); msg2.set_file_name(file_name); msg2.set_file_size(file_size); msg2.set_trans_mode((IM::BaseDefine::TransferFileType)trans_mode); msg2.set_attach_data(attach.GetBuffer(), attach.GetLength()); CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg2); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_FILE_TRANSFER_REQ); pdu.SetSeqNum(pPdu-\u0026gt;GetSeqNum()); if (IM::BaseDefine::FILE_TYPE_OFFLINE == trans_mode) { pFileConn-\u0026gt;SendPdu(\u0026amp;pdu); } else //IM::BaseDefine::FILE_TYPE_ONLINE { CImUser* pUser = CImUserManager::GetInstance()-\u0026gt;GetImUserById(to_id); if (pUser \u0026amp;\u0026amp; pUser-\u0026gt;GetPCLoginStatus())//已有对应的账号pc登录状态 { pFileConn-\u0026gt;SendPdu(\u0026amp;pdu); } else//无对应用户的pc登录状态,向route_server查询状态 { //no pc_client in this msg_server, check it from route_server CPduAttachData attach_data(ATTACH_TYPE_HANDLE_AND_PDU_FOR_FILE, pMsgConn-\u0026gt;GetHandle(), pdu.GetBodyLength(), pdu.GetBodyData()); IM::Buddy::IMUsersStatReq msg3; msg3.set_user_id(from_id); msg3.add_user_id_list(to_id); msg3.set_attach_data(attach_data.GetBuffer(), attach_data.GetLength()); CImPdu pdu2; pdu2.SetPBMsg(\u0026amp;msg3); pdu2.SetServiceId(SID_BUDDY_LIST); pdu2.SetCommandId(CID_BUDDY_LIST_USERS_STATUS_REQUEST); pdu2.SetSeqNum(pPdu-\u0026gt;GetSeqNum()); CRouteServConn* route_conn = get_route_serv_conn(); if (route_conn) { route_conn-\u0026gt;SendPdu(\u0026amp;pdu2); } } } } else { log(\u0026#34;HandleClientFileRequest, no file server. \u0026#34;); IM::File::IMFileRsp msg2; msg2.set_result_code(1); msg2.set_from_user_id(from_id); msg2.set_to_user_id(to_id); msg2.set_file_name(file_name); msg2.set_task_id(\u0026#34;\u0026#34;); msg2.set_trans_mode((IM::BaseDefine::TransferFileType)trans_mode); CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg2); pdu.SetServiceId(SID_FILE); pdu.SetCommandId(CID_FILE_RESPONSE); pdu.SetSeqNum(pPdu-\u0026gt;GetSeqNum()); pMsgConn-\u0026gt;SendPdu(\u0026amp;pdu); } } 这段代码，很有讲究，msg_server会检测file_server是否已经启动，如果没有启动，则直接发包告诉客户端，file_server不存在。另外，如果该文件传输模式是在线文件，会判断接收文件的用户是否和发送用户在同一台msg_server上。不在的话，则给route_server发送消息，查找该用户所在的msg_server（这个不具体介绍了，后面分析route_server会专门介绍的）。否则，会将文件发送请求转发给file_server，包的命令号是CID_OTHER_FILE_TRANSFER_REQ。file_server收到该请求后，处理如下：\nvoid FileMsgServerConn::HandlePdu(CImPdu* pdu) { ... //省略无关代码 case CID_OTHER_FILE_TRANSFER_REQ: _HandleMsgFileTransferReq(pdu); break ; ... //省略无关代码 } void FileMsgServerConn::_HandleMsgFileTransferReq(CImPdu* pdu) { IM::Server::IMFileTransferReq transfer_req; CHECK_PB_PARSE_MSG(transfer_req.ParseFromArray(pdu-\u0026gt;GetBodyData(), pdu-\u0026gt;GetBodyLength())); uint32_t from_id = transfer_req.from_user_id(); uint32_t to_id = transfer_req.to_user_id(); IM::Server::IMFileTransferRsp transfer_rsp; transfer_rsp.set_result_code(1); transfer_rsp.set_from_user_id(from_id); transfer_rsp.set_to_user_id(to_id); transfer_rsp.set_file_name(transfer_req.file_name()); transfer_rsp.set_file_size(transfer_req.file_size()); transfer_rsp.set_task_id(\u0026#34;\u0026#34;); transfer_rsp.set_trans_mode(transfer_req.trans_mode()); transfer_rsp.set_attach_data(transfer_req.attach_data()); bool rv = false; do { std::string task_id = GenerateUUID(); if (task_id.empty()) { log(\u0026#34;Create task id failed\u0026#34;); break; } log(\u0026#34;trams_mode=%d, task_id=%s, from_id=%d, to_id=%d, file_name=%s, file_size=%d\u0026#34;, transfer_req.trans_mode(), task_id.c_str(), from_id, to_id, transfer_req.file_name().c_str(), transfer_req.file_size()); BaseTransferTask* transfer_task = TransferTaskManager::GetInstance()-\u0026gt;NewTransferTask( transfer_req.trans_mode(), task_id, from_id, to_id, transfer_req.file_name(), transfer_req.file_size()); if (transfer_task == NULL) { // 创建未成功 // close connection with msg svr // need_close = true; log(\u0026#34;Create task failed\u0026#34;); break; } transfer_rsp.set_result_code(0); transfer_rsp.set_task_id(task_id); rv = true; // need_seq_no = false; log(\u0026#34;Create task succeed, task id %s, task type %d, from user %d, to user %d\u0026#34;, task_id.c_str(), transfer_req.trans_mode(), from_id, to_id); } while (0); ::SendMessageLite(this, SID_OTHER, CID_OTHER_FILE_TRANSFER_RSP, pdu-\u0026gt;GetSeqNum(), \u0026amp;transfer_rsp); if (!rv) { // 未创建成功，关闭连接 Close(); } } 上述代码会为本次传输任务创建一个唯一的标识uuid作为taskid，然后根据离线文件还是在线文件创建离线文件传输任务OfflineTransferTask或者在线文件传输任务OnlineTransferTask，并加入一个一个成员变量transfer_tasks_中进行管理：\nBaseTransferTask* TransferTaskManager::NewTransferTask(uint32_t trans_mode, const std::string\u0026amp; task_id, uint32_t from_user_id, uint32_t to_user_id, const std::string\u0026amp; file_name, uint32_t file_size) { BaseTransferTask* transfer_task = NULL; TransferTaskMap::iterator it = transfer_tasks_.find(task_id); if (it==transfer_tasks_.end()) { if (trans_mode == IM::BaseDefine::FILE_TYPE_ONLINE) { transfer_task = new OnlineTransferTask(task_id, from_user_id, to_user_id, file_name, file_size); } else if (trans_mode == IM::BaseDefine::FILE_TYPE_OFFLINE) { transfer_task = new OfflineTransferTask(task_id, from_user_id, to_user_id, file_name, file_size); } else { log(\u0026#34;Invalid trans_mode = %d\u0026#34;, trans_mode); } if (transfer_task) { transfer_tasks_.insert(std::make_pair(task_id, transfer_task)); } } else { log(\u0026#34;Task existed by task_id=%s, why?????\u0026#34;, task_id.c_str()); } return transfer_task; } 这个map transfer_tasks_是在定时器里面进行定期处理的，处理的依据是当前任务的状态，比如已经完成的任务就可以从map中移除了：\nvoid TransferTaskManager::OnTimer(uint64_t tick) { for (TransferTaskMap::iterator it = transfer_tasks_.begin(); it != transfer_tasks_.end();) { BaseTransferTask* task = it-\u0026gt;second; if (task == NULL) { transfer_tasks_.erase(it++); continue; } if (task-\u0026gt;state() != kTransferTaskStateWaitingUpload \u0026amp;\u0026amp; task-\u0026gt;state() == kTransferTaskStateTransferDone) { long esp = time(NULL) - task-\u0026gt;create_time(); if (esp \u0026gt; ConfigUtil::GetInstance()-\u0026gt;GetTaskTimeout()) { if (task-\u0026gt;GetFromConn()) { FileClientConn* conn = reinterpret_cast\u0026lt;FileClientConn*\u0026gt;(task-\u0026gt;GetFromConn()); conn-\u0026gt;ClearTransferTask(); } if (task-\u0026gt;GetToConn()) { FileClientConn* conn = reinterpret_cast\u0026lt;FileClientConn*\u0026gt;(task-\u0026gt;GetToConn()); conn-\u0026gt;ClearTransferTask(); } delete task; transfer_tasks_.erase(it++); continue; } } ++it; } } 完成这些工作以后，组装的应答包命令号是CID_OTHER_FILE_TRANSFER_RSP，回复给msg_server。msg_server收到该应答包后处理：\nvoid CFileServConn::HandlePdu(CImPdu* pPdu) { switch (pPdu-\u0026gt;GetCommandId()) { ... //省略无关代码 case CID_OTHER_FILE_TRANSFER_RSP: _HandleFileMsgTransRsp(pPdu); break; ... //省略无关代码 } } void CFileServConn::_HandleFileMsgTransRsp(CImPdu* pPdu) { IM::Server::IMFileTransferRsp msg; CHECK_PB_PARSE_MSG(msg.ParseFromArray(pPdu-\u0026gt;GetBodyData(), pPdu-\u0026gt;GetBodyLength())); uint32_t result = msg.result_code(); uint32_t from_id = msg.from_user_id(); uint32_t to_id = msg.to_user_id(); string file_name = msg.file_name(); uint32_t file_size = msg.file_size(); string task_id = msg.task_id(); uint32_t trans_mode = msg.trans_mode(); CDbAttachData attach((uchar_t*)msg.attach_data().c_str(), msg.attach_data().length()); log(\u0026#34;HandleFileMsgTransRsp, result: %u, from_user_id: %u, to_user_id: %u, file_name: %s, \\ task_id: %s, trans_mode: %u. \u0026#34;, result, from_id, to_id, file_name.c_str(), task_id.c_str(), trans_mode); const list\u0026lt;IM::BaseDefine::IpAddr\u0026gt;* ip_addr_list = GetFileServerIPList(); IM::File::IMFileRsp msg2; msg2.set_result_code(result); msg2.set_from_user_id(from_id); msg2.set_to_user_id(to_id); msg2.set_file_name(file_name); msg2.set_task_id(task_id); msg2.set_trans_mode((IM::BaseDefine::TransferFileType)trans_mode); for (list\u0026lt;IM::BaseDefine::IpAddr\u0026gt;::const_iterator it = ip_addr_list-\u0026gt;begin(); it != ip_addr_list-\u0026gt;end(); it++) { IM::BaseDefine::IpAddr ip_addr_tmp = *it; IM::BaseDefine::IpAddr* ip_addr = msg2.add_ip_addr_list(); ip_addr-\u0026gt;set_ip(ip_addr_tmp.ip()); ip_addr-\u0026gt;set_port(ip_addr_tmp.port()); } CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg2); pdu.SetServiceId(SID_FILE); pdu.SetCommandId(CID_FILE_RESPONSE); pdu.SetSeqNum(pPdu-\u0026gt;GetSeqNum()); uint32_t handle = attach.GetHandle(); CMsgConn* pFromConn = CImUserManager::GetInstance()-\u0026gt;GetMsgConnByHandle(from_id, handle); if (pFromConn) { pFromConn-\u0026gt;SendPdu(\u0026amp;pdu); } if (result == 0) { IM::File::IMFileNotify msg3; msg3.set_from_user_id(from_id); msg3.set_to_user_id(to_id); msg3.set_file_name(file_name); msg3.set_file_size(file_size); msg3.set_task_id(task_id); msg3.set_trans_mode((IM::BaseDefine::TransferFileType)trans_mode); msg3.set_offline_ready(0); for (list\u0026lt;IM::BaseDefine::IpAddr\u0026gt;::const_iterator it = ip_addr_list-\u0026gt;begin(); it != ip_addr_list-\u0026gt;end(); it++) { IM::BaseDefine::IpAddr ip_addr_tmp = *it; IM::BaseDefine::IpAddr* ip_addr = msg3.add_ip_addr_list(); ip_addr-\u0026gt;set_ip(ip_addr_tmp.ip()); ip_addr-\u0026gt;set_port(ip_addr_tmp.port()); } CImPdu pdu2; pdu2.SetPBMsg(\u0026amp;msg3); pdu2.SetServiceId(SID_FILE); pdu2.SetCommandId(CID_FILE_NOTIFY); //send notify to target user CImUser* pToUser = CImUserManager::GetInstance()-\u0026gt;GetImUserById(to_id); if (pToUser) { pToUser-\u0026gt;BroadcastPduWithOutMobile(\u0026amp;pdu2); } //send to route server CRouteServConn* pRouteConn = get_route_serv_conn(); if (pRouteConn) { pRouteConn-\u0026gt;SendPdu(\u0026amp;pdu2); } } } msg_server收到包后，首先装包数据，并把file_server的ip地址和端口信息带上，发给请求发文件的客户端，命令号是CID_FILE_RESPONSE；接着查询通知接收方有人给其发文件（通知方式也是一样，如果接收方在该msg_server上，直接发给该用户；不在的话，发给路由服务route_server）。当然接收到文件发送的端只有pc端，移动端会被过滤掉的，也就是说移动端不会收到发送文件的请求。\n我们先看发送方pc客户端收到应答的逻辑（命令号是CID_FILE_RESPONSE）：\nvoid FileTransferModule_Impl::onPacket(imcore::TTPBHeader\u0026amp; header, std::string\u0026amp; pbBody) { switch (header.getCommandId()) { case IM::BaseDefine::FileCmdID::CID_FILE_RESPONSE://发送“文件请求/离线文件”-返回 _sendfileResponse(pbBody); break;\t} } void FileTransferModule_Impl::_sendfileResponse(IN std::string\u0026amp; body) { IM::File::IMFileRsp imFileRsp; if (!imFileRsp.ParseFromString(body)) { LOG__(ERR, _T(\u0026#34;parse failed,body:%s\u0026#34;), util::stringToCString(body)); return; } UInt32 nResult = imFileRsp.result_code(); if (nResult != 0) { LOG__(ERR, _T(\u0026#34;_sendfileResponse result != 0\u0026#34;)); module::getFileTransferModule()-\u0026gt;asynNotifyObserver(module::KEY_FILESEVER_UPLOAD_FAILED); } TransferFileEntity fileEntity; fileEntity.sTaskID = imFileRsp.task_id(); assert(!fileEntity.sTaskID.empty()); fileEntity.sFromID = util::uint32ToString(imFileRsp.from_user_id()); fileEntity.sToID = util::uint32ToString(imFileRsp.to_user_id()); fileEntity.sFileName = imFileRsp.file_name(); fileEntity.setSaveFilePath(util::stringToCString(fileEntity.sFileName));//发送方文件地址，就是保存地址 fileEntity.time = static_cast\u0026lt;UInt32\u0026gt;(time(0)); uint32_t transMode = imFileRsp.trans_mode(); if (IM::BaseDefine::TransferFileType::FILE_TYPE_ONLINE == transMode) { fileEntity.nClientMode = IM::BaseDefine::ClientFileRole::CLIENT_REALTIME_SENDER; } else if (IM::BaseDefine::TransferFileType::FILE_TYPE_OFFLINE == transMode) { fileEntity.nClientMode = IM::BaseDefine::ClientFileRole::CLIENT_OFFLINE_UPLOAD; } fileEntity.pFileObject = new TransferFile(util::stringToCString(fileEntity.sFileName),FALSE); if (fileEntity.pFileObject) { fileEntity.nFileSize = fileEntity.pFileObject-\u0026gt;length(); } UINT32 nIPCount = imFileRsp.ip_addr_list_size(); if (nIPCount \u0026lt;= 0) { return; } const IM::BaseDefine::IpAddr\u0026amp; ipAdd = imFileRsp.ip_addr_list(0); fileEntity.sIP = ipAdd.ip(); fileEntity.nPort = ipAdd.port(); if (!TransferFileEntityManager::getInstance()-\u0026gt;pushTransferFileEntity(fileEntity)) TransferFileEntityManager::getInstance()-\u0026gt;updateFileInfoBysTaskID(fileEntity); LOG__(DEBG, _T(\u0026#34;FileTransferSevice_Impl::准备连接文件服务器 sTaskId = %s\u0026#34;), util::stringToCString(fileEntity.sTaskID)); TransferFileEntityManager::getInstance()-\u0026gt;openFileSocketByTaskId(fileEntity.sTaskID); } 客户端在TransferFileEntityManager::getInstance()-\u0026gt;openFileSocketByTaskId(fileEntity.sTaskID);里面实际去连接file_server并尝试发文件：\nvoid TransferFileEntityManager::openFileSocketByTaskId(std::string\u0026amp; taskId) { m_fileUIThread-\u0026gt;openFileSocketByTaskId(taskId); } void FileTransferUIThread::openFileSocketByTaskId(std::string\u0026amp; taskId) { FileTransferSocket* pFileSocket = _findFileSocketByTaskId(taskId); if (!pFileSocket) { pFileSocket = new FileTransferSocket(taskId); m_lstFileTransSockets.push_back(pFileSocket); assert(m_hWnd); ::PostMessage(m_hWnd, WM_FILE_TRANSFER, 0, (LPARAM)pFileSocket); } } LRESULT _stdcall FileTransferUIThread::_WndProc(HWND hWnd, UINT message, WPARAM wparam, LPARAM lparam) { if (WM_FILE_TRANSFER == message) { FileTransferSocket* pFileSocket = (FileTransferSocket*)lparam; pFileSocket-\u0026gt;startFileTransLink(); } return ::DefWindowProc(hWnd, message, wparam, lparam); } BOOL FileTransferSocket::startFileTransLink() { TransferFileEntity FileInfo; if (TransferFileEntityManager::getInstance()-\u0026gt;getFileInfoByTaskId(m_sTaskId, FileInfo)) { //大佛：使用msg server 传过来的IP和端口 LOG__(APP, _T(\u0026#34;connect IP=%s,Port=%d\u0026#34;), util::stringToCString(FileInfo.sIP), FileInfo.nPort); connect(util::stringToCString(FileInfo.sIP), FileInfo.nPort); //connect(util::stringToCString(module::FILETRANSFER_IP), module::FILETRANSFER_PORT); return TRUE; } LOG__(ERR, _T(\u0026#34;can\u0026#39;t find the TaskId\u0026#34;)); return FALSE; } 注意，这里只是去连接file_server服务器，连接成功的情况下，会尝试登录文件服务器，登录file_server的命令号是CID_FILE_LOGIN_REQ：\nvoid FileTransferSocket::onConnectDone() { LOG__(APP, _T(\u0026#34;FileTransferSocket::onConnected()\u0026#34;)); startHeartbeat(); TransferFileEntity info; if (!TransferFileEntityManager::getInstance()-\u0026gt;getFileInfoByTaskId(m_sTaskId, info)) { LOG__(APP, _T(\u0026#34;Can\u0026#39;t get the file info,task id:%s\u0026#34;),util::stringToCString(m_sTaskId)); return; } //拉模式文件传输，传输taskid、token、client_mode IM::File::IMFileLoginReq imFileLoginReq; imFileLoginReq.set_user_id(module::getSysConfigModule()-\u0026gt;userId()); imFileLoginReq.set_task_id(info.sTaskID); imFileLoginReq.set_file_role(static_cast\u0026lt;IM::BaseDefine::ClientFileRole\u0026gt;(info.nClientMode)); LOG__(APP, _T(\u0026#34;IMFileLoginReq,sTaskID:%s,nClientMode:%d\u0026#34;), util::stringToCString(info.sTaskID), info.nClientMode); //send packet LOG__(APP, _T(\u0026#34;IMFileLoginReq,taskId:%s\u0026#34;), util::stringToCString(info.sTaskID)); sendPacket(IM::BaseDefine::ServiceID::SID_FILE, IM::BaseDefine::FileCmdID::CID_FILE_LOGIN_REQ, \u0026amp;imFileLoginReq); //CImPduClientFileLoginReq pduFileLoginReq(module::getSysConfigModule()-\u0026gt;userID().c_str() //\t, \u0026#34;\u0026#34;, info.sTaskID.c_str(), ); //sendPacket(\u0026amp;pduFileLoginReq); } file_server收到该数据包处理如下：\nvoid FileClientConn::HandlePdu(CImPdu* pdu) { ... //省略无关代码 case CID_FILE_LOGIN_REQ: _HandleClientFileLoginReq(pdu); break; } void FileClientConn::_HandleClientFileLoginReq(CImPdu* pdu) { IM::File::IMFileLoginReq login_req; CHECK_PB_PARSE_MSG(login_req.ParseFromArray(pdu-\u0026gt;GetBodyData(), pdu-\u0026gt;GetBodyLength())); uint32_t user_id = login_req.user_id(); string task_id = login_req.task_id(); IM::BaseDefine::ClientFileRole mode = login_req.file_role(); log(\u0026#34;Client login, user_id=%d, task_id=%s, file_role=%d\u0026#34;, user_id, task_id.c_str(), mode); BaseTransferTask* transfer_task = NULL; bool rv = false; do { // 查找任务是否存在 transfer_task = TransferTaskManager::GetInstance()-\u0026gt;FindByTaskID(task_id); if (transfer_task == NULL) { if (mode == CLIENT_OFFLINE_DOWNLOAD) { // 文件不存在，检查是否是离线下载，有可能是文件服务器重启 // 尝试从磁盘加载 transfer_task = TransferTaskManager::GetInstance()-\u0026gt;NewTransferTask(task_id, user_id); // 需要再次判断是否加载成功 if (transfer_task == NULL) { log(\u0026#34;Find task id failed, user_id=%u, taks_id=%s, mode=%d\u0026#34;, user_id, task_id.c_str(), mode); break; } } else { log(\u0026#34;Can\u0026#39;t find task_id, user_id=%u, taks_id=%s, mode=%d\u0026#34;, user_id, task_id.c_str(), mode); break; } } // 状态转换 rv = transfer_task-\u0026gt;ChangePullState(user_id, mode); if (!rv) { // log(); break; // } // Ok auth_ = true; transfer_task_ = transfer_task; user_id_ = user_id; // 设置conn transfer_task-\u0026gt;SetConnByUserID(user_id, this); rv = true; } while (0); IM::File::IMFileLoginRsp login_rsp; login_rsp.set_result_code(rv?0:1); login_rsp.set_task_id(task_id); ::SendMessageLite(this, SID_FILE, CID_FILE_LOGIN_RES, pdu-\u0026gt;GetSeqNum(), \u0026amp;login_rsp); if (rv) { if (transfer_task-\u0026gt;GetTransMode() == FILE_TYPE_ONLINE) { if (transfer_task-\u0026gt;state() == kTransferTaskStateWaitingTransfer) { CImConn* conn = transfer_task_-\u0026gt;GetToConn(); if (conn) { _StatesNotify(CLIENT_FILE_PEER_READY, task_id, transfer_task_-\u0026gt;from_user_id(), conn); } else { log(\u0026#34;to_conn is close, close me!!!\u0026#34;); Close(); } // _StatesNotify(CLIENT_FILE_PEER_READY, task_id, user_id, this); // transfer_task-\u0026gt;StatesNotify(CLIENT_FILE_PEER_READY, task_id, user_id_); } } else { if (transfer_task-\u0026gt;state() == kTransferTaskStateWaitingUpload) { OfflineTransferTask* offline = reinterpret_cast\u0026lt;OfflineTransferTask*\u0026gt;(transfer_task); IM::File::IMFilePullDataReq pull_data_req; pull_data_req.set_task_id(task_id); pull_data_req.set_user_id(user_id); pull_data_req.set_trans_mode(FILE_TYPE_OFFLINE); pull_data_req.set_offset(0); pull_data_req.set_data_size(offline-\u0026gt;GetNextSegmentBlockSize()); ::SendMessageLite(this, SID_FILE, CID_FILE_PULL_DATA_REQ, \u0026amp;pull_data_req); log(\u0026#34;Pull Data Req\u0026#34;); } } } else { Close(); } } file_server应答客户端的命令号是CID_FILE_LOGIN_RES，客户端收到该包后处理如下：\nvoid FileTransferSocket::onReceiveData(const char* data, int32_t size) { std::string pbBody; imcore::TTPBHeader pbHeader; try { pbHeader.unSerialize((byte*)data, imcore::HEADER_LENGTH); pbBody.assign(data + imcore::HEADER_LENGTH, size - imcore::HEADER_LENGTH); if (IM::BaseDefine::OtherCmdID::CID_OTHER_HEARTBEAT == pbHeader.getCommandId() \u0026amp;\u0026amp; IM::BaseDefine::ServiceID::SID_OTHER == pbHeader.getModuleId()) return; } catch (CPduException e) { LOG__(ERR, _T(\u0026#34;onPacket CPduException serviceId:%d,commandId:%d,errCode:%d\u0026#34;) , e.GetModuleId(), e.GetCommandId(), e.GetErrorCode()); return; } catch (...) { LOG__(ERR, _T(\u0026#34;FileTransferSocket onPacket unknown exception\u0026#34;)); return; } UInt16 ncmdid = pbHeader.getCommandId(); switch (ncmdid) {\tcase IM::BaseDefine::FileCmdID::CID_FILE_LOGIN_RES: _fileLoginResponse(pbBody); break; //无关代码省略 } } void FileTransferSocket::_fileLoginResponse(IN std::string\u0026amp; body) { IM::File::IMFileLoginRsp imFileLoginRsp; if (!imFileLoginRsp.ParseFromString(body)) { LOG__(ERR, _T(\u0026#34;parse failed,body:%s\u0026#34;), util::stringToCString(body)); return; } if (imFileLoginRsp.result_code() != 0) { LOG__(ERR, _T(\u0026#34;file server login failed! \u0026#34;)); return; } //打开文件 std::string taskId = imFileLoginRsp.task_id(); TransferFileEntity fileEntity; if (!TransferFileEntityManager::getInstance()-\u0026gt;getFileInfoByTaskId(taskId, fileEntity)) { LOG__(ERR, _T(\u0026#34;file server login:can\u0026#39;t find the fileInfo \u0026#34;)); return; } LOG__(APP, _T(\u0026#34;IMFileLoginRsp, file server login succeed\u0026#34;)); //提示界面,界面上插入该项 if (IM::BaseDefine::ClientFileRole::CLIENT_REALTIME_SENDER == fileEntity.nClientMode || IM::BaseDefine::ClientFileRole::CLIENT_OFFLINE_UPLOAD == fileEntity.nClientMode) { module::getFileTransferModule()-\u0026gt;asynNotifyObserver(module::KEY_FILETRANSFER_SENDFILE, fileEntity.sTaskID); } else if (IM::BaseDefine::ClientFileRole::CLIENT_REALTIME_RECVER == fileEntity.nClientMode || IM::BaseDefine::ClientFileRole::CLIENT_OFFLINE_DOWNLOAD == fileEntity.nClientMode) { module::getFileTransferModule()-\u0026gt;asynNotifyObserver(module::KEY_FILETRANSFER_REQUEST, fileEntity.sTaskID); } } 至此，不管是离线文件还是在线文件发送，pc客户端会显示一个文件进度的对话框：\n对于在线文件，需要对端同意接收文件的传输，客户端才会读取文件，这个进度条才会发生变化。而对于离线文件，应该会立马读取文件上传文件数据到服务器。可是哪里会触发客户端读取文件并发送的逻辑呢？门道在于file_server在收到登录请求CID_FILE_LOGIN_REQ后，不仅会给客户端发送登录应答数据包CID_FILE_LOGIN_RES。还会根据文件的传输模式，如果是离线文件则会给客户端发送拉取文件的数据包CID_FILE_PULL_DATA_REQ，代码我们已经在上面的FileClientConn::_HandleClientFileLoginReq(CImPdu* pdu)中贴过了，我们再贴一次：\nvoid FileClientConn::_HandleClientFileLoginReq(CImPdu* pdu) { IM::File::IMFileLoginReq login_req; CHECK_PB_PARSE_MSG(login_req.ParseFromArray(pdu-\u0026gt;GetBodyData(), pdu-\u0026gt;GetBodyLength())); uint32_t user_id = login_req.user_id(); string task_id = login_req.task_id(); IM::BaseDefine::ClientFileRole mode = login_req.file_role(); log(\u0026#34;Client login, user_id=%d, task_id=%s, file_role=%d\u0026#34;, user_id, task_id.c_str(), mode); BaseTransferTask* transfer_task = NULL; bool rv = false; do { // 查找任务是否存在 transfer_task = TransferTaskManager::GetInstance()-\u0026gt;FindByTaskID(task_id); if (transfer_task == NULL) { if (mode == CLIENT_OFFLINE_DOWNLOAD) { // 文件不存在，检查是否是离线下载，有可能是文件服务器重启 // 尝试从磁盘加载 transfer_task = TransferTaskManager::GetInstance()-\u0026gt;NewTransferTask(task_id, user_id); // 需要再次判断是否加载成功 if (transfer_task == NULL) { log(\u0026#34;Find task id failed, user_id=%u, taks_id=%s, mode=%d\u0026#34;, user_id, task_id.c_str(), mode); break; } } else { log(\u0026#34;Can\u0026#39;t find task_id, user_id=%u, taks_id=%s, mode=%d\u0026#34;, user_id, task_id.c_str(), mode); break; } } // 状态转换 rv = transfer_task-\u0026gt;ChangePullState(user_id, mode); if (!rv) { // log(); break; // } // Ok auth_ = true; transfer_task_ = transfer_task; user_id_ = user_id; // 设置conn transfer_task-\u0026gt;SetConnByUserID(user_id, this); rv = true; } while (0); IM::File::IMFileLoginRsp login_rsp; login_rsp.set_result_code(rv?0:1); login_rsp.set_task_id(task_id); ::SendMessageLite(this, SID_FILE, CID_FILE_LOGIN_RES, pdu-\u0026gt;GetSeqNum(), \u0026amp;login_rsp); if (rv) { if (transfer_task-\u0026gt;GetTransMode() == FILE_TYPE_ONLINE) { if (transfer_task-\u0026gt;state() == kTransferTaskStateWaitingTransfer) { CImConn* conn = transfer_task_-\u0026gt;GetToConn(); if (conn) { _StatesNotify(CLIENT_FILE_PEER_READY, task_id, transfer_task_-\u0026gt;from_user_id(), conn); } else { log(\u0026#34;to_conn is close, close me!!!\u0026#34;); Close(); } // _StatesNotify(CLIENT_FILE_PEER_READY, task_id, user_id, this); // transfer_task-\u0026gt;StatesNotify(CLIENT_FILE_PEER_READY, task_id, user_id_); } } else { if (transfer_task-\u0026gt;state() == kTransferTaskStateWaitingUpload) { OfflineTransferTask* offline = reinterpret_cast\u0026lt;OfflineTransferTask*\u0026gt;(transfer_task); IM::File::IMFilePullDataReq pull_data_req; pull_data_req.set_task_id(task_id); pull_data_req.set_user_id(user_id); pull_data_req.set_trans_mode(FILE_TYPE_OFFLINE); pull_data_req.set_offset(0); pull_data_req.set_data_size(offline-\u0026gt;GetNextSegmentBlockSize()); ::SendMessageLite(this, SID_FILE, CID_FILE_PULL_DATA_REQ, \u0026amp;pull_data_req); log(\u0026#34;Pull Data Req\u0026#34;); } } } else { Close(); } } pc端收到CID_FILE_PULL_DATA_REQ后，表示这是一个离线文件，就可以直接上传文件数据了：\ncase IM::BaseDefine::FileCmdID::CID_FILE_PULL_DATA_REQ://发文件 _filePullDataReqResponse(pbBody); void FileTransferSocket::_filePullDataReqResponse(IN std::string\u0026amp; body)//发 { IM::File::IMFilePullDataReq imFilePullDataReq; if (!imFilePullDataReq.ParseFromString(body)) { LOG__(ERR, _T(\u0026#34;parse failed,body:%s\u0026#34;), util::stringToCString(body)); return; } UInt32 fileSize = imFilePullDataReq.data_size(); UInt32 fileOffset = imFilePullDataReq.offset(); std::string taskId = imFilePullDataReq.task_id(); TransferFileEntity fileEntity; if (!TransferFileEntityManager::getInstance()-\u0026gt;getFileInfoByTaskId(taskId, fileEntity)) { LOG__(ERR, _T(\u0026#34;PullDataReqResponse: can\u0026#39;t find the fileInfo\u0026#34;)); return; } LOG__(DEBG, _T(\u0026#34;send:taskId=%s,filesize=%d,name=%s,BolckSize=%d\u0026#34;) ,util::stringToCString(fileEntity.sTaskID) ,fileEntity.nFileSize ,fileEntity.getRealFileName() ,fileSize); std::string buff; if (nullptr == fileEntity.pFileObject) { LOG__(ERR, _T(\u0026#34;PullDataReqResponse: file boject Destoryed!\u0026#34;)); return; } fileEntity.pFileObject-\u0026gt;readBlock(fileOffset, fileSize, buff);//读取本地文件的数据块 IM::File::IMFilePullDataRsp imFilePullDataRsp;//todo check imFilePullDataRsp.set_result_code(0); imFilePullDataRsp.set_task_id(taskId); imFilePullDataRsp.set_user_id(util::stringToInt32(fileEntity.sFromID)); imFilePullDataRsp.set_offset(fileOffset); imFilePullDataRsp.set_file_data((void*)buff.data(), fileSize); //send packet sendPacket(IM::BaseDefine::ServiceID::SID_FILE, IM::BaseDefine::FileCmdID::CID_FILE_PULL_DATA_RSP , \u0026amp;imFilePullDataRsp); fileEntity.nProgress = fileOffset + fileSize; if (fileEntity.nProgress \u0026lt; fileEntity.nFileSize) { //更新进度条 TransferFileEntityManager::getInstance()-\u0026gt;updateFileInfoBysTaskID(fileEntity);//保存当前进度 module::getFileTransferModule()-\u0026gt;asynNotifyObserver(module::KEY_FILESEVER_UPDATA_PROGRESSBAR , fileEntity.sTaskID); } else//传输完成 { if (fileEntity.pFileObject) { delete fileEntity.pFileObject; fileEntity.pFileObject = nullptr; } module::getFileTransferModule()-\u0026gt;asynNotifyObserver(module::KEY_FILESEVER_PROGRESSBAR_FINISHED , fileEntity.sTaskID); } TransferFileEntityManager::getInstance()-\u0026gt;updateFileInfoBysTaskID(fileEntity); } 当然，如果文件比较大，一次发不完也没关系，在CID_FILE_PULL_DATA_REQ中有当前文件的偏移量，客户端在读取文件和应答服务器时也带上这个偏移量fileOffset，应答给服务器的包是CID_FILE_PULL_DATA_RSP。file_server收到应答后处理：\nvoid FileClientConn::HandlePdu(CImPdu* pdu) { ... //省略无关代码 case CID_FILE_PULL_DATA_RSP: _HandleClientFilePullFileRsp( pdu); break ; ... //省略无关代码 } void FileClientConn::_HandleClientFilePullFileRsp(CImPdu *pdu) { if (!auth_ || !transfer_task_) { log(\u0026#34;auth is false\u0026#34;); return; } // 只有rsp IM::File::IMFilePullDataRsp pull_data_rsp; CHECK_PB_PARSE_MSG(pull_data_rsp.ParseFromArray(pdu-\u0026gt;GetBodyData(), pdu-\u0026gt;GetBodyLength())); uint32_t user_id = pull_data_rsp.user_id(); string task_id = pull_data_rsp.task_id(); uint32_t offset = pull_data_rsp.offset(); uint32_t data_size = static_cast\u0026lt;uint32_t\u0026gt;(pull_data_rsp.file_data().length()); const char* data = pull_data_rsp.file_data().data(); // log(\u0026#34;Recv FilePullFileRsp, user_id=%d, task_id=%s, file_role=%d, offset=%d, datasize=%d\u0026#34;, user_id, task_id.c_str(), mode, offset, datasize); log(\u0026#34;Recv FilePullFileRsp, task_id=%s, user_id=%u, offset=%u, data_size=%d\u0026#34;, task_id.c_str(), user_id, offset, data_size); int rv = -1; do { // // 检查user_id if (user_id != user_id_) { log(\u0026#34;Received user_id valid, recv_user_id = %d, transfer_task.user_id = %d, user_id_ = %d\u0026#34;, user_id, transfer_task_-\u0026gt;from_user_id(), user_id_); break; } // 检查task_id if (transfer_task_-\u0026gt;task_id() != task_id) { log(\u0026#34;Received task_id valid, recv_task_id = %s, this_task_id = %s\u0026#34;, task_id.c_str(), transfer_task_-\u0026gt;task_id().c_str()); // Close(); break; } rv = transfer_task_-\u0026gt;DoRecvData(user_id, offset, data, data_size); if (rv == -1) { break; } if (transfer_task_-\u0026gt;GetTransMode() == FILE_TYPE_ONLINE) { // 对于在线，直接转发 OnlineTransferTask* online = reinterpret_cast\u0026lt;OnlineTransferTask*\u0026gt;(transfer_task_); pdu-\u0026gt;SetSeqNum(online-\u0026gt;GetSeqNum()); // online-\u0026gt;SetSeqNum(pdu-\u0026gt;GetSeqNum()); CImConn* conn = transfer_task_-\u0026gt;GetToConn(); if (conn) { conn-\u0026gt;SendPdu(pdu); } } else { // 离线 // all packages recved if (rv == 1) { _StatesNotify(CLIENT_FILE_DONE, task_id, user_id, this); // Close(); } else { OfflineTransferTask* offline = reinterpret_cast\u0026lt;OfflineTransferTask*\u0026gt;(transfer_task_); IM::File::IMFilePullDataReq pull_data_req; pull_data_req.set_task_id(task_id); pull_data_req.set_user_id(user_id); pull_data_req.set_trans_mode(static_cast\u0026lt;IM::BaseDefine::TransferFileType\u0026gt;(offline-\u0026gt;GetTransMode())); pull_data_req.set_offset(offline-\u0026gt;GetNextOffset()); pull_data_req.set_data_size(offline-\u0026gt;GetNextSegmentBlockSize()); ::SendMessageLite(this, SID_FILE, CID_FILE_PULL_DATA_REQ, \u0026amp;pull_data_req); // log(\u0026#34;size not match\u0026#34;); } } } while (0); if (rv!=0) { // -1，出错关闭 // 1, 离线上传完成 Close(); } } 如果是在线文件，就直接转发含有文件数据的包；如果是离线文件，则存入文件服务上，即写入文件：\nint OfflineTransferTask::DoRecvData(uint32_t user_id, uint32_t offset, const char* data, uint32_t data_size) { // 离线文件上传 int rv = -1; do { // 检查是否发送者 if (!CheckFromUserID(user_id)) { log(\u0026#34;rsp user_id=%d, but sender_id is %d\u0026#34;, user_id, from_user_id_); break; } // 检查状态 if (state_ != kTransferTaskStateWaitingUpload \u0026amp;\u0026amp; state_ != kTransferTaskStateUploading) { log(\u0026#34;state=%d error, need kTransferTaskStateWaitingUpload or kTransferTaskStateUploading\u0026#34;, state_); break; } // 检查offset是否有效 if (offset != transfered_idx_*SEGMENT_SIZE) { break; } //if (data_size != GetNextSegmentBlockSize()) { // break; //} // todo // 检查文件大小 data_size = GetNextSegmentBlockSize(); log(\u0026#34;Ready recv data, offset=%d, data_size=%d, segment_size=%d\u0026#34;, offset, data_size, sengment_size_); if (state_ == kTransferTaskStateWaitingUpload) { if (fp_ == NULL) { fp_ = OpenByWrite(task_id_, to_user_id_); if (fp_ == NULL) { break; } } // 写文件头 OfflineFileHeader file_header; memset(\u0026amp;file_header, 0, sizeof(file_header)); file_header.set_create_time(time(NULL)); file_header.set_task_id(task_id_); file_header.set_from_user_id(from_user_id_); file_header.set_to_user_id(to_user_id_); file_header.set_file_name(\u0026#34;\u0026#34;); file_header.set_file_size(file_size_); fwrite(\u0026amp;file_header, 1, sizeof(file_header), fp_); fflush(fp_); state_ = kTransferTaskStateUploading; } // 存储 if (fp_ == NULL) { // break; } fwrite(data, 1, data_size, fp_); fflush(fp_); ++transfered_idx_; SetLastUpdateTime(); if (transfered_idx_ == sengment_size_) { state_ = kTransferTaskStateUploadEnd; fclose(fp_); fp_ = NULL; rv = 1; } else { rv = 0; } } while (0); return rv; } 如此循环，直至文件传输完成。当然文件上传完成后file_server也会断开与客户端的连接。\n到这里我们介绍了发送文件方的逻辑，下面我们看看接收方的逻辑，上文中介绍了接收方会收到接收文件的通知CID_FILE_NOTIFY，客户端处理这个命令号：\ncase IM::BaseDefine::FileCmdID::CID_FILE_NOTIFY://收到“发送文件请求” _fileNotify(pbBody);\t_fileNotify(pbBody); void FileTransferModule_Impl::_fileNotify(IN std::string\u0026amp; body) { IM::File::IMFileNotify imFileNotify; if (!imFileNotify.ParseFromString(body)) { LOG__(ERR, _T(\u0026#34;parse failed,body:%s\u0026#34;), util::stringToCString(body)); return; } TransferFileEntity file; file.sFileName = imFileNotify.file_name(); file.sFromID = util::uint32ToString(imFileNotify.from_user_id()); file.sToID = util::uint32ToString(imFileNotify.to_user_id()); file.sTaskID = imFileNotify.task_id(); file.nFileSize = imFileNotify.file_size(); UINT32 nIPCount = imFileNotify.ip_addr_list_size(); if (nIPCount \u0026lt;= 0) { return; } const IM::BaseDefine::IpAddr\u0026amp; ipAdd = imFileNotify.ip_addr_list(0); file.sIP = ipAdd.ip(); file.nPort = ipAdd.port(); uint32_t transMode = imFileNotify.trans_mode(); if (IM::BaseDefine::TransferFileType::FILE_TYPE_ONLINE == transMode) { file.nClientMode = IM::BaseDefine::ClientFileRole::CLIENT_REALTIME_RECVER; } else if (IM::BaseDefine::TransferFileType::FILE_TYPE_OFFLINE == transMode) { file.nClientMode = IM::BaseDefine::ClientFileRole::CLIENT_OFFLINE_DOWNLOAD; } file.time = static_cast\u0026lt;UInt32\u0026gt;(time(0)); TransferFileEntityManager::getInstance()-\u0026gt;pushTransferFileEntity(file); LOG__(DEBG, _T(\u0026#34;FileTransferSevice_Impl::给你发文件 sFileID = %s\u0026#34;), util::stringToCString(file.sTaskID)); if (1 == imFileNotify.offline_ready()) { //TODO离线文件传输结束 } //连接服务器 TransferFileEntityManager::getInstance()-\u0026gt;openFileSocketByTaskId(file.sTaskID); } 其实也就是接收方会去连接文件服务器。连接成功以后，在对应的回调函数里面触发显示接收文件对话框。但是此时实际上还不能接收文件，因为发送方可能还没准备好。发送方要准备啥呢？前面我们已经介绍了，我们梳理一下上述流程：\n发送方先向msg_server请求发送文件，msg_server转发给file_server；\nfile_server应答msg_server并告诉msg_server自己的地址和端口号；\nmsg_server收到file_server的应答后，先回复发送方，再转发给接收方；\n发送方接着发送登录请求给file_server，file_server收到请求决定是否给发送方发送拉取文件的数据包。如果是离线文件，则会立刻给发送方发送拉取文件的数据包；如果是在线文件，则需要等待接收方同意接收。\n所以，必须过了步骤4，一直到file_server应答了发送方的登录文件服务器请求后，发送方才算准备好。此时，file_server知道发送方已经准备好了，给接收方发送数据包CID_FILE_STATE。接收方收到这个命令号后：\ncase IM::BaseDefine::FileCmdID::CID_FILE_STATE:// _fileState(pbBody); void FileTransferSocket::_fileState(IN std::string\u0026amp; body) { IM::File::IMFileState imFileState; if (!imFileState.ParseFromString(body)) { LOG__(ERR, _T(\u0026#34;parse failed,body:%s\u0026#34;), util::stringToCString(body)); return; } UINT32 nfileState = imFileState.state(); std::string taskId = imFileState.task_id(); TransferFileEntity fileEntity; if (!TransferFileEntityManager::getInstance()-\u0026gt;getFileInfoByTaskId(taskId, fileEntity)) { LOG__(ERR, _T(\u0026#34;fileState:can\u0026#39;t find the fileInfo \u0026#34;)); return; } switch (nfileState) { case IM::BaseDefine::ClientFileState::CLIENT_FILE_PEER_READY: LOG__(APP, _T(\u0026#34;fileState--CLIENT_FILE_PEER_READY \u0026#34;)); break; case IM::BaseDefine::ClientFileState::CLIENT_FILE_CANCEL ://取消的了文件传输 LOG__(APP, _T(\u0026#34;fileState--CLIENT_FILE_CANCEL \u0026#34;)); { if (fileEntity.pFileObject) { delete fileEntity.pFileObject; fileEntity.pFileObject = nullptr; } TransferFileEntityManager::getInstance()-\u0026gt;updateFileInfoBysTaskID(fileEntity); module::getFileTransferModule()-\u0026gt;asynNotifyObserver(module::KEY_FILESEVER_UPLOAD_CANCEL, fileEntity.sTaskID); } break; case IM::BaseDefine::ClientFileState::CLIENT_FILE_REFUSE://拒绝了文件 LOG__(APP, _T(\u0026#34;fileState--CLIENT_FILE_REFUSE \u0026#34;)); { if (fileEntity.pFileObject) { delete fileEntity.pFileObject; fileEntity.pFileObject = nullptr; } TransferFileEntityManager::getInstance()-\u0026gt;updateFileInfoBysTaskID(fileEntity); module::getFileTransferModule()-\u0026gt;asynNotifyObserver(module::KEY_FILESEVER_UPLOAD_REJECT, fileEntity.sTaskID); } break; case IM::BaseDefine::ClientFileState::CLIENT_FILE_DONE: LOG__(APP, _T(\u0026#34;fileState--CLIENT_FILE_DONE \u0026#34;)); if (fileEntity.pFileObject) { delete fileEntity.pFileObject; fileEntity.pFileObject = nullptr; } TransferFileEntityManager::getInstance()-\u0026gt;updateFileInfoBysTaskID(fileEntity); module::getFileTransferModule()-\u0026gt;asynNotifyObserver(module::KEY_FILESEVER_PROGRESSBAR_FINISHED, fileEntity.sTaskID); break; default: break; } } 同理，对于接收方，选择接收还是拒绝文件的逻辑也是在这里一起处理的，与此类似，这里就不再重复叙述了。\n接收方下载文件的逻辑和发送方上传文件的逻辑类似。这里也不在描述了。\n最后说一点我的建议，teamtalk的file_server逻辑、以及与客户端还有msg_server的逻辑流程加上各种细节写的比较的细腻，代码实现上也比较好。强烈建议好好地阅读这部分的代码。毕竟很多人在自己实现一个文件服务器时，还是存在不少问题的。\n​\n","permalink":"https://haokiu.com/blog/c5f5c9828a6f472d9768cffc2f548784/","summary":"08 服务器端file_server源码分析 这篇文章我们来介绍file_server服务的功能和源码实现。TeamTalk支持离线在线文件和离线文件两种传送文件的方式。单纯地研究file_server的程序结构没多大意义，因为其程序结构和其他几个服务结构基本上一模一样，前面几篇文章已经介绍过了。 我们研究teamtalk的file_server是为了学习和借鉴teamtalk的文件传输功能实现思路，以内化为自己的知识，并加以应用。\n所以这篇文章，我们将pc客户端的文件传输功能、msg_server转发消息、file_server处理文件数据三个方面结合起来一起介绍。\n下面开始啦。\n一、连接状况介绍\nfileserver开始并不是和客户端连接的，客户端是按需连接file_server的。但是file_server与msg_server却是长连接。先启动file_server，再启动msg_server。msg_server初始化的时候，会去尝试连接file_server的8601端口。连接成功以后，会给file_server发送一个发包询问file_server侦听客户端连接的ip和端口号信息：\nvoid CFileServConn::OnConfirm() { log(\u0026#34;connect to file server success \u0026#34;); m_bOpen = true; m_connect_time = get_tick_count(); g_file_server_list[m_serv_idx].reconnect_cnt = MIN_RECONNECT_CNT / 2; //连上file_server以后，给file_server发送获取ip地址的数据包 IM::Server::IMFileServerIPReq msg; CImPdu pdu; pdu.SetPBMsg(\u0026amp;msg); pdu.SetServiceId(SID_OTHER); pdu.SetCommandId(CID_OTHER_FILE_SERVER_IP_REQ); SendPdu(\u0026amp;pdu); } file_server收到该数据包后，将自己的侦听客户端连接的ip地址和端口号发包告诉msg_server：\nvoid FileMsgServerConn::_HandleGetServerAddressReq(CImPdu* pPdu) { IM::Server::IMFileServerIPRsp msg; const std::list\u0026lt;IM::BaseDefine::IpAddr\u0026gt;\u0026amp; addrs = ConfigUtil::GetInstance()-\u0026gt;GetAddressList(); for (std::list\u0026lt;IM::BaseDefine::IpAddr\u0026gt;::const_iterator it=addrs.begin(); it!=addrs.end(); ++it) { IM::BaseDefine::IpAddr* addr = msg.add_ip_addr_list(); *addr = *it; log(\u0026#34;Upload file_client_conn addr info, ip=%s, port=%d\u0026#34;, addr-\u0026gt;ip().c_str(), addr-\u0026gt;port()); } SendMessageLite(this, SID_OTHER, CID_OTHER_FILE_SERVER_IP_RSP, pPdu-\u0026gt;GetSeqNum(), \u0026amp;msg); } 得到的信息是file_server侦听的ip地址和端口号，默认配置的端口号是8600。也就是说file_server的8600用于客户端连接，8601端口用于msg_server连接。这样，客户端需要传输文件（注意：不是聊天图片，聊天图片使用另外一个服务msfs进行传输），会先告诉msg_server它需要进行文件传输，msg_server收到消息后告诉客户端，你连file_server来传输文件吧，并把file_server的地址和端口号告诉客户端。客户端这个时候连接file_server进行文件传输。我们来具体看一看这个流程的细节信息：\n客户端发包给msg_server说要进行文件发送 然后选择一个文件：\npc客户端发送文件逻辑：\n//pc客户端代码(Modules工程SessionLayout.cpp) void SessionLayout::Notify(TNotifyUI\u0026amp; msg) { ... //省略无关代码 else if (msg.pSender == m_pBtnsendfile) //文件传输 { module::UserInfoEntity userInfo; if (!module::getUserListModule()-\u0026gt;getUserInfoBySId(m_sId, userInfo)) { LOG__(ERR, _T(\u0026#34;SendFile can\u0026#39;t find the sid\u0026#34;)); return; } CFileDialog\tfileDlg(TRUE, NULL, NULL, OFN_HIDEREADONLY | OFN_FILEMUSTEXIST , _T(\u0026#34;文件|*.","title":"08 服务器端file_server源码分析"},{"content":"09 服务器端route_server源码分析 route_server的作用主要是用户不同msg_server之间消息路由，其框架部分和前面的服务类似，没有什么好说的。我们这里重点介绍下它的业务代码，也就是其路由细节：\nvoid CRouteConn::HandlePdu(CImPdu* pPdu) { switch (pPdu-\u0026gt;GetCommandId()) { case CID_OTHER_HEARTBEAT: // do not take any action, heart beat only update m_last_recv_tick break; case CID_OTHER_ONLINE_USER_INFO: _HandleOnlineUserInfo( pPdu ); break; case CID_OTHER_USER_STATUS_UPDATE: _HandleUserStatusUpdate( pPdu ); break; case CID_OTHER_ROLE_SET: _HandleRoleSet( pPdu ); break; case CID_BUDDY_LIST_USERS_STATUS_REQUEST: _HandleUsersStatusRequest( pPdu ); break; case CID_MSG_DATA: case CID_SWITCH_P2P_CMD: case CID_MSG_READ_NOTIFY: case CID_OTHER_SERVER_KICK_USER: case CID_GROUP_CHANGE_MEMBER_NOTIFY: case CID_FILE_NOTIFY: case CID_BUDDY_LIST_REMOVE_SESSION_NOTIFY: _BroadcastMsg(pPdu, this); break; case CID_BUDDY_LIST_SIGN_INFO_CHANGED_NOTIFY: _BroadcastMsg(pPdu); break; default: log(\u0026#34;CRouteConn::HandlePdu, wrong cmd id: %d \u0026#34;, pPdu-\u0026gt;GetCommandId()); break; } } 上面是route_server处理的消息类型，我们逐一来介绍：\nCID_OTHER_ONLINE_USER_INFO 这个消息是msg_server连接上route_server后告知route_server自己上面的用户登录情况。route_server处理后，只是简单地记录一下每个msg_server上的用户数量和用户id：\nvoid CRouteConn::_HandleOnlineUserInfo(CImPdu* pPdu) { IM::Server::IMOnlineUserInfo msg; CHECK_PB_PARSE_MSG(msg.ParseFromArray(pPdu-\u0026gt;GetBodyData(), pPdu-\u0026gt;GetBodyLength())); uint32_t user_count = msg.user_stat_list_size(); log(\u0026#34;HandleOnlineUserInfo, user_cnt=%u \u0026#34;, user_count); for (uint32_t i = 0; i \u0026lt; user_count; i++) { IM::BaseDefine::ServerUserStat server_user_stat = msg.user_stat_list(i); _UpdateUserStatus(server_user_stat.user_id(), server_user_stat.status(), server_user_stat.client_type()); } } CID_OTHER_USER_STATUS_UPDATE 这个消息是当某个msg_server上有用户上下线时，msg_server会给route_server发送自己最近的用户数量和在线用户id信息，route_server的处理也就是更新下记录的该msg_server上的用户数量和用户id。\nCID_OTHER_ROLE_SET 这个消息没看懂，感觉是确定主从关系的，不过感觉没什么用？\nCID_OTHER_GET_DEVICE_TOKEN_RSP 这个消息用户获取某个用户的登录情况，比如pc登录、安卓版登录还是ios登录，用于某些特殊消息的处理，比如文件发送不会推给移动在线的用户。\nCID_MSG_DATA: CID_SWITCH_P2P_CMD: CID_MSG_READ_NOTIFY: CID_OTHER_SERVER_KICK_USER: CID_GROUP_CHANGE_MEMBER_NOTIFY: CID_FILE_NOTIFY: CID_BUDDY_LIST_REMOVE_SESSION_NOTIFY\nCID_BUDDY_LIST_SIGN_INFO_CHANGED_NOTIFY\n这几个消息都是往外广播消息，由于msg_server 可以配置多个，A给B发了一条消息，必须广播在各个msg_server 才能知道B到底在哪个msg_server上。\nvoid CRouteConn::_BroadcastMsg(CImPdu* pPdu, CRouteConn* pFromConn) { ConnMap_t::iterator it; for (it = g_route_conn_map.begin(); it != g_route_conn_map.end(); it++) { CRouteConn* pRouteConn = (CRouteConn*)it-\u0026gt;second; if (pRouteConn != pFromConn) { pRouteConn-\u0026gt;SendPdu(pPdu); } } } 也就是说CRouteConn代表着到msg_server的连接。\nroute_server的介绍就这么多了，虽然比较简单，但是这种路由的思想却是非常值得我们学习。网络通信数据包的在不同ip地址的路由最终被送达目的地，也就是这个原理。\n","permalink":"https://haokiu.com/blog/d337b00514f346dcb055e1a411da83d8/","summary":"09 服务器端route_server源码分析 route_server的作用主要是用户不同msg_server之间消息路由，其框架部分和前面的服务类似，没有什么好说的。我们这里重点介绍下它的业务代码，也就是其路由细节：\nvoid CRouteConn::HandlePdu(CImPdu* pPdu) { switch (pPdu-\u0026gt;GetCommandId()) { case CID_OTHER_HEARTBEAT: // do not take any action, heart beat only update m_last_recv_tick break; case CID_OTHER_ONLINE_USER_INFO: _HandleOnlineUserInfo( pPdu ); break; case CID_OTHER_USER_STATUS_UPDATE: _HandleUserStatusUpdate( pPdu ); break; case CID_OTHER_ROLE_SET: _HandleRoleSet( pPdu ); break; case CID_BUDDY_LIST_USERS_STATUS_REQUEST: _HandleUsersStatusRequest( pPdu ); break; case CID_MSG_DATA: case CID_SWITCH_P2P_CMD: case CID_MSG_READ_NOTIFY: case CID_OTHER_SERVER_KICK_USER: case CID_GROUP_CHANGE_MEMBER_NOTIFY: case CID_FILE_NOTIFY: case CID_BUDDY_LIST_REMOVE_SESSION_NOTIFY: _BroadcastMsg(pPdu, this); break; case CID_BUDDY_LIST_SIGN_INFO_CHANGED_NOTIFY: _BroadcastMsg(pPdu); break; default: log(\u0026#34;CRouteConn::HandlePdu, wrong cmd id: %d \u0026#34;, pPdu-\u0026gt;GetCommandId()); break; } } 上面是route_server处理的消息类型，我们逐一来介绍：\nCID_OTHER_ONLINE_USER_INFO 这个消息是msg_server连接上route_server后告知route_server自己上面的用户登录情况。route_server处理后，只是简单地记录一下每个msg_server上的用户数量和用户id：\nvoid CRouteConn::_HandleOnlineUserInfo(CImPdu* pPdu) { IM::Server::IMOnlineUserInfo msg; CHECK_PB_PARSE_MSG(msg.ParseFromArray(pPdu-\u0026gt;GetBodyData(), pPdu-\u0026gt;GetBodyLength())); uint32_t user_count = msg.user_stat_list_size(); log(\u0026#34;HandleOnlineUserInfo, user_cnt=%u \u0026#34;, user_count); for (uint32_t i = 0; i \u0026lt; user_count; i++) { IM::BaseDefine::ServerUserStat server_user_stat = msg.","title":"09 服务器端route_server源码分析"},{"content":"1 游戏服务器开发的基本体系与服务器端开发的一些建议 近年来，我身边的朋友有很多都从web转向了游戏开发。他们以前都没有做过游戏服务器开发，更谈不上什么经验，而从网上找的例子或游戏方面的知识，又是那么的少，那么的零散。当他们进入游戏公司时，显得一脸茫然。如果是大公司还好点，起码有人带带，能学点经验，但是有些人是直接进入了小公司，甚至这些小公司只有他一个后台。他们一肩扛起了公司的游戏后端的研发，也扛起了公司的成败。他们也非常尽力，他们也想把游戏的后端做好。可是就是因为没什么经验，刚开始时以为做游戏服务器和做web差不多，但是经过一段时间之后，才发现代码太多，太乱了，一看代码都想重构，都是踩着坑往前走。\n这里我把一些游戏开发方面的东西整理一下，希望能对那些想做游戏服务器开发的朋友有所帮助。\n首先，要明确一点，做游戏服务器开发和做传统的web开发有着本质的区别。游戏服务器开发，如果没有经验，一开始根本没有一个明确清析的目标，不像web那样，有些明确的MVC架构，往往就是为了尽快满足策划的需求，尽快的实现功能，尽快能让游戏跑起来。但是随着功能越来越多，在老代码上面修改的越来越频繁，游戏测试时暴露出来的一堆bug，更让人觉得束手无策，这个时候我们想到了重构，想到了架构的设计。 游戏的构架设计非常重要，好的构架代码清析，责任明确，扩展性强，易调试。这些会为我们的开发省去不少时间。**那要怎么样设计游戏的构架呢？可能每个游戏都不一样，但是本质上还是差不多的。 对于游戏服务器的构架设计，我们首先要了解游戏的服务器构架都有什么组成的？**一款游戏到上线，**需要具备哪些功能？**有些人可能会说，只要让游戏跑起来，访问服务器不出问题不就行了吗？答案是不行的，游戏构架本身代表的是一个体系，它包括：\n系统初始化 游戏逻辑 数据库系统 缓存系统 游戏日志 游戏管理工具 公共服务组件 这一系统的东西都是不可少的，它们共同服务于游戏的整个运营过程。我们一点点来介绍各个系统的功能。\n一，系统初始化 系统初始化是在没有客户端连接的时候，服务器启动时所需要做的工作。基本上就是配置文件的读取，初始化系统参数。\n但是我们必须要考虑的是：\n系统初始化需要的参数配置在哪儿，是配置在本地服务器，还是配置在数据库； 服务器启动的时候去数据库取； 配置的修改需不需要重启服务器等。 二，游戏逻辑 游戏逻辑是游戏的核心功能实现，也是整个游戏的服务中心，它被开发的好坏，直接决定了游戏服务器在运行中的性能。那在游戏逻辑的开发中我们要注意些什么呢？ 游戏是一种网络交互比较强的业务，好的底层通信，可以最大化游戏的性能，增加单台服务器处理的同时在线人数，给游戏带来更好的体验，至少不容易出现因为网络层导致的数据交互卡顿的现象。在这里我推荐使用Netty，它是目前最流行的NIO框架，它的用法可以在我之前的文章中查看，这里不再多说了。 有人疑问，代码也需要分层次？这个是当然了，不同的代码，代表了不同的功能实现。现在的开发语言都是面向对象的，如果我们不加思考，不加整理的把功能代码乱堆一起，起始看起来是快速实现了功能，但是到后期，如果要修改需求，或在原来的代码上增加新的需求，那真是被自己打败了。所以代码一定要分层，主要有以下几层：\n**协议层，**也叫前后台交互层，它主要负责与前台交互协议的解析和返回数据。在这一层基本上没有什么业务逻辑实现。**与前台交互的数据都在这一层开始，也在这一层终止。**比如你使用了Netty框架，那么Netty的ChannelHandlerContext即Ctx只能出现在这一层，他不能出现到游戏业务逻辑代码的实现中，接收到客户端的请求，在这一层把需要的参数解析出来，再把参数传到业务逻辑方法中，业务逻辑方法处理完后，把要返回给客户端的数据再返回到这一层，在这一层组织数据，返回给客户端，这样就可以把业务逻辑和网络层分离，业务逻辑只关心业务实现，而且也方便对业务逻辑进行单元测试。 业务逻辑层，这里处理真正的游戏逻辑，该计算价格计算价格，该通关的通关，该计时的计时。该保存数据的保存数据。但是这一层不直接操作缓存或数据库，只是处理游戏逻辑计算。因为业务逻辑层是整个游戏事件的处理核心，所以他的处理是否正确直接决定游戏的正确性。所以这一层的代码要尽量使用面向对象的方法去实现。**不要出现重复代码或相似的功能进行复制粘贴，这样修改起来非常不方便，可能是修改了某一处，而忘记了修改另外同样的代码。还要考虑每个方法都是可测试的**，一个方法的行数最好不要超过一百行。另外，可以多看看设计模式的书，它可以帮助我们设计出灵活，整洁的代码。 三，数据库系统 数据库是存储数据库的核心，但是游戏数据在存储到数据库的时候会经过网络和磁盘的IO,它的访问速度相对于内存来说是很慢的。一般来说，每次访问数据库都要和数据库建立连接，访问完成之后，为了节省数据库的连接资源，要再把连接断开。\n这样无形中又为服务器增加了开销，在大量的数据访问时，可能会更慢，而游戏又是要求低延时的，这时该怎么办呢？我们想到了数据库连接池，即把访问数据库的连接放到一个地方管理，用完我不断开，用的时候去那拿，用完再放回去。这样不用每次都建立新的连接了。\n但是如果要我们自己去实现一套连接池管理组件的话，需要时间不说，对技术的把控也是一个考验，还要再经过测试等等，幸好互联网开源的今天，有一些现成的可以使用，这里推荐Mybatis，即实现了代码与SQL的分离，又有足够的SQL编写的灵活性，是一个不错的选择。\n四，缓存系统 游戏中，客户端与服务器的交互是要求低延迟的，延迟越低，用户体验越好。像之前说过的一样，低延迟就是要求服务器处理业务尽量的快，客户端一个请求过来，要在最短的时间内响应结果，最低不得超过500ms，因为加上来回的网络传输耗时，基本上就是600ms-到700ms了，再长玩家就会觉得游戏卡了。\n如果直接从数据库中取数据，处理完之后再存回数据库的话，这个性能是跟不上的。在服务器，数据在内存中处理是最快的，所以我们要把一部分常用的数据提前加载到内存中，比如说游戏数据配置表，经常登陆的玩家数据等。这样在处理业务时，就不用走数据库了，直接从内存中取就可以了，速度更快。\n游戏中常见的缓存有两种：\n直接把数据存储在jvm或服务器内存中 使用第三方的缓存工具，这里推荐Redis，详细的用法可以自己去查询。（本公号内有系列文章，详情见【菜单栏】- 【技术文章】 - 【基础系列】 - 【实战R1，实战R2】） 五，游戏日志 日志是个好东西呀，**一个游戏中更不能少了日志，而且日志一定要记录的详细。**它是玩家在整个游戏中的行为记录，有了这个记录，我们就可以分析玩家的行为，查找游戏的不足，在处理玩家在游戏中的问题时，日志也是一个良好的凭证和快速处理方式。 在游戏中，日志分为：\n系统日志，主要记录游戏服务器的系统情况。比如：数据库能否正常连接，服务器是否正常启动，数据是否正常加载； 玩家行为日志，比如玩家发送了什么请求，得到了什么物品，消费了多少货币等等； **统计日志，**这种日志是对游戏中所有玩家某种行为的一种统计，根据这个统计来分析大部分玩家的行为，得出一些共性或不同之处，以方法运营做不同的活动吸引用户消费。 在构架设计中，日志记录一定要做为一种强制行为，因为不强制的话，可能由于某种原因某个功能忘记加日志了，那么当这个功能出问题了，或者运营跟我们要这个功能的一些数据库，就傻眼了。又得加需求，改代码了。日志一定要设计一种良好的格式，日志记录的数据要容易读取，分解。日志行为可以用枚举描述，在功能最后的处理方法里面加上这个枚举做为参数，这样不管谁在调用这个方法时，都要去加参数描述。 俗话说，工欲善其事，必先利其器。**游戏管理工具是对游戏运行中的一系列问题处理的一种工具。**它不仅是给开发人员用，大多数是给运营使用。游戏上线后，我们需要针对线上的问题进行不同的处理。不可能把所有问题都让程序员去处理吧，于是程序员们想到了一个办法，给你们做一个工具，你们爱谁处理谁处理去吧。\n六， 游戏管理工具 游戏管理工具是一个不断增涨的系统，因为它很多时候是伴随着游戏中遇到的问题而实现的。\n但是根据经验，有一些功能是必须有的，比如：\n服务器管理，主要负责服务器的开启，关闭，服务器配置信息，玩家信息查询； 玩家管理，比如踢人，封号； 统计查询，玩家行为日志查询，统计查询，次留率查询，邮件服务，修改玩家数据等。 根据游戏的不同要求，**凡是可以能过工具实现的，都做到游戏管理工具里面。**它是针对所有服务器的管理。\n一个好的，全的游戏管理工具，可以提高游戏运营中遇到问题处理的效率，为玩家提供更好的服务。\n七，公共组件 公共组件是为游戏运行中提供公共的服务。例如：\n充值服务器，我们没必须一个服用一个充值，而且你也不能对外提供多个充值服务器地址，和第三方公司对接，他们绝对不干，这是要疯呀； 还有运营搞活动时的礼包码； 还有注册用户的管理，玩家一个注册账号可以进不同的区等。 这些都是针对所有区服提供的服务，所以要单独做，与游戏逻辑分开，这样方便管理，部署和负载均衡。\n还有SDK的登陆验证，现在手游比较多，与渠道对接里要进行验证，这往往是很多http请求，速度慢，所以这个也要拿出来单独做，不要在游戏逻辑中去验证，因为网络IO的访问时间是不可控制的，http是阻塞的请求。\n所以，综上来看，一个游戏服务器起码有几个大的功能模块组成：\n游戏逻辑工程； 日志处理工程； 充值工程； 游戏管理工具工程； 用户登陆工程； 公共活动工程等。 根据游戏的不同需要，可能还有其它的。所在构架的设计中，一定要考虑到系统的分布式部署，尽量把公共的功能拆出来做，这样可以增强系统的可扩展性。\n服务器端开发的一些建议 本文作为游戏服务器端开发的基本大纲，是游戏实践开发中的总结。\n第一部分 —— 专业基础，用于指导招聘和实习考核； 第二部分 —— 游戏入门，讲述游戏服务器端开发的基本要点； 第三部分 —— 服务端架构，介绍架构设计中的一些基本原则。 希望能帮到大家！\n一、专业基础 1.1网络 1.1.1理解TCP/IP协议 网络传输模型 滑动窗口技术 建立连接的三次握手与断开连接的四次握手 连接建立与断开过程中的各种状态 TCP/IP协议的传输效率 思考：\n请解释DOS攻击与DRDOS攻击的基本原理 一个100Byte数据包，精简到50Byte, 其传输效率提高了50% TIMEWAIT状态怎么解释？ 1.1.2掌握常用的网络通信模型 Select Epoll，边缘触发与平台出发点区别与应用 Select与Epoll的区别及应用 1.2存储 计算机系统存储体系 程序运行时的内存结构 计算机文件系统，页表结构 内存池与对象池的实现原理，应用场景与区别 关系数据库MySQL的使用（本公众号内有系列文章，详情见【菜单】-【 共享内存 1.3程序 对C/C++语言有较深的理解 深刻理解接口，封装与多态，并且有实践经验 深刻理解常用的数据结构：数组，链表，二叉树，哈希表 熟悉常用的算法及相关复杂度：冒泡排序，快速排序 二、游戏开发入门 2.1防御式编程 不要相信客户端数据，一定要检验。作为服务器端你无法确定你的客户端是谁，你也不能假定它是善意的，请做好自我保护。(这是判断一个服务器端程序员是否入门的基本标准) **务必对于函数的传人参数和返回值进行合法性判断，**内部子系统，功能模块之间不要太过信任，要求低耦合，高内聚。 插件式的模块设计，模块功能的健壮性应该是内建的，尽量减少模块间耦合。\n2.2设计模式 **道法自然。**不要迷信，迷恋设计模式，更不要生搬硬套 简化，简化，再简化，用最简单的办法解决问题 借大宝一句话：设计本天成，妙手偶得之\n2.3网络模型 自造轮子: Select, Epoll， Epoll一定比Select高效吗？ 开源框架: Libevent, libev, ACE。（本公众号内有Libevent源码详解，详情见【菜单】-【开源软件】-【源码分析】-【网络库I】） 2.4数据持久化 自定义文件存储，如《梦幻西游》 关系数据库: MySQL NO-SQL数据库: MongoDB 选择存储系统要考虑到因素：稳定性，性能，可扩展性 2.5内存管理 使用内存池和对象池，禁止运行期间动态分配内存 对于输入输出的指针参数，严格检查，宁滥勿缺 写内存保护，使用带内存保护的函数(strncpy, memcpy, snprintf, vsnprintf等) 严防数组下标越界 防止读内存溢出，确保字符串以\u0026rsquo;\\0\u0026rsquo;结束 2.6日志系统 简单高效，大量日志操作不应该影响程序性能 稳定，做到服务器崩溃是日志不丢失 完备，玩家关键操作一定要记日志，理想的情况是通过日志能重建任何时刻的玩家数据 开关，开发日志的要加级别开关控制 2.7通信协议 采用PDL(Protocol Design Language)， 如Protobuf，可以同时生成前后端代码，减少前后端协议联调成本， 扩展性好 JSON，文本协议，简单，自解释，无联调成本，扩展性好，也很方便进行包过滤以及写日志 自定义二进制协议，精简，有高效的传输性能，完全可控，几乎无扩展性 2.8全局唯一Key（GUID） 为合服做准备 方便追踪道具，装备流向 每个角色，装备，道具都应对应有全局唯一Key 2.9多线程与同步 消息队列进行同步化处理 2.10状态机 强化角色的状态 前置状态的检查校验 2.11数据包操作 合并, 同一帧内的数据包进行合并，减少IO操作次数 单副本, 用一个包尽量只保存一份，减少内存复制次数 AOI同步中减少中间过程无用数据包 2.12状态监控 随时监控服务器内部状态 内存池，对象池使用情况 帧处理时间 网络IO 包处理性能 各种业务逻辑的处理次数 2.13包频率控制 基于每个玩家每条协议的包频率控制，瘫痪变速齿轮 2.14开关控制 每个模块都有开关，可以紧急关闭任何出问题的功能模块 2.15反外挂反作弊 包频率控制可以消灭变速齿轮 包id自增校验，可以消灭WPE 包校验码可以消灭或者拦截篡改的包 图形识别码，可以踢掉99%非人的操作 魔高一尺，道高一丈 2.16热更新 核心配置逻辑的热更新，如防沉迷系统，包频率控制，开关控制等 代码基本热更新，如Erlang，Lua等 2.17防刷 关键系统资源（如元宝，精力值，道具，装备等）的产出记日志 资源的产出和消耗尽量依赖两个或以上的独立条件的检测 严格检查各项操作的前置条件 校验参数合法性 2.18防崩溃 系统底层与具体业务逻辑无关，可以用大量的机器人压力测试暴露各种bug，确保稳定 业务逻辑建议使用脚本 系统性的保证游戏不会崩溃 2.19性能优化 IO操作异步化 IO操作合并缓写 （事务性的提交db操作，包合并，文件日志缓写） Cache机制 减少竞态条件 (避免频繁进出切换，尽量减少锁定使用，多线程不一定由于单线程) 多线程不一定比单线程快 减少内存复制 自己测试，用数据说话，别猜 2.20运营支持 接口支持：实时查询，控制指令，数据监控，客服处理等 实现考虑提供http接口 2.21容灾与故障预案 略\n三、服务器端架构 3.1什么是好的架构？ 满足业务要求 能迅速的实现策划需求，响应需求变更 系统级的稳定性保障 简化开发。将复杂性控制在架构底层，降低对开发人员的技术要求，逻辑开发不依赖于开发人员本身强大的技术实力，提高开发效率 完善的运营支撑体系 3.2架构实践的思考 简单，满足需求的架构就是好架构 设计性能，抓住重要的20%， 没必要从程序代码里面去抠性能 热更新是必须的 人难免会犯错，尽可能的用一套机制去保障逻辑的健壮性 游戏服务器的设计是一项颇有挑战性的工作，游戏服务器的发展也由以前的单服结构转变为多服机构，甚至出现了bigworld引擎的分布式解决方案，最近了解到Unreal的服务器解决方案atlas也是基于集群的方式。\n负载均衡是一个很复杂的课题，这里暂不谈bigworld和atlas的这类服务器的设计，更多的是基于功能和场景划分服务器结构。\n首先说一下思路，服务器划分基于以下原则：\n分离游戏中占用系统资源（cpu，内存，IO等）较多的功能，独立成服务器。 在同一服务器架构下的不同游戏，应尽可能的复用某些服务器（进程级别的复用）。 以多线程并发的编程方式适应多核处理器。 宁可在服务器之间多复制数据，也要保持清晰的数据流向。 主要按照场景划分进程，若需按功能划分，必须保持整个逻辑足够的简单，并满足以上1，2点。 服务器结构图： 各个服务器的简要说明： Gateway 是应用网关，主要用于保持和client的连接，该服务器需要2种IO：\n对client采用高并发连接，低吞吐量的网络模型，如IOCP等 对服务器采用高吞吐量连接，如阻塞或异步IO。 网关主要有以下用途：\n分担了网络IO资源，同时，也分担了网络消息包的加解密，压缩解压等cpu密集的操作。 隔离了client和内部服务器组，对client来说，它只需要知道网关的相关信息即可（ip和port）。client由于一直和网关保持常连接，所以切换场景服务器等操作对client来说是透明的。 维护玩家登录状态。 World Server 是一个控制中心，它负责把各种计算资源分布到各个服务器，它具有以下职责：\n** **管理和维护多个Scene Server。 管理和维护多个功能服务器，主要是同步数据到功能服务器。 复杂转发其他服务器和Gateway之间的数据。 实现其他需要跨场景的功能，如组队，聊天，帮派等。 Phys Server 主要用于玩家移动，碰撞等检测。 所有玩家的移动类操作都在该服务器上做检查，所以该服务器本身具备所有地图的地形等相关信息。具体检查过程是这样的：首先，Worldserver收到一个移动信息，WorldServer收到后向Phys Server请求检查，Phys Server检查成功后再返回给world Server，然后world server传递给相应的Scene Server。\nScene Server场景服务器，按场景划分，每个服务器负责的场景应该是可以配置的。理想情况下是可以动态调节的。\nItemMgr Server 物品管理服务器，负责所有物品的生产过程。在该服务器上存储一个物品掉落数据库，服务器初始化的时候载入到内存。任何需要产生物品的服务器均与该服务器直接通信。\nAIServer 又一个功能服务器，负责管理所有NPC的AI。AI服务器通常有2个输入：\n一个是Scene Server发送过来的玩家相关操作信息 另一个时钟Timer驱动 在这个设计中，对其他服务器来说，AIServer就是一个拥有很多个NPC的客户端。AIserver需要同步所有与AI相关的数据，包括很多玩家数据。由于AIServer的Timer驱动特性，可在很大程度上使用TBB程序库来发挥多核的性能。\n把网络游戏服务器分拆成多个进程，分开部署。\n这种设计的好处是模块自然分离，可以单独设计。分担负荷，可以提高整个系统的承载能力。 缺点在于，网络环境并不那么可靠。跨进程通讯有一定的不可预知性。服务器间通讯往往难以架设调试环境，并很容易把事情搅成一团糨糊。而且正确高效的管理多连接，对程序员来说也是一项挑战。 前些年，我也曾写过好几篇与之相关的设计。这几天在思考一个问题：**如果我们要做一个底层通用模块，让后续开发更为方便。到底要解决怎样的需求？**这个需求应该是单一且基础的，每个应用都需要的。 正如 TCP 协议解决了互联网上稳定可靠的点对点数据流通讯一样。游戏世界实际需要的是一个稳定可靠的在游戏系统内的点对点通讯需要。 我们可以在一条 TCP 连接之上做到这一点。一旦实现，可以给游戏服务的开发带来极大的方便。 可以把游戏系统内的各项服务，包括并不限于登陆，拍卖，战斗场景，数据服务，等等独立服务看成网络上的若干终端。每个玩家也可以是一个独立终端。它们一起构成一个网络。在这个网络之上，终端之间可以进行可靠的连接和通讯。 实现可以是这样的：\n每个虚拟终端都在游戏虚拟网络(Game Network)上有一个唯一地址 (Game Network Address , GNA) 。这个地址可以预先设定，也可以动态分配。每个终端都可以通过游戏网络的若干接入点 ( GNAP ) 通过唯一一条 TCP 连接接入网络。 接入过程需要通过鉴权。 鉴权过程依赖内部的安全机制，可以包括密码证书，或是特别的接入点区分。（例如，玩家接入网络就需要特定的接入点，这个接入点接入的终端都一定是玩家） 鉴权通过后，网络为终端分配一个固定的游戏域名。例如，玩家进入会分配到 player.12345 这样的域名，数据库接入可能分配到 database 。 游戏网络默认提供一个域名查询服务（这个服务可以通过鉴权的过程注册到网络中），让每个终端都能通过域名查询到对应的地址。 然后，游戏网络里所有合法接入的终端都可以通过其地址相互发起连接并通讯了。 整个协议建立在 TCP 协议之上，工作于唯一的这个 TCP 连接上。和直接使用 TCP 连接不同。游戏网络中每个终端之间相互发起连接都是可靠的。不仅玩家可以向某个服务发起连接，反过来也是可以的。玩家之间的直接连接也是可行的（是否允许这样，取决于具体设计）。 由于每个虚拟连接都是建立在单一的 TCP 连接之上。所以减少了互连网上发起 TCP 连接的各种不可靠性。鉴权过程也是一次性唯一的。 并且我们提供域名反查服务，我们的游戏服务可以清楚且安全的知道连接过来的是谁。 系统可以设计为，**游戏网络上每个终端离网，域名服务将广播这条消息，通知所有人。这种广播服务在互联网上难以做到，但无论是广播还是组播，在这个虚拟游戏网络中都是可行的。 在这种设计上。在逻辑层面，我们可以**让玩家直接把聊天信息从玩家客互端发送到聊天服务器，而不需要建立多余的 TCP 连接，也不需要对转发处理聊天消息做多余的处理。聊天服务器可以独立的存在于游戏网络。也****可以让广播服务主动向玩家推送消息，由服务器向玩家发起连接，而不是所有连接请求都是由玩家客互端发起。 虚拟游戏网络的构成是一个独立的层次，完全可以撇开具体游戏逻辑来实现，并能够单独去按承载量考虑具体设计方案。非常利于剥离出具体游戏项目来开发并优化。 最终，我们或许需要的一套 C 库，用于游戏网络内的通讯。api 可以和 socket api 类似。额外多两条接入与离开游戏网络即可。 ","permalink":"https://haokiu.com/blog/867310d7f5a74f758c1745b3083cfcc8/","summary":"1 游戏服务器开发的基本体系与服务器端开发的一些建议 近年来，我身边的朋友有很多都从web转向了游戏开发。他们以前都没有做过游戏服务器开发，更谈不上什么经验，而从网上找的例子或游戏方面的知识，又是那么的少，那么的零散。当他们进入游戏公司时，显得一脸茫然。如果是大公司还好点，起码有人带带，能学点经验，但是有些人是直接进入了小公司，甚至这些小公司只有他一个后台。他们一肩扛起了公司的游戏后端的研发，也扛起了公司的成败。他们也非常尽力，他们也想把游戏的后端做好。可是就是因为没什么经验，刚开始时以为做游戏服务器和做web差不多，但是经过一段时间之后，才发现代码太多，太乱了，一看代码都想重构，都是踩着坑往前走。\n这里我把一些游戏开发方面的东西整理一下，希望能对那些想做游戏服务器开发的朋友有所帮助。\n首先，要明确一点，做游戏服务器开发和做传统的web开发有着本质的区别。游戏服务器开发，如果没有经验，一开始根本没有一个明确清析的目标，不像web那样，有些明确的MVC架构，往往就是为了尽快满足策划的需求，尽快的实现功能，尽快能让游戏跑起来。但是随着功能越来越多，在老代码上面修改的越来越频繁，游戏测试时暴露出来的一堆bug，更让人觉得束手无策，这个时候我们想到了重构，想到了架构的设计。 游戏的构架设计非常重要，好的构架代码清析，责任明确，扩展性强，易调试。这些会为我们的开发省去不少时间。**那要怎么样设计游戏的构架呢？可能每个游戏都不一样，但是本质上还是差不多的。 对于游戏服务器的构架设计，我们首先要了解游戏的服务器构架都有什么组成的？**一款游戏到上线，**需要具备哪些功能？**有些人可能会说，只要让游戏跑起来，访问服务器不出问题不就行了吗？答案是不行的，游戏构架本身代表的是一个体系，它包括：\n系统初始化 游戏逻辑 数据库系统 缓存系统 游戏日志 游戏管理工具 公共服务组件 这一系统的东西都是不可少的，它们共同服务于游戏的整个运营过程。我们一点点来介绍各个系统的功能。\n一，系统初始化 系统初始化是在没有客户端连接的时候，服务器启动时所需要做的工作。基本上就是配置文件的读取，初始化系统参数。\n但是我们必须要考虑的是：\n系统初始化需要的参数配置在哪儿，是配置在本地服务器，还是配置在数据库； 服务器启动的时候去数据库取； 配置的修改需不需要重启服务器等。 二，游戏逻辑 游戏逻辑是游戏的核心功能实现，也是整个游戏的服务中心，它被开发的好坏，直接决定了游戏服务器在运行中的性能。那在游戏逻辑的开发中我们要注意些什么呢？ 游戏是一种网络交互比较强的业务，好的底层通信，可以最大化游戏的性能，增加单台服务器处理的同时在线人数，给游戏带来更好的体验，至少不容易出现因为网络层导致的数据交互卡顿的现象。在这里我推荐使用Netty，它是目前最流行的NIO框架，它的用法可以在我之前的文章中查看，这里不再多说了。 有人疑问，代码也需要分层次？这个是当然了，不同的代码，代表了不同的功能实现。现在的开发语言都是面向对象的，如果我们不加思考，不加整理的把功能代码乱堆一起，起始看起来是快速实现了功能，但是到后期，如果要修改需求，或在原来的代码上增加新的需求，那真是被自己打败了。所以代码一定要分层，主要有以下几层：\n**协议层，**也叫前后台交互层，它主要负责与前台交互协议的解析和返回数据。在这一层基本上没有什么业务逻辑实现。**与前台交互的数据都在这一层开始，也在这一层终止。**比如你使用了Netty框架，那么Netty的ChannelHandlerContext即Ctx只能出现在这一层，他不能出现到游戏业务逻辑代码的实现中，接收到客户端的请求，在这一层把需要的参数解析出来，再把参数传到业务逻辑方法中，业务逻辑方法处理完后，把要返回给客户端的数据再返回到这一层，在这一层组织数据，返回给客户端，这样就可以把业务逻辑和网络层分离，业务逻辑只关心业务实现，而且也方便对业务逻辑进行单元测试。 业务逻辑层，这里处理真正的游戏逻辑，该计算价格计算价格，该通关的通关，该计时的计时。该保存数据的保存数据。但是这一层不直接操作缓存或数据库，只是处理游戏逻辑计算。因为业务逻辑层是整个游戏事件的处理核心，所以他的处理是否正确直接决定游戏的正确性。所以这一层的代码要尽量使用面向对象的方法去实现。**不要出现重复代码或相似的功能进行复制粘贴，这样修改起来非常不方便，可能是修改了某一处，而忘记了修改另外同样的代码。还要考虑每个方法都是可测试的**，一个方法的行数最好不要超过一百行。另外，可以多看看设计模式的书，它可以帮助我们设计出灵活，整洁的代码。 三，数据库系统 数据库是存储数据库的核心，但是游戏数据在存储到数据库的时候会经过网络和磁盘的IO,它的访问速度相对于内存来说是很慢的。一般来说，每次访问数据库都要和数据库建立连接，访问完成之后，为了节省数据库的连接资源，要再把连接断开。\n这样无形中又为服务器增加了开销，在大量的数据访问时，可能会更慢，而游戏又是要求低延时的，这时该怎么办呢？我们想到了数据库连接池，即把访问数据库的连接放到一个地方管理，用完我不断开，用的时候去那拿，用完再放回去。这样不用每次都建立新的连接了。\n但是如果要我们自己去实现一套连接池管理组件的话，需要时间不说，对技术的把控也是一个考验，还要再经过测试等等，幸好互联网开源的今天，有一些现成的可以使用，这里推荐Mybatis，即实现了代码与SQL的分离，又有足够的SQL编写的灵活性，是一个不错的选择。\n四，缓存系统 游戏中，客户端与服务器的交互是要求低延迟的，延迟越低，用户体验越好。像之前说过的一样，低延迟就是要求服务器处理业务尽量的快，客户端一个请求过来，要在最短的时间内响应结果，最低不得超过500ms，因为加上来回的网络传输耗时，基本上就是600ms-到700ms了，再长玩家就会觉得游戏卡了。\n如果直接从数据库中取数据，处理完之后再存回数据库的话，这个性能是跟不上的。在服务器，数据在内存中处理是最快的，所以我们要把一部分常用的数据提前加载到内存中，比如说游戏数据配置表，经常登陆的玩家数据等。这样在处理业务时，就不用走数据库了，直接从内存中取就可以了，速度更快。\n游戏中常见的缓存有两种：\n直接把数据存储在jvm或服务器内存中 使用第三方的缓存工具，这里推荐Redis，详细的用法可以自己去查询。（本公号内有系列文章，详情见【菜单栏】- 【技术文章】 - 【基础系列】 - 【实战R1，实战R2】） 五，游戏日志 日志是个好东西呀，**一个游戏中更不能少了日志，而且日志一定要记录的详细。**它是玩家在整个游戏中的行为记录，有了这个记录，我们就可以分析玩家的行为，查找游戏的不足，在处理玩家在游戏中的问题时，日志也是一个良好的凭证和快速处理方式。 在游戏中，日志分为：\n系统日志，主要记录游戏服务器的系统情况。比如：数据库能否正常连接，服务器是否正常启动，数据是否正常加载； 玩家行为日志，比如玩家发送了什么请求，得到了什么物品，消费了多少货币等等； **统计日志，**这种日志是对游戏中所有玩家某种行为的一种统计，根据这个统计来分析大部分玩家的行为，得出一些共性或不同之处，以方法运营做不同的活动吸引用户消费。 在构架设计中，日志记录一定要做为一种强制行为，因为不强制的话，可能由于某种原因某个功能忘记加日志了，那么当这个功能出问题了，或者运营跟我们要这个功能的一些数据库，就傻眼了。又得加需求，改代码了。日志一定要设计一种良好的格式，日志记录的数据要容易读取，分解。日志行为可以用枚举描述，在功能最后的处理方法里面加上这个枚举做为参数，这样不管谁在调用这个方法时，都要去加参数描述。 俗话说，工欲善其事，必先利其器。**游戏管理工具是对游戏运行中的一系列问题处理的一种工具。**它不仅是给开发人员用，大多数是给运营使用。游戏上线后，我们需要针对线上的问题进行不同的处理。不可能把所有问题都让程序员去处理吧，于是程序员们想到了一个办法，给你们做一个工具，你们爱谁处理谁处理去吧。\n六， 游戏管理工具 游戏管理工具是一个不断增涨的系统，因为它很多时候是伴随着游戏中遇到的问题而实现的。\n但是根据经验，有一些功能是必须有的，比如：\n服务器管理，主要负责服务器的开启，关闭，服务器配置信息，玩家信息查询； 玩家管理，比如踢人，封号； 统计查询，玩家行为日志查询，统计查询，次留率查询，邮件服务，修改玩家数据等。 根据游戏的不同要求，**凡是可以能过工具实现的，都做到游戏管理工具里面。**它是针对所有服务器的管理。\n一个好的，全的游戏管理工具，可以提高游戏运营中遇到问题处理的效率，为玩家提供更好的服务。\n七，公共组件 公共组件是为游戏运行中提供公共的服务。例如：\n充值服务器，我们没必须一个服用一个充值，而且你也不能对外提供多个充值服务器地址，和第三方公司对接，他们绝对不干，这是要疯呀； 还有运营搞活动时的礼包码； 还有注册用户的管理，玩家一个注册账号可以进不同的区等。 这些都是针对所有区服提供的服务，所以要单独做，与游戏逻辑分开，这样方便管理，部署和负载均衡。\n还有SDK的登陆验证，现在手游比较多，与渠道对接里要进行验证，这往往是很多http请求，速度慢，所以这个也要拿出来单独做，不要在游戏逻辑中去验证，因为网络IO的访问时间是不可控制的，http是阻塞的请求。\n所以，综上来看，一个游戏服务器起码有几个大的功能模块组成：\n游戏逻辑工程； 日志处理工程； 充值工程； 游戏管理工具工程； 用户登陆工程； 公共活动工程等。 根据游戏的不同需要，可能还有其它的。所在构架的设计中，一定要考虑到系统的分布式部署，尽量把公共的功能拆出来做，这样可以增强系统的可扩展性。\n服务器端开发的一些建议 本文作为游戏服务器端开发的基本大纲，是游戏实践开发中的总结。\n第一部分 —— 专业基础，用于指导招聘和实习考核； 第二部分 —— 游戏入门，讲述游戏服务器端开发的基本要点； 第三部分 —— 服务端架构，介绍架构设计中的一些基本原则。 希望能帮到大家！\n一、专业基础 1.1网络 1.1.1理解TCP/IP协议 网络传输模型 滑动窗口技术 建立连接的三次握手与断开连接的四次握手 连接建立与断开过程中的各种状态 TCP/IP协议的传输效率 思考：\n请解释DOS攻击与DRDOS攻击的基本原理 一个100Byte数据包，精简到50Byte, 其传输效率提高了50% TIMEWAIT状态怎么解释？ 1.1.2掌握常用的网络通信模型 Select Epoll，边缘触发与平台出发点区别与应用 Select与Epoll的区别及应用 1.","title":"1 游戏服务器开发的基本体系与服务器端开发的一些建议"},{"content":"10 十万在线的WebGame的数据库设计思路 服务器数量预估 在线人数预估： 在项目设计之前，需要先对运营后的服务器人数做一下预估，预计激活人数300w，活跃人数40w，同时在线10w。而服务器的设计极限则在激活人数500w，活跃人数60w，最高同时在线15w。 数据参考：\n这里之所以预计这么低的激活人数，是从整个服务器考虑的。《热血三国》是将不同的用户放在不同的服务器里，所以单一服务器的激活人数不会对服务器压力产生太 大影响。而如果将所有玩家统一到一组服务器里，则会导致用户表访问压力过大。偏低的激活人数靠定期清理不活跃账户来实现。\n数据库服务器数量估计： 服务器在搭配上，一般分为db服务器和web服务器。在这之前的运营中，通常按照1:1的方式来配置数据库和web服务器，而实际情况可以使1:2的配置比 例。不过在单一世界的设计里，单台db服务器肯定无法满足需求。之前设计过一款策略类webgame，在运营时，每秒sql数为在线人数的1~1.5倍。 不过这个测试数据，是在没有钱全面应用缓存的情况的数据，在新系统里，如果全面应用缓存，并采用类似于Memcache的软件提供数据缓存，这样数据库的访问压力将可以得到极大的缓解，因此我们暂定吧每秒sql数暂定为在线人数的1倍。正常情况下数据库的访问压力应该为 10w sql/秒 极限数据应该为15w sql/秒。 数据库使用ms sqlserver 2008，在这之前的一个策略类webgame项目，对一台CPU为 E5520核的服务器上做压力测试，得到的数据如下：\nSql数 5k CPU 50% 硬盘IO 0.5M(突发3M） 网卡流量 30Mbit/s(100M网卡） 按照上面的分析，在正常情况下，我们需要为整个系统提供20台db。Web服务端按照1:1和db做搭配，也将安排20台，预计3个机柜的服务器。\n数据库表结构划分 数据库表设计： 因为要把这么多访问量分担到不同的服务器里，原先的数据库表设计肯定不会合适。初步的想法是根据游戏的逻辑模块，将不同模块的数据库表拆分到各个服务器 里，如果按照上面的服务器预估得到的结论是4~6组服务器，实际上这个方案还是可行的。但如果是20组服务器的话，除非是一台服务器一张数据库表，但这的 设计会造成数据表太分散，在处理事务的时候，会跨多个数据库 策略类webgame一般的主要模块为：建筑物和资源、军事、英雄、物品、帮会、交易、地图。根据这些模块的应用场景，可以将数据库表分为2种类型，一种是属于玩家的数据，另外一种是公共数据。\n属于玩家的数据是指玩家个人说拥有的基地、资源、军事单位、物品等数据，它们都是围绕着玩家而产生的。 公共数据则是指由多位玩家共同组合而产生的数据，例如：账户信息、帮会、地图等。 这里划分两种数据的目的是在于他们的数据库表的划分。对于公共数据，则采用单一服务器，单一数据库表处理的方式来处理。例如帮会模块和地图模块就准备分别 用3台服务器来存储各自对应的数据库表。而对于玩家的数据，则根据用户ID采用一定的划分方式，将玩家数据打散到各个服务器里（http://blog.zhaojie.me/2010/03/sharding-by-id-characteristic.html）。\n（数据表的结构划分）\n用户表和其单表的设计思路： 这里所说的单表是指在逻辑上部队数据库表做拆分，程序在访问时只访问一个数据库。当然这只是逻辑上的单一，根据实际上的访问压力，可以将数据库文件作水平切割分布在不同的文件分区和服务器里。这部分的数据库表设计继续沿用之前的设计方案就可以了。 对于用户信息，帮会信息等数据，实际上插入和更新的频率不会太高，更多的是在查询上，因此这部分的设计重点应该是在缓存上。从以前的资料里得知Memcache服务器每秒可以响应4w次的读请求，用一台Memcache就能处理好用户和帮会信息的缓存处理。\n地图模块设计思路 地图模块： 地图在传统策略类webgame里都是以平面的方式展示和存储的。地图的移动都是在这个平面上实现。但一般来说，平面地图的设计容量都会有一个上限，一般来 地图多为400*400，他的人数上限就是16w，实际上服务器容纳3~5w人后，整张地图就会显得很拥挤了。如果要想容纳几百万人在线，平面地图的尺寸 就需要扩容得相当大了，这样玩家从地图中间移动到边缘的时间会相当恐怖，因此平面地图在这里不是很合适。因此，地图不能用平面来构造，必须是立体的方法构 造。在这里我设计了两组方案：\n立体平面空间：\n如上图所描述的，立体平面空间，就是把多块地图一层层叠加在一起，形成一个立体的空间。这样如果用户不够，再增加一个新的平面就行。游戏的背景可以根据需要 做调整（例如整个世界是被大海隔开的5片大陆组成，在这5片大陆之外，还有其它的超位面空间，这些空间自身是互不相连的，但是可以通过传送阵进行位面传 送）。这样做的好处是，用户容易理解，以往用户的操作习惯不用改变，毕竟都是在平面地图上战斗。只不过要做跨位面的战斗的移动计算上会存在问题（逻辑上的 问题：是否允许跨大陆的远征军） 用户坐标的表示方法：地图层次、x坐标、y坐标\n数据库设计方案： 采用了层次结构，只需要增加一个地图层次的字段，这个地图表就能沿用。（参考字段：ID、地图层次、X坐标、y坐标、地图类型、玩家ID、城池ID） 虽然说，加入了一个地图层次的字段能解决地图的表示问题，不过，因为整个游戏世界是单一世界的服务器，当所用地图信息存储到一张表的时候，这数据量就不容小 视。在这之前做webgame项目的时候，整张地图是预先生成好数据库记录的，当有玩家加入游戏的时候，就去修改表里的玩家ID和城池ID。同时因为地图 大小只有400400，整张表也就16w条记录。但如果是要做一个承载500w人的服务器，那地图的尺寸最好是要800800，并且地图的层次为 15~20层，就算最小的15层，按照原先的设计思路，至少需要预先插入960w条记录。 数据量看上去比较夸张，不过对于SqlServer来说也不是处理不了，并且我们还将计划把地图表单独用一台服务器来处理，其压力远小很多。不过也不能不考虑当发生性能瓶颈时的优化处理。优化的方法有两个：\n拆分：按照地图层次，把这张表拆分成15~20张表，或者拆分到15~20个数据库里 用疏矩阵存储：地图不预先生成用户的地图信息，而是有玩家加入时才插入数据。这个方案在服务器早期人数比较少时会得到良好的性能效果，但当用户人数达到一定量时，还是避免不了因为记录函数过多而导致而外的开销。 全立体空间：\n全立体空间就是取消了平面的坐标显示，用户都是在一个三维的立体地图里战斗。好处是地图不用那么分散，在移动计算让很好处理，存在的问题就是游戏在显示的时候，如何表现地图的三维效果会比较困难。 用户坐标的表示方式：x坐标 y坐标 z坐标\n数据库存储方案： 三维空间的数据库表设计结构可以和上面的表一样，而且也只能采用疏矩阵的方式存储，因为做成三维空间后，可表示的位置的记录数更多了。\n可移动基地在全立体空间的设想： 早在两年前，看过《超时空要塞F》的时候，就产生了一个想法，就是玩家的基地是可以移动的。玩家的母舰在游戏的过程中，已一定的速度在整个世界里移动。 可以移动体系的设计要点：\n用户的基地可移动 用户基地只能拥有一个（武林三国、travian都能建立多个） 空间坐标由x坐标 y坐标 z坐标 组成，并且坐标的值应为小数 同一个坐标里运行多个玩家存在，玩家的航线交叉并不会造成影响（只是为了方便计算减少判断过程） 移动的数据通过后台定时刷新 a)每个短周期(1~60s)在内存里更新坐标 b)每个长周期（10~100个短周期时间）将坐标的数据更新的数据库 攻击舰队移动的时间是按照2个阶段来进行的 a)第一个阶段是从母舰移动到目标坐标的时间 b)第二个阶段，在快到达时（前60分钟），做一个判断，判断攻击舰队的雷达能否搜索到目标的母舰坐标，能则做攻击坐标的新修正，如果不能则继续按照原先的坐标点移动。以上判断将每隔1分钟做一次，直到到达目标坐标点。如果到达目标坐标点仍然无法视为攻击失败，舰队返回 舰队的移动距离和舰队所携带的能量有关，超过移动范围的坐标，舰队是无法出发的。 部队和母舰应该是可以进行空间跳跃实现长距离的移动，不过空间跳跃需要在制定地点消耗大量的能量才能实现。 默认情况下，母舰移动速度为1格（x、y、z坐标）/天。 默认舰队的雷达查询范围为1格 默认母舰的雷达查询范围为3格 玩家数据的数据库设计 数据库的划分: 在游戏里数据交互最频繁的还是玩家的数据，他的访问量是一台服务器所不能解决的，因此我们考虑将这部分数据分担到多台服务器里。分担的方法还是做水平切 割，但这次不使用数据库自身的切割功能，而是在应用逻辑层上对数据库进行切割。根据用户的ID取模后写入对应的服务器里。 服务器1 用户ID % 服务器数量 = 0 服务器2 用户ID % 服务器数量 = 1 …… 预计每台服务器能提供6k~8k的在线用户访问，预计一共需要16台服务器。考虑到服务器的进一步扩容问题，在初期规划时，建议规划为32个数据库，每台服务器可以先放3~5个数据库，等服务器用户人数上来后，再将数据库拆分到不同的服务器里。\n用户数据库各个模块的设计: 玩家基地里的建筑物，资源，物品，英雄等相关表，基本上都是玩家独立拥有的，不存在和其他玩家交互的情况，因此这些表的设计继续沿用之前的设计就可以了。\n军事模块: 军事模块分为部队表，部队创建事件表和战斗事件表。部队表和部队创建事件都是玩家自己内部的事情，把相关的数据和玩家其他数据放在一个数据库里就行了，但是战斗事件表则会设计到两位或者多为玩家则会比较复杂一些。 战斗事件表通常记录的是A玩家（城池）对B玩家（城池）的攻击，里面有攻击部队，到达时间等信息。这个条记录和A放在一起，那么B在查询自己被攻击的记录 时，就需要访问32个数据库，反之，和B放在一起，这A查询自己部队的攻击情况时，就需要遍历32个数据库。如果和用户表一样单独把这张表拿出来，用单独 的一个服务器来处理，则会导致表过大，查询会变慢以及战斗服务器的压力过大。 在之前的项目，战斗服务器处理每场战斗大约是100ms，也就是每秒能处理10场战斗。当然你也许说可以用多线程来进行，但是使用多线程后，战斗事件的顺序可能会点到，影响用户的战术安排。 在这里，我设想，将一个表设计改为2个表：攻击事件表和被攻击事件表。这两个表的结构一样。加入A玩家发起对B玩家的攻击，那么将攻击事件加入A玩家所在 服务器里的攻击事件表，在B玩家服务器里，将数据插入被攻击事件表。然后每个数据库对应一个战斗服务器程序，这个程序在已被攻击事件表为依据，进行攻击计 算。在计算完成后，在同时删除2个表里的数据。\n好友模块: 好友表本身就可以分为2个表，已某位玩家ID为主键和对应玩家放在同一个数据库里。但是好友申请则需要另外考虑了。如果申请的申请方不可见自己发出的申 请，则只需把申请记录和被申请玩家放在一个数据里。但如果需要可见，则会麻烦一些，一种方法是参考战斗表的设计思路，分为申请表和被申请表。还有一种方法 就是把申请表独立出来，所用用户的申请都放在这张表里。作为我个人，我倾向于后面的一种方法。\n用户邮件表设计: 用户邮件虽然是属于2位用户之间的交互数据，但从整个系统的角度上来说，用单一的一张表放在单独的服务器里会更简单一些。因为邮件表的内容基本为只读内容，只存在插入和读取功能，并且用户访问的频率不是很高，可以很方便的在逻辑层和web层作缓存。\n整体架构和总结 总结： 虽然对于单一世界的webgame思考了很多，但到最后细化写成文字，也就只有这4篇短文。不是说不想深入细节去讨论，而是发现如果不做一些具体开发就没法深入写下去，因此本系列文章页就在这里点到即止，希望能给大家一些启发。\n","permalink":"https://haokiu.com/blog/ace809ec27124ecc987bcd4c7eec569f/","summary":"10 十万在线的WebGame的数据库设计思路 服务器数量预估 在线人数预估： 在项目设计之前，需要先对运营后的服务器人数做一下预估，预计激活人数300w，活跃人数40w，同时在线10w。而服务器的设计极限则在激活人数500w，活跃人数60w，最高同时在线15w。 数据参考：\n这里之所以预计这么低的激活人数，是从整个服务器考虑的。《热血三国》是将不同的用户放在不同的服务器里，所以单一服务器的激活人数不会对服务器压力产生太 大影响。而如果将所有玩家统一到一组服务器里，则会导致用户表访问压力过大。偏低的激活人数靠定期清理不活跃账户来实现。\n数据库服务器数量估计： 服务器在搭配上，一般分为db服务器和web服务器。在这之前的运营中，通常按照1:1的方式来配置数据库和web服务器，而实际情况可以使1:2的配置比 例。不过在单一世界的设计里，单台db服务器肯定无法满足需求。之前设计过一款策略类webgame，在运营时，每秒sql数为在线人数的1~1.5倍。 不过这个测试数据，是在没有钱全面应用缓存的情况的数据，在新系统里，如果全面应用缓存，并采用类似于Memcache的软件提供数据缓存，这样数据库的访问压力将可以得到极大的缓解，因此我们暂定吧每秒sql数暂定为在线人数的1倍。正常情况下数据库的访问压力应该为 10w sql/秒 极限数据应该为15w sql/秒。 数据库使用ms sqlserver 2008，在这之前的一个策略类webgame项目，对一台CPU为 E5520核的服务器上做压力测试，得到的数据如下：\nSql数 5k CPU 50% 硬盘IO 0.5M(突发3M） 网卡流量 30Mbit/s(100M网卡） 按照上面的分析，在正常情况下，我们需要为整个系统提供20台db。Web服务端按照1:1和db做搭配，也将安排20台，预计3个机柜的服务器。\n数据库表结构划分 数据库表设计： 因为要把这么多访问量分担到不同的服务器里，原先的数据库表设计肯定不会合适。初步的想法是根据游戏的逻辑模块，将不同模块的数据库表拆分到各个服务器 里，如果按照上面的服务器预估得到的结论是4~6组服务器，实际上这个方案还是可行的。但如果是20组服务器的话，除非是一台服务器一张数据库表，但这的 设计会造成数据表太分散，在处理事务的时候，会跨多个数据库 策略类webgame一般的主要模块为：建筑物和资源、军事、英雄、物品、帮会、交易、地图。根据这些模块的应用场景，可以将数据库表分为2种类型，一种是属于玩家的数据，另外一种是公共数据。\n属于玩家的数据是指玩家个人说拥有的基地、资源、军事单位、物品等数据，它们都是围绕着玩家而产生的。 公共数据则是指由多位玩家共同组合而产生的数据，例如：账户信息、帮会、地图等。 这里划分两种数据的目的是在于他们的数据库表的划分。对于公共数据，则采用单一服务器，单一数据库表处理的方式来处理。例如帮会模块和地图模块就准备分别 用3台服务器来存储各自对应的数据库表。而对于玩家的数据，则根据用户ID采用一定的划分方式，将玩家数据打散到各个服务器里（http://blog.zhaojie.me/2010/03/sharding-by-id-characteristic.html）。\n（数据表的结构划分）\n用户表和其单表的设计思路： 这里所说的单表是指在逻辑上部队数据库表做拆分，程序在访问时只访问一个数据库。当然这只是逻辑上的单一，根据实际上的访问压力，可以将数据库文件作水平切割分布在不同的文件分区和服务器里。这部分的数据库表设计继续沿用之前的设计方案就可以了。 对于用户信息，帮会信息等数据，实际上插入和更新的频率不会太高，更多的是在查询上，因此这部分的设计重点应该是在缓存上。从以前的资料里得知Memcache服务器每秒可以响应4w次的读请求，用一台Memcache就能处理好用户和帮会信息的缓存处理。\n地图模块设计思路 地图模块： 地图在传统策略类webgame里都是以平面的方式展示和存储的。地图的移动都是在这个平面上实现。但一般来说，平面地图的设计容量都会有一个上限，一般来 地图多为400*400，他的人数上限就是16w，实际上服务器容纳3~5w人后，整张地图就会显得很拥挤了。如果要想容纳几百万人在线，平面地图的尺寸 就需要扩容得相当大了，这样玩家从地图中间移动到边缘的时间会相当恐怖，因此平面地图在这里不是很合适。因此，地图不能用平面来构造，必须是立体的方法构 造。在这里我设计了两组方案：\n立体平面空间：\n如上图所描述的，立体平面空间，就是把多块地图一层层叠加在一起，形成一个立体的空间。这样如果用户不够，再增加一个新的平面就行。游戏的背景可以根据需要 做调整（例如整个世界是被大海隔开的5片大陆组成，在这5片大陆之外，还有其它的超位面空间，这些空间自身是互不相连的，但是可以通过传送阵进行位面传 送）。这样做的好处是，用户容易理解，以往用户的操作习惯不用改变，毕竟都是在平面地图上战斗。只不过要做跨位面的战斗的移动计算上会存在问题（逻辑上的 问题：是否允许跨大陆的远征军） 用户坐标的表示方法：地图层次、x坐标、y坐标\n数据库设计方案： 采用了层次结构，只需要增加一个地图层次的字段，这个地图表就能沿用。（参考字段：ID、地图层次、X坐标、y坐标、地图类型、玩家ID、城池ID） 虽然说，加入了一个地图层次的字段能解决地图的表示问题，不过，因为整个游戏世界是单一世界的服务器，当所用地图信息存储到一张表的时候，这数据量就不容小 视。在这之前做webgame项目的时候，整张地图是预先生成好数据库记录的，当有玩家加入游戏的时候，就去修改表里的玩家ID和城池ID。同时因为地图 大小只有400400，整张表也就16w条记录。但如果是要做一个承载500w人的服务器，那地图的尺寸最好是要800800，并且地图的层次为 15~20层，就算最小的15层，按照原先的设计思路，至少需要预先插入960w条记录。 数据量看上去比较夸张，不过对于SqlServer来说也不是处理不了，并且我们还将计划把地图表单独用一台服务器来处理，其压力远小很多。不过也不能不考虑当发生性能瓶颈时的优化处理。优化的方法有两个：\n拆分：按照地图层次，把这张表拆分成15~20张表，或者拆分到15~20个数据库里 用疏矩阵存储：地图不预先生成用户的地图信息，而是有玩家加入时才插入数据。这个方案在服务器早期人数比较少时会得到良好的性能效果，但当用户人数达到一定量时，还是避免不了因为记录函数过多而导致而外的开销。 全立体空间：\n全立体空间就是取消了平面的坐标显示，用户都是在一个三维的立体地图里战斗。好处是地图不用那么分散，在移动计算让很好处理，存在的问题就是游戏在显示的时候，如何表现地图的三维效果会比较困难。 用户坐标的表示方式：x坐标 y坐标 z坐标\n数据库存储方案： 三维空间的数据库表设计结构可以和上面的表一样，而且也只能采用疏矩阵的方式存储，因为做成三维空间后，可表示的位置的记录数更多了。\n可移动基地在全立体空间的设想： 早在两年前，看过《超时空要塞F》的时候，就产生了一个想法，就是玩家的基地是可以移动的。玩家的母舰在游戏的过程中，已一定的速度在整个世界里移动。 可以移动体系的设计要点：\n用户的基地可移动 用户基地只能拥有一个（武林三国、travian都能建立多个） 空间坐标由x坐标 y坐标 z坐标 组成，并且坐标的值应为小数 同一个坐标里运行多个玩家存在，玩家的航线交叉并不会造成影响（只是为了方便计算减少判断过程） 移动的数据通过后台定时刷新 a)每个短周期(1~60s)在内存里更新坐标 b)每个长周期（10~100个短周期时间）将坐标的数据更新的数据库 攻击舰队移动的时间是按照2个阶段来进行的 a)第一个阶段是从母舰移动到目标坐标的时间 b)第二个阶段，在快到达时（前60分钟），做一个判断，判断攻击舰队的雷达能否搜索到目标的母舰坐标，能则做攻击坐标的新修正，如果不能则继续按照原先的坐标点移动。以上判断将每隔1分钟做一次，直到到达目标坐标点。如果到达目标坐标点仍然无法视为攻击失败，舰队返回 舰队的移动距离和舰队所携带的能量有关，超过移动范围的坐标，舰队是无法出发的。 部队和母舰应该是可以进行空间跳跃实现长距离的移动，不过空间跳跃需要在制定地点消耗大量的能量才能实现。 默认情况下，母舰移动速度为1格（x、y、z坐标）/天。 默认舰队的雷达查询范围为1格 默认母舰的雷达查询范围为3格 玩家数据的数据库设计 数据库的划分: 在游戏里数据交互最频繁的还是玩家的数据，他的访问量是一台服务器所不能解决的，因此我们考虑将这部分数据分担到多台服务器里。分担的方法还是做水平切 割，但这次不使用数据库自身的切割功能，而是在应用逻辑层上对数据库进行切割。根据用户的ID取模后写入对应的服务器里。 服务器1 用户ID % 服务器数量 = 0 服务器2 用户ID % 服务器数量 = 1 …… 预计每台服务器能提供6k~8k的在线用户访问，预计一共需要16台服务器。考虑到服务器的进一步扩容问题，在初期规划时，建议规划为32个数据库，每台服务器可以先放3~5个数据库，等服务器用户人数上来后，再将数据库拆分到不同的服务器里。","title":"10 十万在线的WebGame的数据库设计思路"},{"content":"10 开放一个TeamTalk测试服务器地址和几个测试账号 由于TeamTalk是用于企业内部的即时通讯软件，一般客户端并不提供账号注册功能。如果你仅对TeamTalk的客户端感兴趣，你可以仅仅研究pc端和移动端代码。官方的测试服务器地址已经失效，所以我已经部署了一套TeamTalk服务器，并建立了几个测试账户可以供你使用：\ntangseng\nsunwukong\nzhubajie\nshaseng\n==================\nxiaowang\nxiaoming\nxiaozhao\nxiaoli\n==================\n以上是账户名，密码随意。我改了下服务器端的代码，密码不进行校验的。你可以填写任意密码。\npc端设置方式：\n安卓端设置方式：\n关于ios端，目前由于服务器端的push_server没有部署，暂且就不提供了。\n我专门把pc端代码和安卓端代码提取出来供大家下载：\npc端：\n下载地址：http://download.csdn.net/detail/analogous_love/9851833\n开发工具：VS2013\n安卓端：\n下载地址：http://download.csdn.net/detail/analogous_love/9851845\nIDE使用Android-studio java 1.7 gradle 2.2.1\n如果测试服务器连接不上，请通过微信 easy_coder 与我联系。\n","permalink":"https://haokiu.com/blog/601f5e2b4c0a4303a540259d9d394d0b/","summary":"10 开放一个TeamTalk测试服务器地址和几个测试账号 由于TeamTalk是用于企业内部的即时通讯软件，一般客户端并不提供账号注册功能。如果你仅对TeamTalk的客户端感兴趣，你可以仅仅研究pc端和移动端代码。官方的测试服务器地址已经失效，所以我已经部署了一套TeamTalk服务器，并建立了几个测试账户可以供你使用：\ntangseng\nsunwukong\nzhubajie\nshaseng\n==================\nxiaowang\nxiaoming\nxiaozhao\nxiaoli\n==================\n以上是账户名，密码随意。我改了下服务器端的代码，密码不进行校验的。你可以填写任意密码。\npc端设置方式：\n安卓端设置方式：\n关于ios端，目前由于服务器端的push_server没有部署，暂且就不提供了。\n我专门把pc端代码和安卓端代码提取出来供大家下载：\npc端：\n下载地址：http://download.csdn.net/detail/analogous_love/9851833\n开发工具：VS2013\n安卓端：\n下载地址：http://download.csdn.net/detail/analogous_love/9851845\nIDE使用Android-studio java 1.7 gradle 2.2.1\n如果测试服务器连接不上，请通过微信 easy_coder 与我联系。","title":"10 开放一个TeamTalk测试服务器地址和几个测试账号"},{"content":"11 pc客户端源码分析 ——写在前面的话\n在要不要写这篇文章的纠结中挣扎了好久，就我个人而已，我接触windows编程，已经六七个年头了，尤其是在我读研的三年内，基本心思都是花在学习和研究windows程序上了。我很庆幸我当初学习windows程序走了一条正确的路线：先是学习常用的windows程序原理和基本API，再学习的mfc、wtl等一些常用的框架和类库，同时看了大量windows项目的源码，如金山卫士的开源代码、filezilla、电驴源码等等。个人觉得，基础真的很重要，拿windows开发来说，当你掌握了windows的程序的基本原理，我列一下大致范围：\nwindows消息机制（消息如何产生、如何发送、如何处理，常见的消息有哪些、消息的优先级、如何自定义消息、窗体消息、常用控件消息）\ngdi原理（要熟悉gdi的各种对象，如画笔、画刷、字体、区域、裁剪、位图等，熟悉它们的API，熟悉各种gdi绘图API、当然最好也要熟悉一整套的gdi+的类，gdi与gdi+的区别）\nwindows进程与线程的概念（进程的概念、如何创建、如何结束、跨进程如何通信；线程的创建与销毁、线程间的同步与资源保护，熟悉windows常用的线程同步对象：临界区、事件、互斥体、信号量等）\nwindows内存管理（清晰地掌握一个进程地址空间的内存分布、windows堆的创建与管理等）\ndll技术（dll的生成、变量的导出、函数的导出、类的导出、如何查看dll导出哪些函数、隐式dll的加载、显示dll的加载、远程dll注入技术等）\nPE文件（一个PE文件的结构、有哪些节、如何修改、分别映射到进程地址空间的什么位置等）\nwindows SEH（结构化异常处理）\nwindows socket编程\nwindows读写文件技术（像CreateFile、WriteFile、GetFileSize等这些API应该熟练掌握、内存映射技术）\n当然很多必备的技术也不好归类到windows技术下面，比如socket编程，这涉及到很多网络的知识，比如tcp的三次握手，数据的收发等，还有就是各种字符编码的知识、以及之间的相互转换，又比如一系列的CRT函数及其对应的宽字符版本。当然如果你搞windows开发，一定要熟悉开发工具Visual Studio，熟悉其工程项目的大多数属性配置，而且要做到知其然也知其所以然。如果不是不能跨平台，我敢说VS是史上最好最强大的开发工具，没有之一！我已经有好几年年不做windows开发了，目前主要从事linux开发，但windows的很多设计思想真的很好，非常值得借鉴，而且从编码风格来说，虽然看起来有点怪异，但是非常规范和易懂。\n有了基础知识，你可以轻松地对工作中的一些问题给出解决方案，也能轻松阅读和使用市面上的那些库，比如，如果你深刻理解windows GDI，你不会在一个群里大喊，duilib某个属性为什么不起作用，你可以直接去阅读它的画法代码，如果是bug你可以改bug，如果只是你使用错误，你可以了解到正确的使用方法。所以基础这个东西，在短时间内，可能让你看不出与其他人的差别，但是从长远来看，它决定着你在技术上走的高度与深度。套用侯捷先生的一句话：勿在浮沙筑高台。\n—— 正题\n上面简单地介绍了下，我个人学习windows程序设计的一些心得吧。扯的有点远了，让我们回到正题上来，来分析TeamTalk的源码吧。当然这篇文章与前面介绍的不一样，我们不仅介绍程序的正题设计思路，还会介绍一些有意义的细节，比如一些windows开发中常用的一些细节。\n一、程序功能 我们来先看下TeamTalk pc客户端包括哪些功能：TeamTalk因为开发的初衷是用于企业内部的即时通讯软件，所以，不提供对外注册的功能，一个员工的加入一般是人事部门在后台管理系统来新增该员工信息。其功能包括登录、聊天、群聊和建讨论组，当然聊天过程中可以发文字、表情、图片和文件，还包括查看聊天记录和简单地查看某个员工的个人信息，业务功能其实不多的。下面是一些功能截图：\n二、编译方法与项目工程文件介绍 TeamTalk的pc客户端的下载地址是：https://github.com/baloonwj/TeamTalk 代码包括服务器端代码、pc端、mac端、安卓和IOS端，还有web端所有代码。\npc客户端代码的编译方法很简单：用VS2013打开win-client\\solution目录下的teamtalk.sln，编译即可。你的VS版本至少要是VS2013，因为代码中大量使用了C++11的东西，VS2013以下版本是不支持C++11的语法的。当然，如果你是VS2015的话，可以参考这篇文章来进行修改和编译：http://www.07net01.com/linux/2017/01/1795569.html\n打开teamtalk.sln之后，总共有10个解决方法，如下图所示：\n其中teamtalk是主工程，你应该将它设置成启动工程，编译完成之后就可以调试了。你可以自己配置服务器来连接进行调试，我也可以连接我的测试服务器，具体参见《TeamTalk源码分析（十） —— 开放一个TeamTalk测试服务器地址和几个测试账号》。下面先大致介绍一个各个工程的作用：\nDuilib是teamtalk使用的一款开源界面库，该界面库模仿web开发中的布局技术，使用xml文件来布局windows界面，并且在主窗口上绘制所有子控件，也就是所谓的directUI技术；\nGifSmiley是程序中用来解析和显示gif格式的图片的库，以支持gif图片的动画效果；\nhttpclient功能是程序中使用的http请求库，登录前程序会先连接服务器的login_server以获得后续需要登录的msg_server的ip地址和端口号 等信息，这里就是使用的http协议，同时聊天过程中收发的聊天图片与图片服务器msfs也使用http协议来收发这些图片；\nlibogg是一个语音库，用来解析声音文件的，因为pc客户端可能会收到移动端的语音聊天，相比较传统的*.wav、.mp3、.wma，*.ogg格式的不仅音质高，而且音频文件的体积小，腾讯的QQ游戏英雄杀中的语音也是使用这个格式的。\nlibspeex是一个音频压缩库；\nModules就是TeamTalk中使用的各种库了，展开来看下你就明白了：\nnetwork是teamtalk使用的网络通信的代码，其实teamtalk pc端和服务器端使用的是同一套网络通信库，只不过如果服务器运行在linux下，其核心的IO复用模型是epoll，而pc客户端使用的IO复用模型是select；\nspeexdec 也是和ogg格式相关的编码和解码器；\nteamtalk是主程序入口工程；\nutility包含了teamtalk中用到的一些工具类工程，比如sqlite的包装接口、md5工具类等。\n除了上面介绍的一些库以外，程序还使用了sqlite库、谷歌protobuf库、日志库yaolog等。关于yaolog可参见http://blog.csdn.net/gemo/article/details/8499692，这个日志库比较有意思的地方是可以单独打印出网络通信中的字节流的二进制形式，推荐一下，效果如下图所示（位于win-client\\bin\\teamtalk\\Debug\\log\\socket.log文件中）：\n三、程序总体框架介绍 整个程序使用了mfc框架来做一个架子，而所有的窗口和对话框都使用的是duilib，关于duilib网上有很多资料，这里不介绍duilib细节的东西了。一个mfc程序框架，使用起来也很简单，就是定义一个类集成mfc的CWinApp类，并改写其InitInstance()方法，mfc内部会替我们做好消息循环的步骤。TeamTalk相关的代码如下：\n//位于teamtalk.h中 class CteamtalkApp : public CWinApp { public: CteamtalkApp(); public: virtual BOOL InitInstance(); virtual BOOL ExitInstance(); private: /** * 创建用户目录 * * @return BOOL * @exception there is no any exception to throw. */\tBOOL _CreateUsersFolder(); /** * 创建主窗口 * * @return BOOL * @exception there is no any exception to throw. */\tBOOL _CreateMainDialog(); /** * 销毁主窗口 * * @return BOOL * @exception there is no any exception to throw. */ BOOL _DestroyMainDialog(); /** * 判断是否是单实例 * * @return BOOL * @exception there is no any exception to throw. */ BOOL _IsHaveInstance(); void _InitLog(); private: MainDialog*\tm_pMainDialog; }; 在teamtalk.cpp中定义了唯一的全局对象CteamtalkApp对象：\n接着，所有的初始化工作就是写在CteamtalkApp::InitInstance()方法中了：\nBOOL CteamtalkApp::InitInstance() { INITCOMMONCONTROLSEX InitCtrls; InitCtrls.dwSize = sizeof(InitCtrls); InitCtrls.dwICC = ICC_WIN95_CLASSES; InitCommonControlsEx(\u0026amp;InitCtrls); //log init _InitLog(); // Verify that the version of the library that we linked against is // compatible with the version of the headers we compiled against. GOOGLE_PROTOBUF_VERIFY_VERSION; LOG__(APP, _T(\u0026#34;===================================VersionNO:%d======BulidTime：%s--%s==========================\u0026#34;) , TEAMTALK_VERSION, util::utf8ToCString(__DATE__), util::utf8ToCString(__TIME__)); if (!__super::InitInstance()) { LOG__(ERR, _T(\u0026#34;__super::InitInstance failed.\u0026#34;)); return FALSE; } AfxEnableControlContainer(); //为了调试方便，暂且注释掉 //if (_IsHaveInstance()) //{ //\tLOG__(ERR, _T(\u0026#34;Had one instance,this will exit\u0026#34;)); //\tHWND hwndMain = FindWindow(_T(\u0026#34;TeamTalkMainDialog\u0026#34;), NULL); //\tif (hwndMain) //\t{ //\t::SendMessage(hwndMain, WM_START_MOGUTALKINSTANCE, NULL, NULL); //\t} //\treturn FALSE; //} //start imcore lib //在这里启动任务队列和网络IO线程 if (!imcore::IMLibCoreRunEvent()) { LOG__(ERR, _T(\u0026#34;start imcore lib failed!\u0026#34;)); } LOG__(APP, _T(\u0026#34;start imcore lib done\u0026#34;)); //start ui event //在这里创建代理窗口并启动定时器定时处理任务 if (module::getEventManager()-\u0026gt;startup() != imcore::IMCORE_OK) { LOG__(ERR, _T(\u0026#34;start ui event failed\u0026#34;)); } LOG__(APP, _T(\u0026#34;start ui event done\u0026#34;)); //create user folders _CreateUsersFolder(); //duilib初始化 CPaintManagerUI::SetInstance(AfxGetInstanceHandle()); CPaintManagerUI::SetResourcePath(CPaintManagerUI::GetInstancePath() + _T(\u0026#34;..\\\\gui\\\\\u0026#34;));//track这个设置了路径，会导致base里设置的无效。 ::CoInitialize(NULL); ::OleInitialize(NULL); //无需配置server module::TTConfig* pCfg = module::getSysConfigModule()-\u0026gt;getSystemConfig(); if (pCfg \u0026amp;\u0026amp; pCfg-\u0026gt;loginServIP.IsEmpty()) { if (!module::getSysConfigModule()-\u0026gt;showServerConfigDialog(NULL)) { LOG__(APP, _T(\u0026#34;server config canceled\u0026#34;)); return FALSE; } } if (!module::getLoginModule()-\u0026gt;showLoginDialog()) { LOG__(ERR, _T(\u0026#34;login canceled\u0026#34;)); return FALSE; } LOG__(APP,_T(\u0026#34;login success\u0026#34;)); //创建主窗口 if (!_CreateMainDialog()) { LOG__(ERR, _T(\u0026#34;Create MianDialog failed\u0026#34;)); return FALSE; } LOG__(APP, _T(\u0026#34;Create MianDialog done\u0026#34;)); CPaintManagerUI::MessageLoop(); CPaintManagerUI::Term(); return TRUE; } 上述代码大致做了以下工作：\n// 1. 初始化yaolog日志库 // 2. google protobuf的版本号检测 // 3. 启动网络通信线程检测网络数据读写，再启动一个线程创建一个队列，如果队列中有任务，则取出该任务执行 // 4. 创建支线程与UI线程的桥梁——代理窗口 // 5. 创建用户文件夹 // 6. 配置duilib的资源文件路径、初始化com库、初始化ole库 // 7. 如果没有配置登录服务器的地址，则显示配置对话框 // 8. 显示登录对话框 // 9. 登录成功后，登录对话框销毁，显示主对话框 // 10. 启动duilib的消息循环（也就是说不使用mfc的消息循环） 其它的没什么好介绍的，我们来重点介绍下第3点和第4点。先说第3点，在第3点中又会牵扯出第4点，网络通信线程的启动：\n//start imcore lib //在这里启动任务队列和网络IO线程 if (!imcore::IMLibCoreRunEvent()) { LOG__(ERR, _T(\u0026#34;start imcore lib failed!\u0026#34;)); } LOG__(APP, _T(\u0026#34;start imcore lib done\u0026#34;));\tLOG__(ERR, _T(\u0026#34;start imcore lib failed!\u0026#34;)); } LOG__(APP, _T(\u0026#34;start imcore lib done\u0026#34;)); bool IMLibCoreRunEvent() {\tLOG__(NET, _T(\u0026#34;===============================================================================\u0026#34;)); //在这里启动任务队列处理线程 getOperationManager()-\u0026gt;startup(); CAutoLock lock(\u0026amp;g_lock); if (!netlib_is_running()) { #ifdef _MSC_VER unsigned int m_dwThreadID; //在这里启动网络IO线程 g_hThreadHandle = (HANDLE)_beginthreadex(0, 0, event_run, 0, 0, (unsigned*)\u0026amp;m_dwThreadID); if (g_hThreadHandle \u0026lt; (HANDLE)2) { m_dwThreadID = 0; g_hThreadHandle = 0; } return g_hThreadHandle \u0026gt;(HANDLE)1; #else pthread_t pt; pthread_create(\u0026amp;pt, NULL, event_run, NULL); #endif } return true; } 先看getOperationManager()-\u0026gt;startup();：\nIMCoreErrorCode OperationManager::startup() { m_operationThread = std::thread([\u0026amp;] { std::unique_lock \u0026lt;std::mutex\u0026gt; lck(m_cvMutex); Operation* pOperation = nullptr; while (m_bContinue) { if (!m_bContinue) break; if (m_vecRealtimeOperations.empty()) m_CV.wait(lck); if (!m_bContinue) break; { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(m_mutexOperation); if (m_vecRealtimeOperations.empty()) continue; pOperation = m_vecRealtimeOperations.front(); m_vecRealtimeOperations.pop_front(); } if (!m_bContinue) break; if (pOperation) { pOperation-\u0026gt;process(); pOperation-\u0026gt;release(); } } }); return IMCORE_OK; } 这里利用一个C++11的新语法lamda表达式来创建一个线程，线程函数就是lamda表达式的具体内容：先从队列中取出任务，然后执行。所有的任务都继承其基类Operation，而Operation又继承接口类IOperatio，任务类根据自己具体需要做什么来改写process()方法：\nclass NETWORK_DLL Operation : public IOperation { enum OperationState { OPERATION_IDLE = 0, OPERATION_STARTING, OPERATION_RUNNING, OPERATION_CANCELLING, OPERATION_FINISHED }; public: /** @name Constructors and Destructor*/ //@{ /** * Constructor */ Operation(); Operation(const std::string\u0026amp; name); /** * Destructor */ virtual ~Operation(); //@} public: virtual void processOpertion() = 0; public: virtual void process(); virtual void release(); inline std::string name() const { return m_name; } inline void set_name(__in std::string name){ m_name = name; } private: OperationState\tm_state; std::string\tm_name; }; struct NETWORK_DLL IOperation { public: virtual void process() = 0; //private: /** * 必须让容器来释放自己 * * @return void * @exception there is no any exception to throw. */ virtual void release() = 0; }; 这里我们介绍的任务队列我们称为队列A，下文中还有一个专门做http请求的队列，我们称为队列B。\n后半部分代码其实就是启动网络检测线程，检测网络数据读写：\ng_hThreadHandle = (HANDLE)_beginthreadex(0, 0, event_run, 0, 0, (unsigned*)\u0026amp;m_dwThreadID); unsigned int __stdcall event_run(void* threadArgu) { LOG__(NET, _T(\u0026#34;event_run\u0026#34;)); netlib_init(); netlib_set_running(); netlib_eventloop(); return NULL; } void netlib_eventloop(uint32_t wait_timeout) { CEventDispatch::Instance()-\u0026gt;StartDispatch(wait_timeout); } void CEventDispatch::StartDispatch(uint32_t wait_timeout) { fd_set read_set, write_set, excep_set; timeval timeout; timeout.tv_sec = 1;\t//wait_timeout 1 second timeout.tv_usec = 0; while (running) { //_CheckTimer(); //_CheckLoop(); if (!m_read_set.fd_count \u0026amp;\u0026amp; !m_write_set.fd_count \u0026amp;\u0026amp; !m_excep_set.fd_count) { Sleep(MIN_TIMER_DURATION); continue; } m_lock.lock(); FD_ZERO(\u0026amp;read_set); FD_ZERO(\u0026amp;write_set); FD_ZERO(\u0026amp;excep_set); memcpy(\u0026amp;read_set, \u0026amp;m_read_set, sizeof(fd_set)); memcpy(\u0026amp;write_set, \u0026amp;m_write_set, sizeof(fd_set)); memcpy(\u0026amp;excep_set, \u0026amp;m_excep_set, sizeof(fd_set)); m_lock.unlock(); if (!running) break; //for (int i = 0; i \u0026lt; read_set.fd_count; i++) { //\tLOG__(NET, \u0026#34;read fd: %d\\n\u0026#34;, read_set.fd_array[i]); //} int nfds = select(0, \u0026amp;read_set, \u0026amp;write_set, \u0026amp;excep_set, \u0026amp;timeout); if (nfds == SOCKET_ERROR) { //LOG__(NET, \u0026#34;select failed, error code: %d\\n\u0026#34;, GetLastError()); Sleep(MIN_TIMER_DURATION); continue;\t// select again } if (nfds == 0) { continue; } for (u_int i = 0; i \u0026lt; read_set.fd_count; i++) { //LOG__(NET, \u0026#34;select return read count=%d\\n\u0026#34;, read_set.fd_count); SOCKET fd = read_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnRead(); pSocket-\u0026gt;ReleaseRef(); } } for (u_int i = 0; i \u0026lt; write_set.fd_count; i++) { //LOG__(NET, \u0026#34;select return write count=%d\\n\u0026#34;, write_set.fd_count); SOCKET fd = write_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnWrite(); pSocket-\u0026gt;ReleaseRef(); } } for (u_int i = 0; i \u0026lt; excep_set.fd_count; i++) { LOG__(NET, _T(\u0026#34;select return exception count=%d\u0026#34;), excep_set.fd_count); SOCKET fd = excep_set.fd_array[i]; CBaseSocket* pSocket = FindBaseSocket((net_handle_t)fd); if (pSocket) { pSocket-\u0026gt;OnClose(); pSocket-\u0026gt;ReleaseRef(); } } } } 我们举个具体的例子来说明这个三个线程的逻辑（任务队列A、网络线程和下文要介绍的专门处理http请求的任务队列B）和代理窗口的消息队列，以在登录对话框输入用户名和密码后接下来的步骤：\n//位于LoginDialog.cpp中 void LoginDialog::_DoLogin() { LOG__(APP,_T(\u0026#34;User Clicked LoginBtn\u0026#34;)); m_ptxtTip-\u0026gt;SetText(_T(\u0026#34;\u0026#34;)); CDuiString userName = m_pedtUserName-\u0026gt;GetText(); CDuiString password = m_pedtPassword-\u0026gt;GetText(); if (userName.IsEmpty()) { CString csTip = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_USERNAME_EMPTY\u0026#34;)); m_ptxtTip-\u0026gt;SetText(csTip); return; } if (password.IsEmpty()) { CString csTip = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_PASSWORD_EMPTY\u0026#34;)); m_ptxtTip-\u0026gt;SetText(csTip); return; } module::TTConfig* pCfg = module::getSysConfigModule()-\u0026gt;getSystemConfig(); pCfg-\u0026gt;userName = userName; if (m_bPassChanged) { std::string sPass = util::cStringToString(CString(password)); char* pOutData = 0; uint32_t nOutLen = 0; int retCode = EncryptPass(sPass.c_str(), sPass.length(), \u0026amp;pOutData, nOutLen); if (retCode == 0 \u0026amp;\u0026amp; nOutLen \u0026gt; 0 \u0026amp;\u0026amp; pOutData != 0) { pCfg-\u0026gt;password = std::string(pOutData, nOutLen); Free(pOutData); } else { LOG__(ERR, _T(\u0026#34;EncryptPass Failed!\u0026#34;)); CString csTip = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_LOGIN_ENCRYPT_PASE_FAIL\u0026#34;)); m_ptxtTip-\u0026gt;SetText(csTip);\treturn; } } pCfg-\u0026gt;isRememberPWD = m_pChkRememberPWD-\u0026gt;GetCheck(); module::getSysConfigModule()-\u0026gt;saveData(); CString csTxt = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_BTN_DOLOGIN\u0026#34;)); m_pBtnLogin-\u0026gt;SetText(csTxt); m_pBtnLogin-\u0026gt;SetEnabled(false); //连接登陆服务器 DoLoginServerParam param; DoLoginServerHttpOperation* pOper = new DoLoginServerHttpOperation( BIND_CALLBACK_1(LoginDialog::OnHttpCallbackOperation), param); module::getHttpPoolModule()-\u0026gt;pushHttpOperation(pOper); } 点击登录按钮之后，程序先对用户名和密码进行一些有效性校验，接着产生一个DoLoginServerHttpOperation对象，该类继承IHttpOperation，IHttpOperation再继承ICallbackOpertaion，ICallbackOpertaion再继承Operation类。这个任务会绑定一个任务完成之后的回调函数，即宏BIND_CALLBACK_1，这个宏实际上就是std::bind：\n#define BIND_CALLBACK_1(func) std::bind(\u0026amp;func, this, placeholders::_1) #define BIND_CALLBACK_2(func)\tstd::bind(\u0026amp;func, this, placeholders::_1, placeholders::_2) 往任务队列中放入任务的动作如下：\nvoid HttpPoolModule_Impl::pushHttpOperation(module::IHttpOperation* pOperaion, BOOL bHighPriority /*= FALSE*/) { if (NULL == pOperaion) { return; } CAutoLock lock(\u0026amp;m_mtxLock); if (bHighPriority) m_lstHttpOpers.push_front(pOperaion); else m_lstHttpOpers.push_back(pOperaion); _launchThread(); ::ReleaseSemaphore(m_hSemaphore, 1, NULL); return; } 其中_launchThread()会启动一个线程，该线程函数是另外一个任务队列，专门处理http任务：\nBOOL HttpPoolModule_Impl::_launchThread() { if ((int)m_vecHttpThread.size() \u0026gt;= MAX_THEAD_COUNT) { return TRUE; } TTHttpThread* pThread = new TTHttpThread(); PTR_FALSE(pThread); if (!pThread-\u0026gt;create()) { return FALSE; } Sleep(300); m_vecHttpThread.push_back(pThread); return TRUE; } 线程函数最终实际执行代码如下：\nUInt32 TTHttpThread::process() { module::IHttpOperation * pHttpOper = NULL; HttpPoolModule_Impl *pPool = m_pInstance; while (m_bContinue) { if (WAIT_OBJECT_0 != ::WaitForSingleObject(pPool-\u0026gt;m_hSemaphore, INFINITE)) { break; } if (!m_bContinue) { break; } { CAutoLock lock(\u0026amp;(pPool-\u0026gt;m_mtxLock)); if (pPool-\u0026gt;m_lstHttpOpers.empty()) pHttpOper = NULL; else { pHttpOper = pPool-\u0026gt;m_lstHttpOpers.front(); pPool-\u0026gt;m_lstHttpOpers.pop_front(); } } try { if (m_bContinue \u0026amp;\u0026amp; pHttpOper) { pHttpOper-\u0026gt;process(); pHttpOper-\u0026gt;release(); } } catch (...) { LOG__(ERR, _T(\u0026#34;TTHttpThread: Failed to execute opertaion(0x%p)\u0026#34;), pHttpOper); } } return 0; } 当这个http任务被任务队列执行时，实际执行DoLoginServerHttpOperation::processOpertion()，代码如下：\nvoid DoLoginServerHttpOperation::processOpertion() { module::TTConfig* pCfg = module::getSysConfigModule()-\u0026gt;getSystemConfig(); LOG__(APP, _T(\u0026#34;loginAddr = %s\u0026#34;), pCfg-\u0026gt;loginServIP); std::string\u0026amp; loginAddr = util::cStringToString(pCfg-\u0026gt;loginServIP); std::string url = loginAddr; DoLoginServerParam* pPamram = new DoLoginServerParam(); pPamram-\u0026gt;resMsg = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_LOGIN_HTTP_DEFERROR\u0026#34;)); Http::HttpResponse\tresponse; Http::HttpClient\tclient; //对于登录：url=http://192.168.226.128:8080/msg_server Http::HttpRequest\trequest(\u0026#34;get\u0026#34;, url); if (!client.execute(\u0026amp;request, \u0026amp;response)) { CString csTemp = util::stringToCString(url); pPamram-\u0026gt;result = DOLOGIN_FAIL; LOG__(ERR,_T(\u0026#34;failed %s\u0026#34;), csTemp); asyncCallback(std::shared_ptr\u0026lt;void\u0026gt;(pPamram)); client.killSelf(); return; } /** { \u0026#34;backupIP\u0026#34; : \u0026#34;localhost\u0026#34;, \u0026#34;code\u0026#34; : 0, \u0026#34;discovery\u0026#34; : \u0026#34;http://127.0.0.1/api/discovery\u0026#34;, \u0026#34;msfsBackup\u0026#34; : \u0026#34;http://127.0.0.1:8700/\u0026#34;, \u0026#34;msfsPrior\u0026#34; : \u0026#34;http://127.0.0.1:8700/\u0026#34;, \u0026#34;msg\u0026#34; : \u0026#34;\u0026#34;, \u0026#34;port\u0026#34; : \u0026#34;8000\u0026#34;, \u0026#34;priorIP\u0026#34; : \u0026#34;localhost\u0026#34; } */ std::string body = response.getBody(); client.killSelf(); //json解析 try { Json::Reader reader; Json::Value root; if (!reader.parse(body, root)) { CString csTemp = util::stringToCString(body); LOG__(ERR, _T(\u0026#34;parse data failed,%s\u0026#34;), csTemp); pPamram-\u0026gt;result = DOLOGIN_FAIL; pPamram-\u0026gt;resMsg = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_LOGIN_HTTP_JSONERROR\u0026#34;)); goto End; } int nCode = root.get(\u0026#34;code\u0026#34;, \u0026#34;\u0026#34;).asInt(); if (0 == nCode)//登陆成功 { LOG__(APP, _T(\u0026#34;get msgSvr IP succeed!\u0026#34;)); pCfg-\u0026gt;msgSevPriorIP = root.get(\u0026#34;priorIP\u0026#34;, \u0026#34;\u0026#34;).asString(); pCfg-\u0026gt;msgSevBackupIP = root.get(\u0026#34;backupIP\u0026#34;, \u0026#34;\u0026#34;).asString(); std::string strPort = root.get(\u0026#34;port\u0026#34;, \u0026#34;\u0026#34;).asString(); pCfg-\u0026gt;msgServPort = util::stringToInt32(strPort); pCfg-\u0026gt;fileSysAddr = util::stringToCString(root.get(\u0026#34;msfsPrior\u0026#34;, \u0026#34;\u0026#34;).asString()); pCfg-\u0026gt;fileSysBackUpAddr = util::stringToCString(root.get(\u0026#34;msfsBackup\u0026#34;, \u0026#34;\u0026#34;).asString()); pPamram-\u0026gt;result = DOLOGIN_SUCC; } else { LOG__(ERR, _T(\u0026#34;get msgSvr IP failed! Code = %d\u0026#34;),nCode); pPamram-\u0026gt;result = DOLOGIN_FAIL; CString csRetMsgTemp = util::stringToCString(root.get(\u0026#34;msg\u0026#34;, \u0026#34;\u0026#34;).asString()); if (!csRetMsgTemp.IsEmpty()) pPamram-\u0026gt;resMsg = csRetMsgTemp; } } catch (...) { CString csTemp = util::stringToCString(body); LOG__(ERR,_T(\u0026#34;parse json execption,%s\u0026#34;), csTemp); pPamram-\u0026gt;result = DOLOGIN_FAIL; pPamram-\u0026gt;resMsg = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_LOGIN_HTTP_JSONERROR\u0026#34;)); } End: asyncCallback(std::shared_ptr\u0026lt;void\u0026gt;(pPamram)); } 实际上是向login_server发送一个http请求，这是一个同步请求。得到的结果是一个json字符串，代码注释中已经给出。然后调用asyncCallback(std::shared_ptr(pPamram));参数pPamram携带了当前任务的回调函数指针：\n/** * 异步回调，借助UIEvent * * @param std::shared_ptr\u0026lt;void\u0026gt; param * @return void * @exception there is no any exception to throw. */ void asyncCallback(std::shared_ptr\u0026lt;void\u0026gt; param) { CallbackOperationEvent* pEvent = new CallbackOperationEvent(m_callback, param); module::getEventManager()-\u0026gt;asynFireUIEvent(pEvent); } 这实际上产生了一个回调事件。也就是说队列B做http请求，操作完成后往代理窗口的消息队列中放入一个回调事件，这个事件通过代理窗口过程函数来处理的（这就是上文中第4点介绍的代理窗口过程的作用，实际上是利用windows消息队列来做任务处理（系统有现成的任务队列系统，为何不利用呢？））：\nmodule::IMCoreErrorCode UIEventManager::asynFireUIEvent(IN const IEvent* const pEvent) { assert(m_hWnd); assert(pEvent); if (0 == m_hWnd || 0 == pEvent) return IMCORE_ARGUMENT_ERROR; if (FALSE == ::PostMessage(m_hWnd, UI_EVENT_MSG, reinterpret_cast\u0026lt;WPARAM\u0026gt;(this), reinterpret_cast\u0026lt;WPARAM\u0026gt;(pEvent))) return IMCORE_WORK_POSTMESSAGE_ERROR; return IMCORE_OK; } 看到没有？向代理窗口的消息队列中投递一个UI_EVENT_MSG事件，并在消息参数LPARAM中传递了回调事件的对象指针。这样代理窗口过程函数就可以处理这个消息了：\nLRESULT _stdcall UIEventManager::_WindowProc(HWND hWnd , UINT message , WPARAM wparam , LPARAM lparam) { switch (message) { case UI_EVENT_MSG: reinterpret_cast\u0026lt;UIEventManager*\u0026gt;(wparam)-\u0026gt;_processEvent(reinterpret_cast\u0026lt;IEvent*\u0026gt;(lparam), TRUE); break; case WM_TIMER: reinterpret_cast\u0026lt;UIEventManager*\u0026gt;(wparam)-\u0026gt;_processTimer(); break; default: break; } return ::DefWindowProc(hWnd, message, wparam, lparam); } void UIEventManager::_processEvent(IEvent* pEvent, BOOL bRelease) { assert(pEvent); if (0 == pEvent) return; try { pEvent-\u0026gt;process(); if (bRelease) pEvent-\u0026gt;release(); } catch (imcore::Exception *e) { LOG__(ERR, _T(\u0026#34;event run exception\u0026#34;)); pEvent-\u0026gt;onException(e); if (bRelease) pEvent-\u0026gt;release(); if (e) { LOG__(ERR, _T(\u0026#34;event run exception:%s\u0026#34;), util::stringToCString(e-\u0026gt;m_msg)); assert(FALSE); } } catch (...) { LOG__(ERR, _T(\u0026#34;operation run exception,unknown reason\u0026#34;)); if (bRelease) pEvent-\u0026gt;release(); assert(FALSE); } } 根据C++的多态特性，pEvent-\u0026gt;process()实际上调用的是CallbackOperationEvent.process()。代码如下：\nvirtual void process() { m_callback(m_param); } m_callback(m_param);调用的就是上文中介绍DoLoginServerHttpOperation操作的回调函数LoginDialog::OnHttpCallbackOperation()：\nvoid LoginDialog::OnHttpCallbackOperation(std::shared_ptr\u0026lt;void\u0026gt; param) { DoLoginServerParam* pParam = (DoLoginServerParam*)param.get(); if (DOLOGIN_SUCC == pParam-\u0026gt;result) { module::TTConfig* pCfg = module::getSysConfigModule()-\u0026gt;getSystemConfig(); PTR_VOID(pCfg); LoginParam loginparam; loginparam.csUserName = pCfg-\u0026gt;userName; loginparam.password = pCfg-\u0026gt;password; loginparam.csUserName.Trim(); LoginOperation* pOperation = new LoginOperation( BIND_CALLBACK_1(LoginDialog::OnOperationCallback), loginparam); imcore::IMLibCoreStartOperation(pOperation); } else { m_ptxtTip-\u0026gt;SetText(pParam-\u0026gt;resMsg); module::TTConfig* pCfg = module::getSysConfigModule()-\u0026gt;getSystemConfig(); LOG__(ERR, _T(\u0026#34;get MsgServer config faild,login server addres:%s:%d\u0026#34;), pCfg-\u0026gt;loginServIP,pCfg-\u0026gt;loginServPort); CString csTxt = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_BTN_LOGIN\u0026#34;)); m_pBtnLogin-\u0026gt;SetText(csTxt); m_pBtnLogin-\u0026gt;SetEnabled(true); } } ok，终于到家了。但是这并没结束，我们只介绍了队列B和代理窗口消息队列，还有队列A呢？LoginDialog::OnHttpCallbackOperation()会根据获取的msg_server的情况来再次产生一个新的任务LoginOperation来放入队列A中，这次才是真正的用户登录，根据上面的介绍，LoginOperation任务从队列A中取出来之后，实际执行的是LoginOperation::processOpertion()：\nvoid LoginOperation::processOpertion() { LOG__(APP,_T(\u0026#34;login start,uname:%s,status:%d\u0026#34;), m_loginParam.csUserName , m_loginParam.mySelectedStatus); LoginParam* pParam = new LoginParam; pParam-\u0026gt;csUserName = m_loginParam.csUserName; pParam-\u0026gt;mySelectedStatus = m_loginParam.mySelectedStatus; //连接消息服务器 module::TTConfig* pCfg = module::getSysConfigModule()-\u0026gt;getSystemConfig(); CString server = util::stringToCString(pCfg-\u0026gt;msgSevPriorIP); LOG__(APP, _T(\u0026#34;MsgServeIp:%s,Port:%d\u0026#34;), server, pCfg-\u0026gt;msgServPort); //8000端口 IM::Login::IMLoginRes* pImLoginResp = (IM::Login::IMLoginRes*)module::getTcpClientModule() -\u0026gt;doLogin(server, pCfg-\u0026gt;msgServPort,m_loginParam.csUserName,m_loginParam.password); if (0 == pImLoginResp || pImLoginResp-\u0026gt;result_code() != IM::BaseDefine::REFUSE_REASON_NONE || !pImLoginResp-\u0026gt;has_user_info()) { //TODO,若失败，尝试备用IP LOG__(ERR,_T(\u0026#34;add:%s:%d,uname:%s,login for msg server failed\u0026#34;),server,pCfg-\u0026gt;msgServPort, m_loginParam.csUserName); if (pImLoginResp) { CString errInfo = util::stringToCString(pImLoginResp-\u0026gt;result_string()); pParam-\u0026gt;errInfo = errInfo; pParam-\u0026gt;result = LOGIN_FAIL; pParam-\u0026gt;server_result = pImLoginResp-\u0026gt;result_code(); LOG__(ERR, _T(\u0026#34;error code :%d,error info:%s\u0026#34;), pImLoginResp-\u0026gt;result_code(), errInfo); } else { pParam-\u0026gt;result = IM::BaseDefine::REFUSE_REASON_NO_MSG_SERVER; LOG__(ERR, _T(\u0026#34;login msg server faild！\u0026#34;)); } asyncCallback(std::shared_ptr\u0026lt;void\u0026gt;(pParam)); return; } pParam-\u0026gt;result = LOGIN_OK; pParam-\u0026gt;serverTime = pImLoginResp-\u0026gt;server_time(); pParam-\u0026gt;mySelectedStatus = pImLoginResp-\u0026gt;online_status(); //存储服务器端返回的userId IM::BaseDefine::UserInfo userInfo = pImLoginResp-\u0026gt;user_info(); pCfg-\u0026gt;userId = util::uint32ToString(userInfo.user_id()); pCfg-\u0026gt;csUserId = util::stringToCString(pCfg-\u0026gt;userId); //登陆成功，创建自己的信息 module::UserInfoEntity myInfo; myInfo.sId = pCfg-\u0026gt;userId; myInfo.csName = m_loginParam.csUserName; myInfo.onlineState = IM::BaseDefine::USER_STATUS_ONLINE; myInfo.csNickName = util::stringToCString(userInfo.user_nick_name()); myInfo.avatarUrl = userInfo.avatar_url(); myInfo.dId = util::uint32ToString(userInfo.department_id()); myInfo.department = myInfo.dId; myInfo.email = userInfo.email(); myInfo.gender = userInfo.user_gender(); myInfo.user_domain = userInfo.user_domain(); myInfo.telephone = userInfo.user_tel(); myInfo.status = userInfo.status(); myInfo.signature = userInfo.sign_info(); module::getUserListModule()-\u0026gt;createUserInfo(myInfo); asyncCallback(std::shared_ptr\u0026lt;void\u0026gt;(pParam)); LOG__(APP, _T(\u0026#34;login succeed! Name = %s Nickname = %s sId = %s status = %d\u0026#34;) , m_loginParam.csUserName , util::stringToCString(userInfo.user_nick_name()) , module::getSysConfigModule()-\u0026gt;UserID() , m_loginParam.mySelectedStatus); //开始发送心跳包 module::getTcpClientModule()-\u0026gt;startHeartbeat(); } 同理，数据包发生成功以后，会再往代理窗口的消息队列中产生一个回调事件，最终调用刚才说的LoginOperation绑定的回调函数：\nvoid asyncCallback(std::shared_ptr\u0026lt;void\u0026gt; param) { CallbackOperationEvent* pEvent = new CallbackOperationEvent(m_callback, param); module::getEventManager()-\u0026gt;asynFireUIEvent(pEvent); } void LoginDialog::OnOperationCallback(std::shared_ptr\u0026lt;void\u0026gt; param) { LoginParam* pLoginParam = (LoginParam*)param.get(); if (LOGIN_OK == pLoginParam-\u0026gt;result)\t//登陆成功 { Close(IDOK); //创建用户目录 _CreateUsersFolder(); //开启同步消息时间timer module::getSessionModule()-\u0026gt;startSyncTimeTimer(); module::getSessionModule()-\u0026gt;setTime(pLoginParam-\u0026gt;serverTime); //通知服务器客户端初始化完毕,获取组织架构信息和群列表 module::getLoginModule()-\u0026gt;notifyLoginDone(); } else\t//登陆失败处理 { module::getTcpClientModule()-\u0026gt;shutdown(); if (IM::BaseDefine::REFUSE_REASON_NO_MSG_SERVER == pLoginParam-\u0026gt;server_result) { CString csTip = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_LOGIN_MSGSVR_FAIL\u0026#34;)); m_ptxtTip-\u0026gt;SetText(csTip); } else if (!pLoginParam-\u0026gt;errInfo.IsEmpty()) { m_ptxtTip-\u0026gt;SetText(pLoginParam-\u0026gt;errInfo); } else { CString errorCode = util::int32ToCString(pLoginParam-\u0026gt;server_result); CString csTip = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_LOGIN_UNKNOWN_ERROR\u0026#34;)); m_ptxtTip-\u0026gt;SetText(csTip + CString(\u0026#34;:\u0026#34;) + errorCode); } } CString csTxt = util::getMultilingual()-\u0026gt;getStringById(_T(\u0026#34;STRID_LOGINDIALOG_BTN_LOGIN\u0026#34;)); m_pBtnLogin-\u0026gt;SetText(csTxt); m_pBtnLogin-\u0026gt;SetEnabled(true); } 至此，登录才成功。等等，那数据包是怎么发到服务器的呢？这也是一个重点，我们来详细地介绍一下，LoginOperation::processOpertion()中有这一行代码：\ndoLogin函数代码如下：\nIM::Login::IMLoginRes* TcpClientModule_Impl::doLogin(CString \u0026amp;linkaddr, UInt16 port ,CString\u0026amp; uName,std::string\u0026amp; pass) { m_socketHandle = imcore::IMLibCoreConnect(util::cStringToString(linkaddr), port); imcore::IMLibCoreRegisterCallback(m_socketHandle, this); if(util::waitSingleObject(m_eventConnected, 5000)) { IM::Login::IMLoginReq imLoginReq; string\u0026amp; name = util::cStringToString(uName); imLoginReq.set_user_name(name); imLoginReq.set_password(pass); imLoginReq.set_online_status(IM::BaseDefine::USER_STATUS_ONLINE); imLoginReq.set_client_type(IM::BaseDefine::CLIENT_TYPE_WINDOWS); imLoginReq.set_client_version(\u0026#34;win_10086\u0026#34;); if (TCPCLIENT_STATE_OK != m_tcpClientState) return 0; sendPacket(IM::BaseDefine::SID_LOGIN, IM::BaseDefine::CID_LOGIN_REQ_USERLOGIN, ++g_seqNum , \u0026amp;imLoginReq); m_pImLoginResp-\u0026gt;Clear(); util::waitSingleObject(m_eventReceived, 10000); } return m_pImLoginResp; } 这段代码先连接服务器，然后调用sendPacket()发送登录数据包。如何连接服务器使用了一些“奇技淫巧”，我们后面单独介绍。我们这里先来看sendPacket()发包代码：\nvoid TcpClientModule_Impl::sendPacket(UInt16 moduleId, UInt16 cmdId, UInt16 seq, google::protobuf::MessageLite* pbBody) { m_TTPBHeader.clear(); m_TTPBHeader.setModuleId(moduleId); m_TTPBHeader.setCommandId(cmdId); m_TTPBHeader.setSeqNumber(seq); _sendPacket(pbBody); } void TcpClientModule_Impl::_sendPacket(google::protobuf::MessageLite* pbBody) { UInt32 length = imcore::HEADER_LENGTH + pbBody-\u0026gt;ByteSize(); m_TTPBHeader.setLength(length); std::unique_ptr\u0026lt;byte\u0026gt; data(new byte[length]); memset(data.get(), 0, length); memcpy(data.get(), m_TTPBHeader.getSerializeBuffer(), imcore::HEADER_LENGTH); if (!pbBody-\u0026gt;SerializeToArray(data.get() + imcore::HEADER_LENGTH, pbBody-\u0026gt;ByteSize())) { LOG__(ERR, _T(\u0026#34;pbBody SerializeToArray failed\u0026#34;)); return; } imcore::IMLibCoreWrite(m_socketHandle, data.get(), length); } 其实就是序列化成protobuf要求的格式，然后调用imcore::IMLibCoreWrite(m_socketHandle, data.get(), length);发出去：\nint IMLibCoreWrite(int key, uchar_t* data, uint32_t size) { int nRet = -1; int nHandle = key; CImConn* pConn = TcpSocketsManager::getInstance()-\u0026gt;get_client_conn(nHandle); if (pConn) { pConn-\u0026gt;Send((void*)data, size); } else { LOG__(NET, _T(\u0026#34;connection is invalied:%d\u0026#34;), key); } return nRet; } 先尝试着直接发送，如果目前tcp窗口太小发不出去，则暂且将数据放在发送缓冲区里面，并检测socket可写事件。这里就是和服务器一样的网络库的代码了，前面一系列的文章，我们已经介绍过了。\nint CImConn::Send(void* data, int len) { if (m_busy) { m_out_buf.Write(data, len); return len; } int offset = 0; int remain = len; while (remain \u0026gt; 0) { int send_size = remain; if (send_size \u0026gt; NETLIB_MAX_SOCKET_BUF_SIZE) { send_size = NETLIB_MAX_SOCKET_BUF_SIZE; } int ret = netlib_send(m_handle, (char*)data + offset, send_size); if (ret \u0026lt;= 0) { ret = 0; break; } offset += ret; remain -= ret; } if (remain \u0026gt; 0) { m_out_buf.Write((char*)data + offset, remain); m_busy = true; LOG__(NET, _T(\u0026#34;send busy, remain=%d\u0026#34;), m_out_buf.GetWriteOffset()); } return len; } 数据发出去以后，服务器应答登录包，网络线程会检测到socket可读事件：\nvoid CBaseSocket::OnRead() { if (m_state == SOCKET_STATE_LISTENING) { _AcceptNewSocket(); } else { u_long avail = 0; if ( (ioctlsocket(m_socket, FIONREAD, \u0026amp;avail) == SOCKET_ERROR) || (avail == 0) ) { m_callback(m_callback_data, NETLIB_MSG_CLOSE, (net_handle_t)m_socket, NULL); } else { m_callback(m_callback_data, NETLIB_MSG_READ, (net_handle_t)m_socket, NULL); } } } void imconn_callback(void* callback_data, uint8_t msg, uint32_t handle, void* pParam) { NOTUSED_ARG(handle); NOTUSED_ARG(pParam); CImConn* pConn = TcpSocketsManager::getInstance()-\u0026gt;get_client_conn(handle); if (!pConn) { //LOG__(NET, _T(\u0026#34;connection is invalied:%d\u0026#34;), handle); return; } pConn-\u0026gt;AddRef(); //\tLOG__(NET, \u0026#34;msg=%d, handle=%d\\n\u0026#34;, msg, handle); switch (msg) { case NETLIB_MSG_CONFIRM: pConn-\u0026gt;onConnect(); break; case NETLIB_MSG_READ: pConn-\u0026gt;OnRead(); break; case NETLIB_MSG_WRITE: pConn-\u0026gt;OnWrite(); break; case NETLIB_MSG_CLOSE: pConn-\u0026gt;OnClose(); break; default: LOG__(NET, _T(\u0026#34;!!!imconn_callback error msg: %d\u0026#34;), msg); break; } pConn-\u0026gt;ReleaseRef(); } void CImConn::OnRead() { for (;;) { uint32_t free_buf_len = m_in_buf.GetAllocSize() - m_in_buf.GetWriteOffset(); if (free_buf_len \u0026lt; READ_BUF_SIZE) m_in_buf.Extend(READ_BUF_SIZE); int ret = netlib_recv(m_handle, m_in_buf.GetBuffer() + m_in_buf.GetWriteOffset(), READ_BUF_SIZE); if (ret \u0026lt;= 0) break; m_in_buf.IncWriteOffset(ret); while (m_in_buf.GetWriteOffset() \u0026gt;= imcore::HEADER_LENGTH) { uint32_t len = m_in_buf.GetWriteOffset(); uint32_t length = CByteStream::ReadUint32(m_in_buf.GetBuffer()); if (length \u0026gt; len) break; try { imcore::TTPBHeader pbHeader; pbHeader.unSerialize((byte*)m_in_buf.GetBuffer(), imcore::HEADER_LENGTH); LOG__(NET, _T(\u0026#34;OnRead moduleId:0x%x,commandId:0x%x\u0026#34;), pbHeader.getModuleId(), pbHeader.getCommandId()); if (m_pTcpSocketCB) m_pTcpSocketCB-\u0026gt;onReceiveData((const char*)m_in_buf.GetBuffer(), length); LOGBIN_F__(SOCK, \u0026#34;OnRead\u0026#34;, m_in_buf.GetBuffer(), length); } catch (std::exception\u0026amp; ex) { assert(FALSE); LOGA__(NET, \u0026#34;std::exception,info:%s\u0026#34;, ex.what()); if (m_pTcpSocketCB) m_pTcpSocketCB-\u0026gt;onReceiveError(); } catch (...) { assert(FALSE); LOG__(NET, _T(\u0026#34;unknown exception\u0026#34;)); if (m_pTcpSocketCB) m_pTcpSocketCB-\u0026gt;onReceiveError(); } m_in_buf.Read(NULL, length); } } } 收取数据，并解包：\nvoid TcpClientModule_Impl::onReceiveData(const char* data, int32_t size) { if (m_pServerPingTimer) m_pServerPingTimer-\u0026gt;m_bHasReceivedPing = TRUE; imcore::TTPBHeader header; header.unSerialize((byte*)data, imcore::HEADER_LENGTH);\tif (IM::BaseDefine::CID_OTHER_HEARTBEAT == header.getCommandId() \u0026amp;\u0026amp; IM::BaseDefine::SID_OTHER == header.getModuleId()) { //模块器端过来的心跳包，不跳到业务层派发 return; } LOG__(NET, _T(\u0026#34;receiveData message moduleId:0x%x,commandId:0x%x\u0026#34;) , header.getModuleId(), header.getCommandId()); if (g_seqNum == header.getSeqNumber()) { m_pImLoginResp-\u0026gt;ParseFromArray(data + imcore::HEADER_LENGTH, size - imcore::HEADER_LENGTH); ::SetEvent(m_eventReceived); return; } //将网络包包装成任务放到逻辑任务队列里面去 _handlePacketOperation(data, size); } void TcpClientModule_Impl::_handlePacketOperation(const char* data, UInt32 size) { std::string copyInBuffer(data, size); imcore::IMLibCoreStartOperationWithLambda( [=]() { imcore::TTPBHeader header; header.unSerialize((byte*)copyInBuffer.data(),imcore::HEADER_LENGTH); module::IPduPacketParse* pModule = (module::IPduPacketParse*)__getModule(header.getModuleId()); if (!pModule) { assert(FALSE); LOG__(ERR, _T(\u0026#34;module is null, moduleId:%d,commandId:%d\u0026#34;) , header.getModuleId(), header.getCommandId()); return; } std::string pbBody(copyInBuffer.data() + imcore::HEADER_LENGTH, size - imcore::HEADER_LENGTH); pModule-\u0026gt;onPacket(header, pbBody); }); } 根据不同的命令号来做相应的处理：\nvoid UserListModule_Impl::onPacket(imcore::TTPBHeader\u0026amp; header, std::string\u0026amp; pbBody) { switch (header.getCommandId()) { case IM::BaseDefine::BuddyListCmdID::CID_BUDDY_LIST_RECENT_CONTACT_SESSION_RESPONSE: _recentlistResponse(pbBody); break; case IM::BaseDefine::BuddyListCmdID::CID_BUDDY_LIST_STATUS_NOTIFY: _userStatusNotify(pbBody); break; case IM::BaseDefine::BuddyListCmdID::CID_BUDDY_LIST_USER_INFO_RESPONSE: _usersInfoResponse(pbBody); break; case IM::BaseDefine::BuddyListCmdID::CID_BUDDY_LIST_REMOVE_SESSION_RES: _removeSessionResponse(pbBody); break; case IM::BaseDefine::BuddyListCmdID::CID_BUDDY_LIST_ALL_USER_RESPONSE: _allUserlistResponse(pbBody); break; case IM::BaseDefine::BuddyListCmdID::CID_BUDDY_LIST_USERS_STATUS_RESPONSE: _usersLineStatusResponse(pbBody); break; case IM::BaseDefine::BuddyListCmdID::CID_BUDDY_LIST_CHANGE_AVATAR_RESPONSE: _changeAvatarResponse(pbBody); break; case IM::BaseDefine::CID_BUDDY_LIST_REMOVE_SESSION_NOTIFY: _removeSessionNotify(pbBody); break; case IM::BaseDefine::CID_BUDDY_LIST_DEPARTMENT_RESPONSE: _departmentResponse(pbBody); break; case IM::BaseDefine::BuddyListCmdID::CID_BUDDY_LIST_AVATAR_CHANGED_NOTIFY: _avatarChangeNotify(pbBody); break; case IM::BaseDefine::BuddyListCmdID::CID_BUDDY_LIST_CHANGE_SIGN_INFO_RESPONSE: _changeSignInfoResponse(pbBody); break; case IM::BaseDefine::BuddyListCmdID::CID_BUDDY_LIST_SIGN_INFO_CHANGED_NOTIFY: _signInfoChangedNotify(pbBody); break; default: LOG__(ERR, _T(\u0026#34;Unknow commandID:%d\u0026#34;), header.getCommandId()); return; } } 每一个处理分支，都最终会产生一个事件放入代理窗口的消息队列中。这前面已经介绍过了。这里我不得不说一点，teamtalk对于其它数据包的应答都是走的上面的介绍的流程，但是对于登录的应答却是使用了一些特殊处理。听我慢慢道来：\n上文中发送了登录数据包之后，在那里等一个事件10秒钟，如果10秒内这个事件有信号，则认为登录成功。那么什么情况该事件会有信号呢？\n该事件在构造函数里面创建，默认无信号：\n当网络线程收到数据以后（上文逻辑流中介绍过了）：\n除了心跳包直接过滤以外，通过一个序列号（Seq，变量g_seqNum）唯一标识了登录数据包的应答，如果收到这个序列号的数据，则置信m_eventReceived。这样等待在那里的登录流程就可以返回了，同时也得到了登录应答，登录应答数据记录在成员变量m_pImLoginResp中。如果是其它的数据包，则走的流程是_handlePacketOperation(data, size);，处理逻辑上文也介绍了。\n至此，整个客户端程序结构就介绍完了，我们总结一下，实际上程序有如下几类线程：\n网络事件检测线程，用于接收和发送网络数据；\nhttp任务处理线程用于处理http操作；\n普通的任务处理线程，用于处理一般性的任务，比如登录；\nUI线程，界面逻辑处理，同时在UI线程里面有一个代理窗口的窗口过程函数，用于非UI线程与UI线程之间的数据流和逻辑中转，核心是利用PostMessage往代理线程投递事件，事件消息参数携带任务信息。\n至于，像聊天、查看用户信息这些业务性的内容，留给有兴趣的读者自己去研究吧。\n四、程序中使用的一些比较有意思的技巧摘录 唯一实例判断 很多程序只能启动一个实例，当你再次启动某个程序的实例时，会激活前一个实例，其实实现起来很简单，就是新建一个命名的Mutex，因为Mutex可以跨进程，当再次启动程序实例时，创建同名的Mutex，会无法创建，错误信息是已经存在。这是windows上非常常用的技巧，如果你从事windows开发，请你务必掌握它。看teamtalk的实现：\n#ifdef _DEBUG #define AppSingletonMutex _T(\u0026#34;{7A666640-EDB3-44CC-954B-0C43F35A2E17}\u0026#34;) #else #define AppSingletonMutex _T(\u0026#34;{5676532A-6F70-460D-A1F0-81D6E68F046A}\u0026#34;) #endif BOOL CteamtalkApp::_IsHaveInstance() { // 单实例运行 HANDLE hMutex = ::CreateMutex(NULL, TRUE, AppSingletonMutex); if (hMutex != NULL \u0026amp;\u0026amp; GetLastError() == ERROR_ALREADY_EXISTS) { MessageBox(0, _T(\u0026#34;上次程序运行还没完全退出，请稍后再启动！\u0026#34;), _T(\u0026#34;TeamTalk\u0026#34;), MB_OK); return TRUE; } return FALSE; } socket函数connect()连接等待时长设定 传统的做法是将socket设置为非阻塞的，调用完connect函数之后，调用select函数检测socket是否可写，在select函数里面设置超时时间。代码如下：\n//为了调试方便，暂且注释掉 int ret = ::connect(m_hSocket, (struct sockaddr*)\u0026amp;addrSrv, sizeof(addrSrv)); if (ret == 0) { m_bConnected = TRUE; return TRUE; } if (ret == SOCKET_ERROR \u0026amp;\u0026amp; WSAGetLastError() != WSAEWOULDBLOCK) { return FALSE; } fd_set writeset; FD_ZERO(\u0026amp;writeset); FD_SET(m_hSocket, \u0026amp;writeset); struct timeval tv = { timeout, 0 }; if (::select(m_hSocket + 1, NULL, \u0026amp;writeset, NULL, \u0026amp;tv) != 1) { return FALSE; } return TRUE; 我们看看teamtalk里面怎么做的：\n​\n红色箭头的地方调用connect函数连接服务器，然后绿色的箭头等待一个事件有信号（内部使用WaitForSingleObject函数），那事件什么时候有信号呢？\n网络线程检测第一次到socket可写时，调用onConnectDone函数：\n实际做的事情还是和上面介绍的差不多。其实对于登录流程做成同步的，也是和这个类似，上文中我们介绍过。我早些年刚做windows网络通信方面的项目时，开始总是找不到好的处理等待登录请求应答的方法。这里是一种很不错的设置超时等待的方法。\nteamtalk的截图功能 不知道，你在使用qq这样的截图工具时，QQ截图工具能自动检测出某个窗口的范围。这个功能在teamtalk中也有实现，实现代码如下：\nBOOL ScreenCapture::initCapture(__in HWND hWnd) { //register hot key const std::wstring screenCaptureHotkeyName = L\u0026#34;_SCREEN_CAPTURE_HOTKEY\u0026#34;; int iHotkeyId = (int)GlobalAddAtom(screenCaptureHotkeyName.c_str()); if (!RegisterHotKey(hWnd, iHotkeyId, MOD_CONTROL | MOD_SHIFT, 0x51)) //ctrl + shift + Q { GlobalDeleteAtom(iHotkeyId); } m_iHotkeyId = iHotkeyId; m_hRegisterHotkeyWnd = hWnd; return createMsgWindow(); } 程序初始化时，注册截屏快捷键，这里是ctrl+shift+Q（QQ默认是ctrl+alt+A）。当点击截屏按钮之后，开始启动截图：\nHWND hDesktopWnd = GetDesktopWindow(); HDC hScreenDC = GetDC(hDesktopWnd); RECT rc = { 0 }; GetWindowRect(hDesktopWnd, \u0026amp;rc); int cx = rc.right - rc.left; int cy = rc.bottom - rc.top; HBITMAP hBitmap = CreateCompatibleBitmap(hScreenDC, cx, cy); m_hMemDC = CreateCompatibleDC(hScreenDC); HGDIOBJ hOldBitmap = SelectObject(m_hMemDC, (HGDIOBJ)hBitmap); BitBlt(m_hMemDC, 0, 0, cx, cy, hScreenDC, 0, 0, SRCCOPY); m_hBkgMemDC = CreateCompatibleDC(hScreenDC); HBITMAP hBkgBitmap = CreateCompatibleBitmap(hScreenDC, cx, cy); SelectObject(m_hBkgMemDC, (HGDIOBJ)hBkgBitmap); BitBlt(m_hBkgMemDC, 0, 0, cx, cy, hScreenDC, 0, 0, SRCCOPY); HDC hMaskDC = CreateCompatibleDC(hScreenDC); HBITMAP hMaskBitmap = CreateCompatibleBitmap(hScreenDC, cx, cy); SelectObject(hMaskDC, (HGDIOBJ)hMaskBitmap); BLENDFUNCTION ftn = { AC_SRC_OVER, 0, 100, 0}; AlphaBlend(m_hBkgMemDC, 0, 0, cx, cy, hMaskDC, 0, 0, cx, cy, ftn); DeleteObject(hMaskBitmap); DeleteDC(hMaskDC); m_hDrawMemDC = CreateCompatibleDC(hScreenDC); HBITMAP hDrawBitmap = CreateCompatibleBitmap(hScreenDC, cx, cy); SelectObject(m_hDrawMemDC, hDrawBitmap); ReleaseDC(hDesktopWnd, hScreenDC); 实际上就是在桌面窗口上画图。再遍历当前所有有显示区域的窗口，并记录这些窗口的窗口句柄和矩形区域：\nfor (HWND hWnd = GetTopWindow(NULL); NULL != hWnd; hWnd = GetWindow(hWnd, GW_HWNDNEXT)) { if (!IsWindow(hWnd) || !IsWindowVisible(hWnd) || IsIconic(hWnd)) { continue; } RECT rcWnd = { 0 }; GetWindowRect(hWnd, \u0026amp;rcWnd); adjustRectInScreen(rcWnd); if (ScreenCommon::isRectEmpty(rcWnd)) { continue; } wchar_t szTxt[MAX_PATH] = { 0 }; GetWindowText(hWnd, szTxt, MAX_PATH); if (wcslen(szTxt) \u0026lt;= 0) { continue; } //combine the rect with the screen rect m_lsWndList.push_back(ScreenCaptureWndInfo(hWnd, rcWnd)); } return m_lsWndList.size() \u0026gt; 0; 然后显示一个截图工具：\nBOOL UIScreenCaptureMgr::createWindows() { m_hBkgUI = BkgroundUI::Instance()-\u0026gt;createWindow(); wchar_t szImg[MAX_PATH] = {0}; GetModuleFileName(NULL, szImg, MAX_PATH); PathRemoveFileSpec(szImg); PathRemoveFileSpec(szImg); std::wstring strBkgPic = std::wstring(szImg) + L\u0026#34;\\\\gui\\\\ScreenCapture\\\\sc_toolbar_normal.png\u0026#34;; std::wstring strHoverPic = std::wstring(szImg) + L\u0026#34;\\\\gui\\\\ScreenCapture\\\\sc_toolbar_hover.png\u0026#34;; std::wstring strSelPic = std::wstring(szImg) + L\u0026#34;\\\\gui\\\\ScreenCapture\\\\sc_toolbar_select.png\u0026#34;; EditToolbarInfo toolBarInfo = { 0, 0, 193, 37, strBkgPic, strHoverPic, strSelPic, { { 9, 5, 35, 31 }, { 43, 5, 69, 31 }, { 85, 5, 112, 31 }, { 119, 5, 185, 31 } } }; m_hEditToolBarUI = EditToolbarUI::Instance()-\u0026gt;createWindow(toolBarInfo, m_hBkgUI); SetWindowPos(m_hBkgUI, HWND_TOPMOST, 0, 0, 0, 0, SWP_NOSIZE | SWP_NOMOVE); forceForgroundWindow(m_hBkgUI); ShowWindow(m_hBkgUI, SW_SHOW); return TRUE; } 然后安装一个消息钩子（hook）：\nBOOL ScreenCapture::installMsgHook(BOOL bInstall) { BOOL result = FALSE; if (bInstall) { if (!m_hMouseHook) { m_hMouseHook = SetWindowsHookEx(WH_MOUSE, MouseProc, NULL, GetCurrentThreadId()); result = (NULL != m_hMouseHook); } } else { UnhookWindowsHookEx(m_hMouseHook); m_hMouseHook = NULL; result = TRUE; } return result; } LRESULT ScreenCapture::MouseProc(_In_ int nCode, _In_ WPARAM wParam, _In_ LPARAM lParam) { PMOUSEHOOKSTRUCT pHookInfo = (PMOUSEHOOKSTRUCT)lParam; int xPos = pHookInfo-\u0026gt;pt.x; int yPos = pHookInfo-\u0026gt;pt.y; LRESULT lResHandled = CallNextHookEx(ScreenCapture::getInstance()-\u0026gt;getMouseHook(), nCode, wParam, lParam); if (WM_LBUTTONDBLCLK == wParam ) { ScreenCommon::postNotifyMessage(WM_SNAPSHOT_FINISH_CAPTURE, 0, 0); } else if (WM_RBUTTONDBLCLK == wParam) { ScreenCommon::postNotifyMessage(WM_SNAPSHOT_CANCEL_CPATURE, 0, 0); } else if (WM_LBUTTONDOWN == wParam) { if (CM_AUTO_SELECT == CaptureModeMgr::Instance()-\u0026gt;getMode()) { CaptureModeMgr::Instance()-\u0026gt;changeMode(CM_MANAL_SELECT); } } CaptureModeMgr::Instance()-\u0026gt;handleMouseMsg(wParam, xPos, yPos); return lResHandled; } 在钩子函数中，如果出现鼠标双击事件，则表示取消截图；如果出现双击事件，则表示完成截图。如果鼠标按下则表示开始绘制截图区域，然后处理鼠标移动事件：\nvoid CaptureModeMgr::handleMouseMsg(__in UINT uMsg, __in int xPos, __in int yPos) { IModeMsgHandler *msgHandler = getModeHandler(); if (!msgHandler) return; if (WM_MOUSEMOVE == uMsg) { msgHandler-\u0026gt;onMouseMove(xPos, yPos); } else if (WM_LBUTTONDOWN == uMsg) { msgHandler-\u0026gt;onLButtonDown(xPos, yPos); } else if (WM_LBUTTONUP == uMsg) { msgHandler-\u0026gt;onLButtonUp(xPos, yPos); } else if (WM_LBUTTONDBLCLK == uMsg) { msgHandler-\u0026gt;onLButtonDBClick(xPos, yPos); } } 选取区域结束时，将选择的区域保存为位图并存至某个路径下：\nvoid ScreenCapture::finishCapture() { RECT rcSelect = {0}; UIScreenCaptureMgr::Instance()-\u0026gt;sendBkgMessage(WM_SNAPSHOT_TEST_SELECT_RECT, (WPARAM)\u0026amp;rcSelect, 0); rcSelect.left += 2; rcSelect.top += 2; rcSelect.right -= 2; rcSelect.bottom -= 2; if (!ScreenCommon::isRectEmpty(rcSelect)) { ScreenSnapshot::Instance()-\u0026gt;saveRect(rcSelect, m_strSavePath); } cancelCapture(); if (m_callBack) m_callBack-\u0026gt;onScreenCaptureFinish(m_strSavePath); }\tRECT rcSelect = {0}; UIScreenCaptureMgr::Instance()-\u0026gt;sendBkgMessage(WM_SNAPSHOT_TEST_SELECT_RECT, (WPARAM)\u0026amp;rcSelect, 0); rcSelect.left += 2; rcSelect.top += 2; rcSelect.right -= 2; rcSelect.bottom -= 2; if (!ScreenCommon::isRectEmpty(rcSelect)) { ScreenSnapshot::Instance()-\u0026gt;saveRect(rcSelect, m_strSavePath); } cancelCapture(); if (m_callBack) m_callBack-\u0026gt;onScreenCaptureFinish(m_strSavePath); } BOOL ScreenSnapshot::saveRect(__in RECT \u0026amp;rc, __in std::wstring \u0026amp;savePath) { snapshotScreen(); CxImage img; int cx = rc.right - rc.left; int cy = rc.bottom - rc.top; HDC hSaveDC = CreateCompatibleDC(m_hMemDC); HBITMAP hBitmap = CreateCompatibleBitmap(m_hMemDC, cx, cy); HBITMAP hSaveBitmap = (HBITMAP)SelectObject(hSaveDC, (HGDIOBJ)hBitmap); BitBlt(hSaveDC, 0, 0, cx, cy, m_hMemDC, rc.left, rc.top, SRCCOPY); hBitmap = (HBITMAP)SelectObject(hSaveDC, (HBITMAP)hSaveBitmap); BOOL result = FALSE; do { if (!img.CreateFromHBITMAP(hBitmap)) { break; } if (!img.Save(savePath.c_str(), CXIMAGE_FORMAT_BMP)) { break; } result = TRUE; } while (FALSE); DeleteObject((HGDIOBJ)hBitmap); DeleteDC(hSaveDC); return result; } 注意整个过程使用了一个神奇的windows API，你没看错，它叫mouse_event，很少有windows API长成这个样子。利用这个api可以用程序模拟鼠标很多事件，后面有时间我会专门介绍一下这个有用的API函数。当然，关于截图的描述，你可能有点迷糊。没关系，后面我会专门写一篇文章细致地探究下teamtalk的屏幕截图效果实现，因为这里面有价值的东西很多。\n线程的创建 IMCoreErrorCode OperationManager::startup() { m_operationThread = std::thread([\u0026amp;] { std::unique_lock \u0026lt;std::mutex\u0026gt; lck(m_cvMutex); Operation* pOperation = nullptr; while (m_bContinue) { if (!m_bContinue) break; if (m_vecRealtimeOperations.empty()) m_CV.wait(lck); if (!m_bContinue) break; { std::lock_guard\u0026lt;std::mutex\u0026gt; lock(m_mutexOperation); if (m_vecRealtimeOperations.empty()) continue; pOperation = m_vecRealtimeOperations.front(); m_vecRealtimeOperations.pop_front(); } if (!m_bContinue) break; if (pOperation) { pOperation-\u0026gt;process(); pOperation-\u0026gt;release(); } } }); return IMCORE_OK; } 这是利用lamda表达式创建一个线程典型的语法，其中m_operationThread是一个成员变量，类型是std::thread，std::thread([\u0026amp;]中括号中的\u0026amp;符号表示该lamda表达式以引用的方式捕获了所有外部的自动变量，这是在一个成员函数里面，也就是说在线程函数里面可以以引用的方式使用该类的所有成员变量。这个语法值得大家学习。\nteamtalk的httpclient工程可以直接拿来使用，作者主页：http://xiangwangfeng.com，github链接：https://github.com/xiangwangfeng/httpclient。 另外teamtalk pc端大量使用C++11的语法和一些替代原来平常的写法，这个就不专门列出来了，后面我将会专门写一篇文章来介绍C++11中那些好用的工程级技巧。\n好了，这篇文章就到此为止了。限于作者水平有限，文中难免有错漏和不足，欢迎批评指正。 ","permalink":"https://haokiu.com/blog/ee4c77c4daf64f5f821d76808ec0b8b3/","summary":"11 pc客户端源码分析 ——写在前面的话\n在要不要写这篇文章的纠结中挣扎了好久，就我个人而已，我接触windows编程，已经六七个年头了，尤其是在我读研的三年内，基本心思都是花在学习和研究windows程序上了。我很庆幸我当初学习windows程序走了一条正确的路线：先是学习常用的windows程序原理和基本API，再学习的mfc、wtl等一些常用的框架和类库，同时看了大量windows项目的源码，如金山卫士的开源代码、filezilla、电驴源码等等。个人觉得，基础真的很重要，拿windows开发来说，当你掌握了windows的程序的基本原理，我列一下大致范围：\nwindows消息机制（消息如何产生、如何发送、如何处理，常见的消息有哪些、消息的优先级、如何自定义消息、窗体消息、常用控件消息）\ngdi原理（要熟悉gdi的各种对象，如画笔、画刷、字体、区域、裁剪、位图等，熟悉它们的API，熟悉各种gdi绘图API、当然最好也要熟悉一整套的gdi+的类，gdi与gdi+的区别）\nwindows进程与线程的概念（进程的概念、如何创建、如何结束、跨进程如何通信；线程的创建与销毁、线程间的同步与资源保护，熟悉windows常用的线程同步对象：临界区、事件、互斥体、信号量等）\nwindows内存管理（清晰地掌握一个进程地址空间的内存分布、windows堆的创建与管理等）\ndll技术（dll的生成、变量的导出、函数的导出、类的导出、如何查看dll导出哪些函数、隐式dll的加载、显示dll的加载、远程dll注入技术等）\nPE文件（一个PE文件的结构、有哪些节、如何修改、分别映射到进程地址空间的什么位置等）\nwindows SEH（结构化异常处理）\nwindows socket编程\nwindows读写文件技术（像CreateFile、WriteFile、GetFileSize等这些API应该熟练掌握、内存映射技术）\n当然很多必备的技术也不好归类到windows技术下面，比如socket编程，这涉及到很多网络的知识，比如tcp的三次握手，数据的收发等，还有就是各种字符编码的知识、以及之间的相互转换，又比如一系列的CRT函数及其对应的宽字符版本。当然如果你搞windows开发，一定要熟悉开发工具Visual Studio，熟悉其工程项目的大多数属性配置，而且要做到知其然也知其所以然。如果不是不能跨平台，我敢说VS是史上最好最强大的开发工具，没有之一！我已经有好几年年不做windows开发了，目前主要从事linux开发，但windows的很多设计思想真的很好，非常值得借鉴，而且从编码风格来说，虽然看起来有点怪异，但是非常规范和易懂。\n有了基础知识，你可以轻松地对工作中的一些问题给出解决方案，也能轻松阅读和使用市面上的那些库，比如，如果你深刻理解windows GDI，你不会在一个群里大喊，duilib某个属性为什么不起作用，你可以直接去阅读它的画法代码，如果是bug你可以改bug，如果只是你使用错误，你可以了解到正确的使用方法。所以基础这个东西，在短时间内，可能让你看不出与其他人的差别，但是从长远来看，它决定着你在技术上走的高度与深度。套用侯捷先生的一句话：勿在浮沙筑高台。\n—— 正题\n上面简单地介绍了下，我个人学习windows程序设计的一些心得吧。扯的有点远了，让我们回到正题上来，来分析TeamTalk的源码吧。当然这篇文章与前面介绍的不一样，我们不仅介绍程序的正题设计思路，还会介绍一些有意义的细节，比如一些windows开发中常用的一些细节。\n一、程序功能 我们来先看下TeamTalk pc客户端包括哪些功能：TeamTalk因为开发的初衷是用于企业内部的即时通讯软件，所以，不提供对外注册的功能，一个员工的加入一般是人事部门在后台管理系统来新增该员工信息。其功能包括登录、聊天、群聊和建讨论组，当然聊天过程中可以发文字、表情、图片和文件，还包括查看聊天记录和简单地查看某个员工的个人信息，业务功能其实不多的。下面是一些功能截图：\n二、编译方法与项目工程文件介绍 TeamTalk的pc客户端的下载地址是：https://github.com/baloonwj/TeamTalk 代码包括服务器端代码、pc端、mac端、安卓和IOS端，还有web端所有代码。\npc客户端代码的编译方法很简单：用VS2013打开win-client\\solution目录下的teamtalk.sln，编译即可。你的VS版本至少要是VS2013，因为代码中大量使用了C++11的东西，VS2013以下版本是不支持C++11的语法的。当然，如果你是VS2015的话，可以参考这篇文章来进行修改和编译：http://www.07net01.com/linux/2017/01/1795569.html\n打开teamtalk.sln之后，总共有10个解决方法，如下图所示：\n其中teamtalk是主工程，你应该将它设置成启动工程，编译完成之后就可以调试了。你可以自己配置服务器来连接进行调试，我也可以连接我的测试服务器，具体参见《TeamTalk源码分析（十） —— 开放一个TeamTalk测试服务器地址和几个测试账号》。下面先大致介绍一个各个工程的作用：\nDuilib是teamtalk使用的一款开源界面库，该界面库模仿web开发中的布局技术，使用xml文件来布局windows界面，并且在主窗口上绘制所有子控件，也就是所谓的directUI技术；\nGifSmiley是程序中用来解析和显示gif格式的图片的库，以支持gif图片的动画效果；\nhttpclient功能是程序中使用的http请求库，登录前程序会先连接服务器的login_server以获得后续需要登录的msg_server的ip地址和端口号 等信息，这里就是使用的http协议，同时聊天过程中收发的聊天图片与图片服务器msfs也使用http协议来收发这些图片；\nlibogg是一个语音库，用来解析声音文件的，因为pc客户端可能会收到移动端的语音聊天，相比较传统的*.wav、.mp3、.wma，*.ogg格式的不仅音质高，而且音频文件的体积小，腾讯的QQ游戏英雄杀中的语音也是使用这个格式的。\nlibspeex是一个音频压缩库；\nModules就是TeamTalk中使用的各种库了，展开来看下你就明白了：\nnetwork是teamtalk使用的网络通信的代码，其实teamtalk pc端和服务器端使用的是同一套网络通信库，只不过如果服务器运行在linux下，其核心的IO复用模型是epoll，而pc客户端使用的IO复用模型是select；\nspeexdec 也是和ogg格式相关的编码和解码器；\nteamtalk是主程序入口工程；\nutility包含了teamtalk中用到的一些工具类工程，比如sqlite的包装接口、md5工具类等。\n除了上面介绍的一些库以外，程序还使用了sqlite库、谷歌protobuf库、日志库yaolog等。关于yaolog可参见http://blog.csdn.net/gemo/article/details/8499692，这个日志库比较有意思的地方是可以单独打印出网络通信中的字节流的二进制形式，推荐一下，效果如下图所示（位于win-client\\bin\\teamtalk\\Debug\\log\\socket.log文件中）：\n三、程序总体框架介绍 整个程序使用了mfc框架来做一个架子，而所有的窗口和对话框都使用的是duilib，关于duilib网上有很多资料，这里不介绍duilib细节的东西了。一个mfc程序框架，使用起来也很简单，就是定义一个类集成mfc的CWinApp类，并改写其InitInstance()方法，mfc内部会替我们做好消息循环的步骤。TeamTalk相关的代码如下：\n//位于teamtalk.h中 class CteamtalkApp : public CWinApp { public: CteamtalkApp(); public: virtual BOOL InitInstance(); virtual BOOL ExitInstance(); private: /** * 创建用户目录 * * @return BOOL * @exception there is no any exception to throw. */\tBOOL _CreateUsersFolder(); /** * 创建主窗口 * * @return BOOL * @exception there is no any exception to throw.","title":"11 pc客户端源码分析"},{"content":"11 一种高性能网络游戏服务器架构设计 ​ 网络游戏的结构分为客户端与服务器端，客户端采用2D绘制引擎或者3D绘制引擎绘制游戏世界的实时画面，服务器端则负责响应所有客户端的连接请求和游戏逻辑处理，并控制所有客户端的游戏画面绘制。客户端与服务器通过网络数据包交互完成每一步游戏逻辑，由于游戏逻辑是由服务器负责处理的，要保证面对海量用户登录时，游戏具有良好的流畅性和用户体验，优秀的服务器架构起到了关键的作用。\n1 服务器架构设计 1.1 服务器架构分类 服务器组的架构一般分为两种：第一种是带网关服务器的服务器架构；第二种是不带网关服务器的服务器架构，这两种方案各有利弊。在给出服务器架构设计之前，先对这两种设计方案进行详细的探讨。 所谓网关服务器，其实是Gate服务器，比如LoginGate、GameGate等。网关服务器的主要职责是将客户端和游戏服务器隔离，客户端程序直接与这些网关服务器通信，并不需要知道具体的游戏服务器内部架构，包括它们的IP、端口、网络通信模型(完成端口或Epoll)等。客户端只与网关服务器相连，通过网关服务器转发数据包间接地与游戏服务器交互。同样地，游戏服务器也不直接和客户端通信，发给客户端的协议都通过网关服务器进行转发。\n1.2 服务器架构设计 根据网络游戏的规模和设计的不同，每组服务器中服务器种类和数量是不尽相同的。本文设计出的带网关服务器的服务器组架构如图1所示。\n本文将服务器设计成带网关服务器的架构，虽然加大了服务器的设计复杂度，但却带来了以下几点好处： （1）作为网络通信的中转站，负责维护将内网和外网隔离开，使外部无法直接访问内部服务器，保障内网服务器的安全，一定程度上较少外挂的攻击。 （2）网关服务器负责解析数据包、加解密、超时处理和一定逻辑处理，这样可以提前过滤掉错误包和非法数据包。 （3）客户端程序只需建立与网关服务器的连接即可进入游戏，无需与其它游戏服务器同时建立多条连接，节省了客户端和服务器程序的网络资源开销。 （4）在玩家跳服务器时，不需要断开与网关服务器的连接，玩家数据在不同游戏服务器间的切换是内网切换，切换工作瞬间完成，玩家几乎察觉不到，这保证了游戏的流畅性和良好的用户体验。\n在享受网关服务器带来上述好处的同时，还需注意以下可能导致负面效果的两个情况：如何避免网关服务器成为高负载情况下的通讯瓶颈问题以及由于网关的单节点故障导致整组服务器无法对外提供服务的问题。上述两个问题可以采用“多网关” 技术加以解决。顾名思义，“多网关” 就是同时存在多个网关服务器，比如一组服务器可以配置三台GameGate。当负载较大时，可以通过增加网关服务器来增加网关的总体通讯流量，当一台网关服务器宕机时，它只会影响连接到本服务器的客户端，其它客户端不会受到任何影响。\n从图1的服务器架构图可以看出，一组服务器包括LoginGate、LoginServer、GameGate、GameServer、DBServer和MServer等多种服务器。LoginGate和GameGate就是网关服务器，一般一组服务器会配置3台GameGate，因为稳定性对于网络游戏运营来说是至关重要的，而服务器宕机等突发事件是游戏运营中所面临的潜在风险，配置多台服务器可以有效地降低单个服务器宕机带来的风险。另外，配置多台网关服务器也是进行负载均衡的有效手段之一。下面将对各种服务器的主要功能和彼此之间的数据交互做详细解释。\n（1）LoginGate LoginGate主要负责在玩家登录时维护客户端与LoginServer之间的网络连接与通讯，对LoginServer和客户端的通信数据进行加解密、校验。\n（2）LoginServer\nLoginServer主要功能是验证玩家的账号是否合法，只有通过验证的账号才能登录游戏。从架构图可以看出， DBServer和GameServer会连接LoginServer。玩家登录基本流程是，客户端发送账号和密码到LoginServer验证，如果验证通过，LoginServer会给玩家分配一个SessionKey，LoginServer会把这个SessionKey发送给客户端、DBServer和GameServer，在后续的选择角色以后进入游戏过程中，DBServer和GameServer将验证SessionKey合法性，如果和客户端携带的SessionKey不一致，将无法成功获取到角色或者进入游戏。\n（3）GameGate\nGameGate(GG)主要负责在用户游戏过程中负责维持GS与客户端之间的网络连接和通讯，对GS和客户端的通信数据进行加解密和校验，对客户端发往GS的用户数据进行解析，过滤错误包，对客户端发来的一些协议作简单的逻辑处理，其中包括游戏逻辑中的一些超时判断。在用户选择角色过程中负责维持DBServer与客户端之间的网络连接和通讯，对DBServer和客户端的通信数据进行加解密和校验，对客户端发往DBServer的用户数据做简单的分析。维持客户端与MServer之间的网络连接与通讯、加解密、数据转发和简单的逻辑处理等。\n（4）GameServer\nGameServer(GS)主要负责游戏逻辑处理。网络游戏有庞大世界观背景，绚丽激烈的阵营对抗以及完备的装备和技能体系。目前，网络游戏主要包括任务系统、声望系统、玩家PK、宠物系统、摆摊系统、行会系统、排名系统、副本系统、生产系统和宝石系统等。从软件架构角度来看，这些系统可以看着GS的子系统或模块，它们共同处理整个游戏世界逻辑的运算。游戏逻辑包括角色进入与退出游戏、跳GS以及各种逻辑动作(比如行走、跑动、说话和攻击等)。\n由于整个游戏世界有许多游戏场景，在该架构中一组服务器有3台GS共同负责游戏逻辑处理，每台游戏服务器负责一部分地图的处理，这样不仅降低了单台服务器的负载，而且降低了GS宕机带来的风险。玩家角色信息里会保持玩家上次退出游戏时的地图编号和所在GS编号，这样玩家再次登录时，会进入到上次退出时的GS。\n上面提到过，在验证账号之后，LoginServer会把这个SessionKey 发给GS，当玩家选择角色登录GS时，会把SessionKey一起发给GS，这时GS会验证SessionKey是否与其保存的相一致，不一致的话GS会拒绝玩家进入游戏。MServer的主要负责GS之间的数据转发以及数据广播，另外，一些系统也可以放到MServer上，这样也可以减轻GS的运算压力。\n（5）DBServer\nDBServer主要的功能是缓存玩家角色数据，保证角色数据能快速的读取和保存。由于角色数据量是比较大的，包括玩家的等级、经验、生命值、魔法值、装备、技能、好友、公会等。如果每次GS获取角色数据都去读数据库，效率必然非常低下，用DBServer缓存角色数据之后，极大地提高了数据请求的响应速度。\nLoginServer会在玩家选组时把SessionKey发给DBServer，当玩家发送获取角色信息协议时会带上这个SessionKey，如果跟DBServer保存的SessionKey不一致，则DBServer会认为玩家不是合法用户，获取角色协议将会失败。另外，玩家选取角色正式进入游戏时，GS会给DBServer发送携带SessionKey的获取角色信息协议，这时DBServer同样会验证SessionKey的合法性。总之，只有客户端、DBServer和GS所保存的SessionKey一致，才能保证协议收到成功反馈。\n与DBServer通讯的服务器主要有GG，GS和LoginServer，DBServer与GG交互的协议主要包括列角色、创建角色、删除角色、恢复角色等，DBServer与GS交互的协议包括读取角色数据、保存角色数据和跳服务器等，DBServer与LoginServer交互的协议主要是用户登录协议，这时候会给DBServer发送SessionKey。\n（6）MServer 每一个组有一台MServer，主要负责维持3台GS之间数据的转发和数据广播。另外一些游戏系统也可能会放到MServer上处理，比如行会系统。\n1.3 服务器交互的主要流程 下面给出服务器之间数据通讯的主要流程从这些流程能看出各种服务器之间是如何数据交互和协同工作的。\n图2的流程说明了，在选角色过程中，客户端会把携带游戏账号和SessionKey的选角色协议发给GG，GG做一些简单处理之后转发给DBServer，DBServer要验证SessionKey的合法性，验证通过之后，DBServer会从角色信息缓冲区里取出该账户的所有角色信息发给客户端。这个过程在客户端的表现是，当选择好服务器组之后，客户端会直接显示该账号下的所有角色，之后就可以选择角色进入游戏了。\n图3的流程说明了，在玩家选角色正式进入游戏时，客户端会把携带游戏账号、角色ID和SessionKey的登录协议发给GG，GG做一些简单处理之后转发给GS。GS会验证SessionKey的合法性，验证通过之后，GS会把验证通过的结果发给客户端，同时GS给DBServer发获取角色数据的协议，这些角色数据是一个玩家所有的游戏数据，包括装备、技能等等。\n图4的流程说明了，在玩家游戏过程，客户端把逻辑协议(包括走、说话、跑、使用技能等)发给GG，GG完成加解密和简单逻辑处理之后转发给GS，GS负责这些协议的主要 逻辑处理。\n2 总结 网络游戏服务器的架构设计已经成为当前网络游戏研究领域的热点，因为高性能服务器架构设计是一款网络游戏成功的关键。本文从实际应用出发，提出了一种高性能的服务器架构设计解决方案，并且详细探讨了各种服务器的功能，本文的最后给出了几个服务器之间数据通讯的关键流程，以图文并茂的方式解释各个服务器是如何协同工作的。\n","permalink":"https://haokiu.com/blog/8d180ec3ae3e409bac6e8a67811f54bc/","summary":"11 一种高性能网络游戏服务器架构设计 ​ 网络游戏的结构分为客户端与服务器端，客户端采用2D绘制引擎或者3D绘制引擎绘制游戏世界的实时画面，服务器端则负责响应所有客户端的连接请求和游戏逻辑处理，并控制所有客户端的游戏画面绘制。客户端与服务器通过网络数据包交互完成每一步游戏逻辑，由于游戏逻辑是由服务器负责处理的，要保证面对海量用户登录时，游戏具有良好的流畅性和用户体验，优秀的服务器架构起到了关键的作用。\n1 服务器架构设计 1.1 服务器架构分类 服务器组的架构一般分为两种：第一种是带网关服务器的服务器架构；第二种是不带网关服务器的服务器架构，这两种方案各有利弊。在给出服务器架构设计之前，先对这两种设计方案进行详细的探讨。 所谓网关服务器，其实是Gate服务器，比如LoginGate、GameGate等。网关服务器的主要职责是将客户端和游戏服务器隔离，客户端程序直接与这些网关服务器通信，并不需要知道具体的游戏服务器内部架构，包括它们的IP、端口、网络通信模型(完成端口或Epoll)等。客户端只与网关服务器相连，通过网关服务器转发数据包间接地与游戏服务器交互。同样地，游戏服务器也不直接和客户端通信，发给客户端的协议都通过网关服务器进行转发。\n1.2 服务器架构设计 根据网络游戏的规模和设计的不同，每组服务器中服务器种类和数量是不尽相同的。本文设计出的带网关服务器的服务器组架构如图1所示。\n本文将服务器设计成带网关服务器的架构，虽然加大了服务器的设计复杂度，但却带来了以下几点好处： （1）作为网络通信的中转站，负责维护将内网和外网隔离开，使外部无法直接访问内部服务器，保障内网服务器的安全，一定程度上较少外挂的攻击。 （2）网关服务器负责解析数据包、加解密、超时处理和一定逻辑处理，这样可以提前过滤掉错误包和非法数据包。 （3）客户端程序只需建立与网关服务器的连接即可进入游戏，无需与其它游戏服务器同时建立多条连接，节省了客户端和服务器程序的网络资源开销。 （4）在玩家跳服务器时，不需要断开与网关服务器的连接，玩家数据在不同游戏服务器间的切换是内网切换，切换工作瞬间完成，玩家几乎察觉不到，这保证了游戏的流畅性和良好的用户体验。\n在享受网关服务器带来上述好处的同时，还需注意以下可能导致负面效果的两个情况：如何避免网关服务器成为高负载情况下的通讯瓶颈问题以及由于网关的单节点故障导致整组服务器无法对外提供服务的问题。上述两个问题可以采用“多网关” 技术加以解决。顾名思义，“多网关” 就是同时存在多个网关服务器，比如一组服务器可以配置三台GameGate。当负载较大时，可以通过增加网关服务器来增加网关的总体通讯流量，当一台网关服务器宕机时，它只会影响连接到本服务器的客户端，其它客户端不会受到任何影响。\n从图1的服务器架构图可以看出，一组服务器包括LoginGate、LoginServer、GameGate、GameServer、DBServer和MServer等多种服务器。LoginGate和GameGate就是网关服务器，一般一组服务器会配置3台GameGate，因为稳定性对于网络游戏运营来说是至关重要的，而服务器宕机等突发事件是游戏运营中所面临的潜在风险，配置多台服务器可以有效地降低单个服务器宕机带来的风险。另外，配置多台网关服务器也是进行负载均衡的有效手段之一。下面将对各种服务器的主要功能和彼此之间的数据交互做详细解释。\n（1）LoginGate LoginGate主要负责在玩家登录时维护客户端与LoginServer之间的网络连接与通讯，对LoginServer和客户端的通信数据进行加解密、校验。\n（2）LoginServer\nLoginServer主要功能是验证玩家的账号是否合法，只有通过验证的账号才能登录游戏。从架构图可以看出， DBServer和GameServer会连接LoginServer。玩家登录基本流程是，客户端发送账号和密码到LoginServer验证，如果验证通过，LoginServer会给玩家分配一个SessionKey，LoginServer会把这个SessionKey发送给客户端、DBServer和GameServer，在后续的选择角色以后进入游戏过程中，DBServer和GameServer将验证SessionKey合法性，如果和客户端携带的SessionKey不一致，将无法成功获取到角色或者进入游戏。\n（3）GameGate\nGameGate(GG)主要负责在用户游戏过程中负责维持GS与客户端之间的网络连接和通讯，对GS和客户端的通信数据进行加解密和校验，对客户端发往GS的用户数据进行解析，过滤错误包，对客户端发来的一些协议作简单的逻辑处理，其中包括游戏逻辑中的一些超时判断。在用户选择角色过程中负责维持DBServer与客户端之间的网络连接和通讯，对DBServer和客户端的通信数据进行加解密和校验，对客户端发往DBServer的用户数据做简单的分析。维持客户端与MServer之间的网络连接与通讯、加解密、数据转发和简单的逻辑处理等。\n（4）GameServer\nGameServer(GS)主要负责游戏逻辑处理。网络游戏有庞大世界观背景，绚丽激烈的阵营对抗以及完备的装备和技能体系。目前，网络游戏主要包括任务系统、声望系统、玩家PK、宠物系统、摆摊系统、行会系统、排名系统、副本系统、生产系统和宝石系统等。从软件架构角度来看，这些系统可以看着GS的子系统或模块，它们共同处理整个游戏世界逻辑的运算。游戏逻辑包括角色进入与退出游戏、跳GS以及各种逻辑动作(比如行走、跑动、说话和攻击等)。\n由于整个游戏世界有许多游戏场景，在该架构中一组服务器有3台GS共同负责游戏逻辑处理，每台游戏服务器负责一部分地图的处理，这样不仅降低了单台服务器的负载，而且降低了GS宕机带来的风险。玩家角色信息里会保持玩家上次退出游戏时的地图编号和所在GS编号，这样玩家再次登录时，会进入到上次退出时的GS。\n上面提到过，在验证账号之后，LoginServer会把这个SessionKey 发给GS，当玩家选择角色登录GS时，会把SessionKey一起发给GS，这时GS会验证SessionKey是否与其保存的相一致，不一致的话GS会拒绝玩家进入游戏。MServer的主要负责GS之间的数据转发以及数据广播，另外，一些系统也可以放到MServer上，这样也可以减轻GS的运算压力。\n（5）DBServer\nDBServer主要的功能是缓存玩家角色数据，保证角色数据能快速的读取和保存。由于角色数据量是比较大的，包括玩家的等级、经验、生命值、魔法值、装备、技能、好友、公会等。如果每次GS获取角色数据都去读数据库，效率必然非常低下，用DBServer缓存角色数据之后，极大地提高了数据请求的响应速度。\nLoginServer会在玩家选组时把SessionKey发给DBServer，当玩家发送获取角色信息协议时会带上这个SessionKey，如果跟DBServer保存的SessionKey不一致，则DBServer会认为玩家不是合法用户，获取角色协议将会失败。另外，玩家选取角色正式进入游戏时，GS会给DBServer发送携带SessionKey的获取角色信息协议，这时DBServer同样会验证SessionKey的合法性。总之，只有客户端、DBServer和GS所保存的SessionKey一致，才能保证协议收到成功反馈。\n与DBServer通讯的服务器主要有GG，GS和LoginServer，DBServer与GG交互的协议主要包括列角色、创建角色、删除角色、恢复角色等，DBServer与GS交互的协议包括读取角色数据、保存角色数据和跳服务器等，DBServer与LoginServer交互的协议主要是用户登录协议，这时候会给DBServer发送SessionKey。\n（6）MServer 每一个组有一台MServer，主要负责维持3台GS之间数据的转发和数据广播。另外一些游戏系统也可能会放到MServer上处理，比如行会系统。\n1.3 服务器交互的主要流程 下面给出服务器之间数据通讯的主要流程从这些流程能看出各种服务器之间是如何数据交互和协同工作的。\n图2的流程说明了，在选角色过程中，客户端会把携带游戏账号和SessionKey的选角色协议发给GG，GG做一些简单处理之后转发给DBServer，DBServer要验证SessionKey的合法性，验证通过之后，DBServer会从角色信息缓冲区里取出该账户的所有角色信息发给客户端。这个过程在客户端的表现是，当选择好服务器组之后，客户端会直接显示该账号下的所有角色，之后就可以选择角色进入游戏了。\n图3的流程说明了，在玩家选角色正式进入游戏时，客户端会把携带游戏账号、角色ID和SessionKey的登录协议发给GG，GG做一些简单处理之后转发给GS。GS会验证SessionKey的合法性，验证通过之后，GS会把验证通过的结果发给客户端，同时GS给DBServer发获取角色数据的协议，这些角色数据是一个玩家所有的游戏数据，包括装备、技能等等。\n图4的流程说明了，在玩家游戏过程，客户端把逻辑协议(包括走、说话、跑、使用技能等)发给GG，GG完成加解密和简单逻辑处理之后转发给GS，GS负责这些协议的主要 逻辑处理。\n2 总结 网络游戏服务器的架构设计已经成为当前网络游戏研究领域的热点，因为高性能服务器架构设计是一款网络游戏成功的关键。本文从实际应用出发，提出了一种高性能的服务器架构设计解决方案，并且详细探讨了各种服务器的功能，本文的最后给出了几个服务器之间数据通讯的关键流程，以图文并茂的方式解释各个服务器是如何协同工作的。","title":"11 一种高性能网络游戏服务器架构设计"},{"content":"12 经典游戏服务器端架构概述 架构的分析模型 一. 讨论的背景 ​ 现代电子游戏，基本上都会使用一定的网络功能。从验证正版，到多人交互等等，都需要架设一些专用的服务器，以及编写在服务器上的程序。因此，游戏服务器端软件的架构，本质上也是游戏服务器这个特定领域的软件架构。 ​ 软件架构的分析，可以通过不同的层面入手。比较经典的软件架构描述，包含了以下几种架构： ​ 1.运行时架构——这种架构关心如何解决运行效率问题，通常以程序进程图、数据流图为表达方式。在大多数开发团队的架构设计文档中，都会包含运行时架构，说明这是一种非常重要的设计方面。这种架构也会显著的影响软件代码的开发效率和部署效率。本文主要讨论的是这种架构。 ​ 2.逻辑架构——这种架构关心软件代码之间的关系，主要目的是为了提高软件应对需求变更的便利性。人们往往会以类图、模块图来表达这种架构。这种架构设计在需要长期运营和重用性高的项目中，有至关重要的作用。因为软件的可扩展性和可重用度基本是由这个方面的设计决定的。特别是在游戏领域，需求变更的频繁程度，在多个互联网产业领域里可以说是最高的。本文会涉及一部分这种架构的内容，但不是本文的讨论重点。 ​ 3.物理架构——关心软件如何部署，以机房、服务器、网络设备为主要描述对象。 ​ 4.数据架构——关心软件涉及的数据结构的设计，对于数据分析挖掘，多系统协作有较大的意义。 ​ 5.开发架构——关心软件开发库之间的关系，以及版本管理、开发工具、编译构建的设计，主要为了提高多人协作开发，以及复杂软件库引用的开发效率。现在流行的集成构建系统就是一种开发架构的理论。\n二. 游戏服务器架构的要素 ​ 服务器端软件的本质，是一个会长期运行的程序，并且它还要服务于多个不定时，不定地点的网络请求。所以这类软件的特点是要非常关注稳定性和性能。这类程序如果需要多个协作来提高承载能力，则还要关注部署和扩容的便利性；同时，还需要考虑如何实现某种程度容灾需求。由于多进程协同工作，也带来了开发的复杂度，这也是需要关注的问题。 ​ 功能约束，是架构设计决定性因素。一个万能的架构，必定是无能的架构。一个优秀的架构，则是正好把握了对应业务领域的核心功能产生的。游戏领域的功能特征，于服务器端系统来说，非常明显的表现为几个功能的需求： ​ 1.对于游戏数据和玩家数据的存储 ​ 2.对玩家客户端进行数据广播 ​ 把一部分游戏逻辑在服务器上运算，便于游戏更新内容，以及防止外挂。 ​ 针对以上的需求特征，在服务器端软件开发上，我们往往会关注软件对电脑内存和CPU的使用，以求在特定业务代码下，能尽量满足承载量和响应延迟的需求。最基本的做法就是“时空转换”，用各种缓存的方式来开发程序，以求在CPU时间和内存空间上取得合适的平衡。在CPU和内存之上，是另外一个约束因素：网卡。网络带宽直接限制了服务器的处理能力，所以游戏服务器架构也必定要考虑这个因素。 ​ 对于游戏服务器架构设计来说，最重要的是利用游戏产品的需求约束，从而优化出对此特定功能最合适的“时-空”架构。并且最小化对网络带宽的占用。\n[图：游戏服务器的分析模型]\n三. 核心的三个架构 ​ 基于上述的分析模型，对于游戏服务端架构，最重要的三个部分就是，如何使用CPU、内存、网卡的设计： ​ 1.内存架构：主要决定服务器如何使用内存，以保证尽量少的内存泄漏的可能，以及最大化利用服务器端内存来提高承载量，降低服务延迟。 ​ 2.调度架构：设计如何使用进程、线程、协程这些对于CPU调度的方案。选择同步、异步等不同的编程模型，以提高服务器的稳定性和承载量。同时也要考虑对于开发带来的复杂度问题。现在出现的虚拟化技术，如虚拟机、docker、云服务器等，都为调度架构提供了更多的选择。 ​ 3.通信模式：决定使用何种方式通讯。网络通讯包含有传输层的选择，如TCP/UDP；据表达层的选择，如定义协议；以及应用层的接口设计，如消息队列、事件分发、远程调用等。 ​ 本文的讨论，也主要是集中于对以上三个架构的分析。\n四. 游戏服务器模型的进化历程 ​ 最早的游戏服务器是比较简单的，如UO《网络创世纪》的服务端一张3.5寸软盘就能存下。基本上只是一个广播和存储文件的服务器程序。后来由于国内的外挂、盗版流行，各游戏厂商开始以MUD为模型，建立主要运行逻辑在服务器端的架构。这种架构在MMORPG类产品的不断更新中发扬光大，从而出现了以地图、视野等分布要素设计的分布式游戏服务器。而在另外一个领域，休闲游戏，天然的需要集中超高的在线用户，所以全区型架构开始出现。现代的游戏服务器架构，基本上都希望能结合承载量和扩展性的有点来设计，从而形成了更加丰富多样的形态。 ​ 本文的讨论主要是选取这些比较典型的游戏服务器模型，分析其底层各种选择的优点和缺点，希望能探讨出更具广泛性，更高开发效率的服务器模型。\n分服模型 一. 模型描述 ​ 分服模型是游戏服务器中最典型，也是历久最悠久的模型。其特征是游戏服务器是一个个单独的世界。每个服务器的帐号是独立的，而且只用同一服务器的帐号才能产生线上交互。在早期服务器的承载量达到上限的时候，游戏开发者就通过架设更多的服务器来解决。这样提供了很多个游戏的“平行世界”，让游戏中的人人之间的比较，产生了更多的空间。所以后来以服务器的开放、合并形成了一套成熟的运营手段。一个技术上的选择最后导致了游戏运营方式的模式，是一个非常有趣的现象。\n[图：分服模型]\n二. 调度架构 1.单进程游戏服务器 最简单的游戏服务器只有一个进程，是一个单点。这个进程如果退出，则整个游戏世界消失。在此进程中，由于需要处理并发的客户端的数据包，因此产生了多种选择方法：\n[图：单进程调度模型]\n​ a.同步-动态多线程：每接收一个用户会话，就建立一个线程。这个用户会话往往就是由客户端的TCP连接来代表，这样每次从socket中调用读取或写出数据包的时候，都可以使用阻塞模式，编码直观而简单。有多少个游戏客户端的连接，就有多少个线程。但是这个方案也有很明显的缺点，就是服务器容易产生大量的线程，这对于内存占用不好控制，同时线程切换也会造成CPU的性能损失。更重要的多线程下对同一块数据的读写，需要处理锁的问题，这可能让代码变的非常复杂，造成各种死锁的BUG，影响服务器的稳定性。 ​ b.同步-多线程池：为了节约线程的建立和释放，建立了一个线程池。每个用户会话建立的时候，向线程池申请处理线程的使用。在用户会话结束的时候，线程不退出，而是向线程池“释放”对此线程的使用。线程池能很好的控制线程数量，可以防止用户暴涨下对服务器造成的连接冲击，形成一种排队进入的机制。但是线程池本身的实现比较复杂，而“申请”、“施放”线程的调用规则需要严格遵守，否则会出现线程泄露，耗尽线程池。 ​ c.异步-单线程/协程：在游戏行业中，采用Linux的epoll作为网络API，以期得到高性能，是一个常见的选择。游戏服务器进程中最常见的阻塞调用就是网路IO，因此在采用epoll之后，整个服务器进程就可能变得完全没有阻塞调用，这样只需要一个线程即可。这彻底解决了多线程的锁问题，而且也简化了对于并发编程的难度。但是，“所有调用都不得阻塞”的约束，并不是那么容易遵守的，比如有些数据库的API就是阻塞的；另外单进程单线程只能使用一个CPU，在现在多核多CPU的服务器情况下，不能充分利用CPU资源。异步编程由于是基于“回调”的方式，会导致要定义很多回调函数，并且把一个流程里面的逻辑，分别写在多个不同的回调函数里面，对于代码阅读非常不理。——针对这种编码问题，协程(Coroutine)能较好的帮忙，所以现在比较流行使用异步+协程的组合。不管怎样，异步-单线程模型由于性能好，无需并发思维，依然是现在很多团队的首选。 ​ d.异步-固定多线程：这是基于异步-单线程模型进化出来的一种模型。这种模型一般有三类线程：主线程、IO线程、逻辑线程。这些线程都在内部以全异步的方式运行，而他们之间通过无锁消息队列通信。 2.多进程游戏服务器 ​ 多进程的游戏服务器系统，最早起源于对于性能问题需求。由于单进程架构下，总会存在承载量的极限，越是复杂的游戏，其单进程承载量就越低，因此开发者们一定要突破进程的限制，才能支撑更复杂的游戏。 ​ 一旦走上多进程之路，开发者们还发现了多进程系统的其他一些好处：能够利用上多核CPU能力；利用操作系统的工具能更仔细的监控到运行状态、更容易进行容灾处理。多进程系统比较经典的模型是“三层架构”。 ​ 在多进程架构下，开发者一般倾向于把每个模块的功能，都单独开发成一个进程，然后以使用进程间通信来协调处理完整的逻辑。这种思想是典型的“管道与过滤器”架构模式思想——把每个进程看成是一个过滤器，用户发来的数据包，流经多个过滤器衔接而成的管道，最后被完整的处理完。由于使用了多进程，所以首选使用单进程单线程来构造其中的每个进程。这样对于程序开发来说，结构清晰简单很多，也能获得更高的性能。\n[图:经典的三层模型]\n​ 尽管有很多好处，但是多进程系统还有一个需要特别注意的问题——数据存储。由于要保证数据的一致性，所以存储进程一般都难以切分成多个进程。就算对关系型数据做分库分表处理，也是非常复杂的，对业务类型有依赖的。而且如果单个逻辑处理进程承载不了，由于其内存中的数据难以分割和同步，开发者很难去平行的扩展某个特定业务逻辑。他们可能会选择把业务逻辑进程做成无状态的，但是这更加加重了存储进程的性能压力，因为每次业务处理都要去存储进程处拉取或写入数据。 ​ 除了数据的问题，多进程也架构也带来了一系列运维和开发上的问题：首先就是整个系统的部署更为复杂了，因为需要对多个不同类型进程进行连接配置，造成大量的配置文件需要管理；其次是由于进程间通讯很多，所以需要定义的协议也数量庞大，在单进程下一个函数调用解决的问题，在多进程下就要定义一套请求、应答的协议，这造成整个源代码规模的数量级的增大；最后是整个系统被肢解为很多个功能短小的代码片段，如果不了解整体结构，是很难理解一个完整的业务流程是如何被处理的，这让代码的阅读和交接成本巨高无比，特别是在游戏领域，由于业务流程变化非常快，几经修改后的系统，几乎没有人能完全掌握其内容。\n三. 内存架构 ​ 由于服务器进程需要长期自动化运行，所以内存使用的稳定是首要大事。在服务器进程中，就算一个触发几率很小的内存泄露，都会积累起来变成严重的运营事故。需要注意的是，不管你的线程和进程结构如何，内存架构都是需要的，除非是Erlang这种不使用堆的函数式语言。 1.动态内存 ​ 在需要的时候申请内存来处理问题，是每个程序员入门的时候必然要学会的技能。但是，如何控制内存释放却是一个大问题。在C/C++语言中，对于堆的控制至关重要。有一些开发者会以树状来规划内存使用，就是一般只new/delete一个主要的类型的对象，其他对象都是此对象的成员（或者指针成员），只要这棵树上所有的对象都管理好自己的成员，就不会出现内存漏洞，整个结构也比较清晰简单。\n[图:对象树架构]\n​ 在Objective C语言中，有所谓autorealse的特性，这种特性实际上是一种引用计数的技术。由于能配合在某个调度模型下，所以使用起来会比较简单。同样的思想，有些开发者会使用一些智能指针，配合自己写的框架，在完整的业务逻辑调用后一次性清理相关内存。\n[图:根据业务处理调度管理内存池]\n​ 在带虚拟机的语言中，最常见的是JAVA，这个问题一般会简单一些，因为有自动垃圾回收机制。但是，JAVA中的容器类型、以及static变量依然是可能造成内存泄露的原因。加上无规划的使用线程，也有可能造成内存的泄露——有些线程不会退出，而且在不断增加，最后耗尽内存。所以这些问题都要求开发者专门针对static变量以及线程结构做统一设计、严格规范。 2.预分配内存 ​ 动态分配内存在小心谨慎的程序员手上，是能发挥很好的效果的。但是游戏业务往往需要用到的数据结构非常多，变化非常大，这导致了内存管理的风险很高。为了比较彻底的解决内存漏洞的问题，很多团队采用了预先分配内存的结构。在服务器启动的时候分配所有的变量，在运行过程中不调用任何new关键字的代码。 ​ 这样做的好处除了可以有效减少内存漏洞的出现概率，也能降低动态分配内存所消耗的性能。同时由于启动时分配内存，如果硬件资源不够的话，进程就会在启动时失败，而不是像动态分配内存的程序一样，可能在任何一个分配内存的时候崩溃。然而，要获得这些好处，在编码上首先还是要遵循“动态分配架构”中对象树的原则，把一类对象构造为“根”对象，然后用一个内存池来管理这些根对象。而这个内存池能存放的根对象的数目，就是此服务进程的最大承载能力。一切都是在启动的时候决定，非常的稳妥可靠。\n[图:预分配内存池]\n​ 不过这样做，同样有一些缺点：首先是不太好部署，比如你想在某个资源较小的虚拟机上部署一套用来测试，可能一位内没改内存池的大小，导致启动不成功。每次更换环境都需要修改这个配置。其次，是所有的用到的类对象，都要在根节点对象那里有个指针或者引用，否则就可能泄漏内存。由于对于非基本类型的对象，我们一般不喜欢用拷贝的方式来作为函数的参数和返回值，而指针和应用所指向的内存，如果不能new的话，只能是现成的某个对象的成员属性。这回导致程序越复杂，这类的成员属性就越多，这些属性在代码维护是一个不小的负担。 ​ 要解决以上的缺点，可以修改内存池的实现，为动态增长，但是具备上限的模型，每次从内存池中“获取”对象的时候才new。这样就能避免在小内存机器上启动不了的问题。对于对象属性复杂的问题，一般上需要好好的按面向对象的原则规划代码，做到尽量少用仅仅表示函数参数和返回值的属性，而是主要是记录对象的“业务状态”属性为主，多花点功夫在构建游戏的数据模型上。\n四. 进程间通讯手段 ​ 在多进程的系统中，进程间如何通讯是一个至关重要的问题，其性能和使用便利性，直接决定了多进程系统的技术效能。 1.Socket通讯 ​ TCP/IP协议是一种通用的、跨语言、跨操作系统、跨机器的通讯方案。这也是开发者首先想到的一种手段。在使用上，有使用TCP和UDP两个选择。一般我们倾向在游戏系统中使用TCP，因为游戏数据的逻辑相关性比较强，UDP由于可能存在的丢包和重发处理，在游戏逻辑上的处理一般比较复杂。由于多进程系统的进程间网络一般情况较好，UDP的性能优势不会特别明显。 ​ 要使用TCP做跨进程通讯，首先就是要写一个TCP Server，做端口监听和连接管理；其次需要对可能用到的通信内容做协议定制；最后是要编写编解码和业务逻辑转发的逻辑。这些都完成了之后，才能真正的开始用来作为进程间通信手段。 ​ 使用Socket编程的好处是通用性广，你可以用来实现任何的功能，和任何的进程进行协作。但是其缺点也异常明显，就是开发量很大。虽然现在有一些开源组件，可以帮你简化Socket Server的编写工作，简化连接管理和消息分发的处理，但是选择目标建立连接、定制协议编解码这两个工作往往还是要自己去做。游戏的特点是业务逻辑变化很多，导致协议修改的工作量非常大。因此我们除了直接使用TCP/IP socket以外，还有很多其他的方案可以尝试。\n[图:TCP通讯]\n2.消息队列 在多进程系统中，如果进程的种类比较多，而且变化比较快，大量编写和配置进程之间的连接是一件非常繁琐的工作，所以开发者就发明了一种简易的通讯方法——消息队列。这种方法的底层还是Socket通讯实现，但是使用者只需要好像投递信件一样，把消息包投递到某个“信箱”，也就是队列里，目标进程则自动不断去“收取”属于自己的“信件”，然后触发业务处理。 这种模型的好处是非常简单易懂，使用者只需要处理“投递”和“收取”两个操作即可，对于消息也只需要处理“编码”和“解码”两个部分。在J2EE规范中，就有定义一套消息队列的规范，叫JMS，Apache ActiveMQ就是一个应用广泛的实现者。在Linux环境下，我们还可以利用共享内存，来承担消息队列的存储器，这样不但性能很高，而且还不怕进程崩溃导致未处理消息丢失。\n[图:消息队列]\n​ 需要注意的是，有些开发者缺乏经验，使用了数据库，如MySQL，或者是NFS这类运行效率比较低的媒介作为队列的存储者。这在功能上虽然可以行得通，但是操作一频繁，就难以发挥作用了。如以前有一些手机短信应用系统，就用MySQL来存储“待发送”的短信。 ​ 消息队列虽然非常好用，但是我们还是要自己对消息进行编解码，并且分发给所需要的处理程序。在消息到处理程序之间，存在着一个转换和对应的工作。由于游戏逻辑的繁多，这种对应工作完全靠手工编码，是比较容易出错的。所以这里还有进一步的改进空间。 3.远程调用 ​ 有一些开发者会希望，在编码的时候完全屏蔽是否跨进程在进行调用，完全可以好像调用本地函数或者本地对象的方法一样。于是诞生了很多远程调用的方案，最经典的有Corba方案，它试图实现能在不同语言的代码直接，实现远程调用。JAVA虚拟机自带了RMI方案的支持，在JAVA进程之间远程调用是比较方便的。在互联网的环境下，还有各种Web Service方案，以HTTP协议作为承载，WSDL作为接口描述。 ​ 使用远程调用的方案，最大好处是开发的便捷，你只需要写一个函数，就能在任何一个其他进程上对此函数进行调用。这对游戏开发来说，就解决了多进程方案最大的一个开发效率问题。但是这种便捷是有成本的：一般来说，远程调用的性能会稍微差一点，因为需要用一套统一的编解码方案。如果你使用的是C/C++这类静态语言，还需要使用一种IDL语言来先描述这种远程函数的接口。但是这些困难带来的好处，在游戏开发领域还是非常值得的。\n[图:远程调用]\n五. 容灾和扩容手段 ​ 在多进程模型中，由于可以采用多台物理服务器来部署服务进程，所以为容灾和扩容提供了基础条件。 ​ 在单进程模型下，容灾常常使用的热备服务器，依然可以在多进程模型中使用，但是开着一台什么都不做的服务器完全是为了做容灾，多少有点浪费。所以在多进程环境下，我们会启动多个相同功能的服务器进程，在请求的时候，根据某种规则来确定对哪个服务进程发起请求。如果这种规则能规避访问那些“失效”了的服务进程，就自动实现了容灾，如果这个规则还包括了“更新新增服务进程”的逻辑，就可以做到很方便的扩容了。而这两个规则，统一起来就是一条：对服务进程状态的集中保存和更新。 ​ 为了实现上面的方案，常常会架设一个“目录”服务器进程。这个进程专门负责搜集服务器进程的状态，并且提供查询。ZooKeeper就是实现这种目录服务器的一个优秀工具。\n[图:服务器状态管理]\n​ 尽管用简单的目录服务器可以实现大部分容灾和扩容的需求，但是如果被访问进程的内存中有数据存在，那么问题就比较复杂了。对于容灾来说，新的进程必须要有办法重建那个“失效”了的进程内存中的数据，才可能完成容灾功能；对于扩容功能来说，新加入的进程，也必须能把需要的数据载入到自己的内存中才行，而这些数据，可能已经存在于其他平行的进程中，如何把这部分数据转移过来，是一个比较耗费性能和需要编写相当多代码的工作。——所以一般我们喜欢对“无状态”的进程来做扩容和容灾。\n全服分线模型 一. 模型描述 ​ 由于多进程服务器模型的发展，游戏开发者们首先发现，由于游戏业务的特点，那些需要持久化的数据，一般都是玩家的存档，以及一些游戏本身需要用的，在运行期只读的数据。这对于存储进程的分布，提供了非常有利的条件。于是玩家数据可以存放于同一个集群中，可以不再和游戏服务器绑定在一起，因为登录的时候便可根据玩家的ID去存储集群中定位想要存取的存储进程。\n[图-全区分线模型]\n二. 存储的挑战 1.需求：扩容和容灾 在全区分线模型下，游戏玩家可以随便选择任何一个服务器登录，自己的帐号数据都可以提取出来玩。这种显然比每个服务器重新“练”一个号要省事的多。而且这样也可以和朋友们约定去一个负载较低的服务器一起玩，而不用苦苦等待某一个特定的服务器变得空闲。然而，这些好处所需要付出的代价，是在存储层的分布式设计。这种设计有一个最需要解决的问题，就是游戏服务器系统的扩容和容灾。 从模型上说，扩容是加入新的服务器，容灾是减掉失效的服务器。这两个操作在无状态的服务器进程上操作，都只是更新一下连接配置表，然后重启一下即可。但是，由于游戏存在大量的状态，包括运行时内存中的状态，以及持久化的存储状态，这就让扩容和容灾需要更多的处理才能成功。 最普通的情况下，在扩容和容灾的时候，首先需要通知所有玩家下线，把内存中的状态数据写入持久化数据进程；然后根据需要的配置，把持久化数据重新“搬迁”到新的变化后的服务器上。——如果一个游戏有几千万用户，这样的数据搬迁将会耗时非常长，玩家也被迫等待很长的时间才能重新登录游戏。所以在这种模型下，对于数据存储的设计是最关键的地方。 2.分区分服的关系型数据库 我们常常会使用MySQL这种关系型数据库来存放游戏数据。由于SQL能够表述非常复杂的数据操作，这对于游戏数据的一些后期处理有非常好的支持：如客服需要发奖励，需要撤销某些错误的运营数据，需要封停某些特征的玩家……但是，分布式数据库也是最难做分布的。一般来说我们都需要通过某一主键字段做分库和分表；而另外一些如唯一关键字等数据，就需要一些技巧来处理。\n[图-分表分库]\n​ 以玩家ID作为分表分库是一个非常自然的选择，但是这种方案，往往需要在逻辑代码中，对玩家数据按照自定义的规则，做存储进程的选择。但是如果发现这个分表分库的算法（原则）不符合需求，就需要把大量的数据做搬迁。如上图是按玩家ID做奇偶规则分布到两个表中，一旦需要增加第三台服务器，数据存储的目的服务器编号就变成了id%3，这样就需要把好多数据需要从原来的第一、二台数据库中拷贝出来，非常麻烦。 ​ 有的开发者会预先建立几十个表（如120个表=2x3x4x5），一开始是全部都放在一个服务器上，然后在增加数据库服务器的时候，把对应的整个表搬迁出来。这样能减轻在搬迁数据的时候造成的复杂度，但还是需要搬迁数据的。最后如果与建立的表还是放不下了，依然还是需要很复杂和耗时的重新拷贝数据。 3.NoSQL ​ 在很多开发者绞尽脑汁折腾MySQL的时候，NoSQL横空出世了。实际上在很早，目录型存储进程就在DNS等特定领域默默工作了。NoSQL系统最大的好处正是关系型数据库最大的弱点——分布。 ​ 由于主键只有一个，因此内置的分布功能使用起来非常简便。而且游戏玩家数据，绝大多数的操作都是根据主键来读写的。“自古以来”游戏就有“SL大法”之称，其本质就是对存档数据的简单读、写。在网游的早期版本MUD游戏时代，玩家存档只是简单的放在硬盘的文件上，文件名就是玩家的ID。这些，都说明了游戏中的玩家数据，其读写都是有明显约束的——玩家ID。这和NoSQL简直是天作之合。\n[图-NoSQL]\n​ NoSQL的确是非常适合用来存储游戏数据。特别是有些服务器如Redis还带有丰富的字段值类型。但是，NoSQL本身往往不带很复杂的容灾热备机制，这是需要额外注意的。而且NoSQL的访问延迟虽然比关系型数据库快很多，但是毕竟要经过一层网络。这对于那些发展了很多年的ORM库来说，缺乏了一个本地缓存的功能。这就导致了NoSQL还不能简单的取代掉所有服务器上的“状态”。而这些正是分布式缓存所希望达成的目标。 4.分布式缓存 ​ 在业界用的比较多的缓存系统有memcached，开发者有时候也会使用诸如Hibernate这样的ROM库提供的cache功能。但是这些缓存系统在使用上往往会有一些限制，最主要的限制是“无法分布式使用”，也就是说缓存系统本身成为性能瓶颈后，就没有办法扩容了。或者在容灾的情景下，缓存系统往往容易变成致命的单点。 ​ Orcale公司有一款叫Coherence的产品，就是一种能很好解决以上问题的“能分布式使用”的产品。他利用局域网的组播功能来做节点间的状态同步，同时采用节点互相备份的方案来分布数据。这款产品还使用Map接口来提供功能。这让整个缓存系统既使用简单又功能强大。更重要的是，它能让用户对于数据的存取特性做配置，从而提供用户可接受的数据风险下的更高性能——本地缓存。 ​ 由于游戏的数据，真正变化频繁的，往往不是“关键”的需要安全保障数据，如玩家的位置、玩家在某次战斗中的HP、子弹怪物的位置等等。而那些非常重要的数据，如等级、装备，又变化的不频繁。这就给了开发者针对数据特性做优化以很大的空间。而且，大部分数据的读、写频率都有典型的不平衡状态。普遍游戏数据都是读多写少。少量的日志、上报数据是写多、几乎不读。 ​ 对于缓存系统来说，有三个重要的因数决定了在游戏开发中的地位。首先是其使用的便利性，因为游戏的数据结构变化非常频繁，如果要很繁琐的配置数据结构，则不会适合游戏开发；其次是要能提供近似本地内存的性能，由于游戏服务器逻辑基本上都是在频繁的读写某一特定数据块，如玩家位置、经验、HP等等，而且游戏对于处理延迟也有较高的需求（WEB应用在2秒以内都可以忍受，游戏则要求最好能在20ms以内完成）。要能同时满足这两点，是不太容易的。\n[图-分布式缓存]\n5.集成缓存的NoSQL 根据上面的描述，读者应该也会想到，如果数据库系统，或者叫持久化系统，自带了缓存，是否更好呢？这样确实是会更好的，而且特别是对于NOSQL系统来说，能以一些内部的算法策略，来降低前端逻辑开发的复杂程度。一般来说，我们需要对集成缓存的NOSQL系统有以下几方面的需求：首先是冷热数据自动交换，就是对于常用数据有算法来判别其冷热，然后换入到内存以提高存取性；其次是分布式扩容和容灾功能，由于NOSQL是可以知道数据的主关键字的，所以自然就可以自动的去划分数据所在的分段，从而可以自动化的寻找到目标存储位置来做操作；最后是数据导出功能，由于NOSQL支持的查询索引只能是主键，对于很多后台游戏操作来说是不够的，所以一定要能够到处到传统的SQL服务器上去。 在这方面，有很多产品都做过一定的尝试，比如在Redis或者MangoDB上做插件修改，或者以ORM系统封装MySQL以试图构造这种系统等等。\n[图-集成缓存的NOSQL]\n三. 跳线和开房间 1.开房间型游戏模型 在全区分线服务器模型中，最早出现在开房间类型的游戏中。因为海量玩家需要临时聚合到一个个小的在线服务单元上互动。比如一起下棋、打牌等。这类游戏玩法和MMORPG有很大的不同，在于其在线广播单元的不确定性和广播数量很小。 这一类游戏最重要的是其“游戏大厅”的承载量，每个“游戏房间”受逻辑所限，需要维持和广播的玩家数据是有限的，但是“游戏大厅”需要维持相当高的在线用户数，所以一般来说，这种游戏还是需要做“分服”的。典型的游戏就是《英雄联盟》《穿越火线》这一类游戏了。而“游戏大厅”里面最有挑战性的任务，就是“自动匹配”玩家进入一个“游戏房间”，这需要对所有在线玩家做搜索和过滤。\n[图-开房间型游戏]\n​ 这类游戏服务器，玩家先登录“大厅服务器”，然后选择组队游戏的功能，服务器会通知参与的所有游戏客户端，新开一条连接到房间服务器上，这样所有参与的用户就能在房间服务器里进行游戏交互了。 ​ 由于“大厅服务器”只负责“组队”，所以其承载力会比具体的房间服务器更高一些，但这里仍然会是性能瓶颈。所以一般我们需要尽量减少大厅服务器的功能，比如把登录功能单独列出来、把玩家的购买物品商城功能也单独出来等等。最后，我们也可以直接想办法把“组队”功能也按组队逻辑做一定划分，比如不同的组队玩法、副本类型、组队用户等级等等。 ​ 虽然这种模型已经可以对很多游戏做很好的承载了，但是在大厅服务器这里依然无法做到平行扩展，原因是玩家的在线数据比较难分布到不同的服务进程上去，而且还带有大量复杂的数据查询逻辑。 2.专用聊天服务器\n不管是MMORPG还是开房间类游戏，聊天一直都是网络游戏中一个重要的功能。而这个功能在“在线人数”很多，“聊天频道”很多的情况下，会给性能带来非常大的挑战。在很多类型的页游和少部分手机游戏里面，在线聊天甚至是唯一的“带公共状态”的服务。 ​ 聊天服务处理点对点的聊天，还有群聊。用户可能会添加好友、建立好友群组等各种功能。这些功能，都是和一般的游戏逻辑有一定差别的功能。这些功能往往并不是非常容易实现。很多游戏都期望建立类似腾讯QQ的游戏聊天功能，但是QQ是一整个公司在做开发，要用仅仅一个游戏团队做成这么完整的功能，是有一定困难的。 ​ 因此游戏开发者们常常会专门的针对聊天功能来开发一系列的服务进程，以便能让游戏的聊天功能独立出来，做到负载分流和代码重用的逻辑。很多网游系统，其聊天系统从客户端来说就是和主游戏进程分开的。 ​ 聊天服务器的本质是对客户端数据做广播，从而让玩家可以交互，所以有很多游戏开发者也直接拿聊天服务器来做棋牌游戏的房间服务器，或者反过来用。由于在游戏“分服”里面单独部署了聊天服务器，这类服务器也往往被用来承担做“跨服玩法”的进程。比如跨服团队战、跨服副本等等。不管这些服务器最终叫什么名字，实际上他们承担的主要功能还是广播，而且是运行玩家“二次登录”的广播服务器。以至于后来，有部分游戏直接全部都用聊天服务器来代替原始的“游戏服务器”，这样还能实现一个叫“跳线”的功能，也就是玩家从一个“在线环境”跳到另外一个“在线环境”去。——这些都是对于“广播”功能的灵活运用。\n[图-专用聊天服务器]\n全服全线模型 尽管分服的游戏模型已经运营了很多年，但是有一些游戏运营商还是希望能让尽量多的玩家一起玩。因为网游的人气越活跃，产生的交互越多，游戏的乐趣也可能越多。这一点最突出表现在棋牌类网游上。如联众、QQ游戏这类产品，无不是希望更多玩家能同时在线接入一个“大”服务器，从而找到可以一起玩的伙伴。在手游时代，由于手机本身在线时间不稳定，所以想要和朋友一起玩本来就比较困难，如果再以“服务器”划分区域，交互的乐趣就更少了，所以同样也呼唤这一个“大”服务器，能容纳下所有此款游戏的玩家。因此，开发者们在以前积累的分服模型和分线模型基础上，开发出满足海量在线互动需求的一系列游戏服务器模型——全服全线模型。\n[图-全服全线模型]\n一. 服务进程的组织 1. 静态配置 全服全线模型的本质是一个各种不同功能进程组成的分布式系统，因此这些进程间的关系是在运维部署期间必须关注的信息。最简单的处理方法，就是预先规划出具体的进程数量、以及进程部署的物理位置，然后通过一套配置文件来描述这个规划的内容。对于每个进程，需要配置列明每个进程的pid文件位置；内部通讯用的地址，如IP+端口或者消息队列ID；启动和停止脚本路径；日志路径等等……由于有了一套这样的配置文件，我们还可以编写工具对所有的这些进程进行监控和操作批量启停。\n[图-静态配置]\n​ 虽然我们可以以静态配置为基础做很丰富的管理工具，但是这种做法还是有可以改进的空间：每次扩容、更换故障服务器或者搬迁服务器（这在运营中很常见），我们都必须手工修改静态配置数据，由于是人工操作，就总会产生很多错误，根据个人经验，游戏运营事故中的70%以上，是跟运维操作有关；由于整个分布式系统被切分成大量的进程，对于新进入此项目的程序员来说，要完整的理解这个系统，需要在思想上跨越层层阻隔：每个进程的功能、它们部署的关联、每个进程间的协议报的含义、每个业务流程具体的跨进程过程……这要花费很多时间才能搞明白的。而且大部分游戏的这种架构并不统一，每个游戏都可能需要重新理解一次，知识无法重用；在开发测试上，由于分布式系统的复杂性，要多搭几个开发、测试环境也是很费时间的，以至于这项工作甚至要安排专人来负责，这对于小型游戏开发团队来说几乎是不可承担的成本。因此我们还需要一些更加自动化，更加容易理解的全服全线游戏服务器模型。 2.基于中心点的动态组织 ​ SOA架构模式是业界一个比较经典的分布式软件架构模式，这个架构的特点是能动态的组织一个非常复杂的分布式服务系统。这个系统可以包含提供各种各样供的服务程序，而这些服务程序都以同一个标准接口来使用，并且服务自己会注册自己到集群中，以便请求方能找到自己。这种架构使用Web Serivce来作为服务接口标准，通过发布WSDL来提供接口API，这极大的降低了开发者对这些服务的使用成本。在游戏领域，服务器端提供的功能程序，实际上也是非常多样的，如果要构建一个分布式的系统，在这个方面是非常适合SOA架构的思想的；然而，游戏却很少使用HTTP协议及其之上的Web Service做通讯层，因为这个协议性能太低。不过，类似SOA的，基于中心节点的动态组织的服务管理思路，却依然适用。\n[图-基于中心点的动态组织]\n​ 一般来说我们会使用一组目录服务器来充当“中心点”，代表整个集群。开源产品中最好的产品就是ZooKeeper了。当然也有一些开发者自己编写这样的目录服务器。由于每个服务进程会自己上报负载和状态，所以每个进程只需要配置自己提供的服务即可：服务名字、服务接口。对于请求方来说，一般都可以预先编写目标服务接口的类库，用来编程，有些项目还使用RPC功能，使用IDL语言配置直接生成这些接口类库。当需要请求的时候，执行“名字查找”-“路由选择”-“发起请求”就可以完成整个过程。由于有“查找”-“路由”的过程，所以如果目标服务故障、或者新增了服务提供者，请求方就能自动获得这些信息，从而达到自动动态扩容或容灾的效果，这些都是无需专门去做配置的。 3.服务化与云 ​ 尽管动态组织的架构有如此多优点，但是开发者还是需要自己部署和维护中心节点。对于一些常用的服务，如网络代理服务、数据存储服务，用户还是要自己去安装，以及想办法接入到这套体系中去。这对于开发、测试还是有一定的运维工作压力的。于是一些开发团队就把这类工作集中起来，预先部署一套大的集群中心系统，所有开发者都直接使用，而不是自己去安装部署，这就成为了服务化，或者云服务。\n[图-服务化、云]\n​ 使用专人维护的服务化集群确实是一个轻松愉快的过程。但是游戏开发和运营过程中，往往需要多套环境，如各个不同版本的测试环境、给不同运营平台搭建的环境、海外运营的环境等等……这些环境会大大增加维护服务化集群的工作量，对于解决这个问题，建立高度自动化运维的私有云，成为一个需要解决的问题放上了桌面。提高集群的运维效率，降低工作复杂程度，需要一些特别的技术，而虚拟化技术正式解决这些问题的最新突破。\n二. 提高开发效率所用的结构 1.使用RPC提高网络接口编写效率 在分布式系统中，如果所有的接口都需要自己定义数据协议报来做交互，这个网络编程的工作量将会非常的大，因为对于一个普通的通信接口来说，至少包括了：一个请求包结构、一个响应包结构、四段代码，包括请求响应包的编码和解码、一个接收数据做分发的代码分支、一个发送回应的调用。由于分布式的游戏服务器进程非常多，一个类似登录这样的操作，可能需要历经三、四个进程的合作处理，这就导致了接近十个数据结构的定义和无数段类似的代码。而这些代码，如果在单进程的环境下，仅仅只是三、四个函数定义而已。 因此很多开发者投入很大精力，让网络通信的编写过程，尽量简化成类似函数的编写一样。这就是前文所述的远程调用的方法。在全区全线的游戏中，如果是比较重度的游戏，采用RPC方式做开发，会大大降低开发的复杂程度。当然也有一些比较轻度的游戏，还是采用传统的协议包编解码、分发逻辑调用的做法。 2.简化数据处理 在分布式系统中，对于避免单点、容灾、扩容中最复杂的问题，就是在内存中的数据。由于内存中有游戏业务的数据，所以一般我们不敢随便停止进程，也难以把一个进程的服务替换为另外一个进程。然而，游戏数据对比其他业务，还是非常有特点的： a.写入越不频繁的数据，价值越高。比如过关、升级、获得重要装备。 b.大量数据都是读非常频繁，而写非常不频繁的，如玩家的等级、经验。 c.大量写入频繁的数据，实际上是不太重要，可以有一定损失，比如玩家位置，在某个关卡内的HP/MP等…… d.因此，只要我们能按数据的特性，对游戏中需要处理的数据做一定分类，就能很好的解决分布式中的这些问题。 e.首先我们要对数据的分布做规划，一般来说采用按玩家ID做分布，这样能让服务进程中内存的数据缓存高度命中。常用的手法有用一致性哈希来选择路由，调用相关的服务进程。 f.其次对于读频繁而写不频繁的数据，我们采用读缓存而写不缓存的策略。每个服务进程都保留其读缓存数据，如果需要扩容和容灾，仅仅需要修改服务访问的路由即可。 g.再次对于读不频繁而写频繁的数据，我们采用写缓存和读不缓存的策略。由于这些数据丢失掉一些是不要紧的，所以容灾处理就直接忽略即可，对于扩容，只需要对所有服务进程都做一次回写即可。 h.最后，有一些数据是读和写都频繁的数据，比如玩家位置，HP/MP这类，我们采用读写都缓存，由于数据重要性不高，只要我们多分几个服务进程即可降低故障时影响的范围；在扩容的时候调用全节点清理读缓存和回写脏数据即可。 在和持久化设备打交道的时候，传统的ORM类库往往能帮我们把数据存入关系型数据库，然而，使用一个自带数据热备的NOSQL也是很好的选择。因为这样能节省大量的分库分表逻辑代码。 3.自动化部署集群环境 最新的虚拟化技术给分布式系统提供能更好的部署手段，以Docker为标志的虚拟化平台，可以很好的提高服务化集群的管理。我们可以把每个服务进程打包成一个映像文件，放入Docker虚拟机中运行，也可以把一组互相关联的服务进程打包运行。这些环境问题都由Docker处理了。 但是，我们同时需要注意的是，如果我们的进程的资源是静态分配的（前文提到），在Docker的虚拟机中可能因为内存不足等原因直接无法启动。这就需要我们把完全静态分配资源的程序，修改为有资源限制，但是动态分配的程序。这样我们才能在任何可以部署Docker的机器上部署我们的游戏服务器。\n三. 分布式难点：状态同步 1.分布式接入层 一般来说，我们全线服务器系统碰到的第一个问题，就是大量并发的网络请求。特别是大量玩家都在一起交互，产生了大量由于状态同步而需要广播的数据包。这些网络请求的处理，显然应该独立出来成为单独的进程。同时这些网络接入进程，还应该是一个集群中的成员。这就诞生了分布式接入服务层。 这些网路接入进程的第一个功能，就是把并发的连接，代理成为后端一个串行的连接，这可以让后端服务进程的处理逻辑更简单，而且网络处理消耗变得更小。 其次，网络接入进程需要支持广播功能。如果只是普通的广播实现，很多人会需要拷贝很多次需要广播的内容，然后挨个对Socket做发送。这其实是一个消耗很高的操作。而单独的网络接入进程，可以善用“零拷贝”等技术，大大降低广播的性能开销。而且还可以通过多个进程一起做广播操作，以达到更大的在线同步区域。 最后，网络接入进程需要支持一些额外的有用功能，包括通讯的加密、压缩、流量控制、过载保护等等。有些团队还把用户的登录鉴权也加入网络接入功能中。\n) [图-分布式接入层]\n2.使用P2P 网络状态同步产生的广播请求中，绝大多数都是客户端之间的网络状态，因此我们在可以使用P2P的客户端之间，直接建立P2P的UDP数据连接，会比通过服务器转发降低非常多的负载。在一些如赛车、音乐、武打类型的著名游戏中，都有使用P2P技术。而接入进程天然的就是一个P2P撮合服务器。 有些游戏为了进一步降低延迟，还对所有的玩家状态，只同步输入动作，以及死亡、技能等重要状态，让怪物和一般状态通过计算获得，这样就更能节省玩家的带宽，提高及时性。加上一些动作预测技术，在客户端上能表现的非常流畅。\n展望 一. 可重用的游戏业务模版 ​ 游戏服务端的各种架构中，以前往往比较关注那些非功能性的需求：容灾性、扩容、承载量，延迟。而在现在手游时代，开发效率越来越重要，有些团队甚至不设专门的服务器端程序员。因此游戏服务端架构应该更多的关注业务开发的效率。 ​ 现代游戏中，只要是带RPG元素的，角色系统、物品系统、技能系统、任务系统就都会具备，而且都有一批比较稳定的核心逻辑。只要是能在线交互的，就有好友系统、邮件系统、聊天系统、公会系统等。另外商城系统、活动系统、公告系统更是每个游戏都似乎要重复发明的轮子。 ​ 游戏的后端应用也有很多可重用的部分，比如客服系统、数据统计平台、官网数据接口等等。这些在游戏服务端框架中往往是最后再添加进去的。 ​ 如果把以上的问题都统一考虑起来，我们实际上是可以在一个稳定的底层架构上，构造出一整套常用的游戏业务逻辑模板，用来减少游戏领域的业务代码开发。所以这样一套可以运行各种业务逻辑模版的底层架构，正是游戏服务端架构发展的方向。\n二. 动态资源调度的PaaS云 ​ 现在有的团队已经在搭建自己的Docker云，这可以让游戏服务器在虚拟云上动态的生长，从而达到真正的动态扩容和动态容灾。加上如果游戏服务器不再是一个个服务进程，而是真正意义上的一个个服务，可以动态的加入或者离开云环境，那么这就是一个游戏领域的PaaS系统。我热切的希望能看到，可以用一套SDK，开发或重用那些成型的业务模版，然后动态注册到服务云中就能运行，这样一种游戏服务器架构。\n","permalink":"https://haokiu.com/blog/d7795d37211b43728424c7c4f7469b67/","summary":"12 经典游戏服务器端架构概述 架构的分析模型 一. 讨论的背景 ​ 现代电子游戏，基本上都会使用一定的网络功能。从验证正版，到多人交互等等，都需要架设一些专用的服务器，以及编写在服务器上的程序。因此，游戏服务器端软件的架构，本质上也是游戏服务器这个特定领域的软件架构。 ​ 软件架构的分析，可以通过不同的层面入手。比较经典的软件架构描述，包含了以下几种架构： ​ 1.运行时架构——这种架构关心如何解决运行效率问题，通常以程序进程图、数据流图为表达方式。在大多数开发团队的架构设计文档中，都会包含运行时架构，说明这是一种非常重要的设计方面。这种架构也会显著的影响软件代码的开发效率和部署效率。本文主要讨论的是这种架构。 ​ 2.逻辑架构——这种架构关心软件代码之间的关系，主要目的是为了提高软件应对需求变更的便利性。人们往往会以类图、模块图来表达这种架构。这种架构设计在需要长期运营和重用性高的项目中，有至关重要的作用。因为软件的可扩展性和可重用度基本是由这个方面的设计决定的。特别是在游戏领域，需求变更的频繁程度，在多个互联网产业领域里可以说是最高的。本文会涉及一部分这种架构的内容，但不是本文的讨论重点。 ​ 3.物理架构——关心软件如何部署，以机房、服务器、网络设备为主要描述对象。 ​ 4.数据架构——关心软件涉及的数据结构的设计，对于数据分析挖掘，多系统协作有较大的意义。 ​ 5.开发架构——关心软件开发库之间的关系，以及版本管理、开发工具、编译构建的设计，主要为了提高多人协作开发，以及复杂软件库引用的开发效率。现在流行的集成构建系统就是一种开发架构的理论。\n二. 游戏服务器架构的要素 ​ 服务器端软件的本质，是一个会长期运行的程序，并且它还要服务于多个不定时，不定地点的网络请求。所以这类软件的特点是要非常关注稳定性和性能。这类程序如果需要多个协作来提高承载能力，则还要关注部署和扩容的便利性；同时，还需要考虑如何实现某种程度容灾需求。由于多进程协同工作，也带来了开发的复杂度，这也是需要关注的问题。 ​ 功能约束，是架构设计决定性因素。一个万能的架构，必定是无能的架构。一个优秀的架构，则是正好把握了对应业务领域的核心功能产生的。游戏领域的功能特征，于服务器端系统来说，非常明显的表现为几个功能的需求： ​ 1.对于游戏数据和玩家数据的存储 ​ 2.对玩家客户端进行数据广播 ​ 把一部分游戏逻辑在服务器上运算，便于游戏更新内容，以及防止外挂。 ​ 针对以上的需求特征，在服务器端软件开发上，我们往往会关注软件对电脑内存和CPU的使用，以求在特定业务代码下，能尽量满足承载量和响应延迟的需求。最基本的做法就是“时空转换”，用各种缓存的方式来开发程序，以求在CPU时间和内存空间上取得合适的平衡。在CPU和内存之上，是另外一个约束因素：网卡。网络带宽直接限制了服务器的处理能力，所以游戏服务器架构也必定要考虑这个因素。 ​ 对于游戏服务器架构设计来说，最重要的是利用游戏产品的需求约束，从而优化出对此特定功能最合适的“时-空”架构。并且最小化对网络带宽的占用。\n[图：游戏服务器的分析模型]\n三. 核心的三个架构 ​ 基于上述的分析模型，对于游戏服务端架构，最重要的三个部分就是，如何使用CPU、内存、网卡的设计： ​ 1.内存架构：主要决定服务器如何使用内存，以保证尽量少的内存泄漏的可能，以及最大化利用服务器端内存来提高承载量，降低服务延迟。 ​ 2.调度架构：设计如何使用进程、线程、协程这些对于CPU调度的方案。选择同步、异步等不同的编程模型，以提高服务器的稳定性和承载量。同时也要考虑对于开发带来的复杂度问题。现在出现的虚拟化技术，如虚拟机、docker、云服务器等，都为调度架构提供了更多的选择。 ​ 3.通信模式：决定使用何种方式通讯。网络通讯包含有传输层的选择，如TCP/UDP；据表达层的选择，如定义协议；以及应用层的接口设计，如消息队列、事件分发、远程调用等。 ​ 本文的讨论，也主要是集中于对以上三个架构的分析。\n四. 游戏服务器模型的进化历程 ​ 最早的游戏服务器是比较简单的，如UO《网络创世纪》的服务端一张3.5寸软盘就能存下。基本上只是一个广播和存储文件的服务器程序。后来由于国内的外挂、盗版流行，各游戏厂商开始以MUD为模型，建立主要运行逻辑在服务器端的架构。这种架构在MMORPG类产品的不断更新中发扬光大，从而出现了以地图、视野等分布要素设计的分布式游戏服务器。而在另外一个领域，休闲游戏，天然的需要集中超高的在线用户，所以全区型架构开始出现。现代的游戏服务器架构，基本上都希望能结合承载量和扩展性的有点来设计，从而形成了更加丰富多样的形态。 ​ 本文的讨论主要是选取这些比较典型的游戏服务器模型，分析其底层各种选择的优点和缺点，希望能探讨出更具广泛性，更高开发效率的服务器模型。\n分服模型 一. 模型描述 ​ 分服模型是游戏服务器中最典型，也是历久最悠久的模型。其特征是游戏服务器是一个个单独的世界。每个服务器的帐号是独立的，而且只用同一服务器的帐号才能产生线上交互。在早期服务器的承载量达到上限的时候，游戏开发者就通过架设更多的服务器来解决。这样提供了很多个游戏的“平行世界”，让游戏中的人人之间的比较，产生了更多的空间。所以后来以服务器的开放、合并形成了一套成熟的运营手段。一个技术上的选择最后导致了游戏运营方式的模式，是一个非常有趣的现象。\n[图：分服模型]\n二. 调度架构 1.单进程游戏服务器 最简单的游戏服务器只有一个进程，是一个单点。这个进程如果退出，则整个游戏世界消失。在此进程中，由于需要处理并发的客户端的数据包，因此产生了多种选择方法：\n[图：单进程调度模型]\n​ a.同步-动态多线程：每接收一个用户会话，就建立一个线程。这个用户会话往往就是由客户端的TCP连接来代表，这样每次从socket中调用读取或写出数据包的时候，都可以使用阻塞模式，编码直观而简单。有多少个游戏客户端的连接，就有多少个线程。但是这个方案也有很明显的缺点，就是服务器容易产生大量的线程，这对于内存占用不好控制，同时线程切换也会造成CPU的性能损失。更重要的多线程下对同一块数据的读写，需要处理锁的问题，这可能让代码变的非常复杂，造成各种死锁的BUG，影响服务器的稳定性。 ​ b.同步-多线程池：为了节约线程的建立和释放，建立了一个线程池。每个用户会话建立的时候，向线程池申请处理线程的使用。在用户会话结束的时候，线程不退出，而是向线程池“释放”对此线程的使用。线程池能很好的控制线程数量，可以防止用户暴涨下对服务器造成的连接冲击，形成一种排队进入的机制。但是线程池本身的实现比较复杂，而“申请”、“施放”线程的调用规则需要严格遵守，否则会出现线程泄露，耗尽线程池。 ​ c.异步-单线程/协程：在游戏行业中，采用Linux的epoll作为网络API，以期得到高性能，是一个常见的选择。游戏服务器进程中最常见的阻塞调用就是网路IO，因此在采用epoll之后，整个服务器进程就可能变得完全没有阻塞调用，这样只需要一个线程即可。这彻底解决了多线程的锁问题，而且也简化了对于并发编程的难度。但是，“所有调用都不得阻塞”的约束，并不是那么容易遵守的，比如有些数据库的API就是阻塞的；另外单进程单线程只能使用一个CPU，在现在多核多CPU的服务器情况下，不能充分利用CPU资源。异步编程由于是基于“回调”的方式，会导致要定义很多回调函数，并且把一个流程里面的逻辑，分别写在多个不同的回调函数里面，对于代码阅读非常不理。——针对这种编码问题，协程(Coroutine)能较好的帮忙，所以现在比较流行使用异步+协程的组合。不管怎样，异步-单线程模型由于性能好，无需并发思维，依然是现在很多团队的首选。 ​ d.异步-固定多线程：这是基于异步-单线程模型进化出来的一种模型。这种模型一般有三类线程：主线程、IO线程、逻辑线程。这些线程都在内部以全异步的方式运行，而他们之间通过无锁消息队列通信。 2.多进程游戏服务器 ​ 多进程的游戏服务器系统，最早起源于对于性能问题需求。由于单进程架构下，总会存在承载量的极限，越是复杂的游戏，其单进程承载量就越低，因此开发者们一定要突破进程的限制，才能支撑更复杂的游戏。 ​ 一旦走上多进程之路，开发者们还发现了多进程系统的其他一些好处：能够利用上多核CPU能力；利用操作系统的工具能更仔细的监控到运行状态、更容易进行容灾处理。多进程系统比较经典的模型是“三层架构”。 ​ 在多进程架构下，开发者一般倾向于把每个模块的功能，都单独开发成一个进程，然后以使用进程间通信来协调处理完整的逻辑。这种思想是典型的“管道与过滤器”架构模式思想——把每个进程看成是一个过滤器，用户发来的数据包，流经多个过滤器衔接而成的管道，最后被完整的处理完。由于使用了多进程，所以首选使用单进程单线程来构造其中的每个进程。这样对于程序开发来说，结构清晰简单很多，也能获得更高的性能。\n[图:经典的三层模型]\n​ 尽管有很多好处，但是多进程系统还有一个需要特别注意的问题——数据存储。由于要保证数据的一致性，所以存储进程一般都难以切分成多个进程。就算对关系型数据做分库分表处理，也是非常复杂的，对业务类型有依赖的。而且如果单个逻辑处理进程承载不了，由于其内存中的数据难以分割和同步，开发者很难去平行的扩展某个特定业务逻辑。他们可能会选择把业务逻辑进程做成无状态的，但是这更加加重了存储进程的性能压力，因为每次业务处理都要去存储进程处拉取或写入数据。 ​ 除了数据的问题，多进程也架构也带来了一系列运维和开发上的问题：首先就是整个系统的部署更为复杂了，因为需要对多个不同类型进程进行连接配置，造成大量的配置文件需要管理；其次是由于进程间通讯很多，所以需要定义的协议也数量庞大，在单进程下一个函数调用解决的问题，在多进程下就要定义一套请求、应答的协议，这造成整个源代码规模的数量级的增大；最后是整个系统被肢解为很多个功能短小的代码片段，如果不了解整体结构，是很难理解一个完整的业务流程是如何被处理的，这让代码的阅读和交接成本巨高无比，特别是在游戏领域，由于业务流程变化非常快，几经修改后的系统，几乎没有人能完全掌握其内容。\n三. 内存架构 ​ 由于服务器进程需要长期自动化运行，所以内存使用的稳定是首要大事。在服务器进程中，就算一个触发几率很小的内存泄露，都会积累起来变成严重的运营事故。需要注意的是，不管你的线程和进程结构如何，内存架构都是需要的，除非是Erlang这种不使用堆的函数式语言。 1.动态内存 ​ 在需要的时候申请内存来处理问题，是每个程序员入门的时候必然要学会的技能。但是，如何控制内存释放却是一个大问题。在C/C++语言中，对于堆的控制至关重要。有一些开发者会以树状来规划内存使用，就是一般只new/delete一个主要的类型的对象，其他对象都是此对象的成员（或者指针成员），只要这棵树上所有的对象都管理好自己的成员，就不会出现内存漏洞，整个结构也比较清晰简单。\n[图:对象树架构]\n​ 在Objective C语言中，有所谓autorealse的特性，这种特性实际上是一种引用计数的技术。由于能配合在某个调度模型下，所以使用起来会比较简单。同样的思想，有些开发者会使用一些智能指针，配合自己写的框架，在完整的业务逻辑调用后一次性清理相关内存。\n[图:根据业务处理调度管理内存池]\n​ 在带虚拟机的语言中，最常见的是JAVA，这个问题一般会简单一些，因为有自动垃圾回收机制。但是，JAVA中的容器类型、以及static变量依然是可能造成内存泄露的原因。加上无规划的使用线程，也有可能造成内存的泄露——有些线程不会退出，而且在不断增加，最后耗尽内存。所以这些问题都要求开发者专门针对static变量以及线程结构做统一设计、严格规范。 2.预分配内存 ​ 动态分配内存在小心谨慎的程序员手上，是能发挥很好的效果的。但是游戏业务往往需要用到的数据结构非常多，变化非常大，这导致了内存管理的风险很高。为了比较彻底的解决内存漏洞的问题，很多团队采用了预先分配内存的结构。在服务器启动的时候分配所有的变量，在运行过程中不调用任何new关键字的代码。 ​ 这样做的好处除了可以有效减少内存漏洞的出现概率，也能降低动态分配内存所消耗的性能。同时由于启动时分配内存，如果硬件资源不够的话，进程就会在启动时失败，而不是像动态分配内存的程序一样，可能在任何一个分配内存的时候崩溃。然而，要获得这些好处，在编码上首先还是要遵循“动态分配架构”中对象树的原则，把一类对象构造为“根”对象，然后用一个内存池来管理这些根对象。而这个内存池能存放的根对象的数目，就是此服务进程的最大承载能力。一切都是在启动的时候决定，非常的稳妥可靠。","title":"12 经典游戏服务器端架构概述"},{"content":"13 游戏跨服架构进化之路 江贵龙，游戏行业从业8年，历任多款游戏项目服务器主程，服务器负责人。 关注游戏服务器架构及优化，监控预警，智能运维，数据统计分析等。\n1.背景 ​ 虽然游戏市场竞争激烈，产品格局变动较大,但游戏产业一直处于稳步增长阶段，无论是在端游，页游，手游还是已经初露端倪的H5游戏。可以预见，游戏类型中，MMOARPG游戏仍然会是引领市场的主流趋势，贡献着大部分流水，市场上也仍然在不断涌现精品。研发团队对MMO游戏的探索从来未间断过,从付费模式的改变，到题材多元化，次时代的视觉效果，更成熟的玩法及数值体系，本文主要针对跨服玩法上的探索和实现做一些思考和分析。 ​ 根据2016年《中国游戏产业报告》数据显示，随着游戏人口红利逐渐消失，获取用户的成本居高不下，几年来至少翻了十倍以上，目前平均导量成本页游为10~15元/人，手游在15~20元/人，其中IOS上成本30~50元/人,“洗”用户模式的效果正在变得微弱，用户流失严重。让我们先来看看滚服玩法的局限性，滚服洗量模式下存在着如下的弊端：\n2.设计目标 ​ 在上述背景下，一款长留存，低流失的精品游戏就成了平台方，渠道商，研发方追捧的目标，设想一下，如果让所有服务器玩家通过“跨域体系”实现自由畅通交互，在此基础上，玩家可以体验到前所未有的“国战系统”——7×24小时昼夜不停服的国家战争，随时开战；突破单地图承载容量极限的国战对决，带来真正万人国战的刺激体验，形成全区玩家能够互动的游戏社交环境。依托平台运营来打造一款真正意义上摆脱传统游戏运营模式的全新产品，为平台吸纳足够的市场份额，大幅降低流失率。 ​ 我们的蓝图是开创“1=1000”模式，让所有玩家，身处一个服务器却如同同时存在于所有服务器，这种打破服务器屏障的设定，杜绝了游戏出现“被迫滚服”现象出现，玩家不用再担心鬼服人烟稀少，不用担心交易所一无所有，所有的数据共享，让玩家轻松Hold住全世界。 3.进化过程 ​ 项目组那时面临的现状是游戏各种档期计划、宣传推广安排都已经就绪，两个月后该独代项目要在腾讯平台按时上线，开发不能因引入跨服机制而导致所有完成度100%的功能都要去分别去增加跨服的支持，而技术人员在跨服功能开发这块经验的积累上也不充分。 技术小组分析了时下项目的现状，跨服业务需求及现有的框架结构，明确了几点原则： ​ 1.为了实现跨服，游戏代码从底层架构到上层业务逻辑的代码改动成本尽量降低 ​ 2.业务逻辑里尽量少关心或者不用关心是否在本服或者跨服，降低开发人员的跨服功能开发复杂度，提高开发的效率，缩短开发周期。 那么，我们需要解决哪些技术疑点呢？\n3.1 客户端直连还是服务器转发 a)如果直连，那么，跨服玩法时客户端要维持两个连接，在跨服里，要模拟玩家登陆，绑定session的过程，游戏服和跨服两边要同时维护两份玩家数据，如何做到数据的同步？跨服要暴露给玩家，需要有公网访问IP和端口。对客户端连接管理来说较复杂。 b)如果通过大区服务器消息转发，那么，服务器之间做RPC通信，连接管理，消息需额外做一步跳转，性能能否满足？跨不跨服，对于客户端来说透明，跨服隐藏在大区之后，更加安全，不需再浪费公网IP和端口。 综合考虑了下，采用了B方案。\n3.1.1 RPC框架设计需求 那么，我们需要先准备一套高性能轻量级的RPC框架。 业界有很多典型的RPC框架，比如Motan、Thrift、gRPC、Hessian、Hprose，Wildfly,Dubbo,DubboX，为什么我们还要重复造轮子呢？综合考虑了下，框架要满足以下几点业务需求: 1.该框架要简单、易用、支持高并发的跨服请求； 2.根据现有的游戏服务器框架，会有很多定制化的场景； 3.通过NIO TCP长连接获取服务，但无需跨语言的需求； 4.支持同步请求，异步请求，异步回调CallBack； 5.要有服务发现的功能，要有Failfast能力； 6.具备负载均衡，分组等路由策略； 基于有以上的诉求，结合团队以前的开发经验，于是就决定自主研发。 我们选用的技术栈有 Netty、Apache Commons Pool、Redis等。 框架分为服务提供方(RPC Server)、服务调用方(RPC Client)、注册中心(Registry)三个角色，基于Redis为服务注册中心，通过其Pub/Sub实现服务动态的注册和发现。Server 端会在服务初始化时向Registry 注册声明所提供的服务；Client 向 Registry 订阅到具体提供服务的 Server 列表，根据需要与相关的 Server 建立连接，进行 RPC 服务调用。同时，Client 通过 Registry 感知 Server 的状态变更。三者的交互关系如右图：\n图1、RPC框架三者关系\n3.1.2 RPC请求的有序性 连接池在设计过程中，比较重要的是要考虑请求的顺序性，也就是先请求的先完成。 如果玩家的跨服请求通过不同的RPC连接并发执行，就有可能单个玩家请求因错序而导致逻辑矛盾，比如玩家移动，见图2：\n图2、玩家移动\n​ 玩家移动是很频繁的，如果A请求让玩家从位置1移动到位置2，B请求从位置2移动到位置3，有可能B请求先被跨服接收处理，这就会产生逻辑问题。 ​ 那么，如何做到请求的有序性呢？其本质是让同一份数据的访问能串行化，方法就是让同一个玩家的跨服请求通过同一条RPC连接执行，加上逻辑上的有效性验证，如图3所示：\n3.1.3 同步RPC实现细节 限于篇幅，这里只讲同步请求的RPC连接池实现。 同步请求的时序图如图4：\n上图为进入跨服战场的一次同步请求,场景切换控制器StageControllAction发起进入跨服战场的请求applyChangeByBattlefield(),场景管理器StageControllManager首先要调用登录跨服的RPC请求GameRpcClient.loginCrossServer(LoginCrossServerReq)， ​ 跨服RPC请求的工作流是这样的:\npublic LoginCrossServerAck loginCrossServer(LoginCrossServerReqreq)throws ServiceException { //从连接池中获取一个连接 RpcClient rpcClient = rpcClientPool.getResource(req.getRoleId()); try { //发起一次同步RPC请求 RpcMsg msg = rpcClient.sendWithReturn(MsgType.RPC_LoginCrossServerReq, req); return JSON.parseObject(msg.getContent(), LoginCrossServerAck.class); } finally { //将连接放回连接池中 rpcClientPool.returnResource(rpcClient); } } ​ 该请求第一步先从连接池里获取一个连接RpcClient rpcClient = rpcClientPool.getResource(roleId),然后发起一个同步请求RpcClient.sendWithReturn(),等待直到结果返回，然后把资源归还连接池。 ​ 我们重点来看看sendWithReturn代码实现:\nprivate ChannelsocketChannel; private Map\u0026lt;Long, CountDownLatch\u0026gt;watchDog = new ConcurrentHashMap\u0026lt;\u0026gt;(); private Map\u0026lt;Long, RpcMsg\u0026gt;responses = new ConcurrentHashMap\u0026lt;\u0026gt;(); /**同步请求*/ public RpcMsg sendWithReturn(intmsgType, Objectmsg) throws ServiceException { RpcMsg rpcMsg = RpcMsg.newBuilder().setServer(false).setSync(true).setSeqId(buildSeqId()). setTimestamp(System.nanoTime()).setType(msgType).setContent(JSON.toJSONString(msg)).build(); //创建一把共享锁 CountDownLatch latch = new CountDownLatch(1); watchDog.put(rpcMsg.getSeqId(), latch); writeRequest(rpcMsg); return readRequest(rpcMsg.getSeqId(), latch); } /**发送消息*/ publicvoid writeRequest(RpcMsgmsg)throws ServiceException { if (channel.isActive()) { channel.writeAndFlush(msg); } } /**阻塞等待返回*/ protected RpcMsg readRequest(longseqId, CountDownLatchlatch)throws ServiceException { try { //锁等待 if (timeout \u0026lt;= 0) { //无限等待，直到有返回 latch.await(); } else { //超时等待 latch.await(timeout, TimeUnit.MILLISECONDS); } } catch (InterruptedExceptione) { throw new ServiceException(e); } //解锁后或者超时后继续往下走 watchDog.remove(seqId); RpcMsg response = responses.remove(seqId); if (response == null) { throw new ServiceException(\u0026#34;read request timeout\u0026#34;); } return response; } //获得锁 CountDownLatch latch = rpcClient.getCountDownLatch(msg.getSeqId()); if (latch != null) { rpcClient.setResponse(msg.getSeqId(), msg); //解锁 latch.countDown(); } ​ 测试场景为分别在连接数在1,8,并发数1,8，数据大小在22byte，94byte，2504byte情况下，做测试，消息同步传输，原样返回,以下是针对同步请求压力测试的结果(取均值):\n连接数 并发数 请求类型 数据大小（bytes） 平均TPS 平均响应时间(ms) 1 1 Sync 22 5917 0.169 8 1 Sync 22 6849 0.146 8 8 Sync 22 25125 0.0398 8 8 Sync 94 20790 0.0481 8 8 Sync 2504 16260 0.0725 3.2 服务器之间主动推，还是被动拉取 3.2.1被动拉取模式(Pull) 由于我们的游戏服务器和跨服服务器代码基本一致，所以只要能在跨服中获得游戏功能所要的数据，那么，就能完成任何原有的功能，并且改造成本基本为零，我们选择了被动拉取。 这里要提出一个概念:数据源的相对性。 提供数据方，C向B请求一份数据，B是C的数据源，B向A请求一份数据，A是B的数据源。\n图5、数据源的相对性\n​ 一个玩家跨服过去后，往游戏原服拉取数据的细节图如图6：\n图6、被动拉取模式\n​ 玩家先跨服过去，loginCrossServer(LoginCrossServerReq)，然后，在用到任意数据时(主角，技能，坐骑，装备，宠物等)，反向同步请求各个系统的数据。 ​ 我们的实现如图7所示:\n图7、被动拉取UML图\npublic abstractclass AbstractCacheRepository\u0026lt;T, Kextends Serializable\u0026gt; { private final LoadingCache\u0026lt;K, DataWrapper\u0026lt;T\u0026gt;\u0026gt;caches; public AbstractCacheRepository() { Type mySuperClass = this.getClass().getGenericSuperclass(); Type type = ((ParameterizedType)mySuperClass).getActualTypeArguments()[0]; AnnotationEntityMaker maker = new AnnotationEntityMaker(); EntityMapping\u0026lt;T\u0026gt; entityMapping = maker.make((Class\u0026lt;T\u0026gt;) type); CacheLoader\u0026lt;K, DataWrapper\u0026lt;T\u0026gt;\u0026gt; loader = new CacheLoader\u0026lt;K, DataWrapper\u0026lt;T\u0026gt;\u0026gt;() { @Override public DataWrapper\u0026lt;T\u0026gt; load(K entityId) throws Exception { return new DataWrapper\u0026lt;T\u0026gt;(this.load(entityId, entityId)); } //根据不同的访问接口访问数据 public T load(Serializable roleId, K entityId) { return this.getDataAccessor(roleId).load(entityMapping, roleId, entityId); } public DataAccessor getDataAccessor(SerializableroleId) { return DataContext.getDataAccessorManager().getDataAccess(roleId); } }; caches = CacheBuilder.newBuilder().expireAfterAccess(300, TimeUnit.SECONDS).build(loader); } public T cacheLoad(K entityId) { return this.load(entityId); } private T load(K entityId) { return caches.getUnchecked(entityId).getEntity(); } } ​ 1) 玩家在游戏本服，获取Role数据，通过RoleRepository.cacheLoad(long roleId)，先从Cache里读取，没有，则调用访问器MySQLDataAccessor.load(EntityMapping em,Serializable roleId, K id)从数据库读取数据。 ​ 2) 玩家在跨服，获取Role数据，通过RoleRepository.cacheLoad(long roleId)，先从Cache里读取，没有，则调用访问器NetworkDataAccessor.load(EntityMappingem, Serializable roleId, K id)，通过RPC远程同步调用读取数据session.sendRPCWithReturn(),该方法的实现可以参考上述的RpcClient.sendWithReturn()，相类似。 ​ 关于被动拉取的优缺点介绍，在下文另有论述。总之，由于被动拉取的一些我们始料未及的缺陷存在，成为了我们服务器端开发部分功能的噩梦，从选择该模式时就埋下了一个天坑。\n3.2.2主动推送模式(Push) 为了解决了上面碰到的一系列问题， 并且还能坚持最初的原则，我们做了如下几点优化 优化方案有如下几点： 1.如果玩家在本服，和调整前一样的处理流程，如果玩家在跨服，客户端请求的指令，发布的事件，异步事件需要在场景Stage线程处理的，就转发到跨服，需要在其他个人业务线程（bus）,公共业务线程（public）处理的，仍旧在本服处理。 2.场景业务线程不再允许有DB操作 3.内部指令的转发、事件分发系统、异步事件系统要在底层支持跨服 4.玩家在登录本服时就会构PlayerTemplate, 场景用到的数据会实时更新，玩家去跨服，则会把场景中用到的数据PlayerTemplate主动推送给跨服。\n图8、主动推送模式\n​ 主动推送模式图示显示如图8所示:\n方案对比 基本参数 被动拉取模式 主动推送模式 改动工作量 既实现了原先的既定目标，改动成本基本为零，对于进度紧张的项目来说，是个极大的诱惑 需屏蔽在Stage线程中针对DB的CRUD操作，构建PlayerTemplate而引发的一系列改动 服务器之间的内部指令和事件分发量 由于个人业务数据和场景业务数据都在跨服处理，所以不需要进行跨进程通信 对于服务器之间内部指令，事件分发增加了一定的量 数据中心问题 数据中心进行了转移，把本服的数据更新给锁住。如果部分数据没锁住，就会导致数据的不同步，或者说，本服数据做了更新而导致回档的风险。而如果跨服宕机，则有5分钟的回档风险 不变不转移，从根本上规避了数据回档的风险 通信数据量 大量数据的迁移，比如要获得一个道具，需要把这个玩家的所有的道具的数据从本服迁移到跨服，大大增加的了数据的通信量 只把跨服所需要的场景数据推送过去，数据量大大降低 用户体验 为了不让一些游戏数据回档，我们不得不对某些功能做显式屏蔽，但这样带来的体验就很不好，当跨服后，点击获取邮件，会显示你在跨服不允许获取提取附件；屏蔽公会的操作，比如公会捐献，公会领工资，因为不可能把整个公会的数据给同步到跨服中 所有的功能都不会被屏蔽 开发活动的难易度 由于每个游戏区的活动系统(开服活动，和服活动，节日活动，商业化冲KPI的活动)的差异性，给编码带来了很大复杂性。 涉及到的所有商业化活动的功能开发和本服一样简单 充值问题 充值回调都是到游戏区本服，那怎么办呢，就必须同步这个数据到跨服 在处理充值回调时不用再考虑是否在跨服 RPC性能问题 因为要跨服从本服拉取数据，这个请求必须是同步的，所以同步的RPC请求的频繁导致了跨服性能的降低，特别是当某个跨服活动刚开启时，有很多玩家涌入这个场景，会发生很多同步请求（role,item,skill,horse,pet,achievement…），导致部分玩家的卡在跨服场景跳转过程中,具体实现请参考上述同步请求代码实现sendWithReturn 去掉了跨服从游戏服拉数据的需求，改成了跨服时本地推送一次场景需要用得到的数据，基本去掉了99%同步RPC请求。 消息转发量 需要把所有玩家的请求都转发到跨服，转发量非常大,60+%的消息其实是没必要转发到跨服去处理的 除了场景上的操作的Action请求，不需要再被转发到跨服去执行，极大的降低了消息的转发量 看下事件分发代码的改造:\n/**事件分发器*/ public abstract class AbEvent { private static AtomicLong seq = new AtomicLong(System.currentTimeMillis()); /**事件订阅*/ public abstract void subscribe(); /**事件监听器*/ protected abstract List\u0026lt;HandlerWrapper\u0026gt; getHandlerPipeline(); /**事件分发*/ protected void dispatch() { id = seq.incrementAndGet(); List\u0026lt;HandlerWrapper\u0026gt; handlerList = this.getHandlerPipeline(); DispatchEventReq\u0026lt;AbEvent\u0026gt; req = new DispatchEventReq\u0026lt;\u0026gt;(); req.setRoleId(roleId); req.setEntity(this); for (HandlerWrapper wrapper : handlerList) { byte group = wrapper.getGroup(); if (group == 0) { // 同线程串行执行 eventManager.syncCall(wrapper, this); } else { // 非同线程异步执行,可能去远程执行 this.advancedAsyncCall(req, wrapper); } } } } /** 跨服接收消息分发的事件 */ @Override public \u0026lt;T\u0026gt; void dispatchEvent(Session session, DispatchEventReq\u0026lt;T\u0026gt; msg) { T event = msg.getEntity(); List\u0026lt;String\u0026gt; list = msg.getHandlerList(); long roleId = msg.getRoleId(); for (String e : list) { HandlerWrapper wrapper = eventManager.getHandlerWrapper(e, event); eventManager.asyncCall(roleId, wrapper, event); } } ​ 如下图，举个例子，在跨服怪物死亡后，会抛出 MonsterDeadEvent事件，在跨服进程直接处理场景的监听对应的逻辑： 场景中道具掉落，尸体处理；其他的监听逻辑抛回游戏服处理，根据这事件,任务模块处理完成任务，获得奖励;成就模块处理完成成就，获得奖励; 主角模块获得经验，金币等奖励;活动模块处理完成活动，获得奖励。\n图9、杀怪事件分发\n3.3 其他方面的优化 3.3.1 消息组播机制 消息组播的优化，在跨服，来自同一服的全部玩家广播从分别单独消息转发，改成一个消息发回本服，然后再广播给玩家（比如来自同一个服n个玩家，原本广播一条消息，服务器之间之间要处理n个RPC消息，现在只需要处理1个消息,降到了原先的1/n）\n图10、消息组播机制\n3.3.2 通信数据量 一个完整的PlayerTemplate模版数据由于包含了玩家在场景里用到的所有数据，比如角色、宠物、坐骑、装备、神器、法宝、时装、技能、翅膀等等，数据量比较大，平均能达到5KB左右，需要在服务器之间传输时做zlib压缩，比如，做了压缩后，11767 Byte的玩家数据能压缩到2337Byte，压缩率可达到19.86%。\n3.3.3 序列化/反序列化 改造前，所有的请求都需要先在本服做AMF3反序列化，如果请求是需要转发到跨服的,再通过JSON序列化传输给跨服，在跨服通过JSON反序列化，最终该请求被处理。 但实际上，中间过程JSON序列化和反序列化似乎是没有必要的，经过改造，对需要转发给跨服的请求，在本服先不做AMF3反序列化，发送到跨服后再处理，这样就少了一次JSON的序列化和反序列化，同时收益了另外的一个好处:降低了传输的字节\n图12、占用字节对比\n图11、序列化和反序列化\n3.3.4 内存占用优化 Oracle JVM目前只能在JVM停止运行的时候才能做到释放占有内存，直到下次重启，所以为了防止资源浪费，各种类型的跨服服务器，游戏服务器都需要设置不同的启动参数。启动参数的设定根据我们自行设置的公式，如下所示。 但内存占用仍然会经常突破预警线90%，由于一旦系统分配内存发现不够时，就会触发自我保护机制，进行OOM killer,所以需要预留很大的内存给每个JVM进程，而且每次维护的时候去脚本修改内存也比较麻烦。\n​ 内存占用状况如上图，服务器更新维护后，内存占用一路上扬，一直到最后维持在一定的值，不会回收，除非等下次维护或者系统触发OOM killer。 ​ 基于阿里 JVM 1.8，只要开启-XX:+DeallocateHeapPages，CMS能在不重启应用的情况下把不使用的HEAP归还给系统的物理内存,这样，我们就不需要预留很多空间给JVM，再也不用担心被误杀了。 ​ 拿我们一款内测阶段的游戏举例，使用了ALI JVM后， 64内存配置的机器最后开到了24个新区，相比起以前64G内存的机器，单台只能放9个独立的游戏区的状况下，单区的成本将会节省62.5% 机器资源，非常可观。完美的解决了内存经常吃紧的问题，并大幅节省了成本。\n​ 上图就是使用了Ali JDK后的锯齿形效果，每隔一定时间闲置内存会被系统回收，这在Oracle JVM是难以做到的。\n3.3.5 服务器分组机制 不定向跨服是指任意游戏区的玩家都有可能匹配到一起进行游戏玩法的体验，比如跨服战场，比如跨服副本匹配，如右图所示:\n图15、服务器未分组前\n​ 如何在游戏正式大区中选择几个服做灰度服，又不影响不定向跨服体验;以及如何解决新老服玩家战力发展不在同一起跑线而导致的不平衡问题曾一度让人纠结。\n图16、服务器分组后\n比如游戏产品推出了大型资料片，想先做下灰度测试，让1~4区的玩家先做下新功能的体验，同时又能防止玩家穿了一件旧版本不存在的装备而在跨服环境下报异常，根据运营需求通过分组，就很完美的解决了上述问题。\n3.3.6 战区自动分配机制*\n图17、战区自动分配\n​ 调整后，每一种基于战区的跨服类型都可以自定义调整时间间隔，到时间点全局服务器（global server）系统自动根据全区的活跃战力匹配进行调整，让运营人员从繁杂的配置中解脱出来。定向跨服是指在一定时间内会固定参与跨服玩法的几个国家，常用于战区中国家之间对战，如右图所示，需要运营在后台配置;当一段时间后，随着玩家流失，又需要运营根据战力进行战区的调整，对运营人员的要求比较高\n3.3.7 跨服断线重连机制 比如战场系统或组队副本，由于网络状况而掉线，如果重新登录后，没法进入，将会严重影响战场的战况，顺风局马上就可能会变成逆风局，主力DPS掉线副本就有可能通不了，这个机制就弥补了这块的缺陷。\n4.支持的玩法 ​ 目前，我们已经能支持任意的游戏区玩家可以到任意的跨服服务器进行游戏功能的体验。比如已经实现的跨服组队副本、跨服战场、跨服国战、跨服皇城争夺、跨服资源战、虫群入侵战、跨服押镖、挖矿争夺等。 ​ 也支持玩家在本服就可以进行跨服互动，比如和别的区的玩家聊天、加好友、送礼等无缝交互，及国家拍卖行，世界拍卖行的跨服贸易。 ​ 甚至支持玩家穿越到另外的游戏区做任意的游戏体验，比如一区的玩家听说二区服在举行抢亲活动， ​ 你可以跑到2区去观赏参与，也跑到任意的区的中央广场去显摆你的极品套装。\n5.跨服在线数据 ​ 如图18，跨服定向玩法有战区国家玩法，虫群入侵，跨服押镖，挖矿争夺, 跨服皇城争夺，跨服国战等，如下图所示，我们可以看出这种玩法的规律:每次活动开启，跨服就会迎来一波波玩家涌入，活动一结束，玩家就会离开，4个跨服进程支持了7600在线的玩家。\n图18、定向跨服在线图\n​ 如图19，跨服非定向性玩法有跨服组队副本，跨服战场等，支持负载均衡，可以随时动态增加跨服。如右图所示，这些玩法的规律是24小时随时可以体验进入，在线比较稳定，8个跨服进程支持了28000在线的玩家。\n图19、不定向跨服在线图\n​ 图20是游戏某个跨服玩法的截图，可以看出，该游戏当时具有很高的人气。当时的最高DAU为650467，最高PCU为143319\n图20、跨服玩法在线截图\n​ 图21为跨服通信拓扑图，属于整体架构的核心部分，关于这一部分的说明见图表:6 技术架构\n图21、游戏服\u0026amp;跨服通信拓扑图\n服务器种类 说明 游戏逻辑服务器 Game Server 1.网关，跟玩家保持连接， 提供对外访问,转发消息，直接与客户消息交互； 2.协议的加密解密,压缩解压缩 3.游戏逻辑服务器，核心逻辑的实现都在这里; 4. Game 会缓存玩家的数据，定时持久化更新的数据到数据库，而对于非在线玩家，用LRU算法； 5.不同Game server间可以跨区通信，跨区加好友，聊天等 6.和全局服务器进行RPC 通信，进行递交申请匹配等请求 7.和跨服服务器进行RPC 通信，承担跨服后的指令转发 跨服服务器Cross Server 处理跨服相关的逻辑，任意区的玩家可以到达到任意的的跨服服务器, 根据负载压力无限动态扩展 全局服务器 Gobal Server 控制跨服服务器的负载均衡，处理要跨服的玩家的匹配处理，分配跨服房间等 Redis 做战区的Pub/Sub服务 关于整体架构的介绍，后续的文章会和大家分享。\n6.小结 此套架构历经了《大闹天宫OL》、《诸神黄昏》、《暴风王座》、《惊天动地》，《三打白骨精》、《英雄领主》、《封神霸业》等先后近两万组服务器运行的验证和团队的技术积累。\n图22、我们的游戏产品\n​ 本文从当前游戏市场发展的背景出发，提出了设计自由交互的“跨域体系”的必要性，然后在实现跨服架构过程中对设计目标、原则、存在的技术难点进行了思考，实现了一套用于跨服通信的高吞吐的RPC通信框架，先后体验了被动拉取模式带来的坑，和改成主动推送模式带来的便利。并且，对该架构设计在消息组播，通信量，消息序列化/反序列化，服务器分组，战区自动分配，断线重连等进行了多方面机制的分析及深度优化，最后上线实践做了可行性验证，提供了强有力的数据支持，总体表现稳定流畅。\n","permalink":"https://haokiu.com/blog/3a513d0ec4fc47e2b3830ec79beb1572/","summary":"13 游戏跨服架构进化之路 江贵龙，游戏行业从业8年，历任多款游戏项目服务器主程，服务器负责人。 关注游戏服务器架构及优化，监控预警，智能运维，数据统计分析等。\n1.背景 ​ 虽然游戏市场竞争激烈，产品格局变动较大,但游戏产业一直处于稳步增长阶段，无论是在端游，页游，手游还是已经初露端倪的H5游戏。可以预见，游戏类型中，MMOARPG游戏仍然会是引领市场的主流趋势，贡献着大部分流水，市场上也仍然在不断涌现精品。研发团队对MMO游戏的探索从来未间断过,从付费模式的改变，到题材多元化，次时代的视觉效果，更成熟的玩法及数值体系，本文主要针对跨服玩法上的探索和实现做一些思考和分析。 ​ 根据2016年《中国游戏产业报告》数据显示，随着游戏人口红利逐渐消失，获取用户的成本居高不下，几年来至少翻了十倍以上，目前平均导量成本页游为10~15元/人，手游在15~20元/人，其中IOS上成本30~50元/人,“洗”用户模式的效果正在变得微弱，用户流失严重。让我们先来看看滚服玩法的局限性，滚服洗量模式下存在着如下的弊端：\n2.设计目标 ​ 在上述背景下，一款长留存，低流失的精品游戏就成了平台方，渠道商，研发方追捧的目标，设想一下，如果让所有服务器玩家通过“跨域体系”实现自由畅通交互，在此基础上，玩家可以体验到前所未有的“国战系统”——7×24小时昼夜不停服的国家战争，随时开战；突破单地图承载容量极限的国战对决，带来真正万人国战的刺激体验，形成全区玩家能够互动的游戏社交环境。依托平台运营来打造一款真正意义上摆脱传统游戏运营模式的全新产品，为平台吸纳足够的市场份额，大幅降低流失率。 ​ 我们的蓝图是开创“1=1000”模式，让所有玩家，身处一个服务器却如同同时存在于所有服务器，这种打破服务器屏障的设定，杜绝了游戏出现“被迫滚服”现象出现，玩家不用再担心鬼服人烟稀少，不用担心交易所一无所有，所有的数据共享，让玩家轻松Hold住全世界。 3.进化过程 ​ 项目组那时面临的现状是游戏各种档期计划、宣传推广安排都已经就绪，两个月后该独代项目要在腾讯平台按时上线，开发不能因引入跨服机制而导致所有完成度100%的功能都要去分别去增加跨服的支持，而技术人员在跨服功能开发这块经验的积累上也不充分。 技术小组分析了时下项目的现状，跨服业务需求及现有的框架结构，明确了几点原则： ​ 1.为了实现跨服，游戏代码从底层架构到上层业务逻辑的代码改动成本尽量降低 ​ 2.业务逻辑里尽量少关心或者不用关心是否在本服或者跨服，降低开发人员的跨服功能开发复杂度，提高开发的效率，缩短开发周期。 那么，我们需要解决哪些技术疑点呢？\n3.1 客户端直连还是服务器转发 a)如果直连，那么，跨服玩法时客户端要维持两个连接，在跨服里，要模拟玩家登陆，绑定session的过程，游戏服和跨服两边要同时维护两份玩家数据，如何做到数据的同步？跨服要暴露给玩家，需要有公网访问IP和端口。对客户端连接管理来说较复杂。 b)如果通过大区服务器消息转发，那么，服务器之间做RPC通信，连接管理，消息需额外做一步跳转，性能能否满足？跨不跨服，对于客户端来说透明，跨服隐藏在大区之后，更加安全，不需再浪费公网IP和端口。 综合考虑了下，采用了B方案。\n3.1.1 RPC框架设计需求 那么，我们需要先准备一套高性能轻量级的RPC框架。 业界有很多典型的RPC框架，比如Motan、Thrift、gRPC、Hessian、Hprose，Wildfly,Dubbo,DubboX，为什么我们还要重复造轮子呢？综合考虑了下，框架要满足以下几点业务需求: 1.该框架要简单、易用、支持高并发的跨服请求； 2.根据现有的游戏服务器框架，会有很多定制化的场景； 3.通过NIO TCP长连接获取服务，但无需跨语言的需求； 4.支持同步请求，异步请求，异步回调CallBack； 5.要有服务发现的功能，要有Failfast能力； 6.具备负载均衡，分组等路由策略； 基于有以上的诉求，结合团队以前的开发经验，于是就决定自主研发。 我们选用的技术栈有 Netty、Apache Commons Pool、Redis等。 框架分为服务提供方(RPC Server)、服务调用方(RPC Client)、注册中心(Registry)三个角色，基于Redis为服务注册中心，通过其Pub/Sub实现服务动态的注册和发现。Server 端会在服务初始化时向Registry 注册声明所提供的服务；Client 向 Registry 订阅到具体提供服务的 Server 列表，根据需要与相关的 Server 建立连接，进行 RPC 服务调用。同时，Client 通过 Registry 感知 Server 的状态变更。三者的交互关系如右图：\n图1、RPC框架三者关系\n3.1.2 RPC请求的有序性 连接池在设计过程中，比较重要的是要考虑请求的顺序性，也就是先请求的先完成。 如果玩家的跨服请求通过不同的RPC连接并发执行，就有可能单个玩家请求因错序而导致逻辑矛盾，比如玩家移动，见图2：\n图2、玩家移动\n​ 玩家移动是很频繁的，如果A请求让玩家从位置1移动到位置2，B请求从位置2移动到位置3，有可能B请求先被跨服接收处理，这就会产生逻辑问题。 ​ 那么，如何做到请求的有序性呢？其本质是让同一份数据的访问能串行化，方法就是让同一个玩家的跨服请求通过同一条RPC连接执行，加上逻辑上的有效性验证，如图3所示：\n3.1.3 同步RPC实现细节 限于篇幅，这里只讲同步请求的RPC连接池实现。 同步请求的时序图如图4：\n上图为进入跨服战场的一次同步请求,场景切换控制器StageControllAction发起进入跨服战场的请求applyChangeByBattlefield(),场景管理器StageControllManager首先要调用登录跨服的RPC请求GameRpcClient.loginCrossServer(LoginCrossServerReq)， ​ 跨服RPC请求的工作流是这样的:\npublic LoginCrossServerAck loginCrossServer(LoginCrossServerReqreq)throws ServiceException { //从连接池中获取一个连接 RpcClient rpcClient = rpcClientPool.getResource(req.getRoleId()); try { //发起一次同步RPC请求 RpcMsg msg = rpcClient.sendWithReturn(MsgType.RPC_LoginCrossServerReq, req); return JSON.parseObject(msg.getContent(), LoginCrossServerAck.","title":"13 游戏跨服架构进化之路"},{"content":"2 网络游戏服务器开发框架设计介绍 在开发过程中，会先有一份开发大纲或是一份策划案，但是这些在我的开发中可能不会有，或者即使有，也很有可能是我随性写下来的，但是我会尽可能写好它。\n网络通信层，我会放到单独的SOCKET编程中去讲解，这里的主题是游戏的架构设计以及系统模块间的协同工作。\n所以，在这里假设所有的网络层都已经开发完毕，具体的网络层开发代码不会再这里出现，因为这需要很多年的开发经验，或者对SOCKET有一定的了解才能够讲述清楚或理解，所以我不想再我还没有足够的把握之前去说这样的问题，主要问题是不想让人说我不专业；另一方面是不希望给没有接触过SOCKET编程或了解不多的人带来误导或困扰。\n在开发游戏具体功能前，第一个要做的就是理清系统功能，这里的系统功能并不是具体的游戏功能，而是从软件角度出发的，行业内部称其为分布式服务器开发，讲的是如何构建一个可移植、可分布到不同网络机器独立或依赖运行的应用程序。\n本系列开发教程是我个人游戏经历和工作历程的一个沉淀，也是我个人主观的一个未实现版本，在这里，我希望它可以以教程的方式存在，并去按部就班的一步一步实现出来。所有的源码代码都是开源的，我不会有丝毫保留，这样做的目的是方便很多像我一样的游戏狂热者入门无门，另一方面也是希望前辈们可以对我的错误进行指正。下面将具体描述服务器的划分以及功能实现。\n此系列开发教程，总共将分为10个模块：它们分别为\nLoginGate服务器、 LoginServer服务器、 GameGate服务器、 GameServer服务器、 IMServer服务器、 AIServer服务器、 CenterServer服务器、 BillingServer服务器、 WebServices服务器、 DBServer服务器。 1\nLoginGate：登陆网关服务器，将所有的LoginServer服务器地址暴露给最终用户，每个LoginGate服务可以挂接n个LoginServer，将最终用户的所有请求转发给目标LoginServer。当最终用户通过此服务完成登陆后，会与该服务断开连接，断开连接前，服务器会将数据上报给GameGate服务。\n2\nLoginServer：登陆服务器，仅作于内部服务与LoginGate进行连接，所有的最终用户请求由LoginGate过滤后，转发过来进行处理。与LoginGate的所有通信都是明文，即未加密数据。\n3\n**GameGate：**游戏网关服务器，与LoginGate协作完成最终用户的登陆过程，每一个服务会连接到唯一一个LoginGate服务上进行注册，LoginGate会将以完成验证登陆的用户信息同步到所有已注册成功的GameGate上，根据注册不同的GameGate类型信息，LoginGate会发生不同的通过认证的最终用户信息。\nGameGate挂接n个GameServer服务到自身，此服务将所有注册到自身的GameServer信息发送给最终用户，提供用户选择具体的区或线路进行游戏（区和线路在不同的游戏设定中有不同的定义），在这里区的定义对应的是GameGate，每一个GameGate可以表示物理或逻辑上的多个游戏分区，每个分区由至少一个GameServer组成；\n线路定义为GameServer，每一个GameServer代表一条线路，线路之间互相不可见，但是可以通过IMServer进行一些扩展通信，例如公会、好友、聊天等服务可以设置透明通信或隐藏通信。透明通信由IMServer向目标GameServer转发请求，并进行处理；隐藏通信仅在当前GameServer进行处理，不会做跨越性操作。\n4\nGameServer：游戏服务器，作为内部服务与GameGate协作处理最终用户的请求，这个服务主要处理游戏逻辑，例如战斗。此服务启动后，会根据配置文件的配置信息进行相应的服务注册，该服务启动成功后，会注册到GameGate和IMServer、AIServer服务器，它们分别提供最终用户游戏、交友、公会、聊天和智能体的移动、创建、销毁等服务。作为整个游戏的核心处理服务器，会处理掉大部分的用户交互服务请求，只有在不能处理的情况下，才会请求其它服务协同处理。\n5\nIMServer：IM通信服务器，全称InstantMessaging（译为即时通讯），ICQ、MSN、QQ等聊天工具都属于此范畴。此服务的作用是提供物理或逻辑不同位置的GameServer上的最终用户通讯的一个媒介，用户成功登陆GameServer时，会将自己的好友、公会信息注册到此服务上，当需要跨GameServer服务时，共IMServer使用。此服务主要提供聊天、交友、交易、公会等社交类行为服务，该服务可以直接或间接的与最终用户进行通信，但最终用户无法直接与该服务进行通信，比如请求操作，所有的用户操作都由GameServer转发，IMServer可以选择性的直接反馈最终用户或通过GameServer反馈。\n6\n**AIServer：**人工智能服务器，全称Artificial Intelligence（译为人工智能），例如现代服务性机器人（自动吸尘器、智能探测仪、智能防爆装置等）都属于人工智能范畴。这里的人工智能主要体现在游戏中的NPC、MONSTER等有行为表现物体。GameServer启动后会连接到此服务进行注册，并获取所需智能体的信息，以反馈给最终用户，并最终显示在用户应用程序中。该服务主要控制智能体的移动、攻击、创建、销毁等行为，另外包括在战斗中或非战斗状态下的行为，比如游走在街道上的商品小贩；在搜索到攻击目标时，主动或召集附近的战斗单位一起攻击用户，都属于该服务的工作内容。\n7\n**CenterServer：**中心服务器，用于监控、更新已注册到此服务的状态，比如电信1区（傲视天地）服务器的运行状态等。此服务主要是管理除自身以外的所有服务程序的运行状态，以及时反馈给技术活运维人员。\n8\n**BillingServer：**计费服务器，用于计算用户在游戏中的消耗、增值；比如XX在游戏中购买了一个双倍经验卡，消耗10金币，或者用户通过网站形式进行充值，都会通过该服务反馈给用户最终结果。\n9\n**WebServices：**网站服务，主要用于网站与游戏之间的交互。比如XX用户通过网站进行充值服务，充值成功后，通知计费服务以响应用户操作；或通过网站进行游戏激活、礼品领取等，都需要此服务与游戏应用程序进行交互，以体现实时的变化。\n10\nDBServer：用于全局数据维护，例如更新、查询、插入、删除操作；这些数据包含用户账号、充值、代金卷、点卡、月卡以及游戏中需要用到的角色数据。\n服务器整体架构图分布示意图：\nLoginGate内部运行示意图：\nLoginServer内部运行示意图：\n由于其它服务器模块程序的内部图与这两个类似，所以就不在这个上面耽搁太多时间，下一篇将讲述具体的游戏开发，网络库使用的是开源库ACE，下载地址http://download.dre.vanderbilt.edu/previous_versions/ACE-5.8.0.zip。\n","permalink":"https://haokiu.com/blog/288a2c3a9e374a3ebf898cfa184e2921/","summary":"2 网络游戏服务器开发框架设计介绍 在开发过程中，会先有一份开发大纲或是一份策划案，但是这些在我的开发中可能不会有，或者即使有，也很有可能是我随性写下来的，但是我会尽可能写好它。\n网络通信层，我会放到单独的SOCKET编程中去讲解，这里的主题是游戏的架构设计以及系统模块间的协同工作。\n所以，在这里假设所有的网络层都已经开发完毕，具体的网络层开发代码不会再这里出现，因为这需要很多年的开发经验，或者对SOCKET有一定的了解才能够讲述清楚或理解，所以我不想再我还没有足够的把握之前去说这样的问题，主要问题是不想让人说我不专业；另一方面是不希望给没有接触过SOCKET编程或了解不多的人带来误导或困扰。\n在开发游戏具体功能前，第一个要做的就是理清系统功能，这里的系统功能并不是具体的游戏功能，而是从软件角度出发的，行业内部称其为分布式服务器开发，讲的是如何构建一个可移植、可分布到不同网络机器独立或依赖运行的应用程序。\n本系列开发教程是我个人游戏经历和工作历程的一个沉淀，也是我个人主观的一个未实现版本，在这里，我希望它可以以教程的方式存在，并去按部就班的一步一步实现出来。所有的源码代码都是开源的，我不会有丝毫保留，这样做的目的是方便很多像我一样的游戏狂热者入门无门，另一方面也是希望前辈们可以对我的错误进行指正。下面将具体描述服务器的划分以及功能实现。\n此系列开发教程，总共将分为10个模块：它们分别为\nLoginGate服务器、 LoginServer服务器、 GameGate服务器、 GameServer服务器、 IMServer服务器、 AIServer服务器、 CenterServer服务器、 BillingServer服务器、 WebServices服务器、 DBServer服务器。 1\nLoginGate：登陆网关服务器，将所有的LoginServer服务器地址暴露给最终用户，每个LoginGate服务可以挂接n个LoginServer，将最终用户的所有请求转发给目标LoginServer。当最终用户通过此服务完成登陆后，会与该服务断开连接，断开连接前，服务器会将数据上报给GameGate服务。\n2\nLoginServer：登陆服务器，仅作于内部服务与LoginGate进行连接，所有的最终用户请求由LoginGate过滤后，转发过来进行处理。与LoginGate的所有通信都是明文，即未加密数据。\n3\n**GameGate：**游戏网关服务器，与LoginGate协作完成最终用户的登陆过程，每一个服务会连接到唯一一个LoginGate服务上进行注册，LoginGate会将以完成验证登陆的用户信息同步到所有已注册成功的GameGate上，根据注册不同的GameGate类型信息，LoginGate会发生不同的通过认证的最终用户信息。\nGameGate挂接n个GameServer服务到自身，此服务将所有注册到自身的GameServer信息发送给最终用户，提供用户选择具体的区或线路进行游戏（区和线路在不同的游戏设定中有不同的定义），在这里区的定义对应的是GameGate，每一个GameGate可以表示物理或逻辑上的多个游戏分区，每个分区由至少一个GameServer组成；\n线路定义为GameServer，每一个GameServer代表一条线路，线路之间互相不可见，但是可以通过IMServer进行一些扩展通信，例如公会、好友、聊天等服务可以设置透明通信或隐藏通信。透明通信由IMServer向目标GameServer转发请求，并进行处理；隐藏通信仅在当前GameServer进行处理，不会做跨越性操作。\n4\nGameServer：游戏服务器，作为内部服务与GameGate协作处理最终用户的请求，这个服务主要处理游戏逻辑，例如战斗。此服务启动后，会根据配置文件的配置信息进行相应的服务注册，该服务启动成功后，会注册到GameGate和IMServer、AIServer服务器，它们分别提供最终用户游戏、交友、公会、聊天和智能体的移动、创建、销毁等服务。作为整个游戏的核心处理服务器，会处理掉大部分的用户交互服务请求，只有在不能处理的情况下，才会请求其它服务协同处理。\n5\nIMServer：IM通信服务器，全称InstantMessaging（译为即时通讯），ICQ、MSN、QQ等聊天工具都属于此范畴。此服务的作用是提供物理或逻辑不同位置的GameServer上的最终用户通讯的一个媒介，用户成功登陆GameServer时，会将自己的好友、公会信息注册到此服务上，当需要跨GameServer服务时，共IMServer使用。此服务主要提供聊天、交友、交易、公会等社交类行为服务，该服务可以直接或间接的与最终用户进行通信，但最终用户无法直接与该服务进行通信，比如请求操作，所有的用户操作都由GameServer转发，IMServer可以选择性的直接反馈最终用户或通过GameServer反馈。\n6\n**AIServer：**人工智能服务器，全称Artificial Intelligence（译为人工智能），例如现代服务性机器人（自动吸尘器、智能探测仪、智能防爆装置等）都属于人工智能范畴。这里的人工智能主要体现在游戏中的NPC、MONSTER等有行为表现物体。GameServer启动后会连接到此服务进行注册，并获取所需智能体的信息，以反馈给最终用户，并最终显示在用户应用程序中。该服务主要控制智能体的移动、攻击、创建、销毁等行为，另外包括在战斗中或非战斗状态下的行为，比如游走在街道上的商品小贩；在搜索到攻击目标时，主动或召集附近的战斗单位一起攻击用户，都属于该服务的工作内容。\n7\n**CenterServer：**中心服务器，用于监控、更新已注册到此服务的状态，比如电信1区（傲视天地）服务器的运行状态等。此服务主要是管理除自身以外的所有服务程序的运行状态，以及时反馈给技术活运维人员。\n8\n**BillingServer：**计费服务器，用于计算用户在游戏中的消耗、增值；比如XX在游戏中购买了一个双倍经验卡，消耗10金币，或者用户通过网站形式进行充值，都会通过该服务反馈给用户最终结果。\n9\n**WebServices：**网站服务，主要用于网站与游戏之间的交互。比如XX用户通过网站进行充值服务，充值成功后，通知计费服务以响应用户操作；或通过网站进行游戏激活、礼品领取等，都需要此服务与游戏应用程序进行交互，以体现实时的变化。\n10\nDBServer：用于全局数据维护，例如更新、查询、插入、删除操作；这些数据包含用户账号、充值、代金卷、点卡、月卡以及游戏中需要用到的角色数据。\n服务器整体架构图分布示意图：\nLoginGate内部运行示意图：\nLoginServer内部运行示意图：\n由于其它服务器模块程序的内部图与这两个类似，所以就不在这个上面耽搁太多时间，下一篇将讲述具体的游戏开发，网络库使用的是开源库ACE，下载地址http://download.dre.vanderbilt.edu/previous_versions/ACE-5.8.0.zip。","title":"2 网络游戏服务器开发框架设计介绍"},{"content":"3 游戏后端开发需要掌握的知识 这篇是从网上找到牛人的博客总结下来的：\n实战方面：\n（1）两种在知名IT公司使用的游戏服务器架构设计\n点击图片可以放大\n1\n各个服务器的功能以及作用：\n**CenterServer服务器管理器：**管理所有的服务器，分配服务器的端口，负责全局的逻辑（管理），对各功能服务器和场景服务器提供服务，保证服务器的合法性 DBserver角色档案缓冲服务器 GameServer逻辑服务器：玩家的实时同步在里面实现 GateServer网关服务器：负责消息转发 **LoginServer登录服务器：**连接账号数据 2\n不带负载均衡的和带负载均衡：\n相同点：\n​ 与带负载均衡大概的架构相同\n不同点：\n不带负载均衡\nGate Server 和Game Server之间是一对一的关系，每个Game Server能容纳的玩家数量是一定的，正常情况下一个Gate Server的对应一个Game Server实时在线人数能达到3000人，一旦达到峰值，就会找下一个对应的Game Server。\n各个Gate Server服务器之间是不通信的\n带负载均衡\n一个Gate Server的对应多个Game Server\n各个GateServer之间可以互相通信，而且还可以随意扩展，通过配置文件可以实现配置\n3\n服务器的工作过程：\n用户从客户端选择游戏服务器列表 登录到Login Server,在登陆的过程中 先去平台服务器进行账号的验证 验证通过后会通知Login Server，然后Login Server会把验证的消息发送 到center Server，请求其中的Gate Server的地址和端口 Center Server会找一个可用的Gate Server信息,发送回LoginServer Login Server会把消息发送给客户端 客户端断开与Login Server的连接，然后与Game Server 连接进入游戏场景中 ","permalink":"https://haokiu.com/blog/16d1fbc7aa204ddba0ef394895d2c2b6/","summary":"3 游戏后端开发需要掌握的知识 这篇是从网上找到牛人的博客总结下来的：\n实战方面：\n（1）两种在知名IT公司使用的游戏服务器架构设计\n点击图片可以放大\n1\n各个服务器的功能以及作用：\n**CenterServer服务器管理器：**管理所有的服务器，分配服务器的端口，负责全局的逻辑（管理），对各功能服务器和场景服务器提供服务，保证服务器的合法性 DBserver角色档案缓冲服务器 GameServer逻辑服务器：玩家的实时同步在里面实现 GateServer网关服务器：负责消息转发 **LoginServer登录服务器：**连接账号数据 2\n不带负载均衡的和带负载均衡：\n相同点：\n​ 与带负载均衡大概的架构相同\n不同点：\n不带负载均衡\nGate Server 和Game Server之间是一对一的关系，每个Game Server能容纳的玩家数量是一定的，正常情况下一个Gate Server的对应一个Game Server实时在线人数能达到3000人，一旦达到峰值，就会找下一个对应的Game Server。\n各个Gate Server服务器之间是不通信的\n带负载均衡\n一个Gate Server的对应多个Game Server\n各个GateServer之间可以互相通信，而且还可以随意扩展，通过配置文件可以实现配置\n3\n服务器的工作过程：\n用户从客户端选择游戏服务器列表 登录到Login Server,在登陆的过程中 先去平台服务器进行账号的验证 验证通过后会通知Login Server，然后Login Server会把验证的消息发送 到center Server，请求其中的Gate Server的地址和端口 Center Server会找一个可用的Gate Server信息,发送回LoginServer Login Server会把消息发送给客户端 客户端断开与Login Server的连接，然后与Game Server 连接进入游戏场景中 ","title":"3 游戏后端开发需要掌握的知识"},{"content":"4 关于游戏服务端架构的整理 一个大型的网落游戏服务器应该包含几个模块：网络通讯，业务逻辑，数据存储，守护监控（不是必须）。其中业务逻辑可能根据具体需要，又划分为好几个子模块。\n这里说的模块可以指一个进程，或者一个线程方式存在，本质上就是一些类的封装。\n对于服务器的并发性，要么采用单进程多线程，要么采用多进程单线程的方式，说说两种方式的优缺点：\n一、单进程多线程的服务器设计模式，只有一个进程，但一个进程包好多个线程： 网络通讯层，业务逻辑，数据存储，分别在独立的线程中，无守护进程。\n优点：\n数据共享和交换方便，使用全局变量或者单例就可以，数据存储方便。 单进程，服务器框架结构相对简单，编码容易。 缺点：\n所有功能只能在单个物理服务器上，不能做成分布式。 不方便监控各个线程状态，容易死锁 一个线程出错，例如内存非法访问，栈空间被破坏，那么服务器进程就退出，所有玩家掉线，影响大。 二、多进程单线程的服务器设计模式，多个进程，每个进程只有一个线程： 网路通讯，业务逻辑，数据存储，守护进程，分别在不同的进程。\n优点：\n各个进程可以分布在不同的物理服务器上，可以做成分布式的服务器框架，例如可以将数据存储单独放到一个物理服务器上，供几个区的服务器使用。将网络通讯进程独立出来，甚至可以做成导向服务器，实现跨服战。 可以通过守护进程监控其它进程状态，例如有进程死掉，马上重启该进程，或者某个进程cpu使用率接近100%（基本可以判断是某个逻辑死循环了）, 强制kill掉该进程，然后重启。 单个服务器进程异常退出，只要不是网络通讯进程（一般这个都会比较稳定，没什么逻辑），那么就可以及时被守护进程重启，不会造成玩家掉线，只会造成在1-2秒内，某个逻辑功能无法使用，甚至玩家都感觉不到。 服务器通过共享内存进行数据交换，那么如果其中一个服务器死掉，数据还在，可以保护用户数据（当然多线程也可以使用共享内存）。 并发性相对多线程要高点。 缺点：\n不方便使用互斥锁，因为进程切换的时间片远远于线程切换，对于一个高并发服务器是无法允许这么高时间片的切换代价的。因此必须设计好服务器的框架，尽量避开使用锁机制，但要保证数据不出错。 多进程编程，在各个进程间会有很多通讯，跨服务器进程的异步消息较多，会让服务器的编码难度加大。 下面先按照一个游戏的功能，将服务器的功能分块框架画出来:\n点击图片可放大\n以上是一个游戏服务器最基础的功能框架图，接下来要做的就是设计服务器的框架了\n1. 早期的MMORPG服务器结构 Client\u0026lt;-\u0026gt;GameServer\u0026lt;-\u0026gt;DB 所有业务数据集中处理\n优点:\n简单,快速开发\n缺点:\n所有业务放在一起,系统负担大大增加.一个bug可能导致整个服务器崩溃,造成所有玩家掉线甚至丢失等严重后果。 开服一刹那,所有玩家全部堆积在同一个新手村.-\u0026raquo;\u0026raquo;卡，客户端卡（同屏人数过多渲染/广播风暴） 服务器卡(处理大量同场景消息/广播风暴) 2. 中期-用户分离集群式 GameServe1 Client | DB GameServer2 玩家不断增多-\u0026gt;分线-\u0026gt;程序自动或玩家手动选择进入 **缺点:**运营到后期,随着每条线玩家的减少, 互动大大减少。\n3. 中后期 数据分离集群式 按地图划分服务器,当前主流 新手村问题：《天龙八部》提出了较好的解决方案，建立多个平行的新手村地图，一主多副，开服时尽可能多的同时容纳新用户的涌入，高等级玩家从其它地图回新手村只能到达主新手村。\n4. 当前主流的网络游戏架构 注：在GateServer和CenterServer之间是有一条TCP连接的。而GameServer和LogServer之间的连接可以是UDP连接。这是有一个大概的图，很多地方需要细化。 **GateServer:**网关服务器,AgentServer、ProxyServer\n优点:\n作为网络通信的中转站，负责维护将内网和外网隔离开，使外部无法直接访问内部服务器，保障内网服务器的安全，一定程度上较少外挂的攻击。 网关服务器负责解析数据包、加解密、超时处理和一定逻辑处理，这样可以提前过滤掉错误包和非法数据包。 客户端程序只需建立与网关服务器的连接即可进入游戏，无需与其它游戏服务器同时建立多条连接，节省了客户端和服务器程序的网络资源开销。 在玩家跳服务器时，不需要断开与网关服务器的连接，玩家数据在不同游戏服务器间的切换是内网切换，切换工作瞬问完成，玩家几乎察觉不到，这保证了游戏的流畅性和良好的用户体验。 缺点:\n网关服务器成为高负载情况下的通讯瓶颈问题 由于网关的单节点故障导致整组服务器无法对外提供服务的问题 解决：\n**多网关技术。**顾名思义，“多网关” 就是同时存在多个网关服务器，比如一组服务器可以配置三台GameGme。当负载较大时，可以通过增加网关服务器来增加网关的总体通讯流量，当一台网关服务器宕机时，它只会影响连接到本服务器的客户端，其它客户端不会受到任何影响。 **DCServer:**数据中心服务器。主要的功能是缓存玩家角色数据，保证角色数据能快速的读取和保存 CenterServer:全局服务器/中心服务器,也叫WorldServer. 主要负责维持GameServer之间数据的转发和数据广播。另外一些游戏系统也可能会放到Center上处理，比如好友系统,公会系统。 改进:\n将网关服务器细化为LogingateServer和多个GameGateServer.\n5. 按业务分离式集群 由于网络游戏存在很多的业务，如聊天，战斗，行走，NPC等，可以将某些业务分到单独的服务器上。这样每个服务器的程序则会精简很多。而且一些大流量业务的分离,可以有效的提高游戏服务器人数上限。\n优点：\n业务的分离使得每种服务器的程序变的简单，这样可以降低出错的几率。即使出错，也不至于影响到每一个整个游戏的进行,而且通过快速启动另一台备用服务器替换出错的服务器。 业务的分离使得流量得到了分散，进而相应速度回得到提升 。 大部分业务都分离了成了单独的服务器,所以可以动态的添加，从而提高人数上限。 改进： 甚至可以将登陆服务器细化拆分建角色,选择角色服务器\n6. 一种简单实用的网络游戏服务器架构 下图中每个方框表示一个独立的进程APP组件，每个服务进程如果发生宕机会影响部分用户，整体服务但不会全部中断。在宕机进程重启后，又可以并入整体，全部服务得以继续。\n**gls：**game login server，游戏登录服务器，某种程序上，其不是核心组件，gls调用外部的接口，进行基本的用户名密码认证。此外需要实现很多附属的功能：登录排队 （对开服非常有帮助），GM超级登录通道（GM可以不排队进入游戏），封测期间激活用户控制，限制用户登录，控制客户端版本等。 **db：**实质上是后台sql的大内存缓冲，隔离了数据库操作，比较内存中的数据，只把改变的数据定时批量写入sql。系统的算法，开发稳定性都要求非常高。 **center：**所有组件都要在这里注册，在线玩家的session状态都在这里集中存放，和各组件有心跳连接。所有对外的接口也全部通过这里。 角色入口：玩家登录游戏后的选择角色 **gs：**game server，最核心组件，同一地图，所有游戏逻辑相关的功能，都在这里完成。 **gate：**建立和用户的常链接，主要作sockt转发，屏蔽恶意包，对gs进行保护。协议加密解密功能，一个gate共享多个gs，降低跳转地图连接不上的风险。 **IM，关系，寄售：**表示其它组件，负责对应的跨地图发生全局的游戏逻辑。 7.另一个架构图 1- 这是一条WebService的管道，在用户激活该区帐号，或者修改帐号密码的时候，通过这条通道来插入和更新用户的帐号信息。 2- 这也是一条WebService管道，用来获取和控制用户该该组内的角色信息，以及进行付费商城代币之类的更新操作。 3- 这是一条本地的TCP/IP连接，这条连接主要用来进行服务器组在登陆服务器的注册，以及登陆服务器验证帐户后，向用户服务器注册帐户登陆信息，以及进行对已经登陆的帐户角色信息进行操作（比如踢掉当前登陆的角色），还有服务器组的信息更新（当前在线玩家数量等）。 4- 这也是一条本地TCP/IP连接，这条连接用来对连接到GameServer的客户端进行验证，以及获取角色数据信息，还有传回GameServer上角色的数据信息改变。 5- 这条连接也是一条本地的TCP/IP连接，它用来进行公共信息服务器和数个游戏服务器间的交互，用来交换一些游戏世界级的信息（比如公会信息，跨服组队信息，跨服聊天频道等）。 6- 这里的两条连接，想表达的意思是，UserServer和GameServer的Agent是可以互换使用的，也就是玩家进入组内之后，就不需要再切换 Agent。如果不怕乱套，也可以把登陆服务器的Agent也算上，这样用户整个过程里就不需要再更换Agent，减少重复连接的次数，也提高了稳定性。 （毕竟连接次数少了，也降低了连不上服务器的出现几率） 在这个架构里面，**GameServer实际上是一个游戏逻辑的综合体，**里面可以再去扩展成几个不同的逻辑服务器，通过PublicServer进行公共数据交换。\nUserServer实际上扮演了一个ServerGroup的领头羊的角色，它负责向LoginServer注册和更新服务器组的信息（名字，当前人数），并且对Agent进 行调度，对选择了该组的玩家提供一个用户量最少的Agent。同时，它也兼了一个角色管理服务器的功能，发送给客户端当前的角色列表，角色的创建，删除， 选择等管理操作，都是在这里进行的。而且，它还是一个用户信息的验证服务器，GameServer需要通过它来进行客户端的合法性验证，以及获取玩家选择 的角色数据信息。 采用这种架构的游戏，通常有以下表现：\n1- 用户必须激活一个大区，才能在大区内登陆自己的帐号。 2- 用户启动客户端的时候，弹出一个登陆器，选择大区。 3- 用户启动真正的客户端的时候，一开始就是输入帐号密码。 4- 帐号验证完成之后，进行区内的服务器选择。 5- 服务器选择完成之后，进入角色管理。同时，角色在不同的服务器里不能共享。 三、正文网络通讯 1.网络协议 根据游戏类型 实时性要求/是否允许丢包 来决定 TCP/UDP协议\na.TCP:面向连接,可靠,保证顺序,慢,有延迟 TCP每次发送一个数据包后都要等待接收方发送一个应答信息，这样TCP才可以确认数据包通过因特网完整地送到了接收方。如果在一段时间内TCP没有收到 接收方的应答，他就会停止发送新的数据包，转而去重新发送没有收到应答2的数据包，并且持续这种发送状态知道收到接收方的应答。所以这会造成网络数据传输 的延迟，若网络情况不好，发送方会等待相当长一段时间 UDP:无连接,不可靠,不保证顺序,快\nb.长连接/短连接 长连接，指在一个TCP连接上可以连续发送多个数据包，在TCP连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接，一般需要自己做在线维 连接→数据传输→保持连接(心跳)→数据传输→保持连接(心跳)→……→关闭连接 **短连接，**是指通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接,如Http 连接→数据传输→关闭连接\n2.IO模型 Unix5中io模型\n阻塞IO (Blocking I/O Model) 非阻塞IO (Nonblocking I/O Model) IO复用 (I/O Multiplexing Model) 信号驱动IO (Signal-Driven I/O Model) 异步IO (Asynchronous I/O Model) IO分两个阶段：\n通知内核准备数据。 数据从内核缓冲区拷贝到应用缓冲区 根据这2点IO类型可以分成：\n阻塞IO，在两个阶段上面都是阻塞的。 .非阻塞IO，在第1阶段，程序不断的轮询直到数据准备好，第2阶段还是阻塞的 IO复用，在第1阶段，当一个或者多个IO准备就绪时，通知程序，第2阶段还是阻塞的，在第1阶段还是轮询实现的，只是所有的IO都集中在一个地方，这个地方进行轮询 信号IO，当数据准备完毕的时候，信号通知程序数据准备完毕，第2阶段阻塞 异步IO，1，2都不阻塞 同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数\nJava#Selector 允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞**。当数据准备好时**，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据.\nJava#NIO2 发出系统调用后,直接返回。通知IO操作完成。 前四种同步IO，最后一种异步IO.二者区别:第二个阶段必须要求进程主动调用recvfrom.而异步io则将io操作全部交给内核完成,完成后发信号通知。此期间,用户不需要去检查IO操作的状态，也不需要主动的去拷贝数据。\n3.线程阻塞的原因: Thread.sleep(),线程放弃CPU，睡眠N秒,然后恢复运行 线程要执行一段同步代码,由于无法获得相关的锁,阻塞。获得同步锁后，才可以恢复运行。 线程执行了一个对象的wait方法，进入阻塞状态,只有等到其他线程执行了该对象的notify、nnotifyAll，才能将其唤醒。 IO操作,等待相关资源 阻塞线程的共同特点是：放弃CPU,停止运行，只有等到导致阻塞的原因消除，才能恢复运行 。或者被其他线程中断，该线程会退出阻塞状态，并抛出InterruptedException. 4.阻塞/非阻塞/同步/异步 同步/异步关注的是消息如何通知的机制。而阻塞和非阻塞关注的是处理消息。是两组完全不同的概念。\n5.几个常用概念 Select Poll Epoll(Linux) Kqueue(FreeBSD) IOCP Windows Reactor Dispatcher（分 发器），Notifer（通知器）, 事件到来时，使用Dispatcher（分发器）对Handler进行分派，这个Dispatcher要对所有注册的Handler进行维护。同时，有一 个Demultiplexer（分拣器）对多路的同步事件进行分拣。\nProactor Proactor和Reactor都是并发编程中的设计模式.用于派发/分离IO操作事件的。这里所谓的IO事件也就是诸如read/write的IO操作。\u0026ldquo;派发/分离\u0026quot;就是将单独的IO事件通知到上层模块。两个模式不同的地方在于，Proactor用于异步IO，而Reactor用于同步IO。\n两个模式的相同点，都是对某个IO事件的事件通知(即告诉某个模块，这个IO操作可以进行或已经完成)。在结构上，两者也有相同点：demultiplexor负责提交IO操作(异步)、查询设备是否可操作(同步)，然后当条件满足时，就回调handler。 不同点在于，异步情况下(Proactor)，当回调handler时，表示IO操作已经完成；同步情况下(Reactor)，回调handler时，表示IO设备可以进行某个操作(can read or can write)，handler这个时候开始提交操作。\n6.网络通讯框架 TCP Server框架: Apache MINA(Multipurpose Infrastructure for Network Applications)2.0.4 Netty 3.5.0Final Grizzly 2.2 Quickserver是一个免费的开源Java库，用于快速创建健壮的多线程、多客户端TCP服务器应用程序。使用QuickServer，用户可以只集中处理应用程序的逻辑/协议 **Cindy ：**强壮，可扩展，高效的异步I/O框架 **xSocket：**一个轻量级的基于nio的服务器框架用于开发高性能、可扩展、多线程的服务器。该框架封装了线程处理、异步读/写等方面 ACE 6.1.0 C++ADAPTIVE CommunicationEnvironment, **SmaxFoxServer 2.X ：**专门为Adobe Flash设计的跨平台socket服务器\n7.消息编码协议 AMF/JSON/XML/自定义/ProtocolBuffer\n无论是做何种网络应用，必须要解决的问题之一就是应用层从字节流中拆分出消息的问题，也就是对于 TCP 这种字节流协议，接收方应用层能够从字节流中识别发送方传输的消息.\n使用特殊字符或者字符串作为消息的边界，应用层解析收到的字节流时，遇见此字符或者字符串则认为收到一个完整的消息 为每个消息定义一个长度，应用层收到指定长度的字节流则认为收到了一个完整的消息 消息分隔标识（separator）、消息头（header）、消息体（body） len | message_id | data |separator | header | body | | len | message_id | data 8. 粘包: TCP粘包是指发送方发送的若干包数据到接收方接收时粘成一包，从接收缓冲区看，后一包数据的头紧接着前一包数据的尾。\n发送方引起的粘包是由TCP协议本身造成的，TCP为提高传输效率，发送方往往要收集到足够多的数据后才发送一包数据。若连续发送几次的数据都很少，通常TCP会根据优化算法把这些数据合成一包后一次发送出去，这样接收方就收到了粘包数据。 接收方引起的粘包是由于接收方用户进程不及时接收数据，从而导致粘包现象。这是因为接收方先把收到的数据放在系统接收缓冲区，用户进程从该缓冲区取数据， 若下一包数据到达时前一包数据尚未被用户进程取走，则下一包数据放到系统接收缓冲区时就接到前一包数据之后，而用户进程根据预先设定的缓冲区大小从系统接 收缓冲区取数据，这样就一次取到了多包数据 解决措施:\n对于发送方引起的粘包现象，用户可通过编程设置来避免，TCP提供了强制数据立即传送的操作指令push，TCP软件接收到该操作指令后，就立即将本段数据发送出去，而不必等待发送缓冲区满； TCP-NO-DELAY-关闭了优化算法,不推荐\n对于接收方引起的粘包，则可通过优化程序设计、精简接收进程工作量、提高接收进程优先级等措施，使其及时接收数据，从而尽量避免出现粘包现象-当发送频率高时依然可能出现粘包\n接收方控制，将一包数据按结构字段，人为控制分多次接收，然后合并，通过这种手段来避免粘包。-效率低\n接收方创建一预处理线程，对接收到的数据包进行预处理，将粘连的包分开\n分包算法思路: 基本思路是首先将待处理的接收数据（长度设为m）强行转换成预定的结构数据形式，并从中取出数据结构长度字段，即n，而后根据n计算得到第一包数据长度\n1) 若n\u0026lt;m，则表明数据流包含多包数据，从其头部截取n个字节存入临时缓冲区，剩余部分数据一次继续循环处理，直至结束。 2) 若n=m，则表明数据流内容恰好是一完整结构数据，直接将其存入临时缓冲区即可。 3) 若n\u0026gt;m，则表明数据流内容尚不够构成一个完整结构数据，需留待与下一包数据合并后再行处理。 在单位设计上必须从头到尾贯彻面向对象的“继承”观念先设计基础单位A ，再在之上扩展到所有的单位，也就是说，所有的普通单位都可以追溯到一个起源的对象，否则代码量会让你想死,然后就能获得所有的单位和建筑物了。 地图寻路 寻路的问题在于自然的移动，追着一个单位打，或者进入射程中停下来，比起如何自然的经过一个单位打，成为了一个，为什么你要在A站或者B站坐公交的问题，Why，如何才能符合逻辑的设计\u0026mdash;敌人进攻的单位，这个AI，不但是策略的问题，还是行为的问题，所以，将敌人的最终目标确定在哪里呢？\n回答：AI 和 行为控制模块要分成两个模块来做\n行为控制模块复制地图上所有单位的移动、攻击等动作，目标、目的的指示； 这必须是一个独立的模块，可以避免为每个单位都写逻辑的同时，让大部分单位战斗起来有个统一的目的；这么做的好处是，大部分的CPU时间都在一段高效率的代码上，由这个模块负责按照顺序给每个单位下达动作指令\n如果有必要 还需要一个监控模块，监控单位的状态改变\nAI : 就是上面写过的 Why ， 我要在A站乘车 还是B站乘车的逻辑，我是优先攻击单位，还是优先攻击建筑物的逻辑。。。本虎还没想明白，这是一个逻辑怪圈。。。。\n","permalink":"https://haokiu.com/blog/a7ec43bdee96498694f118163763c921/","summary":"4 关于游戏服务端架构的整理 一个大型的网落游戏服务器应该包含几个模块：网络通讯，业务逻辑，数据存储，守护监控（不是必须）。其中业务逻辑可能根据具体需要，又划分为好几个子模块。\n这里说的模块可以指一个进程，或者一个线程方式存在，本质上就是一些类的封装。\n对于服务器的并发性，要么采用单进程多线程，要么采用多进程单线程的方式，说说两种方式的优缺点：\n一、单进程多线程的服务器设计模式，只有一个进程，但一个进程包好多个线程： 网络通讯层，业务逻辑，数据存储，分别在独立的线程中，无守护进程。\n优点：\n数据共享和交换方便，使用全局变量或者单例就可以，数据存储方便。 单进程，服务器框架结构相对简单，编码容易。 缺点：\n所有功能只能在单个物理服务器上，不能做成分布式。 不方便监控各个线程状态，容易死锁 一个线程出错，例如内存非法访问，栈空间被破坏，那么服务器进程就退出，所有玩家掉线，影响大。 二、多进程单线程的服务器设计模式，多个进程，每个进程只有一个线程： 网路通讯，业务逻辑，数据存储，守护进程，分别在不同的进程。\n优点：\n各个进程可以分布在不同的物理服务器上，可以做成分布式的服务器框架，例如可以将数据存储单独放到一个物理服务器上，供几个区的服务器使用。将网络通讯进程独立出来，甚至可以做成导向服务器，实现跨服战。 可以通过守护进程监控其它进程状态，例如有进程死掉，马上重启该进程，或者某个进程cpu使用率接近100%（基本可以判断是某个逻辑死循环了）, 强制kill掉该进程，然后重启。 单个服务器进程异常退出，只要不是网络通讯进程（一般这个都会比较稳定，没什么逻辑），那么就可以及时被守护进程重启，不会造成玩家掉线，只会造成在1-2秒内，某个逻辑功能无法使用，甚至玩家都感觉不到。 服务器通过共享内存进行数据交换，那么如果其中一个服务器死掉，数据还在，可以保护用户数据（当然多线程也可以使用共享内存）。 并发性相对多线程要高点。 缺点：\n不方便使用互斥锁，因为进程切换的时间片远远于线程切换，对于一个高并发服务器是无法允许这么高时间片的切换代价的。因此必须设计好服务器的框架，尽量避开使用锁机制，但要保证数据不出错。 多进程编程，在各个进程间会有很多通讯，跨服务器进程的异步消息较多，会让服务器的编码难度加大。 下面先按照一个游戏的功能，将服务器的功能分块框架画出来:\n点击图片可放大\n以上是一个游戏服务器最基础的功能框架图，接下来要做的就是设计服务器的框架了\n1. 早期的MMORPG服务器结构 Client\u0026lt;-\u0026gt;GameServer\u0026lt;-\u0026gt;DB 所有业务数据集中处理\n优点:\n简单,快速开发\n缺点:\n所有业务放在一起,系统负担大大增加.一个bug可能导致整个服务器崩溃,造成所有玩家掉线甚至丢失等严重后果。 开服一刹那,所有玩家全部堆积在同一个新手村.-\u0026raquo;\u0026raquo;卡，客户端卡（同屏人数过多渲染/广播风暴） 服务器卡(处理大量同场景消息/广播风暴) 2. 中期-用户分离集群式 GameServe1 Client | DB GameServer2 玩家不断增多-\u0026gt;分线-\u0026gt;程序自动或玩家手动选择进入 **缺点:**运营到后期,随着每条线玩家的减少, 互动大大减少。\n3. 中后期 数据分离集群式 按地图划分服务器,当前主流 新手村问题：《天龙八部》提出了较好的解决方案，建立多个平行的新手村地图，一主多副，开服时尽可能多的同时容纳新用户的涌入，高等级玩家从其它地图回新手村只能到达主新手村。\n4. 当前主流的网络游戏架构 注：在GateServer和CenterServer之间是有一条TCP连接的。而GameServer和LogServer之间的连接可以是UDP连接。这是有一个大概的图，很多地方需要细化。 **GateServer:**网关服务器,AgentServer、ProxyServer\n优点:\n作为网络通信的中转站，负责维护将内网和外网隔离开，使外部无法直接访问内部服务器，保障内网服务器的安全，一定程度上较少外挂的攻击。 网关服务器负责解析数据包、加解密、超时处理和一定逻辑处理，这样可以提前过滤掉错误包和非法数据包。 客户端程序只需建立与网关服务器的连接即可进入游戏，无需与其它游戏服务器同时建立多条连接，节省了客户端和服务器程序的网络资源开销。 在玩家跳服务器时，不需要断开与网关服务器的连接，玩家数据在不同游戏服务器间的切换是内网切换，切换工作瞬问完成，玩家几乎察觉不到，这保证了游戏的流畅性和良好的用户体验。 缺点:\n网关服务器成为高负载情况下的通讯瓶颈问题 由于网关的单节点故障导致整组服务器无法对外提供服务的问题 解决：\n**多网关技术。**顾名思义，“多网关” 就是同时存在多个网关服务器，比如一组服务器可以配置三台GameGme。当负载较大时，可以通过增加网关服务器来增加网关的总体通讯流量，当一台网关服务器宕机时，它只会影响连接到本服务器的客户端，其它客户端不会受到任何影响。 **DCServer:**数据中心服务器。主要的功能是缓存玩家角色数据，保证角色数据能快速的读取和保存 CenterServer:全局服务器/中心服务器,也叫WorldServer. 主要负责维持GameServer之间数据的转发和数据广播。另外一些游戏系统也可能会放到Center上处理，比如好友系统,公会系统。 改进:\n将网关服务器细化为LogingateServer和多个GameGateServer.\n5. 按业务分离式集群 由于网络游戏存在很多的业务，如聊天，战斗，行走，NPC等，可以将某些业务分到单独的服务器上。这样每个服务器的程序则会精简很多。而且一些大流量业务的分离,可以有效的提高游戏服务器人数上限。\n优点：\n业务的分离使得每种服务器的程序变的简单，这样可以降低出错的几率。即使出错，也不至于影响到每一个整个游戏的进行,而且通过快速启动另一台备用服务器替换出错的服务器。 业务的分离使得流量得到了分散，进而相应速度回得到提升 。 大部分业务都分离了成了单独的服务器,所以可以动态的添加，从而提高人数上限。 改进： 甚至可以将登陆服务器细化拆分建角色,选择角色服务器\n6. 一种简单实用的网络游戏服务器架构 下图中每个方框表示一个独立的进程APP组件，每个服务进程如果发生宕机会影响部分用户，整体服务但不会全部中断。在宕机进程重启后，又可以并入整体，全部服务得以继续。\n**gls：**game login server，游戏登录服务器，某种程序上，其不是核心组件，gls调用外部的接口，进行基本的用户名密码认证。此外需要实现很多附属的功能：登录排队 （对开服非常有帮助），GM超级登录通道（GM可以不排队进入游戏），封测期间激活用户控制，限制用户登录，控制客户端版本等。 **db：**实质上是后台sql的大内存缓冲，隔离了数据库操作，比较内存中的数据，只把改变的数据定时批量写入sql。系统的算法，开发稳定性都要求非常高。 **center：**所有组件都要在这里注册，在线玩家的session状态都在这里集中存放，和各组件有心跳连接。所有对外的接口也全部通过这里。 角色入口：玩家登录游戏后的选择角色 **gs：**game server，最核心组件，同一地图，所有游戏逻辑相关的功能，都在这里完成。 **gate：**建立和用户的常链接，主要作sockt转发，屏蔽恶意包，对gs进行保护。协议加密解密功能，一个gate共享多个gs，降低跳转地图连接不上的风险。 **IM，关系，寄售：**表示其它组件，负责对应的跨地图发生全局的游戏逻辑。 7.另一个架构图 1- 这是一条WebService的管道，在用户激活该区帐号，或者修改帐号密码的时候，通过这条通道来插入和更新用户的帐号信息。 2- 这也是一条WebService管道，用来获取和控制用户该该组内的角色信息，以及进行付费商城代币之类的更新操作。 3- 这是一条本地的TCP/IP连接，这条连接主要用来进行服务器组在登陆服务器的注册，以及登陆服务器验证帐户后，向用户服务器注册帐户登陆信息，以及进行对已经登陆的帐户角色信息进行操作（比如踢掉当前登陆的角色），还有服务器组的信息更新（当前在线玩家数量等）。 4- 这也是一条本地TCP/IP连接，这条连接用来对连接到GameServer的客户端进行验证，以及获取角色数据信息，还有传回GameServer上角色的数据信息改变。 5- 这条连接也是一条本地的TCP/IP连接，它用来进行公共信息服务器和数个游戏服务器间的交互，用来交换一些游戏世界级的信息（比如公会信息，跨服组队信息，跨服聊天频道等）。 6- 这里的两条连接，想表达的意思是，UserServer和GameServer的Agent是可以互换使用的，也就是玩家进入组内之后，就不需要再切换 Agent。如果不怕乱套，也可以把登陆服务器的Agent也算上，这样用户整个过程里就不需要再更换Agent，减少重复连接的次数，也提高了稳定性。 （毕竟连接次数少了，也降低了连不上服务器的出现几率） 在这个架构里面，**GameServer实际上是一个游戏逻辑的综合体，**里面可以再去扩展成几个不同的逻辑服务器，通过PublicServer进行公共数据交换。","title":"4 关于游戏服务端架构的整理"},{"content":"5 各类游戏对应的服务端架构 类型一：卡牌、跑酷等弱交互服务端 卡牌跑酷类因为交互弱，玩家和玩家之间不需要实时面对面PK，打一下对方的离线数据，计算下排行榜，买卖下道具即可，所以实现往往使用简单的 HTTP服务器：\n登录时可以使用非对称加密（RSA, DH），服务器根据客户端uid，当前时间戳还有服务端私钥，计算哈希得到的加密 key 并发送给客户端。之后双方都用 HTTP通信，并用那个key进行RC4加密。客户端收到key和时间戳后保存在内存，用于之后通信，服务端不需要保存 key，因为每次都可以根据客户端传上来的 uid 和 时间戳 以及服务端自己的私钥计算得到。**用模仿 TLS的行为，**来保证多次 HTTP请求间的客户端身份，并通过时间戳保证同一人两次登录密钥不同。 每局开始时，访问一下，请求一下关卡数据，玩完了又提交一下，验算一下是否合法，获得什么奖励，数据库用单台 MySQL或者 MongoDB即可，后端的 Redis做缓存（可选）。\n如果要实现通知，那么让客户端定时15秒轮询一下服务器，如果有消息就取下来，如果没消息可以逐步放长轮询时间，比如30秒；如果有消息，就缩短轮询时间到10秒，5秒，即便两人聊天，延迟也能自适应。 此类服务器用来实现一款三国类策略或者卡牌及酷跑的游戏已经绰绰有余，这类游戏因为逻辑简单，玩家之间交互不强，使用 HTTP来开发的话，开发速度快，调试只需要一个浏览器就可以把逻辑调试清楚了。\n类型2：第一代游戏服务器 1978 1978年，英国著名的财经学校University of Essex的学生 Roy Trubshaw编写了世界上第一个MUD程序《MUD1》，在University of Essex于1980年接入 ARPANET之后加入了不少外部的玩家，甚至包括国外的玩家。《MUD1》程序的源代码在 ARPANET共享之后出现了众多的改编版本，至此MUD才在全世界广泛流行起来。不断完善的 MUD1的基础上产生了开源的 MudOS（1991），成为众多网游的鼻祖：\nMUDOS采用 C语言开发，因为玩家和玩家之间有比较强的交互（聊天，交易，PK），MUDOS使用单线程无阻塞套接字来服务所有玩家，所有玩家的请求都发到同一个线程去处****理，主线程每隔1秒钟更新一次所有对象（网络收发，更新对象状态机，处理超时，刷新地图，刷新NPC）。 游戏世界采用房间的形式组织起来，每个房间有东南西北四个方向可以移动到下一个房间，由于欧美最早的网游都是地牢迷宫形式的，因此场景的基本单位被称为 “房间”。\nMUDOS使用一门称为LPC的脚本语言来描述整个世界（包括房间拓扑，配置，NPC，以及各种剧情）。游戏里面的高级玩家（巫师），可以不断的通过修改脚本来为游戏添加房间以及增加剧情。早年 MUD1上线时只有17个房间，Roy Trubshaw毕业以后交给他的师弟 Richard Battle，在 Richard Battle手上，不断的添加各种玩法到一百多个房间，终于将 MUD发扬光大。 用户使用 Telnet之类的客户端用 Tcp协议连接到 MUDOS上，使用纯文字进行游戏，每条指令用回车进行分割。比如 1995年国内第一款 MUD游戏《侠客行》，你敲入*：”go east”，*游戏就会提示你：“*后花园 - 这里是归云庄的后花园，种满了花草，几个庄丁正在浇花。此地乃是含羞草生长之地。这里唯一的出口是 north。这里有：花待 阿牧（A mu），还有二位庄丁（Zhuang Ding）”，然后你继续用文字操作，查看阿牧的信息：“look a mu”，*系统提示：“*花待 阿牧（A mu）他是陆乘风的弟子，受命在此看管含羞草。他看起来三十多岁，生得眉清目秀，端正大方，一表人才。他的武艺看上去【不是很高】，出手似乎【极轻】”。*然后你可以选择击败他获得含羞草，但是你吃了含羞草却又可能会中毒死亡。在早期网上资源贫乏的时候，这样的游戏有很强的代入感。 用户数据保存在文件中，每个用户登录时，从文本文件里把用户的数据全部加载进来，操作全部在内存里面进行，无需马上刷回磁盘。用户退出了，或者每隔5分钟检查到数据改动了，都会保存到磁盘。这样的系统在当时每台服务器承载个4000人同时游戏，不是特别大的问题。从1991年的 MUDOS发布后，全球各地都在为他改进，扩充，退出新版本，随着 Windows图形机能的增强。1997游戏《UO》在 MUDOS的基础上为角色增加的x,y坐标，为每个房间增加了地图，并且为每个角色增加了动画，形成了第一代的图形网络游戏。 因为游戏内容基本可以通过 LPC脚本进行定制，所以MUDOS也成为名副其实的第一款服务端引擎，引擎一次性开发出来，然后制作不同游戏内容。后续国内的《万王之王》等游戏，很多都是跟《UO》一样，直接在 MUDOS上进行二次开发，加入房间的地图还有角色的坐标等要素，该架构一直为国内的第一代 MMORPG提供了稳固的支持，直到 2003年，还有游戏基于 MUDOS开发。 虽然后面图形化增加了很多东西，但是这些MMORPG后端的本质还是 MUDOS。\n随着游戏内容的越来越复杂，架构变得越来越吃不消了，各种负载问题慢慢浮上水面，于是有了我们的第二代游戏服务器。\n类型3：第二代游戏服务器 2003 2000年后，网游已经脱离最初的文字MUD，进入全面图形化年代。最先承受不住的其实是很多小文件，用户上下线，频繁的读取写入用户数据，导致负载越来越大。随着在线人数的增加和游戏数据的增加，服务器变得不抗重负。同时早期 EXT磁盘分区比较脆弱，稍微停电，容易发生大面积数据丢失。因此第一步就是拆分文件存储到数据库去。\n此时游戏服务端已经脱离陈旧的 MUDOS体系，各个公司在参考 MUDOS结构的情况下，开始自己用 C再重新开发自己的游戏服务端。并且脚本也抛弃了 LPC，采用扩展性更好的 Python或者 Lua来代替。由于主逻辑使用单线程模型，随着游戏内容的增加，传统单服务器的结构进一步成为瓶颈。于是有人开始拆分游戏世界，变为下面的模型：\n游戏服务器压力拆分后得以缓解，但是两台游戏服务器同时访问数据库，大量重复访问，大量数据交换，使得数据库成为下一个瓶颈。于是形成了数据库前端代理（DB Proxy），游戏服务器不直接访问数据库而是访问代理，再有代理访问数据库，同时提供内存级别的cache。早年 MySQL4之前没有提供存储过程，这个前端代理一般和 MySQL跑在同一台上，它转化游戏服务器发过来的高级数据操作指令，拆分成具体的数据库操作，一定程度上代替了存储过程：\n但是这样的结构并没有持续太长时间，因为玩家切换场景经常要切换连接，中间的状态容易错乱。而且游戏服务器多了以后，相互之间数据交互又会变得比较麻烦，于是人们拆分了网络功能，独立出一个网关服务 Gate（有的地方叫 Session，有的地方叫 LinkSvr之类的，名字不同而已）：\n把网络功能单独提取出来，让用户统一去连接一个网关服务器，再有网关服务器转发数据到后端游戏服务器。而游戏服务器之间数据交换也统一连接到网管进行交换。这样类型的服务器基本能稳定的为玩家提供游戏服务，一台网关服务1-2万人，后面的游戏服务器每台服务5k-1w，依游戏类型和复杂度不同而已，图中隐藏了很多不重要的服务器，如登录和管理。这是目前应用最广的一个模型，到今天仍然很多新项目会才用这样的结构来搭建。 人都是有惯性的，按照先前的经验，似乎把 MUDOS拆分的越开性能越好。于是大家继续想，网关可以拆分呀；基础服务如聊天交易可以拆分呀；还可以提供web接口，数据库可以拆分呀，于是有了下面的模型：\n这样的模型好用么？确实有成功游戏使用类似这样的架构，并且发挥了它的性能优势，比如一些大型 MMORPG。但是有两个挑战：\n每增加一级服务器，状态机复杂度可能会翻倍，导致研发和找bug的成本上升； 并且对开发组挑战比较大，一旦项目时间吃紧，开发人员经验不足，很容易弄挂。 比如我见过某上海一线游戏公司的一个 RPG上来就要上这样的架构，我看了下他们团队成员的经验，问了下他们的上线日期，劝他们用前面稍微简单一点的模型。人家自信得很，认为有成功项目是这么做的，他们也要这么做，自己很想实现一套。于是他们义无反顾的开始编码，项目做了一年多，然后，就没有然后了。 现今在游戏成功率不高的情况下，一开始上一套比较复杂的架构需要考虑投资回报率，比如你的游戏上线半年内 PCU会去到多少？如果一个 APRG游戏，每组服务器5千人都到不了的话，那么选择一套更为贴近实际情况的结构更为经济。即使后面你的项目真的超过5千人朝着1万人目标奔的话，相信那个时候你的项目已经挣大钱了 ，你数着钱加着班去逐步迭代，一次次拆分它，相信心里也是乐开花的。 上面这些类型基本都是从拆分 MUDOS开始，将 MUDOS中的各个部件从单机一步步拆成分布式。虽然今天任然很多新项目在用上面某一种类似的结构，或者自己又做了其他热点模块的拆分。因为他们本质上都是对 MUDOS的分解，故将他们归纳为第二代游戏服务器。\n类型4：第三代游戏服务器 2007 从魔兽世界开始无缝世界地图已经深入人心，比较以往游戏玩家走个几步还需要切换场景，每次切换就要等待 LOADING个几十秒是一件十分破坏游戏体验的事情。于是对于 2005年以后的大型 MMORPG来说，无缝地图已成为一个标准配置。比较以往按照地图来切割游戏而言，无缝世界并不存在一块地图上面的人有且只由一台服务器处理了：\n每台 Node服务器用来管理一块地图区域，由 NodeMaster（NM）来为他们提供总体管理。更高层次的 World则提供大陆级别的管理服务。这里省略若干细节服务器，比如传统数据库前端，登录服务器，日志和监控等，统统用 ADMIN概括。在这样的结构下，玩家从一块区域走向另外一块区域需要简单处理一下：\n玩家1完全由节点A控制，玩家3完全由节点B控制。而处在两个节点边缘的2号玩家，则同时由A和B提供服务。玩家2从A移动到B的过程中，会同时向A请求左边的情况，并向B请求右边的情况。但是此时玩家2还是属于A管理。直到玩家2彻底离开AB边界很远，才彻底交由B管理。按照这样的逻辑将世界地图分割为一块一块的区域，交由不同的 Node去管理。 对于一个 Node所负责的区域，地理上没必要连接在一起，比如大陆的四周边缘部分和高山部分的区块人比较少，可以统一交给一个Node去管理，而这些区块在地理上并没有联系在一起的必要性。一个 Node到底管理哪些区块，可以根据游戏实时运行的负载情况，定时维护的时候进行更改 NodeMaster 上面的配置。 于是碰到第一个问题是很多 Node服务器需要和玩家进行通信，需要问管理服务器特定UID为多少的玩家到底在哪台 Gate上，以前按场景切割的服务器这个问题不大，问了一次以后就可以缓存起来了，但是现在服务器种类增加不少，玩家又会飘来飘去，按UID查找玩家比较麻烦；另外一方面 GATE需要动态根据坐标计算和哪些 Node通信，导致逻辑越来越厚，于是把：“用户对象”从负责连接管理的 GATE中切割出来势在必行于是有了下面的模型：\n网关服务器再次退回到精简的网络转发功能，而用户逻辑则由按照 UID划分的 OBJ服务器来承担，GATE是按照网络接入时的负载来分布，而 OBJ则是按照资源的编号（UID）来分布，这样和一个用户通信直接根据 UID计算出 OBJ服务器编号发送数据即可。而新独立出来的 OBJ则提供了更多高层次的服务：\n对象移动：管理具体玩家在不同的 Node所管辖的区域之间的移动，并同需要的 Node进行沟通。 数据广播：Node可以给每个用户设置若干 TAG，然后通知 Object Master 按照TAG广播。 对象消息：通用消息推送，给某个用户发送数据，直接告诉 OBJ，不需要直接和 GATE打交道。 好友聊天：角色之间聊天直接走 OBJ/OBJ MASTER。 整个服务器主体分为三层以后，NODE专注场景，OBJ专注玩家对象，GATE专注网络。这样的模型在无缝场景服务器中得到广泛的应用。但是随着时间的推移，负载问题也越来越明显，做个活动，远来不活跃的区域变得十分活跃，靠每周维护来调整还是比较笨重的，于是有了动态负载均衡。 动态负载均衡有两种方法，第一种是按照负载，由 Node Master 定时动态移动修改一下各个 Node的边界，而不同的玩家对象按照先前的方法从一台 Node上迁移到另外一台 Node上：\n这样 Node Master定时查找地图上的热点区域，计算新的场景切割方式，然后告诉其他服务器开始调整，具体处理方式还是和上面对象跨越边界移动的方法一样。 但是上面这种方式实现相对复杂一些，于是人们设计出了更为简单直接的一种新方法：\n还是将地图按照标准尺寸均匀切割成静态的网格，每个格子由一个具体的Node负责，但是根据负载情况，能够实时的迁移到其他 Node上。\n在迁移分为三个阶段：准备，切换，完成。三个状态由Node Master负责维护。准备阶段新的 Node开始同步老 Node上面该网格的数据，完成后告诉NM；NM确认OK后同时通知新旧 Node完成切换。完成切换后，如果 Obj服务器还在和老的 Node进行通信，老的 Node将会对它进行纠正，得到纠正的 OBJ将修正自己的状态，和新的 Node进行通信。\n很多无缝动态负载均衡的服务端宣称自己支持无限的人数，但不意味着 MMORPG游戏的人数上限真的可以无限扩充，因为这样的体系会受制于网络带宽和客户端性能。带宽决定了同一个区域最大广播上限，而客户端性能决定了同一个屏幕到底可以绘制多少个角色。\n从无缝地图引入了分布式对象模型开始，已经完全脱离 MUDOS体系，成为一种新的服务端模型。又由于动态负载均衡的引入，让无缝服务器如虎添翼，容纳着超过上一代游戏服务器数倍的人数上限，并提供了更好的游戏体验，我们称其为第三代游戏服务端架构。网游以大型多人角色扮演为开端，RPG网游在相当长的时间里一度占据90%以上，使得基于 MMORPG的服务端架构得到了蓬勃的发展，然而随着玩家对RPG的疲惫，各种非MMORPG游戏如雨后春笋般的出现在人们眼前，受到市场的欢迎。\n类型5：战网游戏服务器 经典战网服务端和 RPG游戏有两个区别：RPG是分区分服的，北京区的用户和广州区的用户老死不相往来。而战网，虽然每局游戏一般都是 8人以内，但全国只有一套服务器，所有的玩家都可以在一起游戏，而玩家和玩家之使用 P2P的方式连接在一起，组成一局游戏：\n玩家通过 Match Making 服务器使用：创建、加入、自动匹配、邀请 等方式组成一局游戏。服务器会选择一个人做 Host，其他人 P2P连接到做主的玩家上来。STUN是帮助玩家之间建立 P2P的牵引服务器，而由于 P2P联通情况大概只有 75%，实在联不通的玩家会通过 Forward进行转发。 大量的连接对战，体育竞技游戏采用类似的结构。P2P有网状模型（所有玩家互相连接），和星状模型（所有玩家连接一个主玩家）。复杂的游戏状态在网状模型下难以形成一致，因此星状P2P模型经受住了历史的考验。除去游戏数据，支持语音的战网系统也会将所有人的语音数据发送到做主的那个玩家机器上，通过混音去重再编码的方式返回给所有用户。 战网类游戏，以竞技、体育、动作等类型的游戏为主，较慢节奏的 RPG（包括ARPG）有本质上的区别，而激烈的游戏过程必然带来到较 RPG复杂的多的同步策略，这样的同步机制往往带来的是很多游戏结果由客户端直接计算得出，那在到处都是破解的今天，如何保证游戏结果的公正呢？ 主要方法就是投票法，所有客户端都会独立计算，然后传递给服务器。如果结果相同就更新记录，如果结果不一致，会采取类似投票的方式确定最终结果。同时记录本剧游戏的所有输入，在可能的情况下，找另外闲散的游戏客户端验算整局游戏是否为该结果。并且记录经常有作弊嫌疑的用户，供运营人员封号时参考。\n类型6：休闲游戏服务器 休闲游戏同战网服务器类似，都是全区架构，不同的是有房间服务器，还有具体的游戏服务器，游戏主体不再以玩家 P2P进行，而是连接到专门的游戏服务器处理：\n和战网一样的全区架构，用户数据不能象分区的 RPG那样一次性load到内存，然后在内存里面直接修改。全区架构下，**为了应对一个用户同时玩几个游戏，**用户数据需要区分基本数据和不同的游戏数据，而游戏数据又需要区分积分数据、和文档数据。胜平负之类的积分可以直接提交增量修改，而更为普遍的文档类数据则需要提供读写令牌，写令牌只有一块，读令牌有很多块。同帐号同一个游戏同时在两台电脑上玩时，最先开始的那个游戏获得写令牌，可以操作任意的用户数据。而后开始的那个游戏除了可以提交胜平负积分的增量改变外，对用户数据采用只读的方式，保证游戏能运行下去，但是会提示用户，游戏数据锁定。\n类型7：现代动作类网游 从早期的韩国动作游戏开始，传统的战网动作类游戏和 RPG游戏开始尝试融合。单纯的动作游戏玩家容易疲倦，留存也没有 RPG那么高；而单纯 RPG战斗却又慢节奏的乏味，无法满足很多玩家激烈对抗的期望，于是二者开始融合成为新一代的：动作 + 城镇 模式。玩家在城镇中聚集，然后以开副本的方式几个人出去以动作游戏的玩法来完成各种 RPG任务。**本质就是一套 RPG服务端+副本服务端。**由于每次副本时人物可以控制在8人以内，因此可以获得更为实时的游戏体验，让玩家玩的更加爽快。\n思考 说了那么多的游戏服务器类型，其实也差不多了，剩下的类型大家拼凑一下其实也就是这个样子而已。游戏服务端经历了那么多结构上的变迁，内部开发模式是否依然不变？究竟是继续延续传统的开发方式？还是有了更多突破性的方法？经历那么多次架构变迁，后面是否有共通的逻辑？未来的发展还会存在哪些困难？游戏服务端开发如何达到最终的彼岸？\n","permalink":"https://haokiu.com/blog/47a72212e86d4b6a8fe0516f8ff1cf65/","summary":"5 各类游戏对应的服务端架构 类型一：卡牌、跑酷等弱交互服务端 卡牌跑酷类因为交互弱，玩家和玩家之间不需要实时面对面PK，打一下对方的离线数据，计算下排行榜，买卖下道具即可，所以实现往往使用简单的 HTTP服务器：\n登录时可以使用非对称加密（RSA, DH），服务器根据客户端uid，当前时间戳还有服务端私钥，计算哈希得到的加密 key 并发送给客户端。之后双方都用 HTTP通信，并用那个key进行RC4加密。客户端收到key和时间戳后保存在内存，用于之后通信，服务端不需要保存 key，因为每次都可以根据客户端传上来的 uid 和 时间戳 以及服务端自己的私钥计算得到。**用模仿 TLS的行为，**来保证多次 HTTP请求间的客户端身份，并通过时间戳保证同一人两次登录密钥不同。 每局开始时，访问一下，请求一下关卡数据，玩完了又提交一下，验算一下是否合法，获得什么奖励，数据库用单台 MySQL或者 MongoDB即可，后端的 Redis做缓存（可选）。\n如果要实现通知，那么让客户端定时15秒轮询一下服务器，如果有消息就取下来，如果没消息可以逐步放长轮询时间，比如30秒；如果有消息，就缩短轮询时间到10秒，5秒，即便两人聊天，延迟也能自适应。 此类服务器用来实现一款三国类策略或者卡牌及酷跑的游戏已经绰绰有余，这类游戏因为逻辑简单，玩家之间交互不强，使用 HTTP来开发的话，开发速度快，调试只需要一个浏览器就可以把逻辑调试清楚了。\n类型2：第一代游戏服务器 1978 1978年，英国著名的财经学校University of Essex的学生 Roy Trubshaw编写了世界上第一个MUD程序《MUD1》，在University of Essex于1980年接入 ARPANET之后加入了不少外部的玩家，甚至包括国外的玩家。《MUD1》程序的源代码在 ARPANET共享之后出现了众多的改编版本，至此MUD才在全世界广泛流行起来。不断完善的 MUD1的基础上产生了开源的 MudOS（1991），成为众多网游的鼻祖：\nMUDOS采用 C语言开发，因为玩家和玩家之间有比较强的交互（聊天，交易，PK），MUDOS使用单线程无阻塞套接字来服务所有玩家，所有玩家的请求都发到同一个线程去处****理，主线程每隔1秒钟更新一次所有对象（网络收发，更新对象状态机，处理超时，刷新地图，刷新NPC）。 游戏世界采用房间的形式组织起来，每个房间有东南西北四个方向可以移动到下一个房间，由于欧美最早的网游都是地牢迷宫形式的，因此场景的基本单位被称为 “房间”。\nMUDOS使用一门称为LPC的脚本语言来描述整个世界（包括房间拓扑，配置，NPC，以及各种剧情）。游戏里面的高级玩家（巫师），可以不断的通过修改脚本来为游戏添加房间以及增加剧情。早年 MUD1上线时只有17个房间，Roy Trubshaw毕业以后交给他的师弟 Richard Battle，在 Richard Battle手上，不断的添加各种玩法到一百多个房间，终于将 MUD发扬光大。 用户使用 Telnet之类的客户端用 Tcp协议连接到 MUDOS上，使用纯文字进行游戏，每条指令用回车进行分割。比如 1995年国内第一款 MUD游戏《侠客行》，你敲入*：”go east”，*游戏就会提示你：“*后花园 - 这里是归云庄的后花园，种满了花草，几个庄丁正在浇花。此地乃是含羞草生长之地。这里唯一的出口是 north。这里有：花待 阿牧（A mu），还有二位庄丁（Zhuang Ding）”，然后你继续用文字操作，查看阿牧的信息：“look a mu”，*系统提示：“*花待 阿牧（A mu）他是陆乘风的弟子，受命在此看管含羞草。他看起来三十多岁，生得眉清目秀，端正大方，一表人才。他的武艺看上去【不是很高】，出手似乎【极轻】”。*然后你可以选择击败他获得含羞草，但是你吃了含羞草却又可能会中毒死亡。在早期网上资源贫乏的时候，这样的游戏有很强的代入感。 用户数据保存在文件中，每个用户登录时，从文本文件里把用户的数据全部加载进来，操作全部在内存里面进行，无需马上刷回磁盘。用户退出了，或者每隔5分钟检查到数据改动了，都会保存到磁盘。这样的系统在当时每台服务器承载个4000人同时游戏，不是特别大的问题。从1991年的 MUDOS发布后，全球各地都在为他改进，扩充，退出新版本，随着 Windows图形机能的增强。1997游戏《UO》在 MUDOS的基础上为角色增加的x,y坐标，为每个房间增加了地图，并且为每个角色增加了动画，形成了第一代的图形网络游戏。 因为游戏内容基本可以通过 LPC脚本进行定制，所以MUDOS也成为名副其实的第一款服务端引擎，引擎一次性开发出来，然后制作不同游戏内容。后续国内的《万王之王》等游戏，很多都是跟《UO》一样，直接在 MUDOS上进行二次开发，加入房间的地图还有角色的坐标等要素，该架构一直为国内的第一代 MMORPG提供了稳固的支持，直到 2003年，还有游戏基于 MUDOS开发。 虽然后面图形化增加了很多东西，但是这些MMORPG后端的本质还是 MUDOS。\n随着游戏内容的越来越复杂，架构变得越来越吃不消了，各种负载问题慢慢浮上水面，于是有了我们的第二代游戏服务器。\n类型3：第二代游戏服务器 2003 2000年后，网游已经脱离最初的文字MUD，进入全面图形化年代。最先承受不住的其实是很多小文件，用户上下线，频繁的读取写入用户数据，导致负载越来越大。随着在线人数的增加和游戏数据的增加，服务器变得不抗重负。同时早期 EXT磁盘分区比较脆弱，稍微停电，容易发生大面积数据丢失。因此第一步就是拆分文件存储到数据库去。\n此时游戏服务端已经脱离陈旧的 MUDOS体系，各个公司在参考 MUDOS结构的情况下，开始自己用 C再重新开发自己的游戏服务端。并且脚本也抛弃了 LPC，采用扩展性更好的 Python或者 Lua来代替。由于主逻辑使用单线程模型，随着游戏内容的增加，传统单服务器的结构进一步成为瓶颈。于是有人开始拆分游戏世界，变为下面的模型：\n游戏服务器压力拆分后得以缓解，但是两台游戏服务器同时访问数据库，大量重复访问，大量数据交换，使得数据库成为下一个瓶颈。于是形成了数据库前端代理（DB Proxy），游戏服务器不直接访问数据库而是访问代理，再有代理访问数据库，同时提供内存级别的cache。早年 MySQL4之前没有提供存储过程，这个前端代理一般和 MySQL跑在同一台上，它转化游戏服务器发过来的高级数据操作指令，拆分成具体的数据库操作，一定程度上代替了存储过程：\n但是这样的结构并没有持续太长时间，因为玩家切换场景经常要切换连接，中间的状态容易错乱。而且游戏服务器多了以后，相互之间数据交互又会变得比较麻烦，于是人们拆分了网络功能，独立出一个网关服务 Gate（有的地方叫 Session，有的地方叫 LinkSvr之类的，名字不同而已）：\n把网络功能单独提取出来，让用户统一去连接一个网关服务器，再有网关服务器转发数据到后端游戏服务器。而游戏服务器之间数据交换也统一连接到网管进行交换。这样类型的服务器基本能稳定的为玩家提供游戏服务，一台网关服务1-2万人，后面的游戏服务器每台服务5k-1w，依游戏类型和复杂度不同而已，图中隐藏了很多不重要的服务器，如登录和管理。这是目前应用最广的一个模型，到今天仍然很多新项目会才用这样的结构来搭建。 人都是有惯性的，按照先前的经验，似乎把 MUDOS拆分的越开性能越好。于是大家继续想，网关可以拆分呀；基础服务如聊天交易可以拆分呀；还可以提供web接口，数据库可以拆分呀，于是有了下面的模型：","title":"5 各类游戏对应的服务端架构"},{"content":"6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则 腾讯QQGame游戏同时在线的玩家数量极其庞大，为了方便组织玩家组队游戏，腾讯设置了大量游戏室（房间），玩家可以选择进入属意的房间，并在此房间内找到可以加入的游戏组（牌桌、棋盘等）。玩家选择进入某个房间时，必须确保此房间当前人数未满（通常上限为400），否则进入步骤将会失败。玩家在登入QQGame后，会从服务器端获取某类游戏下所有房间的当前人数数据，玩家可以据此找到未满的房间以便进入。\n如上篇所述的原因，如果待进入房间的人数接近上限时，玩家的进入请求可能失败，这是因为服务器在收到此进入请求之前可能有若干其他玩家也请求进入这个房间，造成房间人数达到上限。\n这一问题是无法通过上篇所述调整协作分配的方法来解决的，这是因为：要进入的房间是由玩家来指定的，无法在服务器端完成此项工作，游戏软件必须将服务器端所维护的所有房间人数数据复制到玩家的客户端，并让玩家在界面上看到这些数据，以便进行选择。\n这样，上篇所述的客户端与服务器端协作分配原则（谁掌握数据，谁干活），还得加上一些限制条件，并让位于另一个所谓\u0026quot;用户驱动客户端行为\u0026quot;原则\u0026ndash;如果某个功能的执行是由用户来推动的，则这个功能的实现应当放在客户端（或者至少由客户端来控制整个协作），并且客户端必须持有此功能所依赖相关数据的副本，这个副本应当尽量与服务器端的源保持同步。\n图一\u0026quot;进入房间\u0026quot;失败示意\nQQGame还存在一个明显的不足，就是：玩家如果在游戏一段时间后，离开了某个房间，并且想进入其它房间，这时QQGame并不会刷新所有房间的当前人数，造成玩家据此信息所选的待进入房间往往实际上人数已满，使得进入步骤失败。笔者碰到的最糟情形是重复3、4次以上，才最后成功进入另外某个房间。此缺陷其实质是完全放弃了客户端数据副本与服务器端的源保持同步的原则。\n实际上，QQGame的开发者有非常充分的理由来为此缺陷的存在进行辩护：QQGame同时在线的用户数超过百万甚至千万数量级，如果所有客户端要实时（所谓实时，就玩家的体验容忍度而言，可以定为不超过1秒的延迟）地从服务器端获取更新数据，那么最终只有一个结果\u0026ndash;系统彻底崩溃。\n设想一下每秒千万次请求的吞吐量，以普通服务器每秒上百个请求的处理能力（这个数据是根据服务请求处理过程可能涉及到I/O操作来估值的，纯内存处理的情形可能提高若干数量级），需要成千上万台服务器组成集群方能承受（高可用性挑战）；而随着玩家不断地进入或退出游戏房间，相关数据一直在快速变化中，\n正向来看，假设有一台中心服务器持有这些数据，那么需要让成千上万台服务器与中心保持这些动态数据的实时同步（数据一致性挑战）； 相对应的，逆向来看，玩家进入房间等请求被分配给不同的服务器来处理，一旦玩家进入房间成功则对应服务器内的相关数据被改变，那么假定中的中心服务器就需要实时汇集所有工作服务器内发生的数据变动（数据完整性挑战）。 同时处理上万台服务器的数据同步，这需要什么样的中心服务器呢？即使有这样的超级服务器存在，那么Internet网较大的（而且不稳定的）网络通讯延迟又怎么解决呢？\n对于软件缺陷而言，可以在不同的层面来加以解决\u0026ndash;从设计、到需求、甚至是直接在业务层面来解决（例如，08年北京奥运会网上购票系统，为了解决订票请求拥塞而至系统崩溃的缺陷，最后放弃了原先\u0026quot;先到先得\u0026quot;的购票业务流程，改为：用户先向系统发订票申请，系统只是记录下来而不进行处理，而到了空闲时，在后台随机抽选幸运者，为他们一一完成订票业务）。当然解决方案所处的层面越高，可能就越让人不满意。\n就上述进入房间可能遭遇失败的缺陷而言，最简便的解决方案就是：在需求层面调整系统的操作方式，即**增加一个类似上篇所述\u0026quot;自动快速加入游戏\u0026quot;的功能\u0026ndash;\u0026ldquo;自动进入房间\u0026quot;功能。**系统在服务器端为玩家找到一个人数较多又未满的房间，并尝试进入（注意，软件需求是由用户的操作目标所驱动的，玩家在此的目标就是尽快加入一个满意的游戏组，因此由系统来替代玩家选择目标房间同样符合相关目标）。而为了方便玩家手工选择要进入的房间，则应当增加一个\u0026quot;刷新当前各房间人数\u0026quot;的功能。另外，**还可以调整房间的组织模式，**例如以地域为单位来划分房间，像深圳（长城宽带）区房间1、四川（电信）房间3、北美区房间1等，在深圳上网的玩家将被系统引导而优先进入深圳区的房间。\n不管怎样，解决软件缺陷的王道还是在设计层面。要解决上述缺陷，架构设计师就必须同时面对高可用、数据一致性、完整性等方面的严峻挑战。\n在思考相关解决方案时，我们将应用若干与高性能服务器集群架构设计相关的一些重要原则。首先是\u0026quot;分而治之\u0026quot;原则，即将大量客户端发出的服务请求进行适当的划分（例如，所有从深圳长城宽带上网的玩家所发出的服务请求分为一组），分别分配给不同的服务器（例如，将前述服务请求分组分配给放置于深圳数据中心的服务器）来加以处理。对于QQGame千万级的并发服务请求数而言，采用Scale Up向上扩展，即升级单个服务器处理能力的方式基本上不予考虑（没有常规的主机能处理每秒上千万的请求）。唯一可行的，只有Scale Out向外扩展，即利用大量服务器集群做负载均衡的方式，这实质上就是\u0026quot;分而治之\u0026quot;原则的具体应用。\n图二 分而治之\u0026quot;下的QQGame游戏服务集群部署\n然而，要应用\u0026quot;分而治之\u0026quot;原则进行Scale Out向外扩展，还依赖于其它的条件。如果各服务器在处理被分配的服务请求时，其行为与其它服务器的行为结果产生交叉（循环）依赖，换句话讲就是共享了某些数据（例如，服务器A处理客户端a发来的进入房间#n请求，而同时，服务器B也在处理客户端b发来的进入房间#n请求，此时服务器A与B的行为存在循环依赖\u0026ndash;因为两者要同时访问房间#n的数据，这一共享数据会造成两者间的循环依赖），则各服务器之间必须确保这些共享数据的一致完整性，否则就可能发生逻辑错误（例如，假定房间#n的人数差一个就满了，服务器A与B在独自处理的情况下，将同时让客户端a与b的进入请求成功，于是房间#n的最终人数将超出上限）。\n而要做到此点，各服务器的处理进程之间就必须保持同步（实际上就是排队按先后顺序访问共享数据，例如：服务器A先处理，让客户端a进入房间成功，此时房间#n满员；此后服务器B更新到房间#n满的数据，于是客户端b的进入请求处理结果失败），这样，原来将海量请求做负载均衡的意图就彻底失败了，多台服务器的并发处理能力在此与一台实质上并没有区别。\n由此，我们导出了另外一个所谓\u0026quot;处理自治\u0026rdquo;（或称\u0026quot;行为独立\u0026quot;）的原则，即所有参与负载均衡的服务器，其处理对应服务请求的行为应当不循环依赖于其它服务器，换句话讲，就是各服务器的行为相对独立（**注意：**在这里，非循环依赖是允许的，下文中我们来分析为什么）。\n由此可见，简单的负载均衡策略对于QQGame而言是解决不了问题的。我们必须找到一种途径，使得在使用大量服务器进行\u0026quot;分而治之\u0026quot;的同时，同时有确保各个服务器\u0026quot;处理自治\u0026quot;。此间的关键就在于\u0026quot;分而治之\u0026quot;的\u0026quot;分\u0026quot;字上。前述将某个地域网段内上网的玩家所发出的服务请求分到一组，并分配给同一服务器的做法，其目的不外乎是尽可能地减少网络通讯延迟带来的负面影响。但它不能满足\u0026quot;处理自治\u0026quot;的要求，为了确保自治，应当让同一台服务器所处理的请求本身是\u0026quot;自治\u0026quot;（准确的说法是\u0026quot;自闭包\u0026quot;Closure）的。同一台服务器所处理的所有请求组成一个服务请求集合，这个集合如果与其它任何与其无交集的（请求）集合（包含此集合的父集合除外）不循环依赖，则此服务请求集合是\u0026quot;自闭包\u0026quot;的，而处理此请求集合的服务器，其\u0026quot;行为独立\u0026quot;。\n我们可以将针对同一房间的进入请求划分到同一服务请求分组，这些请求相互之间当然是存在循环依赖的，但与其它分组中的请求却不存在循环依赖（本房间内人数的变化不会影响到其它房间），而将它们都分配给同一服务器（不妨命名为\u0026quot;房间管理服务器\u0026quot;，简称\u0026quot;房间服务器\u0026quot;）后，那个服务器将是\u0026quot;处理自治\u0026quot;的。\n图三 满足\u0026quot;处理自治\u0026quot;条件的QQ游戏区域\u0026quot;房间管理\u0026quot;服务部署\n那么接下来要解决的问题，就是玩家所关注的某个游戏区内，所有房间当前人数数据的实时更新问题。其解决途径与上述的方法类似，我们还是**将所有获取同一区内房间数据的服务请求归为一组，并交给同一服务器处理。**与上文所述场景不同的是，这个服务器需要实时汇集本区内所有房间服务器的房间人数数据。我们可以让每个房间服务器一旦发生数据变更时，就向此服务器（不妨命名为\u0026quot;游戏区域管理服务器\u0026quot;，简称\u0026quot;区服务器\u0026quot;）推送一个变更数据记录，而推送的数据只需包含房间Id和所有进入的玩家Id（房间服务器还包含其它细节数据，例如牌桌占位数据）便可。\n另外，由于一个区内的玩家数可能是上十万数量级，一个服务器根本承担不了此种负荷，那么**怎么解决这一矛盾呢？**如果深入分析，我们会发现，更新区内房间数据的请求是一种数据只读类请求，它不会对服务器状态造成变更影响，因此这些请求相互间不存在依赖关系；这样，我们可以将它们再任意划分为更小的分组，而同时这些分组仍然保持\u0026quot;自闭包\u0026quot;特性，然后分配给不同的区服务器。多台区服务器来负责同一区的数据更新请求，负载瓶颈被解决。\n当然，此前，还需将这些区服务器分为1台主区服务器和n台从属区服务器；主区服务器负责汇集本区内所有房间服务器的房间人数数据，从属区服务器则从主区服务器实时同步区房间数据副本。\n更好的做法，则是如『图五』所示，由房间服务器来充当从属区服务器的角色，玩家进入某个房间后，在玩家进入另外一个房间之前，其客户端都将从此房间对应的房间服务器来更新区内房间数据。要注意的是，图中房间服务器的数据更新利用了所谓的\u0026quot;分布式对象缓存服务\u0026quot;。\n玩家进入某个房间后，还要加入某个游戏组才能玩游戏。上篇所述的方案，是让第一个加入某个牌桌的用户，其主机自动充当本牌桌的游戏服务器；而其它玩家要加入此牌桌，其加入请求应当发往第一个加入的用户主机；此后开始游戏，其对弈过程将由第一个加入用户的主机来主导执行。\n那么此途径是否同样也符合上述的前两个设计原则呢？游戏在执行的过程中，根据输赢结果，玩家要加分或减分，同时还要记录胜负场数。这些数据必须被持久化（比如在数据库中保存下来），因此游戏服务器（『图六』中的设计，是由4个部署于QQ客户端的\u0026quot;升级\u0026quot;游戏前台逻辑执行服务，加上1个\u0026quot;升级\u0026quot;游戏后台逻辑执行服务，共同组成一个牌桌的\u0026quot;升级\u0026quot;游戏服务）在处理相关游戏执行请求时，将依赖于玩家游戏账户数据服务（『图六』中的所谓\u0026quot;QQGame会话服务\u0026quot;）；\n不过这种依赖是非循环的，即玩家游戏账户数据服务器的行为反过来并不依赖于游戏服务器。上文中曾提到，\u0026ldquo;处理自治\u0026quot;原则中非循环依赖是允许的。这里游戏服务器在处理游戏收盘请求时，要调用玩家游戏账户数据服务器来更新相关数据；因为不同玩家的游戏账户数据是相互独立的，此游戏服务器在调用游戏账户数据服务器时，逻辑上不受其它游戏服务器调用游戏账户数据服务器的影响，不存在同步等待问题；所以，游戏服务器在此能够达成负载均衡的意图。 点击图片可以放大\n图****四 存在\u0026quot;非循环依赖\u0026quot;的QQ游戏客户端P2P服务与交互逻辑部署\n不过，在上述场景中，虽然不存在同步依赖，但是性****能依赖还是存在的，游戏账户数据服务器的处理性能不够时，会造成游戏服务器长时间等待。为此，我们**可以应用分布式数据库表水平分割的技术，**将QQ玩家用户以其登记的行政区来加以分组，并部署于对应区域的数据库中（例如，深圳的玩家数据都在深圳的游戏账户数据库中）。\n点击图片可以放大\n图五 满足\u0026quot;自闭包\u0026quot;条件的QQ分布式数据库（集群）部署\n实际上，我们由此还可以推论出一个数据库表水平分割的原则\u0026ndash;任何数据库表水平分割的方式，必须确保同一数据库实例中的数据记录是\u0026quot;自闭包\u0026quot;的，即不同数据库实例中的数据记录相互间不存在循环依赖。\n总之，初步满足QQGame之苛刻性能要求的分布式架构现在已经是初具雏形了，但仍然有很多涉及性能方面的细节问题有待解决。例如，Internet网络通讯延迟的问题、服务器之间协作产生的性能瓶颈问题等等。笔者将在下篇中继续深入探讨这些话题。\n","permalink":"https://haokiu.com/blog/84414d52b22b4cdaa7a7cf4beb0e1585/","summary":"6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则 腾讯QQGame游戏同时在线的玩家数量极其庞大，为了方便组织玩家组队游戏，腾讯设置了大量游戏室（房间），玩家可以选择进入属意的房间，并在此房间内找到可以加入的游戏组（牌桌、棋盘等）。玩家选择进入某个房间时，必须确保此房间当前人数未满（通常上限为400），否则进入步骤将会失败。玩家在登入QQGame后，会从服务器端获取某类游戏下所有房间的当前人数数据，玩家可以据此找到未满的房间以便进入。\n如上篇所述的原因，如果待进入房间的人数接近上限时，玩家的进入请求可能失败，这是因为服务器在收到此进入请求之前可能有若干其他玩家也请求进入这个房间，造成房间人数达到上限。\n这一问题是无法通过上篇所述调整协作分配的方法来解决的，这是因为：要进入的房间是由玩家来指定的，无法在服务器端完成此项工作，游戏软件必须将服务器端所维护的所有房间人数数据复制到玩家的客户端，并让玩家在界面上看到这些数据，以便进行选择。\n这样，上篇所述的客户端与服务器端协作分配原则（谁掌握数据，谁干活），还得加上一些限制条件，并让位于另一个所谓\u0026quot;用户驱动客户端行为\u0026quot;原则\u0026ndash;如果某个功能的执行是由用户来推动的，则这个功能的实现应当放在客户端（或者至少由客户端来控制整个协作），并且客户端必须持有此功能所依赖相关数据的副本，这个副本应当尽量与服务器端的源保持同步。\n图一\u0026quot;进入房间\u0026quot;失败示意\nQQGame还存在一个明显的不足，就是：玩家如果在游戏一段时间后，离开了某个房间，并且想进入其它房间，这时QQGame并不会刷新所有房间的当前人数，造成玩家据此信息所选的待进入房间往往实际上人数已满，使得进入步骤失败。笔者碰到的最糟情形是重复3、4次以上，才最后成功进入另外某个房间。此缺陷其实质是完全放弃了客户端数据副本与服务器端的源保持同步的原则。\n实际上，QQGame的开发者有非常充分的理由来为此缺陷的存在进行辩护：QQGame同时在线的用户数超过百万甚至千万数量级，如果所有客户端要实时（所谓实时，就玩家的体验容忍度而言，可以定为不超过1秒的延迟）地从服务器端获取更新数据，那么最终只有一个结果\u0026ndash;系统彻底崩溃。\n设想一下每秒千万次请求的吞吐量，以普通服务器每秒上百个请求的处理能力（这个数据是根据服务请求处理过程可能涉及到I/O操作来估值的，纯内存处理的情形可能提高若干数量级），需要成千上万台服务器组成集群方能承受（高可用性挑战）；而随着玩家不断地进入或退出游戏房间，相关数据一直在快速变化中，\n正向来看，假设有一台中心服务器持有这些数据，那么需要让成千上万台服务器与中心保持这些动态数据的实时同步（数据一致性挑战）； 相对应的，逆向来看，玩家进入房间等请求被分配给不同的服务器来处理，一旦玩家进入房间成功则对应服务器内的相关数据被改变，那么假定中的中心服务器就需要实时汇集所有工作服务器内发生的数据变动（数据完整性挑战）。 同时处理上万台服务器的数据同步，这需要什么样的中心服务器呢？即使有这样的超级服务器存在，那么Internet网较大的（而且不稳定的）网络通讯延迟又怎么解决呢？\n对于软件缺陷而言，可以在不同的层面来加以解决\u0026ndash;从设计、到需求、甚至是直接在业务层面来解决（例如，08年北京奥运会网上购票系统，为了解决订票请求拥塞而至系统崩溃的缺陷，最后放弃了原先\u0026quot;先到先得\u0026quot;的购票业务流程，改为：用户先向系统发订票申请，系统只是记录下来而不进行处理，而到了空闲时，在后台随机抽选幸运者，为他们一一完成订票业务）。当然解决方案所处的层面越高，可能就越让人不满意。\n就上述进入房间可能遭遇失败的缺陷而言，最简便的解决方案就是：在需求层面调整系统的操作方式，即**增加一个类似上篇所述\u0026quot;自动快速加入游戏\u0026quot;的功能\u0026ndash;\u0026ldquo;自动进入房间\u0026quot;功能。**系统在服务器端为玩家找到一个人数较多又未满的房间，并尝试进入（注意，软件需求是由用户的操作目标所驱动的，玩家在此的目标就是尽快加入一个满意的游戏组，因此由系统来替代玩家选择目标房间同样符合相关目标）。而为了方便玩家手工选择要进入的房间，则应当增加一个\u0026quot;刷新当前各房间人数\u0026quot;的功能。另外，**还可以调整房间的组织模式，**例如以地域为单位来划分房间，像深圳（长城宽带）区房间1、四川（电信）房间3、北美区房间1等，在深圳上网的玩家将被系统引导而优先进入深圳区的房间。\n不管怎样，解决软件缺陷的王道还是在设计层面。要解决上述缺陷，架构设计师就必须同时面对高可用、数据一致性、完整性等方面的严峻挑战。\n在思考相关解决方案时，我们将应用若干与高性能服务器集群架构设计相关的一些重要原则。首先是\u0026quot;分而治之\u0026quot;原则，即将大量客户端发出的服务请求进行适当的划分（例如，所有从深圳长城宽带上网的玩家所发出的服务请求分为一组），分别分配给不同的服务器（例如，将前述服务请求分组分配给放置于深圳数据中心的服务器）来加以处理。对于QQGame千万级的并发服务请求数而言，采用Scale Up向上扩展，即升级单个服务器处理能力的方式基本上不予考虑（没有常规的主机能处理每秒上千万的请求）。唯一可行的，只有Scale Out向外扩展，即利用大量服务器集群做负载均衡的方式，这实质上就是\u0026quot;分而治之\u0026quot;原则的具体应用。\n图二 分而治之\u0026quot;下的QQGame游戏服务集群部署\n然而，要应用\u0026quot;分而治之\u0026quot;原则进行Scale Out向外扩展，还依赖于其它的条件。如果各服务器在处理被分配的服务请求时，其行为与其它服务器的行为结果产生交叉（循环）依赖，换句话讲就是共享了某些数据（例如，服务器A处理客户端a发来的进入房间#n请求，而同时，服务器B也在处理客户端b发来的进入房间#n请求，此时服务器A与B的行为存在循环依赖\u0026ndash;因为两者要同时访问房间#n的数据，这一共享数据会造成两者间的循环依赖），则各服务器之间必须确保这些共享数据的一致完整性，否则就可能发生逻辑错误（例如，假定房间#n的人数差一个就满了，服务器A与B在独自处理的情况下，将同时让客户端a与b的进入请求成功，于是房间#n的最终人数将超出上限）。\n而要做到此点，各服务器的处理进程之间就必须保持同步（实际上就是排队按先后顺序访问共享数据，例如：服务器A先处理，让客户端a进入房间成功，此时房间#n满员；此后服务器B更新到房间#n满的数据，于是客户端b的进入请求处理结果失败），这样，原来将海量请求做负载均衡的意图就彻底失败了，多台服务器的并发处理能力在此与一台实质上并没有区别。\n由此，我们导出了另外一个所谓\u0026quot;处理自治\u0026rdquo;（或称\u0026quot;行为独立\u0026quot;）的原则，即所有参与负载均衡的服务器，其处理对应服务请求的行为应当不循环依赖于其它服务器，换句话讲，就是各服务器的行为相对独立（**注意：**在这里，非循环依赖是允许的，下文中我们来分析为什么）。\n由此可见，简单的负载均衡策略对于QQGame而言是解决不了问题的。我们必须找到一种途径，使得在使用大量服务器进行\u0026quot;分而治之\u0026quot;的同时，同时有确保各个服务器\u0026quot;处理自治\u0026quot;。此间的关键就在于\u0026quot;分而治之\u0026quot;的\u0026quot;分\u0026quot;字上。前述将某个地域网段内上网的玩家所发出的服务请求分到一组，并分配给同一服务器的做法，其目的不外乎是尽可能地减少网络通讯延迟带来的负面影响。但它不能满足\u0026quot;处理自治\u0026quot;的要求，为了确保自治，应当让同一台服务器所处理的请求本身是\u0026quot;自治\u0026quot;（准确的说法是\u0026quot;自闭包\u0026quot;Closure）的。同一台服务器所处理的所有请求组成一个服务请求集合，这个集合如果与其它任何与其无交集的（请求）集合（包含此集合的父集合除外）不循环依赖，则此服务请求集合是\u0026quot;自闭包\u0026quot;的，而处理此请求集合的服务器，其\u0026quot;行为独立\u0026quot;。\n我们可以将针对同一房间的进入请求划分到同一服务请求分组，这些请求相互之间当然是存在循环依赖的，但与其它分组中的请求却不存在循环依赖（本房间内人数的变化不会影响到其它房间），而将它们都分配给同一服务器（不妨命名为\u0026quot;房间管理服务器\u0026quot;，简称\u0026quot;房间服务器\u0026quot;）后，那个服务器将是\u0026quot;处理自治\u0026quot;的。\n图三 满足\u0026quot;处理自治\u0026quot;条件的QQ游戏区域\u0026quot;房间管理\u0026quot;服务部署\n那么接下来要解决的问题，就是玩家所关注的某个游戏区内，所有房间当前人数数据的实时更新问题。其解决途径与上述的方法类似，我们还是**将所有获取同一区内房间数据的服务请求归为一组，并交给同一服务器处理。**与上文所述场景不同的是，这个服务器需要实时汇集本区内所有房间服务器的房间人数数据。我们可以让每个房间服务器一旦发生数据变更时，就向此服务器（不妨命名为\u0026quot;游戏区域管理服务器\u0026quot;，简称\u0026quot;区服务器\u0026quot;）推送一个变更数据记录，而推送的数据只需包含房间Id和所有进入的玩家Id（房间服务器还包含其它细节数据，例如牌桌占位数据）便可。\n另外，由于一个区内的玩家数可能是上十万数量级，一个服务器根本承担不了此种负荷，那么**怎么解决这一矛盾呢？**如果深入分析，我们会发现，更新区内房间数据的请求是一种数据只读类请求，它不会对服务器状态造成变更影响，因此这些请求相互间不存在依赖关系；这样，我们可以将它们再任意划分为更小的分组，而同时这些分组仍然保持\u0026quot;自闭包\u0026quot;特性，然后分配给不同的区服务器。多台区服务器来负责同一区的数据更新请求，负载瓶颈被解决。\n当然，此前，还需将这些区服务器分为1台主区服务器和n台从属区服务器；主区服务器负责汇集本区内所有房间服务器的房间人数数据，从属区服务器则从主区服务器实时同步区房间数据副本。\n更好的做法，则是如『图五』所示，由房间服务器来充当从属区服务器的角色，玩家进入某个房间后，在玩家进入另外一个房间之前，其客户端都将从此房间对应的房间服务器来更新区内房间数据。要注意的是，图中房间服务器的数据更新利用了所谓的\u0026quot;分布式对象缓存服务\u0026quot;。\n玩家进入某个房间后，还要加入某个游戏组才能玩游戏。上篇所述的方案，是让第一个加入某个牌桌的用户，其主机自动充当本牌桌的游戏服务器；而其它玩家要加入此牌桌，其加入请求应当发往第一个加入的用户主机；此后开始游戏，其对弈过程将由第一个加入用户的主机来主导执行。\n那么此途径是否同样也符合上述的前两个设计原则呢？游戏在执行的过程中，根据输赢结果，玩家要加分或减分，同时还要记录胜负场数。这些数据必须被持久化（比如在数据库中保存下来），因此游戏服务器（『图六』中的设计，是由4个部署于QQ客户端的\u0026quot;升级\u0026quot;游戏前台逻辑执行服务，加上1个\u0026quot;升级\u0026quot;游戏后台逻辑执行服务，共同组成一个牌桌的\u0026quot;升级\u0026quot;游戏服务）在处理相关游戏执行请求时，将依赖于玩家游戏账户数据服务（『图六』中的所谓\u0026quot;QQGame会话服务\u0026quot;）；\n不过这种依赖是非循环的，即玩家游戏账户数据服务器的行为反过来并不依赖于游戏服务器。上文中曾提到，\u0026ldquo;处理自治\u0026quot;原则中非循环依赖是允许的。这里游戏服务器在处理游戏收盘请求时，要调用玩家游戏账户数据服务器来更新相关数据；因为不同玩家的游戏账户数据是相互独立的，此游戏服务器在调用游戏账户数据服务器时，逻辑上不受其它游戏服务器调用游戏账户数据服务器的影响，不存在同步等待问题；所以，游戏服务器在此能够达成负载均衡的意图。 点击图片可以放大\n图****四 存在\u0026quot;非循环依赖\u0026quot;的QQ游戏客户端P2P服务与交互逻辑部署\n不过，在上述场景中，虽然不存在同步依赖，但是性****能依赖还是存在的，游戏账户数据服务器的处理性能不够时，会造成游戏服务器长时间等待。为此，我们**可以应用分布式数据库表水平分割的技术，**将QQ玩家用户以其登记的行政区来加以分组，并部署于对应区域的数据库中（例如，深圳的玩家数据都在深圳的游戏账户数据库中）。\n点击图片可以放大\n图五 满足\u0026quot;自闭包\u0026quot;条件的QQ分布式数据库（集群）部署\n实际上，我们由此还可以推论出一个数据库表水平分割的原则\u0026ndash;任何数据库表水平分割的方式，必须确保同一数据库实例中的数据记录是\u0026quot;自闭包\u0026quot;的，即不同数据库实例中的数据记录相互间不存在循环依赖。\n总之，初步满足QQGame之苛刻性能要求的分布式架构现在已经是初具雏形了，但仍然有很多涉及性能方面的细节问题有待解决。例如，Internet网络通讯延迟的问题、服务器之间协作产生的性能瓶颈问题等等。笔者将在下篇中继续深入探讨这些话题。","title":"6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则"},{"content":"7 QQ游戏百万人同时在线服务器架构实现 QQ游戏于前几日终于突破了百万人同时在线的关口，向着更为远大的目标迈进，这让其它众多传统的棋牌休闲游戏平台黯然失色，相比之下，联众似乎已经根本不是QQ的对手，因为QQ除了这100万的游戏在线人数外，它还拥有3亿多的注册量（当然很多是重复注册的）以及QQ聊天软件900万的同时在线率，我们已经可以预见未来由QQ构建起来的强大棋牌休闲游戏帝国。\n服务器程序，其可承受的同时连接数目是有理论峰值的，在实际应用中，能达到一万人的同时连接并能保证正常的数据交换已经是很不容易了，通常这个值都在2000到5000之间，据说QQ的单台服务器同时连接数目也就是在这个值这间。\n如果要实现2000到5000用户的单服务器同时在线，是不难的。在windows下，比较成熟的技术是采用IOCP\u0026mdash;完成端口。只要运用得当，一个完成端口服务器是完全可以达到2K到5K的同时在线量的。但，5K这样的数值离百万这样的数值实在相差太大了，所以，百万人的同时在线是单台服务器肯定无法实现的。\n要实现百万人同时在线，首先要实现一个比较完善的完成端口服务器模型，这个模型要求至少可以承载2K到5K的同时在线率（当然，如果你MONEY多，你也可以只开发出最多允许100人在线的服务器）。在构建好了基本的完成端口服务器之后，就是有关服务器组的架构设计了。之所以说这是一个服务器组，是因为它绝不仅仅只是一台服务器，也绝不仅仅是只有一种类型的服务器。\n简单地说，实现百万人同时在线的服务器模型应该是：登陆服务器＋大厅服务器＋房间服务器。当然，也可以是其它的模型，但其基本的思想是一样的。下面，我将逐一介绍这三类服务器的各自作用。\n/ 1 /\n**登陆服务器：**一般情况下，我们会向玩家开放若干个公开的登陆服务器，就如QQ登陆时让你选择的从哪个QQ游戏服务器登陆一样，QQ登陆时让玩家选择的六个服务器入口实际上就是登陆服务器。登陆服务器主要完成负载平衡的作用。详细点说就是，在登陆服务器的背后，有N个大厅服务器，登陆服务器只是用于为当前的客户端连接选择其下一步应该连接到哪个大厅服务器，当登陆服务器为当前的客户端连接选择了一个合适的大厅服务器后，客户端开始根据登陆服务器提供的信息连接到相应的大厅上去，同时客户端断开与登陆服务器的连接，为其他玩家客户端连接登陆服务器腾出套接字资源。\n在设计登陆服务器时，至少应该有以下功能：N个大厅服务器的每一个大厅服务器都要与所有的登陆服务器保持连接，并实时地把本大厅服务器当前的同时在线人数通知给各个登陆服务器，这其中包括：用户进入时的同时在线人数增加信息以及用户退出时的同时在线人数减少信息。这里的各个大厅服务器同时在线人数信息就是登陆服务器为客户端选择某个大厅让其登陆的依据。举例来说，玩家A通过登陆服务器1连接到登陆服务器，登陆服务器开始为当前玩家在众多的大厅服务器中根据哪一个大厅服务器人数比较少来选择一个大厅，同时把这个大厅的连接IP和端口发给客户端，客户端收到这个IP和端口信息后，根据这个信息连接到此大厅，同时，客户端断开与登陆服务器之间的连接，这便是用户登陆过程中，在登陆服务器这一块的处理流程。\n/ 2 /\n大厅服务器：是普通玩家看不到的服务器，它的连接IP和端口信息是登陆服务器通知给客户端的。也就是说，在QQ游戏的本地文件中，具体的大厅服务器连接IP和端口信息是没有保存的。大厅服务器的主要作用是向玩家发送游戏房间列表信息。\n这些信息包括：\n每个游戏房间的类型 名称 在线人数 连接地址以及其它如游戏帮助文件URL的信息 从****界面上看的话，大厅服务器就是我们输入用户名和密码并校验通过后进入的游戏房间列表界面。\n大厅服务器，主要有以下功能：\n一是向当前玩家广播各个游戏房间在线人数信息； 二是提供游戏的版本以及下载地址信息； 三是提供各个游戏房间服务器的连接IP和端口信息； 四是提供游戏帮助的URL信息； 五是提供其它游戏辅助功能。 但在这众多的功能中，有一点是最为核心的，即：**为玩家提供进入具体的游戏房间的通道，让玩家顺利进入其欲进入的游戏房间。**玩家根据各个游戏房间在线人数，判定自己进入哪一个房间，然后双击服务器列表中的某个游戏房间后玩家开始进入游戏房间服务器。\n/ 3 /\n游戏房间服务器：具体地说就是如“斗地主1”，“斗地主2”这样的游戏房间。游戏房间服务器才是具体的负责执行游戏相关逻辑的服务器。这样的游戏逻辑分为两大类：\n第一类是通用的游戏房间逻辑，如：进入房间，离开房间，进入桌子，离开桌子以及在房间内说话等； 第二类是游戏桌子逻辑，这个就是各种不同类型游戏的主要区别之处了，比如斗地主中的叫地主或不叫地主的逻辑等，当然，游戏桌子逻辑里也包括有通用的各个游戏里都存在的游戏逻辑，比如在桌子内说话等。 总之，游戏房间服务器才是真正负责执行游戏具体逻辑的服务器。\n这里提到的三类服务器，均采用的是完成端口模型，每个服务器最多连接数目是5000人，但是，我在游戏房间服务器上作了逻辑层的限定，最多只允许300人同时在线。其他两个服务器仍然允许最多5000人的同时在线。\n如果按照这样的结构来设计，那么要实现百万人的同时在线就应该是这样：\n首先是大厅，1000000/5000＝200。也就是说，至少要200台大厅服务器，但通常情况下，考虑到实际使用时服务器的处理能力和负载情况，应该至少准备250台左右的大厅服务器程序。 另外，**具体的各种类型的游戏房间服务器需要多少，**就要根据当前玩各种类型游戏的玩家数目分别计算了，比如斗地主最多是十万人同时在线，每台服务器最多允许300人同时在线，那么需要的斗地主服务器数目就应该不少于：100000/300=333，准备得充分一点，就要准备350台斗地主服务器。 除正常的玩家连接外，还要考虑到：对于登陆服务器，会有250台大厅服务器连接到每个登陆服务器上，这是始终都要保持的连接； 而对于大厅服务器而言，如果仅仅有斗地主这一类的服务器，就要有350多个连接与各个大厅服务器始终保持着。所以从这一点看，结构在某些方面还存在着需要改进的地方，但核心思想是：尽快地提供用户登陆的速度，尽可能方便地让玩家进入游戏中。\n","permalink":"https://haokiu.com/blog/64368e0e78ea4a568fff21e1511c0f43/","summary":"7 QQ游戏百万人同时在线服务器架构实现 QQ游戏于前几日终于突破了百万人同时在线的关口，向着更为远大的目标迈进，这让其它众多传统的棋牌休闲游戏平台黯然失色，相比之下，联众似乎已经根本不是QQ的对手，因为QQ除了这100万的游戏在线人数外，它还拥有3亿多的注册量（当然很多是重复注册的）以及QQ聊天软件900万的同时在线率，我们已经可以预见未来由QQ构建起来的强大棋牌休闲游戏帝国。\n服务器程序，其可承受的同时连接数目是有理论峰值的，在实际应用中，能达到一万人的同时连接并能保证正常的数据交换已经是很不容易了，通常这个值都在2000到5000之间，据说QQ的单台服务器同时连接数目也就是在这个值这间。\n如果要实现2000到5000用户的单服务器同时在线，是不难的。在windows下，比较成熟的技术是采用IOCP\u0026mdash;完成端口。只要运用得当，一个完成端口服务器是完全可以达到2K到5K的同时在线量的。但，5K这样的数值离百万这样的数值实在相差太大了，所以，百万人的同时在线是单台服务器肯定无法实现的。\n要实现百万人同时在线，首先要实现一个比较完善的完成端口服务器模型，这个模型要求至少可以承载2K到5K的同时在线率（当然，如果你MONEY多，你也可以只开发出最多允许100人在线的服务器）。在构建好了基本的完成端口服务器之后，就是有关服务器组的架构设计了。之所以说这是一个服务器组，是因为它绝不仅仅只是一台服务器，也绝不仅仅是只有一种类型的服务器。\n简单地说，实现百万人同时在线的服务器模型应该是：登陆服务器＋大厅服务器＋房间服务器。当然，也可以是其它的模型，但其基本的思想是一样的。下面，我将逐一介绍这三类服务器的各自作用。\n/ 1 /\n**登陆服务器：**一般情况下，我们会向玩家开放若干个公开的登陆服务器，就如QQ登陆时让你选择的从哪个QQ游戏服务器登陆一样，QQ登陆时让玩家选择的六个服务器入口实际上就是登陆服务器。登陆服务器主要完成负载平衡的作用。详细点说就是，在登陆服务器的背后，有N个大厅服务器，登陆服务器只是用于为当前的客户端连接选择其下一步应该连接到哪个大厅服务器，当登陆服务器为当前的客户端连接选择了一个合适的大厅服务器后，客户端开始根据登陆服务器提供的信息连接到相应的大厅上去，同时客户端断开与登陆服务器的连接，为其他玩家客户端连接登陆服务器腾出套接字资源。\n在设计登陆服务器时，至少应该有以下功能：N个大厅服务器的每一个大厅服务器都要与所有的登陆服务器保持连接，并实时地把本大厅服务器当前的同时在线人数通知给各个登陆服务器，这其中包括：用户进入时的同时在线人数增加信息以及用户退出时的同时在线人数减少信息。这里的各个大厅服务器同时在线人数信息就是登陆服务器为客户端选择某个大厅让其登陆的依据。举例来说，玩家A通过登陆服务器1连接到登陆服务器，登陆服务器开始为当前玩家在众多的大厅服务器中根据哪一个大厅服务器人数比较少来选择一个大厅，同时把这个大厅的连接IP和端口发给客户端，客户端收到这个IP和端口信息后，根据这个信息连接到此大厅，同时，客户端断开与登陆服务器之间的连接，这便是用户登陆过程中，在登陆服务器这一块的处理流程。\n/ 2 /\n大厅服务器：是普通玩家看不到的服务器，它的连接IP和端口信息是登陆服务器通知给客户端的。也就是说，在QQ游戏的本地文件中，具体的大厅服务器连接IP和端口信息是没有保存的。大厅服务器的主要作用是向玩家发送游戏房间列表信息。\n这些信息包括：\n每个游戏房间的类型 名称 在线人数 连接地址以及其它如游戏帮助文件URL的信息 从****界面上看的话，大厅服务器就是我们输入用户名和密码并校验通过后进入的游戏房间列表界面。\n大厅服务器，主要有以下功能：\n一是向当前玩家广播各个游戏房间在线人数信息； 二是提供游戏的版本以及下载地址信息； 三是提供各个游戏房间服务器的连接IP和端口信息； 四是提供游戏帮助的URL信息； 五是提供其它游戏辅助功能。 但在这众多的功能中，有一点是最为核心的，即：**为玩家提供进入具体的游戏房间的通道，让玩家顺利进入其欲进入的游戏房间。**玩家根据各个游戏房间在线人数，判定自己进入哪一个房间，然后双击服务器列表中的某个游戏房间后玩家开始进入游戏房间服务器。\n/ 3 /\n游戏房间服务器：具体地说就是如“斗地主1”，“斗地主2”这样的游戏房间。游戏房间服务器才是具体的负责执行游戏相关逻辑的服务器。这样的游戏逻辑分为两大类：\n第一类是通用的游戏房间逻辑，如：进入房间，离开房间，进入桌子，离开桌子以及在房间内说话等； 第二类是游戏桌子逻辑，这个就是各种不同类型游戏的主要区别之处了，比如斗地主中的叫地主或不叫地主的逻辑等，当然，游戏桌子逻辑里也包括有通用的各个游戏里都存在的游戏逻辑，比如在桌子内说话等。 总之，游戏房间服务器才是真正负责执行游戏具体逻辑的服务器。\n这里提到的三类服务器，均采用的是完成端口模型，每个服务器最多连接数目是5000人，但是，我在游戏房间服务器上作了逻辑层的限定，最多只允许300人同时在线。其他两个服务器仍然允许最多5000人的同时在线。\n如果按照这样的结构来设计，那么要实现百万人的同时在线就应该是这样：\n首先是大厅，1000000/5000＝200。也就是说，至少要200台大厅服务器，但通常情况下，考虑到实际使用时服务器的处理能力和负载情况，应该至少准备250台左右的大厅服务器程序。 另外，**具体的各种类型的游戏房间服务器需要多少，**就要根据当前玩各种类型游戏的玩家数目分别计算了，比如斗地主最多是十万人同时在线，每台服务器最多允许300人同时在线，那么需要的斗地主服务器数目就应该不少于：100000/300=333，准备得充分一点，就要准备350台斗地主服务器。 除正常的玩家连接外，还要考虑到：对于登陆服务器，会有250台大厅服务器连接到每个登陆服务器上，这是始终都要保持的连接； 而对于大厅服务器而言，如果仅仅有斗地主这一类的服务器，就要有350多个连接与各个大厅服务器始终保持着。所以从这一点看，结构在某些方面还存在着需要改进的地方，但核心思想是：尽快地提供用户登陆的速度，尽可能方便地让玩家进入游戏中。","title":"7 QQ游戏百万人同时在线服务器架构实现"},{"content":"8 大型多人在线游戏服务器架构设计 由于大型多人在线游戏服务器理论上需要支持无限多的玩家，所以对服务器端是一个非常大的考验。服务器必须是安全的，可维护性高的，可伸缩性高的，可负载均衡的，支持高并发请求的。面对这些需求，我们在设计服务器的时候就需要慎重考虑，特别是架构的设计，如果前期设计不好，最后面临的很可能是重构。\n一款游戏服务器的架构都是慢慢从小变大的，不可能一下子就上来一个完善的服务器构架，目前流行的说法是游戏先上线，再扩展。所以说我们在做架构的时候，一定要把底层的基础组件做好，方便以后扩展，但是刚开始的时候留出一些接口，并不实现它，将来游戏业务的发展，再慢慢扩展。当然，如果前期设计的不好，后期业务扩展了，但架构没办法扩展，只能加班加点搞了。\n面对庞大的数据量我们想到的唯一个解决方案就是分而治之，即采用分布式的方式去解决它。把紧凑独立的功能单独拿出来做。分担到不同的物理服务器上面去运行。而且做到可以动态扩展。这就需要我们考虑好模块的划分，尽量要业务独立，关联性低。\n前期，由于游戏需要尽快上线，开发周期短，我们需要把服务尽快的跑起来，这个时候的目标应该是尽快完成测试版本开发，单台服务器支持的人数可以稍微低一些，但是当人数暴涨时，我们可以能过多开几组服务来支持新增涨的用户量，即可以平衡扩展就可以了。到后期我们再把具体的模块单独拿出来支持，比如前期逻辑服务器上包括:活动，关卡，背包，技能，好友管理等。后期我们可以把好友，背包管理或其它的单独做一个服务进程，部署在不同的物理服务器上面。我们先按分区的服务进行设计，后面在部署的时候可以部署为世界服务器，下面是一个前期的架构图，下面我们从每个服务器的功能说起：\n1，登陆管理服务 负责用户的登陆验证，如果有注册功能的话，也可以放在这里。一般手机游戏直接走sdk验证。网页游戏和客户端游戏会有注册功能，也可以叫用户管理服务。\n1.1 用户登陆验证 负责接收客户端的用户登陆请求，验证账号的合法性，是否在黑名单（被封号的用户），是否在白名单（一般是测试账号，服务未开启时也可以进入）。如果是sdk登陆，此服务向第三方服务发起回调请求。\n1.2 登陆安全加密 使用加密的传输协议，见通信协议部分。\n1.3 是否在白名单内 白名单是给内部测试人员使用的，在服务器未开启的状态下，白名单的用户可以提前进入游戏进行游戏测试。\n1.4 判断是否在黑名单 黑名单的用户是禁止登陆的，一般这是一些被封号的用户，拒绝登陆。\n1.5 登陆验证 服务器使用私钥解密密码，进行验证，如果是sdk登陆，则直接向第三方服务发起回调。\n1.6 登陆令牌（token）生成 当用户登陆验证成功之后，服务器端需要生成一个登陆令牌token,这个token具有时效性，当用户客户端拿到这个token之后，如果在一定时间内没有登陆游戏成功，那么这个token将失败，用户需要重新申请token,token存储在登陆服务这，向外提供用户是否已登陆的接口，其它服务器想验证如果是否登陆，就拿那个服务收到的token来此验证。\n1.7 显示用户角色信息 当用户登陆成功之后，显示最近登陆的角色信息。\n2，显示公告 用户登陆成功之后，请求公告服务器，获取最新的公告，公告服务先根据token和Userid验证用户是否已登陆，公告有可能根据渠道的不同，显示不同的公告。所以 公告一定是要可以根据渠道编辑的。\n3，选区服务 当用户登陆成功之后，请求服务器分区列表服务器，显示当前所有的大区列表。\n3.1 验证用户是否已登陆 向登陆服务器请求验证是否已登陆。\n3.2 大区列表显示 大区列表信息中只显示大区id和大区名称。这样做是为了安全考虑，不一次性把大区对应的网关ip和端口暴露出来，也可以减少网络的传输量。\n3.3 用户点击选择某个大区，客户端拿到大区id再向选区服务请求获取此大区对应的网关ip地址和端口。根据负载算法计算得出。\n3.4 网关的选择 选区服务会维护一份网关的配置列表。一个大区对应一到多个网关，当配置有多个网关时，需要定时检测各个网关是否连接正常，如果发现有网关连接不上，需要把大区对应的网关信息设置为无效，不再参与网关的分配，并发出报警。 一般对于网关的选择，可以使用用户id求余法加虚网关节点法。这样在网关节点数量固定的情况下，一个用户总是会被分配到同一个网关上面。但是如果只是使用求余法的话，可能会造成用户分布不均衡，这里可以通过增加网关的虚拟节点（其它就是增加某个网关的权重，让用户多来一些到这个网关上面），这个可以参考哈稀一致性算法。包括后面说到的一个网关对应多个逻辑服务器，也可以使用同样的方法。这部分可以抽象出来一个模块使用。\n3.5 选区服务对内要提供修改服务器状态的接口，比如维护中…\n4，登陆网关 4.1 建立连接 收到客户端的建立连接请求之后，记录此channel和对应的连接建立时间。并设置如果在一定时间内未收到登陆请求，则断开连接。返回给客户端登陆超时。\n4.2 登陆请求 收到登陆请求后，移除记录的channelid信息，向登陆服务器验证用户是否已登陆过,并向外广播用户角色登陆成功的消息。\n4.3 登陆成功后，接收网关的其它的消息\n4.4 客户端消息合法性验证 在向逻辑服务器转发消息之前验证消息的合法性，具体验证方法见协议安全验 证。\n4.5 将客户端消息转发送到对应的逻辑服务器。\n5 通信协议 5.1协议序列化和返回序列化 可以直接使用protobuf，直接对协议进行序列化和反序列化。\n5.2协议组成 5.2.1 包头构成 包总长度，加密字符串长度，加密字符串内容，userId,playerId,版本号，内包内容。 5.2.2 包体组成 请求的逻辑信息，是protobuf后对应的二进制数据。\n包总长度 加密内容 UserId playerId 请求序列id 版本号 内包内容 Int 64 Long Long Long int varchar 4 64 8 8 8 4 变长 5.3 协议内容加密 如果协议明文传输的话，被篡改的风险就非常大，所以我们要对传输协议进行加密传输，由于协议内容大小不固定，为了保证效率，采用对称加密算法，首先客户端使用AES的公钥对消息内容加密（上表中userid之后的信息），客户端把加密后的报文发送到服务器端。AES的公钥在用户第一次连接时获取。\n5.4 协议完整性验证 尽管我们对消息做了加密，但也不是万无一失的，为了进一步确保消息没有被篡改，我们需要对消息的完整性进行检测，使用数字摘要的方式，首先客户端对userid及之后的协议信息进行AES加密，加密之后取它的md5值，md5值用于验证数据的完整性。这个md5值会被传送到服务器，如果协议信息被修改了，那个md5就会不同。\n5.5 保证md5数字摘要的值的安全 为了防止非法用户修改协议内容后，模拟客户端操作重新生成新的数字摘要信息，我们对生成的数字摘要信息进行二次加密，这次使用RSA的公钥对md5的值进行加密，将加密的内容和其它信息一起发送到服务器。服务器根据ip向登陆服务器拿到AES的公钥和RSA的私钥，先用RSA 私钥取出客户端加密的md5值，服务器端计算userid后面的数据的md5值，如果两个md5值一样，说明安全的。如果不一样，说明用户是非法的，加入黑名单。因为RAS使用公钥加密，必须使用对应的私钥才能解密，而且不同的公钥对应的私钥不同，这样就算非法用户重新生成了数字摘要，在服务器端也是验证不通过的。\n5.6 取出明文信息 当服务器收到报文后，对报文进行数子摘要验证通过之后，服务器端使用用户自己对应的AES的公钥，解密数据，获得明文数据。为了保证安全，每个用户的AES公钥可能不一样。\n6 发布订阅服务 发布订阅是一种分布式的解耦方式，它使用模块更加独立，模块间的数据交互更加方便，发布订阅模式是一种一对多的关系，发布方不关心谁订阅了它，只要想获得它发布的消息的服务，都可以去订阅它。发布方式是异步的，它增强了系统的处理性能，增加了系统的吞吐量。目前的大多数消息队列都支持发布订阅模式，比如rabbitmq,activemq,kafka等消息队列。发布订阅服务可以单独部署，增强了系统的扩展性和稳定性。\n7，RPC调用 在服务器内部不同的服务有时候需要信息交互。为了方便服务之间的调用，我们引入了RPC的概念。客户端调用一个api之后，底层会把此调用发送到远程的服务上处理，远程服务处理完之后再返回结果。rpc的作用就是封装底层协议的序列化和反序列化，它让用户感觉不到调用被发送到了远程服务，而感觉还是在本地一样\n7.1 同步rpc 当调用一个同步的rpc之后，结果并不是立刻返回，而是在等待rpc服务器端的返回。同步rpc可以直接使用带同步的socket实现。或者http请求。另一种方式是调用rpc方法之后，在本地自旋，直到服务端返回。\n7.2 异步rpc 异步rpc调用之后，结果是立刻返回的，它的处理方式是把业务放在回调方法里面，而不是一直占用线程在那里等待数据的返回，这样就可以记空闲的线程去处理另外的消息，当消息从服务器端返回后，会去调用那个回调方法。\n8，合服要提前设计好 现在大多数的游戏都是分区分服的，经过一段时间的运营之后，有些老的大区可能在线人数非常的少了，为了节约成本，首先会在一台物理机器上运行多个大区对应的进程，再过一段时间，可能需要把不同区的数据合并起来到一个数据库中。而对用户来说是感觉不到变化的。 为什么说合服要提交设计好呢?因为如果设计不好，后期在合服的时候会遇到很多问题， 比如用户唯一主键问题，表与表主键关联重复问题，那么在合服存在的情况下，如何保证用户的唯一性呢，也就是我一个用户在两个大区都建立了账号，这个时候userid是一样的，还有一个角色id，如果角色id不是全局唯一的，也可能重复。而角色id如果参与了表外键设计，一重复数据就乱了。 首先，要保证用户的唯一性。而且各个表的外键引用也必须是唯一的，即合服之后不会再发生改变。那么有几个键需要全局唯一，userid（用户id），roleId(角色id)，为了区分用户原来所在的区，需要记录角色所在的大区id,所以一个userid和一个大区id来确定一个唯一的角色id,而角色的其它信息使用角色id做外键引用。这样合服就可以直接把两个库的数据合并到一起了。 这个只是用角色数据举个例子，在数据库中，凡是独立存在的，最好都使用全局唯一id，比如公会，每个服都会有公会，但每个服的公会id不能都是从一开始，即不能使用数据库自增的方式。\n","permalink":"https://haokiu.com/blog/5b23fbec804b470cb12e3c20af54d1d0/","summary":"8 大型多人在线游戏服务器架构设计 由于大型多人在线游戏服务器理论上需要支持无限多的玩家，所以对服务器端是一个非常大的考验。服务器必须是安全的，可维护性高的，可伸缩性高的，可负载均衡的，支持高并发请求的。面对这些需求，我们在设计服务器的时候就需要慎重考虑，特别是架构的设计，如果前期设计不好，最后面临的很可能是重构。\n一款游戏服务器的架构都是慢慢从小变大的，不可能一下子就上来一个完善的服务器构架，目前流行的说法是游戏先上线，再扩展。所以说我们在做架构的时候，一定要把底层的基础组件做好，方便以后扩展，但是刚开始的时候留出一些接口，并不实现它，将来游戏业务的发展，再慢慢扩展。当然，如果前期设计的不好，后期业务扩展了，但架构没办法扩展，只能加班加点搞了。\n面对庞大的数据量我们想到的唯一个解决方案就是分而治之，即采用分布式的方式去解决它。把紧凑独立的功能单独拿出来做。分担到不同的物理服务器上面去运行。而且做到可以动态扩展。这就需要我们考虑好模块的划分，尽量要业务独立，关联性低。\n前期，由于游戏需要尽快上线，开发周期短，我们需要把服务尽快的跑起来，这个时候的目标应该是尽快完成测试版本开发，单台服务器支持的人数可以稍微低一些，但是当人数暴涨时，我们可以能过多开几组服务来支持新增涨的用户量，即可以平衡扩展就可以了。到后期我们再把具体的模块单独拿出来支持，比如前期逻辑服务器上包括:活动，关卡，背包，技能，好友管理等。后期我们可以把好友，背包管理或其它的单独做一个服务进程，部署在不同的物理服务器上面。我们先按分区的服务进行设计，后面在部署的时候可以部署为世界服务器，下面是一个前期的架构图，下面我们从每个服务器的功能说起：\n1，登陆管理服务 负责用户的登陆验证，如果有注册功能的话，也可以放在这里。一般手机游戏直接走sdk验证。网页游戏和客户端游戏会有注册功能，也可以叫用户管理服务。\n1.1 用户登陆验证 负责接收客户端的用户登陆请求，验证账号的合法性，是否在黑名单（被封号的用户），是否在白名单（一般是测试账号，服务未开启时也可以进入）。如果是sdk登陆，此服务向第三方服务发起回调请求。\n1.2 登陆安全加密 使用加密的传输协议，见通信协议部分。\n1.3 是否在白名单内 白名单是给内部测试人员使用的，在服务器未开启的状态下，白名单的用户可以提前进入游戏进行游戏测试。\n1.4 判断是否在黑名单 黑名单的用户是禁止登陆的，一般这是一些被封号的用户，拒绝登陆。\n1.5 登陆验证 服务器使用私钥解密密码，进行验证，如果是sdk登陆，则直接向第三方服务发起回调。\n1.6 登陆令牌（token）生成 当用户登陆验证成功之后，服务器端需要生成一个登陆令牌token,这个token具有时效性，当用户客户端拿到这个token之后，如果在一定时间内没有登陆游戏成功，那么这个token将失败，用户需要重新申请token,token存储在登陆服务这，向外提供用户是否已登陆的接口，其它服务器想验证如果是否登陆，就拿那个服务收到的token来此验证。\n1.7 显示用户角色信息 当用户登陆成功之后，显示最近登陆的角色信息。\n2，显示公告 用户登陆成功之后，请求公告服务器，获取最新的公告，公告服务先根据token和Userid验证用户是否已登陆，公告有可能根据渠道的不同，显示不同的公告。所以 公告一定是要可以根据渠道编辑的。\n3，选区服务 当用户登陆成功之后，请求服务器分区列表服务器，显示当前所有的大区列表。\n3.1 验证用户是否已登陆 向登陆服务器请求验证是否已登陆。\n3.2 大区列表显示 大区列表信息中只显示大区id和大区名称。这样做是为了安全考虑，不一次性把大区对应的网关ip和端口暴露出来，也可以减少网络的传输量。\n3.3 用户点击选择某个大区，客户端拿到大区id再向选区服务请求获取此大区对应的网关ip地址和端口。根据负载算法计算得出。\n3.4 网关的选择 选区服务会维护一份网关的配置列表。一个大区对应一到多个网关，当配置有多个网关时，需要定时检测各个网关是否连接正常，如果发现有网关连接不上，需要把大区对应的网关信息设置为无效，不再参与网关的分配，并发出报警。 一般对于网关的选择，可以使用用户id求余法加虚网关节点法。这样在网关节点数量固定的情况下，一个用户总是会被分配到同一个网关上面。但是如果只是使用求余法的话，可能会造成用户分布不均衡，这里可以通过增加网关的虚拟节点（其它就是增加某个网关的权重，让用户多来一些到这个网关上面），这个可以参考哈稀一致性算法。包括后面说到的一个网关对应多个逻辑服务器，也可以使用同样的方法。这部分可以抽象出来一个模块使用。\n3.5 选区服务对内要提供修改服务器状态的接口，比如维护中…\n4，登陆网关 4.1 建立连接 收到客户端的建立连接请求之后，记录此channel和对应的连接建立时间。并设置如果在一定时间内未收到登陆请求，则断开连接。返回给客户端登陆超时。\n4.2 登陆请求 收到登陆请求后，移除记录的channelid信息，向登陆服务器验证用户是否已登陆过,并向外广播用户角色登陆成功的消息。\n4.3 登陆成功后，接收网关的其它的消息\n4.4 客户端消息合法性验证 在向逻辑服务器转发消息之前验证消息的合法性，具体验证方法见协议安全验 证。\n4.5 将客户端消息转发送到对应的逻辑服务器。\n5 通信协议 5.1协议序列化和返回序列化 可以直接使用protobuf，直接对协议进行序列化和反序列化。\n5.2协议组成 5.2.1 包头构成 包总长度，加密字符串长度，加密字符串内容，userId,playerId,版本号，内包内容。 5.2.2 包体组成 请求的逻辑信息，是protobuf后对应的二进制数据。\n包总长度 加密内容 UserId playerId 请求序列id 版本号 内包内容 Int 64 Long Long Long int varchar 4 64 8 8 8 4 变长 5.3 协议内容加密 如果协议明文传输的话，被篡改的风险就非常大，所以我们要对传输协议进行加密传输，由于协议内容大小不固定，为了保证效率，采用对称加密算法，首先客户端使用AES的公钥对消息内容加密（上表中userid之后的信息），客户端把加密后的报文发送到服务器端。AES的公钥在用户第一次连接时获取。\n5.4 协议完整性验证 尽管我们对消息做了加密，但也不是万无一失的，为了进一步确保消息没有被篡改，我们需要对消息的完整性进行检测，使用数字摘要的方式，首先客户端对userid及之后的协议信息进行AES加密，加密之后取它的md5值，md5值用于验证数据的完整性。这个md5值会被传送到服务器，如果协议信息被修改了，那个md5就会不同。","title":"8 大型多人在线游戏服务器架构设计"},{"content":"9 百万用户级游戏服务器架构设计 服务器结构探讨 \u0026ndash; 最简单的结构 所谓服务器结构，也就是如何将服务器各部分合理地安排，以实现最初的功能需求。所以，结构本无所谓正确与错误；当然，优秀的结构更有助于系统的搭建，对系统的可扩展性及可维护性也有更大的帮助。\n好的结构不是一蹴而就的，而且每个设计者心中的那把尺都不相同，所以这个优秀结构的定义也就没有定论。在这里，我们不打算对现有游戏结构做评价，而是试着从头开始搭建一个我们需要的MMOG结构。\n对于一个最简单的游戏服务器来说，它只需要能够接受来自客户端的连接请求，然后处理客户端在游戏世界中的移动及交互，也即游戏逻辑处理即可。如果我们把这两项功能集成到一个服务进程中，则最终的结构很简单：\n嗯，太简单了点，这样也敢叫服务器结构？好吧，现在我们来往里面稍稍加点东西，让它看起来更像是服务器结构一些。\n一般来说，我们在接入游戏服务器的时候都会要提供一个帐号和密码，验证通过后才能进入。关于为什么要提供用户名和密码才能进入的问题我们这里不打算做过多讨论，云风曾对此也提出过类似的疑问，并给出了只用一个标识串就能进入的设想，有兴趣的可以去看看他们的讨论。但不管是采用何种方式进入，照目前看来我们的服务器起码得提供一个帐号验证的功能。\n我们把观察点先集中在一个大区内。在大多数情况下，一个大区内都会有多组游戏服，也就是多个游戏世界可供选择。简单点来实现，我们完全可以抛弃这个大区的概念，认为一个大区也就是放在同一个机房的多台服务器组，各服务器组间没有什么关系。这样，我们可为每组服务器单独配备一台登录服。最后的结构图应该像这样：\n该结构下的玩家操作流程为，先选择大区，再选择大区下的某台服务器，即某个游戏世界，点击进入后开始帐号验证过程，验证成功则进入了该游戏世界。但是，如果玩家想要切换游戏世界，他只能先退出当前游戏世界，然后进入新的游戏世界重新进行帐号验证。\n早期的游戏大都采用的是这种结构，有些游戏在实现时采用了一些技术手段使得在切换游戏服时不需要再次验证帐号，但整体结构还是未做改变。\n该结构存在一个服务器资源配置的问题。因为登录服处理的逻辑相对来说比较简单，就是将玩家提交的帐号和密码送到数据库进行验证，和生成会话密钥发送给游戏服和客户端，操作完成后连接就会立即断开，而且玩家在以后的游戏过程中不会再与登录服打任何交道。这样处理短连接的过程使得系统在大多数情况下都是比较空闲的，但是在某些时候，由于请求比较密集，比如开新服的时候，登录服的负载又会比较大，甚至会处理不过来。\n另外在实际的游戏运营中，有些游戏世界很火爆，而有些游戏世界却非常冷清，甚至没有多少人玩的情况也是很常见的。所以，我们能否更合理地配置登录服资源，使得整个大区内的登录服可以共享就成了下一步改进的目标。\n服务器结构探讨 \u0026ndash; 登录服的负载均衡 回想一下我们在玩wow时的操作流程：运行wow.exe进入游戏后，首先就会要求我们输入用户名和密码进行验证，验证成功后才会出来游戏世界列表，之后是排队进入游戏世界，开始游戏…\n可以看到跟前面的描述有个很明显的不同，那就是要先验证帐号再选择游戏世界。这种结构也就使得登录服不是固定配备给个游戏世界，而是全区共有的。\n我们可以试着从实际需求的角度来考虑一下这个问题。正如我们之前所描述过的那样，登录服在大多数情况下都是比较空闲的，也许我们的一个拥有20个游戏世界的大区仅仅使用10台或更少的登录服即可满足需求。而当在开新区的时候，或许要配备40台登录服才能应付那如潮水般涌入的玩家登录请求。所以，登录服在设计上应该能满足这种动态增删的需求，我们可以在任何时候为大区增加或减少登录服的部署。\n当然，在这里也不会存在要求添加太多登录服的情况。还是拿开新区的情况来说，即使新增加登录服满足了玩家登录的请求，游戏世界服的承载能力依然有限，玩家一样只能在排队系统中等待，或者是进入到游戏世界中导致大家都卡。\n另外，当我们在增加或移除登录服的时候不应该需要对游戏世界服有所改动，也不会要求重启世界服，当然也不应该要求客户端有什么更新或者修改，一切都是在背后自动完成。\n最后，有关数据持久化的问题也在这里考虑一下。一般来说，使用现有的商业数据库系统比自己手工技术先进要明智得多。我们需要持久化的数据有玩家的帐号及密码，玩家创建的角色相关信息，另外还有一些游戏世界全局共有数据也需要持久化。\n好了，需求已经提出来了，现在来考虑如何将其实现。\n对于负载均衡来说，已有了成熟的解决方案。一般最常用，也最简单部署的应该是基于DNS的负载均衡系统了，其通过在DNS中为一个域名配置多个IP地址来实现。最新的DNS服务已实现了根据服务器系统状态来实现的动态负载均衡，也就是实现了真正意义上的负载均衡，这样也就有效地解决了当某台登录服当机后，DNS服务器不能立即做出反应的问题。当然，如果找不到这样的解决方案，自己从头打造一个也并不难。而且，通过DNS来实现的负载均衡已经包含了所做的修改对登录服及客户端的透明。\n而对于数据库的应用，在这种结构下，登录服及游戏世界服都会需要连接数据库。从数据库服务器的部署上来说，可以将帐号和角色数据都放在一个中心数据库中，也可分为两个不同的库分别来处理，基到从物理上分到两台不同的服务器上去也行。\n但是对于不同的游戏世界来说，其角色及游戏内数据都是互相独立的，所以一般情况下也就为每个游戏世界单独配备一台数据库服务器，以减轻数据库的压力。所以，整体的服务器结构应该是一个大区有一台帐号数据库服务器，所有的登录服都连接到这里。而每个游戏世界都有自己的游戏数据库服务器，只允许本游戏世界内的服务器连接。\n最后，我们的服务器结构就像这样：\n这里既然讨论到了大区及帐号数据库，所以顺带也说一下关于激活大区的概念。wow中一共有八个大区，我们想要进入某个大区游戏之前，必须到官网上激活这个区，这是为什么呢？\n一般来说，在各个大区帐号数据库之上还有一个总的帐号数据库，我们可以称它为中心数据库。比如我们在官网上注册了一个帐号，这时帐号数据是只保存在中心数据库上的。而当我们要到一区去创建角色开始游戏的时候，在一区的帐号数据库中并没有我们的帐号数据，所以，我们必须先到官网上做一次激活操作。这个激活的过程也就是从中心库上把我们的帐号数据拷贝到所要到的大区帐号数据库中。\n服务器结构探讨 \u0026ndash; 简单的世界服实现 讨论了这么久我们一直都还没有进入游戏世界服务器内部，现在就让我们来窥探一下里面的结构吧。\n对于现在大多数MMORPG来说，游戏服务器要处理的基本逻辑有移动、聊天、技能、物品、任务和生物等，另外还有地图管理与消息广播来对其他高级功能做支撑。如纵队、好友、公会、战场和副本等，这些都是通过基本逻辑功能组合或扩展而成。\n在所有这些基础逻辑中，与我们要讨论的服务器结构关系最紧密的当属地图管理方式。决定了地图的管理方式也就决定了我们的服务器结构，我们仍然先从最简单的实现方式开始说起。\n回想一下我们曾战斗过无数个夜晚的暗黑破坏神，整个暗黑的世界被分为了若干个独立的小地图，当我们在地图间穿越时，一般都要经过一个叫做传送门的装置。世界中有些地图间虽然在地理上是直接相连的，但我们发现其游戏内部的逻辑却是完全隔离的。可以这样认为，一块地图就是一个独立的数据处理单元。\n既然如此，我们就把每块地图都当作是一台独立的服务器，他提供了在这块地图上游戏时的所有逻辑功能，至于内部结构如何划分我们暂不理会，先把他当作一个黑盒子吧。\n当两个人合作做一件事时，我们可以以对等的关系相互协商着来做，而且一般也都不会有什么问题。当人数增加到三个时，我们对等的合作关系可能会有些复杂，因为我们每个人都同时要与另两个人合作协商。正如俗语所说的那样，三个和尚可能会碰到没水喝的情况。当人数继续增加，情况就变得不那么简单了，我们得需要一个管理者来对我们的工作进行分工、协调。游戏的地图服务器之间也是这么回事。\n一般来说，我们的游戏世界不可能会只有一块或者两块小地图，那顺理成章的，也就需要一个地图管理者。先称它为游戏世界的中心服务器吧，毕竟是管理者嘛，大家都以它为中心。\n中心服务器主要维护一张地图ID到地图服务器地址的映射表。当我们要进入某张地图时，会从中心服上取得该地图的IP和port告诉客户端，客户端主动去连接，这样进入他想要去的游戏地图。在整个游戏过程中，客户端始终只会与一台地图服务器保持连接，当要切换地图的时候，在获取到新地图的地址后，会先与当前地图断开连接，再进入新的地图，这样保证玩家数据在服务器上只有一份。\n我们来看看结构图是怎样的：\n很简单，不是吗。但是简单并不表示功能上会有什么损失，简单也更不能表示游戏不能赚钱。早期不少游戏也确实采用的就是这种简单结构。\n服务器结构探讨 \u0026ndash; 继续世界服 都已经看出来了，这种每切换一次地图就要重新连接服务器的方式实在是不够优雅，而且在实际游戏运营中也发现，地图切换导致的卡号，复制装备等问题非常多，这里完全就是一个事故多发地段，如何避免这种频繁的连接操作呢？\n最直接的方法就是把那个图倒转过来就行了。客户端只需要连接到中心服上，所有到地图服务器的数据都由中心服来转发。很完美的解决方案，不是吗？\n这种结构在实际的部署中也遇到了一些挑战。对于一般的MMORPG服务器来说，单台服务器的承载量平均在2000左右，如果你的服务器很不幸地只能带1000人，没关系，不少游戏都是如此；如果你的服务器上跑了3000多玩家依然比较流畅，那你可以自豪地告诉你的策划，多设计些大量消耗服务器资源的玩法吧，比如大型国战、公会战争等。\n2000人，似乎我们的策划朋友们不大愿意接受这个数字。我们将地图服务器分开来原来也是想将负载分开，以多带些客户端，现在要所有的连接都从中心服上转发，那连接数又遇到单台服务器的可最大承载量的瓶颈了。\n这里有必要再解释下这个数字。我知道，有人一定会说，才带2000人，那是你水平不行，我随便写个TCP服务器都可带个五六千连接。问题恰恰在于你是随便写的，而MMORPG的服务器是复杂设计的。如果一个演示socket API用的echo服务器就能满足MMOG服务器的需求，那写服务器该是件多么惬意的事啊。\n但我们所遇到的事实是，服务器收到一个移动包后，要向周围所有人广播，而不是echo服务器那样简单的回应；服务器在收到一个连接断开通知时要向很多人通知玩家退出事件，并将该玩家的资料写入数据库，而不是echo服务器那样什么都不需要做；服务器在收到一个物品使用请求包后要做一系列的逻辑判断以检查玩家有没有作弊；服务器上还启动着很多定时器用来更新游戏世界的各种状态……\n其实这么一比较，我们也看出资源消耗的所在了：服务器上大量的复杂的逻辑处理。再回过头来看看我们想要实现的结构，我们既想要有一个唯一的入口，使得客户端不用频繁改变连接，又希望这个唯一入口的负载不会太大，以致于接受不了多少连接。\n仔细看一看这个需求，我们想要的仅仅只是一台管理连接的服务器，并不打算让他承担太多的游戏逻辑。既然如此，那五六千个连接也还有满足我们的要求。至少在现在来说，一个游戏世界内，也就是一组服务器内同时有五六千个在线的玩家还是件让人很兴奋的事。事实上，在大多数游戏的大部分时间里，这个数字也是很让人眼红的。\n什么？你说梦幻、魔兽还有史先生的那个什么征途远不止这么点人了！噢，我说的是大多数，是大多数，不包括那些明星。你知道大陆现在有多少游戏在运营吗？或许你又该说，我们不该在一开始就把自己的目标定的太低！好吧，我们还是先不谈这个。\n继续我们的结构讨论。一般来说，我们把这台负责连接管理的服务器称为网关服务器，因为内部的数据都要通过这个网关才能出去，不过从这台服务器提供的功能来看，称其为反向代理服务器可能更合适。我们也不在这个名字上纠缠了，就按大家通用的叫法，还是称他为网关服务器吧。\n网关之后的结构我们依然可以采用之前描述的方案，只是，似乎并没有必要为每一个地图都开一个独立的监听端口了。我们可以试着对地图进行一些划分，由一个Master Server来管理一些更小的Zone Server，玩家通过网关连接到Master Server上，而实际与地图有关的逻辑是分派给更小的Zone Server去处理。\n最后的结构看起来大概是这样的：\n服务器结构探讨 \u0026ndash; 最终的结构 如果我们就此打住，可能马上就会有人要嗤之以鼻了，就这点古董级的技术也敢出来现。好吧，我们还是把之前留下的问题拿出来解决掉吧。\n一般来说，当某一部分能力达不到我们的要求时，最简单的解决方法就是在此多投入一点资源。既然想要更多的连接数，那就再加一台网关服务器吧。新增加了网关服后需要在大区服上做相应的支持，或者再简单点，有一台主要的网关服，当其负载较高时，主动将新到达的连接重定向到其他网关服上。\n而对于游戏服来说，有一台还是多台网关服是没有什么区别的。每个代表客户端玩家的对象内部都保留一个代表其连接的对象，消息广播时要求每个玩家对象使用自己的连接对象发送数据即可，至于连接是在什么地方，那是完全透明的。当然，这只是一种简单的实现，也是普通使用的一种方案，如果后期想对消息广播做一些优化的话，那可能才需要多考虑一下。\n既然说到了优化，我们也稍稍考虑一下现在结构下可能采用的优化方案。\n首先是当前的Zone Server要做的事情太多了，以至于他都处理不了多少连接。这其中最消耗系统资源的当属生物的AI处理了，尤其是那些复杂的寻路算法，所以我们可以考虑把这部分AI逻辑独立出来，由一台单独的AI服务器来承担。\n然后，我们可以试着把一些与地图数据无关的公共逻辑放到Master Server上去实现，这样Zone Server上只保留了与地图数据紧密相关的逻辑，如生物管理，玩家移动和状态更新等。\n还有聊天处理逻辑，这部分与游戏逻辑没有任何关联，我们也完全可以将其独立出来，放到一台单独的聊天服务器上去实现。\n最后是数据库了，为了减轻数据库的压力，提高数据请求的响应速度，我们可以在数据库之前建立一个数据库缓存服务器，将一些常用数据缓存在此，服务器与数据库的通信都要通过这台服务器进行代理。缓存的数据会定时的写入到后台数据库中。\n好了，做完这些优化我们的服务器结构大体也就定的差不多了，暂且也不再继续深入，更细化的内容等到各个部分实现的时候再探讨。\n好比我们去看一场晚会， 舞台上演员们按着预定的节目单有序地上演着，但这就是整场晚会的全部吗？显然不止，在幕后还有太多太多的人在忙碌着，甚至在晚会前和晚会后都有。我们的游戏服务器也如此。\n在之前描述的部分就如同舞台上的演员，是我们能直接看到的，幕后的工作人员我们也来认识一下。\n现实中有警察来维护秩序，游戏中也如此，这就是我们常说的GM。GM可以采用跟普通玩家一样的拉入方式来进入游戏，当然权限会比普通玩家高一些，也可以提供一台GM服务器专门用来处理GM命令，这样可以有更高的安全性，GM服一般接在中心服务器上。\n在以时间收费的游戏中，我们还需要一台计费的服务器，这台服务器一般接在网关服务器上，注册玩家登录和退出事件以记录玩家的游戏时间。\n任何为用户提供服务的地方都会有日志记录，游戏服务器当然也不例外。从记录玩家登录的时间，地址，机器信息到游戏过程中的每一项操作都可以作为日志记录下来，以备查错及数据挖掘用。至于搜集玩家机器资料所涉及到的法律问题不是我们该考虑的。\n差不多就这么多了吧，接下来我们会按照这个大致的结构来详细讨论各部分的实现。\n服务器结构探讨 —— 一点杂谈 再强调一下，服务器结构本无所谓好坏，只有是否适合自己。我们在前面探讨了一些在现在的游戏中见到过的结构，并尽我所知地分析了各自存在的一些问题和可以做的一些改进，希望其中没有谬误，如果能给大家也带来些启发那自然更好。\n突然发现自己一旦罗嗦起来还真是没完没了。接下来先说说我在开发中遇到过的一些困惑和一基础问题探讨吧，这些问题可能有人与我一样，也曾遇到过，或者正在被困扰中，而所要探讨的这些基础问题向来也是争论比较多的，我们也不评价其中的好与坏，只做简单的描述。\n首先是服务器操作系统，linux与windows之争随处可见，其实在大多数情况下这不是我们所能决定的，似乎各大公司也基本都有了自己的传统，如网易的freebsd，腾讯的linux等。如果真有权利去选择的话，选自己最熟悉的吧。\n决定了OS也就基本上确定了网络IO模型，windows上的IOCP和linux下的epool，或者直接使用现有的网络框架，如ACE和asio等，其他还有些商业的网络库在国内的使用好像没有见到，不符合中国国情嘛。:)\n然后是网络协议的选择，以前的选择大多倾向于UDP，为了可靠传输一般自己都会在上面实现一层封装，而现在更普通的是直接采用本身就很可靠的TCP，或者TCP与UDP的混用。早期选择UDP的主要原因还是带宽限制，现在宽带普通的情况下TCP比UDP多出来的一点点开销与开发的便利性相比已经不算什么了。当然，如果已有了成熟的可靠UDP库，那也可以继续使用着。\n还有消息包格式的定义，这个曾在云风的blog上展开过激烈的争论。消息包格式定义包括三段，包长、消息码和包体，争论的焦点在于应该是消息码在前还是包长在前，我们也把这个当作是信仰问题吧，有兴趣的去云风的blog上看看，论论。\n另外早期有些游戏的包格式定义是以特殊字符作分隔的，这样一个好处是其中某个包出现错误后我们的游戏还能继续。但实际上，我觉得这是完全没有必要的，真要出现这样的错误，直接断开这个客户端的连接可能更安全。而且，以特殊字符做分隔的消息包定义还加大了一点点网络数据量。\n最后是一个纯技术问题，有关socket连接数的最大限制。开始学习网络编程的时候我犯过这样的错误，以为port的定义为unsigned short，所以想当然的认为服务器的最大连接数为65535，这会是一个硬性的限制。而实际上，一个socket描述符在windows上的定义是unsigned int，因此要有限制那也是四十多亿，放心好了。\n在服务器上port是监听用的，想象这样一种情况，web server在80端口上监听，当一个连接到来时，系统会为这个连接分配一个socket句柄，同时与其在80端口上进行通讯；当另一个连接到来时，服务器仍然在80端口与之通信，只是分配的socket句柄不一样。这个socket句柄才是描述每个连接的唯一标识。按windows网络编程第二版上的说法，这个上限值配置影响。\n好了，废话说完了，我们开始进入登录服的设计吧。\n登录服的设计 \u0026ndash; 功能需求 正如我们在前面曾讨论过的，登录服要实现的功能相当简单，就是帐号验证。为了便于描述，我们暂不引入那些讨论过的优化手段，先以最简单的方式实现，另外也将基本以mangos的代码作为参考来进行描述。\n想象一下帐号验证的实现方法，最容易的那就是把用户输入的明文用帐号和密码直接发给登录服，服务器根据帐号从数据库中取出密码，与用户输入的密码相比较。\n这个方法存在的安全隐患实在太大，明文的密码传输太容易被截获了。那我们试着在传输之前先加一下密，为了服务器能进行密码比较，我们应该采用一个可逆的加密算法，在服务器端把这个加密后的字串还原为原始的明文密码，然后与数据库密码进行比较。既然是一个可逆的过程，那外挂制作者总有办法知道我们的加密过程，所以，这个方法仍不够安全。\n哦，如果我们只是希望密码不可能被还原出来，那还不容易吗，使用一个不可逆的散列算法就行了。用户在登录时发送给服务器的是明文的帐号和经散列后的不可逆密码串，服务器取出密码后也用同样的算法进行散列后再进行比较。比如，我们就用使用最广泛的md5算法吧。噢，不要管那个王小云的什么论文，如果我真有那么好的运气，早中500w了，还用在这考虑该死的服务器设计吗？\n似乎是一个很完美的方案，外挂制作者再也偷不到我们的密码了。慢着，外挂偷密码的目的是什么？是为了能用我们的帐号进游戏！如果我们总是用一种固定的算法来对密码做散列，那外挂只需要记住这个散列后的字串就行了，用这个做密码就可以成功登录。\n嗯，这个问题好解决，我们不要用固定的算法进行散列就是了。只是，问题在于服务器与客户端采用的散列算法得出的字串必须是相同的，或者是可验证其是否匹配的。很幸运的是，伟大的数学字们早就为我们准备好了很多优秀的这类算法，而且经理论和实践都证明他们也确实是足够安全的。\n这其中之一是一个叫做SRP的算法，全称叫做Secure Remote Password，即安全远程密码。wow使用的是第6版，也就是SRP6算法。有关其中的数学证明，如果有人能向我解释清楚，并能让我真正弄明白的话，我将非常感激。不过其代码实现步骤倒是并不复杂，mangos中的代码也还算清晰，我们也不再赘述。\n登录服除了帐号验证外还得提供另一项功能，就是在玩家的帐号验证成功后返回给他一个服务器列表让他去选择。这个列表的状态要定时刷新，可能有新的游戏世界开放了，也可能有些游戏世界非常不幸地停止运转了，这些状态的变化都要尽可能及时地让玩家知道。不管发生了什么事，用户都有权利知道，特别是对于付过费的用户来说，我们不该藏着掖着，不是吗？\n这个游戏世界列表的功能将由大区服来提供，具体的结构我们在之前也描述过，这里暂不做讨论。登录服将从大区服上获取到的游戏世界列表发给已验证通过的客户端即可。好了，登录服要实现的功能就这些，很简单，是吧。\n确实是太简单了，不过简单的结构正好更适合我们来看一看游戏服务器内部的模块结构，以及一些服务器共有组件的实现方法。这就留作下一篇吧。\n服务器公共组件实现 \u0026ndash; mangos的游戏主循环 当阅读一项工程的源码时，我们大概会选择从main函数开始，而当开始一项新的工程时，第一个写下的函数大多也是main。那我们就先来看看，游戏服务器代码实现中，main函数都做了些什么。\n由于我在读技术文章时最不喜看到的就是大段大段的代码，特别是那些直接Ctrl+C再Ctrl+V后未做任何修改的代码，用句时髦的话说，一点技术含量都没有！所以在我们今后所要讨论的内容中，尽量会避免出现直接的代码，在有些地方确实需要代码来表述时，也将会选择使用伪码。\n先从mangos的登录服代码开始。mangos的登录服是一个单线程的结构，虽然在数据库连接中可以开启一个独立的线程，但这个线程也只是对无返回结果的执行类SQL做缓冲，而对需要有返回结果的查询类SQL还是在主逻辑线程中阻塞调用的。\n登录服中唯一的这一个线程，也就是主循环线程对监听的socket做select操作，为每个连接进来的客户端读取其上的数据并立即进行处理，直到服务器收到SIGABRT或SIGBREAK信号时结束。\n所以，mangos登录服主循环的逻辑，也包括后面游戏服的逻辑，主循环的关键代码其实是在SocketHandler中，也就是那个Select函数中。检查所有的连接，对新到来的连接调用OnAccept方法，有数据到来的连接则调用OnRead方法，然后socket处理器自己定义对接收到的数据如何处理。\n很简单的结构，也比较容易理解。\n只是，在对性能要求比较高的服务器上，select一般不会是最好的选择。如果我们使用windows平台，那IOCP将是首选；如果是linux，epool将是不二选择。我们也不打算讨论基于IOCP或是基于epool的服务器实现，如果仅仅只是要实现服务器功能，很简单的几个API调用即可，而且网上已有很多好的教程；如果是要做一个成熟的网络服务器产品，不是我几篇简单的技术介绍文章所能达到。\n另外，在服务器实现上，网络IO与逻辑处理一般会放在不同的线程中，以免耗时较长的IO过程阻塞住了需要立即反应的游戏逻辑。\n数据库的处理也类似，会使用异步的方式，也是避免耗时的查询过程将游戏服务器主循环阻塞住。想象一下，因某个玩家上线而发起的一次数据库查询操作导致服务器内所有在线玩家都卡住不动将是多么恐怖的一件事！\n另外还有一些如事件、脚本、消息队列、状态机、日志和异常处理等公共组件，我们也会在接下来的时间里进行探讨。\n服务器公共组件实现 \u0026ndash; 继续来说主循环 前面我们只简单了解了下mangos登录服的程序结构，也发现了一些不足之处，现在我们就来看看如何提供一个更好的方案。\n正如我们曾讨论过的，为了游戏主逻辑循环的流畅运行，所有比较耗时的IO操作都会分享到单独的线程中去做，如网络IO，数据库IO和日志IO等。当然，也有把这些分享到单独的进程中去做的。\n另外对于大多数服务器程序来说，在运行时都是作为精灵进程或服务进程的，所以我们并不需要服务器能够处理控制台用户输入，我们所要处理的数据来源都来自网络。\n这样，主逻辑循环所要做的就是不停要取消息包来处理，当然这些消息包不仅有来自客户端的玩家操作数据包，也有来自GM服务器的管理命令，还包括来自数据库查询线程的返回结果消息包。这个循环将一直持续，直到收到一个通知服务器关闭的消息包。\n主逻辑循环的结构还是很简单的，复杂的部分都在如何处理这些消息包的逻辑上。我们可以用一段简单的伪码来描述这个循环过程：\nwhile (Message* msg = getMessage()) { if (msg为服务器关闭消息) break; 处理msg消息; } 这里就有一个问题需要探讨了，在getMessage()的时候，我们应该去哪里取消息？前面我们考虑过，至少会有三个消息来源，而我们还讨论过，这些消息源的IO操作都是在独立的线程中进行的，我们这里的主线程不应该直接去那几处消息源进行阻塞式的IO操作。\n很简单，让那些独立的IO线程在接收完数据后自己送过来就是了。好比是，我这里提供了一个仓库，有很多的供货商，他们有货要给我的时候只需要交到仓库，然后我再到仓库去取就是了，这个仓库也就是消息队列。消息队列是一个普通的队列实现，当然必须要提供多线程互斥访问的安全性支持，其基本的接口定义大概类似这样：\nIMessageQueue { void putMessage(Message*); Message* getMessage(); } 网络IO，数据库IO线程把整理好的消息包都加入到主逻辑循环线程的这个消息队列中便返回。有关消息队列的实现和线程间消息的传递在ACE中有比较完全的代码实现及描述，还有一些使用示例，是个很好的参考。\n这样的话，我们的主循环就很清晰了，从主线程的消息队列中取消息，处理消息，再取下一条消息……\n服务器公共组件实现 \u0026ndash; 消息队列 既然说到了消息队列，那我们继续来稍微多聊一点吧。\n我们所能想到的最简单的消息队列可能就是使用stl的****list来实现了，即消息队列内部维护一个list和一个互斥锁，putMessage时将message加入到队列尾，getMessage时从队列头取一个message返回，同时在getMessage和putMessage之前都要求先获取锁资源。\n实现虽然简单，但功能是绝对满足需求的，只是性能上可能稍稍有些不尽如人意。其最大的问题在频繁的锁竞争上。\n对于如何减少锁竞争次数的优化方案，Ghost Cheng提出了一种。提供一个队列容器，里面有多个队列，每个队列都可固定存放一定数量的消息。网络IO线程要给逻辑线程投递消息时，会从队列容器中取一个空队列来使用，直到将该队列填满后再放回容器中换另一个空队列。而逻辑线程取消息时是从队列容器中取一个有消息的队列来读取，处理完后清空队列再放回到容器中。\n这样便使得只有在对队列容器进行操作时才需要加锁，而IO线程和逻辑线程在操作自己当前使用的队列时都不需要加锁，所以锁竞争的机会大大减少了。\n这里为每个队列设了个最大消息数，看来好像是打算只有当IO线程写满队列时才会将其放回到容器中换另一个队列。那这样有时也会出现IO线程未写满一个队列，而逻辑线程又没有数据可处理的情况，特别是当数据量很少时可能会很容易出现。Ghost Cheng在他的描述中没有讲到如何解决这种问题，但我们可以先来看看另一个方案。\n这个方案与上一个方案基本类似，只是不再提供队列容器，因为在这个方案中只使用了两个队列，arthur在他的一封邮件中描述了这个方案的实现及部分代码。两个队列，一个给逻辑线程读，一个给IO线程用来写，当逻辑线程读完队列后会将自己的队列与IO线程的队列相调换。所以，这种方案下加锁的次数会比较多一些，IO线程每次写队列时都要加锁，逻辑线程在调换队列时也需要加锁，但逻辑线程在读队列时是不需要加锁的。\n虽然看起来锁的调用次数是比前一种方案要多很多，但实际上大部分锁调用都是不会引起阻塞的，只有在逻辑线程调换队列的那一瞬间可能会使得某个线程阻塞一下。另外对于锁调用过程本身来说，其开销是完全可以忽略的，我们所不能忍受的仅仅是因为锁调用而引起的阻塞而已。\n两种方案都是很优秀的优化方案，但也都是有其适用范围的。Ghost Cheng的方案因为提供了多个队列，可以使得多个IO线程可以总工程师的，互不干扰的使用自己的队列，只是还有一个遗留问题我们还不了解其解决方法。arthur的方案很好的解决了上一个方案遗留的问题，但因为只有一个写队列，所以当想要提供多个IO线程时，线程间互斥地写入数据可能会增大竞争的机会，当然，如果只有一个IO线程那将是非常完美的。\n服务器公共组件实现 \u0026ndash; 环形缓冲区 消息队列锁调用太频繁的问题算是解决了，另一个让人有些苦恼的大概是这太多的内存分配和释放操作了。频繁的内存分配不但增加了系统开销，更使得内存碎片不断增多，非常不利于我们的服务器长期稳定运行。也许我们可以使用内存池，比如SGI STL中附带的小内存分配器。但是对于这种按照严格的先进先出顺序处理的，块大小并不算小的，而且块大小也并不统一的内存分配情况来说，更多使用的是一种叫做环形缓冲区的方案，mangos的网络代码中也有这么一个东西，其原理也是比较简单的。\n就好比两个人围着一张圆形的桌子在追逐，跑的人被网络IO线程所控制，当写入数据时，这个人就往前跑；追的人就是逻辑线程，会一直往前追直到追上跑的人。如果追上了怎么办？那就是没有数据可读了，先等会儿呗，等跑的人向前跑几步了再追，总不能让游戏没得玩了吧。那要是追的人跑的太慢，跑的人转了一圈过来反追上追的人了呢？那您也先歇会儿吧。要是一直这么反着追，估计您就只能换一个跑的更快的追逐者了，要不这游戏还真没法玩下去。\n前面我们特别强调了，按照严格的先进先出顺序进行处理，这是环形缓冲区的使用必须遵守的一项要求。也就是，大家都得遵守规定，追的人不能从桌子上跨过去，跑的人当然也不允许反过来跑。至于为什么，不需要多做解释了吧。\n环形缓冲区是一项很好的技术，不用频繁的分配内存，而且在大多数情况下，内存的反复使用也使得我们能用更少的内存块做更多的事。\n在网络IO线程中，我们会为每一个连接都准备一个环形缓冲区，用于临时存放接收到的数据，以应付半包及粘包的情况。在解包及解密完成后，我们会将这个数据包复制到逻辑线程消息队列中，如果我们只使用一个队列，那这里也将会是个环形缓冲区，IO线程往里写，逻辑线程在后面读，互相追逐。可要是我们使用了前面介绍的优化方案后，可能这里便不再需要环形缓冲区了，至少我们并不再需要他们是环形的了。因为我们对同一个队列不再会出现同时读和写的情况，每个队列在写满后交给逻辑线程去读，逻辑线程读完后清空队列再交给IO线程去写，一段固定大小的缓冲区即可。没关系，这么好的技术，在别的地方一定也会用到的。\n服务器公共组件实现 \u0026ndash; 发包的方式 前面一直都在说接收数据时的处理方法，我们应该用专门的IO线程，接收到完整的消息包后加入到主线程的消息队列，但是主线程如何发送数据还没有探讨过。\n一般来说最直接的方法就是逻辑线程什么时候想发数据了就直接调用相关的socket API发送，这要求服务器的玩家对象中保存其连接的socket句柄。但是直接send调用有时候有会存在一些问题，比如遇到系统的发送缓冲区满而阻塞住的情况，或者只发送了一部分数据的情况也时有发生。我们可以将要发送的数据先缓存一下，这样遇到未发送完的，在逻辑线程的下一次处理时可以接着再发送。\n考虑数据缓存的话，那这里这可以有两种实现方式了，一是为每个玩家准备一个缓冲区，另外就是只有一个全局的缓冲区，要发送的数据加入到全局缓冲区的时候同时要指明这个数据是发到哪个socket的。如果使用全局缓冲区的话，那我们可以再进一步，使用一个独立的线程来处理数据发送，类似于逻辑线程对数据的处理方式，这个独立发送线程也维护一个消息队列，逻辑线程要发数据时也只是把数据加入到这个队列中，发送线程循环取包来执行send调用，这时的阻塞也就不会对逻辑线程有任何影响了。\n采用第二种方式还可以附带一个优化方案。一般对于广播消息而言，发送给周围玩家的数据都是完全相同的，我们如果采用给每个玩家一个缓冲队列的方式，这个数据包将需要拷贝多份，而采用一个全局发送队列时，我们只需要把这个消息入队一次，同时指明该消息包是要发送给哪些socket的即可。有关该优化的说明在云风描述其连接服务器实现的blog文章中也有讲到，有兴趣的可以去阅读一下。\n服务器公共组件实现 \u0026ndash; 状态机 有关State模式的设计意图及实现就不从设计模式中摘抄了，我们只来看看游戏服务器编程中如何使用State设计模式。\n首先还是从mangos的代码开始看起，我们注意到登录服在处理客户端发来的消息时用到了这样一个结构体：\nstruct AuthHandler { eAuthCmd cmd; uint32 status; bool (AuthSocket::*handler)(void); }; 该结构体定义了每个消息码的处理函数及需要的状态标识，只有当前状态满足要求时才会调用指定的处理函数，否则这个消息码的出现是不合法的。这个status状态标识的定义是一个宏，有两种有效的标识，STATUS_CONNECTED和STATUS_AUTHED，也就是未认证通过和已认证通过。而这个状态标识的改变是在运行时进行的，确切的说是在收到某个消息并正确处理完后改变的。\n我们再来看看设计模式中对State模式的说明，其中关于State模式适用情况里有一条，当操作中含有庞大的多分支的条件语句，且这些分支依赖于该对象的状态，这个状态通常用一个或多个枚举变量表示。\n描述的情况与我们这里所要处理的情况是如此的相似，也许我们可以试一试。那再看看State模式提供的解决方案是怎样的，State模式将每一个条件分支放入一个独立的类中。\n由于这里的两个状态标识只区分出了两种状态，所以，我们仅需要两个独立的类，用以表示两种状态即可。然后，按照State模式的描述，我们还需要一个Context类，也就是状态机管理类，用以管理当前的状态类。稍作整理，大概的代码会类似这样：\n状态基类接口：\nStateBase { void Enter() = 0; void Leave() = 0; void Process(Message* msg) = 0; }; 状态机基类接口：\nMachineBase { void ChangeState(StateBase* state) = 0; StateBase* m_curState; }; 我们的逻辑处理类会从MachineBase派生，当取出数据包后交给当前状态处理，前面描述的两个状态类从StateBase派生，每个状态类只处理该状态标识下需要处理的消息。当要进行状态转换时，调用MachineBase的ChangeState()方法，显示地告诉状态机管理类自己要转到哪一个状态。所以，状态类内部需要保存状态机管理类的指针，这个可以在状态类初始化时传入。具体的实现细节就不做过多描述了。\n使用状态机虽然避免了复杂的判断语句，但也引入了新的麻烦。当我们在进行状态转换时，可能会需要将一些现场数据从老状态对象转移到新状态对象，这需要在定义接口时做一下考虑。如果不希望执行拷贝，那么这里公有的现场数据也可放到状态机类中，只是这样在使用时可能就不那么优雅了。 正如同在设计模式中所描述的，所有的模式都是已有问题的另一种解决方案，也就是说这并不是唯一的解决方案。放到我们今天讨论的State模式中，就拿登录服所处理的两个状态来说，也许用mangos所采用的遍历处理函数的方法可能更简单，但当系统中的状态数量增多，状态标识也变多的时候，State模式就显得尤其重要了。\n比如在游戏服务器上玩家的状态管理，还有在实现NPC人工智能时的各种状态管理，这些就留作以后的专题吧。\n服务器公共组件 \u0026ndash; 事件与信号 关于这一节，这几天已经打了好几遍草稿，总觉得说不清楚，也不好组织这些内容，但是打铁要趁热，为避免热情消退，先整理一点东西放这，好继续下面的主题，以后如果有机会再回来完善吧。本节内容欠考虑，希望大家多给点意见。\n有些类似于QT中的event与signal，我将一些动作请求消息定义为事件，而将状态改变消息定义为信号。比如在QT应用程序中，用户的一次鼠标点击会产生一个鼠标点击事件加入到事件队列中，当处理此事件时可能会导致某个按钮控件产生一个clicked()信号。\n对应到我们的服务器上的一个例子，玩家登录时会发给服务器一个请求登录的数据包，服务器可将其当作一个用户登录事件，该事件处理完后可能会产生一个用户已登录信号。\n这样，与QT类似，对于事件我们可以重定义其处理方法，甚至过滤掉某些事件使其不被处理，但对于信号我们只是收到了一个通知，有些类似于Observe模式中的观察者，当收到更新通知时，我们只能更新自己的状态，对刚刚发生的事件我不已不能做任何影响。\n仔细来看，事件与信号其实并无多大差别，从我们对其需求上来说，都只要能注册事件或信号响应函数，在事件或信号产生时能够被通知到即可。但有一项区别在于，事件处理函数的返回值是有意义的，我们要根据这个返回值来确定是否还要继续事件的处理，比如在QT中，事件处理函数如果返回true，则这个事件处理已完成，QApplication会接着处理下一个事件，而如果返回false，那么事件分派函数会继续向上寻找下一个可以处理该事件的注册方法。信号处理函数的返回值对信号分派器来说是无意义的。\n简单点说，就是我们可以为事件定义过滤器，使得事件可以被过滤。这一功能需求在游戏服务器上是到处存在的。\n关于事件和信号机制的实现，网络上的开源训也比较多，比如FastDelegate，sigslot，boost::signal等，其中sigslot还被Google采用，在libjingle的代码中我们可以看到他是如何被使用的。\n在实现事件和信号机制时或许可以考虑用同一套实现，在前面我们就分析过，两者唯一的区别仅在于返回值的处理上。\n另外还有一个需要我们关注的问题是事件和信号处理时的优先级问题。在QT中，事件因为都是与窗口相关的，所以事件回调时都是从当前窗口开始，一级一级向上派发，直到有一个窗口返回true，截断了事件的处理为止。对于信号的处理则比较简单，默认是没有顺序的，如果需要明确的顺序，可以在信号注册时显示地指明槽的位置。\n在我们的需求中，因为没有窗口的概念，事件的处理也与信号类似，对注册过的处理器要按某个顺序依次回调，所以优先级的设置功能是需要的。\n最后需要我们考虑的是事件和信号的处理方式。在QT中，事件使用了一个事件队列来维护，如果事件的处理中又产生了新的事件，那么新的事件会加入到队列尾，直到当前事件处理完毕后，QApplication再去队列头取下一个事件来处理。而信号的处理方式有些不同，信号处理是立即回调的，也就是一个信号产生后，他上面所注册的所有槽都会立即被回调。这样就会产生一个递归调用的问题，比如某个信号处理器中又产生了一个信号，会使得信号的处理像一棵树一样的展开。我们需要注意的一个很重要的问题是会不会引起循环调用。\n关于事件机制的考虑其实还很多，但都是一些不成熟的想法。在上面的文字中就同时出现了消息、事件和信号三个相近的概念，而在实际处理中，经常发现三者不知道如何界定的情况，实际的情况比我在这里描述的要混乱的多。\n这里也就当是挖下一个坑，希望能够有所交流。\n再谈登录服的实现\n离我们的登录服实现已经太远了，先拉回来一下。\n关于登录服、大区服及游戏世界服的结构之前已做过探讨，这里再把各自的职责和关系列一下。\n其中DNSServer负责带负载均衡的域名解析服务，返回LoginServer的IP地址给客户端。WorldServerMgr维护当前大区内的世界服列表，LoginServer会从这里取世界列表发给客户端。LoginServer处理玩家的登录及世界服选择请求。GateWay/WorldServer为各个独立的世界服或者通过网关连接到后面的世界服。\n在mangos的代码中，我们注意到登录服是从数据库中取的世界列表，而在wow官方服务器中，我们却会注意到，这个世界服列表并不是一开始就固定，而是动态生成的。当每周一次的维护完成之后，我们可以很明显的看到这个列表生成的过程。刚开始时，世界列表是空的，慢慢的，世界服会一个个加入进来，而这里如果有世界服当机，他会显示为离线，不会从列表中删除。但是当下一次服务器再维护后，所有的世界服都不存在了，全部重新开始添加。\n从上面的过程描述中，我们很容易想到利用一个临时的列表来保存世界服信息，这也是我们增加WorldServerMgr服务器的目的所在。GateWay/WorldServer在启动时会自动向WorldServerMgr注册自己，这样就把自己所代表的游戏世界添加到世界列表中了。类似的，如果DNSServer也可以让LoginServer自己去注册，这样在临时LoginServer时就不需要去改动DNSServer的配置文件了。\nWorldServerMgr内部的实现很简单，监听一个固定的端口，接受来自WorldServer的主动连接，并检测其状态。这里可以用一个心跳包来实现其状态的检测，如果WorldServer的连接断开或者在规定时间内未收到心跳包，则将其状态更新为离线。另外WorldServerMgr还处理来自LoginServer的列表请求。由于世界列表并不常变化，所以LoginServer没有必要每次发送世界列表时都到WorldServerMgr上去取，LoginServer完全可以自己维护一个列表，当WorldServerMgr上的列表发生变化时，WorldServerMgr会主动通知所有的LoginServer也更新一下自己的列表。这个或许就可以用前面描述过的事件方式，或者就是观察者模式了。\nWorldServerMgr实现所要考虑的内容就这些，我们再来看看LoginServer，这才是我们今天要重点讨论的对象。\n前面探讨一些服务器公共组件，那我们这里也应该试用一下，不能只是停留在理论上。先从状态机开始，前面也说过了，登录服上的连接会有两种状态，一是帐号密码验证状态，一是服务器列表选择状态，其实还有另外一个状态我们未曾讨论过，因为它与我们的登录过程并无多大关系，这就是升级包发送状态。三个状态的转换流程大致为：\n这个版本检查的和决定下一个状态的过程是在LogonState中进行的，下一个状态的选择是由当前状态来决定。密码验证的过程使用了SRP6协议，具体过程就不多做描述，每个游戏使用的方式也都不大一样。而版本检查的过程就更无值得探讨的东西，一个if-else即可。\n升级状态其实就是文件传输过程，文件发送完毕后通知客户端开始执行升级文件并关闭连接。世界选择状态则提供了一个列表给客户端，其中包括了所有游戏世界网关服务器的IP、PORT和当前负载情况。如果客户端一直连接着，则该状态会以每5秒一次的频率不停刷新列表给客户端，当然是否值得这样做还是有待商榷。\n整个过程似乎都没有值得探讨的内容，但是，还没有完。当客户端选择了一个世界之后该怎么办？wow的做法是，当客户端选择一个游戏世界时，客户端 会主动去连接该世界服的IP和PORT，然后进入这个游戏世界。与此同时，与登录服的连接还没有断开，直到客户端确实连接上了选定的世界服并且走完了排队过程为止。这是一个很必要的设计，保证了我们在因意外情况连接不上世界服或者发现世界服正在排队而想换另外一个试试时不会需要重新进行密码验证。\n但是我们所要关注的还不是这些，而是客户端去连接游戏世界的网关服时服务器该如何识别我们。打个比方，有个不自觉的玩家不遵守游戏规则，没有去验证帐号密码就直接跑去连接世界服了，就如同一个不自觉的乘客没有换登机牌就直接跑到登机口一样。这时，乘务员会客气地告诉你要先换登机牌，那登机牌又从哪来？检票口换的，人家会先验明你的身份，确认后才会发给你登机牌。一样的处理过程，我们的登录服在验明客户端身份后，也会发给客户端一个登机牌，这个登机牌还有一个学名，叫做session key。\n客户端拿着这个session key去世界服网关处就可正确登录了吗？似乎还是有个疑问，他怎么知道我这个key是不是造假的？没办法，中国的假货太多，我们不得不到处都考虑假货的问题。方法很简单，去找给他登机牌的那个检票员问一下，这张牌是不是他发的不就得了。可是，那么多的LoginServer，要一个个问下来，这效率也太低了，后面排的长队一定会开始叫唤了。那么，LoginServer将这个key存到数据库中，让网关服自己去数据库验证？似乎也是个可行的方案。\n如果觉得这样给数据库带来了太大的压力的话，也可以考虑类似WorldServerMgr的做法，用一个临时的列表来保存，甚至可以将这个列表就保存到WorldServerMgr上，他正好是全区唯一的。这两种方案的本质并无差别，只是看你愿意将负载放在哪里。而不管在哪里，这个查询的压力都是有点大的，想想，全区所有玩家呢。所以，我们也可以试着考虑一种新的方案，一种不需要去全区唯一一个入口查询的方案。\n那我们将这些session key分开存储不就得了。一个可行的方案是，让任意时刻只有一个地方保存一个客户端的session key，这个地方可能是客户端当前正连接着的服务器，也可以是它正要去连接的服务器。让我们来详细描述一下这个过程，客户端在LoginServer上验证通过时，LoginServer为其生成了本次会话的session key，但只是保存在当前的LoginServer上，不会存数据库，也不会发送给WorldServerMgr。如果客户端这时想要去某个游戏世界，那么他必须先通知当前连接的LoginServer要去的服务器地址，LoginServer将session key安全转移给目标服务器，转移的意思是要确保目标服务器收到了session key，本地保存的要删除掉。转移成功后LoginServer通知客户端再去连接目标服务器，这时目标服务器在验证session key合法性的时候就不需要去别处查询了，只在本地保存的session key列表中查询即可。\n当然了，为了session key的安全，所有的服务器在收到一个新的session key后都会为其设一个有效期，在有效期过后还没来认证的，则该session key会被自动删除。同时，所有服务器上的session key在连接关闭后一定会被删除，保证一个session key真正只为一次连接会话服务。\n但是，很显然的，wow并没有采用这种方案，因为客户端在选择世界服时并没有向服务器发送要求确认的消息。wow中的session key应该是保存在一个类似于WorldServerMgr的地方，或者如mangos一样，就是保存在了数据库中。不管是怎样一种方式，了解了其过程，代码实现都是比较简单的，我们就不再赘述了。\n文章转载自：\nhttps://blog.csdn.net/GoOnDrift/article/details/18843483\nhttps://blog.csdn.net/erlib/article/details/8936990\n","permalink":"https://haokiu.com/blog/db5f58a948804f718159e858bf744da9/","summary":"9 百万用户级游戏服务器架构设计 服务器结构探讨 \u0026ndash; 最简单的结构 所谓服务器结构，也就是如何将服务器各部分合理地安排，以实现最初的功能需求。所以，结构本无所谓正确与错误；当然，优秀的结构更有助于系统的搭建，对系统的可扩展性及可维护性也有更大的帮助。\n好的结构不是一蹴而就的，而且每个设计者心中的那把尺都不相同，所以这个优秀结构的定义也就没有定论。在这里，我们不打算对现有游戏结构做评价，而是试着从头开始搭建一个我们需要的MMOG结构。\n对于一个最简单的游戏服务器来说，它只需要能够接受来自客户端的连接请求，然后处理客户端在游戏世界中的移动及交互，也即游戏逻辑处理即可。如果我们把这两项功能集成到一个服务进程中，则最终的结构很简单：\n嗯，太简单了点，这样也敢叫服务器结构？好吧，现在我们来往里面稍稍加点东西，让它看起来更像是服务器结构一些。\n一般来说，我们在接入游戏服务器的时候都会要提供一个帐号和密码，验证通过后才能进入。关于为什么要提供用户名和密码才能进入的问题我们这里不打算做过多讨论，云风曾对此也提出过类似的疑问，并给出了只用一个标识串就能进入的设想，有兴趣的可以去看看他们的讨论。但不管是采用何种方式进入，照目前看来我们的服务器起码得提供一个帐号验证的功能。\n我们把观察点先集中在一个大区内。在大多数情况下，一个大区内都会有多组游戏服，也就是多个游戏世界可供选择。简单点来实现，我们完全可以抛弃这个大区的概念，认为一个大区也就是放在同一个机房的多台服务器组，各服务器组间没有什么关系。这样，我们可为每组服务器单独配备一台登录服。最后的结构图应该像这样：\n该结构下的玩家操作流程为，先选择大区，再选择大区下的某台服务器，即某个游戏世界，点击进入后开始帐号验证过程，验证成功则进入了该游戏世界。但是，如果玩家想要切换游戏世界，他只能先退出当前游戏世界，然后进入新的游戏世界重新进行帐号验证。\n早期的游戏大都采用的是这种结构，有些游戏在实现时采用了一些技术手段使得在切换游戏服时不需要再次验证帐号，但整体结构还是未做改变。\n该结构存在一个服务器资源配置的问题。因为登录服处理的逻辑相对来说比较简单，就是将玩家提交的帐号和密码送到数据库进行验证，和生成会话密钥发送给游戏服和客户端，操作完成后连接就会立即断开，而且玩家在以后的游戏过程中不会再与登录服打任何交道。这样处理短连接的过程使得系统在大多数情况下都是比较空闲的，但是在某些时候，由于请求比较密集，比如开新服的时候，登录服的负载又会比较大，甚至会处理不过来。\n另外在实际的游戏运营中，有些游戏世界很火爆，而有些游戏世界却非常冷清，甚至没有多少人玩的情况也是很常见的。所以，我们能否更合理地配置登录服资源，使得整个大区内的登录服可以共享就成了下一步改进的目标。\n服务器结构探讨 \u0026ndash; 登录服的负载均衡 回想一下我们在玩wow时的操作流程：运行wow.exe进入游戏后，首先就会要求我们输入用户名和密码进行验证，验证成功后才会出来游戏世界列表，之后是排队进入游戏世界，开始游戏…\n可以看到跟前面的描述有个很明显的不同，那就是要先验证帐号再选择游戏世界。这种结构也就使得登录服不是固定配备给个游戏世界，而是全区共有的。\n我们可以试着从实际需求的角度来考虑一下这个问题。正如我们之前所描述过的那样，登录服在大多数情况下都是比较空闲的，也许我们的一个拥有20个游戏世界的大区仅仅使用10台或更少的登录服即可满足需求。而当在开新区的时候，或许要配备40台登录服才能应付那如潮水般涌入的玩家登录请求。所以，登录服在设计上应该能满足这种动态增删的需求，我们可以在任何时候为大区增加或减少登录服的部署。\n当然，在这里也不会存在要求添加太多登录服的情况。还是拿开新区的情况来说，即使新增加登录服满足了玩家登录的请求，游戏世界服的承载能力依然有限，玩家一样只能在排队系统中等待，或者是进入到游戏世界中导致大家都卡。\n另外，当我们在增加或移除登录服的时候不应该需要对游戏世界服有所改动，也不会要求重启世界服，当然也不应该要求客户端有什么更新或者修改，一切都是在背后自动完成。\n最后，有关数据持久化的问题也在这里考虑一下。一般来说，使用现有的商业数据库系统比自己手工技术先进要明智得多。我们需要持久化的数据有玩家的帐号及密码，玩家创建的角色相关信息，另外还有一些游戏世界全局共有数据也需要持久化。\n好了，需求已经提出来了，现在来考虑如何将其实现。\n对于负载均衡来说，已有了成熟的解决方案。一般最常用，也最简单部署的应该是基于DNS的负载均衡系统了，其通过在DNS中为一个域名配置多个IP地址来实现。最新的DNS服务已实现了根据服务器系统状态来实现的动态负载均衡，也就是实现了真正意义上的负载均衡，这样也就有效地解决了当某台登录服当机后，DNS服务器不能立即做出反应的问题。当然，如果找不到这样的解决方案，自己从头打造一个也并不难。而且，通过DNS来实现的负载均衡已经包含了所做的修改对登录服及客户端的透明。\n而对于数据库的应用，在这种结构下，登录服及游戏世界服都会需要连接数据库。从数据库服务器的部署上来说，可以将帐号和角色数据都放在一个中心数据库中，也可分为两个不同的库分别来处理，基到从物理上分到两台不同的服务器上去也行。\n但是对于不同的游戏世界来说，其角色及游戏内数据都是互相独立的，所以一般情况下也就为每个游戏世界单独配备一台数据库服务器，以减轻数据库的压力。所以，整体的服务器结构应该是一个大区有一台帐号数据库服务器，所有的登录服都连接到这里。而每个游戏世界都有自己的游戏数据库服务器，只允许本游戏世界内的服务器连接。\n最后，我们的服务器结构就像这样：\n这里既然讨论到了大区及帐号数据库，所以顺带也说一下关于激活大区的概念。wow中一共有八个大区，我们想要进入某个大区游戏之前，必须到官网上激活这个区，这是为什么呢？\n一般来说，在各个大区帐号数据库之上还有一个总的帐号数据库，我们可以称它为中心数据库。比如我们在官网上注册了一个帐号，这时帐号数据是只保存在中心数据库上的。而当我们要到一区去创建角色开始游戏的时候，在一区的帐号数据库中并没有我们的帐号数据，所以，我们必须先到官网上做一次激活操作。这个激活的过程也就是从中心库上把我们的帐号数据拷贝到所要到的大区帐号数据库中。\n服务器结构探讨 \u0026ndash; 简单的世界服实现 讨论了这么久我们一直都还没有进入游戏世界服务器内部，现在就让我们来窥探一下里面的结构吧。\n对于现在大多数MMORPG来说，游戏服务器要处理的基本逻辑有移动、聊天、技能、物品、任务和生物等，另外还有地图管理与消息广播来对其他高级功能做支撑。如纵队、好友、公会、战场和副本等，这些都是通过基本逻辑功能组合或扩展而成。\n在所有这些基础逻辑中，与我们要讨论的服务器结构关系最紧密的当属地图管理方式。决定了地图的管理方式也就决定了我们的服务器结构，我们仍然先从最简单的实现方式开始说起。\n回想一下我们曾战斗过无数个夜晚的暗黑破坏神，整个暗黑的世界被分为了若干个独立的小地图，当我们在地图间穿越时，一般都要经过一个叫做传送门的装置。世界中有些地图间虽然在地理上是直接相连的，但我们发现其游戏内部的逻辑却是完全隔离的。可以这样认为，一块地图就是一个独立的数据处理单元。\n既然如此，我们就把每块地图都当作是一台独立的服务器，他提供了在这块地图上游戏时的所有逻辑功能，至于内部结构如何划分我们暂不理会，先把他当作一个黑盒子吧。\n当两个人合作做一件事时，我们可以以对等的关系相互协商着来做，而且一般也都不会有什么问题。当人数增加到三个时，我们对等的合作关系可能会有些复杂，因为我们每个人都同时要与另两个人合作协商。正如俗语所说的那样，三个和尚可能会碰到没水喝的情况。当人数继续增加，情况就变得不那么简单了，我们得需要一个管理者来对我们的工作进行分工、协调。游戏的地图服务器之间也是这么回事。\n一般来说，我们的游戏世界不可能会只有一块或者两块小地图，那顺理成章的，也就需要一个地图管理者。先称它为游戏世界的中心服务器吧，毕竟是管理者嘛，大家都以它为中心。\n中心服务器主要维护一张地图ID到地图服务器地址的映射表。当我们要进入某张地图时，会从中心服上取得该地图的IP和port告诉客户端，客户端主动去连接，这样进入他想要去的游戏地图。在整个游戏过程中，客户端始终只会与一台地图服务器保持连接，当要切换地图的时候，在获取到新地图的地址后，会先与当前地图断开连接，再进入新的地图，这样保证玩家数据在服务器上只有一份。\n我们来看看结构图是怎样的：\n很简单，不是吗。但是简单并不表示功能上会有什么损失，简单也更不能表示游戏不能赚钱。早期不少游戏也确实采用的就是这种简单结构。\n服务器结构探讨 \u0026ndash; 继续世界服 都已经看出来了，这种每切换一次地图就要重新连接服务器的方式实在是不够优雅，而且在实际游戏运营中也发现，地图切换导致的卡号，复制装备等问题非常多，这里完全就是一个事故多发地段，如何避免这种频繁的连接操作呢？\n最直接的方法就是把那个图倒转过来就行了。客户端只需要连接到中心服上，所有到地图服务器的数据都由中心服来转发。很完美的解决方案，不是吗？\n这种结构在实际的部署中也遇到了一些挑战。对于一般的MMORPG服务器来说，单台服务器的承载量平均在2000左右，如果你的服务器很不幸地只能带1000人，没关系，不少游戏都是如此；如果你的服务器上跑了3000多玩家依然比较流畅，那你可以自豪地告诉你的策划，多设计些大量消耗服务器资源的玩法吧，比如大型国战、公会战争等。\n2000人，似乎我们的策划朋友们不大愿意接受这个数字。我们将地图服务器分开来原来也是想将负载分开，以多带些客户端，现在要所有的连接都从中心服上转发，那连接数又遇到单台服务器的可最大承载量的瓶颈了。\n这里有必要再解释下这个数字。我知道，有人一定会说，才带2000人，那是你水平不行，我随便写个TCP服务器都可带个五六千连接。问题恰恰在于你是随便写的，而MMORPG的服务器是复杂设计的。如果一个演示socket API用的echo服务器就能满足MMOG服务器的需求，那写服务器该是件多么惬意的事啊。\n但我们所遇到的事实是，服务器收到一个移动包后，要向周围所有人广播，而不是echo服务器那样简单的回应；服务器在收到一个连接断开通知时要向很多人通知玩家退出事件，并将该玩家的资料写入数据库，而不是echo服务器那样什么都不需要做；服务器在收到一个物品使用请求包后要做一系列的逻辑判断以检查玩家有没有作弊；服务器上还启动着很多定时器用来更新游戏世界的各种状态……\n其实这么一比较，我们也看出资源消耗的所在了：服务器上大量的复杂的逻辑处理。再回过头来看看我们想要实现的结构，我们既想要有一个唯一的入口，使得客户端不用频繁改变连接，又希望这个唯一入口的负载不会太大，以致于接受不了多少连接。\n仔细看一看这个需求，我们想要的仅仅只是一台管理连接的服务器，并不打算让他承担太多的游戏逻辑。既然如此，那五六千个连接也还有满足我们的要求。至少在现在来说，一个游戏世界内，也就是一组服务器内同时有五六千个在线的玩家还是件让人很兴奋的事。事实上，在大多数游戏的大部分时间里，这个数字也是很让人眼红的。\n什么？你说梦幻、魔兽还有史先生的那个什么征途远不止这么点人了！噢，我说的是大多数，是大多数，不包括那些明星。你知道大陆现在有多少游戏在运营吗？或许你又该说，我们不该在一开始就把自己的目标定的太低！好吧，我们还是先不谈这个。\n继续我们的结构讨论。一般来说，我们把这台负责连接管理的服务器称为网关服务器，因为内部的数据都要通过这个网关才能出去，不过从这台服务器提供的功能来看，称其为反向代理服务器可能更合适。我们也不在这个名字上纠缠了，就按大家通用的叫法，还是称他为网关服务器吧。\n网关之后的结构我们依然可以采用之前描述的方案，只是，似乎并没有必要为每一个地图都开一个独立的监听端口了。我们可以试着对地图进行一些划分，由一个Master Server来管理一些更小的Zone Server，玩家通过网关连接到Master Server上，而实际与地图有关的逻辑是分派给更小的Zone Server去处理。\n最后的结构看起来大概是这样的：\n服务器结构探讨 \u0026ndash; 最终的结构 如果我们就此打住，可能马上就会有人要嗤之以鼻了，就这点古董级的技术也敢出来现。好吧，我们还是把之前留下的问题拿出来解决掉吧。\n一般来说，当某一部分能力达不到我们的要求时，最简单的解决方法就是在此多投入一点资源。既然想要更多的连接数，那就再加一台网关服务器吧。新增加了网关服后需要在大区服上做相应的支持，或者再简单点，有一台主要的网关服，当其负载较高时，主动将新到达的连接重定向到其他网关服上。\n而对于游戏服来说，有一台还是多台网关服是没有什么区别的。每个代表客户端玩家的对象内部都保留一个代表其连接的对象，消息广播时要求每个玩家对象使用自己的连接对象发送数据即可，至于连接是在什么地方，那是完全透明的。当然，这只是一种简单的实现，也是普通使用的一种方案，如果后期想对消息广播做一些优化的话，那可能才需要多考虑一下。\n既然说到了优化，我们也稍稍考虑一下现在结构下可能采用的优化方案。\n首先是当前的Zone Server要做的事情太多了，以至于他都处理不了多少连接。这其中最消耗系统资源的当属生物的AI处理了，尤其是那些复杂的寻路算法，所以我们可以考虑把这部分AI逻辑独立出来，由一台单独的AI服务器来承担。\n然后，我们可以试着把一些与地图数据无关的公共逻辑放到Master Server上去实现，这样Zone Server上只保留了与地图数据紧密相关的逻辑，如生物管理，玩家移动和状态更新等。\n还有聊天处理逻辑，这部分与游戏逻辑没有任何关联，我们也完全可以将其独立出来，放到一台单独的聊天服务器上去实现。\n最后是数据库了，为了减轻数据库的压力，提高数据请求的响应速度，我们可以在数据库之前建立一个数据库缓存服务器，将一些常用数据缓存在此，服务器与数据库的通信都要通过这台服务器进行代理。缓存的数据会定时的写入到后台数据库中。\n好了，做完这些优化我们的服务器结构大体也就定的差不多了，暂且也不再继续深入，更细化的内容等到各个部分实现的时候再探讨。\n好比我们去看一场晚会， 舞台上演员们按着预定的节目单有序地上演着，但这就是整场晚会的全部吗？显然不止，在幕后还有太多太多的人在忙碌着，甚至在晚会前和晚会后都有。我们的游戏服务器也如此。\n在之前描述的部分就如同舞台上的演员，是我们能直接看到的，幕后的工作人员我们也来认识一下。\n现实中有警察来维护秩序，游戏中也如此，这就是我们常说的GM。GM可以采用跟普通玩家一样的拉入方式来进入游戏，当然权限会比普通玩家高一些，也可以提供一台GM服务器专门用来处理GM命令，这样可以有更高的安全性，GM服一般接在中心服务器上。\n在以时间收费的游戏中，我们还需要一台计费的服务器，这台服务器一般接在网关服务器上，注册玩家登录和退出事件以记录玩家的游戏时间。\n任何为用户提供服务的地方都会有日志记录，游戏服务器当然也不例外。从记录玩家登录的时间，地址，机器信息到游戏过程中的每一项操作都可以作为日志记录下来，以备查错及数据挖掘用。至于搜集玩家机器资料所涉及到的法律问题不是我们该考虑的。\n差不多就这么多了吧，接下来我们会按照这个大致的结构来详细讨论各部分的实现。\n服务器结构探讨 —— 一点杂谈 再强调一下，服务器结构本无所谓好坏，只有是否适合自己。我们在前面探讨了一些在现在的游戏中见到过的结构，并尽我所知地分析了各自存在的一些问题和可以做的一些改进，希望其中没有谬误，如果能给大家也带来些启发那自然更好。\n突然发现自己一旦罗嗦起来还真是没完没了。接下来先说说我在开发中遇到过的一些困惑和一基础问题探讨吧，这些问题可能有人与我一样，也曾遇到过，或者正在被困扰中，而所要探讨的这些基础问题向来也是争论比较多的，我们也不评价其中的好与坏，只做简单的描述。\n首先是服务器操作系统，linux与windows之争随处可见，其实在大多数情况下这不是我们所能决定的，似乎各大公司也基本都有了自己的传统，如网易的freebsd，腾讯的linux等。如果真有权利去选择的话，选自己最熟悉的吧。\n决定了OS也就基本上确定了网络IO模型，windows上的IOCP和linux下的epool，或者直接使用现有的网络框架，如ACE和asio等，其他还有些商业的网络库在国内的使用好像没有见到，不符合中国国情嘛。:)\n然后是网络协议的选择，以前的选择大多倾向于UDP，为了可靠传输一般自己都会在上面实现一层封装，而现在更普通的是直接采用本身就很可靠的TCP，或者TCP与UDP的混用。早期选择UDP的主要原因还是带宽限制，现在宽带普通的情况下TCP比UDP多出来的一点点开销与开发的便利性相比已经不算什么了。当然，如果已有了成熟的可靠UDP库，那也可以继续使用着。\n还有消息包格式的定义，这个曾在云风的blog上展开过激烈的争论。消息包格式定义包括三段，包长、消息码和包体，争论的焦点在于应该是消息码在前还是包长在前，我们也把这个当作是信仰问题吧，有兴趣的去云风的blog上看看，论论。\n另外早期有些游戏的包格式定义是以特殊字符作分隔的，这样一个好处是其中某个包出现错误后我们的游戏还能继续。但实际上，我觉得这是完全没有必要的，真要出现这样的错误，直接断开这个客户端的连接可能更安全。而且，以特殊字符做分隔的消息包定义还加大了一点点网络数据量。\n最后是一个纯技术问题，有关socket连接数的最大限制。开始学习网络编程的时候我犯过这样的错误，以为port的定义为unsigned short，所以想当然的认为服务器的最大连接数为65535，这会是一个硬性的限制。而实际上，一个socket描述符在windows上的定义是unsigned int，因此要有限制那也是四十多亿，放心好了。\n在服务器上port是监听用的，想象这样一种情况，web server在80端口上监听，当一个连接到来时，系统会为这个连接分配一个socket句柄，同时与其在80端口上进行通讯；当另一个连接到来时，服务器仍然在80端口与之通信，只是分配的socket句柄不一样。这个socket句柄才是描述每个连接的唯一标识。按windows网络编程第二版上的说法，这个上限值配置影响。","title":"9 百万用户级游戏服务器架构设计"},{"content":"bind 函数重难点解析 bind 函数如何选择绑定地址 bind 函数的基本用法如下：\nstruct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); bindaddr.sin_port = htons(3000); if (bind(listenfd, (struct sockaddr *)\u0026amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;bind listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } 其中 bind 的地址我们使用了一个宏叫 INADDR_ANY ，关于这个宏的解释如下：\nIf an application does not care what local address is assigned, specify the constant value INADDR_ANY for an IPv4 local address or the constant value in6addr_any for an IPv6 local address in the sa_data member of the name parameter. This allows the underlying service provider to use any appropriate network address, potentially simplifying application programming in the presence of multihomed hosts (that is, hosts that have more than one network interface and address). 意译一下：\n如果应用程序不关心bind绑定的ip地址，可以使用INADDR_ANY(如果是IPv6， 则对应in6addr_any)，这样底层的（协议栈）服务会自动选择一个合适的ip地址， 这样使在一个有多个网卡机器上选择ip地址问题变得简单。 也就是说 INADDR_ANY 相当于地址 0.0.0.0。可能读者还是不太明白我想表达什么。这里我举个例子，假设我们在一台机器上开发一个服务器程序，使用 bind 函数时，我们有多个ip 地址可以选择。首先，这台机器对外访问的ip地址是120.55.94.78，这台机器在当前局域网的地址是192.168.1.104；同时这台机器有本地回环地址127.0.0.1。\n如果你指向本机上可以访问，那么你 bind 函数中的地址就可以使用127.0.0.1; 如果你的服务只想被局域网内部机器访问，bind 函数的地址可以使用192.168.1.104；如果 希望这个服务可以被公网访问，你就可以使用地址0.0.0.0或 INADDR_ANY。\nbind 函数端口号问题 网络通信程序的基本逻辑是客户端连接服务器，即从客户端的地址:端口连接到服务器地址:端口上，以 4.2 小节中的示例程序为例，服务器端的端口号使用 3000，那客户端连接时的端口号是多少呢？TCP 通信双方中一般服务器端端口号是固定的，而客户端端口号是连接发起时由操作系统随机分配的（不会分配已经被占用的端口）。端口号是一个 C short 类型的值，其范围是0～65535，知道这点很重要，所以我们在编写压力测试程序时，由于端口数量的限制，在某台机器上网卡地址不变的情况下压力测试程序理论上最多只能发起六万五千多个连接。注意我说的是理论上，在实际情况下，由于当时的操作系统很多端口可能已经被占用，实际可以使用的端口比这个更少，例如，一般规定端口号在1024以下的端口是保留端口，不建议用户程序使用。而对于 Windows 系统，MSDN 甚至明确地说：\nOn Windows Vista and later, the dynamic client port range is a value between 49152 and 65535. This is a change from Windows Server 2003 and earlier where the dynamic client port range was a value between 1025 and 5000. Vista 及以后的Windows，可用的动态端口范围是49152～65535，而 Windows Server及更早的系统，可以的动态端口范围是1025~5000。（你可以通过修改注册表来改变这一设置，参考网址：https://docs.microsoft.com/en-us/windows/desktop/api/winsock/nf-winsock-bind）\n如果将 bind 函数中的端口号设置成0，那么操作系统会随机给程序分配一个可用的侦听端口，当然服务器程序一般不会这么做，因为服务器程序是要对外服务的，必须让客户端知道确切的ip地址和端口号。\n很多人觉得只有服务器程序可以调用 bind 函数绑定一个端口号，其实不然，在一些特殊的应用中，我们需要客户端程序以指定的端口号去连接服务器，此时我们就可以在客户端程序中调用 bind 函数绑定一个具体的端口。\n我们用代码来实际验证一下上路所说的，为了能看到连接状态，我们将客户端和服务器关闭socket的代码注释掉，这样连接会保持一段时间。\n情形一：客户端代码不绑定端口 修改后的服务器代码如下：\n/** * TCP服务器通信基本流程 * zhangyl 2018.12.13 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;vector\u0026gt; int main(int argc, char* argv[]) { //1.创建一个侦听socket int listenfd = socket(AF_INET, SOCK_STREAM, 0); if (listenfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //2.初始化服务器地址 struct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); bindaddr.sin_port = htons(3000); if (bind(listenfd, (struct sockaddr *)\u0026amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;bind listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //3.启动侦听 if (listen(listenfd, SOMAXCONN) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;listen error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //记录所有客户端连接的容器 std::vector\u0026lt;int\u0026gt; clientfds; while (true) { struct sockaddr_in clientaddr; socklen_t clientaddrlen = sizeof(clientaddr); //4. 接受客户端连接 int clientfd = accept(listenfd, (struct sockaddr *)\u0026amp;clientaddr, \u0026amp;clientaddrlen); if (clientfd != -1) { char recvBuf[32] = {0}; //5. 从客户端接受数据 int ret = recv(clientfd, recvBuf, 32, 0); if (ret \u0026gt; 0) { std::cout \u0026lt;\u0026lt; \u0026#34;recv data from client, data: \u0026#34; \u0026lt;\u0026lt; recvBuf \u0026lt;\u0026lt; std::endl; //6. 将收到的数据原封不动地发给客户端 ret = send(clientfd, recvBuf, strlen(recvBuf), 0); if (ret != strlen(recvBuf)) std::cout \u0026lt;\u0026lt; \u0026#34;send data error.\u0026#34; \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;send data to client successfully, data: \u0026#34; \u0026lt;\u0026lt; recvBuf \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;recv data error.\u0026#34; \u0026lt;\u0026lt; std::endl; } //close(clientfd); clientfds.push_back(clientfd); } } //7.关闭侦听socket close(listenfd); return 0; } 修改后的客户端代码如下：\n/** * TCP客户端通信基本流程 * zhangyl 2018.12.13 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 #define SEND_DATA \u0026#34;helloworld\u0026#34; int main(int argc, char* argv[]) { //1.创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //2.连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); if (connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;connect socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //3. 向服务器发送数据 int ret = send(clientfd, SEND_DATA, strlen(SEND_DATA), 0); if (ret != strlen(SEND_DATA)) { std::cout \u0026lt;\u0026lt; \u0026#34;send data error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } std::cout \u0026lt;\u0026lt; \u0026#34;send data successfully, data: \u0026#34; \u0026lt;\u0026lt; SEND_DATA \u0026lt;\u0026lt; std::endl; //4. 从客户端收取数据 char recvBuf[32] = {0}; ret = recv(clientfd, recvBuf, 32, 0); if (ret \u0026gt; 0) { std::cout \u0026lt;\u0026lt; \u0026#34;recv data successfully, data: \u0026#34; \u0026lt;\u0026lt; recvBuf \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;recv data error, data: \u0026#34; \u0026lt;\u0026lt; recvBuf \u0026lt;\u0026lt; std::endl; } //5. 关闭socket //close(clientfd); //这里仅仅是为了让客户端程序不退出 while (true) { sleep(3); } return 0; } 将程序编译好后（编译方法和上文一样），我们先启动server，再启动三个客户端。然后通过 lsof 命令查看当前机器上的 TCP 连接信息，为了更清楚地显示结果，已经将不相关的连接信息去掉了，结果如下所示：\n[root@localhost ~]# lsof -i -Pn COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME server 1445 root 3u IPv4 21568 0t0 TCP *:3000 (LISTEN) server 1445 root 4u IPv4 21569 0t0 TCP 127.0.0.1:3000-\u0026gt;127.0.0.1:40818 (ESTABLISHED) server 1445 root 5u IPv4 21570 0t0 TCP 127.0.0.1:3000-\u0026gt;127.0.0.1:40820 (ESTABLISHED) server 1445 root 6u IPv4 21038 0t0 TCP 127.0.0.1:3000-\u0026gt;127.0.0.1:40822 (ESTABLISHED) client 1447 root 3u IPv4 21037 0t0 TCP 127.0.0.1:40818-\u0026gt;127.0.0.1:3000 (ESTABLISHED) client 1448 root 3u IPv4 21571 0t0 TCP 127.0.0.1:40820-\u0026gt;127.0.0.1:3000 (ESTABLISHED) client 1449 root 3u IPv4 21572 0t0 TCP 127.0.0.1:40822-\u0026gt;127.0.0.1:3000 (ESTABLISHED) 上面的结果显示，server 进程（进程 ID 是 1445）在 3000 端口开启侦听，有三个 client 进程（进程 ID 分别是1447、1448、1449）分别通过端口号 40818、40820、40822 连到 server 进程上的，作为客户端的一方，端口号是系统随机分配的。\n情形二：客户端绑定端口号 0\n服务器端代码保持不变，我们修改下客户端代码：\n/** * TCP服务器通信基本流程 * zhangyl 2018.12.13 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 #define SEND_DATA \u0026#34;helloworld\u0026#34; int main(int argc, char* argv[]) { //1.创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } struct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); //将socket绑定到0号端口上去 bindaddr.sin_port = htons(0); if (bind(clientfd, (struct sockaddr *)\u0026amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;bind socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //2.连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); if (connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;connect socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //3. 向服务器发送数据 int ret = send(clientfd, SEND_DATA, strlen(SEND_DATA), 0); if (ret != strlen(SEND_DATA)) { std::cout \u0026lt;\u0026lt; \u0026#34;send data error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } std::cout \u0026lt;\u0026lt; \u0026#34;send data successfully, data: \u0026#34; \u0026lt;\u0026lt; SEND_DATA \u0026lt;\u0026lt; std::endl; //4. 从客户端收取数据 char recvBuf[32] = {0}; ret = recv(clientfd, recvBuf, 32, 0); if (ret \u0026gt; 0) { std::cout \u0026lt;\u0026lt; \u0026#34;recv data successfully, data: \u0026#34; \u0026lt;\u0026lt; recvBuf \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;recv data error, data: \u0026#34; \u0026lt;\u0026lt; recvBuf \u0026lt;\u0026lt; std::endl; } //5. 关闭socket //close(clientfd); //这里仅仅是为了让客户端程序不退出 while (true) { sleep(3); } return 0; } 我们再次编译客户端程序，并启动三个 client 进程，然后用 lsof 命令查看机器上的 TCP 连接情况，结果如下所示：\n[root@localhost ~]# lsof -i -Pn COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME server 1593 root 3u IPv4 21807 0t0 TCP *:3000 (LISTEN) server 1593 root 4u IPv4 21808 0t0 TCP 127.0.0.1:3000-\u0026gt;127.0.0.1:44220 (ESTABLISHED) server 1593 root 5u IPv4 19311 0t0 TCP 127.0.0.1:3000-\u0026gt;127.0.0.1:38990 (ESTABLISHED) server 1593 root 6u IPv4 21234 0t0 TCP 127.0.0.1:3000-\u0026gt;127.0.0.1:42365 (ESTABLISHED) client 1595 root 3u IPv4 22626 0t0 TCP 127.0.0.1:44220-\u0026gt;127.0.0.1:3000 (ESTABLISHED) client 1611 root 3u IPv4 21835 0t0 TCP 127.0.0.1:38990-\u0026gt;127.0.0.1:3000 (ESTABLISHED) client 1627 root 3u IPv4 21239 0t0 TCP 127.0.0.1:42365-\u0026gt;127.0.0.1:3000 (ESTABLISHED) 通过上面的结果，我们发现三个 client 进程使用的端口号仍然是系统随机分配的，也就是说绑定 0 号端口和没有绑定效果是一样的。\n情形三：客户端绑定一个固定端口\n我们这里使用 20000 端口，当然读者可以根据自己的喜好选择，只要保证所选择的端口号当前没有被其他程序占用即可，服务器代码保持不变，客户端绑定代码中的端口号从 0 改成 20000。这里为了节省篇幅，只贴出修改处的代码：\nstruct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); //将socket绑定到20000号端口上去 bindaddr.sin_port = htons(20000); if (bind(clientfd, (struct sockaddr *)\u0026amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;bind socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } 再次重新编译程序，先启动一个客户端后，我们看到此时的 TCP 连接状态：\n[root@localhost testsocket]# lsof -i -Pn COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME server 1676 root 3u IPv4 21933 0t0 TCP *:3000 (LISTEN) server 1676 root 4u IPv4 21934 0t0 TCP 127.0.0.1:3000-\u0026gt;127.0.0.1:20000 (ESTABLISHED) client 1678 root 3u IPv4 21336 0t0 TCP 127.0.0.1:20000-\u0026gt;127.0.0.1:3000 (ESTABLISHED) 通过上面的结果，我们发现 client 进程确实使用 20000 号端口连接到 server 进程上去了。这个时候如果我们再开启一个 client 进程，我们猜想由于端口号 20000 已经被占用，新启动的 client 会由于调用 bind 函数出错而退出，我们实际验证一下：\n[root@localhost testsocket]# ./client bind socket error. [root@localhost testsocket]# 结果确实和我们预想的一样。\n在技术面试的时候，有时候面试官会问 TCP 网络通信的客户端程序中的 socket 是否可以调用 bind 函数，相信读到这里，聪明的读者已经有答案了。\n另外，Linux 的 nc 命令有个 -p 选项（字母 p 是小写），这个选项的作用就是 nc 在模拟客户端程序时，可以使用指定端口号连接到服务器程序上去，实现原理相信读者也明白了。我们还是以上面的服务器程序为例，这个我们不用我们的 client 程序，改用 nc 命令来模拟客户端。在 shell 终端输入：\n[root@localhost testsocket]# nc -v -p 9999 127.0.0.1 3000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 127.0.0.1:3000. My name is zhangxf My name is zhangxf -v 选项表示输出 nc 命令连接的详细信息，这里连接成功以后，会输出“Ncat: Connected to 127.0.0.1:3000.” 提示已经连接到服务器的 3000 端口上去了。\n-p 选项的参数值是 9999 表示，我们要求 nc 命令本地以端口号 9999 连接服务器，注意不要与端口号 3000 混淆，3000 是服务器的侦听端口号，也就是我们的连接的目标端口号，9999 是我们客户端使用的端口号。我们用 lsof 命令来验证一下我们的 nc 命令是否确实以 9999 端口号连接到 server 进程上去了。\n[root@localhost testsocket]# lsof -i -Pn COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME server 1676 root 3u IPv4 21933 0t0 TCP *:3000 (LISTEN) server 1676 root 7u IPv4 22405 0t0 TCP 127.0.0.1:3000-\u0026gt;127.0.0.1:9999 (ESTABLISHED) nc 2005 root 3u IPv4 22408 0t0 TCP 127.0.0.1:9999-\u0026gt;127.0.0.1:3000 (ESTABLISHED) 结果确实如我们期望的一致。\n当然，我们用 nc 命令连接上 server 进程以后，我们还给服务器发了一条消息\u0026quot;My name is zhangxf\u0026quot;，server 程序收到消息后把这条消息原封不动地返还给我们，以下是 server 端运行结果：\n[root@localhost testsocket]# ./server recv data from client, data: My name is zhangxf send data to client successfully, data: My name is zhangxf 关于 lsof 和 nc 命令我们会在后面的系列文章中详细讲解。\n","permalink":"https://haokiu.com/blog/48af9bced29e4786944b5661c4155665/","summary":"bind 函数重难点解析 bind 函数如何选择绑定地址 bind 函数的基本用法如下：\nstruct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); bindaddr.sin_port = htons(3000); if (bind(listenfd, (struct sockaddr *)\u0026amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;bind listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } 其中 bind 的地址我们使用了一个宏叫 INADDR_ANY ，关于这个宏的解释如下：\nIf an application does not care what local address is assigned, specify the constant value INADDR_ANY for an IPv4 local address or the constant value in6addr_any for an IPv6 local address in the sa_data member of the name parameter. This allows the underlying service provider to use any appropriate network address, potentially simplifying application programming in the presence of multihomed hosts (that is, hosts that have more than one network interface and address).","title":"bind 函数重难点解析"},{"content":"C++ 17 结构化绑定 stl 的 map 容器很多读者应该都很熟悉，map 容器提供了一个 insert 方法，我们用该方法向 map 中插入元素，但是应该很少有人记得 insert 方法的返回值是什么类型，让我们来看一下 C++98/03 提供的 insert 方法的签名：\nstd::pair\u0026lt;iterator,bool\u0026gt; insert( const value_type\u0026amp; value ); 这里我们仅关心其返回值，这个返回值是一个 std::pair 类型，由于 map 中的元素的 key 不允许重复，所以如果 insert 方法调用成功，T1 是被成功插入到 map 中的元素的迭代器，T2 的类型为 bool，此时其值为 true（表示插入成功）；如果 insert 由于 key 重复，T1 是造成 insert 插入失败、已经存在于 map 中的元素的迭代器，此时 T2 的值为 false（表示插入失败）。\n在 C++98/03 标准中我们可以使用 std::pair 的 first 和 second 属性来分别引用 T1 和 T2 的值。如下面的我们熟悉的代码所示：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;map\u0026gt; int main() { std::map\u0026lt;std::string, int\u0026gt; cities; cities[\u0026#34;beijing\u0026#34;] = 0; cities[\u0026#34;shanghai\u0026#34;] = 1; cities[\u0026#34;shenzhen\u0026#34;] = 2; cities[\u0026#34;guangzhou\u0026#34;] = 3; //for (const auto\u0026amp; [key, value] : m) //{ // std::cout \u0026lt;\u0026lt; key \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; value \u0026lt;\u0026lt; std::endl; //} //这一行在 C++11 之前写法实在太麻烦了， //std::pair\u0026lt;std::map\u0026lt;std::string, int\u0026gt;::iterator, int\u0026gt; insertResult = cities.insert(std::pair\u0026lt;std::string, int\u0026gt;(\u0026#34;shanghai\u0026#34;, 2)); //C++ 11中我们写成： auto insertResult = cities.insert(std::pair\u0026lt;std::string, int\u0026gt;(\u0026#34;shanghai\u0026#34;, 2)); std::cout \u0026lt;\u0026lt; \u0026#34;Is insertion successful ? \u0026#34; \u0026lt;\u0026lt; (insertResult.second ? \u0026#34;true\u0026#34; : \u0026#34;false\u0026#34;) \u0026lt;\u0026lt; \u0026#34;, element key: \u0026#34; \u0026lt;\u0026lt; insertResult.first-\u0026gt;first \u0026lt;\u0026lt; \u0026#34;, value: \u0026#34; \u0026lt;\u0026lt; insertResult.first-\u0026gt;second \u0026lt;\u0026lt; std::endl; return 0; } 代码 19 行实在太啰嗦了，我们使用 auto 关键字让编译器自动推导类型。\nstd::pair 一般只能表示两个元素，C++11 标准中引入了 std::tuple 类型，有了这个类型，我们就可以放任意个元素了，原来需要定义成结构体的 POD 对象我们可以直接使用 std::tuple 表示，例如下面表示用户信息的结构体：\nstruct UserInfo { std::string username; std::string password; int gender; int age; std::string address; }; int main() { UserInfo userInfo = { \u0026#34;Tom\u0026#34;, \u0026#34;123456\u0026#34;, 0, 25, \u0026#34;Pudong Street\u0026#34; }; std::string username = userInfo.username; std::string password = userInfo.password; int gender = userInfo.gender; int age = userInfo.age; std::string address = userInfo.address; return 0; } 我们不再需要定义 struct UserInfo 这样的对象，可以直接使用 std::tuple 表示：\nint main() { std::tuple\u0026lt;std::string, std::string, int, int, std::string\u0026gt; userInfo(\u0026#34;Tom\u0026#34;, \u0026#34;123456\u0026#34;, 0, 25, \u0026#34;Pudong Street\u0026#34;); std::string username = std::get\u0026lt;0\u0026gt;(userInfo); std::string password = std::get\u0026lt;1\u0026gt;(userInfo); int gender = std::get\u0026lt;2\u0026gt;(userInfo); int age = std::get\u0026lt;3\u0026gt;(userInfo); std::string address = std::get\u0026lt;4\u0026gt;(userInfo); return 0; } 从 std::tuple 中获取对应位置的元素，我们使用 std::get ，其中 N 是元素的序号（从 0 开始）。\n与定义结构体相比，通过 std::pair 的 first 和 second 还是 std::tuple 的 std::get 方法来获取元素子属性，这些代码都是非常难以维护的，其根本原因是 first 和 second 这样的命名不能做到见名知意。\nC++17 引入的结构化绑定（Structured Binding ）将我们从这类代码中解放出来。结构化绑定使用语法如下：\nauto [a, b, c, ...] = expression; auto [a, b, c, ...] { expression }; auto [a, b, c, ...] ( expression ); 右边的 expression 可以是一个函数调用、花括号表达式或者支持结构化绑定的某个类型的变量。例如：\n//形式1 auto [iterator, inserted] = someMap.insert(...); //形式2 double myArray[3] = { 1.0, 2.0, 3.0 }; auto [a, b, c] = myArray; //形式3 struct Point { double x; double y; }; Point myPoint(10.0, 20.0); auto [myX, myY] = myPoint; 这样，我们可以给用于绑定到目标的变量名（语法中的 a、b、c）起一个有意义的名字。\n需要注意的是，绑定名称 a、b、c 是绑定目标的一份拷贝，当绑定类型不是基础数据类型时，如果你的本意不是想要得到绑定目标的副本，为了避免拷贝带来的不必要开销，建议使用引用，如果不需要修改绑定目标建议使用 const 引用。示例如下：\ndouble myArray[3] = { 1.0, 2.0, 3.0 }; auto\u0026amp; [a, b, c] = myArray; //形式3 struct Point { double x; double y; }; Point myPoint(10.0, 20.0); const auto\u0026amp; [myX, myY] = myPoint; 结构化绑定（Structured Binding ）是 C++17 引入的一个非常好用的语法特性。有了这种语法，在遍历像 map 这样的容器时，我们可以使用更简洁和清晰的代码去遍历这些容器了：\nstd::map\u0026lt;std::string, int\u0026gt; cities; cities[\u0026#34;beijing\u0026#34;] = 0; cities[\u0026#34;shanghai\u0026#34;] = 1; cities[\u0026#34;shenzhen\u0026#34;] = 2; cities[\u0026#34;guangzhou\u0026#34;] = 3; for (const auto\u0026amp; [cityName, cityNumber] : cities) { std::cout \u0026lt;\u0026lt; cityName \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; cityNumber \u0026lt;\u0026lt; std::endl; } 上述代码中 cityName 和 cityNumber 可以更好地反映出这个 map 容器的元素内容。\n我们再来看一个例子，某 WebSocket 网络库（https://github.com/uNetworking/uWebSockets）中有如下代码：\nstd::pair\u0026lt;int, bool\u0026gt; uncork(const char *src = nullptr, int length = 0, bool optionally = false) { LoopData *loopData = getLoopData(); if (loopData-\u0026gt;corkedSocket == this) { loopData-\u0026gt;corkedSocket = nullptr; if (loopData-\u0026gt;corkOffset) { /* Corked data is already accounted for via its write call */ auto [written, failed] = write(loopData-\u0026gt;corkBuffer, loopData-\u0026gt;corkOffset, false, length); loopData-\u0026gt;corkOffset = 0; if (failed) { /* We do not need to care for buffering here, write does that */ return {0, true}; } } /* We should only return with new writes, not things written to cork already */ return write(src, length, optionally, 0); } else { /* We are not even corked! */ return {0, false}; } } 代码的第 9 行 write 函数返回类型是 std::pair，被绑定到 [written, failed] 这两个变量中去。前者在写入成功的情况下表示实际写入的字节数，后者表示是否写入成功。\nstd::pair\u0026lt;int, bool\u0026gt; write(const char *src, int length, bool optionally = false, int nextLength = 0) { //具体实现省略... } 结构化绑定的限制\n结构化绑定不能使用 constexpr 修饰或被申明为 static，例如：\n//正常编译 auto [first, second] = std::pair\u0026lt;int, int\u0026gt;(1, 2); //无法编译通过 //constexpr auto [first, second] = std::pair\u0026lt;int, int\u0026gt;(1, 2); //无法编译通过 //static auto [first, second] = std::pair\u0026lt;int, int\u0026gt;(1, 2); 注意：有些编译器也不支持在 lamda 表达式捕获列表中使用结构化绑定语法。\n","permalink":"https://haokiu.com/blog/b08571a528324d72b376f4ccb2a6dad3/","summary":"C++ 17 结构化绑定 stl 的 map 容器很多读者应该都很熟悉，map 容器提供了一个 insert 方法，我们用该方法向 map 中插入元素，但是应该很少有人记得 insert 方法的返回值是什么类型，让我们来看一下 C++98/03 提供的 insert 方法的签名：\nstd::pair\u0026lt;iterator,bool\u0026gt; insert( const value_type\u0026amp; value ); 这里我们仅关心其返回值，这个返回值是一个 std::pair 类型，由于 map 中的元素的 key 不允许重复，所以如果 insert 方法调用成功，T1 是被成功插入到 map 中的元素的迭代器，T2 的类型为 bool，此时其值为 true（表示插入成功）；如果 insert 由于 key 重复，T1 是造成 insert 插入失败、已经存在于 map 中的元素的迭代器，此时 T2 的值为 false（表示插入失败）。\n在 C++98/03 标准中我们可以使用 std::pair 的 first 和 second 属性来分别引用 T1 和 T2 的值。如下面的我们熟悉的代码所示：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;map\u0026gt; int main() { std::map\u0026lt;std::string, int\u0026gt; cities; cities[\u0026#34;beijing\u0026#34;] = 0; cities[\u0026#34;shanghai\u0026#34;] = 1; cities[\u0026#34;shenzhen\u0026#34;] = 2; cities[\u0026#34;guangzhou\u0026#34;] = 3; //for (const auto\u0026amp; [key, value] : m) //{ // std::cout \u0026lt;\u0026lt; key \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; value \u0026lt;\u0026lt; std::endl; //} //这一行在 C++11 之前写法实在太麻烦了， //std::pair\u0026lt;std::map\u0026lt;std::string, int\u0026gt;::iterator, int\u0026gt; insertResult = cities.","title":"C++ 17 结构化绑定"},{"content":"C++必知必会的知识点 如何成为一名合格的C/C++开发者？\n不定参数函数实现var_arg系列的宏\n你一定要搞明白的C函数调用方式与栈原理\n深入理解C/C++中的指针\n详解C++11中的智能指针\nC++17结构化绑定\nC++必须掌握的pimpl惯用法\n用Visual Studio调试Linux程序\n如何使用Visual Studio管理和阅读开源项目代码\n利用cmake工具生成Visual Studio工程文件\n","permalink":"https://haokiu.com/blog/6176f55c32444820a0055fadcf89273c/","summary":"C++必知必会的知识点 如何成为一名合格的C/C++开发者？\n不定参数函数实现var_arg系列的宏\n你一定要搞明白的C函数调用方式与栈原理\n深入理解C/C++中的指针\n详解C++11中的智能指针\nC++17结构化绑定\nC++必须掌握的pimpl惯用法\n用Visual Studio调试Linux程序\n如何使用Visual Studio管理和阅读开源项目代码\n利用cmake工具生成Visual Studio工程文件","title":"C++必知必会的知识点"},{"content":"connect 函数在阻塞和非阻塞模式下的行为 在 socket 是阻塞模式下 connect 函数会一直到有明确的结果才会返回（或连接成功或连接失败），如果服务器地址“较远”，连接速度比较慢，connect 函数在连接过程中可能会导致程序阻塞在 connect 函数处好一会儿（如两三秒之久），虽然这一般也不会对依赖于网络通信的程序造成什么影响，但在实际项目中，我们一般倾向使用所谓的异步的 connect 技术，或者叫非阻塞的 connect。这个流程一般有如下步骤：\n1. 创建socket，并将 socket 设置成非阻塞模式； 2. 调用 connect 函数，此时无论 connect 函数是否连接成功会立即返回；如果返回-1并不表示连接出错，如果此时错误码是EINPROGRESS 3. 接着调用 select 函数，在指定的时间内判断该 socket 是否可写，如果可写说明连接成功，反之则认为连接失败。 按上述流程编写代码如下：\n/** * 异步的connect写法，nonblocking_connect.cpp * zhangyl 2018.12.17 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 #define SEND_DATA \u0026#34;helloworld\u0026#34; int main(int argc, char* argv[]) { //1.创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //连接成功以后，我们再将 clientfd 设置成非阻塞模式， //不能在创建时就设置，这样会影响到 connect 函数的行为 int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(clientfd, F_SETFL, newSocketFlag) == -1) { close(clientfd); std::cout \u0026lt;\u0026lt; \u0026#34;set socket to nonblock error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //2.连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); for (;;) { int ret = connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)); if (ret == 0) { std::cout \u0026lt;\u0026lt; \u0026#34;connect to server successfully.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); return 0; } else if (ret == -1) { if (errno == EINTR) { //connect 动作被信号中断，重试connect std::cout \u0026lt;\u0026lt; \u0026#34;connecting interruptted by signal, try again.\u0026#34; \u0026lt;\u0026lt; std::endl; continue; } else if (errno == EINPROGRESS) { //连接正在尝试中 break; } else { //真的出错了， close(clientfd); return -1; } } } fd_set writeset; FD_ZERO(\u0026amp;writeset); FD_SET(clientfd, \u0026amp;writeset); //可以利用tv_sec和tv_usec做更小精度的超时控制 struct timeval tv; tv.tv_sec = 3; tv.tv_usec = 0; if (select(clientfd + 1, NULL, \u0026amp;writeset, NULL, \u0026amp;tv) == 1) { std::cout \u0026lt;\u0026lt; \u0026#34;[select] connect to server successfully.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;[select] connect to server error.\u0026#34; \u0026lt;\u0026lt; std::endl; } //5. 关闭socket close(clientfd); return 0; } 为了区别到底是在调用 connect 函数时判断连接成功还是通过 select 函数判断连接成功，我们在后者的输出内容中加上了“[select]”标签以示区别。\n我们先用 nc 命令启动一个服务器程序：\nnc -v -l 0.0.0.0 3000 然后编译客户端程序并执行：\n[root@localhost testsocket]# g++ -g -o nonblocking_connect nonblocking_connect.cpp [root@localhost testsocket]# ./nonblocking_connect [select] connect to server successfully. 我们把服务器程序关掉，再重新启动一下客户端，这个时候应该会连接失败，程序输出结果如下：\n[root@localhost testsocket]# ./nonblocking_connect [select] connect to server successfully. 奇怪？为什么连接不上也会得出一样的输出结果？难道程序有问题？这是因为：\n在 Windows 系统上，一个 socket 没有建立连接之前，我们使用 select 函数检测其是否可写，能得到正确的结果（不可写），连接成功后检测，会变为可写。所以，上述介绍的异步 connect 写法流程在 Windows 系统上时没有问题的。 在 Linux 系统上一个 socket 没有建立连接之前，用 select 函数检测其是否可写，你也会得到可写得结果，所以上述流程并不适用于 Linux 系统。正确的做法是，connect 之后，不仅要用 select 检测可写，还要检测此时 socket 是否出错，通过错误码来检测确定是否连接上，错误码为 0 表示连接上，反之为未连接上。完整代码如下： /** * Linux 下正确的异步的connect写法，linux_nonblocking_connect.cpp * zhangyl 2018.12.17 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 #define SEND_DATA \u0026#34;helloworld\u0026#34; int main(int argc, char* argv[]) { //1.创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //连接成功以后，我们再将 clientfd 设置成非阻塞模式， //不能在创建时就设置，这样会影响到 connect 函数的行为 int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(clientfd, F_SETFL, newSocketFlag) == -1) { close(clientfd); std::cout \u0026lt;\u0026lt; \u0026#34;set socket to nonblock error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //2.连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); for (;;) { int ret = connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)); if (ret == 0) { std::cout \u0026lt;\u0026lt; \u0026#34;connect to server successfully.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); return 0; } else if (ret == -1) { if (errno == EINTR) { //connect 动作被信号中断，重试connect std::cout \u0026lt;\u0026lt; \u0026#34;connecting interruptted by signal, try again.\u0026#34; \u0026lt;\u0026lt; std::endl; continue; } else if (errno == EINPROGRESS) { //连接正在尝试中 break; } else { //真的出错了， close(clientfd); return -1; } } } fd_set writeset; FD_ZERO(\u0026amp;writeset); FD_SET(clientfd, \u0026amp;writeset); //可以利用tv_sec和tv_usec做更小精度的超时控制 struct timeval tv; tv.tv_sec = 3; tv.tv_usec = 0; if (select(clientfd + 1, NULL, \u0026amp;writeset, NULL, \u0026amp;tv) != 1) { std::cout \u0026lt;\u0026lt; \u0026#34;[select] connect to server error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); return -1; } int err; socklen_t len = static_cast\u0026lt;socklen_t\u0026gt;(sizeof err); if (::getsockopt(clientfd, SOL_SOCKET, SO_ERROR, \u0026amp;err, \u0026amp;len) \u0026lt; 0) { close(clientfd); return -1; } if (err == 0) std::cout \u0026lt;\u0026lt; \u0026#34;connect to server successfully.\u0026#34; \u0026lt;\u0026lt; std::endl; else std::cout \u0026lt;\u0026lt; \u0026#34;connect to server error.\u0026#34; \u0026lt;\u0026lt; std::endl; //5. 关闭socket close(clientfd); return 0; } 当然，在实际的项目中，第 3 个步骤中 Linux 平台上你也可以使用 poll 函数来判断 socket 是否可写；在 Windows 平台上你可以使用 WSAEventSelect 或 WSAAsyncSelect 函数判断连接是否成功，关于这三个函数我们将在后面的章节中详细讲解，这里暂且仅以 select 函数为例。\n","permalink":"https://haokiu.com/blog/f82abb8bce8a4c85b9b8c665cb9fe48d/","summary":"connect 函数在阻塞和非阻塞模式下的行为 在 socket 是阻塞模式下 connect 函数会一直到有明确的结果才会返回（或连接成功或连接失败），如果服务器地址“较远”，连接速度比较慢，connect 函数在连接过程中可能会导致程序阻塞在 connect 函数处好一会儿（如两三秒之久），虽然这一般也不会对依赖于网络通信的程序造成什么影响，但在实际项目中，我们一般倾向使用所谓的异步的 connect 技术，或者叫非阻塞的 connect。这个流程一般有如下步骤：\n1. 创建socket，并将 socket 设置成非阻塞模式； 2. 调用 connect 函数，此时无论 connect 函数是否连接成功会立即返回；如果返回-1并不表示连接出错，如果此时错误码是EINPROGRESS 3. 接着调用 select 函数，在指定的时间内判断该 socket 是否可写，如果可写说明连接成功，反之则认为连接失败。 按上述流程编写代码如下：\n/** * 异步的connect写法，nonblocking_connect.cpp * zhangyl 2018.12.17 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 #define SEND_DATA \u0026#34;helloworld\u0026#34; int main(int argc, char* argv[]) { //1.创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //连接成功以后，我们再将 clientfd 设置成非阻塞模式， //不能在创建时就设置，这样会影响到 connect 函数的行为 int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(clientfd, F_SETFL, newSocketFlag) == -1) { close(clientfd); std::cout \u0026lt;\u0026lt; \u0026#34;set socket to nonblock error.","title":"connect 函数在阻塞和非阻塞模式下的行为"},{"content":"leveldb源码分析 leveldb源码分析1\nleveldb源码分析2\nleveldb源码分析3\nleveldb源码分析4\nleveldb源码分析5\nleveldb源码分析6\nleveldb源码分析7\nleveldb源码分析8\nleveldb源码分析9\nleveldb源码分析10\nleveldb源码分析11\nleveldb源码分析12\nleveldb源码分析13\nleveldb源码分析14\nleveldb源码分析15\nleveldb源码分析16\nleveldb源码分析17\nleveldb源码分析18\nleveldb源码分析19\nleveldb源码分析20\nleveldb源码分析21\nleveldb源码分析22\n","permalink":"https://haokiu.com/blog/c898014e5b304df0bade6b12d638467a/","summary":"leveldb源码分析 leveldb源码分析1\nleveldb源码分析2\nleveldb源码分析3\nleveldb源码分析4\nleveldb源码分析5\nleveldb源码分析6\nleveldb源码分析7\nleveldb源码分析8\nleveldb源码分析9\nleveldb源码分析10\nleveldb源码分析11\nleveldb源码分析12\nleveldb源码分析13\nleveldb源码分析14\nleveldb源码分析15\nleveldb源码分析16\nleveldb源码分析17\nleveldb源码分析18\nleveldb源码分析19\nleveldb源码分析20\nleveldb源码分析21\nleveldb源码分析22","title":"leveldb源码分析"},{"content":"leveldb源码分析1 本系列《leveldb源码分析》共有22篇文章，这是第一篇。\nleveldb，除去测试部分，代码不超过1.5w行。这是一个单机k/v存储系统，决定看完它，并把源码分析完整的写下来，还是会很有帮助的。我比较厌烦太复杂的东西，而Leveldb的逻辑很清晰，代码不多、风格很好，功能就不用讲了，正合我的胃口。 BTW，分析Leveldb也参考了网上一些朋友写的分析blog，如【巴山独钓】。\nleveldb源码分析 2012年1月21号开始研究下leveldb的代码，Google两位大牛开发的单机KV存储系统，涉及到了skip list、内存KV table、LRU cache管理、table文件存储、operation log系统等。先从边边角角的小角色开始扫。\n不得不说，Google大牛的代码风格太好了，读起来很舒服，不像有些开源项目，很快就看不下去了。\n开始之前先来看看Leveldb的基本框架，几大关键组件，如图1-1所示。\n图1-1\nleveldb是一种基于operation log的文件系统，是Log-Structured-Merge Tree的典型实现。LSM源自Ousterhout和Rosenblum在1991年发表的经典论文\u0026laquo;The Design and Implementation of a Log-Structured File System \u0026raquo;。\n由于采用了op log，它就可以把随机的磁盘写操作，变成了对op log的append操作，因此提高了IO效率，最新的数据则存储在内存memtable中。\n当op log文件大小超过限定值时，就定时做check point。Leveldb会生成新的Log文件和Memtable，后台调度会将Immutable Memtable的数据导出到磁盘，形成一个新的SSTable文件。SSTable就是由内存中的数据不断导出并进行Compaction操作后形成的，而且SSTable的所有文件是一种层级结构，第一层为Level 0，第二层为Level 1，依次类推，层级逐渐增高，这也是为何称之为LevelDb的原因。\n1. 一些约定 先说下代码中的一些约定：\n1.1 字节序 Leveldb对于数字的存储是little-endian的，在把int32或者int64转换为char*的函数中，是按照先低位再高位的顺序存放的，也就是little-endian的。\n1.2 VarInt 把一个int32或者int64格式化到字符串中，除了上面说的little-endian字节序外，大部分还是变长存储的，也就是VarInt。对于VarInt，每byte的有效存储是7bit的，用最高的8bit位来表示是否结束，如果是1就表示后面还有一个byte的数字，否则表示结束。直接见Encode和Decode函数。\n在操作log中使用的是Fixed存储格式。\n1.3 字符比较 是基于unsigned char的，而非char。\n2. 基本数据结构 别看是基本数据结构，有些也不是那么简单的，像LRU Cache管理和Skip list那都算是leveldb的核心数据结构。\n2.1 Slice Leveldb中的基本数据结构：\n包括length和一个指向外部字节数组的指针。 和string一样，允许字符串中包含’\\0’。 提供一些基本接口，可以把const char和string转换为Slice；把Slice转换为string，取得数据指针const char。\n2.2 Status Leveldb 中的返回状态，将错误号和错误信息封装成Status类，统一进行处理。并定义了几种具体的返回状态，如成功或者文件不存在等。\n为了节省空间Status并没有用std::string来存储错误信息，而是将返回码(code), 错误信息message及长度打包存储于一个字符串数组中。\n成功状态OK 是NULL state_，否则state_ 是一个包含如下信息的数组:\nstate_[0..3] == 消息message长度 state_[4] == 消息code state_[5..] ==消息message 2.3 Arena Leveldb的简单的内存池，它所作的工作十分简单，申请内存时，将申请到的内存块放入std::vector blocks_中，在Arena的生命周期结束后，统一释放掉所有申请到的内存，内部结构如图2.3-1所示。\nArena主要提供了两个申请函数：其中一个直接分配内存，另一个可以申请对齐的内存空间。\nArena没有直接调用delete/free函数，而是由Arena的析构函数统一释放所有的内存。\n应该说这是和leveldb特定的应用场景相关的，比如一个memtable使用一个Arena，当memtable被释放时，由Arena统一释放其内存。\n2.4 Skip list **Skip list(跳跃表）是一种可以代替平衡树的数据结构。**Skip lists应用概率保证平衡，平衡树采用严格的旋转（比如平衡二叉树有左旋右旋）来保证平衡，因此Skip list比较容易实现，而且相比平衡树有着较高的运行效率。\n从概率上保持数据结构的平衡比显式的保持数据结构平衡要简单的多。对于大多数应用，用skip list要比用树更自然，算法也会相对简单。由于skip list比较简单，实现起来会比较容易，虽然和平衡树有着相同的时间复杂度(O(logn))，但是skip list的常数项相对小很多。skip list在空间上也比较节省。一个节点平均只需要1.333个指针（甚至更少），并且不需要存储保持平衡的变量。\n如图2.4-1所示。\n在Leveldb中，skip list是实现memtable的核心数据结构，memtable的KV数据都存储在skip list中。\n2.5 Cache Leveldb内部通过双向链表实现了一个标准版的LRUCache，先上个示意图，看看几个数据之间的关系，如图2.5-1。\nLeveldb实现LRUCache的几个步骤 接下来说说Leveldb实现LRUCache的几个步骤，很直观明了。\nS1 定义一个LRUHandle结构体，代表cache中的元素。它包含了几个主要的成员：\nvoid* value; 这个存储的是cache的数据；\nvoid (*deleter)(const Slice\u0026amp;, void* value); 这个是数据从Cache中清除时执行的清理函数；\n后面的三个成员事关LRUCache的数据的组织结构：\n\u0026gt; LRUHandle *next_hash; 指向节点在hash table链表中的下一个hash(key)相同的元素，在有碰撞时Leveldb采用的是链表法。最后一个节点的next_hash为NULL。\n\u0026gt; LRUHandle *next, *prev; 节点在双向链表中的前驱后继节点指针，所有的cache数据都是存储在一个双向list中，最前面的是最新加入的，每次新加入的位置都是head-\u0026gt;next。所以每次剔除的规则就是剔除list tail。\nS2 Leveldb自己实现了一个hash table：HandleTable，而不是使用系统提供的hash table。这个类就是基本的hash操作**：Lookup、Insert和Delete**。\nHash table的作用是根据key快速查找元素是否在cache中，并返回LRUHandle节点指针，由此就能快速定位节点在hash表和双向链表中的位置。\n它是通过LRUHandle的成员next_hash组织起来的。\nHandleTable使用LRUHandle **list_存储所有的hash节点，**其实就是一个二维数组，**一维是不同的hash(key)，另一维则是相同hash(key)的碰撞list。\n每次当hash节点数超过当前一维数组的长度后，都会做Resize操作：\nLRUHandle** new_list = new LRUHandle*[new_length]; 然后复制list_到new_list中，并删除旧的list_。\nS3 基于HandleTable和LRUHandle，实现了一个标准的LRUcache，并内置了mutex保护锁，是线程安全的。\n其中存储所有数据的双向链表是LRUHandle lru_，这是一个list head；\nHash表则是HandleTable table_；\nS4 ShardedLRUCache类，实际上到S3，一个标准的LRU Cache已经实现了，为何还要更近一步呢？答案就是速度！\n为了多线程访问，尽可能快速，减少锁开销，ShardedLRUCache内部有16个LRUCache，查找Key时首先计算key属于哪一个分片，分片的计算方法是取32位hash值的高4位，然后在相应的LRUCache中进行查找，这样就大大减少了多线程的访问锁的开销。\nLRUCache shard_[kNumShards] 它就是一个包装类，实现都在LRUCache类中。\n2.6 其它 此外还有其它几个Random、Hash、CRC32、Histogram等，都在util文件夹下，不仔细分析了。\n","permalink":"https://haokiu.com/blog/1776ae3c50104b7ea0c90cf31322958a/","summary":"leveldb源码分析1 本系列《leveldb源码分析》共有22篇文章，这是第一篇。\nleveldb，除去测试部分，代码不超过1.5w行。这是一个单机k/v存储系统，决定看完它，并把源码分析完整的写下来，还是会很有帮助的。我比较厌烦太复杂的东西，而Leveldb的逻辑很清晰，代码不多、风格很好，功能就不用讲了，正合我的胃口。 BTW，分析Leveldb也参考了网上一些朋友写的分析blog，如【巴山独钓】。\nleveldb源码分析 2012年1月21号开始研究下leveldb的代码，Google两位大牛开发的单机KV存储系统，涉及到了skip list、内存KV table、LRU cache管理、table文件存储、operation log系统等。先从边边角角的小角色开始扫。\n不得不说，Google大牛的代码风格太好了，读起来很舒服，不像有些开源项目，很快就看不下去了。\n开始之前先来看看Leveldb的基本框架，几大关键组件，如图1-1所示。\n图1-1\nleveldb是一种基于operation log的文件系统，是Log-Structured-Merge Tree的典型实现。LSM源自Ousterhout和Rosenblum在1991年发表的经典论文\u0026laquo;The Design and Implementation of a Log-Structured File System \u0026raquo;。\n由于采用了op log，它就可以把随机的磁盘写操作，变成了对op log的append操作，因此提高了IO效率，最新的数据则存储在内存memtable中。\n当op log文件大小超过限定值时，就定时做check point。Leveldb会生成新的Log文件和Memtable，后台调度会将Immutable Memtable的数据导出到磁盘，形成一个新的SSTable文件。SSTable就是由内存中的数据不断导出并进行Compaction操作后形成的，而且SSTable的所有文件是一种层级结构，第一层为Level 0，第二层为Level 1，依次类推，层级逐渐增高，这也是为何称之为LevelDb的原因。\n1. 一些约定 先说下代码中的一些约定：\n1.1 字节序 Leveldb对于数字的存储是little-endian的，在把int32或者int64转换为char*的函数中，是按照先低位再高位的顺序存放的，也就是little-endian的。\n1.2 VarInt 把一个int32或者int64格式化到字符串中，除了上面说的little-endian字节序外，大部分还是变长存储的，也就是VarInt。对于VarInt，每byte的有效存储是7bit的，用最高的8bit位来表示是否结束，如果是1就表示后面还有一个byte的数字，否则表示结束。直接见Encode和Decode函数。\n在操作log中使用的是Fixed存储格式。\n1.3 字符比较 是基于unsigned char的，而非char。\n2. 基本数据结构 别看是基本数据结构，有些也不是那么简单的，像LRU Cache管理和Skip list那都算是leveldb的核心数据结构。\n2.1 Slice Leveldb中的基本数据结构：\n包括length和一个指向外部字节数组的指针。 和string一样，允许字符串中包含’\\0’。 提供一些基本接口，可以把const char和string转换为Slice；把Slice转换为string，取得数据指针const char。\n2.2 Status Leveldb 中的返回状态，将错误号和错误信息封装成Status类，统一进行处理。并定义了几种具体的返回状态，如成功或者文件不存在等。\n为了节省空间Status并没有用std::string来存储错误信息，而是将返回码(code), 错误信息message及长度打包存储于一个字符串数组中。\n成功状态OK 是NULL state_，否则state_ 是一个包含如下信息的数组:\nstate_[0..3] == 消息message长度 state_[4] == 消息code state_[5..] ==消息message 2.3 Arena Leveldb的简单的内存池，它所作的工作十分简单，申请内存时，将申请到的内存块放入std::vector blocks_中，在Arena的生命周期结束后，统一释放掉所有申请到的内存，内部结构如图2.3-1所示。\nArena主要提供了两个申请函数：其中一个直接分配内存，另一个可以申请对齐的内存空间。\nArena没有直接调用delete/free函数，而是由Arena的析构函数统一释放所有的内存。\n应该说这是和leveldb特定的应用场景相关的，比如一个memtable使用一个Arena，当memtable被释放时，由Arena统一释放其内存。\n2.4 Skip list **Skip list(跳跃表）是一种可以代替平衡树的数据结构。**Skip lists应用概率保证平衡，平衡树采用严格的旋转（比如平衡二叉树有左旋右旋）来保证平衡，因此Skip list比较容易实现，而且相比平衡树有着较高的运行效率。\n从概率上保持数据结构的平衡比显式的保持数据结构平衡要简单的多。对于大多数应用，用skip list要比用树更自然，算法也会相对简单。由于skip list比较简单，实现起来会比较容易，虽然和平衡树有着相同的时间复杂度(O(logn))，但是skip list的常数项相对小很多。skip list在空间上也比较节省。一个节点平均只需要1.333个指针（甚至更少），并且不需要存储保持平衡的变量。\n如图2.4-1所示。\n在Leveldb中，skip list是实现memtable的核心数据结构，memtable的KV数据都存储在skip list中。","title":"leveldb源码分析1"},{"content":"leveldb源码分析10 本系列《leveldb源码分析》共有22篇文章，这是第十篇\n6.SSTable之四 6.6 遍历Table 6.6.1 遍历接口 Table导出了一个返回Iterator的接口，通过Iterator对象，调用者就可以遍历Table的内容，它简单的返回了一个TwoLevelIterator对象。见函数实现：\nIterator* NewIterator(const ReadOptions\u0026amp;options) const; { return NewTwoLevelIterator(rep_-\u0026gt;index_block-\u0026gt;NewIterator(rep_-\u0026gt;options.comparator), \u0026amp;Table::BlockReader,const_cast\u0026lt;Table*\u0026gt;(this), options); } // 函数NewTwoLevelIterator创建了一个TwoLevelIterator对象： Iterator* NewTwoLevelIterator(Iterator* index_iter,BlockFunction block_function, void* arg, constReadOptions\u0026amp; options) { return newTwoLevelIterator(index_iter, block_function, arg, options); } 这里有一个函数指针BlockFunction，类型为：\ntypedef Iterator* (*BlockFunction)(void*, const ReadOptions\u0026amp;, constSlice\u0026amp;); 为什么叫TwoLevelIterator呢，下面就来看看。\n6.6.2 TwoLevelIterator 它也是Iterator的子类，之所以叫two level应该是不仅可以迭代其中存储的对象，它还接受了一个函数BlockFunction，可以遍历存储的对象，可见它是专门为Table定制的。 我们已经知道各种Block的存储格式都是相同的，但是各自block data存储的k/v又互不相同，于是我们就需要一个途径，能够在使用同一个方式遍历不同的block时，又能解析这些k/v。这就是BlockFunction，它又返回了一个针对block data的Iterator。Block和block data存储的k/v对的key是统一的。 先来看类的主要成员变量：\nBlockFunction block_function_; // block操作函数 void* arg_; // BlockFunction的自定义参数 const ReadOptions options_; // BlockFunction的read option参数 Status status_; // 当前状态 IteratorWrapper index_iter_; // 遍历block的迭代器 IteratorWrapper data_iter_; // May be NULL-遍历block data的迭代器 // 如果data_iter_ != NULL，data_block_handle_保存的是传递给 // block_function_的index value，以用来创建data_iter_ std::string data_block_handle_; 下面分析一下对于Iterator几个接口的实现。\nS1 对于其Key和Value接口都是返回的data_iter_对应的key和value： virtual bool Valid() const { return data_iter_.Valid(); } virtual Slice key() const { assert(Valid()); return data_iter_.key(); } virtual Slice value() const { assert(Valid()); return data_iter_.value(); } S2 在分析Seek系函数之前，有必要先了解下面这几个函数的用途。\nvoid InitDataBlock(); void SetDataIterator(Iterator*data_iter); //设置date_iter_ = data_iter voidSkipEmptyDataBlocksForward(); voidSkipEmptyDataBlocksBackward(); S2.1首先是InitDataBlock()，它是根据index_iter来初始化data_iter，当定位到新的block时，需要更新data Iterator，指向该block中k/v对的合适位置，函数如下： if (!index_iter_.Valid()) SetDataIterator(NULL); // index_iter非法 else { Slice handle =index_iter_.value(); if (data_iter_.iter() != NULL\u0026amp;\u0026amp; handle.compare(data_block_handle_) == 0) { //data_iter已经在该block data上了，无须改变 } else { // 根据handle数据定位data iter Iterator* iter =(*block_function_)(arg_, options_, handle); data_block_handle_.assign(handle.data(), handle.size()); SetDataIterator(iter); } } S2.2 SkipEmptyDataBlocksForward，向前跳过空的datablock，函数实现如下： while (data_iter_.iter() == NULL|| !data_iter_.Valid()) { // 跳到下一个block if (!index_iter_.Valid()) { // 如果index iter非法，设置data iteration为NULL SetDataIterator(NULL); return; } index_iter_.Next(); InitDataBlock(); if (data_iter_.iter() != NULL)data_iter_.SeekToFirst(); // 跳转到开始 } S2.3 SkipEmptyDataBlocksBackward，向后跳过空的datablock，函数实现如下： while (data_iter_.iter() == NULL|| !data_iter_.Valid()) { // 跳到前一个block if (!index_iter_.Valid()) { // 如果index iter非法，设置data iteration为NULL SetDataIterator(NULL); return; } index_iter_.Prev(); InitDataBlock(); if (data_iter_.iter() != NULL)data_iter_.SeekToLast(); // 跳转到开始 } S3 了解了几个跳转的辅助函数，再来看Seek系接口。 void TwoLevelIterator::Seek(const Slice\u0026amp; target) { index_iter_.Seek(target); InitDataBlock(); // 根据index iter设置data iter if (data_iter_.iter() != NULL)data_iter_.Seek(target); // 调整data iter跳转到target SkipEmptyDataBlocksForward(); // 调整iter，跳过空的block } void TwoLevelIterator::SeekToFirst() { index_iter_.SeekToFirst(); InitDataBlock(); // 根据index iter设置data iter if (data_iter_.iter() != NULL)data_iter_.SeekToFirst(); SkipEmptyDataBlocksForward(); // 调整iter，跳过空的block } void TwoLevelIterator::SeekToLast() { index_iter_.SeekToLast(); InitDataBlock(); // 根据index iter设置data iter if (data_iter_.iter() != NULL)data_iter_.SeekToLast(); SkipEmptyDataBlocksBackward();// 调整iter，跳过空的block } void TwoLevelIterator::Next() { assert(Valid()); data_iter_.Next(); SkipEmptyDataBlocksForward(); // 调整iter，跳过空的block } void TwoLevelIterator::Prev() { assert(Valid()); data_iter_.Prev(); SkipEmptyDataBlocksBackward();// 调整iter，跳过空的block } 6.6.3 BlockReader() 上面传递给twolevel Iterator的函数是Table::BlockReader函数，声明如下：\nstatic Iterator* Table::BlockReader(void* arg, const ReadOptions\u0026amp;options, constSlice\u0026amp; index_value); 它根据参数指明的blockdata，返回一个iterator对象，调用者就可以通过这个iterator对象遍历blockdata存储的k/v对，这其中用到了LRUCache。 函数实现逻辑如下：\nS1 从参数中解析出BlockHandle对象，其中arg就是Table对象，index_value存储的是BlockHandle对象，读取Block的索引。 Table* table =reinterpret_cast\u0026lt;Table*\u0026gt;(arg); Block* block = NULL; Cache::Handle* cache_handle =NULL; BlockHandle handle; Slice input = index_value; Status s =handle.DecodeFrom(\u0026amp;input); S2 根据block handle，首先尝试从cache中直接取出block，不在cache中则调用ReadBlock从文件读取，读取成功后，根据option尝试将block加入到LRU cache中。并在Insert的时候注册了释放函数DeleteCachedBlock。 Cache* block_cache =table-\u0026gt;rep_-\u0026gt;options.block_cache; BlockContents contents; if (block_cache != NULL) { char cache_key_buffer[16]; // cache key的格式为table.cache_id + offset EncodeFixed64(cache_key_buffer, table-\u0026gt;rep_-\u0026gt;cache_id); EncodeFixed64(cache_key_buffer+8, handle.offset()); Slice key(cache_key_buffer,sizeof(cache_key_buffer)); cache_handle =block_cache-\u0026gt;Lookup(key); // 尝试从LRU cache中查找 if (cache_handle != NULL) { // 找到则直接取值 block =reinterpret_cast\u0026lt;Block*\u0026gt;(block_cache-\u0026gt;Value(cache_handle)); } else { // 否则直接从文件读取 s =ReadBlock(table-\u0026gt;rep_-\u0026gt;file, options, handle, \u0026amp;contents); if (s.ok()) { block = new Block(contents); if (contents.cachable\u0026amp;\u0026amp; options.fill_cache) // 尝试加到cache中 cache_handle =block_cache-\u0026gt;Insert(key, block,block-\u0026gt;size(), \u0026amp;DeleteCachedBlock); } } } else { s =ReadBlock(table-\u0026gt;rep_-\u0026gt;file, options, handle, \u0026amp;contents); if (s.ok()) block = newBlock(contents); } S3 如果读取到了block，调用Block::NewIterator接口创建Iterator，如果cache handle为NULL，则注册DeleteBlock，否则注册ReleaseBlock，事后清理。 Iterator* iter; if (block != NULL) { iter =block-\u0026gt;NewIterator(table-\u0026gt;rep_-\u0026gt;options.comparator); if (cache_handle == NULL) iter-\u0026gt;RegisterCleanup(\u0026amp;DeleteBlock,block, NULL); else iter-\u0026gt;RegisterCleanup(\u0026amp;ReleaseBlock,block_cache, cache_handle); } else iter = NewErrorIterator(s); 处理结束，最后返回iter。这里简单列下这几个静态函数，都很简单：\nstatic void DeleteBlock(void* arg, void* ignored) { deletereinterpret_cast\u0026lt;Block*\u0026gt;(arg); } static void DeleteCachedBlock(const Slice\u0026amp; key, void* value) { Block* block =reinterpret_cast\u0026lt;Block*\u0026gt;(value); delete block; } static void ReleaseBlock(void* arg, void* h) { Cache* cache =reinterpret_cast\u0026lt;Cache*\u0026gt;(arg); Cache::Handle* handle =reinterpret_cast\u0026lt;Cache::Handle*\u0026gt;(h); cache-\u0026gt;Release(handle); } 6.7 定位key 这里并不是精确的定位，而是在Table中找到第一个\u0026gt;=指定key的k/v对，然后返回其value在sstable文件中的偏移。也是Table类的一个接口：\nuint64_t ApproximateOffsetOf(const Slice\u0026amp; key) const; 函数实现比较简单：\nS1 调用Block::Iter的Seek函数定位 Iterator* index_iter=rep_-\u0026gt;index_block-\u0026gt;NewIterator(rep_-\u0026gt;options.comparator); index_iter-\u0026gt;Seek(key); uint64_t result; S2 如果index_iter是合法的值，并且Decode成功，返回结果offset。 BlockHandle handle; handle.DecodeFrom(\u0026amp;index_iter-\u0026gt;value()); result = handle.offset(); S3 其它情况，设置result为rep_-\u0026gt;metaindex_handle.offset()，metaindex的偏移在文件结尾附近。 6.8 获取Key—InternalGet() InternalGet，这是为TableCache开的一个口子。这是一个private函数，声明为：\nStatus Table::InternalGet(const ReadOptions\u0026amp; options, constSlice\u0026amp; k, void*arg, void (*saver)(void*, const Slice\u0026amp;, const Slice\u0026amp;)) 其中又有函数指针，在找到数据后，就调用传入的函数指针saver执行调用者的自定义处理逻辑，并且TableCache可能会做缓存。 函数逻辑如下：\nS1 首先根据传入的key定位数据，这需要indexblock的Iterator。 Iterator* iiter =rep_-\u0026gt;index_block-\u0026gt;NewIterator(rep_-\u0026gt;options.comparator); iiter-\u0026gt;Seek(k); S2 如果key是合法的，取出其filter指针，如果使用了filter，则检查key是否存在，这可以快速判断，提升效率。 Status s; Slice handle_value =iiter-\u0026gt;value(); FilterBlockReader* filter = rep_-\u0026gt;filter; BlockHandle handle; if (filter != NULL \u0026amp;\u0026amp; handle.DecodeFrom(\u0026amp;handle_value).ok() \u0026amp;\u0026amp; !filter-\u0026gt;KeyMayMatch(handle.offset(),k)) { // key不存在 } else { // 否则就要读取block，并查找其k/v对 Slice handle = iiter-\u0026gt;value(); Iterator* block_iter =BlockReader(this, options, iiter-\u0026gt;value()); block_iter-\u0026gt;Seek(k); if (block_iter-\u0026gt;Valid())(*saver)(arg, block_iter-\u0026gt;key(), block_iter-\u0026gt;value()); s = block_iter-\u0026gt;status(); delete block_iter; } S3 最后返回结果，删除临时变量。 if (s.ok()) s =iiter-\u0026gt;status(); delete iiter; return s; 随着有关sstable文件读取的结束，sstable的源码也就分析完了，其中我们还遗漏了一些功课要做，那就是Filter和TableCache部分。\n","permalink":"https://haokiu.com/blog/603a94de7932474cbf7478a2d7b94ebf/","summary":"leveldb源码分析10 本系列《leveldb源码分析》共有22篇文章，这是第十篇\n6.SSTable之四 6.6 遍历Table 6.6.1 遍历接口 Table导出了一个返回Iterator的接口，通过Iterator对象，调用者就可以遍历Table的内容，它简单的返回了一个TwoLevelIterator对象。见函数实现：\nIterator* NewIterator(const ReadOptions\u0026amp;options) const; { return NewTwoLevelIterator(rep_-\u0026gt;index_block-\u0026gt;NewIterator(rep_-\u0026gt;options.comparator), \u0026amp;Table::BlockReader,const_cast\u0026lt;Table*\u0026gt;(this), options); } // 函数NewTwoLevelIterator创建了一个TwoLevelIterator对象： Iterator* NewTwoLevelIterator(Iterator* index_iter,BlockFunction block_function, void* arg, constReadOptions\u0026amp; options) { return newTwoLevelIterator(index_iter, block_function, arg, options); } 这里有一个函数指针BlockFunction，类型为：\ntypedef Iterator* (*BlockFunction)(void*, const ReadOptions\u0026amp;, constSlice\u0026amp;); 为什么叫TwoLevelIterator呢，下面就来看看。\n6.6.2 TwoLevelIterator 它也是Iterator的子类，之所以叫two level应该是不仅可以迭代其中存储的对象，它还接受了一个函数BlockFunction，可以遍历存储的对象，可见它是专门为Table定制的。 我们已经知道各种Block的存储格式都是相同的，但是各自block data存储的k/v又互不相同，于是我们就需要一个途径，能够在使用同一个方式遍历不同的block时，又能解析这些k/v。这就是BlockFunction，它又返回了一个针对block data的Iterator。Block和block data存储的k/v对的key是统一的。 先来看类的主要成员变量：\nBlockFunction block_function_; // block操作函数 void* arg_; // BlockFunction的自定义参数 const ReadOptions options_; // BlockFunction的read option参数 Status status_; // 当前状态 IteratorWrapper index_iter_; // 遍历block的迭代器 IteratorWrapper data_iter_; // May be NULL-遍历block data的迭代器 // 如果data_iter_ != NULL，data_block_handle_保存的是传递给 // block_function_的index value，以用来创建data_iter_ std::string data_block_handle_; 下面分析一下对于Iterator几个接口的实现。\nS1 对于其Key和Value接口都是返回的data_iter_对应的key和value： virtual bool Valid() const { return data_iter_.Valid(); } virtual Slice key() const { assert(Valid()); return data_iter_.","title":"leveldb源码分析10"},{"content":"leveldb源码分析11 本系列《leveldb源码分析》共有22篇文章，这是第十一篇\n7.TableCache 这章的内容比较简单，篇幅也不长。\n7.1 TableCache简介 TableCache缓存的是Table对象，每个DB一个，它内部使用一个LRUCache缓存所有的table对象，实际上其内容是文件编号{file number, TableAndFile}*。TableAndFile是一个拥有2个变量的结构体：RandomAccessFile和Table；\nTableCache类的主要成员变量有：\nEnv* const env_; // 用来操作文件 const std::string dbname_; // db名 Cache* cache_; // LRUCache 三个函数接口，其中的参数**@file_number是文件编号，@file_size**是文件大小：\nvoid Evict(uint64_tfile_number); // 该函数用以清除指定文件所有cache的entry， //函数实现很简单，就是根据file number清除cache对象。 EncodeFixed64(buf,file_number); cache_-\u0026gt;Erase(Slice(buf, sizeof(buf))); Iterator* NewIterator(constReadOptions\u0026amp; options, uint64_t file_number, uint64_t file_size, Table**tableptr = NULL); //该函数为指定的file返回一个iterator(对应的文件长度必须是\u0026#34;file_size\u0026#34;字节). //如果tableptr不是NULL，那么tableptr保存的是底层的Table指针。 //返回的tableptr是cache拥有的，不能被删除，生命周期同返回的iterator Status Get(constReadOptions\u0026amp; options, uint64_t file_number,uint64_t file_size, const Slice\u0026amp; k,void* arg, void(*handle_result)(void*, const Slice\u0026amp;, const Slice\u0026amp;)); // 这是一个查找函数，如果在指定文件中seek 到internal key \u0026#34;k\u0026#34; 找到一个entry， //就调用 (*handle_result)(arg,found_key, found_value). 7.2 TableCache::Get() 先来看看**Get接口，**只有几行代码：\nCache::Handle* handle = NULL; Status s =FindTable(file_number, file_size, \u0026amp;handle); if (s.ok()) { Table* t =reinterpret_cast\u0026lt;TableAndFile*\u0026gt;(cache_-\u0026gt;Value(handle))-\u0026gt;table; s = t-\u0026gt;InternalGet(options,k, arg, saver); cache_-\u0026gt;Release(handle); } return s; 首先根据file_number找到Table的cache对象，如果找到了就调用Table::InternalGet，对查找结果的处理在调用者传入的saver回调函数中。 Cache在Lookup找到cache对象后，如果不再使用需要调用Release减引用计数。这个见Cache的接口说明。\n7.3 TableCache遍历 函数NewIterator()，返回一个可以遍历Table对象的Iterator指针，函数逻辑：\nS1 初始化tableptr，调用FindTable，返回cache对象 if (tableptr != NULL) *tableptr =NULL; Cache::Handle* handle = NULL; Status s =FindTable(file_number, file_size, \u0026amp;handle); if (!s.ok()) returnNewErrorIterator(s); S2 从cache对象中取出Table对象指针，调用其NewIterator返回Iterator对象，并为Iterator注册一个cleanup函数。 Table* table =reinterpret_cast\u0026lt;TableAndFile*\u0026gt;(cache_-\u0026gt;Value(handle))-\u0026gt;table; Iterator* result =table-\u0026gt;NewIterator(options); result-\u0026gt;RegisterCleanup(\u0026amp;UnrefEntry, cache_, handle); if (tableptr != NULL) *tableptr= table; return result; 7.4 TableCache::FindTable() 前面的遍历和Get函数都依赖于FindTable这个私有函数完成对cache的查找，下面就来看看该函数的逻辑。函数声明为：\nStatus FindTable(uint64_t file_number, uint64_t file_size, Cache::Handle** handle) 函数流程为：\nS1 首先根据file number从cache中查找table，找到就直接返回成功。 char buf[sizeof(file_number)]; EncodeFixed64(buf, file_number); Slice key(buf, sizeof(buf)); *handle = cache_-\u0026gt;Lookup(key); S2 如果没有找到，说明table不在cache中，则根据file number和db name打开一个RadomAccessFile。Table文件格式为：..sst。如果文件打开成功，则调用Table::Open读取sstable文件。 std::string fname =TableFileName(dbname_, file_number); RandomAccessFile* file = NULL; Table* table = NULL; s =env_-\u0026gt;NewRandomAccessFile(fname, \u0026amp;file); if (s.ok()) s =Table::Open(*options_, file, file_size, \u0026amp;table); S3 如果Table::Open成功则，插入到Cache中。 TableAndFile* tf = newTableAndFile(table, file); *handle = cache_-\u0026gt;Insert(key,tf, 1, \u0026amp;DeleteEntry); 如果失败，则删除file，直接返回失败，失败的结果是不会cache的。\n7.5 辅助函数 有点啰嗦，不过还是写一下吧。其中一个是为LRUCache注册的删除函数DeleteEntry。\nstatic void DeleteEntry(const Slice\u0026amp; key, void* value) { TableAndFile* tf =reinterpret_cast\u0026lt;TableAndFile*\u0026gt;(value); delete tf-\u0026gt;table; delete tf-\u0026gt;file; delete tf; } 另外一个是为Iterator注册的清除函数UnrefEntry。\nstatic void UnrefEntry(void* arg1, void* arg2) { Cache* cache =reinterpret_cast\u0026lt;Cache*\u0026gt;(arg1); Cache::Handle* h =reinterpret_cast\u0026lt;Cache::Handle*\u0026gt;(arg2); cache-\u0026gt;Release(h); } ","permalink":"https://haokiu.com/blog/0159e326ba0e4917878529ee1ae3af48/","summary":"leveldb源码分析11 本系列《leveldb源码分析》共有22篇文章，这是第十一篇\n7.TableCache 这章的内容比较简单，篇幅也不长。\n7.1 TableCache简介 TableCache缓存的是Table对象，每个DB一个，它内部使用一个LRUCache缓存所有的table对象，实际上其内容是文件编号{file number, TableAndFile}*。TableAndFile是一个拥有2个变量的结构体：RandomAccessFile和Table；\nTableCache类的主要成员变量有：\nEnv* const env_; // 用来操作文件 const std::string dbname_; // db名 Cache* cache_; // LRUCache 三个函数接口，其中的参数**@file_number是文件编号，@file_size**是文件大小：\nvoid Evict(uint64_tfile_number); // 该函数用以清除指定文件所有cache的entry， //函数实现很简单，就是根据file number清除cache对象。 EncodeFixed64(buf,file_number); cache_-\u0026gt;Erase(Slice(buf, sizeof(buf))); Iterator* NewIterator(constReadOptions\u0026amp; options, uint64_t file_number, uint64_t file_size, Table**tableptr = NULL); //该函数为指定的file返回一个iterator(对应的文件长度必须是\u0026#34;file_size\u0026#34;字节). //如果tableptr不是NULL，那么tableptr保存的是底层的Table指针。 //返回的tableptr是cache拥有的，不能被删除，生命周期同返回的iterator Status Get(constReadOptions\u0026amp; options, uint64_t file_number,uint64_t file_size, const Slice\u0026amp; k,void* arg, void(*handle_result)(void*, const Slice\u0026amp;, const Slice\u0026amp;)); // 这是一个查找函数，如果在指定文件中seek 到internal key \u0026#34;k\u0026#34; 找到一个entry， //就调用 (*handle_result)(arg,found_key, found_value). 7.2 TableCache::Get() 先来看看**Get接口，**只有几行代码：\nCache::Handle* handle = NULL; Status s =FindTable(file_number, file_size, \u0026amp;handle); if (s.ok()) { Table* t =reinterpret_cast\u0026lt;TableAndFile*\u0026gt;(cache_-\u0026gt;Value(handle))-\u0026gt;table; s = t-\u0026gt;InternalGet(options,k, arg, saver); cache_-\u0026gt;Release(handle); } return s; 首先根据file_number找到Table的cache对象，如果找到了就调用Table::InternalGet，对查找结果的处理在调用者传入的saver回调函数中。 Cache在Lookup找到cache对象后，如果不再使用需要调用Release减引用计数。这个见Cache的接口说明。","title":"leveldb源码分析11"},{"content":"leveldb源码分析12 本系列《leveldb源码分析》共有22篇文章，这是第十二篇\n8.FilterPolicy\u0026amp;Bloom之1 8.1 FilterPolicy 因名知意，FilterPolicy是用于key过滤的，可以快速的排除不存在的key。前面介绍Table的时候，在Table::InternalGet函数中有过一面之缘。 FilterPolicy有3个接口：\nvirtual const char* Name() const = 0; // 返回filter的名字 virtual void CreateFilter(const Slice* keys, int n, std::string* dst)const = 0; virtual bool KeyMayMatch(const Slice\u0026amp; key, const Slice\u0026amp; filter)const = 0; CreateFilter接口，它根据指定的参数创建过滤器，并将结果append到dst中，注意：不能修改dst的原始内容，只做append。 参数@keys[0,n-1]包含依据用户提供的comparator排序的key列表\u0026ndash;可重复，并把根据这些key创建的filter追加到@*dst中。 KeyMayMatch，参数@filter包含了调用CreateFilter函数append的数据，如果key在传递函数CreateFilter的key列表中，则必须返回true。\n注意：它不需要精确，也就是即使key不在前面传递的key列表中，也可以返回true，但是如果key在列表中，就必须返回true。 涉及到的类如图8.1-1所示。\n8.2InternalFilterPolicy 这是一个简单的FilterPolicy的wrapper，以方便的把FilterPolicy应用在InternalKey上，InternalKey是Leveldb内部使用的key，这些前面都讲过。它所做的就是从InternalKey拆分得到user key，然后在user key上做FilterPolicy的操作。 它有一个成员：\nconstFilterPolicy* const user_policy_; 其Name()返回的是user_policy_-\u0026gt;Name()；\nbool InternalFilterPolicy::KeyMayMatch(const Slice\u0026amp; key, constSlice\u0026amp; f) const { returnuser_policy_-\u0026gt;KeyMayMatch(ExtractUserKey(key), f); } void InternalFilterPolicy::CreateFilter(const Slice* keys, int n,std::string* dst) const { Slice* mkey =const_cast\u0026lt;Slice*\u0026gt;(keys); for (int i = 0; i \u0026lt; n; i++)mkey[i] = ExtractUserKey(keys[i]); user_policy_-\u0026gt;CreateFilter(keys, n, dst); } 8.3 BloomFilter 8.3.1 基本理论 Bloom Filter实际上是一种hash算法，数学之美系列有专门介绍。它是由巴顿.布隆于一九七零年提出的，它实际上是一个很长的二进制向量和一系列随机映射函数。 Bloom Filter将元素映射到一个长度为m的bit向量上的一个bit，当这个bit是1时，就表示这个元素在集合内。使用hash的缺点就是元素很多时可能有冲突，为了减少误判，就使用k个hash函数计算出k个bit，只要有一个bit为0，就说明元素肯定不在集合内。下面的图8.3-1是一个示意图。\n在leveldb的实现中，Name()返回\u0026quot;leveldb.BuiltinBloomFilter\u0026quot;，因此metaindex block** 中的key就是”filter.leveldb.BuiltinBloomFilter”。Leveldb使用了double hashing来模拟多个hash函数，当然这里不是用来解决冲突的。 和线性再探测（linearprobing）一样，Double hashing从一个hash值开始，重复向前迭代，直到解决冲突或者搜索完hash表。不同的是，double hashing使用的是另外一个hash函数，而不是固定的步长。 给定两个独立的hash函数h1和h2，对于hash表T和值k，第i次迭代计算出的位置就是：h(i, k) = (h1(k) + i*h2(k)) mod |T|。 对此，Leveldb选择的hash函数是：\nGi(x)=H1(x)+iH2(x) H2(x)=(H1(x)\u0026gt;\u0026gt;17) | (H1(x)\u0026lt;\u0026lt;15) H1是一个基本的hash函数，H2是由H1循环右移得到的，Gi(x)就是第i次循环得到的hash值。【理论分析可参考论文Kirsch,Mitzenmacher2006】 在bloom_filter的数据的最后一个字节存放的是k_的值，k_实际上就是G(x)的个数，也就是计算时采用的hash函数个数。\n8.3.2 BloomFilter参数 这里先来说下其两个成员变量：bits_per_key_和key_；其实这就是Bloom Hashing的两个关键参数。 变量k_实际上就是模拟的hash函数的个数； 关于变量bits_per_key_，对于n个key，其hash table的大小就是bits_per_key_。它的值越大，发生冲突的概率就越低，那么bloom hashing误判的概率就越低。因此这是一个时间空间的trade-off。 对于hash(key)，在平均意义上，发生冲突的概率就是1/ bits_per_key_。 它们在构造函数中根据传入的参数bits_per_key初始化。\nbits_per_key_ = bits_per_key; k_ =static_cast\u0026lt;size_t\u0026gt;(bits_per_key * 0.69); // 0.69 =~ ln(2) if (k_ \u0026lt; 1) k_ = 1; if (k_ \u0026gt; 30) k_ = 30; 模拟hash函数的个数k_取值为bits_per_key_*ln(2)，为何不是0.5或者0.4了，可能是什么理论推导的结果吧，不了解了。\n8.3.3 建立BloomFilter 了解了上面的理论，再来看leveldb对Bloom Fil****ter的实现就轻松多了，先来看Bloom Filter的构建。这就是FilterPolicy::CreateFilter接口的实现：\nvoid CreateFilter(const Slice* keys, int n, std::string* dst) const 下面分析其实现代码，大概有如下几个步骤：\nS1 首先根据key个数分配filter空间，并圆整到8byte。 size_t bits = n * bits_per_key_; if (bits \u0026lt; 64) bits = 64; // 如果n太小FP会很高，限定filter的最小长度 size_t bytes = (bits + 7) / 8; // 圆整到8byte bits = bytes * 8; // bit计算的空间大小 const size_t init_size =dst-\u0026gt;size(); dst-\u0026gt;resize(init_size +bytes, 0); // 分配空间 S2 在filter最后的字节位压入hash函数个数 dst-\u0026gt;push_back(static_cast\u0026lt;char\u0026gt;(k_)); // Remember # of probes in filter S3 对于每个key，使用double-hashing生产一系列的hash值h(K_个)，设置bits array的第h位=1。 char* array =\u0026amp;(*dst)[init_size]; for (size_t i = 0; i \u0026lt; n;i++) { // double-hashing，分析参见[Kirsch,Mitzenmacher 2006] uint32_t h =BloomHash(keys[i]); // h1函数 const uint32_t delta = (h\u0026gt;\u0026gt; 17) | (h \u0026lt;\u0026lt; 15); // h2函数、由h1 Rotate right 17 bits for (size_t j = 0; j \u0026lt;k_; j++) { // double-hashing生产k_个的hash值 const uint32_t bitpos = h% bits; // 在bits array上设置第bitpos位 array[bitpos/8] |= (1\u0026lt;\u0026lt; (bitpos % 8)); h += delta; } } Bloom Filter的创建就完成了。\n8.3.4 查找BloomFilter 在指定的filer中查找key是否存在，这就是bloom filter的查找函数： bool KeyMayMatch(const Slice\u0026amp; key, const Slice\u0026amp; bloom_filter)，函数逻辑如下：\nS1 准备工作，并做些基本判断。 const size_t len =bloom_filter.size(); if (len \u0026lt; 2) return false; const char* array = bloom_filter.data(); const size_t bits = (len - 1)* 8; const size_t k = array[len-1]; // 使用filter的k，而不是k_，这样更灵活 if (k \u0026gt; 30) return true; // 为短bloom filter保留，当前认为直接match S2 计算key的hash值，重复计算阶段的步骤，循环计算k个hash值，只要有一个结果对应的bit位为0，就认为不匹配，否则认为匹配。 uint32_t h = BloomHash(key); const uint32_t delta = (h\u0026gt;\u0026gt; 17) | (h \u0026lt;\u0026lt; 15); // Rotate right 17 bits for (size_t j = 0; j \u0026lt; k;j++) { const uint32_t bitpos = h %bits; if ((array[bitpos/8] \u0026amp;(1 \u0026lt;\u0026lt; (bitpos % 8))) == 0) return false; // notmatch h += delta; } return true; // match 8.4 Filter Block格式 Filter Block也就是前面sstable中的meta block，位于data block之后。\n如果打开db时指定了FilterPolicy，那么每个创建的table都会保存一个filter block，table中的metaindex就包含一条从”filter.到filter block的BlockHandle的映射，其中””是filter policy的Name()函数返回的string。\nFilter block存储了一连串的filter值，其中第i个filter保存的是block b中所有的key通过FilterPolicy::CreateFilter()计算得到的结果，block b在sstable文件中的偏移满足[ i*base … (i+1)*base-1 ]。\n当前base是2KB，举个例子，如果block X和Y在sstable的起始位置都在[0KB, 2KB-1]中，X和Y中的所有key调用FilterPolicy::CreateFilter()的计算结果都将生产到同一个filter中，而且该filter是filter block的第一个filter。 Filter block也是一个block，其格式遵从block的基本格式：|block data| type | crc32|。其中block dat的格式如图8.4-1所示。\n图8.4-1 filter block data\n了解了格式，再分析构建和读取filter的代码就很简单了。\n","permalink":"https://haokiu.com/blog/cd6a8ad07c9f4c479a1e88591f05cd70/","summary":"leveldb源码分析12 本系列《leveldb源码分析》共有22篇文章，这是第十二篇\n8.FilterPolicy\u0026amp;Bloom之1 8.1 FilterPolicy 因名知意，FilterPolicy是用于key过滤的，可以快速的排除不存在的key。前面介绍Table的时候，在Table::InternalGet函数中有过一面之缘。 FilterPolicy有3个接口：\nvirtual const char* Name() const = 0; // 返回filter的名字 virtual void CreateFilter(const Slice* keys, int n, std::string* dst)const = 0; virtual bool KeyMayMatch(const Slice\u0026amp; key, const Slice\u0026amp; filter)const = 0; CreateFilter接口，它根据指定的参数创建过滤器，并将结果append到dst中，注意：不能修改dst的原始内容，只做append。 参数@keys[0,n-1]包含依据用户提供的comparator排序的key列表\u0026ndash;可重复，并把根据这些key创建的filter追加到@*dst中。 KeyMayMatch，参数@filter包含了调用CreateFilter函数append的数据，如果key在传递函数CreateFilter的key列表中，则必须返回true。\n注意：它不需要精确，也就是即使key不在前面传递的key列表中，也可以返回true，但是如果key在列表中，就必须返回true。 涉及到的类如图8.1-1所示。\n8.2InternalFilterPolicy 这是一个简单的FilterPolicy的wrapper，以方便的把FilterPolicy应用在InternalKey上，InternalKey是Leveldb内部使用的key，这些前面都讲过。它所做的就是从InternalKey拆分得到user key，然后在user key上做FilterPolicy的操作。 它有一个成员：\nconstFilterPolicy* const user_policy_; 其Name()返回的是user_policy_-\u0026gt;Name()；\nbool InternalFilterPolicy::KeyMayMatch(const Slice\u0026amp; key, constSlice\u0026amp; f) const { returnuser_policy_-\u0026gt;KeyMayMatch(ExtractUserKey(key), f); } void InternalFilterPolicy::CreateFilter(const Slice* keys, int n,std::string* dst) const { Slice* mkey =const_cast\u0026lt;Slice*\u0026gt;(keys); for (int i = 0; i \u0026lt; n; i++)mkey[i] = ExtractUserKey(keys[i]); user_policy_-\u0026gt;CreateFilter(keys, n, dst); } 8.3 BloomFilter 8.3.1 基本理论 Bloom Filter实际上是一种hash算法，数学之美系列有专门介绍。它是由巴顿.布隆于一九七零年提出的，它实际上是一个很长的二进制向量和一系列随机映射函数。 Bloom Filter将元素映射到一个长度为m的bit向量上的一个bit，当这个bit是1时，就表示这个元素在集合内。使用hash的缺点就是元素很多时可能有冲突，为了减少误判，就使用k个hash函数计算出k个bit，只要有一个bit为0，就说明元素肯定不在集合内。下面的图8.3-1是一个示意图。\n在leveldb的实现中，Name()返回\u0026quot;leveldb.BuiltinBloomFilter\u0026quot;，因此metaindex block** 中的key就是”filter.leveldb.BuiltinBloomFilter”。Leveldb使用了double hashing来模拟多个hash函数，当然这里不是用来解决冲突的。 和线性再探测（linearprobing）一样，Double hashing从一个hash值开始，重复向前迭代，直到解决冲突或者搜索完hash表。不同的是，double hashing使用的是另外一个hash函数，而不是固定的步长。 给定两个独立的hash函数h1和h2，对于hash表T和值k，第i次迭代计算出的位置就是：h(i, k) = (h1(k) + i*h2(k)) mod |T|。 对此，Leveldb选择的hash函数是：","title":"leveldb源码分析12"},{"content":"leveldb源码分析13 本系列《leveldb源码分析》共有22篇文章，这是第十三篇\n8.FilterPolicy\u0026amp;Bloom之二 8.5 构建FilterBlock 8.5.1 FilterBlockBuilder 了解了filter机制，现在来看看filter block的构建，这就是类FilterBlockBuilder。它为指定的table构建所有的filter，结果是一个string字符串，并作为一个block存放在table中。它有三个函数接口：\n// 开始构建新的filter block，TableBuilder在构造函数和Flush中调用 void StartBlock(uint64_tblock_offset); // 添加key，TableBuilder每次向data block中加入key时调用 void AddKey(const Slice\u0026amp;key); // 结束构建，TableBuilder在结束对table的构建时调用 Slice Finish(); FilterBlockBuilder的构建顺序必须满足如下范式：(StartBlock AddKey*)* Finish，显然这和前面讲过的BlockBuilder有所不同。 其成员变量有：\nconst FilterPolicy* policy_; // filter类型，构造函数参数指定 std::string keys_; //Flattened key contents std::vector\u0026lt;size_t\u0026gt; start_; // 各key在keys_中的位置 std::string result_; // 当前计算出的filter data std::vector\u0026lt;uint32_t\u0026gt;filter_offsets_; // 各个filter在result_中的位置 std::vector\u0026lt;Slice\u0026gt; tmp_keys_;// policy_-\u0026gt;CreateFilter()参数 前面说过base是2KB，这对应两个常量kFilterBase =11, kFilterBase =(1\u0026lt;\u0026lt;kFilterBaseLg)；其实从后面的实现来看tmp_keys_完全不必作为成员变量，直接作为函数GenerateFilter()的栈变量就可以。下面就分别分析三个函数接口。\n8.5.2 FilterBlockBuilder::StartBlock() 它根据参数block_offset计算出filter index，然后循环调用GenerateFilter生产新的Filter。\nuint64_t filter_index =(block_offset / kFilterBase); assert(filter_index \u0026gt;=filter_offsets_.size()); while (filter_index \u0026gt;filter_offsets_.size()) GenerateFilter(); 我们来到GenerateFilter这个函数，看看它的逻辑。\n//S1 如果filter中key个数为0，则直接压入result_.size()并返回 const size_t num_keys =start_.size(); if (num_keys == 0) { // there are no keys for this filter filter_offsets_.push_back(result_.size()); //result_.size()应该是0 return; } //S2 从key创建临时key list，根据key的序列字符串kyes_和各key在keys_ //中的开始位置start_依次提取出key。 start_.push_back(keys_.size()); // Simplify lengthcomputation tmp_keys_.resize(num_keys); for (size_t i = 0; i \u0026lt;num_keys; i++) { const char* base =keys_.data() + start_[i]; // 开始指针 size_t length = start_[i+1] -start_[i]; // 长度 tmp_keys_[i] = Slice(base,length); } //S3 为当前的key集合生产filter，并append到result_ filter_offsets_.push_back(result_.size()); policy_-\u0026gt;CreateFilter(\u0026amp;tmp_keys_[0], num_keys, \u0026amp;result_); //S4 清空，重置状态 tmp_keys_.clear(); keys_.clear(); start_.clear(); 8.5.3 FilterBlockBuilder::AddKey() 这个接口很简单，就是把key添加到key_中，并在start_中记录位置。\nSlice k = key; start_.push_back(keys_.size()); keys_.append(k.data(),k.size()); 8.5.4 FilterBlockBuilder::Finish() 调用这个函数说明整个table的data block已经构建完了，可以生产最终的filter block了，在TableBuilder::Finish函数中被调用，向sstable写入meta block。 函数逻辑为：\n//S1 如果start_数字不空，把为的key列表生产filter if (!start_.empty()) GenerateFilter(); //S2 从0开始顺序存储各filter的偏移值，见filter block data的数据格式。 const uint32_t array_offset =result_.size(); for (size_t i = 0; i \u0026lt; filter_offsets_.size();i++) { PutFixed32(\u0026amp;result_,filter_offsets_[i]); } //S3 最后是filter个数，和shift常量（11），并返回结果 PutFixed32(\u0026amp;result_,array_offset); result_.push_back(kFilterBaseLg); // Save encoding parameter in result return Slice(result_); 8.5.5 简单示例 让我们根据TableBuilder对FilterBlockBuilder接口的调用范式： (StartBlock AddKey*)* Finish以及上面的函数实现，结合一个简单例子看看leveldb是如何为data block创建filter block（也就是meta block）的。 考虑两个datablock，在sstable的范围分别是：Block 1 [0, 7KB-1], Block 2 [7KB, 14.1KB]\nS1 首先TableBuilder为Block 1调用FilterBlockBuilder::StartBlock(0)，该函数直接返回；\nS2 然后依次向Block 1加入k/v，其中会调用FilterBlockBuilder::AddKey，FilterBlockBuilder记录这些key。\nS3 下一次TableBuilder添加k/v时，例行检查发现Block 1的大小超过设置，则执行Flush操作，Flush操作在写入Block 1后，开始准备Block 2并更新block offset=7KB，最后调用FilterBlockBuilder::StartBlock(7KB)，开始为Block 2构建Filter。\nS4 在FilterBlockBuilder::StartBlock(7KB)中，计算出filter index = 3，触发3次GenerateFilter函数，为Block 1添加的那些key列表创建filter，其中第2、3次循环创建的是空filter。此时filter的结构如图8.5-1所示。 图8.5-1\n在StartBlock(7KB)时会向filter的偏移数组filter_offsets_压入两个包含空key set的元素，filter_offsets_[1]和filter_offsets_[2]，它们的值都等于7KB-1。\nS5Block 2构建结束，TableBuilder调用Finish结束table的构建，这会再次触发Flush操作，在写入Block 2后，为Block 2的key创建filter。最终的filter如图8.5-2所示。 图8.5-2\n这里如果Block 1的范围是[0, 1.8KB-1]，Block 2从1.8KB开始，那么Block 2将会和Block 1共用一个filter，它们的filter都被生成到filter 0中。 当然在TableBuilder构建表时，Block的大小是根据参数配置的，也是基本均匀的。\n8.6 读取FilterBlock 8.6.1 FilterBlockReader FilterBlock的读取操作在FilterBlockReader类中，它的主要功能是根据传入的FilterPolicy和filter，进行key的匹配查找。 它有如下的几个成员变量：\nconst FilterPolicy* policy_; // filter策略 const char* data_; // filter data指针 (at block-start) const char* offset_; // offset array的开始地址 (at block-end) size_t num_; // offsetarray元素个数 size_t base_lg_; // 还记得kFilterBaseLg吗 Filter策略和filter block内容都由构造函数传入。一个接口函数，就是key的批判查找：\nbool KeyMayMatch(uint64_t block_offset, const Slice\u0026amp; key); 8.6.2 构造 在构造函数中，根据存储格式解析出偏移数组开始指针、个数等信息。\nFilterBlockReader::FilterBlockReader(const FilterPolicy* policy, constSlice\u0026amp; contents) : policy_(policy),data_(NULL), offset_(NULL), num_(0), base_lg_(0) { size_t n = contents.size(); if (n \u0026lt; 5) return; // 1 byte forbase_lg_ and 4 for start of offset array base_lg_ = contents[n-1]; // 最后1byte存的是base uint32_t last_word =DecodeFixed32(contents.data() + n - 5); //偏移数组的位置 if (last_word \u0026gt; n - 5)return; data_ = contents.data(); offset_ = data_ + last_word; // 偏移数组开始指针 num_ = (n - 5 - last_word) / 4; // 计算出filter个数 8.6.3 查找 查找函数传入两个参数\n@block_offset是查找data block在sstable中的偏移，Filter根据此偏移计算filter的编号； @key是查找的key。 声明如下： bool FilterBlockReader::KeyMayMatch(uint64_t block_offset, constSlice\u0026amp; key) 它首先计算出filterindex，根据index解析出filter的range，如果是合法的range，就从data_中取出filter，调用policy_做key的匹配查询。函数实现： uint64_t index = block_offset\u0026gt;\u0026gt; base_lg_; // 计算出filter index if (index \u0026lt; num_) { // 解析出filter的range uint32_t start =DecodeFixed32(offset_ + index*4); uint32_t limit =DecodeFixed32(offset_ + index*4 + 4); if (start \u0026lt;= limit\u0026amp;\u0026amp; limit \u0026lt;= (offset_ - data_)) { Slice filter = Slice(data_ +start, limit - start); // 根据range得到filter returnpolicy_-\u0026gt;KeyMayMatch(key, filter); } else if (start == limit) { return false; // 空filter不匹配任何key } } return true; // 当匹配处理 至此，FilterPolicy和Bloom就分析完了。\n","permalink":"https://haokiu.com/blog/f110bd8130344cbf801fc30d4d7a7ce9/","summary":"leveldb源码分析13 本系列《leveldb源码分析》共有22篇文章，这是第十三篇\n8.FilterPolicy\u0026amp;Bloom之二 8.5 构建FilterBlock 8.5.1 FilterBlockBuilder 了解了filter机制，现在来看看filter block的构建，这就是类FilterBlockBuilder。它为指定的table构建所有的filter，结果是一个string字符串，并作为一个block存放在table中。它有三个函数接口：\n// 开始构建新的filter block，TableBuilder在构造函数和Flush中调用 void StartBlock(uint64_tblock_offset); // 添加key，TableBuilder每次向data block中加入key时调用 void AddKey(const Slice\u0026amp;key); // 结束构建，TableBuilder在结束对table的构建时调用 Slice Finish(); FilterBlockBuilder的构建顺序必须满足如下范式：(StartBlock AddKey*)* Finish，显然这和前面讲过的BlockBuilder有所不同。 其成员变量有：\nconst FilterPolicy* policy_; // filter类型，构造函数参数指定 std::string keys_; //Flattened key contents std::vector\u0026lt;size_t\u0026gt; start_; // 各key在keys_中的位置 std::string result_; // 当前计算出的filter data std::vector\u0026lt;uint32_t\u0026gt;filter_offsets_; // 各个filter在result_中的位置 std::vector\u0026lt;Slice\u0026gt; tmp_keys_;// policy_-\u0026gt;CreateFilter()参数 前面说过base是2KB，这对应两个常量kFilterBase =11, kFilterBase =(1\u0026lt;\u0026lt;kFilterBaseLg)；其实从后面的实现来看tmp_keys_完全不必作为成员变量，直接作为函数GenerateFilter()的栈变量就可以。下面就分别分析三个函数接口。\n8.5.2 FilterBlockBuilder::StartBlock() 它根据参数block_offset计算出filter index，然后循环调用GenerateFilter生产新的Filter。\nuint64_t filter_index =(block_offset / kFilterBase); assert(filter_index \u0026gt;=filter_offsets_.size()); while (filter_index \u0026gt;filter_offsets_.size()) GenerateFilter(); 我们来到GenerateFilter这个函数，看看它的逻辑。\n//S1 如果filter中key个数为0，则直接压入result_.size()并返回 const size_t num_keys =start_.size(); if (num_keys == 0) { // there are no keys for this filter filter_offsets_.push_back(result_.size()); //result_.size()应该是0 return; } //S2 从key创建临时key list，根据key的序列字符串kyes_和各key在keys_ //中的开始位置start_依次提取出key。 start_.","title":"leveldb源码分析13"},{"content":"leveldb源码分析14 本系列《leveldb源码分析》共有22篇文章，这是第十四篇\n9 LevelDB框架之1\n到此为止，基本上Leveldb的主要功能组件都已经分析完了，下面就是把它们组合在一起，形成一个高性能的k/v存储系统。这就是leveldb::DB类。 这里先看一下LevelDB的导出接口和涉及的类，后面将依次以接口分析的方式展开。 而实际上leveldb::DB只是一个接口类，真正的实现和框架类是DBImpl这个类，正是它集合了上面的各种组件。 此外，还有Leveldb对版本的控制，执行版本控制的是Version和VersionSet类。 在leveldb的源码中，DBImpl和VersionSet是两个庞然大物，体量基本算是最大的。对于这两个类的分析，也会分散在打开、销毁和快照等等这些功能中，很难在一个地方集中分析。 作者在文档impl.html中描述了leveldb的实现，其中包括文件组织、compaction和recovery等等。下面的9.1和9.2基本都是翻译子impl.html文档。 在进入框架代码之前，先来了解下leveldb的文件组织和管理。\n9.1 DB文件管理 9.1.1 文件类型\n对于一个数据库Level包含如下的6种文件:\n1/[0-9]+.log：db操作日志 这就是前面分析过的操作日志，log文件包含了最新的db更新，每个更新都以append的方式追加到文件结尾。当log文件达到预定大小时（缺省大约4MB），leveldb就把它转换为一个有序表（如下-2），并创建一个新的log文件。 当前的log文件在内存中的存在形式就是memtable，每次read操作都会访问memtable，以保证read读取到的是最新的数据。\n2/[0-9]+.sst：db的sstable文件 这两个就是前面分析过的静态sstable文件，sstable存储了以key排序的元素。每个元素或者是key对应的value，或者是key的删除标记（删除标记可以掩盖更老sstable文件中过期的value）。 Leveldb把sstable文件通过level的方式组织起来，从log文件中生成的sstable被放在level 0。当level 0的sstable文件个数超过设置（当前为4个）时，leveldb就把所有的level 0文件，以及有重合的level 1文件merge起来，组织成一个新的level 1文件（每个level 1文件大小为2MB）。 Level 0的SSTable文件（后缀为.sst）和Level\u0026gt;1的文件相比有特殊性：这个层级内的.sst文件，两个文件可能存在key重叠。对于Level\u0026gt;0，同层sstable文件的key不会重叠。考虑level\u0026gt;0，level中的文件的总大小超过10^level MB时（如level=1是10MB，level=2是100MB），那么level中的一个文件，以及所有level+1中和它有重叠的文件，会被merge到level+1层的一系列新文件。Merge操作的作用是将更新从低一级level迁移到最高级，只使用批量读写（最小化seek操作，提高效率）。\n3/MANIFEST-[0-9]+：DB元信息文件 它记录的是leveldb的元信息，比如DB使用的Comparator名，以及各SSTable文件的管理信息：如Level层数、文件名、最小key和最大key等等。\n4/CURRENT：记录当前正在使用的Manifest文件 它的内容就是当前的manifest文件名；因为在LevleDb的运行过程中，随着Compaction的进行，新的SSTable文件被产生，老的文件被废弃。并生成新的Manifest文件来记载sstable的变动，而CURRENT则用来记录我们关心的Manifest文件。 当db被重新打开时，leveldb总是生产一个新的manifest文件。Manifest文件使用log的格式，对服务状态的改变（新加或删除的文件）都会追加到该log中。 上面的log文件、sst文件、清单文件，末尾都带着序列号，其序号都是单调递增的（随着next_file_number从1开始递增），以保证不和之前的文件名重复。\n5/log：系统的运行日志，记录系统的运行信息或者错误日志。 6/dbtmp：临时数据库文件，repair时临时生成的。 这里就涉及到几个关键的number计数器，log文件编号，下一个文件（sstable、log和manifest）编号，sequence。 所有正在使用的文件编号，包括log、sstable和manifest都应该小于下一个文件编号计数器。 9.1.2 Level 0\n当操作log超过一定大小时（缺省是1MB），执行如下操作：\nS1 创建新的memtable和log文件，并重导向新的更新到新memtable和log中； S2 在后台： S2.1 将前一个memtable的内容dump到sstable文件； S2.2 丢弃前一个memtable； S2.3 删除旧的log文件和memtable S2.4 把创建的sstable文件放到level 0\n9.2 Compaction 当level L的总文件大小查过限制时，我们就在后台执行compaction操作。Compaction操作从level L中选择一个文件f，以及选择中所有和f有重叠的文件。如果某个level (L+1)的文件ff只是和f部分重合，compaction依然选择ff的完整内容作为输入，在compaction后f和ff都会被丢弃。 另外：因为level 0有些特殊（同层文件可能有重合），从level 0到level 1的compaction就需要特殊对待：level 0的compaction可能会选择多个level 0文件，如果它们之间有重叠。 Compaction将选择的文件内容merge起来，并生成到一系列的level (L+1)文件中，如果输出文件超过设置（2MB），就切换到新的。当输出文件的key范围太大以至于和超过10个level (L+2)文件有重合时，也会切换。后一个规则确保了level (L+1)的文件不会和过多的level (L+2)文件有重合，其后的level (L+1) compaction不会选择过多的level (L+2)文件。 老的文件会被丢弃，新创建的文件将加入到server状态中。 Compaction操作在key空间中循环执行，详细讲一点就是，对于每个level，我们记录上次compaction的ending key。Level的下一次compaction将选择ending key之后的第一个文件（如果这样的文件不存在，将会跳到key空间的开始）。 Compaction会忽略被写覆盖的值，如果更高一层的level没有文件的范围包含了这个key，key的删除标记也会被忽略。\n9.2.1 时间\nLevel 0的compaction最多从level 0读取4个1MB的文件，以及所有的level 1文件（10MB），也就是我们将读取14MB，并写入14BM。 Level \u0026gt; 0的compaction，从level L选择一个2MB的文件，最坏情况下，将会和levelL+1的12个文件有重合（10：level L+1的总文件大小是level L的10倍；边界的2：level L的文件范围通常不会和level L+1的文件对齐）。因此Compaction将会读26MB，写26MB。对于100MB/s的磁盘IO来讲，compaction将最坏需要0.5秒。 如果磁盘IO更低，比如10MB/s，那么compaction就需要更长的时间5秒。如果user以10MB/s的速度写入，我们可能生成很多level 0文件（50个来装载5*10MB的数据）。这将会严重影响读取效率，因为需要merge更多的文件。\n解决方法1：为了降低该问题，我们可能想增加log切换的阈值，缺点就是，log文件越大，对应的memtable文件就越大，这需要更多的内存。 解决方法2：当level 0文件太多时，人工降低写入速度。 解决方法3：降低merge的开销，如把level 0文件都无压缩的存放在cache中。\n9.2.2 文件数\n对于更高的level我们可以创建更大的文件，而不是2MB，代价就是更多突发性的compaction。或者，我们可以考虑分区，把文件放存放多目录中。 在2011年2月4号，作者做了一个实验，在ext3文件系统中打开100KB的文件，结果表明可以不需要分区。\n文件数 文件打开ms 1000 9 10000 10 100000 16\n9.3 Recovery \u0026amp; GC 9.3.1 Recovery\nDb恢复的步骤：\nS1 首先从CURRENT读取最后提交的MANIFEST S2 读取MANIFEST内容 S3 清除过期文件 S4 这里可以打开所有的sstable文件，但是更好的方案是lazy open S5 把log转换为新的level 0sstable S6 将新写操作导向到新的log文件，从恢复的序号开始 9.3.2 GC\n垃圾回收，每次compaction和recovery之后都会有文件被废弃，成为垃圾文件。GC就是删除这些文件的，它在每次compaction和recovery完成之后被调用。\n","permalink":"https://haokiu.com/blog/5a5f7db3f4fc4684a0c7ddb21dd6ea40/","summary":"leveldb源码分析14 本系列《leveldb源码分析》共有22篇文章，这是第十四篇\n9 LevelDB框架之1\n到此为止，基本上Leveldb的主要功能组件都已经分析完了，下面就是把它们组合在一起，形成一个高性能的k/v存储系统。这就是leveldb::DB类。 这里先看一下LevelDB的导出接口和涉及的类，后面将依次以接口分析的方式展开。 而实际上leveldb::DB只是一个接口类，真正的实现和框架类是DBImpl这个类，正是它集合了上面的各种组件。 此外，还有Leveldb对版本的控制，执行版本控制的是Version和VersionSet类。 在leveldb的源码中，DBImpl和VersionSet是两个庞然大物，体量基本算是最大的。对于这两个类的分析，也会分散在打开、销毁和快照等等这些功能中，很难在一个地方集中分析。 作者在文档impl.html中描述了leveldb的实现，其中包括文件组织、compaction和recovery等等。下面的9.1和9.2基本都是翻译子impl.html文档。 在进入框架代码之前，先来了解下leveldb的文件组织和管理。\n9.1 DB文件管理 9.1.1 文件类型\n对于一个数据库Level包含如下的6种文件:\n1/[0-9]+.log：db操作日志 这就是前面分析过的操作日志，log文件包含了最新的db更新，每个更新都以append的方式追加到文件结尾。当log文件达到预定大小时（缺省大约4MB），leveldb就把它转换为一个有序表（如下-2），并创建一个新的log文件。 当前的log文件在内存中的存在形式就是memtable，每次read操作都会访问memtable，以保证read读取到的是最新的数据。\n2/[0-9]+.sst：db的sstable文件 这两个就是前面分析过的静态sstable文件，sstable存储了以key排序的元素。每个元素或者是key对应的value，或者是key的删除标记（删除标记可以掩盖更老sstable文件中过期的value）。 Leveldb把sstable文件通过level的方式组织起来，从log文件中生成的sstable被放在level 0。当level 0的sstable文件个数超过设置（当前为4个）时，leveldb就把所有的level 0文件，以及有重合的level 1文件merge起来，组织成一个新的level 1文件（每个level 1文件大小为2MB）。 Level 0的SSTable文件（后缀为.sst）和Level\u0026gt;1的文件相比有特殊性：这个层级内的.sst文件，两个文件可能存在key重叠。对于Level\u0026gt;0，同层sstable文件的key不会重叠。考虑level\u0026gt;0，level中的文件的总大小超过10^level MB时（如level=1是10MB，level=2是100MB），那么level中的一个文件，以及所有level+1中和它有重叠的文件，会被merge到level+1层的一系列新文件。Merge操作的作用是将更新从低一级level迁移到最高级，只使用批量读写（最小化seek操作，提高效率）。\n3/MANIFEST-[0-9]+：DB元信息文件 它记录的是leveldb的元信息，比如DB使用的Comparator名，以及各SSTable文件的管理信息：如Level层数、文件名、最小key和最大key等等。\n4/CURRENT：记录当前正在使用的Manifest文件 它的内容就是当前的manifest文件名；因为在LevleDb的运行过程中，随着Compaction的进行，新的SSTable文件被产生，老的文件被废弃。并生成新的Manifest文件来记载sstable的变动，而CURRENT则用来记录我们关心的Manifest文件。 当db被重新打开时，leveldb总是生产一个新的manifest文件。Manifest文件使用log的格式，对服务状态的改变（新加或删除的文件）都会追加到该log中。 上面的log文件、sst文件、清单文件，末尾都带着序列号，其序号都是单调递增的（随着next_file_number从1开始递增），以保证不和之前的文件名重复。\n5/log：系统的运行日志，记录系统的运行信息或者错误日志。 6/dbtmp：临时数据库文件，repair时临时生成的。 这里就涉及到几个关键的number计数器，log文件编号，下一个文件（sstable、log和manifest）编号，sequence。 所有正在使用的文件编号，包括log、sstable和manifest都应该小于下一个文件编号计数器。 9.1.2 Level 0\n当操作log超过一定大小时（缺省是1MB），执行如下操作：\nS1 创建新的memtable和log文件，并重导向新的更新到新memtable和log中； S2 在后台： S2.1 将前一个memtable的内容dump到sstable文件； S2.2 丢弃前一个memtable； S2.3 删除旧的log文件和memtable S2.4 把创建的sstable文件放到level 0\n9.2 Compaction 当level L的总文件大小查过限制时，我们就在后台执行compaction操作。Compaction操作从level L中选择一个文件f，以及选择中所有和f有重叠的文件。如果某个level (L+1)的文件ff只是和f部分重合，compaction依然选择ff的完整内容作为输入，在compaction后f和ff都会被丢弃。 另外：因为level 0有些特殊（同层文件可能有重合），从level 0到level 1的compaction就需要特殊对待：level 0的compaction可能会选择多个level 0文件，如果它们之间有重叠。 Compaction将选择的文件内容merge起来，并生成到一系列的level (L+1)文件中，如果输出文件超过设置（2MB），就切换到新的。当输出文件的key范围太大以至于和超过10个level (L+2)文件有重合时，也会切换。后一个规则确保了level (L+1)的文件不会和过多的level (L+2)文件有重合，其后的level (L+1) compaction不会选择过多的level (L+2)文件。 老的文件会被丢弃，新创建的文件将加入到server状态中。 Compaction操作在key空间中循环执行，详细讲一点就是，对于每个level，我们记录上次compaction的ending key。Level的下一次compaction将选择ending key之后的第一个文件（如果这样的文件不存在，将会跳到key空间的开始）。 Compaction会忽略被写覆盖的值，如果更高一层的level没有文件的范围包含了这个key，key的删除标记也会被忽略。\n9.2.1 时间\nLevel 0的compaction最多从level 0读取4个1MB的文件，以及所有的level 1文件（10MB），也就是我们将读取14MB，并写入14BM。 Level \u0026gt; 0的compaction，从level L选择一个2MB的文件，最坏情况下，将会和levelL+1的12个文件有重合（10：level L+1的总文件大小是level L的10倍；边界的2：level L的文件范围通常不会和level L+1的文件对齐）。因此Compaction将会读26MB，写26MB。对于100MB/s的磁盘IO来讲，compaction将最坏需要0.5秒。 如果磁盘IO更低，比如10MB/s，那么compaction就需要更长的时间5秒。如果user以10MB/s的速度写入，我们可能生成很多level 0文件（50个来装载5*10MB的数据）。这将会严重影响读取效率，因为需要merge更多的文件。\n解决方法1：为了降低该问题，我们可能想增加log切换的阈值，缺点就是，log文件越大，对应的memtable文件就越大，这需要更多的内存。 解决方法2：当level 0文件太多时，人工降低写入速度。 解决方法3：降低merge的开销，如把level 0文件都无压缩的存放在cache中。","title":"leveldb源码分析14"},{"content":"leveldb源码分析15 本系列《leveldb源码分析》共有22篇文章，这是第十五篇\n9 LevelDB框架之2\n9.4 版本控制 当执行一次compaction后，Leveldb将在当前版本基础上创建一个新版本，当前版本就变成了历史版本。还有，如果你创建了一个Iterator，那么该Iterator所依附的版本将不会被leveldb删除。 在leveldb中，Version就代表了一个版本，它包括当前磁盘及内存中的所有文件信息。在所有的version中，只有一个是CURRENT。 VersionSet是所有Version的集合，这是个version的管理机构。 前面讲过的VersionEdit记录了Version之间的变化，相当于delta增量，表示又增加了多少文件，删除了文件。也就是说：Version0 + VersionEdit \u0026ndash;\u0026gt; Version1。 每次文件有变动时，leveldb就把变动记录到一个VersionEdit变量中，然后通过VersionEdit把变动应用到current version上，并把current version的快照，也就是db元信息保存到MANIFEST文件中。 另外，MANIFEST文件组织是以VersionEdit的形式写入的，它本身是一个log文件格式，采用log::Writer/Reader的方式读写，一个VersionEdit就是一条log record。\n9.4.1 VersionSet\n和DBImpl一样，下面就初识一下Version和VersionSet。 先来看看Version的成员：\nstd::vector\u0026lt;FileMetaData*\u0026gt;files_[config::kNumLevels]; // sstable文件列表 // Next fileto compact based on seek stats. 下一个要compact的文件 FileMetaData* file_to_compact_; int file_to_compact_level_; // 下一个应该compact的level和compaction分数. // 分数 \u0026lt; 1 说明compaction并不紧迫. 这些字段在Finalize()中初始化 double compaction_score_; int compaction_level_; 可见一个Version就是一个sstable文件集合，以及它管理的compact状态。Version通过Version* prev和*next指针构成了一个Version双向循环链表，表头指针则在VersionSet中（初始都指向自己）。 下面是VersionSet的成员。可见它除了通过Version管理所有的sstable文件外，还关心manifest文件信息，以及控制log文件等编号。\n//=== 第一组，直接来自于DBImple，构造函数传入 Env* const env_; // 操作系统封装 const std::string dbname_; const Options* const options_; TableCache* const table_cache_; // table cache const InternalKeyComparatoricmp_; //=== 第二组，db元信息相关 uint64_t next_file_number_; // log文件编号 uint64_t manifest_file_number_; // manifest文件编号 uint64_t last_sequence_; uint64_t log_number_; // log编号 uint64_t prev_log_number_; // 0 or backingstore for memtable being compacted //=== 第三组，menifest文件相关 WritableFile* descriptor_file_; log::Writer* descriptor_log_; //=== 第四组，版本管理 Version dummy_versions_; // versions双向链表head. Version* current_; // ==dummy_versions_.prev_ // level下一次compaction的开始key，空字符串或者合法的InternalKey std::stringcompact_pointer_[config::kNumLevels]; 关于版本控制大概了解其Version和VersionEdit的功能和管理范围，详细的函数操作在后面再慢慢揭开。\n9.4.2 VersionEdit\nLevelDB中对Manifest的Decode/Encode是通过类VersionEdit完成的，Menifest文件保存了LevelDB的管理元信息。VersionEdit这个名字起的蛮有意思，每一次compaction，都好比是生成了一个新的DB版本，对应的Menifest则保存着这个版本的DB元信息。VersionEdit并不操作文件，只是为Manifest文件读写准备好数据、从读取的数据中解析出DB元信息。 VersionEdit有两个作用：\n1 当版本间有增量变动时，VersionEdit记录了这种变动； 2 写入到MANIFEST时，先将current version的db元信息保存到一个VersionEdit中，然后在组织成一个log record写入文件；\n了解了VersionEdit的作用，来看看这个类导出的函数接口：\nvoid Clear(); // 清空信息 void Setxxx(); // 一系列的Set函数，设置信息 // 添加sstable文件信息，要求：DB元信息还没有写入磁盘Manifest文件 // @level：.sst文件层次；@file 文件编号-用作文件名 @size 文件大小 // @smallest, @largest：sst文件包含k/v对的最大最小key void AddFile(int level, uint64_t file, uint64_t file_size, constInternalKey\u0026amp; smallest, const InternalKey\u0026amp; largest); void DeleteFile(int level, uint64_t file); // 从指定的level删除文件 void EncodeTo(std::string* dst) const; // 将信息Encode到一个string中 Status DecodeFrom(const Slice\u0026amp; src); // 从Slice中Decode出DB元信息 //===================下面是成员变量，由此可大概窥得DB元信息的内容。 typedef std::set\u0026lt; std::pair\u0026lt;int, uint64_t\u0026gt; \u0026gt; DeletedFileSet; std::string comparator_; // key comparator名字 uint64_t log_number_; // 日志编号 uint64_t prev_log_number_; // 前一个日志编号 uint64_t next_file_number_; // 下一个文件编号 SequenceNumber last_sequence_; // 上一个seq bool has_comparator_; // 是否有comparator bool has_log_number_;// 是否有log_number_ bool has_prev_log_number_;// 是否有prev_log_number_ bool has_next_file_number_;// 是否有next_file_number_ bool has_last_sequence_;// 是否有last_sequence_ std::vector\u0026lt; std::pair\u0026lt;int, InternalKey\u0026gt; \u0026gt;compact_pointers_; // compact点 DeletedFileSet deleted_files_; // 删除文件集合 std::vector\u0026lt; std::pair\u0026lt;int, FileMetaData\u0026gt; \u0026gt; new_files_; // 新文件集合 Set系列的函数都很简单，就是根据参数设置相应的信息。 AddFile函数就是根据参数生产一个FileMetaData对象，把sstable文件信息添加到new_files_数组中。 DeleteFile函数则是把参数指定的文件添加到deleted_files中； SetCompactPointer函数把{level, key}指定的compact点加入到compact_pointers_中。 执行序列化和发序列化的是Decode和Encode函数，根据这些代码，我们可以了解Manifest文件的存储格式。序列化函数逻辑都很直观，不详细说了。\n9.4.3 Manifest文件格式\n前面说过Manifest文件记录了leveldb的管理元信息，这些元信息到底都包含哪些内容呢？下面就来一一列示。 首先是使用的coparator名、log编号、前一个log编号、下一个文件编号、上一个序列号。这些都是日志、sstable文件使用到的重要信息，这些字段不一定必然存在。 Leveldb在写入每个字段之前，都会先写入一个varint型数字来标记后面的字段类型。在读取时，先读取此字段，根据类型解析后面的信息。一共有9种类型：\nkComparator = 1, kLogNumber = 2, kNextFileNumber = 3, kLastSequence = 4, kCompactPointer = 5, kDeletedFile = 6, kNewFile = 7, kPrevLogNumber = 9 // 8 was used for large value refs 其中8另有它用。 其次是compact点，可能有多个，写入格式为**{kCompactPointer, level, internal key}。 其后是删除文件，可能有多个，格式为{kDeletedFile, level, file number}**。 最后是新文件，可能有多个，格式为 {kNewFile, level, file number, file size, min key, max key}。 对于版本间变动它是新加的文件集合，对于MANIFEST快照是该版本包含的所有sstable文件集合。 一张图表示一下，如图9.3-1所示。\n其中的数字都是varint存储格式，string都是以varint指明其长度，后面跟实际的字符串内容。\n9.5 DB接口 9.5.1 接口函数\n除了DB类， leveldb还导出了C语言风格的接口：接口和实现在c.h\u0026amp;c.cc，它其实是对leveldb::DB的一层封装。 DB是一个持久化的有序map{key, value}，它是线程安全的。DB只是一个虚基类，下面来看看其接口： 首先是一个静态函数，打开一个db，成功返回OK，打开的db指针保存在*dbptr中，用完后，调用者需要调用delete *dbptr删除之。\n1static Status Open(const Options\u0026amp; options, const std::string\u0026amp;name, DB** dbptr); 下面几个是纯虚函数，最后还有两个全局函数，为何不像Open一样作为静态函数呢。 注：在几个更新接口中，可考虑设置options.sync = true。另外，虽然是纯虚函数，但是leveldb还是提供了缺省的实现。\n// 设置db项{key, value} virtual Status Put(const WriteOptions\u0026amp; options, const Slice\u0026amp;key, const Slice\u0026amp; value) = 0; // 在db中删除\u0026#34;key\u0026#34;，key不存在依然返回成功 virtual Status Delete(const WriteOptions\u0026amp; options, const Slice\u0026amp;key) = 0; // 更新操作 virtual Status Write(const WriteOptions\u0026amp; options, WriteBatch*updates) = 0; // 获取操作，如果db中有”key”项则返回结果，没有就返回Status::IsNotFound() virtual Status Get(const ReadOptions\u0026amp; options, const Slice\u0026amp; key,std::string* value) = 0; // 返回heap分配的iterator，访问db的内容，返回的iterator的位置是invalid的 // 在使用之前，调用者必须先调用Seek。 virtual Iterator* NewIterator(const ReadOptions\u0026amp; options) = 0; // 返回当前db状态的handle，和handle一起创建的Iterator看到的都是 // 当前db状态的稳定快照。不再使用时，应该调用ReleaseSnapshot(result) virtual const Snapshot* GetSnapshot() = 0; // 释放获取的db快照 virtual voidReleaseSnapshot(const Snapshot* snapshot) = 0; // 借此方法DB实现可以展现它们的属性状态. 如果\u0026#34;property\u0026#34; 是合法的， // 设置\u0026#34;*value\u0026#34;为属性的当前状态值并返回true，否则返回false. // 合法属性名包括： // // \u0026gt;\u0026#34;leveldb.num-files-at-level\u0026lt;N\u0026gt;\u0026#34;– 返回level \u0026lt;N\u0026gt;的文件个数, // \u0026lt;N\u0026gt; 是level 数的ASCII 值 (e.g. \u0026#34;0\u0026#34;). // \u0026gt;\u0026#34;leveldb.stats\u0026#34; – 返回描述db内部操作统计的多行string // \u0026gt;\u0026#34;leveldb.sstables\u0026#34; – 返回一个多行string，描述构成db内容的所有sstable virtual bool GetProperty(constSlice\u0026amp; property, std::string* value) = 0; //\u0026#34;sizes[i]\u0026#34;保存的是\u0026#34;[range[i].start.. range[i].limit)\u0026#34;中的key使用的文件空间. // 注：返回的是文件系统的使用空间大概值， // 如果用户数据以10倍压缩，那么返回值就是对应用户数据的1/10 // 结果可能不包含最近写入的数据大小. virtual voidGetApproximateSizes(const Range* range, int n, uint64_t* sizes) = 0; // Compactkey范围[*begin,*end]的底层存储，删除和被覆盖的版本将会被抛弃 // 数据会被重新组织，以减少访问开销 // 注：那些不了解底层实现的用户不应该调用该方法。 //begin==NULL被当作db中所有key之前的key. //end==NULL被当作db中所有key之后的key. // 所以下面的调用将会compact整个db: // db-\u0026gt;CompactRange(NULL, NULL); virtual void CompactRange(constSlice* begin, const Slice* end) = 0; // 最后是两个全局函数--删除和修复DB // 要小心，该方法将删除指定db的所有内容 Status DestroyDB(const std::string\u0026amp; name, const Options\u0026amp;options); // 如果db不能打开了，你可能调用该方法尝试纠正尽可能多的数据 // 可能会丢失数据，所以调用时要小心 Status RepairDB(const std::string\u0026amp; dbname, const Options\u0026amp;options); 9.5.2 类图\n这里又会设计到几个功能类，如图9.5-1所示。此外还有前面我们讲过的几大组件：操作日志的读写类、内存MemTable类、InternalFilterPolicy类、Internal Key比较类、以及sstable的读取构建类。如图9.5-2所示。\n图9.5-1\n图9.5-2\n这里涉及的类很多，snapshot是内存快照，Version和VersionSet类。\n9.6 DBImpl类 在向下继续之前，有必要先了解下DBImpl这个具体的实现类。主要是它的成员变量，这说明了它都利用了哪些组件。 整篇代码里面，这算是一个庞然大物了。现在只是先打第一个照面吧，后面的路还很长，先来看看类成员。\n//== 第一组，他们在构造函数中初始化后将不再改变。其中，InternalKeyComparator和InternalFilterPolicy已经分别在Memtable和FilterPolicy中分析过。 Env* const env_; // 环境，封装了系统相关的文件操作、线程等等 const InternalKeyComparatorinternal_comparator_; // key comparator const InternalFilterPolicyinternal_filter_policy_; // filter policy const Options options_; //options_.comparator == \u0026amp;internal_comparator_ bool owns_info_log_; bool owns_cache_; const std::string dbname_; //== 第二组，只有两个。 TableCache* table_cache_; // Table cache，线程安全的 FileLock* db_lock_;// 锁db文件，persistent state，直到leveldb进程结束 //== 第三组，被mutex_包含的状态和成员 port::Mutex mutex_; // 互斥锁 port::AtomicPointershutting_down_; port::CondVar bg_cv_; // 在background work结束时激发 MemTable* mem_; MemTable* imm_; // Memtablebeing compacted port::AtomicPointerhas_imm_; // BGthread 用来检查是否是非NULL的imm_ // 这三个是log相关的 WritableFile* logfile_; // log文件 uint64_t logfile_number_; // log文件编号 log::Writer* log_; // log writer //== 第四组，没有规律 std::deque\u0026lt;Writer*\u0026gt;writers_; // writers队列. WriteBatch* tmp_batch_; SnapshotList snapshots_; //snapshot列表 // Setof table files to protect from deletion because they are // part ofongoing compactions. std::set\u0026lt;uint64_t\u0026gt;pending_outputs_; // 待copact的文件列表，保护以防误删 bool bg_compaction_scheduled_; // 是否有后台compaction在调度或者运行? Status bg_error_; // paranoid mode下是否有后台错误? ManualCompaction*manual_compaction_; // 手动compaction信息 CompactionStatsstats_[config::kNumLevels]; // compaction状态 VersionSet* versions_; // 多版本DB文件，又一个庞然大物 ","permalink":"https://haokiu.com/blog/bd56540c7f464f2e8e9392c3903b27f5/","summary":"leveldb源码分析15 本系列《leveldb源码分析》共有22篇文章，这是第十五篇\n9 LevelDB框架之2\n9.4 版本控制 当执行一次compaction后，Leveldb将在当前版本基础上创建一个新版本，当前版本就变成了历史版本。还有，如果你创建了一个Iterator，那么该Iterator所依附的版本将不会被leveldb删除。 在leveldb中，Version就代表了一个版本，它包括当前磁盘及内存中的所有文件信息。在所有的version中，只有一个是CURRENT。 VersionSet是所有Version的集合，这是个version的管理机构。 前面讲过的VersionEdit记录了Version之间的变化，相当于delta增量，表示又增加了多少文件，删除了文件。也就是说：Version0 + VersionEdit \u0026ndash;\u0026gt; Version1。 每次文件有变动时，leveldb就把变动记录到一个VersionEdit变量中，然后通过VersionEdit把变动应用到current version上，并把current version的快照，也就是db元信息保存到MANIFEST文件中。 另外，MANIFEST文件组织是以VersionEdit的形式写入的，它本身是一个log文件格式，采用log::Writer/Reader的方式读写，一个VersionEdit就是一条log record。\n9.4.1 VersionSet\n和DBImpl一样，下面就初识一下Version和VersionSet。 先来看看Version的成员：\nstd::vector\u0026lt;FileMetaData*\u0026gt;files_[config::kNumLevels]; // sstable文件列表 // Next fileto compact based on seek stats. 下一个要compact的文件 FileMetaData* file_to_compact_; int file_to_compact_level_; // 下一个应该compact的level和compaction分数. // 分数 \u0026lt; 1 说明compaction并不紧迫. 这些字段在Finalize()中初始化 double compaction_score_; int compaction_level_; 可见一个Version就是一个sstable文件集合，以及它管理的compact状态。Version通过Version* prev和*next指针构成了一个Version双向循环链表，表头指针则在VersionSet中（初始都指向自己）。 下面是VersionSet的成员。可见它除了通过Version管理所有的sstable文件外，还关心manifest文件信息，以及控制log文件等编号。\n//=== 第一组，直接来自于DBImple，构造函数传入 Env* const env_; // 操作系统封装 const std::string dbname_; const Options* const options_; TableCache* const table_cache_; // table cache const InternalKeyComparatoricmp_; //=== 第二组，db元信息相关 uint64_t next_file_number_; // log文件编号 uint64_t manifest_file_number_; // manifest文件编号 uint64_t last_sequence_; uint64_t log_number_; // log编号 uint64_t prev_log_number_; // 0 or backingstore for memtable being compacted //=== 第三组，menifest文件相关 WritableFile* descriptor_file_; log::Writer* descriptor_log_; //=== 第四组，版本管理 Version dummy_versions_; // versions双向链表head.","title":"leveldb源码分析15"},{"content":"Leveldb源码分析16 本系列《leveldb源码分析》共有22篇文章，这是第十六篇\n10.Version分析之一 先来分析leveldb对单版本的sstable文件管理，主要集中在Version类中。前面的10.4节已经说明了Version类的功能和成员，这里分析其函数接口和代码实现。 Version不会修改其管理的sstable文件，只有读取操作。\n10.1 Version接口 先来看看Version类的接口函数，接下来再一一分析。\n// 追加一系列iterator到 @*iters中， //将在merge到一起时生成该Version的内容 // 要求: Version已经保存了(见VersionSet::SaveTo) void AddIterators(constReadOptions\u0026amp;, std::vector\u0026lt;Iterator*\u0026gt;* iters); // 给定@key查找value，如果找到保存在@*val并返回OK。 // 否则返回non-OK，设置@ *stats. // 要求：没有hold lock struct GetStats { FileMetaData* seek_file; int seek_file_level; }; Status Get(constReadOptions\u0026amp;, const LookupKey\u0026amp; key, std::string* val,GetStats* stats); // 把@stats加入到当前状态中，如果需要触发新的compaction返回true // 要求：hold lock bool UpdateStats(constGetStats\u0026amp; stats); void GetOverlappingInputs(intlevel, const InternalKey*begin, // NULL 指在所有key之前 const InternalKey* end, // NULL指在所有key之后 std::vector\u0026lt;FileMetaData*\u0026gt;* inputs); // 如果指定level中的某些文件和[*smallest_user_key,*largest_user_key] //有重合就返回true。 // @smallest_user_key==NULL表示比DB中所有key都小的key. // @largest_user_key==NULL表示比DB中所有key都大的key. bool OverlapInLevel(int level,const Slice*smallest_user_key, const Slice* largest_user_key); // 返回我们应该在哪个level上放置新的memtable compaction， // 该compaction覆盖了范围[smallest_user_key,largest_user_key]. int PickLevelForMemTableOutput(const Slice\u0026amp; smallest_user_key, const Slice\u0026amp; largest_user_key); // 指定level的sstable个数 int NumFiles(int level) const {return files_[level].size(); 10.2 Version::AddIterators() 该函数最终在DB::NewIterators()接口中被调用，调用层次为： DBImpl::NewIterator()-\u0026gt;DBImpl::NewInternalIterator()-\u0026gt;Version::AddIterators()。 函数功能是为该Version中的所有sstable都创建一个Two Level Iterator，以遍历sstable的内容。\n对于level=0级别的sstable文件，直接通过TableCache::NewIterator()接口创建，这会直接载入sstable文件到内存cache中。 对于level\u0026gt;0级别的sstable文件，通过函数NewTwoLevelIterator()创建一个TwoLevelIterator，这就使用了lazy open的机制。 下面来分析函数代码：\nS1 对于level=0级别的sstable文件，直接装入cache，level0的sstable文件可能有重合，需要merge。 for (size_t i = 0; i \u0026lt;files_[0].size(); i++) { iters-\u0026gt;push_back(vset_-\u0026gt;table_cache_-\u0026gt;NewIterator(// versionset::table_cache_ options,files_[0][i]-\u0026gt;number, files_[0][i]-\u0026gt;file_size)); } S2 对于level\u0026gt;0级别的sstable文件，lazy open机制，它们不会有重叠。 for (int ll = 1; ll \u0026lt;config::kNumLevels; ll++) { if(!files_[ll].empty()) iters-\u0026gt;push_back(NewConcatenatingIterator(options,level)); } 函数NewConcatenatingIterator()直接返回一个TwoLevelIterator对象：\nreturn NewTwoLevelIterator(new LevelFileNumIterator(vset_-\u0026gt;icmp_,\u0026amp;files_[level]), \u0026amp;GetFileIterator,vset_-\u0026gt;table_cache_, options); 其第一级iterator是一个LevelFileNumIterator 第二级的迭代函数是GetFileIterator 下面就来分别分析之。 GetFileIterator是一个静态函数，很简单，直接返回TableCache::NewIterator()。函数声明为：\nstatic Iterator* GetFileIterator(void* arg,const ReadOptions\u0026amp; options, constSlice\u0026amp; file_value) TableCache* cache =reinterpret_cast\u0026lt;TableCache*\u0026gt;(arg); if (file_value.size() != 16) { // 错误 return NewErrorIterator(Status::Corruption(\u0026#34;xxx\u0026#34;)); } else { return cache-\u0026gt;NewIterator(options, DecodeFixed64(file_value.data()), // filenumber DecodeFixed64(file_value.data() + 8)); // filesize } 这里的file_value是取自于LevelFileNumIterator的value，它的value()函数把file number和size以Fixed 8byte的方式压缩成一个Slice对象并返回。\n10.3 Version::LevelFileNumIterator类 这也是一个继承者Iterator的子类，一个内部Iterator。\n给定一个version/level对，生成该level内的文件信息。\n对于给定的entry：\nkey()返回的是文件中所包含的最大的key； value()返回的是|file number(8 bytes)|file size(8 bytes)|串； 它的构造函数接受两个参数：InternalKeyComparator\u0026amp;，用于key的比较； vector\u0026lt;FileMetaData*\u0026gt;*，指向version的所有sstable文件列表。 LevelFileNumIterator(const InternalKeyComparator\u0026amp; icmp, const std::vector\u0026lt;FileMetaData*\u0026gt;* flist) : icmp_(icmp), flist_(flist),index_(flist-\u0026gt;size()) {} // Marks as invalid 来看看其接口实现，不限啰嗦，全部都列出来。\nValid函数、SeekToxx和Next/Prev函数都很简单，毕竟容器是一个vector。Seek函数调用了FindFile，这个函数后面会分析。\nvirtual void Seek(constSlice\u0026amp; target) { index_ = FindFile(icmp_, *flist_, target);} virtual void SeekToFirst() {index_ = 0; } virtual void SeekToLast() {index_ = flist_-\u0026gt;empty() ? 0 : flist_-\u0026gt;size() - 1;} virtual void Next() { assert(Valid()); index_++; } virtual void Prev() { assert(Valid()); if (index_ == 0) index_ =flist_-\u0026gt;size(); // Marks as invalid else index_--; } Slice key() const { assert(Valid()); return(*flist_)[index_]-\u0026gt;largest.Encode(); // 返回当前sstable包含的largest key } Slice value() const { // 根据|number|size|的格式Fixed int压缩 assert(Valid()); EncodeFixed64(value_buf_,(*flist_)[index_]-\u0026gt;number); EncodeFixed64(value_buf_+8,(*flist_)[index_]-\u0026gt;file_size); return Slice(value_buf_,sizeof(value_buf_)); } 来看FindFile，这其实是一个二分查找函数，因为传入的sstable文件列表是有序的，因此可以使用二分查找算法。就不再列出代码了。\n10.4 Version::Get() 查找函数，直接在DBImpl::Get()中被调用，函数原型为：\nStatus Version::Get(const ReadOptions\u0026amp; options, constLookupKey\u0026amp; k, std::string* value, GetStats* stats) 如果本次Get不止seek了一个文件（仅会发生在level 0的情况），就将搜索的第一个文件保存在stats中。如果stat有数据返回，表明本次读取在搜索到包含key的sstable文件之前，还做了其它无谓的搜索。这个结果将用在UpdateStats()中。 这个函数逻辑还是有些复杂的，来看看代码。\nS1 首先，取得必要的信息，初始化几个临时变量 Slice ikey = k.internal_key(); Slice user_key = k.user_key(); const Comparator* ucmp =vset_-\u0026gt;icmp_.user_comparator(); Status s; stats-\u0026gt;seek_file = NULL; stats-\u0026gt;seek_file_level = -1; FileMetaData* last_file_read =NULL; // 在找到\u0026gt;1个文件时，读取时记录上一个 int last_file_read_level = -1; // 这仅发生在level 0的情况下 std::vector\u0026lt;FileMetaData*\u0026gt;tmp; FileMetaData* tmp2; S2 从0开始遍历所有的level，依次查找。因为entry不会跨越level，因此如果在某个level中找到了entry，那么就无需在后面的level中查找了。 for (int level = 0; level \u0026lt;config::kNumLevels; level++) { size_t num_files = files_[level].size(); if (num_files == 0) continue; // 本层没有文件，则直接跳过 // 取得level下的所有sstable文件列表，搜索本层 FileMetaData* const* files = \u0026amp;files_[level][0]; 后面的所有逻辑都在for循环体中。\nS3 遍历level下的sstable文件列表，搜索，注意对于level=0和\u0026gt;0的sstable文件的处理，由于level 0文件之间的key可能有重叠，因此处理逻辑有别于\u0026gt;0的level。 S3.1 对于level 0，文件可能有重叠，找到所有和user_key有重叠的文件，然后根据时间顺序从最新的文件依次处理。 tmp.reserve(num_files); for (uint32_t i = 0; i \u0026lt;num_files; i++) { // 遍历level 0下的所有sstable文件 FileMetaData* f =files[i]; if(ucmp-\u0026gt;Compare(user_key, f-\u0026gt;smallest.user_key()) \u0026gt;= 0 \u0026amp;\u0026amp; ucmp-\u0026gt;Compare(user_key, f-\u0026gt;largest.user_key()) \u0026lt;= 0) tmp.push_back(f); // sstable文件有user_key有重叠 } if (tmp.empty()) continue; std::sort(tmp.begin(),tmp.end(), NewestFirst); // 排序 files = \u0026amp;tmp[0]; num_files= tmp.size();// 指向tmp指针和大小 S3.2 对于level\u0026gt;0，leveldb保证sstable文件之间不会有重叠，所以处理逻辑有别于level 0，直接根据ikey定位到sstable文件即可。 //二分查找，找到第一个largest key \u0026gt;=ikey的file index uint32_t index =FindFile(vset_-\u0026gt;icmp_, files_[level], ikey); if (index \u0026gt;= num_files) { // 未找到，文件不存在 files = NULL; num_files = 0; } else { tmp2 = files[index]; if(ucmp-\u0026gt;Compare(user_key, tmp2-\u0026gt;smallest.user_key()) \u0026lt; 0) { // 找到的文件其所有key都大于user_key，等于文件不存在 files = NULL; num_files = 0; } else { files = \u0026amp;tmp2; num_files = 1; } } S4 遍历找到的文件，存在files中，其个数为num_files。 for (uint32_t i = 0; i \u0026lt;num_files; ++i) { 后面的逻辑都在这一层循环中，只要在某个文件中找到了k/v对，就跳出for循环。\nS4.1 如果本次读取不止搜索了一个文件，记录之，这仅会发生在level 0的情况下。 if(last_file_read != NULL \u0026amp;\u0026amp; stats-\u0026gt;seek_file == NULL) { // 本次读取不止seek了一个文件，记录第一个 stats-\u0026gt;seek_file =last_file_read; stats-\u0026gt;seek_file_level= last_file_read_level; } FileMetaData* f = files[i]; last_file_read = f; // 记录本次读取的level和file last_file_read_level =level; S4.2 调用TableCache::Get()尝试获取{ikey, value}，如果返回OK则进入，否则直接返回，传递的回调函数是SaveValue()。 Saver saver; // 初始化saver saver.state = kNotFound; saver.ucmp = ucmp; saver.user_key = user_key; saver.value = value; s = vset_-\u0026gt;table_cache_-\u0026gt;Get(options,f-\u0026gt;number, f-\u0026gt;file_size, ikey, \u0026amp;saver, SaveValue); if (!s.ok()) return s; S4.3 根据saver的状态判断，如果是Not Found则向下搜索下一个更早的sstable文件，其它值则返回。 switch (saver.state) { case kNotFound: break; // 继续搜索下一个更早的sstable文件 case kFound: return s; // 找到 case kDeleted: // 已删除 s =Status::NotFound(Slice()); // 为了效率，使用空的错误字符串 return s; case kCorrupt: // 数据损坏 s =Status::Corruption(\u0026#34;corrupted key for \u0026#34;, user_key); return s; } 以上就是Version::Get()的代码逻辑，如果level 0的sstable文件太多的话，会影响读取速度，这也是为什么进行compaction的原因。 另外，还有一个传递给TableCache::Get()的saver函数，下面就来简单分析下。这是一个静态函数：static void SaveValue(void* arg,const Slice\u0026amp; ikey, const Slice\u0026amp; v)。它内部使用了结构体Saver：\nstruct Saver { SaverState state; const Comparator* ucmp; // user key比较器 Slice user_key; std::string* value; }; 函数SaveValue的逻辑很简单。首先解析Table传入的InternalKey，然后根据指定的Comparator判断user key是否是要查找的user key。如果是并且type是kTypeValue，则设置到Saver::*value中，并返回kFound，否则返回kDeleted。代码如下：\nSaver* s =reinterpret_cast\u0026lt;Saver*\u0026gt;(arg); ParsedInternalKey parsed_key; // 解析ikey到ParsedInternalKey if (!ParseInternalKey(ikey,\u0026amp;parsed_key)) s-\u0026gt;state = kCorrupt; // 解析失败 else { if(s-\u0026gt;ucmp-\u0026gt;Compare(parsed_key.user_key, s-\u0026gt;user_key) == 0) { // 比较user key s-\u0026gt;state =(parsed_key.type == kTypeValue) ? kFound : kDeleted; if (s-\u0026gt;state == kFound) s-\u0026gt;value-\u0026gt;assign(v.data(), v.size()); // 找到，保存结果 } } 下面要分析的几个函数，或多或少都和compaction相关。\n","permalink":"https://haokiu.com/blog/383f27c1087943b39b255aa993d7b9ac/","summary":"Leveldb源码分析16 本系列《leveldb源码分析》共有22篇文章，这是第十六篇\n10.Version分析之一 先来分析leveldb对单版本的sstable文件管理，主要集中在Version类中。前面的10.4节已经说明了Version类的功能和成员，这里分析其函数接口和代码实现。 Version不会修改其管理的sstable文件，只有读取操作。\n10.1 Version接口 先来看看Version类的接口函数，接下来再一一分析。\n// 追加一系列iterator到 @*iters中， //将在merge到一起时生成该Version的内容 // 要求: Version已经保存了(见VersionSet::SaveTo) void AddIterators(constReadOptions\u0026amp;, std::vector\u0026lt;Iterator*\u0026gt;* iters); // 给定@key查找value，如果找到保存在@*val并返回OK。 // 否则返回non-OK，设置@ *stats. // 要求：没有hold lock struct GetStats { FileMetaData* seek_file; int seek_file_level; }; Status Get(constReadOptions\u0026amp;, const LookupKey\u0026amp; key, std::string* val,GetStats* stats); // 把@stats加入到当前状态中，如果需要触发新的compaction返回true // 要求：hold lock bool UpdateStats(constGetStats\u0026amp; stats); void GetOverlappingInputs(intlevel, const InternalKey*begin, // NULL 指在所有key之前 const InternalKey* end, // NULL指在所有key之后 std::vector\u0026lt;FileMetaData*\u0026gt;* inputs); // 如果指定level中的某些文件和[*smallest_user_key,*largest_user_key] //有重合就返回true。 // @smallest_user_key==NULL表示比DB中所有key都小的key. // @largest_user_key==NULL表示比DB中所有key都大的key. bool OverlapInLevel(int level,const Slice*smallest_user_key, const Slice* largest_user_key); // 返回我们应该在哪个level上放置新的memtable compaction， // 该compaction覆盖了范围[smallest_user_key,largest_user_key]. int PickLevelForMemTableOutput(const Slice\u0026amp; smallest_user_key, const Slice\u0026amp; largest_user_key); // 指定level的sstable个数 int NumFiles(int level) const {return files_[level].size(); 10.2 Version::AddIterators() 该函数最终在DB::NewIterators()接口中被调用，调用层次为： DBImpl::NewIterator()-\u0026gt;DBImpl::NewInternalIterator()-\u0026gt;Version::AddIterators()。 函数功能是为该Version中的所有sstable都创建一个Two Level Iterator，以遍历sstable的内容。","title":"Leveldb源码分析16"},{"content":"leveldb源码分析17 本系列《leveldb源码分析》共有22篇文章，这是第十七篇\n10 Version分析之2\n10.5 Version::UpdateStats() 当Get操作直接搜寻memtable没有命中时，就需要调用Version::Get()函数从磁盘load数据文件并查找。如果此次Get不止seek了一个文件，就记录第一个文件到stat并返回。其后leveldb就会调用UpdateStats(stat)。 Stat表明在指定key range查找key时，都要先seek此文件，才能在后续的sstable文件中找到key。 该函数是将stat记录的sstable文件的allowed_seeks减1，减到0就执行compaction。也就是说如果文件被seek的次数超过了限制，表明读取效率已经很低，需要执行compaction了。所以说allowed_seeks是对compaction流程的有一个优化。 函数声明：boolVersion::UpdateStats(const GetStats\u0026amp; stats) 函数逻辑很简单：\nFileMetaData* f =stats.seek_file; if (f != NULL) { f-\u0026gt;allowed_seeks--; if (f-\u0026gt;allowed_seeks \u0026lt;=0 \u0026amp;\u0026amp; file_to_compact_ == NULL) { file_to_compact_ = f; file_to_compact_level_ =stats.seek_file_level; return true; } } return false; 变量allowed_seeks的值在sstable文件加入到version时确定，也就是后面将遇到的VersionSet::Builder::Apply()函数。\n10.6 Version::GetOverlappingInputs() 它在指定level中找出和**[begin, end]**有重合的sstable文件，函数声明为：\nvoid Version::GetOverlappingInputs(int level, const InternalKey* begin, constInternalKey* end, std::vector\u0026lt;FileMetaData*\u0026gt;* inputs); 要注意的是，对于level0，由于文件可能有重合，其处理具有特殊性。当在level 0中找到有sstable文件和**[begin, end]**重合时，会相应的将begin/end扩展到文件的min key/max key，然后重新开始搜索。 了解了功能，下面分析函数实现代码，逻辑还是很直观的。 S1 首先根据参数初始化查找变量。\ninputs-\u0026gt;clear(); Slice user_begin, user_end; if (begin != NULL) user_begin =begin-\u0026gt;user_key(); if (end != NULL) user_end = end-\u0026gt;user_key(); const Comparator* user_cmp =vset_-\u0026gt;icmp_.user_comparator(); S2 遍历该层的sstable文件，比较sstable的**{minkey,max key}和传入的[begin, end]**，如果有重合就记录文件到@inputs中，需要对level 0做特殊处理。\nfor (size_t i = 0; i \u0026lt;files_[level].size(); ) { FileMetaData* f =files_[level][i++]; const Slice file_start =f-\u0026gt;smallest.user_key(); const Slice file_limit =f-\u0026gt;largest.user_key(); if (begin != NULL \u0026amp;\u0026amp;user_cmp-\u0026gt;Compare(file_limit, user_begin) \u0026lt; 0) { //\u0026#34;f\u0026#34; 中的k/v全部在指定范围之前; 跳过 } else if (end != NULL\u0026amp;\u0026amp; user_cmp-\u0026gt;Compare(file_start, user_end) \u0026gt; 0) { //\u0026#34;f\u0026#34; 中的k/v全部在指定范围之后; 跳过 } else { inputs-\u0026gt;push_back(f); // 有重合，记录 if (level == 0) { // 对于level 0，sstable文件可能相互有重叠，所以要检查新加的文件 // 是否范围更大，如果是则扩展范围重新开始搜索 if (begin != NULL\u0026amp;\u0026amp; user_cmp-\u0026gt;Compare(file_start, user_begin) \u0026lt; 0) { user_begin = file_start; inputs-\u0026gt;clear(); i = 0; } else if (end != NULL\u0026amp;\u0026amp; user_cmp-\u0026gt;Compare(file_limit, user_end) \u0026gt; 0) { user_end = file_limit; inputs-\u0026gt;clear(); i = 0; } } } } 10.7 Version::OverlapInLevel() 检查是否和指定level的文件有重合，该函数直接调用了SomeFileOverlapsRange()，这两个函数的声明为：\nbool Version::OverlapInLevel(int level,const Slice*smallest_user_key, const Slice* largest_user_key){ return SomeFileOverlapsRange(vset_-\u0026gt;icmp_,(level \u0026gt; 0), files_[level], smallest_user_key, largest_user_key); } bool SomeFileOverlapsRange(const InternalKeyComparator\u0026amp; icmp, bool disjoint_sorted_files, const std::vector\u0026lt;FileMetaData*\u0026gt;\u0026amp; files,const Slice*smallest_user_key, const Slice* largest_user_key); 所以下面直接分析SomeFileOverlapsRange()函数的逻辑，代码很直观。 disjoint_sorted_files=true，表明文件集合是互不相交、有序的，对于乱序的、可能有交集的文件集合，需要逐个查找，找到有重合的就返回true；对于有序、互不相交的文件集合，直接执行二分查找。\n// S1 乱序、可能相交的文件集合，依次查找 for (size_t i = 0; i \u0026lt;files.size(); i++) { const FileMetaData* f =files[i]; if(AfterFile(ucmp,smallest_user_key, f) || BeforeFile(ucmp, largest_user_key, f)){ } else return true; // 有重合 } // S2 有序\u0026amp;互不相交，直接二分查找 uint32_t index = 0; if (smallest_user_key != NULL) { // Findthe earliest possible internal key smallest_user_key InternalKeysmall(*smallest_user_key, kMaxSequenceNumber,kValueTypeForSeek); index = FindFile(icmp, files,small.Encode()); } if (index \u0026gt;= files.size()) // 不存在比smallest_user_key小的key return false; //保证在largest_user_key之后 return !BeforeFile(ucmp,largest_user_key, files[index]); 上面的逻辑使用到了AfterFile()和BeforeFile()两个辅助函数，都很简单。\nstatic bool AfterFile(const Comparator* ucmp, const Slice* user_key, constFileMetaData* f) { return (user_key!=NULL\u0026amp;\u0026amp; ucmp-\u0026gt;Compare(*user_key, f-\u0026gt;largest.user_key())\u0026gt;0); } static bool BeforeFile(const Comparator* ucmp, constSlice* user_key, const FileMetaData* f) { return (user_key!=NULL\u0026amp;\u0026amp; ucmp-\u0026gt;Compare(*user_key, f-\u0026gt;smallest.user_key())\u0026lt;0); } 10.8 Version::PickLevelForMemTableOutput() 函数返回我们应该在哪个level上放置新的memtable compaction，这个compaction覆盖了范围**[smallest_user_key,largest_user_key]**。 该函数的调用链为：\nDBImpl::RecoverLogFile/DBImpl::CompactMemTable -\u0026gt; DBImpl:: WriteLevel0Table-\u0026gt;Version::PickLevelForMemTableOutput; 函数声明如下：\nint Version::PickLevelForMemTableOutput(const Slice\u0026amp; smallest_user_key, constSlice\u0026amp; largest_user_key); 如果level 0没有找到重合就向下一层找，最大查找层次为kMaxMemCompactLevel = 2。如果在level 0or1找到了重合，就返回level 0。否则查找level 2，如果level 2有重合就返回level 1，否则返回level 2。 函数实现：\nint level = 0; //level 0无重合 if (!OverlapInLevel(0,\u0026amp;smallest_user_key, \u0026amp;largest_user_key)) { // 如果下一层没有重叠，就压到下一层， // andthe #bytes overlapping in the level after that are limited. InternalKeystart(smallest_user_key, kMaxSequenceNumber, kValueTypeForSeek); InternalKeylimit(largest_user_key, 0, static_cast\u0026lt;ValueType\u0026gt;(0)); std::vector\u0026lt;FileMetaData*\u0026gt; overlaps; while (level \u0026lt;config::kMaxMemCompactLevel) { if (OverlapInLevel(level +1, \u0026amp;smallest_user_key, \u0026amp;largest_user_key)) break; // 检查level + 1层，有重叠就跳出循环 GetOverlappingInputs(level +2, \u0026amp;start, \u0026amp;limit, \u0026amp;overlaps); // 没理解这个调用 const int64_t sum =TotalFileSize(overlaps); if (sum \u0026gt;kMaxGrandParentOverlapBytes) break; level++; } } return level; 这个函数在整个compaction逻辑中的作用在分析DBImpl时再来结合整个流程分析，现在只需要了解它找到一个level存放新的compaction就行了。 如果返回level = 0，表明在level 0或者1和指定的range有重叠；如果返回1，表明在level2和指定的range有重叠；否则就返回2（kMaxMemCompactLevel）。 也就是说在compactmemtable的时候，写入的sstable文件不一定总是在level 0，如果比较顺利，没有重合的，它可能会写到level1或者level2中。\n10.9 小结 Version是管理某个版本的所有sstable的类，就其导出接口而言，无非是遍历sstable，查找k/v。以及为compaction做些事情，给定range，检查重叠情况。 而它不会修改它管理的sstable这些文件，对这些文件而言它是只读操作接口。\n","permalink":"https://haokiu.com/blog/0d1705067c1d403889b748a57e0b3af5/","summary":"leveldb源码分析17 本系列《leveldb源码分析》共有22篇文章，这是第十七篇\n10 Version分析之2\n10.5 Version::UpdateStats() 当Get操作直接搜寻memtable没有命中时，就需要调用Version::Get()函数从磁盘load数据文件并查找。如果此次Get不止seek了一个文件，就记录第一个文件到stat并返回。其后leveldb就会调用UpdateStats(stat)。 Stat表明在指定key range查找key时，都要先seek此文件，才能在后续的sstable文件中找到key。 该函数是将stat记录的sstable文件的allowed_seeks减1，减到0就执行compaction。也就是说如果文件被seek的次数超过了限制，表明读取效率已经很低，需要执行compaction了。所以说allowed_seeks是对compaction流程的有一个优化。 函数声明：boolVersion::UpdateStats(const GetStats\u0026amp; stats) 函数逻辑很简单：\nFileMetaData* f =stats.seek_file; if (f != NULL) { f-\u0026gt;allowed_seeks--; if (f-\u0026gt;allowed_seeks \u0026lt;=0 \u0026amp;\u0026amp; file_to_compact_ == NULL) { file_to_compact_ = f; file_to_compact_level_ =stats.seek_file_level; return true; } } return false; 变量allowed_seeks的值在sstable文件加入到version时确定，也就是后面将遇到的VersionSet::Builder::Apply()函数。\n10.6 Version::GetOverlappingInputs() 它在指定level中找出和**[begin, end]**有重合的sstable文件，函数声明为：\nvoid Version::GetOverlappingInputs(int level, const InternalKey* begin, constInternalKey* end, std::vector\u0026lt;FileMetaData*\u0026gt;* inputs); 要注意的是，对于level0，由于文件可能有重合，其处理具有特殊性。当在level 0中找到有sstable文件和**[begin, end]**重合时，会相应的将begin/end扩展到文件的min key/max key，然后重新开始搜索。 了解了功能，下面分析函数实现代码，逻辑还是很直观的。 S1 首先根据参数初始化查找变量。\ninputs-\u0026gt;clear(); Slice user_begin, user_end; if (begin != NULL) user_begin =begin-\u0026gt;user_key(); if (end != NULL) user_end = end-\u0026gt;user_key(); const Comparator* user_cmp =vset_-\u0026gt;icmp_.user_comparator(); S2 遍历该层的sstable文件，比较sstable的**{minkey,max key}和传入的[begin, end]**，如果有重合就记录文件到@inputs中，需要对level 0做特殊处理。\nfor (size_t i = 0; i \u0026lt;files_[level].size(); ) { FileMetaData* f =files_[level][i++]; const Slice file_start =f-\u0026gt;smallest.","title":"leveldb源码分析17"},{"content":"leveldb源码分析18 本系列《leveldb源码分析》共有22篇文章，这是第十八篇\n11 VersionSet分析之1 Version之后就是VersionSet，它并不是Version的简单集合，还肩负了不少的处理逻辑。这里的分析不涉及到compaction相关的部分，这部分会单独分析。包括log等各种编号计数器，compaction点的管理等等。\n11.1 VersionSet接口 1 首先是构造函数，VersionSet会使用到TableCache，这个是调用者传入的。TableCache用于Get k/v操作。\nVersionSet(const std::string\u0026amp; dbname, const Options* options, TableCache*table_cache, const InternalKeyComparator*); VersionSet的构造函数很简单，除了根据参数初始化，还有两个地方值得注意： N1 next_file_number_从2开始； N2 创建新的Version并加入到Version链表中，并设置CURRENT=新创建version； 其它的数字初始化为0，指针初始化为NULL。 2 恢复函数，从磁盘恢复最后保存的元信息\nStatus Recover(); 3 标记指定的文件编号已经被使用了\nvoid MarkFileNumberUsed(uint64_t number); 逻辑很简单，就是根据编号更新文件编号计数器：\nif (next_file_number_ \u0026lt;= number) next_file_number_ = number + 1; 4 在current version上应用指定的VersionEdit，生成新的MANIFEST信息，保存到磁盘上，并用作current version。 要求：没有其它线程并发调用；要用于mu；\nStatus LogAndApply(VersionEdit* edit, port::Mutex* mu)EXCLUSIVE_LOCKS_REQUIRED(mu); 5 对于@v中的@key，返回db中的大概位置\nuint64_t ApproximateOffsetOf(Version* v, const InternalKey\u0026amp; key); 6 其它一些简单接口，信息获取或者设置，如下：\n//返回current version Version* current() const { return current_; } // 当前的MANIFEST文件号 uint64_t ManifestFileNumber() const { return manifest_file_number_; } // 分配并返回新的文件编号 uint64_t NewFileNumber() { return next_file_number_++; } // 返回当前log文件编号 uint64_t LogNumber() const { return log_number_; } // 返回正在compact的log文件编号，如果没有返回0 uint64_t PrevLogNumber() const { return prev_log_number_; } // 获取、设置last sequence，set时不能后退 uint64_t LastSequence() const { return last_sequence_; } void SetLastSequence(uint64_t s) { assert(s \u0026gt;=last_sequence_); last_sequence_ = s; } // 返回指定level中所有sstable文件大小的和 int64_t NumLevelBytes(int level) const; // 返回指定level的文件个数 int NumLevelFiles(int level) const; // 重用@file_number，限制很严格：@file_number必须是最后分配的那个 // 要求: @file_number是NewFileNumber()返回的. void ReuseFileNumber(uint64_t file_number) { if (next_file_number_ ==file_number + 1) next_file_number_ = file_number; } // 对于所有level\u0026gt;0，遍历文件，找到和下一层文件的重叠数据的最大值(in bytes) // 这个就是Version:: GetOverlappingInputs()函数的简单应用 int64_t MaxNextLevelOverlappingBytes(); // 获取函数，把所有version的所有level的文件加入到@live中 void AddLiveFiles(std::set\u0026lt;uint64_t\u0026gt;* live); // 返回一个可读的单行信息——每个level的文件数，保存在*scratch中 struct LevelSummaryStorage {char buffer[100]; }; const char* LevelSummary(LevelSummaryStorage* scratch) const; 下面就来分析这两个接口Recover、LogAndApply以及ApproximateOffsetOf。\n11.2 VersionSet::Builder类 Builder是一个内部辅助类，其主要作用是： 1 把一个MANIFEST记录的元信息应用到版本管理器VersionSet中； 2 把当前的版本状态设置到一个Version对象中。\n11.2.1 成员与构造\nBuilder的vset_与base_都是调用者传入的，此外它还为FileMetaData定义了一个比较类BySmallestKey，首先依照文件的min key，小的在前；如果min key相等则file number小的在前。\ntypedefstd::set\u0026lt;FileMetaData*, BySmallestKey\u0026gt; FileSet; // 这个是记录添加和删除的文件 struct LevelState { std::set\u0026lt;uint64_t\u0026gt;deleted_files; // 保证添加文件的顺序是有效定义的 FileSet* added_files; }; VersionSet* vset_; Version* base_; LevelStatelevels_[config::kNumLevels]; // 其接口有3个： void Apply(VersionEdit* edit); void SaveTo(Version* v); void MaybeAddFile(Version* v, int level, FileMetaData* f); 构造函数执行简单的初始化操作，在析构时，遍历检查LevelState::added_files，如果文件引用计数为0，则删除文件。\n11.2.2 Apply()\n函数声明：voidApply(VersionEdit* edit)，该函数将edit中的修改应用到当前状态中。注意除了compaction点直接修改了vset_，其它删除和新加文件的变动只是先存储在Builder自己的成员变量中，在调用SaveTo(v)函数时才施加到v上。\nS1 把edit记录的compaction点应用到当前状态\nedit-\u0026gt;compact_pointers_ =\u0026gt; vset_-\u0026gt;compact_pointer_ S2 把edit记录的已删除文件应用到当前状态\nedit-\u0026gt;deleted_files_ =\u0026gt; levels_[level].deleted_files S3把edit记录的新加文件应用到当前状态，这里会初始化文件的allowed_seeks值，以在文件被无谓seek指定次数后自动执行compaction，这里作者阐述了其设置规则。\nfor (size_t i = 0; i \u0026lt;edit-\u0026gt;new_files_.size(); i++) { const int level =edit-\u0026gt;new_files_[i].first; FileMetaData* f = newFileMetaData(edit-\u0026gt;new_files_[i].second); f-\u0026gt;refs = 1; f-\u0026gt;allowed_seeks = (f-\u0026gt;file_size /16384); // 16KB-见下面 if (f-\u0026gt;allowed_seeks \u0026lt;100) f-\u0026gt;allowed_seeks = 100; levels_[level].deleted_files.erase(f-\u0026gt;number); // 以防万一 levels_[level].added_files-\u0026gt;insert(f); } 值allowed_seeks事关compaction的优化，其计算依据如下，首先假设：\n1 一次seek时间为10ms 2 写入10MB数据的时间为10ms（100MB/s） 3 compact 1MB的数据需要执行25MB的IO -\u0026gt;从本层读取1MB -\u0026gt;从下一层读取10-12MB（文件的key range边界可能是非对齐的） -\u0026gt;向下一层写入10-12MB\n这意味这25次seek的代价等同于compact 1MB的数据，也就是一次seek花费的时间大约相当于compact 40KB的数据。基于保守的角度考虑，对于每16KB的数据，我们允许它在触发compaction之前能做一次seek。\n11.2.3 MaybeAddFile()\n函数声明：\nvoidMaybeAddFile(Version* v, int level, FileMetaData* f); 该函数尝试将f加入到levels_[level]文件set中。 要满足两个条件：\n1 文件不能被删除，也就是不能在levels_[level].deleted_files集合中； 2 保证文件之间的key是连续的，即基于比较器vset_-\u0026gt;icmp_，f的min key要大于levels_[level]集合中最后一个文件的max key；\n11.2.4 SaveTo()\n把当前的状态存储到v中返回，函数声明：\nvoid SaveTo(Version* v); 函数逻辑：For循环遍历所有的level[0, config::kNumLevels-1]，把新加的文件和已存在的文件merge在一起，丢弃已删除的文件，结果保存在v中。对于level\u0026gt; 0，还要确保集合中的文件没有重合。 S1 merge流程\n// 原文件集合 conststd::vector\u0026lt;FileMetaData*\u0026gt;\u0026amp; base_files = base_-\u0026gt;files_[level]; std::vector\u0026lt;FileMetaData*\u0026gt;::const_iterator base_iter =base_files.begin(); std::vector\u0026lt;FileMetaData*\u0026gt;::const_iterator base_end =base_files.end(); const FileSet* added =levels_[level].added_files; v-\u0026gt;files_[level].reserve(base_files.size()+ added-\u0026gt;size()); for (FileSet::const_iteratoradded_iter = added-\u0026gt;begin(); added_iter !=added-\u0026gt;end(); ++added_iter) { //加入base_中小于added_iter的那些文件 for(std::vector\u0026lt;FileMetaData*\u0026gt;::const_iterator bpos = std::upper_bound(base_iter,base_end,*added_iter, cmp); base_iter != bpos;++base_iter) { // base_iter逐次向后移到 MaybeAddFile(v, level,*base_iter); } // 加入added_iter MaybeAddFile(v, level,*added_iter); } // 添加base_剩余的那些文件 for (; base_iter != base_end;++base_iter) MaybeAddFile(v, level, *base_iter); 对象cmp就是前面定义的比较仿函数BySmallestKey对象。 S2 检查流程，保证level\u0026gt;0的文件集合无重叠，基于vset_-\u0026gt;icmp_，确保文件i-1的max key \u0026lt; 文件i的min key。\n11.3 Recover() 对于VersionSet而言，Recover就是根据CURRENT指定的MANIFEST，读取db元信息。这是9.3介绍的Recovery流程的开始部分。\n11.3.1 函数流程\n下面就来分析其具体逻辑。\nS1 读取CURRENT文件，获得最新的MANIFEST文件名，根据文件名打开MANIFEST文件。CURRENT文件以\\n结尾，读取后需要trim下。\nstd::string current; // MANIFEST文件名 ReadFileToString(env_, CurrentFileName(dbname_), ¤t); std::string dscname = dbname_ + \u0026#34;/\u0026#34; + current; SequentialFile* file; env_-\u0026gt;NewSequentialFile(dscname, \u0026amp;file); S2 读取MANIFEST内容，MANIFEST是以log的方式写入的，因此这里调用的是log::Reader来读取。然后调用VersionEdit::DecodeFrom，从内容解析出VersionEdit对象，并将VersionEdit记录的改动应用到versionset中。读取MANIFEST中的log number, prev log number, nextfile number, last sequence。\nBuilder builder(this, current_); while (reader.ReadRecord(\u0026amp;record, \u0026amp;scratch) \u0026amp;\u0026amp; s.ok()) { VersionEdit edit; s = edit.DecodeFrom(record); if (s.ok())builder.Apply(\u0026amp;edit); // log number, file number, …逐个判断 if (edit.has_log_number_) { log_number =edit.log_number_; have_log_number = true; } … … } S3 将读取到的log number, prev log number标记为已使用。\nMarkFileNumberUsed(prev_log_number); MarkFileNumberUsed(log_number); S4 最后，如果一切顺利就创建新的Version，并应用读取的几个number。\nif (s.ok()) { Version* v = newVersion(this); builder.SaveTo(v); // 安装恢复的version Finalize(v); AppendVersion(v); manifest_file_number_ =next_file; next_file_number_ = next_file+ 1; last_sequence_ = last_sequence; log_number_ = log_number; prev_log_number_ =prev_log_number; } Finalize(v)和AppendVersion(v)用来安装并使用version v，在AppendVersion函数中会将current version设置为v。下面就来分别分析这两个函数。\n11.3.2 Finalize()\n函数声明：\nvoid Finalize(Version*v); 该函数依照规则为下次的compaction计算出最适用的level，对于level 0和\u0026gt;0需要分别对待，逻辑如下。\nS1 对于level 0以文件个数计算，kL0_CompactionTrigger默认配置为4。\nscore =v-\u0026gt;files_[level].size()/static_cast\u0026lt;double\u0026gt;(config::kL0_CompactionTrigger); S2 对于level\u0026gt;0，根据level内的文件总大小计算\nconst uint64_t level_bytes = TotalFileSize(v-\u0026gt;files_[level]); score = static_cast\u0026lt;double\u0026gt;(level_bytes) /MaxBytesForLevel(level); S3 最后把计算结果保存到v的两个成员compaction_level_和compaction_score_中。\n其中函数MaxBytesForLevel根据level返回其本层文件总大小的预定最大值。 计算规则为：1048576.0* level^10。 这里就有一个问题，为何level0和其它level计算方法不同，原因如下，这也是leveldb为compaction所做的另一个优化。\n1 对于较大的写缓存（write-buffer），做太多的level 0 compaction并不好 2 每次read操作都要merge level 0的所有文件，因此我们不希望level 0有太多的小文件存在（比如写缓存太小，或者压缩比较高，或者覆盖/删除较多导致小文件太多）。 看起来这里的写缓存应该就是配置的操作log大小。\n11.3.3 AppendVersion()\n函数声明：\nvoid AppendVersion(Version*v); 把v加入到versionset中，并设置为current version。并对老的current version执行Uref()。 在双向循环链表中的位置在dummy_versions_之前。\n","permalink":"https://haokiu.com/blog/9276872cee384cebb6d1c912acedf0a2/","summary":"leveldb源码分析18 本系列《leveldb源码分析》共有22篇文章，这是第十八篇\n11 VersionSet分析之1 Version之后就是VersionSet，它并不是Version的简单集合，还肩负了不少的处理逻辑。这里的分析不涉及到compaction相关的部分，这部分会单独分析。包括log等各种编号计数器，compaction点的管理等等。\n11.1 VersionSet接口 1 首先是构造函数，VersionSet会使用到TableCache，这个是调用者传入的。TableCache用于Get k/v操作。\nVersionSet(const std::string\u0026amp; dbname, const Options* options, TableCache*table_cache, const InternalKeyComparator*); VersionSet的构造函数很简单，除了根据参数初始化，还有两个地方值得注意： N1 next_file_number_从2开始； N2 创建新的Version并加入到Version链表中，并设置CURRENT=新创建version； 其它的数字初始化为0，指针初始化为NULL。 2 恢复函数，从磁盘恢复最后保存的元信息\nStatus Recover(); 3 标记指定的文件编号已经被使用了\nvoid MarkFileNumberUsed(uint64_t number); 逻辑很简单，就是根据编号更新文件编号计数器：\nif (next_file_number_ \u0026lt;= number) next_file_number_ = number + 1; 4 在current version上应用指定的VersionEdit，生成新的MANIFEST信息，保存到磁盘上，并用作current version。 要求：没有其它线程并发调用；要用于mu；\nStatus LogAndApply(VersionEdit* edit, port::Mutex* mu)EXCLUSIVE_LOCKS_REQUIRED(mu); 5 对于@v中的@key，返回db中的大概位置\nuint64_t ApproximateOffsetOf(Version* v, const InternalKey\u0026amp; key); 6 其它一些简单接口，信息获取或者设置，如下：\n//返回current version Version* current() const { return current_; } // 当前的MANIFEST文件号 uint64_t ManifestFileNumber() const { return manifest_file_number_; } // 分配并返回新的文件编号 uint64_t NewFileNumber() { return next_file_number_++; } // 返回当前log文件编号 uint64_t LogNumber() const { return log_number_; } // 返回正在compact的log文件编号，如果没有返回0 uint64_t PrevLogNumber() const { return prev_log_number_; } // 获取、设置last sequence，set时不能后退 uint64_t LastSequence() const { return last_sequence_; } void SetLastSequence(uint64_t s) { assert(s \u0026gt;=last_sequence_); last_sequence_ = s; } // 返回指定level中所有sstable文件大小的和 int64_t NumLevelBytes(int level) const; // 返回指定level的文件个数 int NumLevelFiles(int level) const; // 重用@file_number，限制很严格：@file_number必须是最后分配的那个 // 要求: @file_number是NewFileNumber()返回的.","title":"leveldb源码分析18"},{"content":"leveldb源码分析19 本系列《leveldb源码分析》共有22篇文章，这是第十九篇\n11.VersionSet分析之2 11.4 LogAndApply() 函数声明：\nStatus LogAndApply(VersionEdit*edit, port::Mutex* mu) 前面接口小节中讲过其功能：在currentversion上应用指定的VersionEdit，生成新的MANIFEST信息，保存到磁盘上，并用作current version，故为Log And Apply。 参数edit也会被函数修改。\n11.4.1 函数流程 下面就来具体分析函数代码。 S1 为edit设置log number等4个计数器。\nif (edit-\u0026gt;has_log_number_) { assert(edit-\u0026gt;log_number_ \u0026gt;= log_number_); assert(edit-\u0026gt;log_number_ \u0026lt; next_file_number_); } else edit-\u0026gt;SetLogNumber(log_number_); if (!edit-\u0026gt;has_prev_log_number_) edit-\u0026gt;SetPrevLogNumber(prev_log_number_); edit-\u0026gt;SetNextFile(next_file_number_); edit-\u0026gt;SetLastSequence(last_sequence_); 要保证edit自己的log number是比较大的那个，否则就是致命错误。保证edit的log number小于next file number，否则就是致命错误-见9.1小节。\nS2 创建一个新的Version v，并把新的edit变动保存到v中。\nVersion* v = new Version(this); { Builder builder(this, current_); builder.Apply(edit); builder.SaveTo(v); } Finalize(v); //如前分析，只是为v计算执行compaction的最佳level S3 如果MANIFEST文件指针不存在，就创建并初始化一个新的MANIFEST文件。这只会发生在第一次打开数据库时。这个MANIFEST文件保存了current version的快照。\nstd::string new_manifest_file; Status s; if (descriptor_log_ == NULL) { // 这里不需要unlock *mu因为我们只会在第一次调用LogAndApply时 // 才走到这里(打开数据库时). assert(descriptor_file_ == NULL); // 文件指针和log::Writer都应该是NULL new_manifest_file = DescriptorFileName(dbname_, manifest_file_number_); edit-\u0026gt;SetNextFile(next_file_number_); s = env_-\u0026gt;NewWritableFile(new_manifest_file, \u0026amp;descriptor_file_); if (s.ok()) { descriptor_log_ = new log::Writer(descriptor_file_); s = WriteSnapshot(descriptor_log_); // 写入快照 } } S4 向MANIFEST写入一条新的log，记录current version的信息。在文件写操作时unlock锁，写入完成后，再重新lock，以防止浪费在长时间的IO操作上。\n[cpp] view plain copy mu-\u0026gt;Unlock(); if (s.ok()) { std::string record; edit-\u0026gt;EncodeTo(\u0026amp;record);// 序列化current version信息 s = descriptor_log_-\u0026gt;AddRecord(record); // append到MANIFEST log中 if (s.ok()) s = descriptor_file_-\u0026gt;Sync(); if (!s.ok()) { Log(options_-\u0026gt;info_log, \u0026#34;MANIFEST write: %s\\n\u0026#34;, s.ToString().c_str()); if (ManifestContains(record)) { // 返回出错，其实确实写成功了 Log(options_-\u0026gt;info_log, \u0026#34;MANIFEST contains log record despiteerror \u0026#34;); s = Status::OK(); } } } //如果刚才创建了一个MANIFEST文件，通过写一个指向它的CURRENT文件 //安装它；不需要再次检查MANIFEST是否出错，因为如果出错后面会删除它 if (s.ok() \u0026amp;\u0026amp; !new_manifest_file.empty()) { s = SetCurrentFile(env_, dbname_, manifest_file_number_); } mu-\u0026gt;Lock(); S5 安装这个新的version\nif (s.ok()) { // 安装这个version AppendVersion(v); log_number_ = edit-\u0026gt;log_number_; prev_log_number_ = edit-\u0026gt;prev_log_number_; } else { // 失败了，删除 delete v; if (!new_manifest_file.empty()) { delete descriptor_log_; delete descriptor_file_; descriptor_log_ = descriptor_file_ = NULL; env_-\u0026gt;DeleteFile(new_manifest_file); } } 流程的S4中，函数会检查MANIFEST文件是否已经有了这条record，那么什么时候会有呢？\n主函数使用到了几个新的辅助函数WriteSnapshot，ManifestContains和SetCurrentFile，下面就来分析。\n11.4.2 WriteSnapshot() 函数声明：\nStatus WriteSnapshot(log::Writer*log) 把currentversion保存到*log中，信息包括comparator名字、compaction点和各级sstable文件，函数逻辑很直观。\nS1 首先声明一个新的VersionEdit edit； S2 设置comparator：edit.SetComparatorName(icmp_.user_comparator()-\u0026gt;Name()); S3 遍历所有level，根据compact_pointer_[level]，设置compaction点： edit.SetCompactPointer(level, key); S4 遍历所有level，根据current_-\u0026gt;files_，设置sstable文件集合：edit.AddFile(level, xxx) S5 根据序列化并append到log（MANIFEST文件）中； std::string record; edit.EncodeTo(\u0026amp;record); returnlog-\u0026gt;AddRecord(record); 以上就是WriteSnapshot的代码逻辑。\n11.4.3 ManifestContains() 函数声明：\nbool ManifestContains(conststd::string\u0026amp; record) 如果当前MANIFEST包含指定的record就返回true，来看看函数逻辑。\nS1 根据当前的manifest_file_number_文件编号打开文件，创建SequentialFile对象\nS2 根据创建的SequentialFile对象创建log::Reader，以读取文件\nS3 调用log::Reader的ReadRecord依次读取record，如果和指定的record相同，就返回true，没有相同的record就返回false\nSetCurrentFile很简单，就是根据指定manifest文件编号，构造出MANIFEST文件名，并写入到CURRENT即可。\n11.5 ApproximateOffsetOf() 函数声明：\nuint64_tApproximateOffsetOf(Version* v, const InternalKey\u0026amp; ikey) 在指定的version中查找指定key的大概位置。 假设version中有n个sstable文件，并且落在了地i个sstable的key空间内，那么返回的位置**= sstable1文件大小+sstable2文件大小 + … + sstable (i-1)文件大小 + key在sstable i中的大概偏移**。 可分为两段逻辑。\n首先直接和sstable的max key作比较，如果key \u0026gt; max key，直接跳过该文件，还记得sstable文件是有序排列的。 对于level \u0026gt;0的文件集合而言，如果如果key \u0026lt; sstable文件的min key，则直接跳出循环，因为后续的sstable的min key肯定大于key。\nkey在sstable i中的大概偏移使用的是Table:: ApproximateOffsetOf(target)接口，前面分析过，它返回的是Table中\u0026gt;= target的key的位置。\nVersionSet的相关函数暂时分析到这里，compaction部分后需单独分析。\n","permalink":"https://haokiu.com/blog/2d765b7b763343038b1df047545b2017/","summary":"leveldb源码分析19 本系列《leveldb源码分析》共有22篇文章，这是第十九篇\n11.VersionSet分析之2 11.4 LogAndApply() 函数声明：\nStatus LogAndApply(VersionEdit*edit, port::Mutex* mu) 前面接口小节中讲过其功能：在currentversion上应用指定的VersionEdit，生成新的MANIFEST信息，保存到磁盘上，并用作current version，故为Log And Apply。 参数edit也会被函数修改。\n11.4.1 函数流程 下面就来具体分析函数代码。 S1 为edit设置log number等4个计数器。\nif (edit-\u0026gt;has_log_number_) { assert(edit-\u0026gt;log_number_ \u0026gt;= log_number_); assert(edit-\u0026gt;log_number_ \u0026lt; next_file_number_); } else edit-\u0026gt;SetLogNumber(log_number_); if (!edit-\u0026gt;has_prev_log_number_) edit-\u0026gt;SetPrevLogNumber(prev_log_number_); edit-\u0026gt;SetNextFile(next_file_number_); edit-\u0026gt;SetLastSequence(last_sequence_); 要保证edit自己的log number是比较大的那个，否则就是致命错误。保证edit的log number小于next file number，否则就是致命错误-见9.1小节。\nS2 创建一个新的Version v，并把新的edit变动保存到v中。\nVersion* v = new Version(this); { Builder builder(this, current_); builder.Apply(edit); builder.SaveTo(v); } Finalize(v); //如前分析，只是为v计算执行compaction的最佳level S3 如果MANIFEST文件指针不存在，就创建并初始化一个新的MANIFEST文件。这只会发生在第一次打开数据库时。这个MANIFEST文件保存了current version的快照。\nstd::string new_manifest_file; Status s; if (descriptor_log_ == NULL) { // 这里不需要unlock *mu因为我们只会在第一次调用LogAndApply时 // 才走到这里(打开数据库时). assert(descriptor_file_ == NULL); // 文件指针和log::Writer都应该是NULL new_manifest_file = DescriptorFileName(dbname_, manifest_file_number_); edit-\u0026gt;SetNextFile(next_file_number_); s = env_-\u0026gt;NewWritableFile(new_manifest_file, \u0026amp;descriptor_file_); if (s.ok()) { descriptor_log_ = new log::Writer(descriptor_file_); s = WriteSnapshot(descriptor_log_); // 写入快照 } } S4 向MANIFEST写入一条新的log，记录current version的信息。在文件写操作时unlock锁，写入完成后，再重新lock，以防止浪费在长时间的IO操作上。","title":"leveldb源码分析19"},{"content":"leveldb源码分析2 本系列《leveldb源码分析》共有22篇文章，这是第二篇。\n3.Int Coding 轻松一刻，前面约定中讲过Leveldb使用了很多VarInt型编码，典型的如后面将涉及到的各种key。其中的编码、解码函数分为VarInt和FixedInt两种。int32和int64操作都是类似的。\n3.1 Decode 首先是FixedInt编码，直接上代码，很简单明了。\nvoid EncodeFixed32(char* buf, uint32_t value) { if (port::kLittleEndian) { memcpy(buf, \u0026amp;value,sizeof(value)); } else { buf[0] = value \u0026amp; 0xff; buf[1] = (value \u0026gt;\u0026gt; 8)\u0026amp; 0xff; buf[2] = (value \u0026gt;\u0026gt; 16)\u0026amp; 0xff; buf[3] = (value \u0026gt;\u0026gt; 24)\u0026amp; 0xff; } } 下面是VarInt编码，int32和int64格式，代码如下，有效位是7bit的，因此把uint32按7bit分割，对unsigned char赋值时，超出0xFF会自动截断，因此直接*(ptr++) = v|B即可，不需要再把(v|B)与0xFF作\u0026amp;操作。\nchar* EncodeVarint32(char* dst, uint32_t v) { unsigned char* ptr =reinterpret_cast\u0026lt;unsigned char*\u0026gt;(dst); static const int B = 128; if (v \u0026lt; (1\u0026lt;\u0026lt;7)) { *(ptr++) = v; } else if (v \u0026lt; (1\u0026lt;\u0026lt;14)){ *(ptr++) = v | B; *(ptr++) = v\u0026gt;\u0026gt;7; } else if (v \u0026lt; (1\u0026lt;\u0026lt;21)){ *(ptr++) = v | B; *(ptr++) = (v\u0026gt;\u0026gt;7) | B; *(ptr++) = v\u0026gt;\u0026gt;14; } else if (v \u0026lt; (1\u0026lt;\u0026lt;28)){ *(ptr++) = v | B; *(ptr++) = (v\u0026gt;\u0026gt;7) | B; *(ptr++) = (v\u0026gt;\u0026gt;14) | B; *(ptr++) = v\u0026gt;\u0026gt;21; } else { *(ptr++) = v | B; *(ptr++) = (v\u0026gt;\u0026gt;7) | B; *(ptr++) = (v\u0026gt;\u0026gt;14) | B; *(ptr++) = (v\u0026gt;\u0026gt;21) | B; *(ptr++) = v\u0026gt;\u0026gt;28; } return reinterpret_cast\u0026lt;char*\u0026gt;(ptr); } // 对于uint64，直接循环 char* EncodeVarint64(char* dst, uint64_t v) { static const int B = 128; unsigned char* ptr =reinterpret_cast\u0026lt;unsigned char*\u0026gt;(dst); while (v \u0026gt;= B) { *(ptr++) = (v \u0026amp; (B-1)) |B; v \u0026gt;\u0026gt;= 7; } *(ptr++) =static_cast\u0026lt;unsigned char\u0026gt;(v); returnreinterpret_cast\u0026lt;char*\u0026gt;(ptr); } 3.2 Decode Fixed Int的Decode，操作，代码：\ninline uint32_t DecodeFixed32(const char* ptr) { if (port::kLittleEndian) { uint32_t result; // gcc optimizes this to a plain load memcpy(\u0026amp;result, ptr,sizeof(result)); return result; } else { return((static_cast\u0026lt;uint32_t\u0026gt;(static_cast\u0026lt;unsigned char\u0026gt;(ptr[0]))) |(static_cast\u0026lt;uint32_t\u0026gt;(static_cast\u0026lt;unsigned char\u0026gt;(ptr[1])) \u0026lt;\u0026lt;8) | (static_cast\u0026lt;uint32_t\u0026gt;(static_cast\u0026lt;unsignedchar\u0026gt;(ptr[2])) \u0026lt;\u0026lt; 16) |(static_cast\u0026lt;uint32_t\u0026gt;(static_cast\u0026lt;unsigned char\u0026gt;(ptr[3])) \u0026lt;\u0026lt;24)); } } 再来看看VarInt的解码，很简单，依次读取1byte，直到最高位为0的byte结束，取低7bit，作(\u0026laquo;7)移位操作组合成Int。看代码：\nconst char* GetVarint32Ptr(const char* p, const char* limit, uint32_t* value) { if (p \u0026lt; limit) { uint32_t result =*(reinterpret_cast\u0026lt;const unsigned char*\u0026gt;(p)); if ((result \u0026amp; 128) == 0) { *value = result; return p + 1; } } return GetVarint32PtrFallback(p,limit, value); } const char* GetVarint32PtrFallback(const char* p, const char* limit, uint32_t* value) { uint32_t result = 0; for (uint32_t shift = 0; shift\u0026lt;= 28 \u0026amp;\u0026amp; p \u0026lt; limit; shift += 7) { uint32_t byte =*(reinterpret_cast\u0026lt;const unsigned char*\u0026gt;(p)); p++; if (byte \u0026amp; 128) { // More bytes are present result |= ((byte \u0026amp; 127)\u0026lt;\u0026lt; shift); } else { result |= (byte \u0026lt;\u0026lt;shift); *value = result; returnreinterpret_cast\u0026lt;const char*\u0026gt;(p); } } return NULL; } ","permalink":"https://haokiu.com/blog/c955baadcc824d20acb455e1078a257c/","summary":"leveldb源码分析2 本系列《leveldb源码分析》共有22篇文章，这是第二篇。\n3.Int Coding 轻松一刻，前面约定中讲过Leveldb使用了很多VarInt型编码，典型的如后面将涉及到的各种key。其中的编码、解码函数分为VarInt和FixedInt两种。int32和int64操作都是类似的。\n3.1 Decode 首先是FixedInt编码，直接上代码，很简单明了。\nvoid EncodeFixed32(char* buf, uint32_t value) { if (port::kLittleEndian) { memcpy(buf, \u0026amp;value,sizeof(value)); } else { buf[0] = value \u0026amp; 0xff; buf[1] = (value \u0026gt;\u0026gt; 8)\u0026amp; 0xff; buf[2] = (value \u0026gt;\u0026gt; 16)\u0026amp; 0xff; buf[3] = (value \u0026gt;\u0026gt; 24)\u0026amp; 0xff; } } 下面是VarInt编码，int32和int64格式，代码如下，有效位是7bit的，因此把uint32按7bit分割，对unsigned char赋值时，超出0xFF会自动截断，因此直接*(ptr++) = v|B即可，不需要再把(v|B)与0xFF作\u0026amp;操作。\nchar* EncodeVarint32(char* dst, uint32_t v) { unsigned char* ptr =reinterpret_cast\u0026lt;unsigned char*\u0026gt;(dst); static const int B = 128; if (v \u0026lt; (1\u0026lt;\u0026lt;7)) { *(ptr++) = v; } else if (v \u0026lt; (1\u0026lt;\u0026lt;14)){ *(ptr++) = v | B; *(ptr++) = v\u0026gt;\u0026gt;7; } else if (v \u0026lt; (1\u0026lt;\u0026lt;21)){ *(ptr++) = v | B; *(ptr++) = (v\u0026gt;\u0026gt;7) | B; *(ptr++) = v\u0026gt;\u0026gt;14; } else if (v \u0026lt; (1\u0026lt;\u0026lt;28)){ *(ptr++) = v | B; *(ptr++) = (v\u0026gt;\u0026gt;7) | B; *(ptr++) = (v\u0026gt;\u0026gt;14) | B; *(ptr++) = v\u0026gt;\u0026gt;21; } else { *(ptr++) = v | B; *(ptr++) = (v\u0026gt;\u0026gt;7) | B; *(ptr++) = (v\u0026gt;\u0026gt;14) | B; *(ptr++) = (v\u0026gt;\u0026gt;21) | B; *(ptr++) = v\u0026gt;\u0026gt;28; } return reinterpret_cast\u0026lt;char*\u0026gt;(ptr); } // 对于uint64，直接循环 char* EncodeVarint64(char* dst, uint64_t v) { static const int B = 128; unsigned char* ptr =reinterpret_cast\u0026lt;unsigned char*\u0026gt;(dst); while (v \u0026gt;= B) { *(ptr++) = (v \u0026amp; (B-1)) |B; v \u0026gt;\u0026gt;= 7; } *(ptr++) =static_cast\u0026lt;unsigned char\u0026gt;(v); returnreinterpret_cast\u0026lt;char*\u0026gt;(ptr); } 3.","title":"leveldb源码分析2"},{"content":"leveldb源码分析20 本系列《leveldb源码分析》共有22篇文章，这是第二十篇 12 DB的打开 先分析LevelDB是如何打开db的，万物始于创建。在打开流程中有几个辅助函数：DBImpl()，DBImpl::Recover, DBImpl::DeleteObsoleteFiles, DBImpl::RecoverLogFile, DBImpl::MaybeScheduleCompaction。\n12.1 DB::Open() 打开一个db，进行PUT、GET操作，就是前面的静态函数DB::Open的工作。如果操作成功，它就返回一个db指针。前面说过DB就是一个接口类，其具体实现在DBImp类中，这是一个DB的子类。 函数声明为：\nStatus DB::Open(const Options\u0026amp; options, const std::string\u0026amp;dbname, DB** dbptr); 分解来看，Open()函数主要有以下5个执行步骤。 S1 创建DBImpl对象，其后进入**DBImpl::Recover()函数执行S2和S3。 S2 从已存在的db文件恢复db数据，根据CURRENT记录的MANIFEST文件读取db元信息；这通过调用VersionSet::Recover()完成。 S3 然后过滤出那些最近的更新log，前一个版本可能新加了这些log，但并没有记录在MANIFEST中。然后依次根据时间顺序，调用DBImpl::RecoverLogFile()从旧到新回放这些操作log。回放log时可能会修改db元信息，比如dump了新的level 0文件，因此它将返回一个VersionEdit对象，记录db元信息的变动。 S4 如果DBImpl::Recover()返回成功，就执行VersionSet::LogAndApply()**应用VersionEdit，并保存当前的DB信息到新的MANIFEST文件中。 S5 最后删除一些过期文件，并检查是否需要执行compaction，如果需要，就启动后台线程执行。 下面就来具体分析Open函数的代码，在Open函数中涉及到上面的3个流程。 S1 首先创建DBImpl对象，锁定并试图做Recover操作。Recover操作用来处理创建flag，比如存在就返回失败等等，尝试从已存在的sstable文件恢复db。并返回db元信息的变动信息，一个VersionEdit对象。\n1DBImpl* impl = newDBImpl(options, dbname); 2impl-\u0026gt;mutex_.Lock(); // 锁db 3VersionEdit edit; 4Status s =impl-\u0026gt;Recover(\u0026amp;edit); // 处理flag\u0026amp;恢复：create_if_missing,error_if_exists S2 如果Recover返回成功，则调用VersionSet取得新的log文件编号——实际上是在当前基础上+1，准备新的log文件。如果log文件创建成功，则根据log文件创建log::Writer。然后执行VersionSet::LogAndApply，根据edit记录的增量变动生成新的current version，并写入MANIFEST文件。\n函数NewFileNumber(){returnnext_file_number_++;}，直接返回next_file_number_。\n1uint64_t new_log_number = impl-\u0026gt;versions_-\u0026gt;NewFileNumber(); 2WritableFile* lfile; 3s = options.env-\u0026gt;NewWritableFile(LogFileName(dbname, new_log_number), \u0026amp;lfile); 4if (s.ok()) { 5 edit.SetLogNumber(new_log_number); 6 impl-\u0026gt;logfile_ = lfile; 7 impl-\u0026gt;logfile_number_ = new_log_number; 8 impl-\u0026gt;log_ = newlog::Writer(lfile); 9 s = impl-\u0026gt;versions_-\u0026gt;LogAndApply(\u0026amp;edit, \u0026amp;impl-\u0026gt;mutex_); 10} S3 如果VersionSet::LogAndApply返回成功，则删除过期文件，检查是否需要执行compaction，最终返回创建的DBImpl对象。\n1if (s.ok()) { 2 impl-\u0026gt;DeleteObsoleteFiles(); 3 impl-\u0026gt;MaybeScheduleCompaction(); 4} 5impl-\u0026gt;mutex_.Unlock(); 6if (s.ok()) *dbptr = impl; 7return s; 以上就是DB::Open的主题逻辑。\n12.2 DBImpl::DBImpl()\n构造函数做的都是初始化操作，\nDBImpl::DBImpl(const Options\u0026amp; options, const std::string\u0026amp;dbname) 首先是初始化列表中，直接根据参数赋值，或者直接初始化。Comparator和filter policy都是参数传入的。在传递option时会首先将option中的参数合法化，**logfile_number_**初始化为0，指针初始化为NULL。 创建MemTable，并增加引用计数，创建WriteBatch。\n1mem_(newMemTable(internal_comparator_)), 2tmp_batch_(new WriteBatch), 3mem_-\u0026gt;Ref(); 4// 然后在函数体中，创建TableCache和VersionSet。 5// 为其他预留10个文件，其余的都给TableCache. 6const int table_cache_size = options.max_open_files - 10; 7table_cache_ = newTableCache(dbname_, \u0026amp;options_, table_cache_size); 8versions_ = newVersionSet(dbname_, \u0026amp;options_, table_cache_, \u0026amp;internal_comparator_); 12.3 DBImp::NewDB() 当外部在调用DB::Open()时设置了option指定如果db不存在就创建，如果db不存在leveldb就会调用函数创建新的db。判断db是否存在的依据是**/CURRENT**文件是否存在。其逻辑很简单。\n1// S1首先生产DB元信息，设置comparator名，以及log文件编号、文件编号，以及seq no。 2VersionEdit new_db; 3new_db.SetComparatorName(user_comparator()-\u0026gt;Name()); 4new_db.SetLogNumber(0); 5new_db.SetNextFile(2); 6new_db.SetLastSequence(0); 7// S2 生产MANIFEST文件，将db元信息写入MANIFEST文件。 8const std::string manifest = DescriptorFileName(dbname_, 1); 9WritableFile* file; 10Status s = env_-\u0026gt;NewWritableFile(manifest, \u0026amp;file); 11if (!s.ok()) return s; 12{ 13 log::Writer log(file); 14 std::string record; 15 new_db.EncodeTo(\u0026amp;record); 16 s = log.AddRecord(record); 17 if (s.ok()) s = file-\u0026gt;Close(); 18} 19delete file; 20// S3 如果成功，就把MANIFEST文件名写入到CURRENT文件中 21if (s.ok()) s = SetCurrentFile(env_, dbname_, 1); 22elseenv_-\u0026gt;DeleteFile(manifest); 23return s; 这就是创建新DB的逻辑，很简单。\n12.4 DBImpl::Recover()\n函数声明为：\nStatusDBImpl::Recover(VersionEdit* edit) 如果调用成功则设置VersionEdit。Recover的基本功能是：首先是处理创建flag，比如存在就返回失败等等；然后是尝试从已存在的sstable文件恢复db；最后如果发现有大于原信息记录的log编号的log文件，则需要回放log，更新db数据。回放期间db可能会dump新的level 0文件，因此需要把db元信息的变动记录到edit中返回。函数逻辑如下：\nS1 创建目录，目录以db name命名，忽略任何创建错误，然后尝试获取db name/LOCK文件锁，失败则返回。\n1env_-\u0026gt;CreateDir(dbname_); 2Status s = env_-\u0026gt;LockFile(LockFileName(dbname_), \u0026amp;db_lock_); 3if (!s.ok()) return s; S2 根据CURRENT文件是否存在，以及option参数执行检查。 如果文件不存在**\u0026amp;create_is_missing=true**，则调用函数NewDB()创建；否则报错。 如果文件存在\u0026amp; error_if_exists=true，则报错。 S3 调用VersionSet的**Recover()**函数，就是从文件中恢复数据。如果出错则打开失败，成功则向下执行S4。\ns = versions_-\u0026gt;Recover(); S4尝试从所有比manifest文件中记录的log要新的log文件中恢复（前一个版本可能会添加新的log文件，却没有记录在manifest中）。另外，函数PrevLogNumber()已经不再用了，仅为了兼容老版本。\n1// S4.1 这里先找出所有满足条件的log文件：比manifest文件记录的log编号更新。 2SequenceNumber max_sequence(0); 3const uint64_t min_log = versions_-\u0026gt;LogNumber(); 4const uint64_t prev_log = versions_-\u0026gt;PrevLogNumber(); 5std::vector\u0026lt;std::string\u0026gt;filenames; 6s = env_-\u0026gt;GetChildren(dbname_, \u0026amp;filenames); // 列出目录内的所有文件 7uint64_t number; 8FileType type; 9std::vector\u0026lt;uint64_t\u0026gt;logs; 10for (size_t i = 0; i \u0026lt; filenames.size(); i++) { // 检查log文件是否比min log更新 11 if (ParseFileName(filenames[i], \u0026amp;number, \u0026amp;type) \u0026amp;\u0026amp; type == kLogFile 12 \u0026amp;\u0026amp; ((number \u0026gt;= min_log) || (number == prev_log))) { 13 logs.push_back(number); 14 } 15} 16// S4.2 找到log文件后，首先排序，保证按照生成顺序，依次回放log。并把DB元信息的变动（sstable文件的变动）追加到edit中返回。 17std::sort(logs.begin(), logs.end()); 18for (size_t i = 0; i \u0026lt; logs.size(); i++) { 19 s = RecoverLogFile(logs[i], edit, \u0026amp;max_sequence); 20 // 前一版可能在生成该log编号后没有记录在MANIFEST中， 21 //所以这里我们手动更新VersionSet中的文件编号计数器 22 versions_-\u0026gt;MarkFileNumberUsed(logs[i]); 23} 24// S4.3 更新VersionSet的sequence 25if (s.ok()) { 26 if (versions_-\u0026gt;LastSequence() \u0026lt; max_sequence) 27 versions_-\u0026gt;SetLastSequence(max_sequence); 28} 上面就是Recover的执行流程。\n12.5 DBImpl::DeleteObsoleteFiles() 这个是垃圾回收函数，如前所述，每次compaction和recovery之后都会有文件被废弃。DeleteObsoleteFiles就是删除这些垃圾文件的，它在每次compaction和recovery完成之后被调用。 其调用点包括：DBImpl::CompactMemTable,DBImpl::BackgroundCompaction, 以及DB::Open的recovery步骤之后。 它会删除所有过期的log文件，没有被任何level引用到、或不是正在执行的compaction的output的sstable文件。 该函数没有参数，其代码逻辑也很直观，就是列出db的所有文件，对不同类型的文件分别判断，如果是过期文件，就删除之，如下：\n1// S1 首先，确保不会删除pending文件，将versionset正在使用的所有文件加入到live中。 2std::set\u0026lt;uint64_t\u0026gt; live = pending_outputs_; 3versions_-\u0026gt;AddLiveFiles(\u0026amp;live); //该函数其后分析 4 // S2 列举db的所有文件 5std::vector\u0026lt;std::string\u0026gt;filenames; 6env_-\u0026gt;GetChildren(dbname_, \u0026amp;filenames); 7// S3 遍历所有列举的文件，根据文件类型，分别处理； 8uint64_t number; 9FileType type; 10for (size_t i = 0; i \u0026lt; filenames.size(); i++) { 11 if (ParseFileName(filenames[i], \u0026amp;number, \u0026amp;type)) { 12 bool keep = true; //false表明是过期文件 13 // S3.1 kLogFile，log文件，根据log编号判断是否过期 14 keep = ((number \u0026gt;= versions_-\u0026gt;LogNumber()) || 15 (number == versions_-\u0026gt;PrevLogNumber())); 16 // S3.2 kDescriptorFile，MANIFEST文件，根据versionset记录的编号判断 17 keep = (number \u0026gt;= versions_-\u0026gt;ManifestFileNumber()); 18 // S3.3 kTableFile，sstable文件，只要在live中就不能删除 19 // S3.4 kTempFile，如果是正在写的文件，只要在live中就不能删除 20 keep = (live.find(number) != live.end()); 21 // S3.5 kCurrentFile,kDBLockFile, kInfoLogFile，不能删除 22 keep = true; 23 // S3.6 如果keep为false，表明需要删除文件，如果是table还要从cache中删除 24 if (!keep) { 25 if (type == kTableFile) table_cache_-\u0026gt;Evict(number); 26 Log(options_.info_log, \u0026#34;Delete type=%d #%lld\\n\u0026#34;, type, number); 27 env_-\u0026gt;DeleteFile(dbname_ + \u0026#34;/\u0026#34; + filenames[i]); 28 } 29 } 30} 这就是删除过期文件的逻辑，其中调用到了VersionSet::AddLiveFiles函数，保证不会删除active的文件。\n函数DbImpl::MaybeScheduleCompaction()放在Compaction一节分析，基本逻辑就是如果需要compaction，就启动后台线程执行compaction操作。\n12.6 DBImpl::RecoverLogFile() 函数声明：\nStatusRecoverLogFile(uint64_t log_number, VersionEdit* edit,SequenceNumber* max_sequence) 参数说明： @log_number是指定的log文件编号 @edit记录db元信息的变化——sstable文件变动 @max_sequence 返回max{log记录的最大序号, *max_sequence} 该函数打开指定的log文件，回放日志。期间可能会执行compaction，生产新的level 0sstable文件，记录文件变动到edit中。 它声明了一个局部类LogReporter以打印错误日志，没什么好说的，下面来看代码逻辑。\n1// S1 打开log文件返回SequentialFile*file，出错就返回，否则向下执行S2。 2// S2 根据log文件句柄file创建log::Reader，准备读取log。 3log::Reader reader(file, \u0026amp;reporter, true/*checksum*/, 0/*initial_offset*/); 4// S3 依次读取所有的log记录，并插入到新生成的memtable中。这里使用到了批量更新接口WriteBatch，具体后面再分析。 5std::string scratch; 6Slice record; 7WriteBatch batch; 8MemTable* mem = NULL; 9while (reader.ReadRecord(\u0026amp;record, \u0026amp;scratch) \u0026amp;\u0026amp; status.ok()) { // 读取全部log 10 if (record.size() \u0026lt; 12) { // log数据错误，不满足最小长度12 11 reporter.Corruption(record.size(), Status::Corruption(\u0026#34;log recordtoo small\u0026#34;)); 12 continue; 13 } 14 WriteBatchInternal::SetContents(\u0026amp;batch, record); // log内容设置到WriteBatch中 15 if (mem == NULL) { // 创建memtable 16 mem = new MemTable(internal_comparator_); 17 mem-\u0026gt;Ref(); 18 } 19 status = WriteBatchInternal::InsertInto(\u0026amp;batch, mem); // 插入到memtable中 20 MaybeIgnoreError(\u0026amp;status); 21 if (!status.ok()) break; 22 const SequenceNumber last_seq = 23 WriteBatchInternal::Sequence(\u0026amp;batch) + WriteBatchInternal::Count(\u0026amp;batch) - 1; 24 if (last_seq \u0026gt; *max_sequence) *max_sequence = last_seq; // 更新max sequence 25 // 如果mem的内存超过设置值，则执行compaction，如果compaction出错， 26 // 立刻返回错误，DB::Open失败 27 if (mem-\u0026gt;ApproximateMemoryUsage() \u0026gt; options_.write_buffer_size) { 28 status = WriteLevel0Table(mem, edit, NULL); 29 if (!status.ok()) break; 30 mem-\u0026gt;Unref(); // 释放当前memtable 31 mem = NULL; 32 } 33} 34// S4 扫尾工作，如果mem != NULL，说明还需要dump到新的sstable文件中。 35if (status.ok() \u0026amp;\u0026amp; mem != NULL) {// 如果compaction出错，立刻返回错误 36 status = WriteLevel0Table(mem, edit, NULL); 37} 38if (mem != NULL)mem-\u0026gt;Unref(); 39delete file; 40return status; 把MemTabledump到sstable是函数WriteLevel0Table的工作，其实这是compaction的一部分，准备放在compaction一节来分析。\n12.7 小结\n如上DB打开的逻辑就已经分析完了，打开逻辑参见DB::Open()中描述的5个步骤。此外还有两个东东：把Memtable dump到sstable的WriteLevel0Table()函数，以及批量修改WriteBatch。第一个放在后面的compaction一节，第二个放在DB更新操作中。接下来就是db的关闭。\n13 DB的关闭\u0026amp;销毁 13.1 DB关闭 外部调用者通过DB::Open()获取一个DB对象，如果要关闭打开的DBdb对象，则直接delete db即可，这会调用到DBImpl的析构函数。 析构依次执行如下的5个逻辑： S1 等待后台compaction任务结束 S2 释放db文件锁，/lock文件 S3 删除VersionSet对象，并释放MemTable对象 S4 删除log相关以及TableCache对象 S5 删除options的block_cache以及info_log对象\n13.2 DB销毁 函数声明：\nStatusDestroyDB(const std::string\u0026amp; dbname, const Options\u0026amp; options) 该函数会删除掉db的数据内容，要谨慎使用。函数逻辑为： S1 获取dbname目录的文件列表到filenames中，如果为空则直接返回，否则进入S2。 S2 锁文件/lock，如果锁成功就执行S3 S3 遍历filenames文件列表，过滤掉lock文件，依次调用DeleteFile删除。 S4 释放lock文件，并删除之，然后删除文件夹。 Destory就执行完了，如果删除文件出现错误，记录之，依然继续删除下一个。最后返回错误代码。 看来这一章很短小。DB的打开关闭分析完毕。\n","permalink":"https://haokiu.com/blog/0da12c5829764cdc8a508c0a05e99a3e/","summary":"leveldb源码分析20 本系列《leveldb源码分析》共有22篇文章，这是第二十篇 12 DB的打开 先分析LevelDB是如何打开db的，万物始于创建。在打开流程中有几个辅助函数：DBImpl()，DBImpl::Recover, DBImpl::DeleteObsoleteFiles, DBImpl::RecoverLogFile, DBImpl::MaybeScheduleCompaction。\n12.1 DB::Open() 打开一个db，进行PUT、GET操作，就是前面的静态函数DB::Open的工作。如果操作成功，它就返回一个db指针。前面说过DB就是一个接口类，其具体实现在DBImp类中，这是一个DB的子类。 函数声明为：\nStatus DB::Open(const Options\u0026amp; options, const std::string\u0026amp;dbname, DB** dbptr); 分解来看，Open()函数主要有以下5个执行步骤。 S1 创建DBImpl对象，其后进入**DBImpl::Recover()函数执行S2和S3。 S2 从已存在的db文件恢复db数据，根据CURRENT记录的MANIFEST文件读取db元信息；这通过调用VersionSet::Recover()完成。 S3 然后过滤出那些最近的更新log，前一个版本可能新加了这些log，但并没有记录在MANIFEST中。然后依次根据时间顺序，调用DBImpl::RecoverLogFile()从旧到新回放这些操作log。回放log时可能会修改db元信息，比如dump了新的level 0文件，因此它将返回一个VersionEdit对象，记录db元信息的变动。 S4 如果DBImpl::Recover()返回成功，就执行VersionSet::LogAndApply()**应用VersionEdit，并保存当前的DB信息到新的MANIFEST文件中。 S5 最后删除一些过期文件，并检查是否需要执行compaction，如果需要，就启动后台线程执行。 下面就来具体分析Open函数的代码，在Open函数中涉及到上面的3个流程。 S1 首先创建DBImpl对象，锁定并试图做Recover操作。Recover操作用来处理创建flag，比如存在就返回失败等等，尝试从已存在的sstable文件恢复db。并返回db元信息的变动信息，一个VersionEdit对象。\n1DBImpl* impl = newDBImpl(options, dbname); 2impl-\u0026gt;mutex_.Lock(); // 锁db 3VersionEdit edit; 4Status s =impl-\u0026gt;Recover(\u0026amp;edit); // 处理flag\u0026amp;恢复：create_if_missing,error_if_exists S2 如果Recover返回成功，则调用VersionSet取得新的log文件编号——实际上是在当前基础上+1，准备新的log文件。如果log文件创建成功，则根据log文件创建log::Writer。然后执行VersionSet::LogAndApply，根据edit记录的增量变动生成新的current version，并写入MANIFEST文件。\n函数NewFileNumber(){returnnext_file_number_++;}，直接返回next_file_number_。\n1uint64_t new_log_number = impl-\u0026gt;versions_-\u0026gt;NewFileNumber(); 2WritableFile* lfile; 3s = options.env-\u0026gt;NewWritableFile(LogFileName(dbname, new_log_number), \u0026amp;lfile); 4if (s.ok()) { 5 edit.SetLogNumber(new_log_number); 6 impl-\u0026gt;logfile_ = lfile; 7 impl-\u0026gt;logfile_number_ = new_log_number; 8 impl-\u0026gt;log_ = newlog::Writer(lfile); 9 s = impl-\u0026gt;versions_-\u0026gt;LogAndApply(\u0026amp;edit, \u0026amp;impl-\u0026gt;mutex_); 10} S3 如果VersionSet::LogAndApply返回成功，则删除过期文件，检查是否需要执行compaction，最终返回创建的DBImpl对象。\n1if (s.ok()) { 2 impl-\u0026gt;DeleteObsoleteFiles(); 3 impl-\u0026gt;MaybeScheduleCompaction(); 4} 5impl-\u0026gt;mutex_.Unlock(); 6if (s.","title":"leveldb源码分析20"},{"content":"leveldb源码分析21 本系列《leveldb源码分析》共有22篇文章，这是第二十一篇\n14 DB的查询与遍历之1 分析完如何打开和关闭db，本章就继续分析如何从db中根据key查询value，以及遍历整个db。\n14.1 Get() 函数声明：StatusGet(const ReadOptions\u0026amp; options, const Slice\u0026amp; key, std::string* value) 从DB中查询key 对应的value，参数@options指定读取操作的选项，典型的如snapshot号，从指定的快照中读取。快照本质上就是一个sequence号，后面将单独在快照一章中分析。 下面就来分析下函数逻辑：\n// S1 锁mutex，防止并发，如果指定option则尝试获取snapshot；然后增加MemTable的引用值。 MutexLock l(\u0026amp;mutex_); SequenceNumber snapshot; if (options.snapshot != NULL) snapshot = reinterpret_cast\u0026lt;const SnapshotImpl*\u0026gt;(options.snapshot)-\u0026gt;number_; else snapshot = versions_-\u0026gt;LastSequence(); // 取当前版本的最后Sequence MemTable *mem = mem_, *imm = imm_; Version* current = versions_-\u0026gt;current(); mem-\u0026gt;Ref(); if (imm != NULL) imm-\u0026gt;Ref(); current-\u0026gt;Ref(); // S2 从sstable文件和MemTable中读取时，释放锁mutex；之后再次锁mutex。 bool have_stat_update = false; Version::GetStats stats; { mutex_.Unlock(); // 先从memtable中查询，再从immutable memtable中查询 LookupKey lkey(key, snapshot); if (mem-\u0026gt;Get(lkey, value, \u0026amp;s)) { } else if (imm != NULL \u0026amp;\u0026amp; imm-\u0026gt;Get(lkey, value, \u0026amp;s)) { } else { // 需要从sstable文件中查询 s = current-\u0026gt;Get(options, lkey, value, \u0026amp;stats); have_stat_update = true; // 记录之，用于compaction } mutex_.Lock(); } // S3 如果是从sstable文件查询出来的，检查是否需要做compaction。最后把MemTable的引用计数减1。 if (have_stat_update \u0026amp;¤t-\u0026gt;UpdateStats(stats)) { MaybeScheduleCompaction(); } mem-\u0026gt;Unref(); if (imm != NULL)imm-\u0026gt;Unref(); current-\u0026gt;Unref(); 查询是比较简单的操作，UpdateStats在前面Version一节已经分析过。\n14.2 NewIterator() 函数声明：Iterator*NewIterator(const ReadOptions\u0026amp; options) 通过该函数生产了一个Iterator*对象，调用这就可以基于该对象遍历db内容了。 函数很简单，调用两个函数创建了一个二级Iterator。\nIterator* DBImpl::NewIterator(const ReadOptions\u0026amp; options) { SequenceNumber latest_snapshot; Iterator* internal_iter = NewInternalIterator(options, \u0026amp;latest_snapshot); returnNewDBIterator(\u0026amp;dbname_, env_, user_comparator(), internal_iter, (options.snapshot != NULL ? reinterpret_cast\u0026lt;constSnapshotImpl*\u0026gt;(options.snapshot)-\u0026gt;number_ : latest_snapshot)); } 其中，函数NewDBIterator直接返回了一个DBIter指针\nIterator* NewDBIterator(const std::string* dbname, Env* env, const Comparator*user_key_comparator, Iterator* internal_iter, const SequenceNumber\u0026amp; sequence) { return new DBIter(dbname, env, user_key_comparator, internal_iter, sequence); } 函数NewInternalIterator有一些处理逻辑，就是收集所有能用到的iterator，生产一个Merging Iterator。这包括MemTable，Immutable MemTable，以及各sstable。\nIterator* DBImpl::NewInternalIterator(const ReadOptions\u0026amp; options, SequenceNumber*latest_snapshot) { IterState* cleanup = newIterState; mutex_.Lock(); // 根据last sequence设置lastest snapshot，并收集所有的子iterator *latest_snapshot = versions_-\u0026gt;LastSequence(); std::vector\u0026lt;Iterator*\u0026gt;list; list.push_back(mem_-\u0026gt;NewIterator()); // \u0026gt;memtable mem_-\u0026gt;Ref(); if (imm_ != NULL) { list.push_back(imm_-\u0026gt;NewIterator()); // \u0026gt;immutablememtable imm_-\u0026gt;Ref(); } versions_-\u0026gt;current()-\u0026gt;AddIterators(options, \u0026amp;list); // \u0026gt;current的所有sstable Iterator* internal_iter = NewMergingIterator(\u0026amp;internal_comparator_, \u0026amp;list[0], list.size()); versions_-\u0026gt;current()-\u0026gt;Ref(); // 注册清理机制 cleanup-\u0026gt;mu = \u0026amp;mutex_; cleanup-\u0026gt;mem = mem_; cleanup-\u0026gt;imm = imm_; cleanup-\u0026gt;version = versions_-\u0026gt;current(); internal_iter-\u0026gt;RegisterCleanup(CleanupIteratorState, cleanup, NULL); mutex_.Unlock(); return internal_iter; } 这个清理函数CleanupIteratorState是很简单的，对注册的对象做一下Unref操作即可。\nstatic void CleanupIteratorState(void* arg1, void* arg2) { IterState* state = reinterpret_cast\u0026lt;IterState*\u0026gt;(arg1); state-\u0026gt;mu-\u0026gt;Lock(); state-\u0026gt;mem-\u0026gt;Unref(); if (state-\u0026gt;imm != NULL)state-\u0026gt;imm-\u0026gt;Unref(); state-\u0026gt;version-\u0026gt;Unref(); state-\u0026gt;mu-\u0026gt;Unlock(); delete state; } 可见对于db的遍历依赖于DBIter和Merging Iterator这两个迭代器，它们都是Iterator接口的实现子类。\n14.3 MergingIterator MergingIterator是一个合并迭代器，它内部使用了一组自Iterator，保存在其成员数组children_中。如上面的函数NewInternalIterator，包括memtable，immutable memtable，以及各sstable文件；它所做的就是根据调用者指定的key和sequence，从这些Iterator中找到合适的记录。 在分析其Iterator接口之前，先来看看两个辅助函数FindSmallest和FindLargest。FindSmallest从0开始向后遍历内部Iterator数组，找到key最小的Iterator，并设置到current_；FindLargest从最后一个向前遍历内部Iterator数组，找到key最大的Iterator，并设置到current_； MergingIterator还定义了两个移动方向：kForward，向前移动；kReverse，向后移动。\n14.3.1 Get系接口 下面就把其接口拖出来一个一个分析，首先是简单接口，key和value都是返回current_的值，current_是当前seek到的Iterator位置。\nvirtual Slice key() const { assert(Valid()); return current_-\u0026gt;key(); } virtual Slice value() const { assert(Valid()); return current_-\u0026gt;value(); } virtual Status status() const { Status status; for (int i = 0; i \u0026lt; n_; i++) { // 只有所有内部Iterator都ok时，才返回ok status = children_[i].status(); if (!status.ok()) break; } return status; } 14.3.2 Seek系接口 然后是几个seek系的函数，也比较简单，都是依次调用内部Iterator的seek系函数。然后做merge，对于Seek和SeekToFirst都调用FindSmallest；对于SeekToLast调用FindLargest。\nvirtual void SeekToFirst() { for (int i = 0; i \u0026lt; n_; i++) children_[i].SeekToFirst(); FindSmallest(); direction_ = kForward; } virtual void SeekToLast() { for (int i = 0; i \u0026lt; n_; i++) children_[i].SeekToLast(); FindLargest(); direction_ = kReverse; } virtual void Seek(constSlice\u0026amp; target) { for (int i = 0; i \u0026lt; n_; i++) children_[i].Seek(target); FindSmallest(); direction_ = kForward; } 14.3.3 逐步移动 最后就是Next和Prev函数，完成迭代遍历。这可能会有点绕。下面分别来说明。 首先，在Next移动时，如果当前direction不是kForward的，也就是上一次调用了Prev或者SeekToLast函数，就需要先调整除current之外的所有iterator，为什么要做这种调整呢？啰嗦一点，考虑如下的场景，如图14.3-1所示。\n图14.3-1 Next的移动\n当前direction为kReverse，并且有：Current = memtable Iterator。各Iterator位置为：{memtable, stable 0, sstable1} ={ key3:1:1, key2:3:1, key2:1:1}，这符合prev操作的largest key要求。 注：需要说明下，对于每个update操作，leveldb都会赋予一个全局唯一的sequence号，且是递增的。例子中的sequence号可理解为每个key的相对值，后面也是如此。 接下来我们来分析Prev移动的操作。 第一次Prev，current(memtable iterator)移动到key1:3:0上，3者中最大者变成sstable0；因此current修改为sstable0； 第二次Prev，current(sstable0 Iterator)移动到key1:2:1上，3者中最大者变成sstable1；因此current修改为sstable1: 此时各Iterator的位置为{memtable, sstable 0, sstable1} = { key1:3:0, key1:2:1, key2:2:1}，并且current=sstable1。 接下来再调用Next，显然当前Key()为key2:2:1，综合考虑3个iterator，两次Next()的调用结果应该是key2:1:1和key3:1:1。而memtable和sstable0指向的key却是key1:3:0和key1:2:1，这时就需要调整memtable和sstable0了，使他们都定位到Key()之后，也就是key3:1:1和key2:3:1上。 然后current(current1)Next移动到key2:1:1上。这就是Next时的调整逻辑，同理，对于Prev也有相同的调整逻辑。代码如下：\nvirtual void Next() { assert(Valid()); // 确保所有的子Iterator都定位在key()之后. // 如果我们在正向移动，对于除current_外的所有子Iterator这点已然成立 // 因为current_是最小的子Iterator，并且key() = current_-\u0026gt;key()。 // 否则，我们需要明确设置其它的子Iterator if (direction_ != kForward) { for (int i = 0; i \u0026lt; n_; i++) { // 把所有current之外的Iterator定位到key()之后 IteratorWrapper* child = \u0026amp;children_[i]; if (child != current_) { child-\u0026gt;Seek(key()); if (child-\u0026gt;Valid() \u0026amp;\u0026amp; comparator_-\u0026gt;Compare(key(), child-\u0026gt;key()) == 0) child-\u0026gt;Next(); // key等于current_-\u0026gt;key()的，再向后移动一位 } } direction_ = kForward; } // current也向后移一位，然后再查找key最小的Iterator current_-\u0026gt;Next(); FindSmallest(); } virtual void Prev() { assert(Valid()); // 确保所有的子Iterator都定位在key()之前. // 如果我们在逆向移动，对于除current_外的所有子Iterator这点已然成立 // 因为current_是最大的，并且key() = current_-\u0026gt;key() // 否则，我们需要明确设置其它的子Iterator if (direction_ != kReverse) { for (int i = 0; i \u0026lt; n_; i++) { IteratorWrapper* child = \u0026amp;children_[i]; if (child != current_) { child-\u0026gt;Seek(key()); if (child-\u0026gt;Valid()) { // child位于\u0026gt;=key()的第一个entry上，prev移动一位到\u0026lt;key() child-\u0026gt;Prev(); } else { // child所有的entry都 \u0026lt; key()，直接seek到last即可 child-\u0026gt;SeekToLast(); } } } direction_ = kReverse; } //current也向前移一位，然后再查找key最大的Iterator current_-\u0026gt;Prev(); FindLargest(); } 这就是MergingIterator的全部代码逻辑了，每次Next或者Prev移动时，都要重新遍历所有的子Iterator以找到key最小或最大的Iterator作为current_。这就是merge的语义所在了。 但是它没有考虑到删除标记等问题，因此直接使用MergingIterator是不能正确的遍历DB的，这些问题留待给DBIter来解决。\n","permalink":"https://haokiu.com/blog/1d4ede18ded04a569baee5550226fa6f/","summary":"leveldb源码分析21 本系列《leveldb源码分析》共有22篇文章，这是第二十一篇\n14 DB的查询与遍历之1 分析完如何打开和关闭db，本章就继续分析如何从db中根据key查询value，以及遍历整个db。\n14.1 Get() 函数声明：StatusGet(const ReadOptions\u0026amp; options, const Slice\u0026amp; key, std::string* value) 从DB中查询key 对应的value，参数@options指定读取操作的选项，典型的如snapshot号，从指定的快照中读取。快照本质上就是一个sequence号，后面将单独在快照一章中分析。 下面就来分析下函数逻辑：\n// S1 锁mutex，防止并发，如果指定option则尝试获取snapshot；然后增加MemTable的引用值。 MutexLock l(\u0026amp;mutex_); SequenceNumber snapshot; if (options.snapshot != NULL) snapshot = reinterpret_cast\u0026lt;const SnapshotImpl*\u0026gt;(options.snapshot)-\u0026gt;number_; else snapshot = versions_-\u0026gt;LastSequence(); // 取当前版本的最后Sequence MemTable *mem = mem_, *imm = imm_; Version* current = versions_-\u0026gt;current(); mem-\u0026gt;Ref(); if (imm != NULL) imm-\u0026gt;Ref(); current-\u0026gt;Ref(); // S2 从sstable文件和MemTable中读取时，释放锁mutex；之后再次锁mutex。 bool have_stat_update = false; Version::GetStats stats; { mutex_.Unlock(); // 先从memtable中查询，再从immutable memtable中查询 LookupKey lkey(key, snapshot); if (mem-\u0026gt;Get(lkey, value, \u0026amp;s)) { } else if (imm != NULL \u0026amp;\u0026amp; imm-\u0026gt;Get(lkey, value, \u0026amp;s)) { } else { // 需要从sstable文件中查询 s = current-\u0026gt;Get(options, lkey, value, \u0026amp;stats); have_stat_update = true; // 记录之，用于compaction } mutex_.","title":"leveldb源码分析21"},{"content":"leveldb源码分析22 本系列《leveldb源码分析》共有22篇文章，这是第二十二篇\n14 DB的查询与遍历之2 14.4 DBIter Leveldb数据库的MemTable和sstable文件的存储格式都是**(user key, seq, type) =\u0026gt; uservalue**。DBIter把同一个userkey在DB中的多条记录合并为一条，综合考虑了userkey的序号、删除标记、和写覆盖等等因素。 从前面函数NewIterator的代码还能看到，DBIter内部使用了MergingIterator，在调用MergingItertor的系列seek函数后，DBIter还要处理key的删除标记。否则，遍历时会把已删除的key列举出来。 DBIter还定义了两个移动方向，默认是kForward： 1） kForward，向前移动，代码保证此时DBIter的内部迭代器刚好定位在this-\u0026gt;key(),this-\u0026gt;value()这条记录上； 2） kReverse，向后移动，代码保证此时DBIter的内部迭代器刚好定位在所有key=this-\u0026gt;key()的entry之前。 其成员变量savedkey和saved value保存的是KReverse方向移动时的k/v对，每次seek系调用之后，其值都会跟随iter_而改变。 DBIter的代码开始读来感觉有些绕，主要就是它要处理删除标记，而且其底层的MergingIterator，对于同一个key会有多个不同sequence的entry。导致其Next/Prev操作比较复杂，要考虑到上一次移动的影响，跳过删除标记和重复的key。 DBIter必须导出Iterator定义的几个接口，下面就拖出来挨个分析。\n14.4.1 Get系接口 首先是几个简单接口，获取key、value和status的：\n//kForward直接取iter_-\u0026gt;value()，否则取saved value virtual Slice value() const { assert(valid_); return (direction_ == kForward) ? iter_-\u0026gt;value() : saved_value_; } virtual Status status() const { if (status_.ok()) returniter_-\u0026gt;status(); return status_; } 14.4.2 辅助函数 在分析seek系函数之前，先来理解两个重要的辅助函数：FindNextUserEntry和FindPrevUserEntry的功能和逻辑。其功能就是循环跳过下一个/前一个delete的记录，直到遇到kValueType的记录。 先来看看，函数声明为： void DBIter::FindNextUserEntry(bool skipping, std::string* skip) 参数@skipping表明是否要跳过sequence更小的entry； 参数@skip临时存储空间，保存seek时要跳过的key； 在进入FindNextUserEntry时，iter_刚好定位在this-\u0026gt;key(), this-\u0026gt;value()这条记录上。下面来看函数实现：\nvirtual Slice key() const { //kForward直接取iter_-\u0026gt;key()，否则取saved key assert(valid_); return (direction_ == kForward) ? ExtractUserKey(iter_-\u0026gt;key()) : saved_key_; } // 循环直到找到合适的entry，direction必须是kForward assert(iter_-\u0026gt;Valid()); assert(direction_ == kForward); do { ParsedInternalKey ikey; // 确保iter_-\u0026gt;key()的sequence \u0026lt;= 遍历指定的sequence if (ParseKey(\u0026amp;ikey) \u0026amp;\u0026amp; ikey.sequence \u0026lt;= sequence_) { switch (ikey.type) { case kTypeDeletion: //对于该key，跳过后面遇到的所有entry，它们被这次删除覆盖了 //保存key到skip中，并设置skipping=true SaveKey(ikey.user_key, skip); skipping = true; break; case kTypeValue: if (skipping \u0026amp;\u0026amp; user_comparator_-\u0026gt;Compare(ikey.user_key, *skip) \u0026lt;= 0) { // 这是一个被删除覆盖的entry，或者user key比指定的key小，跳过 } else { // 找到，清空saved key并返回，iter_已定位到正确的entry valid_ = true; saved_key_.clear(); return; } break; } } iter_-\u0026gt;Next(); // 继续检查下一个entry } while (iter_-\u0026gt;Valid()); // 到这里表明已经找到最后了，没有符合的entry saved_key_.clear(); valid_ = false; FindNextUserKey移动方向是kForward，DBIter在向kForward移动时，借用了saved key作为临时缓存。FindNextUserKey确保定位到的entry的sequence不会大于指定的sequence，并跳过被删除标记覆盖的旧记录。 接下来是FindPrevUserKey，函数声明为：void DBIter::FindPrevUserEntry()，在进入FindPrevUserEntry时，iter_刚好位于saved key对应的所有记录之前。源代码如下：\nassert(direction_ == kReverse); // 确保是kReverse方向 ValueType value_type =kTypeDeletion; //后面的循环至少执行一次Prev操作 if (iter_-\u0026gt;Valid()) { do { // 循环 // 确保iter_-\u0026gt;key()的sequence \u0026lt;= 遍历指定的sequence ParsedInternalKey ikey; if (ParseKey(\u0026amp;ikey)\u0026amp;\u0026amp; ikey.sequence \u0026lt;= sequence_) { if ((value_type !=kTypeDeletion) \u0026amp;\u0026amp; user_comparator_-\u0026gt;Compare(ikey.user_key, saved_key_) \u0026lt; 0) { break; // 我们遇到了前一个key的一个未被删除的entry，跳出循环 // 此时Key()将返回saved_key，saved key非空； } //根据类型，如果是Deletion则清空saved key和saved value //否则，把iter_的user key和value赋给saved key和saved value value_type = ikey.type; if (value_type ==kTypeDeletion) { saved_key_.clear(); ClearSavedValue(); } else { Slice raw_value =iter_-\u0026gt;value(); if(saved_value_.capacity() \u0026gt; raw_value.size() + 1048576) { std::string empty; swap(empty,saved_value_); } SaveKey(ExtractUserKey(iter_-\u0026gt;key()), \u0026amp;saved_key_); saved_value_.assign(raw_value.data(), raw_value.size()); } } iter_-\u0026gt;Prev(); // 前一个 } while (iter_-\u0026gt;Valid()); } if (value_type == kTypeDeletion){ // 表明遍历结束了，将direction设置为kForward valid_ = false; saved_key_.clear(); ClearSavedValue(); direction_ = kForward; } else { valid_ = true; } 函数FindPrevUserKey根据指定的sequence，依次检查前一个entry，直到遇到user key小于saved key，并且类型不是Delete的entry。如果entry的类型是Delete，就清空saved key和saved value，这样在依次遍历前一个entry的循环中，只要类型不是Delete，就是要找的entry。这就是Prev的语义。\n14.4.3 Seek系函数 了解了这两个重要的辅助函数，可以分析几个Seek接口了，它们需要借助于上面的这两个函数来跳过被delete的记录。\nvoid DBIter::Seek(const Slice\u0026amp; target) { direction_ = kForward; // 向前seek // 清空saved value和saved key，并根据target设置saved key ClearSavedValue(); saved_key_.clear(); AppendInternalKey( // kValueTypeForSeek(1) \u0026gt; kDeleteType(0) \u0026amp;saved_key_,ParsedInternalKey(target, sequence_, kValueTypeForSeek)); iter_-\u0026gt;Seek(saved_key_); // iter seek到saved key //可以定位到合法的iter，还需要跳过Delete的entry if (iter_-\u0026gt;Valid()) FindNextUserEntry(false,\u0026amp;saved_key_); else valid_ = false; } void DBIter::SeekToFirst() { direction_ = kForward; // 向前seek // 清空saved value，首先iter_-\u0026gt;SeekToFirst，然后跳过Delete的entry ClearSavedValue(); iter_-\u0026gt;SeekToFirst(); if (iter_-\u0026gt;Valid()) FindNextUserEntry(false,\u0026amp;saved_key_ /*临时存储*/); else valid_ = false; } void DBIter::SeekToLast() { // 更简单 direction_ = kReverse; ClearSavedValue(); iter_-\u0026gt;SeekToLast(); FindPrevUserEntry(); } 14.4.4 Prev()和Next() Next和Prev接口，相对复杂一些。和底层的merging iterator不同，DBIter的Prev和Next步进是以key为单位的，而mergingiterator是以一个record为单位的。所以在调用merging Iterator做Prev和Next迭代时，必须循环直到key发生改变。 这次让我们以Prev为例，以14.4-1图解一下，还真是一图胜千言啊。 假设指定读取的sequence为2，当前iter在key4:2:1上，direction为kForward。此时调用Prev()，此图显示了Prev操作执行的5个步骤：\nS1 首先因为direction为kForward，先调整iter到key3:1:1上。此图也说明了调整的理由，key4:2:1前面还有key4:3:1。然后进入FindPrevUserEntry函数，执行S2到S4。 S2 跳到key3:2:0上时，这是一个删除标记，清空saved key（其中保存的是key3:1:1）。 S3 循环继续，跳到key2:1:1上，此时key2:1:1 \u0026gt; saved key，设置saved key为key2:1:1，并继续循环。 S4 循环继续，跳到key2:2:1上，此时key2:2:1 \u0026gt; saved key，设置saved key为key2:2:1，并继续循环。 S5 跳到Key1:1:1上，因为key1:1:1 \u0026lt; saved key，跳出循环。 最终状态iter_位置在key1:1:1上，而saved key保存的则是key2:2:1上，这也就是Prev应该定位到的值。也就是说在Prev操作下，iter_的位置并不是真正的key位置。这就是前面Get系函数中，在direction为kReverse时，返回saved key/value的原因。 同理，在Next时，如果direction是kReverse，根据上面的Prev可以发现，此时iter刚好是saved key的前一个entry。执行**iter-\u0026gt;Next()**就跳到了saved key的dentry范围的sequence最大的那个entry。在前面的例子中，在Prev后执行Next，那么iter首先跳转到key2:3:1上，然后再调用FindNextUserEntry循环，使iter定位在key2:2:1上。 下面首先来分析Next的实现。如果direction是kReverse，表明上一次做的是kReverse跳转，这种情况下，iter_位于key是this-\u0026gt;key()的所有entry之前，我们需要先把iter_跳转到this-\u0026gt;key()对应的entries范围内。\nvoid DBIter::Next() { assert(valid_); if (direction_ == kReverse) { //需要预处理，并更改direction=kForward direction_ = kForward; // iter_刚好在this-\u0026gt;key()的所有entry之前，所以先跳转到this-\u0026gt;key() // 的entries范围之内，然后再做常规的skip if (!iter_-\u0026gt;Valid()) iter_-\u0026gt;SeekToFirst(); else iter_-\u0026gt;Next(); if (!iter_-\u0026gt;Valid()) { valid_ = false; saved_key_.clear(); return; } } // 把saved_key_ 用作skip的临时存储空间 std::string* skip =\u0026amp;saved_key_; SaveKey(ExtractUserKey(iter_-\u0026gt;key()), skip);// 设置skip为iter_-\u0026gt;key()的user key FindNextUserEntry(true, skip); } 接下来是Prev()，其实和Next()逻辑相似，但方向相反。\n如果direction是kForward，表明上一次是做的是kForward跳转，这种情况下，iter_指向当前的entry，我们需要调整iter，使其指向到前一个key，iter的位置是这个key所有record序列的最后一个，也就是sequence最小的那个record。\nvoid DBIter::Prev() { assert(valid_); if (direction_ == kForward) { //需要预处理，并更改direction // iter_指向当前的entry，向后扫描直到key发生改变，然后我们可以做 //常规的reverse扫描 assert(iter_-\u0026gt;Valid()); // iter_必须合法，并把saved key设置为iter_-\u0026gt;key() SaveKey(ExtractUserKey(iter_-\u0026gt;key()), \u0026amp;saved_key_); while (true) { iter_-\u0026gt;Prev(); if (!iter_-\u0026gt;Valid()) { // 到头了，直接返回 valid_ = false; saved_key_.clear(); ClearSavedValue(); return; } if (user_comparator_-\u0026gt;Compare(ExtractUserKey(iter_-\u0026gt;key()), saved_key_) \u0026lt; 0) { break; // key变化就跳出循环，此时iter_刚好位于saved key对应的所有entry之前 } } direction_ = kReverse; } FindPrevUserEntry(); } 接下来要分析的是插入和删除操作。\n14.5 小结 查询操作并不复杂，只需要根据seq找到最新的记录即可。知道leveldb的遍历会比较复杂，不过也没想到会这么复杂。这主要是得益于sstable 0的重合性，以及memtable和sstable文件的重合性。\nleveldb源码分析全系列完。\n","permalink":"https://haokiu.com/blog/08d56462861f4df7b247921ba14a88e2/","summary":"leveldb源码分析22 本系列《leveldb源码分析》共有22篇文章，这是第二十二篇\n14 DB的查询与遍历之2 14.4 DBIter Leveldb数据库的MemTable和sstable文件的存储格式都是**(user key, seq, type) =\u0026gt; uservalue**。DBIter把同一个userkey在DB中的多条记录合并为一条，综合考虑了userkey的序号、删除标记、和写覆盖等等因素。 从前面函数NewIterator的代码还能看到，DBIter内部使用了MergingIterator，在调用MergingItertor的系列seek函数后，DBIter还要处理key的删除标记。否则，遍历时会把已删除的key列举出来。 DBIter还定义了两个移动方向，默认是kForward： 1） kForward，向前移动，代码保证此时DBIter的内部迭代器刚好定位在this-\u0026gt;key(),this-\u0026gt;value()这条记录上； 2） kReverse，向后移动，代码保证此时DBIter的内部迭代器刚好定位在所有key=this-\u0026gt;key()的entry之前。 其成员变量savedkey和saved value保存的是KReverse方向移动时的k/v对，每次seek系调用之后，其值都会跟随iter_而改变。 DBIter的代码开始读来感觉有些绕，主要就是它要处理删除标记，而且其底层的MergingIterator，对于同一个key会有多个不同sequence的entry。导致其Next/Prev操作比较复杂，要考虑到上一次移动的影响，跳过删除标记和重复的key。 DBIter必须导出Iterator定义的几个接口，下面就拖出来挨个分析。\n14.4.1 Get系接口 首先是几个简单接口，获取key、value和status的：\n//kForward直接取iter_-\u0026gt;value()，否则取saved value virtual Slice value() const { assert(valid_); return (direction_ == kForward) ? iter_-\u0026gt;value() : saved_value_; } virtual Status status() const { if (status_.ok()) returniter_-\u0026gt;status(); return status_; } 14.4.2 辅助函数 在分析seek系函数之前，先来理解两个重要的辅助函数：FindNextUserEntry和FindPrevUserEntry的功能和逻辑。其功能就是循环跳过下一个/前一个delete的记录，直到遇到kValueType的记录。 先来看看，函数声明为： void DBIter::FindNextUserEntry(bool skipping, std::string* skip) 参数@skipping表明是否要跳过sequence更小的entry； 参数@skip临时存储空间，保存seek时要跳过的key； 在进入FindNextUserEntry时，iter_刚好定位在this-\u0026gt;key(), this-\u0026gt;value()这条记录上。下面来看函数实现：\nvirtual Slice key() const { //kForward直接取iter_-\u0026gt;key()，否则取saved key assert(valid_); return (direction_ == kForward) ? ExtractUserKey(iter_-\u0026gt;key()) : saved_key_; } // 循环直到找到合适的entry，direction必须是kForward assert(iter_-\u0026gt;Valid()); assert(direction_ == kForward); do { ParsedInternalKey ikey; // 确保iter_-\u0026gt;key()的sequence \u0026lt;= 遍历指定的sequence if (ParseKey(\u0026amp;ikey) \u0026amp;\u0026amp; ikey.","title":"leveldb源码分析22"},{"content":"leveldb源码分析3 本系列《leveldb源码分析》共有22篇文章，这是第三篇。\n4. Memtable之一 Memtable是leveldb很重要的一块，leveldb的核心之一。我们肯定关注KV数据在Memtable中是如何组织的，秘密在Skip list中。\n4.1 用途 在Leveldb中，所有内存中的KV数据都存储在Memtable中，物理disk则存储在SSTable中。在系统运行过程中，如果Memtable中的数据占用内存到达指定值(Options.write_buffer_size)，则Leveldb就自动将Memtable转换为Memtable，并自动生成新的Memtable，也就是Copy-On-Write机制了。\nImmutable Memtable则被新的线程Dump到磁盘中，Dump结束则该Immutable Memtable就可以释放了。因名知意，Immutable Memtable是只读的。\n所以可见，最新的数据都是存储在Memtable中的，Immutable Memtable和物理SSTable则是某个时点的数据。\n为了防止系统down机导致内存数据Memtable或者Immutable Memtable丢失，leveldb自然也依赖于log机制来保证可靠性了。\nMemtable提供了写入KV记录，删除以及读取KV记录的接口，但是事实上**Memtable并不执行真正的删除操作,**删除某个Key的Value在Memtable内是作为插入一条记录实施的，但是会打上一个Key的删除标记，真正的删除操作在后面的 Compaction过程中，lazy delete。\n4.2 核心是Skip list 另外，Memtable中的KV对是根据Key排序的，leveldb在插入等操作时保证key的有序性。想想，前面看到的Skip list不正是合适的人选吗，因此Memtable的核心数据结构是一个Skip list，Memtable只是一个接口类。当然随之而来的一个问题就是Skip list是如何组织KV数据对的，在后面分析Memtable的插入、查询接口时我们将会看到答案。\n4.3 接口说明 先来看看Memtable的接口：\nvoid Ref() { ++refs_; } void Unref(); Iterator* NewIterator(); void Add(SequenceNumber seq, ValueType type, const Slice\u0026amp; key, const Slice\u0026amp; value); bool Get(const LookupKey\u0026amp; key, std::string* value, Status* s); 首先Memtable是基于引用计数的机制，如果引用计数为0，则在Unref中删除自己，Ref和Unref就是干这个的。\nNewIterator是返回一个迭代器，可以遍历访问table的内部数据，很好的设计思想，这种方式隐藏了table的内部实现。外部调用者必须保证使用Iterator访问Memtable的时候该Memtable是live的。 Add和Get是添加和获取记录的接口，没有Delete，还记得前面说过，memtable的delete实际上是插入一条type为kTypeDeletion的记录。 4.4 类图 先来看看Memtable相关的整体类层次吧，并不复杂，还是相当清晰的。见图4.4-1。\n4.5 Key结构 Memtable是一个KV存储结构，那么这个key肯定是个重点了，在分析接口实现之前，有必要仔细分析一下Memtable对key的使用。\n这里面有5个key的概念，可能会让人混淆，下面就来一个一个的分析。\n4.5.1 InternalKey \u0026amp; ParsedInternalKey \u0026amp; User Key InternalKey是一个复合概念，是有几个部分组合成的一个key，ParsedInternalKey就是对InternalKey分拆后的结果，先来看看ParsedInternalKey的成员，这是一个struct：\nSlice user_key; SequenceNumber sequence; ValueType type; 也就是说InternalKey是由User key + SequenceNumber + ValueType组合而成的，顺便先分析下几个Key相关的函数，它们是了解Internal Key和User Key的关键。\n首先是InternalKey和ParsedInternalKey相互转换的两个函数，如下。\nbool ParseInternalKey (const Slice\u0026amp; internal_key, ParsedInternalKey* result); void AppendInternalKey (std::string* result, const ParsedInternalKey\u0026amp; key); 函数实现很简单，就是字符串的拼接与把字符串按字节拆分，代码略过。根据实现，容易得到InternalKey的格式为：\n| User key (string) | sequence number (7 bytes) | value type (1 byte) | 由此还可知道sequence number大小是7 bytes，sequence number是所有基于op log系统的关键数据，它唯一指定了不同操作的时间顺序。\n把user key放到前面****的原因是，这样对同一个user key的操作就可以按照sequence number顺序连续存放了，不同的user key是互不相干的，因此把它们的操作放在一起也没有什么意义。\n另外用户可以为user key定制比较函数，系统默认是字母序的。\n下面的两个函数是分别从InternalKey中拆分出User Key和Value Type的，非常直观，代码也附上吧。\ninline Slice ExtractUserKey(const Slice\u0026amp; internal_key) { assert(internal_key.size() \u0026gt;= 8); return Slice(internal_key.data(), internal_key.size() - 8); } inline ValueType ExtractValueType(const Slice\u0026amp; internal_key) { assert(internal_key.size() \u0026gt;= 8); const size_t n = internal_key.size(); uint64_t num = DecodeFixed64(internal_key.data() + n - 8); unsigned char c = num \u0026amp; 0xff; return static_cast\u0026lt;ValueType\u0026gt;(c); } 4.5.2 LookupKey \u0026amp; Memtable Key Memtable的查询接口传入的是LookupKey，它也是由User Key和Sequence Number组合而成的，从其构造函数：\nLookupKey(const Slice\u0026amp; user_key, SequenceNumber s) 中分析出LookupKey的格式为：\n| Size (int32变长)| User key (string) | sequence number (7 bytes) | value type (1 byte) | 两点：\n这里的Size是user key长度+8，也就是整个字符串长度了； value type是kValueTypeForSeek，它等于kTypeValue。 由于LookupKey的size是变长存储的，因此它使用kstart_记录了user key string的起始地址，否则将不能正确的获取size和user key；\nLookupKey导出了三个函数，可以分别从LookupKey得到Internal Key，Memtable Key和User Key，如下：\n// Return a key suitable for lookup in a MemTable. Slice memtable_key() const { return Slice(start_, end_ - start_); } // Return an internal key (suitable for passing to an internal iterator) Slice internal_key() const { return Slice(kstart_, end_ - kstart_); } // Return the user key Slice user_key() const { return Slice(kstart_, end_ - kstart_ - 8); } 其中**start_**是LookupKey字符串的开始，**end_**是结束，**kstart_**是start_+4，也就是user key字符串的起始地址。\n","permalink":"https://haokiu.com/blog/34fc58749a224c92be698a0d9cd27b99/","summary":"leveldb源码分析3 本系列《leveldb源码分析》共有22篇文章，这是第三篇。\n4. Memtable之一 Memtable是leveldb很重要的一块，leveldb的核心之一。我们肯定关注KV数据在Memtable中是如何组织的，秘密在Skip list中。\n4.1 用途 在Leveldb中，所有内存中的KV数据都存储在Memtable中，物理disk则存储在SSTable中。在系统运行过程中，如果Memtable中的数据占用内存到达指定值(Options.write_buffer_size)，则Leveldb就自动将Memtable转换为Memtable，并自动生成新的Memtable，也就是Copy-On-Write机制了。\nImmutable Memtable则被新的线程Dump到磁盘中，Dump结束则该Immutable Memtable就可以释放了。因名知意，Immutable Memtable是只读的。\n所以可见，最新的数据都是存储在Memtable中的，Immutable Memtable和物理SSTable则是某个时点的数据。\n为了防止系统down机导致内存数据Memtable或者Immutable Memtable丢失，leveldb自然也依赖于log机制来保证可靠性了。\nMemtable提供了写入KV记录，删除以及读取KV记录的接口，但是事实上**Memtable并不执行真正的删除操作,**删除某个Key的Value在Memtable内是作为插入一条记录实施的，但是会打上一个Key的删除标记，真正的删除操作在后面的 Compaction过程中，lazy delete。\n4.2 核心是Skip list 另外，Memtable中的KV对是根据Key排序的，leveldb在插入等操作时保证key的有序性。想想，前面看到的Skip list不正是合适的人选吗，因此Memtable的核心数据结构是一个Skip list，Memtable只是一个接口类。当然随之而来的一个问题就是Skip list是如何组织KV数据对的，在后面分析Memtable的插入、查询接口时我们将会看到答案。\n4.3 接口说明 先来看看Memtable的接口：\nvoid Ref() { ++refs_; } void Unref(); Iterator* NewIterator(); void Add(SequenceNumber seq, ValueType type, const Slice\u0026amp; key, const Slice\u0026amp; value); bool Get(const LookupKey\u0026amp; key, std::string* value, Status* s); 首先Memtable是基于引用计数的机制，如果引用计数为0，则在Unref中删除自己，Ref和Unref就是干这个的。\nNewIterator是返回一个迭代器，可以遍历访问table的内部数据，很好的设计思想，这种方式隐藏了table的内部实现。外部调用者必须保证使用Iterator访问Memtable的时候该Memtable是live的。 Add和Get是添加和获取记录的接口，没有Delete，还记得前面说过，memtable的delete实际上是插入一条type为kTypeDeletion的记录。 4.4 类图 先来看看Memtable相关的整体类层次吧，并不复杂，还是相当清晰的。见图4.4-1。\n4.5 Key结构 Memtable是一个KV存储结构，那么这个key肯定是个重点了，在分析接口实现之前，有必要仔细分析一下Memtable对key的使用。\n这里面有5个key的概念，可能会让人混淆，下面就来一个一个的分析。\n4.5.1 InternalKey \u0026amp; ParsedInternalKey \u0026amp; User Key InternalKey是一个复合概念，是有几个部分组合成的一个key，ParsedInternalKey就是对InternalKey分拆后的结果，先来看看ParsedInternalKey的成员，这是一个struct：\nSlice user_key; SequenceNumber sequence; ValueType type; 也就是说InternalKey是由User key + SequenceNumber + ValueType组合而成的，顺便先分析下几个Key相关的函数，它们是了解Internal Key和User Key的关键。\n首先是InternalKey和ParsedInternalKey相互转换的两个函数，如下。\nbool ParseInternalKey (const Slice\u0026amp; internal_key, ParsedInternalKey* result); void AppendInternalKey (std::string* result, const ParsedInternalKey\u0026amp; key); 函数实现很简单，就是字符串的拼接与把字符串按字节拆分，代码略过。根据实现，容易得到InternalKey的格式为：","title":"leveldb源码分析3"},{"content":"leveldb源码分析4 本系列《leveldb源码分析》共有22篇文章，这是第四篇\n4.Memtable之2 4.6 Comparator 弄清楚了key，接下来就要看看key的使用了，先从Comparator开始分析。首先Comparator是一个抽象类，导出了几个接口。\n其中**Name()和Compare()**接口都很明了，另外的两个Find xxx接口都有什么功能呢，直接看程序注释：\n//Advanced functions: these are used to reduce the space requirements //for internal data structures like index blocks. // 这两个函数：用于减少像index blocks这样的内部数据结构占用的空间 // 其中的*start和*key参数都是IN OUT的。 //If *start \u0026lt; limit, changes *start to a short string in [start,limit). //Simple comparator implementations may return with *start unchanged, //i.e., an implementation of this method that does nothing is correct. // 这个函数的作用就是：如果*start \u0026lt; limit，就在[startlimit,)中找到一个 // 短字符串，并赋给*start返回 // 简单的comparator实现可能不改变*start，这也是正确的 virtual void FindShortestSeparator(std::string* start, const Slice\u0026amp; limit) const = 0; //Changes *key to a short string \u0026gt;= *key. //Simple comparator implementations may return with *key unchanged, //i.e., an implementation of this method that does nothing is correct. //这个函数的作用就是：找一个\u0026gt;= *key的短字符串 //简单的comparator实现可能不改变*key，这也是正确的 virtual void FindShortSuccessor(std::string* key) const = 0; 其中的实现类有两个，一个是内置的BytewiseComparatorImpl，另一个是InternalKeyComparator。下面分别来分析。\n4.6.1 BytewiseComparatorImpl 首先是重载的Name和比较函数，比较函数如其名，就是字符串比较，如下：\nvirtual const char* Name() const {return\u0026#34;leveldb.BytewiseComparator\u0026#34;;} virtual int Compare(const Slice\u0026amp; a, const Slice\u0026amp; b) const {return a.compare(b);} 再来看看Byte wise的comparator是如何实现**FindShortestSeparator()**的，没什么特别的，代码 + 注释如下：\nvirtual void FindShortestSeparator(std::string* start, onst Slice\u0026amp; limit) const { // 首先计算共同前缀字符串的长度 size_t min_length = std::min(start-\u0026gt;size(), limit.size()); size_t diff_index = 0; while ((diff_index \u0026lt; min_length) \u0026amp;\u0026amp; ((*start)[diff_index] == limit[diff_index])) { diff_index++; } if (diff_index \u0026gt;= min_length) { // 说明*start是limit的前缀，或者反之，此时不作修改，直接返回 } else { // 尝试执行字符start[diff_index]++， 设置start长度为diff_index+1，并返回 // ++条件：字符\u0026lt; oxff 并且字符+1 \u0026lt; limit上该index的字符 uint8_t diff_byte = static_cast\u0026lt;uint8_t\u0026gt;((*start)[diff_index]); if (diff_byte \u0026lt; static_cast\u0026lt;uint8_t\u0026gt;(0xff) \u0026amp;\u0026amp; diff_byte + 1 \u0026lt; static_cast\u0026lt;uint8_t\u0026gt;(limit[diff_index])) { (*start)[diff_index]++; start-\u0026gt;resize(diff_index + 1); assert(Compare(*start, limit) \u0026lt; 0); } } } 最后是FindShortSuccessor()，这个更简单了，代码+注释如下：\nvirtual void FindShortSuccessor(std::string* key) const { // 找到第一个可以++的字符，执行++后，截断字符串； // 如果找不到说明*key的字符都是0xff啊，那就不作修改，直接返回 size_t n = key-\u0026gt;size(); for (size_t i = 0; i \u0026lt; n; i++) { const uint8_t byte = (*key)[i]; if (byte != static_cast\u0026lt;uint8_t\u0026gt;(0xff)) { (*key)[i] = byte + 1; key-\u0026gt;resize(i+1); return; } } } Leveldb内建的基于Byte wise的comparator类就这么多内容了，下面再来看看InternalKeyComparator。\n4.6.2 InternalKeyComparator 从上面对Internal Key的讨论可知，由于它是由user key和sequence number和value type组合而成的，因此它还需要user key的比较，所以InternalKeyComparator有一个Comparator* user_comparator_成员，用于user key的比较。\n在leveldb中的名字为：\u0026ldquo;leveldb.InternalKeyComparator\u0026rdquo;，下面来看看比较函数：\nCompare(const Slice\u0026amp; akey, const Slice\u0026amp; bkey) 代码很简单，其比较逻辑是：\nS1 首先比较user key，基于用户设置的comparator，如果user key不相等就直接返回比较,否则执行进入S2 S2 取出8字节的sequence number | value type，如果akey的 \u0026gt; bkey的则返回**-1**，如果akey的**\u0026lt;bkey的返回1**，相等返回0 由此可见其排序比较依据依次是：\n首先根据user key按升序排列 然后根据sequence number按降序排列 最后根据value type按降序排列 虽然比较时value type并不重要，因为sequence number是唯一的，但是直接取出8byte的sequence number | value type，然后做比较更方便，不需要再次移位提取出7byte的sequence number，又何乐而不为呢。这也是把value type安排在低7byte的好处吧，排序的两个依据就是user key和sequence number。\n接下来就该看看其FindShortestSeparator()函数实现了，该函数取出Internal Key中的user key字段，根据user指定的comparator找到并替换start，如果start被替换了，就用新的start更新Internal Key，并使用最大的sequence number。否则保持不变。\n函数声明：\nvoid InternalKeyComparator::FindShortestSeparator(std::string* start, const Slice\u0026amp; limit) const; 函数实现：\n// 尝试更新user key，基于指定的user comparator Slice user_start = ExtractUserKey(*start); Slice user_limit = ExtractUserKey(limit); std::string tmp(user_start.data(), user_start.size()); user_comparator_-\u0026gt;FindShortestSeparator(\u0026amp;tmp, user_limit); if(tmp.size()\u0026lt;user_start.size()\u0026amp;\u0026amp; user_comparator_-\u0026gt;Compare(user_start, tmp)\u0026lt;0) { // user key在物理上长度变短了，但其逻辑值变大了.生产新的*start时， // 使用最大的sequence number，以保证排在相同user key记录序列的第一个 PutFixed64(\u0026amp;tmp, PackSequenceAndType(kMaxSequenceNumber, kValueTypeForSeek)); assert(this-\u0026gt;Compare(*start, tmp) \u0026lt; 0); assert(this-\u0026gt;Compare(tmp, limit) \u0026lt; 0); start-\u0026gt;swap(tmp); } 接下来是FindShortSuccessor(std::string* key)函数，该函数取出Internal Key中的user key字段，根据user指定的comparator找到并替换key，如果key被替换了，就用新的key更新Internal Key，并使用最大的sequence number。否则保持不变。实现逻辑如下：\nSlice user_key = ExtractUserKey(*key); // 尝试更新user key，基于指定的user comparator std::string tmp(user_key.data(), user_key.size()); user_comparator_-\u0026gt;FindShortSuccessor(\u0026amp;tmp); if(tmp.size()\u0026lt;user_key.size() \u0026amp;\u0026amp; user_comparator_-\u0026gt;Compare(user_key, tmp)\u0026lt;0) { // user key在物理上长度变短了，但其逻辑值变大了.生产新的*start时， // 使用最大的sequence number，以保证排在相同user key记录序列的第一个 PutFixed64(\u0026amp;tmp, PackSequenceAndType(kMaxSequenceNumber, kValueTypeForSeek)); assert(this-\u0026gt;Compare(*key, tmp) \u0026lt; 0); key-\u0026gt;swap(tmp); } 4.7 Memtable::Insert() 把相关的Key和Key Comparator都弄清楚后，是时候分析memtable本身了。首先是向memtable插入记录的接口，函数原型如下：\nvoid Add(SequenceNumber seq, ValueType type, const Slice\u0026amp; key, const Slice\u0026amp; value); 代码实现如下：\n// KV entry字符串有下面4部分连接而成 //key_size : varint32 of internal_key.size() //key bytes : char[internal_key.size()] //value_size : varint32 of value.size() // value bytes : char[value.size()] size_t key_size = key.size(); size_t val_size = value.size(); size_t internal_key_size = key_size + 8; const size_t encoded_len = VarintLength(internal_key_size) + internal_key_size + VarintLength(val_size) + val_size; char* buf = arena_.Allocate(encoded_len); char* p = EncodeVarint32(buf, internal_key_size); memcpy(p, key.data(), key_size); p += key_size; EncodeFixed64(p, (s \u0026lt;\u0026lt; 8) | type); p += 8; p = EncodeVarint32(p, val_size); memcpy(p, value.data(), val_size); assert((p + val_size) - buf == encoded_len); able_.Insert(buf); 根据代码，我们可以分析出KV记录在skip list的存储格式等信息，首先总长度为：\nVarInt(Internal Key size) len + internal key size + VarInt(value) len + value size 它们的相互衔接也就是KV的存储格式：\n| VarInt(Internal Key size) len | internal key |VarInt(value) len |value| 其中前面说过：\ninternal key = |user key |sequence number |type | Internal key size = key size + 8 4.8 Memtable::Get() Memtable的查找接口，根据一个LookupKey找到响应的记录，函数声明：\nbool MemTable::Get(const LookupKey\u0026amp; key, std::string* value, Status* s) 函数实现如下：\nSlice memkey = key.memtable_key(); Table::Iterator iter(\u0026amp;table_); iter.Seek(memkey.data()); // seek到value\u0026gt;= memkey.data()的第一个记录 if (iter.Valid()) { // 这里不需要再检查sequence number了，因为Seek()已经跳过了所有 // 值更大的sequence number了 const char* entry = iter.key(); uint32_t key_length; const char* key_ptr = GetVarint32Ptr(entry, entry+5, \u0026amp;key_length); // 比较user key是否相同，key_ptr开始的len(internal key) -8 byte是user key if (comparator_.comparator.user_comparator()-\u0026gt;Compare (Slice(key_ptr, key_length - 8), key.user_key()) == 0) { // len(internal key)的后8byte是 |sequence number | value type| const uint64_t tag = DecodeFixed64(key_ptr + key_length - 8); switch (static_cast\u0026lt;ValueType\u0026gt;(tag \u0026amp; 0xff)) { case kTypeValue: { // 只取出value Slice v = GetLengthPrefixedSlice(key_ptr + key_length); value-\u0026gt;assign(v.data(), v.size()); return true; } case kTypeDeletion: *s = Status::NotFound(Slice()); return true; } } } return false; 这段代码，主要就是一个Seek函数，根据传入的LookupmKey得到在emtable中存储的key，然后调用Skip list::Iterator的Seek函数查找。Seek直接调用Skip list的FindGreaterOrEqual(key)接口，返回大于等于key的Iterator。然后取出user key判断时候和传入的user key相同，如果相同则取出value，如果记录的Value Type为kTypeDeletion，返回Status::NotFound(Slice())。\n4.9 小结 Memtable到此就分析完毕了，本质上就是一个有序的Skip list，排序基于user key的sequence number，其排序比较依据依次是：\n首先根据user key按升序排列 然后根据sequence number按降序排列 最后根据value type按降序排列（这个其实无关紧要） ","permalink":"https://haokiu.com/blog/f4dfd0e7e33240c9807a11402d34ddb3/","summary":"leveldb源码分析4 本系列《leveldb源码分析》共有22篇文章，这是第四篇\n4.Memtable之2 4.6 Comparator 弄清楚了key，接下来就要看看key的使用了，先从Comparator开始分析。首先Comparator是一个抽象类，导出了几个接口。\n其中**Name()和Compare()**接口都很明了，另外的两个Find xxx接口都有什么功能呢，直接看程序注释：\n//Advanced functions: these are used to reduce the space requirements //for internal data structures like index blocks. // 这两个函数：用于减少像index blocks这样的内部数据结构占用的空间 // 其中的*start和*key参数都是IN OUT的。 //If *start \u0026lt; limit, changes *start to a short string in [start,limit). //Simple comparator implementations may return with *start unchanged, //i.e., an implementation of this method that does nothing is correct. // 这个函数的作用就是：如果*start \u0026lt; limit，就在[startlimit,)中找到一个 // 短字符串，并赋给*start返回 // 简单的comparator实现可能不改变*start，这也是正确的 virtual void FindShortestSeparator(std::string* start, const Slice\u0026amp; limit) const = 0; //Changes *key to a short string \u0026gt;= *key. //Simple comparator implementations may return with *key unchanged, //i.e., an implementation of this method that does nothing is correct.","title":"leveldb源码分析4"},{"content":"leveldb源码分析5 本系列《leveldb源码分析》共有22篇文章，这是第五篇。\n5.操作Log 1 分析完KV在内存中的存储，接下来就是操作日志。所有的写操作都必须先成功的append到操作日志中，然后再更新内存memtable。这样做有两点：\n可以将随机的写IO变成append，极大的提高写磁盘速度； 防止在节点down机导致内存数据丢失，造成数据丢失，这对系统来说是个灾难。 在各种高效的存储系统中，这已经是口水技术了。\n5.1 格式 在源码下的文档doc/log_format.txt中，作者详细描述了log格式：\nThe log file contents are a sequence of 32KB blocks. The only exception is that the tail of thefile may contain a partial block. Each block consists of a sequence of records: block:= record* trailer? record := checksum: uint32 // crc32c of type and data[] ; little-endian length: uint16 // little-endian type: uint8 // One of FULL,FIRST, MIDDLE, LAST data: uint8[length] A record never starts within the last six bytes of a block (since it won\u0026rsquo;tfit). Any leftover bytes here form thetrailer, which must consist entirely of zero bytes and must be skipped byreaders.\n翻译过来就是： Leveldb把日志文件切分成了大小为32KB的连续block块，block由连续的log record组成，log record的格式为： 注意：CRC32, Length都是little-endian的。\nLog Type有4种：FULL = 1、FIRST = 2、MIDDLE = 3、LAST = 4。FULL类型表明该log record包含了完整的user record；而user record可能内容很多，超过了block的可用大小，就需要分成几条log record，第一条类型为FIRST，中间的为MIDDLE，最后一条为LAST。也就是：\nFULL，说明该log record包含一个完整的user record； FIRST，说明是user record的第一条log record MIDDLE，说明是user record中间的log record LAST，说明是user record最后的一条log record 翻一下文档上的例子，考虑到如下序列的user records： A: length 1000 B: length 97270 C: length 8000\nA作为FULL类型的record存储在第一个block中； B将被拆分成3条log record，分别存储在第1、2、3个block中，这时block3还剩6byte，将被填充为0； C将作为FULL类型的record存储在block 4中。 由于一条logrecord长度最短为7，如果一个block的剩余空间\u0026lt;=6byte，那么将**被填充为*空字*符串，另外长度为7的log record是不包括任何用户数据的。\n5.2 写日志 写比读简单，而且写入决定了读，所以从写开始分析。有意思的是在写文件时，Leveldb使用了内存映射文件，内存映射文件的读写效率比普通文件要高，关于内存映射文件为何更高效，这篇文章写的不错： http://blog.csdn.net/mg0832058/article/details/5890688\n其中涉及到的类层次比较简单，如图5.2-1：\n注意Write类的成员type_crc_数组，这里存放的为Record Type预先计算的CRC32值，因为Record Type是固定的几种，为了效率。Writer类只有一个接口，就是AddRecord()，传入Slice参数，下面来看函数实现。首先取出slice的字符串指针和长度，初始化begin=true，表明是第一条log record。\nconst char* ptr = slice.data(); size_t left = slice.size(); bool begin = true; 然后进入一个do{}while循环，直到写入出错，或者成功写入全部数据，如下：\n1\nS1 首先查看当前block是否\u0026lt;7，如果\u0026lt;7则补位，并重置block偏移 dest_-\u0026gt;Append(Slice(\u0026#34;\\x00\\x00\\x00\\x00\\x00\\x00\u0026#34;,leftover)); block_offset_ = 0; S2 计算block剩余大小，以及本次log record可写入数据长度 const size_t avail =kBlockSize - block_offset_ - kHeaderSize; const size_t fragment_length = (left \u0026lt;avail) ? left : avail S3 根据两个值，判断log type RecordType type; const bool end = (left ==fragment_length); // 两者相等，表明写 if (begin \u0026amp;\u0026amp; end) type = kFullType; else if (begin) type = kFirstType; else if (end) type = kLastType; else type = kMiddleType; S4 调用EmitPhysicalRecord函数，append日志；并更新指针、剩余长度和begin标记 s = EmitPhysicalRecord(type, ptr,fragment_length); ptr += fragment_length; left -= fragment_length; begin = false; 2\n接下来看看EmitPhysicalRecord函数，这是实际写入的地方，涉及到log的存储格式。函数声明为：\nStatusWriter::EmitPhysicalRecord(RecordType t, const char* ptr, size_t n) 参数ptr为用户record数据，参数n为record长度，不包含log header。\nS1 计算header，并Append到log文件，共7byte格式为： | CRC32 (4 byte) | payload length lower + high (2 byte) | type (1byte)| char buf[kHeaderSize]; buf[4] = static_cast\u0026lt;char\u0026gt;(n\u0026amp; 0xff); buf[5] =static_cast\u0026lt;char\u0026gt;(n \u0026gt;\u0026gt; 8); buf[6] =static_cast\u0026lt;char\u0026gt;(t); // 计算record type和payload的CRC校验值 uint32_t crc = crc32c::Extend(type_crc_[t], ptr, n); crc = crc32c::Mask(crc); // 空间调整 EncodeFixed32(buf, crc); dest_-\u0026gt;Append(Slice(buf,kHeaderSize)); S2 写入payload，并Flush，更新block的当前偏移 s =dest_-\u0026gt;Append(Slice(ptr, n)); s = dest_-\u0026gt;Flush(); block_offset_ += kHeaderSize +n; 以上就是写日志的逻辑，很直观。\n","permalink":"https://haokiu.com/blog/81982087975a4f49913e723952169670/","summary":"leveldb源码分析5 本系列《leveldb源码分析》共有22篇文章，这是第五篇。\n5.操作Log 1 分析完KV在内存中的存储，接下来就是操作日志。所有的写操作都必须先成功的append到操作日志中，然后再更新内存memtable。这样做有两点：\n可以将随机的写IO变成append，极大的提高写磁盘速度； 防止在节点down机导致内存数据丢失，造成数据丢失，这对系统来说是个灾难。 在各种高效的存储系统中，这已经是口水技术了。\n5.1 格式 在源码下的文档doc/log_format.txt中，作者详细描述了log格式：\nThe log file contents are a sequence of 32KB blocks. The only exception is that the tail of thefile may contain a partial block. Each block consists of a sequence of records: block:= record* trailer? record := checksum: uint32 // crc32c of type and data[] ; little-endian length: uint16 // little-endian type: uint8 // One of FULL,FIRST, MIDDLE, LAST data: uint8[length] A record never starts within the last six bytes of a block (since it won\u0026rsquo;tfit). Any leftover bytes here form thetrailer, which must consist entirely of zero bytes and must be skipped byreaders.","title":"leveldb源码分析5"},{"content":"leveldb源码分析6 本系列《leveldb源码分析》共有22篇文章，这是第六篇。\n5. 操作Log 2 5.3 读日志 日志读取显然比写入要复杂，要检查checksum，检查是否有损坏等等，处理各种错误。\n5.3.1 类层次 Reader主要用到了两个接口，一个是汇报错误的Reporter，另一个是log文件读取类SequentialFile。\nReporter的接口只有一个：\nvoid Corruption(size_t bytes,const Status\u0026amp; status); SequentialFile有两个接口：\nStatus Read(size_t n, Slice* result, char* scratch); Status Skip(uint64_t n); 说明下，Read接口有一个result参数传递结果就行了，为何还有一个scratch呢，这个就和Slice相关了。它的字符串指针是传入的外部char*指针，自己并不负责内存的管理与分配。因此Read接口需要调用者提供一个字符串指针，实际存放字符串的地方。\nReader类有几个成员变量，需要注意：\nbool eof_; // 上次Read()返回长度\u0026lt; kBlockSize，暗示到了文件结尾EOF uint64_t last_record_offset_; // 函数ReadRecord返回的上一个record的偏移 uint64_t end_of_buffer_offset_;// 当前的读取偏移 uint64_t const initial_offset_;// 偏移，从哪里开始读取第一条record Slice buffer_; // 读取的内容 5.3.2日志读取流程 Reader只有一个接口，那就是ReadRecord，下面来分析下这个函数。\nS1 根据initial offset跳转到调用者指定的位置，开始读取日志文件。跳转就是直接调用SequentialFile的Seek接口。 另外，需要先调整调用者传入的initialoffset参数，调整和跳转逻辑在SkipToInitialBlock函数中。\nif (last_record_offset_ \u0026lt;initial_offset_) { // 当前偏移 \u0026lt; 指定的偏移，需要Seek if (!SkipToInitialBlock()) return false; } 下面的代码是SkipToInitialBlock函数调整read offset的逻辑：\n// 计算在block内的偏移位置，并圆整到开始读取block的起始位置 size_t offset_in_block =initial_offset_ % kBlockSize; uint64_t block_start_location =initial_offset_ - offset_in_block; // 如果偏移在最后的6byte里，肯定不是一条完整的记录，跳到下一个block if (offset_in_block \u0026gt;kBlockSize - 6) { offset_in_block = 0; block_start_location +=kBlockSize; } end_of_buffer_offset_ =block_start_location; // 设置读取偏移 if (block_start_location \u0026gt; 0) file_-\u0026gt;Skip(block_start_location); // 跳转 首先计算出在block内的偏移位置，然后圆整到要读取block的起始位置。开始读取日志的时候都要保证读取的是完整的block，这就是调整的目的。\n同时成员变量end_of_buffer_offset_记录了这个值，在后续读取中会用到。\nS2在开始while循环前首先初始化几个标记： // 当前是否在fragment内，也就是遇到了FIRST 类型的record bool in_fragmented_record = false; uint64_t prospective_record_offset = 0; // 我们正在读取的逻辑record的偏移 S3 进入到while(true)循环，直到读取到KLastType或者KFullType的record，或者到了文件结尾。从日志文件读取完整的record是ReadPhysicalRecord函数完成的。 读取出现错误时，并不会退出循环，而是汇报错误，继续执行，直到成功读取一条user record，或者遇到文件结尾。 S3.1 从文件读取record\nuint64_t physical_record_offset = end_of_buffer_offset_ -buffer_.size(); const unsigned int record_type = ReadPhysicalRecord(\u0026amp;fragment); physical_record_offset存储的是当前正在读取的record的偏移值。接下来根据不同的record_type类型，分别处理，一共有7种情况：\nS3.2 FULL type(kFullType)，表明是一条完整的log record，成功返回读取的user record数据。另外需要对早期版本做些work around，早期的Leveldb会在block的结尾生产一条空的kFirstType log record。\nif (in_fragmented_record) { if (scratch-\u0026gt;empty())in_fragmented_record = false; else ReportCorruption(scratch-\u0026gt;size(),\u0026#34;partial record without end(1)\u0026#34;); } prospective_record_offset= physical_record_offset; scratch-\u0026gt;clear(); // 清空scratch，读取成功不需要返回scratch数据 *record = fragment; last_record_offset_ =prospective_record_offset; // 更新last record offset return true; S3.3 FIRST type(kFirstType)，表明是一系列logrecord(fragment)的第一个record。同样需要对早期版本做work around。\n把数据读取到scratch中，直到成功读取了LAST类型的log record，才把数据返回到result中，继续下次的读取循环。\n如果再次遇到FIRSTor FULL类型的log record，如果scratch不为空，就说明日志文件有错误。\nif (in_fragmented_record) { if (scratch-\u0026gt;empty())in_fragmented_record = false; else ReportCorruption(scratch-\u0026gt;size(),\u0026#34;partial record without end(2)\u0026#34;); } prospective_record_offset =physical_record_offset; scratch-\u0026gt;assign(fragment.data(), fragment.size()); //赋值给scratch in_fragmented_record =true; // 设置fragment标记为true S3.4 MIDDLE type(kMiddleType)，这个处理很简单，如果不是在fragment中，报告错误，否则直接append到scratch中就可以了。\nif (!in_fragmented_record) { ReportCorruption(fragment.size(), \u0026#34;missing start of fragmentedrecord(1)\u0026#34;); } else {scratch-\u0026gt;append(fragment.data(),fragment.size());} S3.5 LAST type(kLastType)，说明是一系列log record(fragment)中的最后一条。如果不在fragment中，报告错误。\nif (!in_fragmented_record) { ReportCorruption(fragment.size(), \u0026#34;missing start of fragmentedrecord(2)\u0026#34;); } else { scratch-\u0026gt;append(fragment.data(), fragment.size()); *record = Slice(*scratch); last_record_offset_ =prospective_record_offset; return true; } 至此，4种正常的log record type已经处理完成，下面3种情况是其它的错误处理，类型声明在Logger类中：\nenum { kEof = kMaxRecordType + 1, // 遇到文件结尾 // 非法的record，当前有3中情况会返回bad record： // * CRC校验失败 (ReadPhysicalRecord reports adrop) // * 长度为0 (No drop is reported) // * 在指定的initial_offset之外 (No drop is reported) kBadRecord = kMaxRecordType +2 }; S3.6 遇到文件结尾kEof，返回false。不返回任何结果。\nif (in_fragmented_record) { ReportCorruption(scratch-\u0026gt;size(), \u0026#34;partial record withoutend(3)\u0026#34;); scratch-\u0026gt;clear(); } return false; S3.7 非法的record(kBadRecord)，如果在fragment中，则报告错误。\nif (in_fragmented_record) { ReportCorruption(scratch-\u0026gt;size(), \u0026#34;error in middle ofrecord\u0026#34;); in_fragmented_record = false; scratch-\u0026gt;clear(); } S3.8 缺省分支，遇到非法的record 类型，报告错误，清空scratch。\nReportCorruption(…, \u0026#34;unknownrecord type %u\u0026#34;, record_type); in_fragmented_record = false; // 重置fragment标记 scratch-\u0026gt;clear();// 清空scratch 上面就是ReadRecord的全部逻辑，解释起来还有些费力。\n5.3.3 从log文件读取record 就是前面讲过的ReadPhysicalRecord函数，它调用SequentialFile的Read接口，从文件读取数据。\n该函数开始就进入了一个while(true)循环，其目的是为了读取到一个完整的record。读取的内容存放在成员变量**buffer_**中。这样的逻辑有些奇怪，实际上，完全不需要一个while(true)循环的。\n函数基本逻辑如下：\nS1 如果buffer_小于block header大小kHeaderSize，进入如下的几个分支： S1.1 如果eof_为false，表明还没有到文件结尾，清空buffer，并读取数据。\nbuffer_.clear(); // 因为上次肯定读取了一个完整的record Status status =file_-\u0026gt;Read(kBlockSize, \u0026amp;buffer_, backing_store_); end_of_buffer_offset_ +=buffer_.size(); // 更新buffer读取偏移值 if (!status.ok()) { // 读取失败，设置eof_为true，报告错误并返回kEof buffer_.clear(); ReportDrop(kBlockSize,status); eof_ = true; return kEof; } else if (buffer_.size()\u0026lt; kBlockSize) { eof_ = true; // 实际读取字节\u0026lt;指定(Block Size)，表明到了文件结尾 } continue; // 继续下次循环 S1.2 如果eof_为true并且buffer为空，表明已经到了文件结尾，正常结束，返回kEof。\nS1.3 否则，也就是eof_为true，buffer不为空，说明文件结尾包含了一个不完整的record，报告错误，返回kEof。\nsize_t drop_size =buffer_.size(); buffer_.clear(); ReportCorruption(drop_size,\u0026#34;truncated record at end of file\u0026#34;); return kEof; S2 进入到这里表明上次循环中的Read读取到了一个完整的log record，continue后的第二次循环判断buffer_.size() \u0026gt;= kHeaderSize将执行到此处。 解析出log record的header部分，判断长度是否一致。\n根据log的格式，前4byte是crc32。后面就是length和type，解析如下：\nconst char* header = buffer_.data(); const uint32_t length = ((header[4])\u0026amp; 0xff) | ((header[5]\u0026amp;0xff)\u0026lt;\u0026lt;8) const uint32_t type = header[6]; if (kHeaderSize + length \u0026gt;buffer_.size()) { // 长度超出了，汇报错误 size_t drop_size =buffer_.size(); buffer_.clear(); ReportCorruption(drop_size,\u0026#34;bad record length\u0026#34;); return kBadRecord; // 返回kBadRecord } if (type == kZeroType\u0026amp;\u0026amp; length == 0) { // 对于Zero Type类型，不汇报错误 buffer_.clear(); return kBadRecord; // 依然返回kBadRecord } S3 校验CRC32，如果校验出错，则汇报错误，并返回kBadRecord。 S4 如果record的开始位置在initial offset之前，则跳过，并返回kBadRecord，否则返回record数据和type。 buffer_.remove_prefix(kHeaderSize+ length); if (end_of_buffer_offset_ -buffer_.size() - kHeaderSize - length \u0026lt; initial_offset_) { result-\u0026gt;clear(); return kBadRecord; } *result = Slice(header +kHeaderSize, length); return type; 从log文件读取record的逻辑就是这样的。至此，读日志的逻辑也完成了。接下来将进入磁盘存储的sstable部分。\n","permalink":"https://haokiu.com/blog/3e005b6becda44edaa67dc81f32d5499/","summary":"leveldb源码分析6 本系列《leveldb源码分析》共有22篇文章，这是第六篇。\n5. 操作Log 2 5.3 读日志 日志读取显然比写入要复杂，要检查checksum，检查是否有损坏等等，处理各种错误。\n5.3.1 类层次 Reader主要用到了两个接口，一个是汇报错误的Reporter，另一个是log文件读取类SequentialFile。\nReporter的接口只有一个：\nvoid Corruption(size_t bytes,const Status\u0026amp; status); SequentialFile有两个接口：\nStatus Read(size_t n, Slice* result, char* scratch); Status Skip(uint64_t n); 说明下，Read接口有一个result参数传递结果就行了，为何还有一个scratch呢，这个就和Slice相关了。它的字符串指针是传入的外部char*指针，自己并不负责内存的管理与分配。因此Read接口需要调用者提供一个字符串指针，实际存放字符串的地方。\nReader类有几个成员变量，需要注意：\nbool eof_; // 上次Read()返回长度\u0026lt; kBlockSize，暗示到了文件结尾EOF uint64_t last_record_offset_; // 函数ReadRecord返回的上一个record的偏移 uint64_t end_of_buffer_offset_;// 当前的读取偏移 uint64_t const initial_offset_;// 偏移，从哪里开始读取第一条record Slice buffer_; // 读取的内容 5.3.2日志读取流程 Reader只有一个接口，那就是ReadRecord，下面来分析下这个函数。\nS1 根据initial offset跳转到调用者指定的位置，开始读取日志文件。跳转就是直接调用SequentialFile的Seek接口。 另外，需要先调整调用者传入的initialoffset参数，调整和跳转逻辑在SkipToInitialBlock函数中。\nif (last_record_offset_ \u0026lt;initial_offset_) { // 当前偏移 \u0026lt; 指定的偏移，需要Seek if (!SkipToInitialBlock()) return false; } 下面的代码是SkipToInitialBlock函数调整read offset的逻辑：\n// 计算在block内的偏移位置，并圆整到开始读取block的起始位置 size_t offset_in_block =initial_offset_ % kBlockSize; uint64_t block_start_location =initial_offset_ - offset_in_block; // 如果偏移在最后的6byte里，肯定不是一条完整的记录，跳到下一个block if (offset_in_block \u0026gt;kBlockSize - 6) { offset_in_block = 0; block_start_location +=kBlockSize; } end_of_buffer_offset_ =block_start_location; // 设置读取偏移 if (block_start_location \u0026gt; 0) file_-\u0026gt;Skip(block_start_location); // 跳转 首先计算出在block内的偏移位置，然后圆整到要读取block的起始位置。开始读取日志的时候都要保证读取的是完整的block，这就是调整的目的。","title":"leveldb源码分析6"},{"content":"leveldb源码分析7 本系列《leveldb源码分析》共有22篇文章，这是第七篇。\n6. SSTable之一 SSTable是Leveldb的核心之一，是表数据最终在磁盘上的物理存储。也是体量比较大的模块。\n6.1 SSTable的文件组织 作者在文档doc/table_format.txt中描述了表的逻辑结构，如图6.1-1所示。逻辑上可分为两大块，数据存储区Data Block，以及各种Meta信息。\n文件中的k/v对是有序存储的，并且被划分到连续排列的Data Block里面，这些Data Block从文件头开始顺序存储，Data Block的存储格式代码在block_builder.cc中；\n紧跟在Data Block之后的是Meta Block，其格式代码也在block_builder.cc中；Meta Block存储的是Filter信息，比如Bloom过滤器，用于快速定位key是否在data block中。\nMetaIndex Block是对Meta Block的索引，它只有一条记录，key是meta index的名字（也就是Filter的名字），value为指向meta index的BlockHandle；BlockHandle是一个结构体，成员offset_是Block在文件中的偏移，成员size_是block的大小；\nIndex block是对Data Block的索引，对于其中的每个记录，其key \u0026gt;=Data Block最后一条记录的key，同时\u0026lt;其后Data Block的第一条记录的key；value是指向data index的BlockHandle；\nFooter，文件的最后，大小固定，其格式如图6.1-2所示。\n成员metaindex_handle指出了meta index block的起始位置和大小； 成员index_handle指出了index block的起始地址和大小； 这两个字段都是BlockHandle对象，可以理解为索引的索引，通过Footer可以直接定位到metaindex和index block。再后面是一个填充区和魔数（0xdb4775248b80fb57）。\n6.2 Block存储格式 6.2.1 Block的逻辑存储 Data Block是具体的k/v数据对存储区域，此外还有存储meta的metaIndex Block，存储data block索引信息的Index Block等等，他们都是以Block的方式存储的。来看看Block是如何组织的。每个Block有三部分构成：block data, type, crc32，如图6.2-1所示。\n类型type指明使用的是哪种压缩方式，当前支持none和snappy压缩。\n虽然block有好几种，但是Block Data都是有序的k/v对，因此写入、读取BlockData的接口都是统一的，对于Block Data的管理也都是相同的。\n对Block的写入、读取将在创建、读取sstable时分析，知道了格式之后，其读取写入代码都是很直观的。\n由于sstable对数据的存储格式都是Block，因此在分析sstable的读取和写入逻辑之前，我们先来分析下Leveldb对Block Data的管理。\nLeveldb对Block Data的管理是读写分离的，读取后的遍历查询操作由Block类实现，BlockData的构建则由BlockBuilder类实现。\n6.2.2 重启点-restartpoint BlockBuilder对key的存储是前缀压缩的，对于有序的字符串来讲，这能极大的减少存储空间。但是却增加了查找的时间复杂度，为了兼顾查找效率，每隔K个key，leveldb就不使用前缀压缩，而是存储整个key，这就是重启点（restartpoint）。\n在构建Block时，有参数Options::block_restart_interval定每隔几个key就直接存储一个重启点key。\nBlock在结尾记录所有重启点的偏移，可以二分查找指定的key。Value直接存储在key的后面，无压缩。\n对于一个k/v对，其在block中的存储格式为：\n共享前缀长度 shared_bytes: varint32\n前缀之后的字符串长度 unshared_bytes: varint32\n值的长度 value_length: varint32\n前缀之后的字符串 key_delta: char[unshared_bytes]\n值 value: char[value_length]\n对于重启点，shared_bytes= 0\nBlock的结尾段格式是：\n\u0026gt; restarts: uint32[num_restarts]\n\u0026gt; num_restarts: uint32 // 重启点个数\n**元素restarts[i]**存储的是block的第i个重启点的偏移。很明显第一个k/v对，总是第一个重启点，也就是restarts[0] = 0;\n图6.2-2给出了block的存储示意图。\n总体来看Block可分为k/v存储区和后面的重启点存储区两部分，其中k/v的存储格式如前面所讲，可看做4部分：\n前缀压缩的key长度信息 + value长度 + key前缀之后的字符串+ value\n最后一个4byte为重启点的个数。\n对Block的存储格式了解之后，对Block的构建和读取代码分析就是很直观的事情了。见下面的分析。\n6.3 Block的构建与读取 6.3.1 BlockBuilder的接口 首先从Block的构建开始，这就是BlockBuilder类，来看下BlockBuilder的函数接口，一共有5个：\nvoid Reset(); // 重设内容，通常在Finish之后调用已构建新的block //添加k/v，要求：Reset()之后没有调用过Finish()；Key \u0026gt; 任何已加入的key void Add(const Slice\u0026amp; key,const Slice\u0026amp; value); // 结束构建block，并返回指向block内容的指针 Slice Finish();// 返回Slice的生存周期：Builder的生存周期，or直到Reset()被调用 size_t CurrentSizeEstimate()const; // 返回正在构建block的未压缩大小—估计值 bool empty() const { returnbuffer_.empty();} // 没有entry则返回true 主要成员变量如下：\nstd::string buffer_; // block的内容 std::vector\u0026lt;uint32_t\u0026gt; restarts_; // 重启点-后面会分析到 int counter_; // 重启后生成的entry数 std::string last_key_; // 记录最后添加的key 6.3.2 BlockBuilder::Add() 调用Add函数向当前Block中新加入一个k/v对{key, value}。函数处理逻辑如下：\nS1 保证新加入的key \u0026gt; 已加入的任何一个key； assert(!finished_); assert(counter_ \u0026lt;= options_-\u0026gt;block_restart_interval); assert(buffer_.empty() || options_-\u0026gt;comparator-\u0026gt;Compare(key,last_key_piece) \u0026gt; 0); S2 如果计数器counter \u0026lt; opions-\u0026gt;block_restart_interval，则使用前缀算法压缩key，否则就把key作为一个重启点，无压缩存储； Slice last_key_piece(last_key_); if (counter_ \u0026lt; options_-\u0026gt;block_restart_interval) { //前缀压缩 // 计算key与last_key_的公共前缀 const size_t min_length= std::min(last_key_piece.size(), key.size()); while ((shared \u0026lt; min_length)\u0026amp;\u0026amp; (last_key_piece[shared] == key[shared])) { shared++; } else { // 新的重启点 restarts_.push_back(buffer_.size()); counter_ = 0; } Slice last_key_piece(last_key_); if (counter_ \u0026lt; options_-\u0026gt;block_restart_interval) { //前缀压缩 // 计算key与last_key_的公共前缀 const size_t min_length= std::min(last_key_piece.size(), key.size()); while ((shared \u0026lt; min_length)\u0026amp;\u0026amp; (last_key_piece[shared] == key[shared])) { shared++; } else { // 新的重启点 restarts_.push_back(buffer_.size()); counter_ = 0; } S3根据上面的数据格式存储k/v对，追加到buffer中，并更新block状态。 const size_t non_shared = key.size() - shared; // key前缀之后的字符串长度 // append\u0026#34;\u0026lt;shared\u0026gt;\u0026lt;non_shared\u0026gt;\u0026lt;value_size\u0026gt;\u0026#34; 到buffer_ PutVarint32(\u0026amp;buffer_, shared); PutVarint32(\u0026amp;buffer_, non_shared); PutVarint32(\u0026amp;buffer_, value.size()); // 其后是前缀之后的字符串 + value buffer_.append(key.data() + shared, non_shared); buffer_.append(value.data(), value.size()); // 更新状态 ，last_key_ = key及计数器counter_ last_key_.resize(shared); // 连一个string的赋值都要照顾到，使内存copy最小化 last_key_.append(key.data() + shared, non_shared); assert(Slice(last_key_) == key); counter_++; 6.3.3 BlockBuilder::Finish()\n调用该函数完成Block的构建，很简单，压入重启点信息，并返回buffer_，设置结束标记finished_:\nfor (size_t i = 0; i \u0026lt; restarts_.size(); i++) { // 重启点 PutFixed32(\u0026amp;buffer_, restarts_[i]); } PutFixed32(\u0026amp;buffer_, restarts_.size()); // 重启点数量 finished_ = true; return Slice(buffer_); 6.3.4 BlockBuilder::Reset() \u0026amp; 大小 还有Reset和CurrentSizeEstimate两个函数，Reset复位函数，清空各个信息；函数CurrentSizeEstimate返回block的预计大小，从函数实现来看，应该在调用Finish之前调用该函数。\nvoid BlockBuilder::Reset() { buffer_.clear(); restarts_.clear(); last_key_.clear(); restarts_.push_back(0); // 第一个重启点位置总是 0 counter_ = 0; finished_ = false; } size_t BlockBuilder::CurrentSizeEstimate () const { // buffer大小 +重启点数组长度 + 重启点长度(uint32) return (buffer_.size() + restarts_.size() * sizeof(uint32_t) + sizeof(uint32_t)); } Block的构建就这些内容了，下面开始分析Block的读取，就是类Block。\n6.3.5 Block类接口 对Block的读取是由类Block完成的，先来看看其函数接口和关键成员变量。\nBlock只有两个函数接口，通过Iterator对象，调用者就可以遍历访问Block的存储的k/v对了；以及几个成员变量，如下：\nsize_t size() const { returnsize_; } Iterator* NewIterator(constComparator* comparator); const char* data_; // block数据指针 size_t size_; // block数据大小 uint32_t restart_offset_; // 重启点数组在data_中的偏移 bool owned_; //data_[]是否是Block拥有的 6.3.6 Block初始化 Block的构造函数接受一个BlockContents对象contents初始化，BlockContents是一个有3个成员的结构体。\n\u0026gt;data = Slice(); \u0026gt;cachable = false; // 无cache \u0026gt;heap_allocated = false; // 非heap分配 根据contents为成员赋值\ndata_ = contents.data.data(), size_ =contents.data.size(),owned_ = contents.heap_allocated; 然后从data中解析出重启点数组，如果数据太小，或者重启点计算出错，就设置size_=0，表明该block data解析失败。\nif (size_ \u0026lt; sizeof(uint32_t)){ size_ = 0; // 出错了 } else { restart_offset_ = size_ - (1 +NumRestarts()) * sizeof(uint32_t); if (restart_offset_ \u0026gt; size_- sizeof(uint32_t)) size_ = 0; } NumRestarts()函数就是从最后的uint32解析出重启点的个数，并返回:\nreturn DecodeFixed32(data_ +size_ - sizeof(uint32_t)) 6.3.7 Block::Iter 这是一个用以遍历Block内部数据的内部类，它继承了Iterator接口。函数NewIterator返回Block::Iter对象：\nreturn new Iter(cmp, data_,restart_offset_, num_restarts); 下面我们就分析Iter的实现。\n主要成员变量有：\nconst Comparator* constcomparator_; // key比较器 const char* const data_; // block内容 uint32_t const restarts_; // 重启点(uint32数组)在data中的偏移 uint32_t const num_restarts_; // 重启点个数 uint32_t current_; // 当前entry在data中的偏移. \u0026gt;= restarts_表明非法 uint32_t restart_index_; // current_所在的重启点的index 下面来看看对Iterator接口的实现，简单函数略过。\n首先是Next()函数，直接调用private函数ParseNextKey()跳到下一个k/v对，函数实现如下：\nS1 跳到下一个entry，其位置紧邻在当前value_之后。如果已经是最后一个entry了，返回false，标记current_为invalid。 current_ = NextEntryOffset(); // (value_.data() + value_.size()) - data_ const char* p = data_ +current_; const char* limit = data_ +restarts_; // Restarts come right after data if (p \u0026gt;= limit) { // entry到头了，标记为invalid. current_ = restarts_; restart_index_ =num_restarts_; return false; } S2 解析出entry，解析出错则设置错误状态，记录错误并返回false。解析成功则根据信息组成key和value，并更新重启点index。 uint32_t shared, non_shared,value_length; p = DecodeEntry(p, limit,\u0026amp;shared, \u0026amp;non_shared, \u0026amp;value_length); if (p == NULL || key_.size()\u0026lt; shared) { CorruptionError(); return false; } else { // 成功 key_.resize(shared); key_.append(p, non_shared); value_ = Slice(p +non_shared, value_length); while (restart_index_ + 1\u0026lt; num_restarts_ \u0026amp;\u0026amp; GetRestartPoint(restart_index_ + 1) \u0026lt; current_) { ++restart_index_; //更新重启点index } return true; } 函数DecodeEntry从字符串[p, limit)解析出key的前缀长度、key前缀之后的字符串长度和value的长度这三个vint32值，代码很简单。 **函数CorruptionError将current_和restart_index_**都设置为invalid状态，并在status中设置错误状态。 函数GetRestartPoint从data中读取指定restart index的偏移值restart[index]，并返回： DecodeFixed32(data_ + restarts_ +index * sizeof(uint32_t); 接下来看看Prev函数，Previous操作分为两步：首先回到current_之前的重启点，然后再向后直到current_，实现如下：\nS1首先向前回跳到在current_前面的那个重启点，并定位到重启点的k/v对开始位置。 const uint32_t original =current_; while (GetRestartPoint(restart_index_)\u0026gt;= original) { // 到第一个entry了，标记invalid状态 if (restart_index_ == 0) { current_ = restarts_; restart_index_ =num_restarts_; return; } restart_index_--; } //根据restart index定位到重启点的k/v对 SeekToRestartPoint(restart_index_); S2 第二步，从重启点位置开始向后遍历，直到遇到original前面的那个k/v对。 do {} while (ParseNextKey() \u0026amp;\u0026amp;NextEntryOffset() \u0026lt; original); 说说上面遇到的SeekToRestartPoint函数，它只是设置了几个有限的状态，其它值将在函数ParseNextKey()中设置。感觉这有点tricky，这里的value_并不是k/v对的value，而只是一个指向k/v对起始位置的0长度指针，这样后面的ParseNextKey函数将会取出重启点的k/v值。\nvoid SeekToRestartPoint(uint32_tindex) { key_.clear(); restart_index_ = index; // ParseNextKey()会设置current_; //ParseNextKey()从value_结尾开始, 因此需要相应的设置value_ uint32_t offset =GetRestartPoint(index); value_ = Slice(data_ + offset,0); // value长度设置为0，字符串指针是data_+offset } SeekToFirst/Last，这两个函数都很简单，借助于前面的SeekToResartPoint函数就可以完成。\nvirtual void SeekToFirst() { SeekToRestartPoint(0); ParseNextKey(); } virtual void SeekToLast() { SeekToRestartPoint(num_restarts_ - 1); while (ParseNextKey()\u0026amp;\u0026amp; NextEntryOffset() \u0026lt; restarts_) {} //Keep skipping } 最后一个Seek函数，跳到指定的target(Slice)，函数逻辑如下：\nS1 二分查找，找到key \u0026lt; target的最后一个重启点，典型的二分查找算法，代码就不再贴了。 S2 找到后，跳转到重启点，其索引由left指定，这是前面二分查找到的结果。如前面所分析的，value_指向重启点的地址，而size_指定为0，这样ParseNextKey函数将会取出重启点的k/v值。 SeekToRestartPoint(left); S3 自重启点线性向下，直到遇到key\u0026gt;= target的k/v对。 while (true) { if (!ParseNextKey()) return; if (Compare(key_, target)\u0026gt;= 0) return; } 上面就是Block::Iter的全部实现逻辑，这样Block的创建和读取遍历都已经分析完毕。\n","permalink":"https://haokiu.com/blog/b3a81cdfb8624332bd1f184097675b32/","summary":"leveldb源码分析7 本系列《leveldb源码分析》共有22篇文章，这是第七篇。\n6. SSTable之一 SSTable是Leveldb的核心之一，是表数据最终在磁盘上的物理存储。也是体量比较大的模块。\n6.1 SSTable的文件组织 作者在文档doc/table_format.txt中描述了表的逻辑结构，如图6.1-1所示。逻辑上可分为两大块，数据存储区Data Block，以及各种Meta信息。\n文件中的k/v对是有序存储的，并且被划分到连续排列的Data Block里面，这些Data Block从文件头开始顺序存储，Data Block的存储格式代码在block_builder.cc中；\n紧跟在Data Block之后的是Meta Block，其格式代码也在block_builder.cc中；Meta Block存储的是Filter信息，比如Bloom过滤器，用于快速定位key是否在data block中。\nMetaIndex Block是对Meta Block的索引，它只有一条记录，key是meta index的名字（也就是Filter的名字），value为指向meta index的BlockHandle；BlockHandle是一个结构体，成员offset_是Block在文件中的偏移，成员size_是block的大小；\nIndex block是对Data Block的索引，对于其中的每个记录，其key \u0026gt;=Data Block最后一条记录的key，同时\u0026lt;其后Data Block的第一条记录的key；value是指向data index的BlockHandle；\nFooter，文件的最后，大小固定，其格式如图6.1-2所示。\n成员metaindex_handle指出了meta index block的起始位置和大小； 成员index_handle指出了index block的起始地址和大小； 这两个字段都是BlockHandle对象，可以理解为索引的索引，通过Footer可以直接定位到metaindex和index block。再后面是一个填充区和魔数（0xdb4775248b80fb57）。\n6.2 Block存储格式 6.2.1 Block的逻辑存储 Data Block是具体的k/v数据对存储区域，此外还有存储meta的metaIndex Block，存储data block索引信息的Index Block等等，他们都是以Block的方式存储的。来看看Block是如何组织的。每个Block有三部分构成：block data, type, crc32，如图6.2-1所示。\n类型type指明使用的是哪种压缩方式，当前支持none和snappy压缩。\n虽然block有好几种，但是Block Data都是有序的k/v对，因此写入、读取BlockData的接口都是统一的，对于Block Data的管理也都是相同的。\n对Block的写入、读取将在创建、读取sstable时分析，知道了格式之后，其读取写入代码都是很直观的。\n由于sstable对数据的存储格式都是Block，因此在分析sstable的读取和写入逻辑之前，我们先来分析下Leveldb对Block Data的管理。\nLeveldb对Block Data的管理是读写分离的，读取后的遍历查询操作由Block类实现，BlockData的构建则由BlockBuilder类实现。\n6.2.2 重启点-restartpoint BlockBuilder对key的存储是前缀压缩的，对于有序的字符串来讲，这能极大的减少存储空间。但是却增加了查找的时间复杂度，为了兼顾查找效率，每隔K个key，leveldb就不使用前缀压缩，而是存储整个key，这就是重启点（restartpoint）。\n在构建Block时，有参数Options::block_restart_interval定每隔几个key就直接存储一个重启点key。\nBlock在结尾记录所有重启点的偏移，可以二分查找指定的key。Value直接存储在key的后面，无压缩。\n对于一个k/v对，其在block中的存储格式为：\n共享前缀长度 shared_bytes: varint32\n前缀之后的字符串长度 unshared_bytes: varint32\n值的长度 value_length: varint32\n前缀之后的字符串 key_delta: char[unshared_bytes]\n值 value: char[value_length]\n对于重启点，shared_bytes= 0\nBlock的结尾段格式是：\n\u0026gt; restarts: uint32[num_restarts]\n\u0026gt; num_restarts: uint32 // 重启点个数\n**元素restarts[i]**存储的是block的第i个重启点的偏移。很明显第一个k/v对，总是第一个重启点，也就是restarts[0] = 0;\n图6.2-2给出了block的存储示意图。\n总体来看Block可分为k/v存储区和后面的重启点存储区两部分，其中k/v的存储格式如前面所讲，可看做4部分：\n前缀压缩的key长度信息 + value长度 + key前缀之后的字符串+ value","title":"leveldb源码分析7"},{"content":"leveldb源码分析8 本系列《leveldb源码分析》共有22篇文章，这是第八篇\n6 SSTable之2 6.4 创建sstable文件 了解了sstable文件的存储格式，以及Data Block的组织，下面就可以分析如何创建sstable文件了。相关代码在table_builder.h/.cc以及block_builder.h/.cc（构建Block）中。\n6.4.1 TableBuilder类 构建sstable文件的类是TableBuilder，该类提供了几个有限的方法可以用来添加k/v对，Flush到文件中等等，它依赖于BlockBuilder来构建Block。\nTableBuilder的几个接口说明下：\nvoid Add(const Slice\u0026amp; key, const Slice\u0026amp; value)，向当前正在构建的表添加新的{key, value}对，要求根据Option指定的Comparator，key必须位于所有前面添加的key之后； void Flush()，将当前缓存的k/v全部flush到文件中，一个高级方法，大部分的client不需要直接调用该方法； void Finish()，结束表的构建，该方法被调用后，将不再会使用传入的WritableFile； void Abandon()，结束表的构建，并丢弃当前缓存的内容，该方法被调用后，将不再会使用传入的WritableFile；【只是设置closed为true，无其他操作】 一旦**Finish()/Abandon()**方法被调用，将不能再次执行Flush或者Add操作。 下面来看看涉及到的类，如图6.3-1所示。 图6.3-1\n其中WritableFile和op log一样，使用的都是内存映射文件。Options是一些调用者可设置的选项。\nTableBuilder只有一个成员变量Rep* rep_，实际上Rep结构体的成员就是TableBuilder所有的成员变量；这样做的目的，可能是为了隐藏其内部细节。Rep的定义也是在.cc文件中，对外是透明的。\n简单解释下成员的含义：\nOptions options; // data block的选项 Options index_block_options; // index block的选项 WritableFile* file; // sstable文件 uint64_t offset; // 要写入data block在sstable文件中的偏移，初始0 Status status; //当前状态-初始ok BlockBuilder data_block; //当前操作的data block BlockBuilder index_block; // sstable的index block std::string last_key; //当前data block最后的k/v对的key int64_t num_entries; //当前data block的个数，初始0 bool closed; //调用了Finish() or Abandon()，初始false FilterBlockBuilder*filter_block; //根据filter数据快速定位key是否在block中 bool pending_index_entry; //见下面的Add函数，初始false BlockHandle pending_handle; //添加到index block的data block的信息 std::string compressed_output;//压缩后的data block，临时存储，写入后即被清空 Filter block是存储的过滤器信息，它会存储{key, 对应data block在sstable的偏移值}，不一定是完全精确的，以快速定位给定key是否在data block中。\n下面分析如何向sstable中添加k/v对，创建并持久化sstable。其它函数都比较简单，略过。另外对于Abandon，简单设置closed=true即返回。\n6.4.2 添加k/v对 这是通过方法**Add(constSlice\u0026amp; key, const Slice\u0026amp; value)**完成的，没有返回值。下面分析下函数的逻辑：\n1\nS1 首先保证文件没有close，也就是没有调用过Finish/Abandon，以及保证当前status是ok的；如果当前有缓存的kv对，保证新加入的key是最大的。\nRep* r = rep_; assert(!r-\u0026gt;closed); if (!ok()) return; if (r-\u0026gt;num_entries \u0026gt; 0) { assert(r-\u0026gt;options.comparator-\u0026gt;Compare(key, Slice(r-\u0026gt;last_key))\u0026gt; 0); } S2 如果标记r-\u0026gt;pending_index_entry为true，表明遇到下一个data block的第一个k/v，根据key调整r-\u0026gt;last_key，这是通过Comparator的FindShortestSeparator完成的。\nif (r-\u0026gt;pending_index_entry) { assert(r-\u0026gt;data_block.empty()); r-\u0026gt;options.comparator-\u0026gt;FindShortestSeparator(\u0026amp;r-\u0026gt;last_key,key); std::string handle_encoding; r-\u0026gt;pending_handle.EncodeTo(\u0026amp;handle_encoding); r-\u0026gt;index_block.Add(r-\u0026gt;last_key, Slice(handle_encoding)); r-\u0026gt;pending_index_entry =false; } 接下来将pending_handle加入到index block中{r-\u0026gt;last_key, r-\u0026gt;pending_handle’sstring}。最后将r-\u0026gt;pending_index_entry设置为false。\n值得讲讲pending_index_entry这个标记的意义，见代码注释：\n直到遇到下一个databock的第一个key时，我们才为上一个datablock生成index entry，这样的好处是：可以为index使用较短的key；比如上一个data block最后一个k/v的key是\u0026quot;the quick brown fox\u0026quot;，其后继data block的第一个key是\u0026quot;the who\u0026quot;，我们就可以用一个较短的字符串\u0026ldquo;the r\u0026quot;作为上一个data block的index block entry的key。\n简而言之，就是在开始下一个datablock时，Leveldb才将上一个data block加入到index block中。标记pending_index_entry就是干这个用的，对应data block的index entry信息就保存在（BlockHandle）pending_handle。\nS3 如果filter_block不为空，就把key加入到filter_block中。\nif (r-\u0026gt;filter_block != NULL) { r-\u0026gt;filter_block-\u0026gt;AddKey(key); } S4 设置r-\u0026gt;last_key = key，将(key, value)添加到r-\u0026gt;data_block中，并更新entry数。\nr-\u0026gt;last_key.assign(key.data(), key.size()); r-\u0026gt;num_entries++; r-\u0026gt;data_block.Add(key,value); S5 如果data block的个数超过限制，就立刻Flush到文件中。\nconst size_testimated_block_size = r-\u0026gt;data_block.CurrentSizeEstimate(); if (estimated_block_size \u0026gt;=r-\u0026gt;options.block_size) Flush(); 6.4.3 Flush文件 该函数逻辑比较简单，直接见代码如下：\nRep* r = rep_; assert(!r-\u0026gt;closed); // 首先保证未关闭，且状态ok if (!ok()) return; if (r-\u0026gt;data_block.empty())return; // data block是空的 // 保证pending_index_entry为false，即data block的Add已经完成 assert(!r-\u0026gt;pending_index_entry); // 写入data block，并设置其index entry信息—BlockHandle对象 WriteBlock(\u0026amp;r-\u0026gt;data_block, \u0026amp;r-\u0026gt;pending_handle); //写入成功，则Flush文件，并设置r-\u0026gt;pending_index_entry为true， //以根据下一个data block的first key调整index entry的key—即r-\u0026gt;last_key if (ok()) { r-\u0026gt;pending_index_entry =true; r-\u0026gt;status =r-\u0026gt;file-\u0026gt;Flush(); } if (r-\u0026gt;filter_block != NULL) { //将data block在sstable中的便宜加入到filter block中 r-\u0026gt;filter_block-\u0026gt;StartBlock(r-\u0026gt;offset); // 并指明开始新的data block } 6.4.4 WriteBlock函数 在Flush文件时，会调用WriteBlock函数将data block写入到文件中，该函数同时还设置data block的index entry信息。原型为：\nvoid WriteBlock(BlockBuilder* block, BlockHandle* handle) 该函数做些预处理工作，序列化要写入的data block，根据需要压缩数据，真正的写入逻辑是在WriteRawBlock函数中。下面分析该函数的处理逻辑。\n2\nS1 获得block的序列化数据Slice，根据配置参数决定是否压缩，以及根据压缩格式压缩数据内容。对于Snappy压缩，如果压缩率太低\u0026lt;12.5%，还是作为未压缩内容存储。\nBlockBuilder的Finish()函数将data block的数据序列化成一个Slice。\nRep* r = rep_; Slice raw = block-\u0026gt;Finish(); // 获得data block的序列化字符串 Slice block_contents; CompressionType type =r-\u0026gt;options.compression; switch (type) { case kNoCompression: block_contents= raw; break; // 不压缩 case kSnappyCompression: { // snappy压缩格式 std::string* compressed =\u0026amp;r-\u0026gt;compressed_output; if(port::Snappy_Compress(raw.data(), raw.size(), compressed) \u0026amp;\u0026amp; compressed-\u0026gt;size()\u0026lt; raw.size() - (raw.size() / 8u)) { block_contents =*compressed; } else { // 如果不支持Snappy，或者压缩率低于12.5%，依然当作不压缩存储 block_contents = raw; type = kNoCompression; } break; } } S2 将data内容写入到文件，并重置block成初始化状态，清空compressedoutput。\nWriteRawBlock(block_contents,type, handle); r-\u0026gt;compressed_output.clear(); block-\u0026gt;Reset(); 6.4.5 WriteRawBlock函数 在WriteBlock把准备工作都做好后，就可以写入到sstable文件中了。来看函数原型：\nvoid WriteRawBlock(const Slice\u0026amp; data, CompressionType, BlockHandle*handle); 函数逻辑很简单，见代码。\nRep* r = rep_; handle-\u0026gt;set_offset(r-\u0026gt;offset); // 为index设置data block的handle信息 handle-\u0026gt;set_size(block_contents.size()); r-\u0026gt;status =r-\u0026gt;file-\u0026gt;Append(block_contents); // 写入data block内容 if (r-\u0026gt;status.ok()) { // 写入1byte的type和4bytes的crc32 chartrailer[kBlockTrailerSize]; trailer[0] = type; uint32_t crc = crc32c::Value(block_contents.data(), block_contents.size()); crc = crc32c::Extend(crc, trailer, 1); // Extend crc tocover block type EncodeFixed32(trailer+1, crc32c::Mask(crc)); r-\u0026gt;status =r-\u0026gt;file-\u0026gt;Append(Slice(trailer, kBlockTrailerSize)); if (r-\u0026gt;status.ok()) { // 写入成功更新offset-下一个data block的写入偏移 r-\u0026gt;offset +=block_contents.size() + kBlockTrailerSize; } } 6.4.6 Finish函数 调用Finish函数，表明调用者将所有已经添加的k/v对持久化到sstable，并关闭sstable文件。\n该函数逻辑很清晰，可分为5部分。\n3\nS1 首先调用Flush，写入最后的一块data block，然后设置关闭标志closed=true。表明该sstable已经关闭，不能再添加k/v对。\n1 Rep* r = rep_; 2 Flush(); 3 assert(!r-\u0026gt;closed); 4 r-\u0026gt;closed = true; 5 BlockHandle filter_block_handle,metaindex_block_handle, index_block_handle; S2 写入filter block到文件中。\nif (ok() \u0026amp;\u0026amp;r-\u0026gt;filter_block != NULL) { WriteRawBlock(r-\u0026gt;filter_block-\u0026gt;Finish(), kNoCompression,\u0026amp;filter_block_handle); } S3 写入meta index block到文件中。\n如果filterblock不为NULL，则加入从\u0026quot;filter.Name\u0026quot;到filter data位置的映射。通过meta index block，可以根据filter名字快速定位到filter的数据区。\nif (ok()) { BlockBuildermeta_index_block(\u0026amp;r-\u0026gt;options); if (r-\u0026gt;filter_block !=NULL) { //加入从\u0026#34;filter.Name\u0026#34;到filter data位置的映射 std::string key =\u0026#34;filter.\u0026#34;; key.append(r-\u0026gt;options.filter_policy-\u0026gt;Name()); std::string handle_encoding; filter_block_handle.EncodeTo(\u0026amp;handle_encoding); meta_index_block.Add(key,handle_encoding); } // TODO(postrelease): Add stats and other metablocks WriteBlock(\u0026amp;meta_index_block, \u0026amp;metaindex_block_handle); } S4 写入index block，如果成功Flush过data block，那么需要为最后一块data block设置index block，并加入到index block中。\nif (ok()) { if (r-\u0026gt;pending_index_entry) { // Flush时会被设置为true r-\u0026gt;options.comparator-\u0026gt;FindShortSuccessor(\u0026amp;r-\u0026gt;last_key); std::string handle_encoding; r-\u0026gt;pending_handle.EncodeTo(\u0026amp;handle_encoding); r-\u0026gt;index_block.Add(r-\u0026gt;last_key, Slice(handle_encoding)); // 加入到index block中 r-\u0026gt;pending_index_entry =false; } WriteBlock(\u0026amp;r-\u0026gt;index_block, \u0026amp;index_block_handle); } S5 写入Footer。\nif (ok()) { Footer footer; footer.set_metaindex_handle(metaindex_block_handle); footer.set_index_handle(index_block_handle); std::string footer_encoding; footer.EncodeTo(\u0026amp;footer_encoding); r-\u0026gt;status =r-\u0026gt;file-\u0026gt;Append(footer_encoding); if (r-\u0026gt;status.ok()) { r-\u0026gt;offset +=footer_encoding.size(); } } 整个写入流程就分析完了，对于Datablock和Filter Block的操作将在Data block和Filter Block中单独分析，下面的读取相同。\n","permalink":"https://haokiu.com/blog/8554dc1843294f5fa7955b748c61710f/","summary":"leveldb源码分析8 本系列《leveldb源码分析》共有22篇文章，这是第八篇\n6 SSTable之2 6.4 创建sstable文件 了解了sstable文件的存储格式，以及Data Block的组织，下面就可以分析如何创建sstable文件了。相关代码在table_builder.h/.cc以及block_builder.h/.cc（构建Block）中。\n6.4.1 TableBuilder类 构建sstable文件的类是TableBuilder，该类提供了几个有限的方法可以用来添加k/v对，Flush到文件中等等，它依赖于BlockBuilder来构建Block。\nTableBuilder的几个接口说明下：\nvoid Add(const Slice\u0026amp; key, const Slice\u0026amp; value)，向当前正在构建的表添加新的{key, value}对，要求根据Option指定的Comparator，key必须位于所有前面添加的key之后； void Flush()，将当前缓存的k/v全部flush到文件中，一个高级方法，大部分的client不需要直接调用该方法； void Finish()，结束表的构建，该方法被调用后，将不再会使用传入的WritableFile； void Abandon()，结束表的构建，并丢弃当前缓存的内容，该方法被调用后，将不再会使用传入的WritableFile；【只是设置closed为true，无其他操作】 一旦**Finish()/Abandon()**方法被调用，将不能再次执行Flush或者Add操作。 下面来看看涉及到的类，如图6.3-1所示。 图6.3-1\n其中WritableFile和op log一样，使用的都是内存映射文件。Options是一些调用者可设置的选项。\nTableBuilder只有一个成员变量Rep* rep_，实际上Rep结构体的成员就是TableBuilder所有的成员变量；这样做的目的，可能是为了隐藏其内部细节。Rep的定义也是在.cc文件中，对外是透明的。\n简单解释下成员的含义：\nOptions options; // data block的选项 Options index_block_options; // index block的选项 WritableFile* file; // sstable文件 uint64_t offset; // 要写入data block在sstable文件中的偏移，初始0 Status status; //当前状态-初始ok BlockBuilder data_block; //当前操作的data block BlockBuilder index_block; // sstable的index block std::string last_key; //当前data block最后的k/v对的key int64_t num_entries; //当前data block的个数，初始0 bool closed; //调用了Finish() or Abandon()，初始false FilterBlockBuilder*filter_block; //根据filter数据快速定位key是否在block中 bool pending_index_entry; //见下面的Add函数，初始false BlockHandle pending_handle; //添加到index block的data block的信息 std::string compressed_output;//压缩后的data block，临时存储，写入后即被清空 Filter block是存储的过滤器信息，它会存储{key, 对应data block在sstable的偏移值}，不一定是完全精确的，以快速定位给定key是否在data block中。\n下面分析如何向sstable中添加k/v对，创建并持久化sstable。其它函数都比较简单，略过。另外对于Abandon，简单设置closed=true即返回。\n6.4.2 添加k/v对 这是通过方法**Add(constSlice\u0026amp; key, const Slice\u0026amp; value)**完成的，没有返回值。下面分析下函数的逻辑：","title":"leveldb源码分析8"},{"content":"leveldb源码分析9 本系列《leveldb源码分析》共有22篇文章，这是第九篇\n6 SSTable之3 6.5 读取sstable文件 6.5.1 类层次 Sstable文件的读取逻辑在类Table中，其中涉及到的类还是比较多的，如图6.5-1所示。\nTable类导出的函数只有3个，先从这三个导出函数开始分析。其中涉及到的类（包括上图中为画出的）都会一一遇到，然后再一一拆解。\n本节分析sstable的打开逻辑，后面再分析key的查找与数据遍历。\n6.5.2 Table::Open() 打开一个sstable文件，函数声明为：\nstatic Status Open(const Options\u0026amp; options, RandomAccessFile* file, uint64_tfile_size, Table** table); 这是Table类的一个静态函数，如果操作成功，指针*table指向新打开的表，否则返回错误。\n要打开的文件和大小分别由参数file和file_size指定；option是一些选项；\n下面就分析下函数逻辑：\n*1* S1 首先从文件的结尾读取Footer，并Decode到Footer对象中，如果文件长度小于Footer的长度，则报错。Footer的decode很简单，就是根据前面的Footer结构，解析并判断magic number是否正确，解析出meta index和index block的偏移和长度。 *table = NULL; if (size \u0026lt;Footer::kEncodedLength) { // 文件太短 returnStatus::InvalidArgument(\u0026#34;file is too short to be an sstable\u0026#34;); } charfooter_space[Footer::kEncodedLength]; // Footer大小是固定的 Slice footer_input; Status s = file-\u0026gt;Read(size -Footer::kEncodedLength, Footer::kEncodedLength, \u0026amp;footer_input, footer_space); if (!s.ok()) return s; Footer footer; s =footer.DecodeFrom(\u0026amp;footer_input); if (!s.ok()) return s; S2 解析出了Footer，我们就可以读取index block和meta index了，首先读取index block。 BlockContents contents; Block* index_block = NULL; if (s.ok()) { s = ReadBlock(file, ReadOptions(),footer.index_handle(), \u0026amp;contents); if (s.ok()) { index_block = newBlock(contents); } } 这是通过调用ReadBlock完成的，下面会分析这个函数。\nS3 已经成功读取了footer和index block，此时table已经可以响应请求了。构建table对象，并读取metaindex数据构建filter policy。如果option打开了cache，还要为table创建cache。 if (s.ok()) { // 已成功读取footer和index block: 可以响应请求了 Rep* rep = new Table::Rep; rep-\u0026gt;options = options; rep-\u0026gt;file = file; rep-\u0026gt;metaindex_handle =footer.metaindex_handle(); rep-\u0026gt;index_block =index_block; rep-\u0026gt;cache_id =(options.block_cache ? options.block_cache-\u0026gt;NewId() : 0); rep-\u0026gt;filter_data = rep-\u0026gt;filter= NULL; *table = new Table(rep); (*table)-\u0026gt;ReadMeta(footer); // 调用ReadMeta读取metaindex } else { if (index_block) deleteindex_block; } 到这里，Table的打开操作就已经为完成了。下面来分析上面用到的ReadBlock()和ReadMeta()函数。\n6.5.3 ReadBlock() 前面讲过block的格式，以及Block的写入（TableBuilder::WriteRawBlock），现在我们可以轻松的分析Block的读取操作了。\n这是一个全局函数，声明为：\nStatus ReadBlock(RandomAccessFile* file, const ReadOptions\u0026amp; options, const BlockHandle\u0026amp;handle, BlockContents* result); 下面来分析实现逻辑：\n2 S1 初始化结果result，BlockContents是一个有3个成员的结构体。 result-\u0026gt;data = Slice(); result-\u0026gt;cachable = false; // 无cache result-\u0026gt;heap_allocated =false; // 非heap分配 S2 根据handle指定的偏移和大小，读取block内容，type和crc32值，其中常量kBlockTrailerSize=5= 1byte的type和4bytes的crc32。 Status s = file-\u0026gt;Read(handle.offset(),handle.size() + kBlockTrailerSize, \u0026amp;contents, buf); S3 如果option要校验CRC32，则计算content + type的CRC32并校验。 S4 最后根据type指定的存储类型，如果是非压缩的，则直接取数据赋给result，否则先解压，把解压结果赋给result，目前支持的是snappy压缩。 另外，文件的Read接口返回的Slice结果，其data指针可能没有使用我们传入的buf，如果没有，那么释放Slice的data指针就是我们的事情，否则就是文件来管理的。\nif (data != buf) { // 文件自己管理，cacheable等标记设置为false delete[] buf; result-\u0026gt;data =Slice(data, n); result-\u0026gt;heap_allocated= result-\u0026gt;cachable =false; } else { // 读取者自己管理，标记设置为true result-\u0026gt;data =Slice(buf, n); result-\u0026gt;heap_allocated= result-\u0026gt;cachable = true; } 对于压缩存储，解压后的字符串存储需要读取者自行分配的，所以标记都是true。\n6.5.4 Table::ReadMeta() 解决完了Block的读取，接下来就是meta的读取了。函数声明为：\nvoid Table::ReadMeta(const Footer\u0026amp; footer) 函数逻辑并不复杂 。\n3 S1首先调用ReadBlock读取meta的内容 if(rep_-\u0026gt;options.filter_policy == NULL) return; // 不需要metadata ReadOptions opt; BlockContents contents; if (!ReadBlock(rep_-\u0026gt;file,opt, footer.metaindex_handle(), \u0026amp;contents).ok()) { return; // 失败了也没报错，因为没有meta信息也没关系 } S2 根据读取的content构建Block，找到指定的filter；如果找到了就调用ReadFilter构建filter对象。Block的分析留在后面。 Block* meta = newBlock(contents); Iterator* iter =meta-\u0026gt;NewIterator(BytewiseComparator()); std::string key =\u0026#34;filter.\u0026#34;; key.append(rep_-\u0026gt;options.filter_policy-\u0026gt;Name()); iter-\u0026gt;Seek(key); if (iter-\u0026gt;Valid() \u0026amp;\u0026amp;iter-\u0026gt;key() == Slice(key)) ReadFilter(iter-\u0026gt;value()); delete iter; delete meta; 6.5.5 Table::ReadFilter() 根据指定的偏移和大小，读取filter，函数声明：\nvoid ReadFilter(const Slice\u0026amp; filter_handle_value); 简单分析下函数逻辑：\n4 S1 从传入的filter_handle_value Decode出BlockHandle，这是filter的偏移和大小； BlockHandle filter_handle; filter_handle.DecodeFrom(\u0026amp;filter_handle_value); S2 根据解析出的位置读取filter内容，ReadBlock。如果block的heap_allocated为true，表明需要自行释放内存，因此要把指针保存在filter_data中。最后根据读取的data创建FilterBlockReader对象。 ReadOptions opt; BlockContents block; ReadBlock(rep_-\u0026gt;file, opt,filter_handle, \u0026amp;block); if (block.heap_allocated)rep_-\u0026gt;filter_data = block.data.data(); // 需要自行释放内存 rep_-\u0026gt;filter = newFilterBlockReader(rep_-\u0026gt;options.filter_policy, block.data); 以上就是sstable文件的读取操作，不算复杂。\n","permalink":"https://haokiu.com/blog/899ada7f72f249e6938aef7f300eaf1a/","summary":"leveldb源码分析9 本系列《leveldb源码分析》共有22篇文章，这是第九篇\n6 SSTable之3 6.5 读取sstable文件 6.5.1 类层次 Sstable文件的读取逻辑在类Table中，其中涉及到的类还是比较多的，如图6.5-1所示。\nTable类导出的函数只有3个，先从这三个导出函数开始分析。其中涉及到的类（包括上图中为画出的）都会一一遇到，然后再一一拆解。\n本节分析sstable的打开逻辑，后面再分析key的查找与数据遍历。\n6.5.2 Table::Open() 打开一个sstable文件，函数声明为：\nstatic Status Open(const Options\u0026amp; options, RandomAccessFile* file, uint64_tfile_size, Table** table); 这是Table类的一个静态函数，如果操作成功，指针*table指向新打开的表，否则返回错误。\n要打开的文件和大小分别由参数file和file_size指定；option是一些选项；\n下面就分析下函数逻辑：\n*1* S1 首先从文件的结尾读取Footer，并Decode到Footer对象中，如果文件长度小于Footer的长度，则报错。Footer的decode很简单，就是根据前面的Footer结构，解析并判断magic number是否正确，解析出meta index和index block的偏移和长度。 *table = NULL; if (size \u0026lt;Footer::kEncodedLength) { // 文件太短 returnStatus::InvalidArgument(\u0026#34;file is too short to be an sstable\u0026#34;); } charfooter_space[Footer::kEncodedLength]; // Footer大小是固定的 Slice footer_input; Status s = file-\u0026gt;Read(size -Footer::kEncodedLength, Footer::kEncodedLength, \u0026amp;footer_input, footer_space); if (!s.ok()) return s; Footer footer; s =footer.DecodeFrom(\u0026amp;footer_input); if (!s.ok()) return s; S2 解析出了Footer，我们就可以读取index block和meta index了，首先读取index block。 BlockContents contents; Block* index_block = NULL; if (s.ok()) { s = ReadBlock(file, ReadOptions(),footer.index_handle(), \u0026amp;contents); if (s.ok()) { index_block = newBlock(contents); } } 这是通过调用ReadBlock完成的，下面会分析这个函数。","title":"leveldb源码分析9"},{"content":"libevent源码深度剖析 libevent源码深度剖析01\nlibevent源码深度剖析02\nlibevent源码深度剖析03\nlibevent源码深度剖析04\nlibevent源码深度剖析05\nlibevent源码深度剖析06\nlibevent源码深度剖析07\nlibevent源码深度剖析08\nlibevent源码深度剖析09\nlibevent源码深度剖析10\nlibevent源码深度剖析11\nlibevent源码深度剖析12\nlibevent源码深度剖析13\n","permalink":"https://haokiu.com/blog/5d2f8fa20fdc4018a34afe19f8c23987/","summary":"libevent源码深度剖析 libevent源码深度剖析01\nlibevent源码深度剖析02\nlibevent源码深度剖析03\nlibevent源码深度剖析04\nlibevent源码深度剖析05\nlibevent源码深度剖析06\nlibevent源码深度剖析07\nlibevent源码深度剖析08\nlibevent源码深度剖析09\nlibevent源码深度剖析10\nlibevent源码深度剖析11\nlibevent源码深度剖析12\nlibevent源码深度剖析13","title":"libevent源码深度剖析"},{"content":"libevent源码深度剖析02 Reactor模式\n前面讲到，整个libevent本身就是一个Reactor，因此本节将专门对Reactor模式进行必要的介绍，并列出libevnet中的几个重要组件和Reactor的对应关系，在后面的章节中可能还会提到本节介绍的基本概念。\n1. Reactor的事件处理机制 首先来回想一下普通函数调用的机制：程序调用某函数?函数执行，程序等待?函数将结果和控制权返回给程序?程序继续处理。\nReactor释义**“反应堆”，是一种事件驱动机制。和普通函数调用的不同之处在于：应用程序不是主动的调用某个API完成处理，而是恰恰相反，Reactor逆置了事件处理流程，应用程序需要提供相应的接口并注册到Reactor上，如果相应的时间发生，Reactor将主动调用应用程序注册的接口，这些接口又称为“回调函数”**。使用libevent也是想libevent框架注册相应的事件和回调函数；当这些事件发生时，libevent会调用这些回调函数处理相应的事件（I/O读写、定时和信号）。\n用“好莱坞原则”来形容Reactor再合适不过了：不要打电话给我们，我们会打电话通知你。\n举个例子：你去应聘某xx公司，面试结束后。\n“普通函数调用机制”公司HR比较懒，不会记你的联系方式，那怎么办呢，你只能面试完后自己打电话去问结果；有没有被录取啊，还是被据了；\n“Reactor”公司HR就记下了你的联系方式，结果出来后会主动打电话通知你：有没有被录取啊，还是被据了；你不用自己打电话去问结果，事实上也不能，你没有HR的留联系方式。\n2. Reactor模式的优点 Reactor模式是编写高性能网络服务器的必备技术之一，它具有如下的优点\n1）响应快，不必为单个同步时间所阻塞，虽然Reactor本身依然是同步的；\n2）编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销； 3）可扩展性，可以方便的通过增加Reactor实例个数来充分利用CPU资源； 4）可复用性，reactor框架本身与具体事件处理逻辑无关，具有很高的复用性；\n3. Reactor模式框架 使用Reactor模型，必备的几个组件：事件源、Reactor框架、多路复用机制和事件处理程序，先来看看Reactor模型的整体框架，接下来再对每个组件做逐一说明。\n1） 事件源 Linux上是文件描述符，Windows上就是Socket或者Handle了，这里统一称为“句柄集”；程序在指定的句柄上注册关心的事件，比如I/O事件。\n2） event demultiplexer——事件多路分发机制 由操作系统提供的I/O多路复用机制，比如select和epoll。 程序首先将其关心的句柄（事件源）及其事件注册到event demultiplexer上； 当有事件到达时，event demultiplexer会发出通知“在已经注册的句柄集中，一个或多个句柄的事件已经就绪”； 程序收到通知后，就可以在非阻塞的情况下对事件进行处理了。 对应到libevent中，依然是select、poll、epoll等，但是libevent使用结构体eventop进行了封装，以统一的接口来支持这些I/O多路复用机制，达到了对外隐藏底层系统机制的目的。\n3） Reactor——反应器 Reactor，是事件管理的接口，内部使用event demultiplexer注册、注销事件；并运行事件循环，当有事件进入“就绪”状态时，调用注册事件的回调函数处理事件。 对应到libevent中，就是event_base结构体。 一个典型的Reactor声明方式：\nclass Reactor{ public: int register_handler(Event_Handler *pHandler, int event); int remove_handler(Event_Handler *pHandler, int event); void handle_events(timeval *ptv); // ... }; 4） Event Handler——事件处理程序\n事件处理程序提供了一组接口，每个接口对应了一种类型的事件，供Reactor在相应的事件发生时调用，执行相应的事件处理。通常它会绑定一个有效的句柄。 对应到libevent中，就是event结构体。 下面是两种典型的Event Handler类声明方式，二者互有优缺点。\nclass Event_Handler{ public: virtual void handle_read() = 0; virtual void handle_write() = 0; virtual void handle_timeout() = 0; virtual void handle_close() = 0; virtual HANDLE get_handle() = 0; // ... }; class Event_Handler{ public: // events maybe read/write/timeout/close .etc virtual void handle_events(int events) = 0; virtual HANDLE get_handle() = 0; // ... }; 4. Reactor事件处理流程 前面说过Reactor将事件流“逆置”了，那么使用Reactor模式后，事件控制流是什么样子呢？ 可以参见下面的序列图。\n5. 小结 上面讲到了Reactor的基本概念、框架和处理流程，对Reactor有个基本清晰的了解后，再来对比看libevent就会更容易理解了，接下来就正式进入到libevent的代码世界了，加油！\n参考资料： Pattern-Oriented Software Architecture, Patterns for Concurrent and Networked Objects, Volume 2\n","permalink":"https://haokiu.com/blog/d62a9a215b334817945e5814d92a423a/","summary":"libevent源码深度剖析02 Reactor模式\n前面讲到，整个libevent本身就是一个Reactor，因此本节将专门对Reactor模式进行必要的介绍，并列出libevnet中的几个重要组件和Reactor的对应关系，在后面的章节中可能还会提到本节介绍的基本概念。\n1. Reactor的事件处理机制 首先来回想一下普通函数调用的机制：程序调用某函数?函数执行，程序等待?函数将结果和控制权返回给程序?程序继续处理。\nReactor释义**“反应堆”，是一种事件驱动机制。和普通函数调用的不同之处在于：应用程序不是主动的调用某个API完成处理，而是恰恰相反，Reactor逆置了事件处理流程，应用程序需要提供相应的接口并注册到Reactor上，如果相应的时间发生，Reactor将主动调用应用程序注册的接口，这些接口又称为“回调函数”**。使用libevent也是想libevent框架注册相应的事件和回调函数；当这些事件发生时，libevent会调用这些回调函数处理相应的事件（I/O读写、定时和信号）。\n用“好莱坞原则”来形容Reactor再合适不过了：不要打电话给我们，我们会打电话通知你。\n举个例子：你去应聘某xx公司，面试结束后。\n“普通函数调用机制”公司HR比较懒，不会记你的联系方式，那怎么办呢，你只能面试完后自己打电话去问结果；有没有被录取啊，还是被据了；\n“Reactor”公司HR就记下了你的联系方式，结果出来后会主动打电话通知你：有没有被录取啊，还是被据了；你不用自己打电话去问结果，事实上也不能，你没有HR的留联系方式。\n2. Reactor模式的优点 Reactor模式是编写高性能网络服务器的必备技术之一，它具有如下的优点\n1）响应快，不必为单个同步时间所阻塞，虽然Reactor本身依然是同步的；\n2）编程相对简单，可以最大程度的避免复杂的多线程及同步问题，并且避免了多线程/进程的切换开销； 3）可扩展性，可以方便的通过增加Reactor实例个数来充分利用CPU资源； 4）可复用性，reactor框架本身与具体事件处理逻辑无关，具有很高的复用性；\n3. Reactor模式框架 使用Reactor模型，必备的几个组件：事件源、Reactor框架、多路复用机制和事件处理程序，先来看看Reactor模型的整体框架，接下来再对每个组件做逐一说明。\n1） 事件源 Linux上是文件描述符，Windows上就是Socket或者Handle了，这里统一称为“句柄集”；程序在指定的句柄上注册关心的事件，比如I/O事件。\n2） event demultiplexer——事件多路分发机制 由操作系统提供的I/O多路复用机制，比如select和epoll。 程序首先将其关心的句柄（事件源）及其事件注册到event demultiplexer上； 当有事件到达时，event demultiplexer会发出通知“在已经注册的句柄集中，一个或多个句柄的事件已经就绪”； 程序收到通知后，就可以在非阻塞的情况下对事件进行处理了。 对应到libevent中，依然是select、poll、epoll等，但是libevent使用结构体eventop进行了封装，以统一的接口来支持这些I/O多路复用机制，达到了对外隐藏底层系统机制的目的。\n3） Reactor——反应器 Reactor，是事件管理的接口，内部使用event demultiplexer注册、注销事件；并运行事件循环，当有事件进入“就绪”状态时，调用注册事件的回调函数处理事件。 对应到libevent中，就是event_base结构体。 一个典型的Reactor声明方式：\nclass Reactor{ public: int register_handler(Event_Handler *pHandler, int event); int remove_handler(Event_Handler *pHandler, int event); void handle_events(timeval *ptv); // ... }; 4） Event Handler——事件处理程序\n事件处理程序提供了一组接口，每个接口对应了一种类型的事件，供Reactor在相应的事件发生时调用，执行相应的事件处理。通常它会绑定一个有效的句柄。 对应到libevent中，就是event结构体。 下面是两种典型的Event Handler类声明方式，二者互有优缺点。\nclass Event_Handler{ public: virtual void handle_read() = 0; virtual void handle_write() = 0; virtual void handle_timeout() = 0; virtual void handle_close() = 0; virtual HANDLE get_handle() = 0; // ... }; class Event_Handler{ public: // events maybe read/write/timeout/close .","title":"libevent源码深度剖析02"},{"content":"libevent源码深度剖析03 libevent基本使用场景和事件流程 1. 前言 学习源代码该从哪里入手？我觉得从程序的基本使用场景和代码的整体处理流程入手是个不错的方法，至少从个人的经验上讲，用此方法分析libevent是比较有效的。\n2. 基本应用场景 基本应用场景也是使用libevnet的基本流程，下面来考虑一个最简单的场景，使用livevent设置定时器，应用程序只需要执行下面几个简单的步骤即可。 1）首先初始化libevent库，并保存返回的指针\nstruct event_base* base = event_init(); 实际上这一步相当于初始化一个Reactor实例；在初始化libevent后，就可以注册事件了。\n2）初始化事件event，设置回调函数和关注的事件\nevtimer_set(\u0026amp;ev, timer_cb, NULL); 事实上这等价于调用 event_set(\u0026amp;ev, -1, 0, timer_cb, NULL); event_set的函数原型是：\nvoid event_set(struct event *ev, int fd, short event, void (*cb)(int, short, void *), void *arg) ev：执行要初始化的event对象； fd：该event绑定的“句柄”，对于信号事件，它就是关注的信号； event：在该fd上关注的事件类型，它可以是EV_READ, EV_WRITE, EV_SIGNAL； cb：这是一个函数指针，当fd上的事件event发生时，调用该函数执行处理，它有三个参数，调用时由event_base负责传入，按顺序，实际上就是event_set时的fd, event和arg； arg：传递给cb函数指针的参数； 由于定时事件不需要fd，并且定时事件是根据添加时**（event_add）的超时值设定的，因此这里event也不需要设置。 这一步相当于初始化一个event handler**，在libevent中事件类型保存在event结构体中。 注意：libevent并不会管理event事件集合，这需要应用程序自行管理；\n3）设置event从属的event_base\nevent_base_set(base, \u0026amp;ev); 这一步相当于指明event要注册到哪个event_base实例上；\n4）是正式的添加事件的时候了\nevent_add(\u0026amp;ev, timeout); 基本信息都已设置完成，只要简单的调用**event_add()函数即可完成，其中timeout是定时值； 这一步相当于调用Reactor::register_handler()**函数注册事件。\n5）程序进入无限循环，等待就绪事件并执行事件处理\nevent_base_dispatch(base); 3. 实例代码 上面例子的程序代码如下所示\nstruct event ev; struct timeval tv; void time_cb(int fd, short event, void *argc){ printf(\u0026#34;timer wakeup/n\u0026#34;); event_add(\u0026amp;ev, \u0026amp;tv); // reschedule timer } int main(){ struct event_base *base = event_init(); tv.tv_sec = 10; // 10s period tv.tv_usec = 0; evtimer_set(\u0026amp;ev, time_cb, NULL); event_add(\u0026amp;ev, \u0026amp;tv); event_base_dispatch(base); } 4. 事件处理流程 当应用程序向libevent注册一个事件后，libevent内部是怎么样进行处理的呢？下面的图就给出了这一基本流程。 1）首先应用程序准备并初始化event，设置好事件类型和回调函数；这对应于前面第步骤2和3； 2）向libevent添加该事件event。对于定时事件，libevent使用一个小根堆管理，key为超时时间；对于Signal和I/O事件，libevent将其放入到等待链表（wait list）中，这是一个双向链表结构； 3）程序调用**event_base_dispatch()**系列函数进入无限循环，等待事件，以select()函数为例；每次循环前libevent会检查定时事件的最小超时时间tv，根据tv设置select()的最大等待时间，以便于后面及时处理超时事件； 当select()返回后，首先检查超时事件，然后检查I/O事件； Libevent将所有的就绪事件，放入到激活链表中； 然后对激活链表中的事件，调用事件的回调函数执行事件处理； 5. 小结 本节介绍了libevent的简单实用场景，并旋风般的介绍了libevent的事件处理流程，读者应该对libevent有了基本的印象，下面将会详细介绍libevent的事件管理框架（Reactor模式中的Reactor框架）做详细的介绍，在此之前会对源代码文件做简单的分类。\n","permalink":"https://haokiu.com/blog/88dcf812d9464727bdfa54410657cfaa/","summary":"libevent源码深度剖析03 libevent基本使用场景和事件流程 1. 前言 学习源代码该从哪里入手？我觉得从程序的基本使用场景和代码的整体处理流程入手是个不错的方法，至少从个人的经验上讲，用此方法分析libevent是比较有效的。\n2. 基本应用场景 基本应用场景也是使用libevnet的基本流程，下面来考虑一个最简单的场景，使用livevent设置定时器，应用程序只需要执行下面几个简单的步骤即可。 1）首先初始化libevent库，并保存返回的指针\nstruct event_base* base = event_init(); 实际上这一步相当于初始化一个Reactor实例；在初始化libevent后，就可以注册事件了。\n2）初始化事件event，设置回调函数和关注的事件\nevtimer_set(\u0026amp;ev, timer_cb, NULL); 事实上这等价于调用 event_set(\u0026amp;ev, -1, 0, timer_cb, NULL); event_set的函数原型是：\nvoid event_set(struct event *ev, int fd, short event, void (*cb)(int, short, void *), void *arg) ev：执行要初始化的event对象； fd：该event绑定的“句柄”，对于信号事件，它就是关注的信号； event：在该fd上关注的事件类型，它可以是EV_READ, EV_WRITE, EV_SIGNAL； cb：这是一个函数指针，当fd上的事件event发生时，调用该函数执行处理，它有三个参数，调用时由event_base负责传入，按顺序，实际上就是event_set时的fd, event和arg； arg：传递给cb函数指针的参数； 由于定时事件不需要fd，并且定时事件是根据添加时**（event_add）的超时值设定的，因此这里event也不需要设置。 这一步相当于初始化一个event handler**，在libevent中事件类型保存在event结构体中。 注意：libevent并不会管理event事件集合，这需要应用程序自行管理；\n3）设置event从属的event_base\nevent_base_set(base, \u0026amp;ev); 这一步相当于指明event要注册到哪个event_base实例上；\n4）是正式的添加事件的时候了\nevent_add(\u0026amp;ev, timeout); 基本信息都已设置完成，只要简单的调用**event_add()函数即可完成，其中timeout是定时值； 这一步相当于调用Reactor::register_handler()**函数注册事件。\n5）程序进入无限循环，等待就绪事件并执行事件处理\nevent_base_dispatch(base); 3. 实例代码 上面例子的程序代码如下所示\nstruct event ev; struct timeval tv; void time_cb(int fd, short event, void *argc){ printf(\u0026#34;timer wakeup/n\u0026#34;); event_add(\u0026amp;ev, \u0026amp;tv); // reschedule timer } int main(){ struct event_base *base = event_init(); tv.tv_sec = 10; // 10s period tv.","title":"libevent源码深度剖析03"},{"content":"libevent源码深度剖析04 1. 前言 详细分析源代码之前，如果能对其代码文件的基本结构有个大概的认识和分类，对于代码的分析将是大有裨益的。本节内容不多，我想并不是说它不重要！\n2. 源代码组织结构 Libevent的源代码虽然都在一层文件夹下面，但是其代码分类还是相当清晰的，主要可分为头文件、内部使用的头文件、辅助功能函数、日志、libevent框架、对系统I/O多路复用机制的封装、信号管理、定时事件管理、缓冲区管理、基本数据结构和基于libevent的两个实用库等几个部分，有些部分可能就是一个源文件。 源代码中的test部分就不在我们关注的范畴了。 1）头文件 主要就是event.h：事件宏定义、接口函数声明，主要结构体event的声明； 2）内部头文件 xxx-internal.h：内部数据结构和函数，对外不可见，以达到信息隐藏的目的； 3）libevent框架 event.c：event整体框架的代码实现； 4）对系统I/O多路复用机制的封装 epoll.c：对epoll的封装； select.c：对select的封装； devpoll.c：对dev/poll的封装; kqueue.c：对kqueue的封装； 5）定时事件管理 min-heap.h：其实就是一个以时间作为key的小根堆结构； 6）信号管理 signal.c：对信号事件的处理； 7）辅助功能函数 evutil.h 和evutil.c：一些辅助功能函数，包括创建socket pair和一些时间操作函数：加、减和比较等。 8）日志 log.h和log.c：log日志函数 9）缓冲区管理 evbuffer.c和buffer.c：libevent对缓冲区的封装； 10）基本数据结构 compat/sys下的两个源文件：queue.h是libevent基本数据结构的实现，包括链表，双向链表，队列等；_libevent_time.h：一些用于时间操作的结构体定义、函数和宏定义； 11）实用网络库 http和evdns：是基于libevent实现的http服务器和异步dns查询库；\n3. 小结 本节介绍了libevent的组织和分类，下面将会详细介绍libevent的核心部分event结构。\n","permalink":"https://haokiu.com/blog/7fd5744edc6741c18b5cb6187e662e40/","summary":"libevent源码深度剖析04 1. 前言 详细分析源代码之前，如果能对其代码文件的基本结构有个大概的认识和分类，对于代码的分析将是大有裨益的。本节内容不多，我想并不是说它不重要！\n2. 源代码组织结构 Libevent的源代码虽然都在一层文件夹下面，但是其代码分类还是相当清晰的，主要可分为头文件、内部使用的头文件、辅助功能函数、日志、libevent框架、对系统I/O多路复用机制的封装、信号管理、定时事件管理、缓冲区管理、基本数据结构和基于libevent的两个实用库等几个部分，有些部分可能就是一个源文件。 源代码中的test部分就不在我们关注的范畴了。 1）头文件 主要就是event.h：事件宏定义、接口函数声明，主要结构体event的声明； 2）内部头文件 xxx-internal.h：内部数据结构和函数，对外不可见，以达到信息隐藏的目的； 3）libevent框架 event.c：event整体框架的代码实现； 4）对系统I/O多路复用机制的封装 epoll.c：对epoll的封装； select.c：对select的封装； devpoll.c：对dev/poll的封装; kqueue.c：对kqueue的封装； 5）定时事件管理 min-heap.h：其实就是一个以时间作为key的小根堆结构； 6）信号管理 signal.c：对信号事件的处理； 7）辅助功能函数 evutil.h 和evutil.c：一些辅助功能函数，包括创建socket pair和一些时间操作函数：加、减和比较等。 8）日志 log.h和log.c：log日志函数 9）缓冲区管理 evbuffer.c和buffer.c：libevent对缓冲区的封装； 10）基本数据结构 compat/sys下的两个源文件：queue.h是libevent基本数据结构的实现，包括链表，双向链表，队列等；_libevent_time.h：一些用于时间操作的结构体定义、函数和宏定义； 11）实用网络库 http和evdns：是基于libevent实现的http服务器和异步dns查询库；\n3. 小结 本节介绍了libevent的组织和分类，下面将会详细介绍libevent的核心部分event结构。","title":"libevent源码深度剖析04"},{"content":"libevent源码深度剖析05 libevent的核心：事件event\n对事件处理流程有了高层的认识后，本节将详细介绍libevent的核心结构event，以及libevent对event的管理**。**\n1. libevent的核心-event libevent是基于**事件驱动（event-driven）**的，从名字也可以看到event是整个库的核心。event就是Reactor框架中的事件处理程序组件；它提供了函数接口，供Reactor在事件发生时调用，以执行相应的事件处理，通常它会绑定一个有效的句柄。\n首先给出event结构体的声明，它位于event.h文件中：\nstruct event { TAILQ_ENTRY (event) ev_next; TAILQ_ENTRY (event) ev_active_next; TAILQ_ENTRY (event) ev_signal_next; unsigned int min_heap_idx; /* for managing timeouts */ struct event_base *ev_base; int ev_fd; short ev_events; short ev_ncalls; short *ev_pncalls; /* Allows deletes in callback */ struct timeval ev_timeout; int ev_pri; /* smaller numbers are higher priority */ void (*ev_callback)(int, short, void *arg); void *ev_arg; int ev_res; /* result passed to event callback */ int ev_flags; }; ev_events：event关注的事件类型，它可以是以下3种类型：\nI/O事件： EV_WRITE和EV_READ 定时事件：EV_TIMEOUT 信号： EV_SIGNAL 辅助选项：EV_PERSIST，表明是一个永久事件 Libevent中的定义为：\n#define EV_TIMEOUT 0x01 #define EV_READ 0x02 #define EV_WRITE 0x04 #define EV_SIGNAL 0x08 #define EV_PERSIST 0x10 /* Persistant event */ 可以看出事件类型可以使用“|”运算符进行组合，需要说明的是，信号和I/O事件不能同时设置；\n还可以看出libevent使用event结构体将这3种事件的处理统一起来；\nev_next，ev_active_next和ev_signal_next都是双向链表节点指针；它们是libevent对不同事件类型和在不同的时期，对事件的管理时使用到的字段。 libevent使用双向链表保存所有注册的I/O和Signal事件\nev_next就是该I/O事件在链表中的位置；称此链表为“已注册事件链表”；\n同样ev_signal_next就是signal事件在signal事件链表中的位置；\nev_active_next：libevent将所有的激活事件放入到链表active list中，然后遍历active list执行调度，ev_active_next就指明了event在active list中的位置；\nmin_heap_idx和ev_timeout，如果是timeout事件，它们是event在小根堆中的索引和超时值，libevent使用小根堆来管理定时事件，这将在后面定时事件处理时专门讲解；\nev_base该事件所属的反应堆实例，这是一个event_base结构体，下一节将会详细讲解；\nev_fd，对于I/O事件，是绑定的文件描述符；对于signal事件，是绑定的信号；\nev_callback，event的回调函数，被ev_base调用，执行事件处理程序，这是一个函数指针，原型为：\n1void (*ev_callback)(int fd, short events, void *arg) 其中参数fd对应于ev_fd；events对应于ev_events；arg对应于ev_arg；\nev_arg：void*，表明可以是任意类型的数据，在设置event时指定；\neb_flags：libevent用于标记event信息的字段，表明其当前的状态，可能的值有：\n1#define EVLIST_TIMEOUT 0x01 // event在time堆中 2 3#define EVLIST_INSERTED 0x02 // event在已注册事件链表中 4 5#define EVLIST_SIGNAL 0x04 // 未见使用 6 7#define EVLIST_ACTIVE 0x08 // event在激活链表中 8 9#define EVLIST_INTERNAL 0x10 // 内部使用标记 10 11#define EVLIST_INIT 0x80 // event已被初始化 ev_ncalls：事件就绪执行时，调用ev_callback的次数，通常为1；\nev_pncalls：指针，通常指向ev_ncalls或者为NULL；\nev_res：记录了当前激活事件的类型；\n2. libevent对event的管理 从event结构体中的3个链表节点指针和一个堆索引出发，大体上也能窥出libevent对event的管理方法了，可以参见下面的示意图：\n每次当有事件event转变为就绪状态时，libevent就会把它移入到active event list[priority]中，其中priority是event的优先级； 接着libevent会根据自己的调度策略选择就绪事件，调用其cb_callback()函数执行事件处理；并根据就绪的句柄和事件类型填充cb_callback函数的参数。 3. 事件设置的接口函数 要向libevent添加一个事件，需要首先设置event对象，这通过调用libevent提供的函数有：event_set(), event_base_set(), event_priority_set()来完成；下面分别进行讲解。\nvoid event_set(struct event *ev, int fd, short events, void (*callback)(int, short, void *), void *arg) 设置事件ev绑定的文件描述符或者信号，对于定时事件，设为-1即可； 设置事件类型，比如EV_READ|EV_PERSIST, EV_WRITE, EV_SIGNAL等； 设置事件的回调函数以及参数arg； 初始化其它字段，比如缺省的event_base和优先级； int event_base_set(struct event_base *base, struct event *ev) 设置event ev将要注册到的event_base； libevent有一个全局event_base指针current_base，默认情况下事件ev将被注册到current_base上，使用该函数可以指定不同的event_base； 如果一个进程中存**在多个libevent实例，**则必须要调用该函数为event设置不同的event_base； int event_priority_set(struct event *ev, int pri) 设置event ev的优先级，没什么可说的，注意的一点就是：当ev正处于就绪状态时，不能设置，返回-1。\n4. 小结 本节讲述了libevent的核心event结构，以及libevent支持的事件类型和libevent对event的管理模型；接下来将会描述libevent的事件处理框架，以及其中使用的重要的结构体event_base。\n","permalink":"https://haokiu.com/blog/1f6a82cdb17742a49514907b604e44c1/","summary":"libevent源码深度剖析05 libevent的核心：事件event\n对事件处理流程有了高层的认识后，本节将详细介绍libevent的核心结构event，以及libevent对event的管理**。**\n1. libevent的核心-event libevent是基于**事件驱动（event-driven）**的，从名字也可以看到event是整个库的核心。event就是Reactor框架中的事件处理程序组件；它提供了函数接口，供Reactor在事件发生时调用，以执行相应的事件处理，通常它会绑定一个有效的句柄。\n首先给出event结构体的声明，它位于event.h文件中：\nstruct event { TAILQ_ENTRY (event) ev_next; TAILQ_ENTRY (event) ev_active_next; TAILQ_ENTRY (event) ev_signal_next; unsigned int min_heap_idx; /* for managing timeouts */ struct event_base *ev_base; int ev_fd; short ev_events; short ev_ncalls; short *ev_pncalls; /* Allows deletes in callback */ struct timeval ev_timeout; int ev_pri; /* smaller numbers are higher priority */ void (*ev_callback)(int, short, void *arg); void *ev_arg; int ev_res; /* result passed to event callback */ int ev_flags; }; ev_events：event关注的事件类型，它可以是以下3种类型：\nI/O事件： EV_WRITE和EV_READ 定时事件：EV_TIMEOUT 信号： EV_SIGNAL 辅助选项：EV_PERSIST，表明是一个永久事件 Libevent中的定义为：\n#define EV_TIMEOUT 0x01 #define EV_READ 0x02 #define EV_WRITE 0x04 #define EV_SIGNAL 0x08 #define EV_PERSIST 0x10 /* Persistant event */ 可以看出事件类型可以使用“|”运算符进行组合，需要说明的是，信号和I/O事件不能同时设置；","title":"libevent源码深度剖析05"},{"content":"libevent源码深度剖析06 初见事件处理框架\n前面已经对libevent的事件处理框架和event结构体做了描述，现在是时候剖析libevent对事件的详细处理流程了，本节将分析libevent的事件处理框架event_base和libevent注册、删除事件的具体流程，可结合前一节libevent对event的管理。\n1. 事件处理框架-event_base 回想Reactor模式的几个基本组件，本节讲解的部分对应于Reactor框架组件。在libevent中，这就表现为event_base结构体，结构体声明如下，它位于event-internal.h文件中：\nstruct event_base { const struct eventop *evsel; void *evbase;　int event_count; /* counts number of total events */ int event_count_active; /* counts number of active events */ int event_gotterm; /* Set to terminate loop */ int event_break; /* Set to terminate loop immediately */ /* active event management */ struct event_list **activequeues; int nactivequeues; /* signal handling info */ struct evsignal_info sig; struct event_list eventqueue; struct timeval event_tv; struct min_heap timeheap; struct timeval tv_cache; }; 下面详细解释一下结构体中各字段的含义。\nevsel和evbase这两个字段的设置可能会让人有些迷惑，这里你可以把evsel和evbase看作是类和静态函数的关系，比如添加事件时的调用行为：evsel-\u0026gt;add(evbase, ev)，实际执行操作的是evbase；这相当于class::add(instance, ev)，instance就是class的一个对象实例。 evsel指向了全局变量static const struct eventop *eventops[]中的一个； 前面也说过，libevent将系统提供的I/O demultiplex机制统一封装成了eventop结构；因此eventops[]包含了select、poll、kequeue和epoll等等其中的若干个全局实例对象。 evbase实际上是一个eventop实例对象； 先来看看eventop结构体，它的成员是一系列的函数指针, 在event-internal.h文件中：\nstruct eventop { const char *name; void *(*init)(struct event_base *); // 初始化 int (*add)(void *, struct event *); // 注册事件 int (*del)(void *, struct event *); // 删除事件 int (*dispatch)(struct event_base *, void *, struct timeval *); // 事件分发 void (*dealloc)(struct event_base *, void *); // 注销，释放资源 /* set if we need to reinitialize the event base */ int need_reinit; }; 也就是说，在libevent中，每种I/O demultiplex机制的实现都必须提供这五个函数接口，来完成自身的初始化、销毁释放；对事件的注册、注销和分发。 比如对于epoll，libevent实现了5个对应的接口函数，并在初始化时并将eventop的5个函数指针指向这5个函数，那么程序就可以使用epoll作为I/O demultiplex机制了，这个在后面会再次提到。\nactivequeues是一个二级指针，前面讲过libevent支持事件优先级，因此你可以把它看作是数组，其中的元素activequeues[priority]是一个链表，链表的每个节点指向一个优先级为priority的就绪事件event。\neventqueue，链表，保存了所有的注册事件event的指针。\nsig是由来管理信号的结构体，将在后面信号处理时专门讲解；\ntimeheap是管理定时事件的小根堆，将在后面定时事件处理时专门讲解；\nevent_tv和tv_cache是libevent用于时间管理的变量，将在后面讲到； 其它各个变量都能因名知意，就不再啰嗦了。\n2. 创建和初始化event_base 创建一个event_base对象也既是创建了一个新的libevent实例，程序需要通过调用event_init()（内部调用event_base_new函数执行具体操作）函数来创建，该函数同时还对新生成的libevent实例进行了初始化。\n该函数首先为event_base实例申请空间， 然后初始化timer mini-heap，选择并初始化合适的系统I/O 的demultiplexer机制，初始化各事件链表； 函数还检测了系统的时间设置，为后面的时间管理打下基础。\n3. 接口函数 前面提到Reactor框架的作用就是提供事件的注册、注销接口；根据系统提供的事件多路分发机制执行事件循环，当有事件进入“就绪”状态时，调用注册事件的回调函数来处理事件。 Libevent中对应的接口函数主要就是：\nint event_add(struct event *ev, const struct timeval *timeout); int event_del(struct event *ev); int event_base_loop(struct event_base *base, int loops); void event_active(struct event *event, int res, short events); void event_process_active(struct event_base *base); 本节将按介绍事件注册和删除的代码流程，libevent的事件循环框架将在下一节再具体描述。\n对于定时事件，这些函数将调用timer heap管理接口执行插入和删除操作； 对于I/O和Signal事件将调用eventopadd和delete接口函数执行插入和删除操作（eventop会对Signal事件调用Signal处理接口执行操作）； 这些组件将在后面的内容描述。\n1）注册事件 函数原型：\nint event_add(struct event *ev, const struct timeval *tv) 参数：ev：指向要注册的事件； tv：超时时间；\ne函数将ev注册到ev-\u0026gt;ev_base上，事件类型由ev-\u0026gt;ev_events指明，\n如果注册成功，v将被插入到已注册链表中； 如果tv不是NULL，则会同时注册定时事件，将ev添加到timer堆上； 如果其中有一步操作失败，那么函数保证没有事件会被注册，可以讲这相当于一个原子操作。这个函数也体现了libevent细节之处的巧妙设计，且仔细看程序代码，部分有省略，注释直接附在代码中。\nint event_add(struct event *ev, const struct timeval *tv) { struct event_base *base = ev-\u0026gt;ev_base; // 要注册到的event_base const struct eventop *evsel = base-\u0026gt;evsel; void *evbase = base-\u0026gt;evbase; // base使用的系统I/O策略 // 新的timer事件，调用timer heap接口在堆上预留一个位置 // 注：这样能保证该操作的原子性： // 向系统I/O机制注册可能会失败，而当在堆上预留成功后， // 定时事件的添加将肯定不会失败； // 而预留位置的可能结果是堆扩充，但是内部元素并不会改变 if (tv != NULL \u0026amp;\u0026amp; !(ev-\u0026gt;ev_flags \u0026amp; EVLIST_TIMEOUT)) { if (min_heap_reserve(\u0026amp;base-\u0026gt;timeheap, 1 + min_heap_size(\u0026amp;base-\u0026gt;timeheap)) == -1) return (-1); /* ENOMEM == errno */ } // 如果事件ev不在已注册或者激活链表中，则调用evbase注册事件 if ((ev-\u0026gt;ev_events \u0026amp; (EV_READ|EV_WRITE|EV_SIGNAL)) \u0026amp;\u0026amp; !(ev-\u0026gt;ev_flags \u0026amp; (EVLIST_INSERTED|EVLIST_ACTIVE))) { res = evsel-\u0026gt;add(evbase, ev); if (res != -1) // 注册成功，插入event到已注册链表中 event_queue_insert(base, ev, EVLIST_INSERTED); } // 准备添加定时事件 if (res != -1 \u0026amp;\u0026amp; tv != NULL) { struct timeval now; // EVLIST_TIMEOUT表明event已经在定时器堆中了，删除旧的 if (ev-\u0026gt;ev_flags \u0026amp; EVLIST_TIMEOUT) event_queue_remove(base, ev, EVLIST_TIMEOUT); // 如果事件已经是就绪状态则从激活链表中删除 if ((ev-\u0026gt;ev_flags \u0026amp; EVLIST_ACTIVE) \u0026amp;\u0026amp; (ev-\u0026gt;ev_res \u0026amp; EV_TIMEOUT)) { // 将ev_callback调用次数设置为0 if (ev-\u0026gt;ev_ncalls \u0026amp;\u0026amp; ev-\u0026gt;ev_pncalls) { *ev-\u0026gt;ev_pncalls = 0; } event_queue_remove(base, ev, EVLIST_ACTIVE); } // 计算时间，并插入到timer小根堆中 gettime(base, \u0026amp;now); evutil_timeradd(\u0026amp;now, tv, \u0026amp;ev-\u0026gt;ev_timeout); event_queue_insert(base, ev, EVLIST_TIMEOUT); } return (res); } event_queue_insert()负责将事件插入到对应的链表中，下面是程序代码； event_queue_remove()负责将事件从对应的链表中删除，这里就不再重复贴代码了； void event_queue_insert(struct event_base *base, struct event *ev, int queue) { // ev可能已经在激活列表中了，避免重复插入 if (ev-\u0026gt;ev_flags \u0026amp; queue) { if (queue \u0026amp; EVLIST_ACTIVE) return; } // ... ev-\u0026gt;ev_flags |= queue; // 记录queue标记 switch (queue) { case EVLIST_INSERTED: // I/O或Signal事件，加入已注册事件链表 TAILQ_INSERT_TAIL(\u0026amp;base-\u0026gt;eventqueue, ev, ev_next); break; case EVLIST_ACTIVE: // 就绪事件，加入激活链表 base-\u0026gt;event_count_active++; TAILQ_INSERT_TAIL(base-\u0026gt;activequeues[ev-\u0026gt;ev_pri], ev, ev_active_next); break; case EVLIST_TIMEOUT: // 定时事件，加入堆 min_heap_push(\u0026amp;base-\u0026gt;timeheap, ev); break; } } 2）删除事件： 函数原型为：\nint event_del(struct event *ev); 该函数将删除事件ev\n对于I/O事件，从I/O 的demultiplexer上将事件注销； 对于Signal事件，将从Signal事件链表中删除； 对于定时事件，将从堆上删除； 同样删除事件的操作则不一定是原子的，比如删除时间事件之后，有可能从系统I/O机制中注销会失败。\nint event_del(struct event *ev) { struct event_base *base; const struct eventop *evsel; void *evbase; // ev_base为NULL，表明ev没有被注册 if (ev-\u0026gt;ev_base == NULL) return (-1); // 取得ev注册的event_base和eventop指针 base = ev-\u0026gt;ev_base; evsel = base-\u0026gt;evsel; evbase = base-\u0026gt;evbase; // 将ev_callback调用次数设置为 if (ev-\u0026gt;ev_ncalls \u0026amp;\u0026amp; ev-\u0026gt;ev_pncalls) { *ev-\u0026gt;ev_pncalls = 0; } // 从对应的链表中删除 if (ev-\u0026gt;ev_flags \u0026amp; EVLIST_TIMEOUT) event_queue_remove(base, ev, EVLIST_TIMEOUT); if (ev-\u0026gt;ev_flags \u0026amp; EVLIST_ACTIVE) event_queue_remove(base, ev, EVLIST_ACTIVE); if (ev-\u0026gt;ev_flags \u0026amp; EVLIST_INSERTED) { event_queue_remove(base, ev, EVLIST_INSERTED); // EVLIST_INSERTED表明是I/O或者Signal事件， // 需要调用I/O demultiplexer注销事件 return (evsel-\u0026gt;del(evbase, ev)); } return (0); } 4. 小结 分析了event_base这一重要结构体，初步看到了libevent对系统的I/O demultiplex机制的封装event_op结构，并结合源代码分析了事件的注册和删除处理，下面将会接着分析事件管理框架中的主事件循环部分。\n","permalink":"https://haokiu.com/blog/fc115cade0c049a8ab14e737a22b37fe/","summary":"libevent源码深度剖析06 初见事件处理框架\n前面已经对libevent的事件处理框架和event结构体做了描述，现在是时候剖析libevent对事件的详细处理流程了，本节将分析libevent的事件处理框架event_base和libevent注册、删除事件的具体流程，可结合前一节libevent对event的管理。\n1. 事件处理框架-event_base 回想Reactor模式的几个基本组件，本节讲解的部分对应于Reactor框架组件。在libevent中，这就表现为event_base结构体，结构体声明如下，它位于event-internal.h文件中：\nstruct event_base { const struct eventop *evsel; void *evbase;　int event_count; /* counts number of total events */ int event_count_active; /* counts number of active events */ int event_gotterm; /* Set to terminate loop */ int event_break; /* Set to terminate loop immediately */ /* active event management */ struct event_list **activequeues; int nactivequeues; /* signal handling info */ struct evsignal_info sig; struct event_list eventqueue; struct timeval event_tv; struct min_heap timeheap; struct timeval tv_cache; }; 下面详细解释一下结构体中各字段的含义。\nevsel和evbase这两个字段的设置可能会让人有些迷惑，这里你可以把evsel和evbase看作是类和静态函数的关系，比如添加事件时的调用行为：evsel-\u0026gt;add(evbase, ev)，实际执行操作的是evbase；这相当于class::add(instance, ev)，instance就是class的一个对象实例。 evsel指向了全局变量static const struct eventop *eventops[]中的一个； 前面也说过，libevent将系统提供的I/O demultiplex机制统一封装成了eventop结构；因此eventops[]包含了select、poll、kequeue和epoll等等其中的若干个全局实例对象。 evbase实际上是一个eventop实例对象； 先来看看eventop结构体，它的成员是一系列的函数指针, 在event-internal.h文件中：\nstruct eventop { const char *name; void *(*init)(struct event_base *); // 初始化 int (*add)(void *, struct event *); // 注册事件 int (*del)(void *, struct event *); // 删除事件 int (*dispatch)(struct event_base *, void *, struct timeval *); // 事件分发 void (*dealloc)(struct event_base *, void *); // 注销，释放资源 /* set if we need to reinitialize the event base */ int need_reinit; }; 也就是说，在libevent中，每种I/O demultiplex机制的实现都必须提供这五个函数接口，来完成自身的初始化、销毁释放；对事件的注册、注销和分发。 比如对于epoll，libevent实现了5个对应的接口函数，并在初始化时并将eventop的5个函数指针指向这5个函数，那么程序就可以使用epoll作为I/O demultiplex机制了，这个在后面会再次提到。","title":"libevent源码深度剖析06"},{"content":"libevent源码深度剖析07 事件主循环\n现在我们已经初步了解了libevent的Reactor组件——event_base和事件管理框架，接下来就是libevent事件处理的中心部分——事件主循环，根据系统提供的事件多路分发机制执行事件循环，对已注册的就绪事件，调用注册事件的回调函数来处理事件。\n1. 阶段性的胜利 libevent将I/O事件、定时器和信号事件处理很好的结合到了一起，本节也会介绍libevent是如何做到这一点的。 在看完本节的内容后，读者应该会对Libevent的基本框架：事件管理和主循环有比较清晰的认识了，并能够把libevent的事件控制流程清晰的串通起来，剩下的就是一些细节的内容了。\n2. 事件处理主循环 libevent的事件主循环主要是通过**event_base_loop ()**函数完成的，其主要操作如下面的流程图所示，event_base_loop所作的就是持续执行下面的循环。 清楚了event_base_loop所作的主要操作，就可以对比源代码看个究竟了，代码结构还是相当清晰的。\nint event_base_loop(struct event_base *base, int flags){ const struct eventop *evsel = base-\u0026gt;evsel; void *evbase = base-\u0026gt;evbase; struct timeval tv; struct timeval *tv_p; int res, done; // 清空时间缓存 base-\u0026gt;tv_cache.tv_sec = 0; // evsignal_base是全局变量，在处理signal时，用于指名signal所属的event_base实例 if (base-\u0026gt;sig.ev_signal_added) evsignal_base = base; done = 0; while (!done) { // 事件主循环 // 查看是否需要跳出循环，程序可以调用event_loopexit_cb()设置event_gotterm标记 // 调用event_base_loopbreak()设置event_break标记 if (base-\u0026gt;event_gotterm) { base-\u0026gt;event_gotterm = 0; break; } if (base-\u0026gt;event_break) { base-\u0026gt;event_break = 0; break; } // 校正系统时间，如果系统使用的是非MONOTONIC时间，用户可能会向后调整了系统时间 // 在timeout_correct函数里，比较last wait time和当前时间，如果当前时间\u0026lt; last wait time // 表明时间有问题，这是需要更新timer_heap中所有定时事件的超时时间。 timeout_correct(base, \u0026amp;tv); // 根据timer heap中事件的最小超时时间，计算系统I/O demultiplexer的最大等待时间 tv_p = \u0026amp;tv; if (!base-\u0026gt;event_count_active \u0026amp;\u0026amp; !(flags \u0026amp; EVLOOP_NONBLOCK)) { timeout_next(base, \u0026amp;tv_p); } else { // 依然有未处理的就绪时间，就让I/O demultiplexer立即返回，不必等待 // 下面会提到，在libevent中，低优先级的就绪事件可能不能立即被处理 evutil_timerclear(\u0026amp;tv); } // 如果当前没有注册事件，就退出 if (!event_haveevents(base)) { event_debug((\u0026#34;%s: no events registered.\u0026#34;, __func__)); return (1); } // 更新last wait time，并清空time cache gettime(base, \u0026amp;base-\u0026gt;event_tv); base-\u0026gt;tv_cache.tv_sec = 0; // 调用系统I/O demultiplexer等待就绪I/O events，可能是epoll_wait，或者select等； // 在evsel-\u0026gt;dispatch()中，会把就绪signal event、I/O event插入到激活链表中 res = evsel-\u0026gt;dispatch(base, evbase, tv_p); if (res == -1) return (-1); // 将time cache赋值为当前系统时间 gettime(base, \u0026amp;base-\u0026gt;tv_cache); // 检查heap中的timer events，将就绪的timer event从heap上删除，并插入到激活链表中 timeout_process(base); // 调用event_process_active()处理激活链表中的就绪event，调用其回调函数执行事件处理 // 该函数会寻找最高优先级（priority值越小优先级越高）的激活事件链表， // 然后处理链表中的所有就绪事件； // 因此低优先级的就绪事件可能得不到及时处理； if (base-\u0026gt;event_count_active) { event_process_active(base); if (!base-\u0026gt;event_count_active \u0026amp;\u0026amp; (flags \u0026amp; EVLOOP_ONCE)) done = 1; } else if (flags \u0026amp; EVLOOP_NONBLOCK) done = 1; } // 循环结束，清空时间缓存 base-\u0026gt;tv_cache.tv_sec = 0; event_debug((\u0026#34;%s: asked to terminate loop.\u0026#34;, __func__)); return (0); } 3. I/O和Timer事件的统一 libevent将Timer和Signal事件都统一到了系统的I/O 的demultiplex机制中了，相信读者从上面的流程和代码中也能窥出一斑了，下面就再啰嗦一次了。 首先将Timer事件融合到系统I/O多路复用机制中，还是相当清晰的，因为系统的I/O机制像select()和epoll_wait()都允许程序制定一个最大等待时间（也称为最大超时时间）timeout，即使没有I/O事件发生，它们也保证能在timeout时间内返回。 那么根据所有Timer事件的最小超时时间来设置系统I/O的timeout时间；当系统I/O返回时，再激活所有就绪的Timer事件就可以了，这样就能将Timer事件完美的融合到系统的I/O机制中了。 这是在Reactor和Proactor模式（主动器模式，比如Windows上的IOCP）中处理Timer事件的经典方法了，ACE采用的也是这种方法，大家可以参考POSA vol2书中的Reactor模式一节。 堆是一种经典的数据结构，向堆中插入、删除元素时间复杂度都是O(lgN)，N为堆中元素的个数，而获取最小key值（小根堆）的复杂度为O(1)；因此变成了管理Timer事件的绝佳人选（当然是非唯一的），libevent就是采用的堆结构。\n4. I/O和Signal事件的统一 Signal是异步事件的经典事例，将Signal事件统一到系统的I/O多路复用中就不像Timer事件那么自然了，Signal事件的出现对于进程来讲是完全随机的，进程不能只是测试一个变量来判别是否发生了一个信号，而是必须告诉内核“在此信号发生时，请执行如下的操作”。 如果当Signal发生时，并不立即调用event的callback函数处理信号，而是设法通知系统的I/O机制，让其返回，然后再统一和I/O事件以及Timer一起处理，不就可以了嘛。是的，这也是libevent中使用的方法。 问题的核心在于，当Signal发生时，如何通知系统的I/O多路复用机制，这里先买个小关子，放到信号处理一节再详细说明，我想读者肯定也能想出通知的方法，比如使用pipe。\n5 小节 介绍了libevent的事件主循环，描述了libevent是如何处理就绪的I/O事件、定时器和信号事件，以及如何将它们无缝的融合到一起。\n","permalink":"https://haokiu.com/blog/1fa932a07dd84e9fbdde728e110c098f/","summary":"libevent源码深度剖析07 事件主循环\n现在我们已经初步了解了libevent的Reactor组件——event_base和事件管理框架，接下来就是libevent事件处理的中心部分——事件主循环，根据系统提供的事件多路分发机制执行事件循环，对已注册的就绪事件，调用注册事件的回调函数来处理事件。\n1. 阶段性的胜利 libevent将I/O事件、定时器和信号事件处理很好的结合到了一起，本节也会介绍libevent是如何做到这一点的。 在看完本节的内容后，读者应该会对Libevent的基本框架：事件管理和主循环有比较清晰的认识了，并能够把libevent的事件控制流程清晰的串通起来，剩下的就是一些细节的内容了。\n2. 事件处理主循环 libevent的事件主循环主要是通过**event_base_loop ()**函数完成的，其主要操作如下面的流程图所示，event_base_loop所作的就是持续执行下面的循环。 清楚了event_base_loop所作的主要操作，就可以对比源代码看个究竟了，代码结构还是相当清晰的。\nint event_base_loop(struct event_base *base, int flags){ const struct eventop *evsel = base-\u0026gt;evsel; void *evbase = base-\u0026gt;evbase; struct timeval tv; struct timeval *tv_p; int res, done; // 清空时间缓存 base-\u0026gt;tv_cache.tv_sec = 0; // evsignal_base是全局变量，在处理signal时，用于指名signal所属的event_base实例 if (base-\u0026gt;sig.ev_signal_added) evsignal_base = base; done = 0; while (!done) { // 事件主循环 // 查看是否需要跳出循环，程序可以调用event_loopexit_cb()设置event_gotterm标记 // 调用event_base_loopbreak()设置event_break标记 if (base-\u0026gt;event_gotterm) { base-\u0026gt;event_gotterm = 0; break; } if (base-\u0026gt;event_break) { base-\u0026gt;event_break = 0; break; } // 校正系统时间，如果系统使用的是非MONOTONIC时间，用户可能会向后调整了系统时间 // 在timeout_correct函数里，比较last wait time和当前时间，如果当前时间\u0026lt; last wait time // 表明时间有问题，这是需要更新timer_heap中所有定时事件的超时时间。 timeout_correct(base, \u0026amp;tv); // 根据timer heap中事件的最小超时时间，计算系统I/O demultiplexer的最大等待时间 tv_p = \u0026amp;tv; if (!base-\u0026gt;event_count_active \u0026amp;\u0026amp; !","title":"libevent源码深度剖析07"},{"content":"libevent源码深度剖析08 集成信号处理\n现在我们已经了解了libevent的基本框架：事件管理框架和事件主循环。上节提到了libevent中I/O事件和Signal以及Timer事件的集成，这一节将分析如何将Signal集成到事件主循环的框架中。\n1. 集成策略——使用socket pair 前一节已经做了足够多的介绍了，基本方法就是采用“消息机制”。在libevent中这是通过socket pair完成的，下面就来详细分析一下。 Socket pair就是一个socket对，包含两个socket，一个读socket，一个写socket。工作方式如下图所示：\n创建一个socket pair并不是复杂的操作，可以参见下面的流程图，清晰起见，其中忽略了一些错误处理和检查。\nLibevent提供了辅助函数evutil_socketpair()来创建一个socket pair，可以结合上面的创建流程来分析该函数。\n2. 集成到事件主循环——通知event_base Socket pair创建好了，可是libevent的事件主循环还是不知道Signal是否发生了啊，看来我们还差了最后一步，那就是：为socket pair的读socket在libevent的event_base实例上注册一个persist的读事件。 这样当向写socket写入数据时，读socket就会得到通知，触发读事件，从而event_base就能相应的得到通知了。 前面提到过，Libevent会在事件主循环中检查标记，来确定是否有触发的signal，如果标记被设置就处理这些signal，这段代码在各个具体的I/O机制中，以Epoll为例，在**epoll_dispatch()**函数中，代码片段如下：\nres = epoll_wait(epollop-\u0026gt;epfd, events, epollop-\u0026gt;nevents, timeout); if (res == -1) { if (errno != EINTR) { event_warn(\u0026#34;epoll_wait\u0026#34;); return (-1); } evsignal_process(base);// 处理signal事件 return (0); } else if (base-\u0026gt;sig.evsignal_caught) { evsignal_process(base);// 处理signal事件 } 完整的处理框架如下所示：\n注1：libevent中，初始化阶段并不注册读socket的读事件，而是在注册信号阶段才会测试并注册； 注2：libevent中，检查I/O事件是在各系统I/O机制的**dispatch()函数中完成的，该dispatch()函数在event_base_loop()**函数中被调用；\n3. evsignal_info结构体 libevent中Signal事件的管理是通过结构体evsignal_info完成的，结构体位于evsignal.h文件中，定义如下：\nstruct evsignal_info { struct event ev_signal; int ev_signal_pair[2]; int ev_signal_added; volatile sig_atomic_t evsignal_caught; struct event_list evsigevents[NSIG]; sig_atomic_t evsigcaught[NSIG]; #ifdef HAVE_SIGACTION struct sigaction **sh_old; #else ev_sighandler_t **sh_old; #endif int sh_old_max; }; 下面详细介绍一下个字段的含义和作用： 1）ev_signal， 为socket pair的读socket向event_base注册读事件时使用的event结构体； 2）ev_signal_pair，socket pair对，作用见第一节的介绍； 3）ev_signal_added，记录ev_signal事件是否已经注册了； 4）evsignal_caught，是否有信号发生的标记；是volatile类型，因为它会在另外的线程中被修改； 5）evsigvents[NSIG]，数组，evsigevents[signo]表示注册到信号signo的事件链表； 6）evsigcaught[NSIG]，具体记录每个信号触发的次数，evsigcaught[signo]是记录信号signo被触发的次数； 7）sh_old记录了原来的signal处理函数指针，当信号signo注册的event被清空时，需要重新设置其处理函数； evsignal_info的初始化包括，创建socket pair，设置ev_signal事件（但并没有注册，而是等到有信号注册时才检查并注册），并将所有标记置零，初始化信号的注册事件链表指针等。\n4. 注册、注销signal事件 注册signal事件是通过evsignal_add(struct event *ev)函数完成的，libevent对所有的信号注册同一个处理函数evsignal_handler()，该函数将在下一段介绍，注册过程如下： 1 取得ev要注册到的信号signo； 2 如果信号signo未被注册，那么就为signo注册信号处理函数evsignal_handler()； 3 如果事件ev_signal还没哟注册，就注册ev_signal事件； 4 将事件ev添加到signo的event链表中； 从signo上注销一个已注册的signal事件就更简单了，直接从其已注册事件的链表中移除即可。如果事件链表已空，那么就恢复旧的处理函数； 下面的讲解都以signal()函数为例，sigaction()函数的处理和signal()相似。 处理函数evsignal_handler()函数做的事情很简单，就是记录信号的发生次数，并通知event_base有信号触发，需要处理：\nstatic void evsignal_handler(int sig){ int save_errno = errno; // 不覆盖原来的错误代码 if (evsignal_base == NULL) { event_warn(\u0026#34;%s: received signal %d, but have no base configured\u0026#34;, __func__, sig); return; } // 记录信号sig的触发次数，并设置event触发标记 evsignal_base-\u0026gt;sig.evsigcaught[sig]++; evsignal_base-\u0026gt;sig.evsignal_caught = 1; #ifndef HAVE_SIGACTION signal(sig, evsignal_handler); // 重新注册信号 #endif // 向写socket写一个字节数据，触发event_base的I/O事件，从而通知其有信号触发，需要处理 send(evsignal_base-\u0026gt;sig.ev_signal_pair[0], \u0026#34;a\u0026#34;, 1, 0); errno = save_errno; // 错误代码 } 5. 小节 本节介绍了libevent对signal事件的具体处理框架，包括事件注册、删除和socket pair通知机制，以及是如何将Signal事件集成到事件主循环之中的。\n","permalink":"https://haokiu.com/blog/4a5e0c5a568b4187b207ec0ada2dbdfb/","summary":"libevent源码深度剖析08 集成信号处理\n现在我们已经了解了libevent的基本框架：事件管理框架和事件主循环。上节提到了libevent中I/O事件和Signal以及Timer事件的集成，这一节将分析如何将Signal集成到事件主循环的框架中。\n1. 集成策略——使用socket pair 前一节已经做了足够多的介绍了，基本方法就是采用“消息机制”。在libevent中这是通过socket pair完成的，下面就来详细分析一下。 Socket pair就是一个socket对，包含两个socket，一个读socket，一个写socket。工作方式如下图所示：\n创建一个socket pair并不是复杂的操作，可以参见下面的流程图，清晰起见，其中忽略了一些错误处理和检查。\nLibevent提供了辅助函数evutil_socketpair()来创建一个socket pair，可以结合上面的创建流程来分析该函数。\n2. 集成到事件主循环——通知event_base Socket pair创建好了，可是libevent的事件主循环还是不知道Signal是否发生了啊，看来我们还差了最后一步，那就是：为socket pair的读socket在libevent的event_base实例上注册一个persist的读事件。 这样当向写socket写入数据时，读socket就会得到通知，触发读事件，从而event_base就能相应的得到通知了。 前面提到过，Libevent会在事件主循环中检查标记，来确定是否有触发的signal，如果标记被设置就处理这些signal，这段代码在各个具体的I/O机制中，以Epoll为例，在**epoll_dispatch()**函数中，代码片段如下：\nres = epoll_wait(epollop-\u0026gt;epfd, events, epollop-\u0026gt;nevents, timeout); if (res == -1) { if (errno != EINTR) { event_warn(\u0026#34;epoll_wait\u0026#34;); return (-1); } evsignal_process(base);// 处理signal事件 return (0); } else if (base-\u0026gt;sig.evsignal_caught) { evsignal_process(base);// 处理signal事件 } 完整的处理框架如下所示：\n注1：libevent中，初始化阶段并不注册读socket的读事件，而是在注册信号阶段才会测试并注册； 注2：libevent中，检查I/O事件是在各系统I/O机制的**dispatch()函数中完成的，该dispatch()函数在event_base_loop()**函数中被调用；\n3. evsignal_info结构体 libevent中Signal事件的管理是通过结构体evsignal_info完成的，结构体位于evsignal.h文件中，定义如下：\nstruct evsignal_info { struct event ev_signal; int ev_signal_pair[2]; int ev_signal_added; volatile sig_atomic_t evsignal_caught; struct event_list evsigevents[NSIG]; sig_atomic_t evsigcaught[NSIG]; #ifdef HAVE_SIGACTION struct sigaction **sh_old; #else ev_sighandler_t **sh_old; #endif int sh_old_max; }; 下面详细介绍一下个字段的含义和作用： 1）ev_signal， 为socket pair的读socket向event_base注册读事件时使用的event结构体； 2）ev_signal_pair，socket pair对，作用见第一节的介绍； 3）ev_signal_added，记录ev_signal事件是否已经注册了； 4）evsignal_caught，是否有信号发生的标记；是volatile类型，因为它会在另外的线程中被修改； 5）evsigvents[NSIG]，数组，evsigevents[signo]表示注册到信号signo的事件链表； 6）evsigcaught[NSIG]，具体记录每个信号触发的次数，evsigcaught[signo]是记录信号signo被触发的次数； 7）sh_old记录了原来的signal处理函数指针，当信号signo注册的event被清空时，需要重新设置其处理函数； evsignal_info的初始化包括，创建socket pair，设置ev_signal事件（但并没有注册，而是等到有信号注册时才检查并注册），并将所有标记置零，初始化信号的注册事件链表指针等。","title":"libevent源码深度剖析08"},{"content":"libevent源码深度剖析09 集成定时器事件\n现在再来详细分析libevent中I/O事件和Timer事件的集成，与Signal相比，Timer事件的集成会直观和简单很多。Libevent对堆的调整操作做了一些优化，本节还会描述这些优化方法。\n1. 集成到事件主循环 因为系统的I/O机制像select()和epoll_wait()都允许程序制定一个最大等待时间（也称为最大超时时间）timeout，即使没有I/O事件发生，它们也保证能在timeout时间内返回。 那么根据所有Timer事件的最小超时时间来设置系统I/O的timeout时间；当系统I/O返回时，再激活所有就绪的Timer事件就可以了，这样就能将Timer事件完美的融合到系统的I/O机制中了。 具体的代码在源文件event.c的**event_base_loop()**中，现在就对比代码来看看这一处理方法：\nif (!base-\u0026gt;event_count_active \u0026amp;\u0026amp; !(flags \u0026amp; EVLOOP_NONBLOCK)) { // 根据Timer事件计算evsel-\u0026gt;dispatch的最大等待时间 timeout_next(base, \u0026amp;tv_p); } else { // 如果还有活动事件，就不要等待，让evsel-\u0026gt;dispatch立即返回 evutil_timerclear(\u0026amp;tv); } // ... // 调用select() or epoll_wait() 等待就绪I/O事件 res = evsel-\u0026gt;dispatch(base, evbase, tv_p); // ... // 处理超时事件，将超时事件插入到激活链表中 timeout_process(base); **timeout_next()**函数根据堆中具有最小超时值的事件和当前时间来计算等待时间，下面看看代码：\n1static int timeout_next(struct event_base *base, struct timeval **tv_p){ 2 struct timeval now; 3 struct event *ev; 4 struct timeval *tv = *tv_p; 5 // 堆的首元素具有最小的超时值 6 if ((ev = min_heap_top(\u0026amp;base-\u0026gt;timeheap)) == NULL) { 7 // 如果没有定时事件，将等待时间设置为NULL,表示一直阻塞直到有I/O事件发生 8 *tv_p = NULL; 9 return (0); 10 } 11 // 取得当前时间 12 gettime(base, \u0026amp;now); 13 // 如果超时时间\u0026lt;=当前值，不能等待，需要立即返回 14 if (evutil_timercmp(\u0026amp;ev-\u0026gt;ev_timeout, \u0026amp;now, \u0026lt;=)) { 15 evutil_timerclear(tv); 16 return (0); 17 } 18 // 计算等待的时间=当前时间-最小的超时时间 19 evutil_timersub(\u0026amp;ev-\u0026gt;ev_timeout, \u0026amp;now, tv); 20 return (0); 21} 2. Timer小根堆 libevent使用堆来管理Timer事件，其key值就是事件的超时时间，源代码位于文件min_heap.h中。 所有的数据结构书中都有关于堆的详细介绍，向堆中插入、删除元素时间复杂度都是O(lgN)，N为堆中元素的个数，而获取最小key值（小根堆）的复杂度为O(1)。堆是一个完全二叉树，基本存储方式是一个数组。 libevent实现的堆还是比较轻巧的，虽然我不喜欢这种编码方式（搞一些复杂的表达式）。轻巧到什么地方呢，就以插入元素为例，来对比说明，下面伪代码中的size表示当前堆的元素个数：\n典型的代码逻辑如下：\nHeap[size++] = new; // 先放到数组末尾，元素个数+1 // 下面就是shift_up()的代码逻辑，不断的将new向上调整 _child = size; while(_child\u0026gt;0) // 循环 { _parent = (_child-1)/2; // 计算parent if(Heap[_parent].key \u0026lt; Heap[_child].key) break; // 调整结束，跳出循环 swap(_parent, _child); // 交换parent和child } 而libevent的heap代码对这一过程做了优化，在插入新元素时，只是为新元素预留了一个位置hole（初始时hole位于数组尾部），但并不立刻将新元素插入到hole上，而是不断向上调整hole的值，将父节点向下调整，最后确认hole就是新元素的所在位置时，才会真正的将新元素插入到hole上，因此在调整过程中就比上面的代码少了一次赋值的操作，代码逻辑是：\n// 下面就是shift_up()的代码逻辑，不断的将new的“预留位置”向上调整 _hole = size; // _hole就是为new预留的位置，但并不立刻将new放上 while(_hole\u0026gt;0) // 循环 { _parent = (_hole-1)/2; // 计算parent if(Heap[_parent].key \u0026lt; new.key) break; // 调整结束，跳出循环 Heap[_hole] = Heap[_parent]; // 将parent向下调整 _hole = _parent; // 将_hole调整到_parent } Heap[_hole] = new; // 调整结束，将new插入到_hole指示的位置 size++; // 元素个数+1 由于每次调整都少做一次赋值操作，在调整路径比较长时，调整效率会比第一种有所提高。libevent中的min_heap_shift_up_()函数就是上面逻辑的具体实现，对应的向下调整函数是min_heap_shift_down_()。\n举个例子，向一个小根堆3, 5, 8, 7, 12中插入新元素2，使用第一中典型的代码逻辑，其调整过程如下图所示：\n使用libevent中的堆调整逻辑，调整过程如下图所示：\n对于删除和元素修改操作，也遵从相同的逻辑，就不再罗嗦了。\n3. 小节 通过设置系统I/O机制的wait时间，从而简洁的集成Timer事件；主要分析了libevent对堆调整操作的优化。\n","permalink":"https://haokiu.com/blog/e65e0c91ca7e45ad9ad3081edbd423f8/","summary":"libevent源码深度剖析09 集成定时器事件\n现在再来详细分析libevent中I/O事件和Timer事件的集成，与Signal相比，Timer事件的集成会直观和简单很多。Libevent对堆的调整操作做了一些优化，本节还会描述这些优化方法。\n1. 集成到事件主循环 因为系统的I/O机制像select()和epoll_wait()都允许程序制定一个最大等待时间（也称为最大超时时间）timeout，即使没有I/O事件发生，它们也保证能在timeout时间内返回。 那么根据所有Timer事件的最小超时时间来设置系统I/O的timeout时间；当系统I/O返回时，再激活所有就绪的Timer事件就可以了，这样就能将Timer事件完美的融合到系统的I/O机制中了。 具体的代码在源文件event.c的**event_base_loop()**中，现在就对比代码来看看这一处理方法：\nif (!base-\u0026gt;event_count_active \u0026amp;\u0026amp; !(flags \u0026amp; EVLOOP_NONBLOCK)) { // 根据Timer事件计算evsel-\u0026gt;dispatch的最大等待时间 timeout_next(base, \u0026amp;tv_p); } else { // 如果还有活动事件，就不要等待，让evsel-\u0026gt;dispatch立即返回 evutil_timerclear(\u0026amp;tv); } // ... // 调用select() or epoll_wait() 等待就绪I/O事件 res = evsel-\u0026gt;dispatch(base, evbase, tv_p); // ... // 处理超时事件，将超时事件插入到激活链表中 timeout_process(base); **timeout_next()**函数根据堆中具有最小超时值的事件和当前时间来计算等待时间，下面看看代码：\n1static int timeout_next(struct event_base *base, struct timeval **tv_p){ 2 struct timeval now; 3 struct event *ev; 4 struct timeval *tv = *tv_p; 5 // 堆的首元素具有最小的超时值 6 if ((ev = min_heap_top(\u0026amp;base-\u0026gt;timeheap)) == NULL) { 7 // 如果没有定时事件，将等待时间设置为NULL,表示一直阻塞直到有I/O事件发生 8 *tv_p = NULL; 9 return (0); 10 } 11 // 取得当前时间 12 gettime(base, \u0026amp;now); 13 // 如果超时时间\u0026lt;=当前值，不能等待，需要立即返回 14 if (evutil_timercmp(\u0026amp;ev-\u0026gt;ev_timeout, \u0026amp;now, \u0026lt;=)) { 15 evutil_timerclear(tv); 16 return (0); 17 } 18 // 计算等待的时间=当前时间-最小的超时时间 19 evutil_timersub(\u0026amp;ev-\u0026gt;ev_timeout, \u0026amp;now, tv); 20 return (0); 21} 2.","title":"libevent源码深度剖析09"},{"content":"libevent源码深度剖析10 支持I/O多路复用技术\nlibevent的核心是事件驱动、同步非阻塞，为了达到这一目标，必须采用系统提供的I/O多路复用技术，而这些在Windows、Linux、Unix等不同平台上却各有不同，如何能提供优雅而统一的支持方式，是首要关键的问题，这其实不难，本节就来分析一下。\n1. 统一的关键 libevent支持多种I/O多路复用技术的关键就在于结构体eventop，这个结构体前面也曾提到过，它的成员是一系列的函数指针, 定义在event-internal.h文件中：\nstruct eventop { const char *name; void *(*init)(struct event_base *); // 初始化 int (*add)(void *, struct event *); // 注册事件 int (*del)(void *, struct event *); // 删除事件 int (*dispatch)(struct event_base *, void *, struct timeval *); // 事件分发 void (*dealloc)(struct event_base *, void *); // 注销，释放资源 /* set if we need to reinitialize the event base */ int need_reinit; }; 在libevent中，每种I/O demultiplex机制的实现都必须提供这五个函数接口，来完成自身的初始化、销毁释放；对事件的注册、注销和分发。 比如对于epoll，libevent实现了5个对应的接口函数，并在初始化时并将eventop的5个函数指针指向这5个函数，那么程序就可以使用epoll作为I/O demultiplex机制了。\n2. 设置I/O demultiplex机制 libevent把所有支持的I/O demultiplex机制存储在一个全局静态数组eventops中，并在初始化时选择使用何种机制，数组内容根据优先级顺序声明如下：\n/* In order of preference */ static const struct eventop *eventops[] = { #ifdef HAVE_EVENT_PORTS \u0026amp;evportops, #endif #ifdef HAVE_WORKING_KQUEUE \u0026amp;kqops, #endif #ifdef HAVE_EPOLL \u0026amp;epollops, #endif #ifdef HAVE_DEVPOLL \u0026amp;devpollops, #endif #ifdef HAVE_POLL \u0026amp;pollops, #endif #ifdef HAVE_SELECT \u0026amp;selectops, #endif #ifdef WIN32 \u0026amp;win32ops, #endif NULL }; 然后libevent根据系统配置和编译选项决定使用哪一种I/O demultiplex机制，这段代码在函数**event_base_new()**中：\nbase-\u0026gt;evbase = NULL; for (i = 0; eventops[i] \u0026amp;\u0026amp; !base-\u0026gt;evbase; i++) { base-\u0026gt;evsel = eventops[i]; base-\u0026gt;evbase = base-\u0026gt;evsel-\u0026gt;init(base); } base-\u0026gt;evbase = NULL; for (i = 0; eventops[i] \u0026amp;\u0026amp; !base-\u0026gt;evbase; i++) { base-\u0026gt;evsel = eventops[i]; base-\u0026gt;evbase = base-\u0026gt;evsel-\u0026gt;init(base); } 可以看出，libevent在编译阶段选择系统的I/O demultiplex机制，而不支持在运行阶段根据配置再次选择。\n以Linux下面的epoll为例，实现在源文件epoll.c中，eventops对象epollops定义如下：\nconst struct eventop epollops = { \u0026#34;epoll\u0026#34;, epoll_init, epoll_add, epoll_del, epoll_dispatch, epoll_dealloc, 1 /* need reinit */ }; 变量epollops中的函数指针具体声明如下，注意到其返回值和参数都和eventop中的定义严格一致，这是函数指针的语法限制。\nstatic void *epoll_init (struct event_base *); static int epoll_add (void *, struct event *); static int epoll_del (void *, struct event *); static int epoll_dispatch(struct event_base *, void *, struct timeval *); static void epoll_dealloc (struct event_base *, void *); 那么如果选择的是epoll，那么调用结构体eventop的init和dispatch函数指针时，实际调用的函数就是epoll的初始化函数**epoll_init()和事件分发函数epoll_dispatch()**了；\nhttp://blog.csdn.net/sparkliang/archive/2009/06/09/4254115.aspx 同样的，上面epollops以及epoll的各种函数都直接定义在了epoll.c源文件中，对外都是不可见的。对于libevent的使用者而言，完全不会知道它们的存在，对epoll的使用也是通过eventop来完成的，达到了信息隐藏的目的。\n3. 小节 支持多种I/O demultiplex机制的方法其实挺简单的，借助于函数指针就OK了。通过对源代码的分析也可以看出，libevent是在编译阶段选择系统的I/O demultiplex机制的，而不支持在运行阶段根据配置再次选择。\n","permalink":"https://haokiu.com/blog/f567712a9375435692b3217e444f19e5/","summary":"libevent源码深度剖析10 支持I/O多路复用技术\nlibevent的核心是事件驱动、同步非阻塞，为了达到这一目标，必须采用系统提供的I/O多路复用技术，而这些在Windows、Linux、Unix等不同平台上却各有不同，如何能提供优雅而统一的支持方式，是首要关键的问题，这其实不难，本节就来分析一下。\n1. 统一的关键 libevent支持多种I/O多路复用技术的关键就在于结构体eventop，这个结构体前面也曾提到过，它的成员是一系列的函数指针, 定义在event-internal.h文件中：\nstruct eventop { const char *name; void *(*init)(struct event_base *); // 初始化 int (*add)(void *, struct event *); // 注册事件 int (*del)(void *, struct event *); // 删除事件 int (*dispatch)(struct event_base *, void *, struct timeval *); // 事件分发 void (*dealloc)(struct event_base *, void *); // 注销，释放资源 /* set if we need to reinitialize the event base */ int need_reinit; }; 在libevent中，每种I/O demultiplex机制的实现都必须提供这五个函数接口，来完成自身的初始化、销毁释放；对事件的注册、注销和分发。 比如对于epoll，libevent实现了5个对应的接口函数，并在初始化时并将eventop的5个函数指针指向这5个函数，那么程序就可以使用epoll作为I/O demultiplex机制了。\n2. 设置I/O demultiplex机制 libevent把所有支持的I/O demultiplex机制存储在一个全局静态数组eventops中，并在初始化时选择使用何种机制，数组内容根据优先级顺序声明如下：\n/* In order of preference */ static const struct eventop *eventops[] = { #ifdef HAVE_EVENT_PORTS \u0026amp;evportops, #endif #ifdef HAVE_WORKING_KQUEUE \u0026amp;kqops, #endif #ifdef HAVE_EPOLL \u0026amp;epollops, #endif #ifdef HAVE_DEVPOLL \u0026amp;devpollops, #endif #ifdef HAVE_POLL \u0026amp;pollops, #endif #ifdef HAVE_SELECT \u0026amp;selectops, #endif #ifdef WIN32 \u0026amp;win32ops, #endif NULL }; 然后libevent根据系统配置和编译选项决定使用哪一种I/O demultiplex机制，这段代码在函数**event_base_new()**中：","title":"libevent源码深度剖析10"},{"content":"libevent源码深度剖析11 时间管理\n为了支持定时器，libevent必须和系统时间打交道，这一部分的内容也比较简单，主要涉及到时间的加减辅助函数、时间缓存、时间校正和定时器堆的时间值调整等。下面就结合源代码来分析一下。\n1. 初始化检测 libevent在初始化时会检测系统时间的类型，通过调用函数**d****etect_monotonic()完成，它通过调用clock_gettime()**来检测系统是否支持monotonic时钟类型：\nstatic void detect_monotonic(void){ #if defined(HAVE_CLOCK_GETTIME) \u0026amp;\u0026amp; defined(CLOCK_MONOTONIC) struct timespec ts; if (clock_gettime(CLOCK_MONOTONIC, \u0026amp;ts) == 0) use_monotonic = 1; // 系统支持monotonic时间 #endif } Monotonic时间指示的是系统从boot后到现在所经过的时间，如果系统支持Monotonic时间就将全局变量use_monotonic设置为1，设置use_monotonic到底有什么用，这个在后面说到时间校正时就能看出来了。\n2. 时间缓存 结构体event_base中的tv_cache，用来记录时间缓存。这个还要从函数**gettime()**说起，先来看看该函数的代码：\nstatic int gettime(struct event_base *base, struct timeval *tp){ // 如果tv_cache时间缓存已设置，就直接使用 if (base-\u0026gt;tv_cache.tv_sec) { *tp = base-\u0026gt;tv_cache; return (0); } // 如果支持monotonic，就用clock_gettime获取monotonic时间 #if defined(HAVE_CLOCK_GETTIME) \u0026amp;\u0026amp; defined(CLOCK_MONOTONIC) if (use_monotonic) { struct timespec ts; if (clock_gettime(CLOCK_MONOTONIC, \u0026amp;ts) == -1) return (-1); tp-\u0026gt;tv_sec = ts.tv_sec; tp-\u0026gt;tv_usec = ts.tv_nsec / 1000; return (0); } #endif // 否则只能取得系统当前时间 return (evutil_gettimeofday(tp, NULL)); } 如果tv_cache已经设置，那么就直接使用缓存的时间；否则需要再次执行系统调用获取系统时间。 函数**evutil_gettimeofday()用来获取当前系统时间，在Linux下其实就是系统调用gettimeofday()；Windows没有提供函数gettimeofday，而是通过调用_ftime()**来完成的。 在每次系统事件循环中，时间缓存tv_cache将会被相应的清空和设置，再次来看看下面event_base_loop的主要代码逻辑：\nint event_base_loop(struct event_base *base, int flags){ // 清空时间缓存 base-\u0026gt;tv_cache.tv_sec = 0; while(!done){ timeout_correct(base, \u0026amp;tv); // 时间校正 // 更新event_tv到tv_cache指示的时间或者当前时间（第一次） // event_tv \u0026lt;--- tv_cache gettime(base, \u0026amp;base-\u0026gt;event_tv); // 清空时间缓存-- 时间点1 base-\u0026gt;tv_cache.tv_sec = 0; // 等待I/O事件就绪 res = evsel-\u0026gt;dispatch(base, evbase, tv_p); // 缓存tv_cache存储了当前时间的值-- 时间点2 // tv_cache \u0026lt;--- now gettime(base, \u0026amp;base-\u0026gt;tv_cache); // .. 处理就绪事件 } // 退出时也要清空时间缓存 base-\u0026gt;tv_cache.tv_sec = 0; return (0); } 时间event_tv指示了dispatch()上次返回，也就是I/O事件就绪时的时间，第一次进入循环时，由于tv_cache被清空，因此gettime()执行系统调用获取当前系统时间；而后将会更新为tv_cache指示的时间。 时间tv_cache在dispatch()返回后被设置为当前系统时间，因此它缓存了本次I/O事件就绪时的时间（event_tv）。 从代码逻辑里可以看出event_tv取得的是tv_cache上一次的值，因此event_tv应该小于tv_cache的值。 设置时间缓存的优点是不必每次获取时间都执行系统调用，这是个相对费时的操作；在上面标注的时间点2到时间点1的这段时间（处理就绪事件时），调用gettime()取得的都是tv_cache缓存的时间。\n3. 时间校正 如果系统支持monotonic时间，该时间是系统从boot后到现在所经过的时间，因此不需要执行校正。 根据前面的代码逻辑，如果系统不支持monotonic时间，用户可能会手动的调整时间，如果时间被向前调整了（MS前面第7部分讲成了向后调整，要改正），比如从5点调整到了3点，那么在时间点2取得的值可能会小于上次的时间，这就需要调整了，下面来看看校正的具体代码，由函数**timeout_correct()**完成：\nstatic void timeout_correct(struct event_base *base, struct timeval *tv){ struct event **pev; unsigned int size; struct timeval off; if (use_monotonic) // monotonic时间就直接返回，无需调整 return; gettime(base, tv); // tv \u0026lt;---tv_cache // 根据前面的分析可以知道event_tv应该小于tv_cache // 如果tv \u0026lt; event_tv表明用户向前调整时间了，需要校正时间 if (evutil_timercmp(tv, \u0026amp;base-\u0026gt;event_tv, \u0026gt;=)) { base-\u0026gt;event_tv = *tv; return; } // 计算时间差值 evutil_timersub(\u0026amp;base-\u0026gt;event_tv, tv, \u0026amp;off); // 调整定时事件小根堆 pev = base-\u0026gt;timeheap.p; size = base-\u0026gt;timeheap.n; for (; size-- \u0026gt; 0; ++pev) { struct timeval *ev_tv = \u0026amp;(**pev).ev_timeout; evutil_timersub(ev_tv, \u0026amp;off, ev_tv); } base-\u0026gt;event_tv = *tv; // 更新event_tv为tv_cache } 在调整小根堆时，因为所有定时事件的时间值都会被减去相同的值，因此虽然堆中元素的时间键值改变了，但是相对关系并没有改变，不会改变堆的整体结构。因此只需要遍历堆中的所有元素，将每个元素的时间键值减去相同的值即可完成调整，不需要重新调整堆的结构。 当然调整完后，要将event_tv值重新设置为tv_cache值了。\n4. 小节 主要分析了一下libevent对系统时间的处理，时间缓存、时间校正和定时堆的时间值调整等，逻辑还是很简单的，时间的加减、设置等辅助函数则非常简单，主要在头文件evutil.h中，就不再多说了。\n","permalink":"https://haokiu.com/blog/136973dd819b459bac605bcb1a25571c/","summary":"libevent源码深度剖析11 时间管理\n为了支持定时器，libevent必须和系统时间打交道，这一部分的内容也比较简单，主要涉及到时间的加减辅助函数、时间缓存、时间校正和定时器堆的时间值调整等。下面就结合源代码来分析一下。\n1. 初始化检测 libevent在初始化时会检测系统时间的类型，通过调用函数**d****etect_monotonic()完成，它通过调用clock_gettime()**来检测系统是否支持monotonic时钟类型：\nstatic void detect_monotonic(void){ #if defined(HAVE_CLOCK_GETTIME) \u0026amp;\u0026amp; defined(CLOCK_MONOTONIC) struct timespec ts; if (clock_gettime(CLOCK_MONOTONIC, \u0026amp;ts) == 0) use_monotonic = 1; // 系统支持monotonic时间 #endif } Monotonic时间指示的是系统从boot后到现在所经过的时间，如果系统支持Monotonic时间就将全局变量use_monotonic设置为1，设置use_monotonic到底有什么用，这个在后面说到时间校正时就能看出来了。\n2. 时间缓存 结构体event_base中的tv_cache，用来记录时间缓存。这个还要从函数**gettime()**说起，先来看看该函数的代码：\nstatic int gettime(struct event_base *base, struct timeval *tp){ // 如果tv_cache时间缓存已设置，就直接使用 if (base-\u0026gt;tv_cache.tv_sec) { *tp = base-\u0026gt;tv_cache; return (0); } // 如果支持monotonic，就用clock_gettime获取monotonic时间 #if defined(HAVE_CLOCK_GETTIME) \u0026amp;\u0026amp; defined(CLOCK_MONOTONIC) if (use_monotonic) { struct timespec ts; if (clock_gettime(CLOCK_MONOTONIC, \u0026amp;ts) == -1) return (-1); tp-\u0026gt;tv_sec = ts.tv_sec; tp-\u0026gt;tv_usec = ts.tv_nsec / 1000; return (0); } #endif // 否则只能取得系统当前时间 return (evutil_gettimeofday(tp, NULL)); } 如果tv_cache已经设置，那么就直接使用缓存的时间；否则需要再次执行系统调用获取系统时间。 函数**evutil_gettimeofday()用来获取当前系统时间，在Linux下其实就是系统调用gettimeofday()；Windows没有提供函数gettimeofday，而是通过调用_ftime()**来完成的。 在每次系统事件循环中，时间缓存tv_cache将会被相应的清空和设置，再次来看看下面event_base_loop的主要代码逻辑：\nint event_base_loop(struct event_base *base, int flags){ // 清空时间缓存 base-\u0026gt;tv_cache.tv_sec = 0; while(!","title":"libevent源码深度剖析11"},{"content":"libevent源码深度剖析12 让libevent支持多线程\nlibevent本身不是多线程安全的，在多核的时代，如何能充分利用CPU的能力呢，这一节来说说如何在多线程环境中使用libevent，跟源代码并没有太大的关系，纯粹是使用上的技巧。\n1. 错误使用示例 在多核的CPU上只使用一个线程始终是对不起CPU的处理能力啊，那好吧，那就多创建几个线程，比如下面的简单服务器场景。 1 主线程创建工作线程1； 2 接着主线程监听在端口上，等待新的连接； 3 在线程1中执行event事件循环，等待事件到来； 4 新连接到来，主线程调用libevent接口event_add将新连接注册到libevent上； … … 上面的逻辑看起来没什么错误，在很多服务器设计中都可能用到主线程和工作线程的模式…. 可是就在线程1注册事件时，主线程很可能也在操作事件，比如删除，修改，通过libevent的源代码也能看到，没有同步保护机制，问题麻烦了，看起来不能这样做啊，难道只能使用单线程不成！？\n2. 支持多线程的几种模式 libevent并不是线程安全的，但这不代表libevent不支持多线程模式，其实方法在前面已经将signal事件处理时就接触到了，那就是消息通知机制。 一句话，“你发消息通知我，然后再由我在合适的时间来处理”； 说到这就再多说几句，再打个比方，把你自己比作一个工作线程，而你的头是主线程，你有一个消息信箱来接收别人发给你的消息，当时头有个新任务要指派给你。\n2.1 暴力抢占 那么第一节中使用的多线程方法相当下面的流程： 1 当时你正在做事，比如在写文档； 2 你的头找到了一个任务，要指派给你，比如帮他搞个PPT，哈； 3 头命令你马上搞PPT，你这是不得不停止手头的工作，把PPT搞定了再接着写文档； …\n2.2 纯粹的消息通知机制 那么基于纯粹的消息通知机制的多线程方式就像下面这样： 1 当时你正在写文档； 2 你的头找到了一个任务，要指派给你，帮他搞个PPT； 3 头发个消息到你信箱，有个PPT要帮他搞定，这时你并不鸟他； 4 你写好文档，接着检查消息发现头有个PPT要你搞定，你开始搞PPT； … 第一种的好处是消息可以立即得到处理，但是很方法很粗暴，你必须立即处理这个消息，所以你必须处理好切换问题，省得把文档上的内容不小心写到PPT里。在操作系统的进程通信中，消息队列（消息信箱）都是操作系统维护的，你不必关心。 第二种的优点是通过消息通知，切换问题省心了，不过消息是不能立即处理的（基于消息通知机制，这个总是难免的），而且所有的内容都通过消息发送，比如PPT的格式、内容等等信息，这无疑增加了通信开销。\n2.3 消息通知+同步层 有个折中机制可以减少消息通信的开销，就是提取一个同步层，还拿上面的例子来说，你把工作安排都存放在一个工作队列中，而且你能够保证“任何人把新任务扔到这个队列”，“自己取出当前第一个任务”等这些操作都能够保证不会把队列搞乱（其实就是个加锁的队列容器）。 再来看看处理过程和上面有什么不同： 1 当时你正在写文档； 2 你的头找到了一个任务，要指派给你，帮他搞个PPT； 2 头有个PPT要你搞定，他把任务push到你的工作队列中，包括了PPT的格式、内容等信息； 3 头发个消息（一个字节）到你信箱，有个PPT要帮他搞定，这时你并不鸟他； 4 你写好文档，发现有新消息（这预示着有新任务来了），检查工作队列知道头有个PPT要你搞定，你开始搞PPT； … 工作队列其实就是一个加锁的容器（队列、链表等等），这个很容易实现实现；而消息通知仅需要一个字节，具体的任务都push到了在工作队列中，因此想比2.2减少了不少通信开销。 多线程编程有很多陷阱，线程间资源的同步互斥不是一两句能说得清的，而且出现bug很难跟踪调试；这也有很多的经验和教训，因此如果让我选择，在绝大多数情况下都会选择机制3作为实现多线程的方法。\n3. 例子——memcached Memcached中的网络部分就是基于libevent完成的，其中的多线程模型就是典型的消息通知+同步层机制。下面的图足够说明其多线程模型了，其中有详细的文字说明。\n注：该图的具体出处忘记了，感谢原作者。\n4. 小节 本节更是libevent的使用方面的技巧，讨论了一下如何让libevent支持多线程，以及几种支持多线程的机制，和memcached使用libevent的多线程模型。\n","permalink":"https://haokiu.com/blog/1f455bc4e89944fe8fb0ca8f3bbcdc1b/","summary":"libevent源码深度剖析12 让libevent支持多线程\nlibevent本身不是多线程安全的，在多核的时代，如何能充分利用CPU的能力呢，这一节来说说如何在多线程环境中使用libevent，跟源代码并没有太大的关系，纯粹是使用上的技巧。\n1. 错误使用示例 在多核的CPU上只使用一个线程始终是对不起CPU的处理能力啊，那好吧，那就多创建几个线程，比如下面的简单服务器场景。 1 主线程创建工作线程1； 2 接着主线程监听在端口上，等待新的连接； 3 在线程1中执行event事件循环，等待事件到来； 4 新连接到来，主线程调用libevent接口event_add将新连接注册到libevent上； … … 上面的逻辑看起来没什么错误，在很多服务器设计中都可能用到主线程和工作线程的模式…. 可是就在线程1注册事件时，主线程很可能也在操作事件，比如删除，修改，通过libevent的源代码也能看到，没有同步保护机制，问题麻烦了，看起来不能这样做啊，难道只能使用单线程不成！？\n2. 支持多线程的几种模式 libevent并不是线程安全的，但这不代表libevent不支持多线程模式，其实方法在前面已经将signal事件处理时就接触到了，那就是消息通知机制。 一句话，“你发消息通知我，然后再由我在合适的时间来处理”； 说到这就再多说几句，再打个比方，把你自己比作一个工作线程，而你的头是主线程，你有一个消息信箱来接收别人发给你的消息，当时头有个新任务要指派给你。\n2.1 暴力抢占 那么第一节中使用的多线程方法相当下面的流程： 1 当时你正在做事，比如在写文档； 2 你的头找到了一个任务，要指派给你，比如帮他搞个PPT，哈； 3 头命令你马上搞PPT，你这是不得不停止手头的工作，把PPT搞定了再接着写文档； …\n2.2 纯粹的消息通知机制 那么基于纯粹的消息通知机制的多线程方式就像下面这样： 1 当时你正在写文档； 2 你的头找到了一个任务，要指派给你，帮他搞个PPT； 3 头发个消息到你信箱，有个PPT要帮他搞定，这时你并不鸟他； 4 你写好文档，接着检查消息发现头有个PPT要你搞定，你开始搞PPT； … 第一种的好处是消息可以立即得到处理，但是很方法很粗暴，你必须立即处理这个消息，所以你必须处理好切换问题，省得把文档上的内容不小心写到PPT里。在操作系统的进程通信中，消息队列（消息信箱）都是操作系统维护的，你不必关心。 第二种的优点是通过消息通知，切换问题省心了，不过消息是不能立即处理的（基于消息通知机制，这个总是难免的），而且所有的内容都通过消息发送，比如PPT的格式、内容等等信息，这无疑增加了通信开销。\n2.3 消息通知+同步层 有个折中机制可以减少消息通信的开销，就是提取一个同步层，还拿上面的例子来说，你把工作安排都存放在一个工作队列中，而且你能够保证“任何人把新任务扔到这个队列”，“自己取出当前第一个任务”等这些操作都能够保证不会把队列搞乱（其实就是个加锁的队列容器）。 再来看看处理过程和上面有什么不同： 1 当时你正在写文档； 2 你的头找到了一个任务，要指派给你，帮他搞个PPT； 2 头有个PPT要你搞定，他把任务push到你的工作队列中，包括了PPT的格式、内容等信息； 3 头发个消息（一个字节）到你信箱，有个PPT要帮他搞定，这时你并不鸟他； 4 你写好文档，发现有新消息（这预示着有新任务来了），检查工作队列知道头有个PPT要你搞定，你开始搞PPT； … 工作队列其实就是一个加锁的容器（队列、链表等等），这个很容易实现实现；而消息通知仅需要一个字节，具体的任务都push到了在工作队列中，因此想比2.2减少了不少通信开销。 多线程编程有很多陷阱，线程间资源的同步互斥不是一两句能说得清的，而且出现bug很难跟踪调试；这也有很多的经验和教训，因此如果让我选择，在绝大多数情况下都会选择机制3作为实现多线程的方法。\n3. 例子——memcached Memcached中的网络部分就是基于libevent完成的，其中的多线程模型就是典型的消息通知+同步层机制。下面的图足够说明其多线程模型了，其中有详细的文字说明。\n注：该图的具体出处忘记了，感谢原作者。\n4. 小节 本节更是libevent的使用方面的技巧，讨论了一下如何让libevent支持多线程，以及几种支持多线程的机制，和memcached使用libevent的多线程模型。","title":"libevent源码深度剖析12"},{"content":"libevent源码深度剖析13 libevent信号处理注意点\n前面讲到了 libevent 实现多线程的方法，然而在多线程的环境中注册信号事件，还是有一些情况需要小心处理，那就是不能在多个 libevent 实例上注册信号事件。依然冠名追加到 libevent 系列。\n以 2 个线程为例，做简单的场景分析。\n1 首先是创建并初始化线程 1 的 libevent 实例 base1 ，线程 1 的 libevent 实例 base2 ；\n2 在 base1 上注册 SIGALRM 信号；在 base2 上注册 SIGINT 信号；\n3 假设当前 base1 和 base2 上都没有注册其他的事件；\n4 线程 1 和 2 都进入 event_base_loop 事件循环：\n5 假设线程 1 先进入 event_base_loop ，并设置 evsignal_base = base1 ；并等待；\n6 接着线程 2 也进入 event_base_loop ，并设置 evsignal_base = base2 ；并等待；\n于是 evsignal_base 就指向了 base2 ；\n7 信号 ALARM 触发，调用服务例程：\nstatic void evsignal_handler(int sig){ ... evsignal_base-\u0026gt;sig.evsigcaught[sig]++; evsignal_base-\u0026gt;sig.evsignal_caught = 1; /* Wake up our notification mechanism */ send(evsignal_base-\u0026gt;sig.ev_signal_pair[0], \u0026#34;a\u0026#34;, 1, 0); ... } 于是 base2 得到通知 ALARM 信号发生了，而实际上 ALARM 是注册在 base1 上的， base2 上的 ALARM 注册 event 是空的，于是处理函数将不能得到调用；因此在 libevent 中，如果需要处理信号，只能将信号注册到一个 libevent 实例上。\nmemcached 就没有使用 libevent 提供的 signal 接口，而是直接使用系统提供的原生 API ，看起来这样更简洁。\nlibevent源码深度剖析全系列完。\n","permalink":"https://haokiu.com/blog/b05b12b227ee4ce494fe99d9116d6a23/","summary":"libevent源码深度剖析13 libevent信号处理注意点\n前面讲到了 libevent 实现多线程的方法，然而在多线程的环境中注册信号事件，还是有一些情况需要小心处理，那就是不能在多个 libevent 实例上注册信号事件。依然冠名追加到 libevent 系列。\n以 2 个线程为例，做简单的场景分析。\n1 首先是创建并初始化线程 1 的 libevent 实例 base1 ，线程 1 的 libevent 实例 base2 ；\n2 在 base1 上注册 SIGALRM 信号；在 base2 上注册 SIGINT 信号；\n3 假设当前 base1 和 base2 上都没有注册其他的事件；\n4 线程 1 和 2 都进入 event_base_loop 事件循环：\n5 假设线程 1 先进入 event_base_loop ，并设置 evsignal_base = base1 ；并等待；\n6 接着线程 2 也进入 event_base_loop ，并设置 evsignal_base = base2 ；并等待；\n于是 evsignal_base 就指向了 base2 ；\n7 信号 ALARM 触发，调用服务例程：\nstatic void evsignal_handler(int sig){ ... evsignal_base-\u0026gt;sig.evsigcaught[sig]++; evsignal_base-\u0026gt;sig.evsignal_caught = 1; /* Wake up our notification mechanism */ send(evsignal_base-\u0026gt;sig.ev_signal_pair[0], \u0026#34;a\u0026#34;, 1, 0); ... } 于是 base2 得到通知 ALARM 信号发生了，而实际上 ALARM 是注册在 base1 上的， base2 上的 ALARM 注册 event 是空的，于是处理函数将不能得到调用；因此在 libevent 中，如果需要处理信号，只能将信号注册到一个 libevent 实例上。","title":"libevent源码深度剖析13"},{"content":"libevent源码深度剖析一 1. 前言 libevent是一个轻量级的开源高性能网络库，使用者众多，研究者更甚，相关文章也不少。写这一系列文章的用意在于，一则分享心得；二则对libevent代码和设计思想做系统的、更深层次的分析，写出来，也可供后来者参考。\n附带一句：libevent是用c语言编写的（大牛们都偏爱c语言哪），而且几乎是无处不函数指针，学习其源代码也需要相当的c语言基础。\n2. Libevent简介 上来当然要先夸奖啦，libevent 有几个显著的亮点： 事件驱动（event-driven），高性能; 轻量级，专注于网络，不如ACE那么臃肿庞大； 源代码相当精炼、易读； 跨平台，支持Windows、Linux、BSD和Mac Os； 支持多种I/O多路复用技术， epoll、poll、dev/poll、select和kqueue等； 支持I/O，定时器和信号等事件； 注册事件优先级；\nlibevent已经被广泛的应用，作为底层的网络库；比如memcached、Vomit、Nylon、Netchat等等。 libevent当前的最新稳定版是1.4.13；这也是本文参照的版本。\n3. 学习的好处 学习libevent有助于提升程序设计功力，除了网络程序设计方面外，libevent的代码里有很多有用的设计技巧和基础数据结构，比如信息隐藏、函数指针、c语言的多态支持、链表和堆等等，都有助于提升自身的程序功力。 程序设计不止要了解框架，很多细节之处恰恰也是事关整个系统成败的关键。只对libevent本身的框架大概了解，那或许仅仅是一知半解，不深入代码分析，就难以了解其设计的精巧之处，也就难以为自己所用。\n事实上libevent本身就是一个典型的Reactor模型，理解Reactor模式是理解libevent的基石；因此下一节将介绍典型的事件驱动设计模式——Reactor模式。\n参考资料： libevent官方地址: http://monkey.org/~provos/libevent/\n","permalink":"https://haokiu.com/blog/8aa77e3ff7e54bdb8899e32f75300864/","summary":"libevent源码深度剖析一 1. 前言 libevent是一个轻量级的开源高性能网络库，使用者众多，研究者更甚，相关文章也不少。写这一系列文章的用意在于，一则分享心得；二则对libevent代码和设计思想做系统的、更深层次的分析，写出来，也可供后来者参考。\n附带一句：libevent是用c语言编写的（大牛们都偏爱c语言哪），而且几乎是无处不函数指针，学习其源代码也需要相当的c语言基础。\n2. Libevent简介 上来当然要先夸奖啦，libevent 有几个显著的亮点： 事件驱动（event-driven），高性能; 轻量级，专注于网络，不如ACE那么臃肿庞大； 源代码相当精炼、易读； 跨平台，支持Windows、Linux、BSD和Mac Os； 支持多种I/O多路复用技术， epoll、poll、dev/poll、select和kqueue等； 支持I/O，定时器和信号等事件； 注册事件优先级；\nlibevent已经被广泛的应用，作为底层的网络库；比如memcached、Vomit、Nylon、Netchat等等。 libevent当前的最新稳定版是1.4.13；这也是本文参照的版本。\n3. 学习的好处 学习libevent有助于提升程序设计功力，除了网络程序设计方面外，libevent的代码里有很多有用的设计技巧和基础数据结构，比如信息隐藏、函数指针、c语言的多态支持、链表和堆等等，都有助于提升自身的程序功力。 程序设计不止要了解框架，很多细节之处恰恰也是事关整个系统成败的关键。只对libevent本身的框架大概了解，那或许仅仅是一知半解，不深入代码分析，就难以了解其设计的精巧之处，也就难以为自己所用。\n事实上libevent本身就是一个典型的Reactor模型，理解Reactor模式是理解libevent的基石；因此下一节将介绍典型的事件驱动设计模式——Reactor模式。\n参考资料： libevent官方地址: http://monkey.org/~provos/libevent/","title":"libevent源码深度剖析一"},{"content":"Linux C/C++后端开发面试问哪些问题 今天我的技术群（想加技术群的可以加我微信 easy_coder）里面一名叫“成都-go-戒炸鸡”的群友提出了他最近面试的一些面试题，面试题内容个人觉得非常典型、也非常有代表性和针对性，故拿出来与大家分享一下，也感谢他的分享。成都-go-戒炸鸡说：\n“今天面试，我没答出来的有redis持久化机制，redis销毁方式机制，mq实现原理，c++虚函数，hash冲突的解决，memcached一致性哈希，socket函数select的缺陷，epoll模型，同步互斥，异步非阻塞，回调的概念，innodb索引原理，单向图最短路径，动态规划算法。”\n为了避免问题有歧义，面试题略有修改。\n思路分析 从面试题的内容可以看出，这是一个后台开发的职位。\n除了关于 c++ 虚函数这个问题以外，其他的大多数问题都与哪种编程语言关系不大，大多数是原理性和基础性的问题，少数是工作经验问题，笔者试着给大家分析。\n语言基础 C++ 虚函数这是面试初、中级 C ++ 职位一个概率95%以上的面试题。一般有以下几种问法：\n在有继承关系的父子类中，构建和析构一个子类对象时，父子构造函数和析构函数的执行顺序分别是怎样的？ 在有继承关系的类体系中，父类的构造函数和析构函数一定要申明为 virtual 吗？如果不申明为 virtual 会怎样？ 什么是 C++ 多态？C++ 多态的实现原理是什么？ 什么是虚函数？虚函数的实现原理是什么？ 什么是虚表？虚表的内存结构布局如何？虚表的第一项（或第二项）是什么？ 菱形继承（类D同时继承B和C，B和C又继承自A）体系下，虚表在各个类中的布局如何？如果类B和类C同时有一个成员变了m，m如何在D对象的内存地址上分布的？是否会相互覆盖？ 算法与数据结构基础 说到算法和数据结构，对于社招人士和对于应届生一般是不一样的，对于大的互联网公司和一般的小的企业也是不一样的。下面根据我当面试官面试别人和找工作被别人面试经验来谈一谈。\n先说考察的内容，除了一些特殊的岗位，常见的算法和数据结构面试问题有如下：\n排序（常考的排序按频率考排序为：快速排序 \u0026gt; 冒泡排序 \u0026gt; 归并排序 \u0026gt; 桶排序） 一般对于对算法基础有要求的公司，如果你是应届生或者工作经验在一至三年内，以上算法如果写不出来，给面试官的影响会非常不好，甚至直接被 pass 掉。对于工作三年以上的社会人士，如果写不出来，但是能分析出其算法复杂度、最好和最坏的情况下的复杂度，说出算法大致原理，在多数面试官面前也可以过的。注意，如果你是学生，写不出来或者写的不对，基本上面试过不了。\n二分查找\n二分查找的算法尽量要求写出来。当然，大多数面试官并不会直接问你二分查找，而是结合具体的场景，例如如何求一个数的平方根，这个时候你要能想到是二分查找。我在2017年年底，面试agora时，面试官问了一个问题：如何从所有很多的ip地址中快速找个某个ip地址。\n链表\n无论是应届生还是工作年限不长的社会人士，琏表常见的操作一定要熟练写出来，如链表的查找、定位、反转、连接等等。还有一些经典的问题也经常被问到，如两个链表如何判断有环（我在2017年面试饿了么二面、上海黄金交易所一面被问过）。链表的问题一般不难，但是链表的问题存在非常多的“坑”，如很多人不注意边界检查、空链表、返回一个链表的函数应该返回链表的头指针等等。\n队列与栈\n对于应届生来说一般这一类问的比较少，但是对于社会人士尤其是中高级岗位开发，会结合相关的问题问的比较多，例如让面试者利用队列写一个多线程下的生产者和消费者程序，全面考察的多线程的资源同步与竞态问题（下文介绍多线程面试题时详细地介绍）。\n栈一般对于基础要求高的面试，会结合函数调用实现来问。即函数如何实现的，包括函数的调用的几种常见调用方式、参数的入栈顺序、内存栈在地址从高向低扩展、栈帧指针和栈顶指针的位置、函数内局部变量在栈中的内存分布、函数调用结束后，调用者和被调用者谁和如何清理栈等等。某年面试京东一基础部门，面试官让写从0加到100这样一个求和算法，然后写其汇编代码。\n哈希表\n哈希表是考察最多的数据结构之一。常见的问题有哈希冲突的检测、让面试者写一个哈希插入函数等等。基本上一场面试下来不考察红黑树基本上就会问哈希表，而且问题可浅可深。我印象比较深刻的是，当年面试百度广告推荐部门时，二面问的一些关于哈希表的问题。当时面试官时先问的链表，接着问的哈希冲突的解决方案，后来让写一个哈希插入算法，这里需要注意的是，你的算法中插入的元素一定要是通用元素，所以对于 C++ 或者 Java 语言，一定要使用模板这一类参数作为哈希插入算法的对象。然后，就是哈希表中多个元素冲突时，某个位置的元素使用链表往后穿成一串的方案。最终考察 linux 下 malloc（下面的ptmalloc） 函数在频繁调用造成的内存碎片问题，以及开源方案解决方案 tcmalloc 和 jemalloc。总体下来，面试官是一步步引导你深入。（有兴趣的读者可以自行搜索，网上有很多相关资料）\n树\n面试高频的树是红黑树，也有一部分是B树（B+树）。\n红黑树一般的问的深浅不一，大多数面试官只要能说出红黑树的概念、左旋右旋的方式、分析出查找和插入的平均算法复杂度和最好最坏时的算法复杂度，并不要写面试者写出具体代码实现。一般 C++ 面试问 stl 的map，java 面试问 TreeMap 基本上就等于开始问你红黑树了，要有心里准备。笔者曾经面试爱奇艺被问过红黑树。\nB树一般不会直接问，问的最多的形式是通过问 MySQL 索引实现原理（数据库知识点将在下文中讨论）。笔者面试腾讯看点部门二面被问到过。\n图\n图的问题就我个人面试从来没遇到过，不过据我某位哥哥所说，他在进三星电子之前有一道面试题就是深度优先和广度优先问题。\n其他的一些算法\n如A*寻路、霍夫曼编码也偶尔会在某一个领域的公司的面试中被问到，如宝开（《植物大战僵尸》的母公司， 在上海人民广场附近有分公司）。\n编码基本功 还有一类面试题不好分类，笔者姑且将其当作是考察编码基本功，这类问题既可以考察算法也可以考察你写代码基本素养，这些素养不仅包括编码风格、计算机英语水平、调试能力等，还包括你对细节的掌握和易错点理解，如有意识地对边界条件的检查和非法值的过滤。请读者看以下的代码执行结果是什么？（笔者2011年去北京中关村的鼎普面试的问题）\nfor(char i = 0; i \u0026lt; 256; ++i) { printf(\u0026#34;%d\\n\u0026#34;, i); } 下面再列举几个常见的编码题：\n实现一个 memmov 函数\n这个题目考查点在于 memmov 函数与 memcpy 函数的区别，这两者对于源地址与目标地址内存有重叠的这一情况的处理方式是不一样的。\n实现strcpy或strcpy函数\n这个函数写出来没啥难度，但是除了边界条件需要检查以外，还有一个容易被忽视的地方即其返回值一定要是目标内存地址，以支持所谓的链式拷贝。即：\nstrcpy(dest3, strcpy(dest2, strcpy(dest1, src1))); 实现atoi函数\n这个函数的签名如下：\nint atoi(const char* p); 容易疏忽的地方有如下几点：\n小数点问题，如数字0.123和.123都是合法的；\n正负号问题，如+123和-123；\n考虑如何识别第一个非法字符问题，如123Z89，则应转换成应该123。\n我在面试掌门科技（无线万能钥匙那一家）就遇到过这样的问题。\n多线程开发基础 现如今的多核CPU早已经是司空见惯，而多线程编程早已经是“飞入寻常百姓家”。对于大多数桌面应用（与 Web 开发相对），尤其是像后台开发这样的岗位，且面试者是社会人员（有一定的工作经验），如果面试者不熟悉多线程编程，那么一般会被直接 pass 掉。\n这里说的“熟悉多线程编程”到底熟悉到什么程度呢？一般包括：知道何种场合下需要新建新的线程、线程如何创建和等待、线程与进程的关系、线程局部存储（TLS 或者叫 thread local）、多线程访问资源产生竞态的原因和解决方案等等、熟练使用所在操作系统平台提供的线程同步的各种原语。\n对于 C++ 开发者，你需要：\n对于 Windows 开发者，你需要熟练使用 Interlock系列函数、CriticalSection、Event、Mutex、Semphore等API 函数和两个重要的函数 WaitForSingleObject、WaitForMultipleObjects。 对于linux 开发者，你需要熟练使用 mutex、semphore、condition_variable、read-write-lock 等操作系统API。 对于 Java，你需要熟悉使用 synchronized关键字、CountDownLatch、CyclicBarrier、Semaphore以及java.util.concurrent 等包中的大多数线程同步对象。\n数据库 数据库知识一般在大的互联网企业对应届生不做硬性要求，对于小的互联网企业或社会人士一般有一定的要求。其要求一般包括：\n熟悉基本 SQL 操作\n包括增删改查（insert、delete、update、select语句），排序 order，条件查询（where 子语句），限制查询结果数量（LIMIT语句）等\n稍微高级一点的 SQL 操作（如Group by，in，join，left join，多表联合查询，别名的使用，select 子语句等）\n索引的概念、索引的原理、索引的创建技巧\n数据库本身的操作，建库建表，数据的导入导出\n数据库用户权限控制（权限机制）\nMySQL的两种数据库引擎的区别\nSQL 优化技巧\n网络编程 网络编程这一块，对于应届生或者初级岗位一般只会问一些基础网络通信原理（如三次握手和四次挥手）的socket 基础 API 的使用，客户端与服务器端网络通信的流程（回答 【客户端创建socket -\u0026gt; 连接server -\u0026gt;收发数据；服务器端创建socket -\u0026gt; 绑定ip和端口号 -\u0026gt; 启动侦听 -\u0026gt;接受客户端连接 -\u0026gt;与客户端通信收发数据】即可）、TCP 与 UDP的区别等等。\n对于工作经验三年以内的社会人士或者一些中级面试者一般会问一些稍微重难点问题，如 select 函数的用法，非阻塞 connect 函数的写法，epoll 的水平和边缘模式、阻塞socket与非阻塞socket的区别、send/recv函数的返回值情形、reuse_addr选项等等。Windows 平台可能还会问 WSAEventSelect 和 WSAAsyncSelect 函数的用法、完成端口（IOCP模型）。\n对于三年以上尤其是“号称”自己设计过服务器、看过开源网络通信库代码的面试者，面试官一般会深入问一些问题，这类问题要么是实际项目中常见的难题或者网络通信细节，根据我的经验，一般有这样一些问题：\nnagle算法； keepalive选项； Linger选项； 对于某一端出现大量CLOSE_WAIT 或者 TIME_WAIT如何解决； 通讯协议如何设计或如何解决数据包的粘包与分片问题； 心跳机制如何设计；（可能不会直接问问题本身，如问如何检查死链） 断线重连机制如何设计； 对 IO Multiplexing 技术的理解； 收发数据包正确的方式，收发缓冲区如何设计； 优雅关闭； 定时器如何设计； epoll 的实现原理。 举个例子，让读者感受一下，笔者曾去BiliBili被问过这样一个问题：如果A机器与B机器网络 connect 成功后从未互发过数据，此时其中一机器突然断电，则另外一台机器与断电的机器之间的网络连接处于哪种状态？\n内存数据库技术 时下以NoSql key-value为思想的内存数据库大行其道，广泛地用于各种后台项目开发。所以熟悉一种或几种内存数据库程序已经是面试后台开发的基本要求，而这当中以 redis 和 memcached 为最典型代表，这里以 redis 为例。\n第一层面一般是对 redis 的基础用法的考察\n如考察 redis 支持的基础数据类型、redis的数据持久化、事务等。\n第二层面不仅考察 redis 的基础用法，还会深入到 redis 源码层面上，如 redis 的网络通信模型、redis 各种数据结构的实现等等。\n笔者以为，无论是从找工作应付面试还是从提高技术的角度，redis 是一个非常值得学习的开源软件，希望广大读者有意识地去了解、学习它。\n项目经验 除了社会招聘和一些小型的企业，一般的大型互联网公司对应届生不会做过多的项目经验要求，而是希望他们算法与数据结构等基础扎实、动手实践能力强即可。对于一般的小公司，对于应届生会要求其至少熟练使用一门编程语言以及相应的开发工具，号称熟悉linux C++ 开发的面试者，不熟悉 GDB 调试基本上不是真正的熟悉 linux C++ 开发；号称熟悉汇编或者反汇编，不熟悉 IDA 或者 OllyDbg，基本上也是名不符实的；号称熟悉 VC++ 开发，连F8、F9、F10、F11、F12等快捷键不熟悉也是难以经得住面试官的提问的；号称熟悉 Java 开发的却对 IDEA 或 eclipse 陌生，这也是说不过去的。\n这里给一些学历不算好，学校不是非常有名，尤其是二本以下的广大想进入 IT 行业的同学一个建议，在大学期间除了要学好计算机专业基础知识以外，一定要熟练使用一门编程语言以及相应的开发工具。\n关于项目经验，许多面试者认为一定要是自己参与的项目，其实也可以来源于你学习和阅读他人源码或开源软件的源码，如果你能理解并掌握这些开源软件中的思想和技术，在面试的时候能够与面试官侃侃而谈，面试官也会非常满意的。笔者的一个学弟前段时间告诉我，他看懂了我公众号【easyserverdev】中《服务器开发基础系列和进阶》的文章后，成功拿到了网易的offer ，有兴趣的读者可以好好看一下。\n很多同学可能纠结大学或者研究生期间要不要跟着导师做一些项目。当然，如果这些项目是课程要求，那么你必须得参加；如果这些项目是可以选择性的，尤其是一些仅仅拿着第三方的库进行所谓的包装和加工，那么建议可以少参加一些。\n思路总结 不知道通过我上面的技术分析，聪明的读者是否已经明确本文开头“成都-go-戒炸鸡”同学提出的面试题中，哪些是技术面试重难点，哪些又是技术开发的重难点呢？\n技术比重与薪资 这里根据我自己招人的经验来谈一谈技术水平与薪资，就上面的面试题来看：\n第一层次：如果面试者能答出上面面试题中的C++基础问题和算法与数据结构题目（如 C++ 函数与hash冲突的解决、innodb索引原理，单向图最短路径，动态规划算法等），可以认为面试者是一个合格的初、中级开发者，薪资范围一般在6 ～ 12k（注意：这里以我所在的上海为参考标准）。\n第二层次：在第一层次基础之上，如果面试者还能答出上述面试题中网络编程相关的或者多线程相关的问题（如socket函数select的缺陷，epoll模型，同步互斥，异步非阻塞，回调的概念等），可以认为面试者是个基础不错的中级开发者，薪资范围一般在14～22k之间。\n第三层次：在前两个层次之间，如果面试者还能回答出上述问题中关于redis、memcached和mq实现原理，说明面试者是一个有着不错项目经验并且对一些常用开源项目也有一定的理解，薪资可以给到22k +。\n总结 工资收入是每个人的秘密，一般不轻易对外人道也。这里笔者冒天下之大不韪，只想说明一点——对于普通开发人员，提高薪资最好的捷径就是提高自己的技术，无论是“面向搜索引擎编程”还是“面向工资编程”终将得不偿失，聪明的你一定会深谋远虑的。\n","permalink":"https://haokiu.com/blog/8570010b5d82422da83500ab481816be/","summary":"Linux C/C++后端开发面试问哪些问题 今天我的技术群（想加技术群的可以加我微信 easy_coder）里面一名叫“成都-go-戒炸鸡”的群友提出了他最近面试的一些面试题，面试题内容个人觉得非常典型、也非常有代表性和针对性，故拿出来与大家分享一下，也感谢他的分享。成都-go-戒炸鸡说：\n“今天面试，我没答出来的有redis持久化机制，redis销毁方式机制，mq实现原理，c++虚函数，hash冲突的解决，memcached一致性哈希，socket函数select的缺陷，epoll模型，同步互斥，异步非阻塞，回调的概念，innodb索引原理，单向图最短路径，动态规划算法。”\n为了避免问题有歧义，面试题略有修改。\n思路分析 从面试题的内容可以看出，这是一个后台开发的职位。\n除了关于 c++ 虚函数这个问题以外，其他的大多数问题都与哪种编程语言关系不大，大多数是原理性和基础性的问题，少数是工作经验问题，笔者试着给大家分析。\n语言基础 C++ 虚函数这是面试初、中级 C ++ 职位一个概率95%以上的面试题。一般有以下几种问法：\n在有继承关系的父子类中，构建和析构一个子类对象时，父子构造函数和析构函数的执行顺序分别是怎样的？ 在有继承关系的类体系中，父类的构造函数和析构函数一定要申明为 virtual 吗？如果不申明为 virtual 会怎样？ 什么是 C++ 多态？C++ 多态的实现原理是什么？ 什么是虚函数？虚函数的实现原理是什么？ 什么是虚表？虚表的内存结构布局如何？虚表的第一项（或第二项）是什么？ 菱形继承（类D同时继承B和C，B和C又继承自A）体系下，虚表在各个类中的布局如何？如果类B和类C同时有一个成员变了m，m如何在D对象的内存地址上分布的？是否会相互覆盖？ 算法与数据结构基础 说到算法和数据结构，对于社招人士和对于应届生一般是不一样的，对于大的互联网公司和一般的小的企业也是不一样的。下面根据我当面试官面试别人和找工作被别人面试经验来谈一谈。\n先说考察的内容，除了一些特殊的岗位，常见的算法和数据结构面试问题有如下：\n排序（常考的排序按频率考排序为：快速排序 \u0026gt; 冒泡排序 \u0026gt; 归并排序 \u0026gt; 桶排序） 一般对于对算法基础有要求的公司，如果你是应届生或者工作经验在一至三年内，以上算法如果写不出来，给面试官的影响会非常不好，甚至直接被 pass 掉。对于工作三年以上的社会人士，如果写不出来，但是能分析出其算法复杂度、最好和最坏的情况下的复杂度，说出算法大致原理，在多数面试官面前也可以过的。注意，如果你是学生，写不出来或者写的不对，基本上面试过不了。\n二分查找\n二分查找的算法尽量要求写出来。当然，大多数面试官并不会直接问你二分查找，而是结合具体的场景，例如如何求一个数的平方根，这个时候你要能想到是二分查找。我在2017年年底，面试agora时，面试官问了一个问题：如何从所有很多的ip地址中快速找个某个ip地址。\n链表\n无论是应届生还是工作年限不长的社会人士，琏表常见的操作一定要熟练写出来，如链表的查找、定位、反转、连接等等。还有一些经典的问题也经常被问到，如两个链表如何判断有环（我在2017年面试饿了么二面、上海黄金交易所一面被问过）。链表的问题一般不难，但是链表的问题存在非常多的“坑”，如很多人不注意边界检查、空链表、返回一个链表的函数应该返回链表的头指针等等。\n队列与栈\n对于应届生来说一般这一类问的比较少，但是对于社会人士尤其是中高级岗位开发，会结合相关的问题问的比较多，例如让面试者利用队列写一个多线程下的生产者和消费者程序，全面考察的多线程的资源同步与竞态问题（下文介绍多线程面试题时详细地介绍）。\n栈一般对于基础要求高的面试，会结合函数调用实现来问。即函数如何实现的，包括函数的调用的几种常见调用方式、参数的入栈顺序、内存栈在地址从高向低扩展、栈帧指针和栈顶指针的位置、函数内局部变量在栈中的内存分布、函数调用结束后，调用者和被调用者谁和如何清理栈等等。某年面试京东一基础部门，面试官让写从0加到100这样一个求和算法，然后写其汇编代码。\n哈希表\n哈希表是考察最多的数据结构之一。常见的问题有哈希冲突的检测、让面试者写一个哈希插入函数等等。基本上一场面试下来不考察红黑树基本上就会问哈希表，而且问题可浅可深。我印象比较深刻的是，当年面试百度广告推荐部门时，二面问的一些关于哈希表的问题。当时面试官时先问的链表，接着问的哈希冲突的解决方案，后来让写一个哈希插入算法，这里需要注意的是，你的算法中插入的元素一定要是通用元素，所以对于 C++ 或者 Java 语言，一定要使用模板这一类参数作为哈希插入算法的对象。然后，就是哈希表中多个元素冲突时，某个位置的元素使用链表往后穿成一串的方案。最终考察 linux 下 malloc（下面的ptmalloc） 函数在频繁调用造成的内存碎片问题，以及开源方案解决方案 tcmalloc 和 jemalloc。总体下来，面试官是一步步引导你深入。（有兴趣的读者可以自行搜索，网上有很多相关资料）\n树\n面试高频的树是红黑树，也有一部分是B树（B+树）。\n红黑树一般的问的深浅不一，大多数面试官只要能说出红黑树的概念、左旋右旋的方式、分析出查找和插入的平均算法复杂度和最好最坏时的算法复杂度，并不要写面试者写出具体代码实现。一般 C++ 面试问 stl 的map，java 面试问 TreeMap 基本上就等于开始问你红黑树了，要有心里准备。笔者曾经面试爱奇艺被问过红黑树。\nB树一般不会直接问，问的最多的形式是通过问 MySQL 索引实现原理（数据库知识点将在下文中讨论）。笔者面试腾讯看点部门二面被问到过。\n图\n图的问题就我个人面试从来没遇到过，不过据我某位哥哥所说，他在进三星电子之前有一道面试题就是深度优先和广度优先问题。\n其他的一些算法\n如A*寻路、霍夫曼编码也偶尔会在某一个领域的公司的面试中被问到，如宝开（《植物大战僵尸》的母公司， 在上海人民广场附近有分公司）。\n编码基本功 还有一类面试题不好分类，笔者姑且将其当作是考察编码基本功，这类问题既可以考察算法也可以考察你写代码基本素养，这些素养不仅包括编码风格、计算机英语水平、调试能力等，还包括你对细节的掌握和易错点理解，如有意识地对边界条件的检查和非法值的过滤。请读者看以下的代码执行结果是什么？（笔者2011年去北京中关村的鼎普面试的问题）\nfor(char i = 0; i \u0026lt; 256; ++i) { printf(\u0026#34;%d\\n\u0026#34;, i); } 下面再列举几个常见的编码题：\n实现一个 memmov 函数\n这个题目考查点在于 memmov 函数与 memcpy 函数的区别，这两者对于源地址与目标地址内存有重叠的这一情况的处理方式是不一样的。","title":"Linux C/C++后端开发面试问哪些问题"},{"content":"Linux epoll 模型（含LT 模式和 ET 模式详解） 综合 select 和 poll 的一些优缺点，Linux 从内核 2.6 版本开始引入了更高效的 epoll 模型，本节我们来详细介绍 epoll 模型。\n要想使用 epoll 模型，必须先需要创建一个 epollfd，这需要使用 epoll_create 函数去创建：\n#include \u0026lt;sys/epoll.h\u0026gt; int epoll_create(int size); 参数 size 从 Linux 2.6.8 以后就不再使用，但是必须设置一个大于 0 的值。epoll_create 函数调用成功返回一个非负值的 epollfd，调用失败返回 -1。\n有了 epollfd 之后，我们需要将我们需要检测事件的其他 fd 绑定到这个 epollfd 上，或者修改一个已经绑定上去的 fd 的事件类型，或者在不需要时将 fd 从 epollfd 上解绑，这都可以使用 epoll_ctl 函数：\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event* event); 参数说明：\n参数 epfd 即上文提到的 epollfd；\n参数 op，操作类型，取值有 EPOLL_CTL_ADD、EPOLL_CTL_MOD 和 EPOLL_CTL_DEL，分别表示向 epollfd 上添加、修改和移除一个其他 fd，当取值是 EPOLL_CTL_DEL，第四个参数 event 忽略不计，可以设置为 NULL；\n参数 fd，即需要被操作的 fd；\n参数 event，这是一个 epoll_event 结构体的地址，epoll_event 结构体定义如下：\nstruct epoll_event { uint32_t events; /* 需要检测的 fd 事件，取值与 poll 函数一样 */ epoll_data_t data; /* 用户自定义数据 */ }; epoll_event 结构体的 data 字段的类型是 epoll_data_t，我们可以利用这个字段设置一个自己的自定义数据，它本质上是一个 Union 对象，在 64 位操作系统中其大小是 8 字节，其定义如下：\ntypedef union epoll_data { void* ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; 函数返回值：epoll_ctl 调用成功返回 0，调用失败返回 -1，你可以通过 errno 错误码获取具体的错误原因。\n创建了 epollfd，设置好某个 fd 上需要检测事件并将该 fd 绑定到 epollfd 上去后，我们就可以调用 epoll_wait 检测事件了，epoll_wait 函数签名如下：\nint epoll_wait(int epfd, struct epoll_event* events, int maxevents, int timeout); 参数的形式和 poll 函数很类似，参数 events 是一个 epoll_event 结构数组的首地址，这是一个输出参数，函数调用成功后，events 中存放的是与就绪事件相关 epoll_event 结构体数组；参数 maxevents 是数组元素的个数；timeout 是超时时间，单位是毫秒，如果设置为 0，epoll_wait 会立即返回。\n当 epoll_wait 调用成功会返回有事件的 fd 数目；如果返回 0 表示超时；调用失败返回 -1。\nepoll_wait 使用示例如下：\nwhile (true) { epoll_event epoll_events[1024]; int n = epoll_wait(epollfd, epoll_events, 1024, 1000); if (n \u0026lt; 0) { //被信号中断 if (errno == EINTR) continue; //出错，退出 break; } else if (n == 0) { //超时，继续 continue; } for (size_t i = 0; i \u0026lt; n; ++i) { // 处理可读事件 if (epoll_events[i].events \u0026amp; POLLIN) { } // 处理可写事件 else if (epoll_events[i].events \u0026amp; POLLOUT) { } //处理出错事件 else if (epoll_events[i].events \u0026amp; POLLERR) { } } } epoll_wait 与 poll 的区别 通过前面介绍 poll 与 epoll_wait 函数的介绍，我们可以发现：\nepoll_wait 函数调用完之后，我们可以直接在 event 参数中拿到所有有事件就绪的 fd，直接处理即可（event 参数仅仅是个出参）；而 poll 函数的事件集合调用前后数量都未改变，只不过调用前我们通过 pollfd 结构体的 events 字段设置待检测事件，调用后我们需要通过 pollfd 结构体的 revents 字段去检测就绪的事件（ 参数 fds 既是入参也是出参）。\n举个生活中的例子，某人不断给你一些苹果，这些苹果有生有熟，调用 epoll_wait 相当于：\n1. 你把苹果挨个投入到 epoll 机器中(调用 epoll_ctl); 2. 调用 epoll_wait 加工，你直接通过另外一个袋子就能拿到所有熟苹果。 调用 poll 相当于：\n1. 把收到的苹果装入一个袋子里面然后调用 poll 加工； 2. 调用结束后，拿到原来的袋子，袋子中还是原来那么多苹果，只不过熟苹果被贴上了标签纸，你还是需要挨个去查看标签纸挑选熟苹果。 当然，这并不意味着，poll 函数的效率不如 epoll_wait，一般在 fd 数量比较多，但某段时间内，就绪事件 fd 数量较少的情况下，epoll_wait 才会体现出它的优势，也就是说 socket 连接数量较大时而活跃连接较少时 epoll 模型更高效。\nLT 模式和 ET 模式 与 poll 的事件宏相比，epoll 新增了一个事件宏 EPOLLET，这就是所谓的边缘触发模式（Edge Trigger，ET），而默认的模式我们称为 水平触发模式（Level Trigger，LT）。这两种模式的区别在于：\n对于水平触发模式，一个事件只要有，就会一直触发； 对于边缘触发模式，只有一个事件从无到有才会触发。 这两个词汇来自电学术语，你可以将 fd 上有数据认为是高电平，没有数据认为是低电平，将 fd 可写认为是高电平，fd 不可写认为是低电平。那么水平模式的触发条件是状态处于高电平，而边缘模式是状态改为高电平，即：\n水平模式的触发条件\n1. 低电平 =\u0026gt; 高电平 2. 高电平 =\u0026gt; 高电平 边缘模式的触发条件\n1. 低电平 =\u0026gt; 高电平 说的有点抽象，以 socket 的读事件为例，对于水平模式，只要 socket 上有未读完的数据，就会一直产生 POLLIN 事件；而对于边缘模式，socket 上第一次有数据会触发一次，后续 socket 上存在数据也不会再触发，除非把数据读完后，再次产生数据才会继续触发。对于 socket 写事件，如果 socket 的 TCP 窗口一直不饱和，会一直触发 POLLOUT 事件；而对于边缘模式，只会触发一次，除非 TCP 窗口由不饱和变成饱和再一次变成不饱和，才会再次触发 POLLOUT 事件。\nsocket 可读事件水平模式触发条件：\n1. socket上无数据 =\u0026gt; socket上有数据 2. socket上有数据 =\u0026gt; socket上有数据 socket 可读事件边缘模式触发条件：\n1. socket上无数据 =\u0026gt; socket上有数据 socket 可写事件水平模式触发条件：\n1. socket可写 =\u0026gt; socket可写 2. socket不可写 =\u0026gt; socket可写 socket 可写事件边缘模式触发条件：\n1. socket不可写 =\u0026gt; socket可写 也就是说，如果对于一个非阻塞 socket，如果使用 epoll 边缘模式去检测数据是否可读，触发可读事件以后，一定要一次性把 socket 上的数据收取干净才行，也就是一定要循环调用 recv 函数直到 recv 出错，错误码是EWOULDBLOCK（EAGAIN 一样）；如果使用水平模式，则不用，你可以根据业务一次性收取固定的字节数，或者收完为止。边缘模式下收取数据的代码示例如下：\nbool TcpSession::RecvEtMode() { //每次只收取256个字节 char buff[256]; while (true) { int nRecv = ::recv(clientfd_, buff, 256, 0); if (nRecv == -1) { if (errno == EWOULDBLOCK) return true; else if (errno == EINTR) continue; return false; } //对端关闭了socket else if (nRecv == 0) return false; inputBuffer_.add(buff, (size_t)nRecv); } return true; } 最后，我们来看一个 epoll 模型的完整例子：\n/** * 演示 epoll 通信模型，epoll_server.cpp * zhangyl 2019.03.16 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; #include \u0026lt;poll.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;errno.h\u0026gt; int main(int argc, char* argv[]) { //创建一个侦听socket int listenfd = socket(AF_INET, SOCK_STREAM, 0); if (listenfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //将侦听socket设置为非阻塞的 int oldSocketFlag = fcntl(listenfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(listenfd, F_SETFL, newSocketFlag) == -1) { close(listenfd); std::cout \u0026lt;\u0026lt; \u0026#34;set listenfd to nonblock error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //初始化服务器地址 struct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); bindaddr.sin_port = htons(3000); if (bind(listenfd, (struct sockaddr *)\u0026amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;bind listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(listenfd); return -1; } //启动侦听 if (listen(listenfd, SOMAXCONN) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;listen error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(listenfd); return -1; } //复用地址和端口号 int on = 1; setsockopt(listenfd, SOL_SOCKET, SO_REUSEADDR, (char *)\u0026amp;on, sizeof(on)); setsockopt(listenfd, SOL_SOCKET, SO_REUSEPORT, (char *)\u0026amp;on, sizeof(on)); //创建epollfd int epollfd = epoll_create(1); if (epollfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create epollfd error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(listenfd); return -1; } epoll_event listen_fd_event; listen_fd_event.events = POLLIN; listen_fd_event.data.fd = listenfd; //将侦听socket绑定到epollfd上去 if(epoll_ctl(epollfd, EPOLL_CTL_ADD, listenfd, \u0026amp;listen_fd_event) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;epoll_ctl error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(listenfd); return -1; } int n; while (true) { epoll_event epoll_events[1024]; n = epoll_wait(epollfd, epoll_events, 1024, 1000); if (n \u0026lt; 0) { //被信号中断 if (errno == EINTR) continue; //出错，退出 break; } else if (n == 0) { //超时，继续 continue; } for (size_t i = 0; i \u0026lt; n; ++i) { // 事件可读 if (epoll_events[i].events \u0026amp; POLLIN) { if (epoll_events[i].data.fd == listenfd) { //侦听socket，接受新连接 struct sockaddr_in clientaddr; socklen_t clientaddrlen = sizeof(clientaddr); //接受客户端连接, 并加入到fds集合中 int clientfd = accept(listenfd, (struct sockaddr *)\u0026amp;clientaddr, \u0026amp;clientaddrlen); if (clientfd != -1) { //将客户端socket设置为非阻塞的 int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(clientfd, F_SETFL, newSocketFlag) == -1) { close(clientfd); std::cout \u0026lt;\u0026lt; \u0026#34;set clientfd to nonblock error.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { epoll_event client_fd_event; client_fd_event.events = POLLIN; client_fd_event.data.fd = clientfd; if(epoll_ctl(epollfd, EPOLL_CTL_ADD, clientfd, \u0026amp;client_fd_event) != -1) { std::cout \u0026lt;\u0026lt; \u0026#34;new client accepted, clientfd: \u0026#34; \u0026lt;\u0026lt; clientfd \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;add client fd to epollfd error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); } } } } else { //普通clientfd,收取数据 char buf[64] = { 0 }; int m = recv(epoll_events[i].data.fd, buf, 64, 0); if (m == 0) { //对端关闭了连接，从epollfd上移除clientfd if(epoll_ctl(epollfd, EPOLL_CTL_DEL, epoll_events[i].data.fd, NULL) != -1) { std::cout \u0026lt;\u0026lt; \u0026#34;client disconnected, clientfd: \u0026#34; \u0026lt;\u0026lt; epoll_events[i].data.fd \u0026lt;\u0026lt; std::endl; } close(epoll_events[i].data.fd); } else if (m \u0026lt; 0) { //出错，从epollfd上移除clientfd if (errno != EWOULDBLOCK \u0026amp;\u0026amp; errno != EINTR) { if(epoll_ctl(epollfd, EPOLL_CTL_DEL, epoll_events[i].data.fd, NULL) != -1) { std::cout \u0026lt;\u0026lt; \u0026#34;client disconnected, clientfd: \u0026#34; \u0026lt;\u0026lt; epoll_events[i].data.fd \u0026lt;\u0026lt; std::endl; } close(epoll_events[i].data.fd); } } else { //正常收到数据 std::cout \u0026lt;\u0026lt; \u0026#34;recv from client: \u0026#34; \u0026lt;\u0026lt; buf \u0026lt;\u0026lt; \u0026#34;, clientfd: \u0026#34; \u0026lt;\u0026lt; epoll_events[i].data.fd \u0026lt;\u0026lt; std::endl; } } } else if (epoll_events[i].events \u0026amp; POLLERR) { //TODO: 暂且不处理 } }// end outer-for-loop }// end while-loop //关闭侦听socket //（理论上应该关闭包括所有clientfd在内的fd，但这里只是为了演示问题，就不写额外的代码来处理啦） close(listenfd); return 0; } 编译上述程序生成 epoll_server 并启动，然后使用 nc 命令启动三个客户端给服务器发数据效果如下图所示：\n","permalink":"https://haokiu.com/blog/e4e0126749ad480399c46665753f03e4/","summary":"Linux epoll 模型（含LT 模式和 ET 模式详解） 综合 select 和 poll 的一些优缺点，Linux 从内核 2.6 版本开始引入了更高效的 epoll 模型，本节我们来详细介绍 epoll 模型。\n要想使用 epoll 模型，必须先需要创建一个 epollfd，这需要使用 epoll_create 函数去创建：\n#include \u0026lt;sys/epoll.h\u0026gt; int epoll_create(int size); 参数 size 从 Linux 2.6.8 以后就不再使用，但是必须设置一个大于 0 的值。epoll_create 函数调用成功返回一个非负值的 epollfd，调用失败返回 -1。\n有了 epollfd 之后，我们需要将我们需要检测事件的其他 fd 绑定到这个 epollfd 上，或者修改一个已经绑定上去的 fd 的事件类型，或者在不需要时将 fd 从 epollfd 上解绑，这都可以使用 epoll_ctl 函数：\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event* event); 参数说明：\n参数 epfd 即上文提到的 epollfd；\n参数 op，操作类型，取值有 EPOLL_CTL_ADD、EPOLL_CTL_MOD 和 EPOLL_CTL_DEL，分别表示向 epollfd 上添加、修改和移除一个其他 fd，当取值是 EPOLL_CTL_DEL，第四个参数 event 忽略不计，可以设置为 NULL；\n参数 fd，即需要被操作的 fd；\n参数 event，这是一个 epoll_event 结构体的地址，epoll_event 结构体定义如下：\nstruct epoll_event { uint32_t events; /* 需要检测的 fd 事件，取值与 poll 函数一样 */ epoll_data_t data; /* 用户自定义数据 */ }; epoll_event 结构体的 data 字段的类型是 epoll_data_t，我们可以利用这个字段设置一个自己的自定义数据，它本质上是一个 Union 对象，在 64 位操作系统中其大小是 8 字节，其定义如下：","title":"Linux epoll 模型（含LT 模式和 ET 模式详解）"},{"content":"Linux tcpdump 使用介绍 tcpdump 是 Linux 系统提供一个非常强大的抓包工具，熟练使用它，对我们排查网络问题非常有用。如果你的机器上还没有安装，可以使用如下命令安装：\nyum install tcpdump 如果要使用 tcpdump 命令必须具有 sudo 权限。\ntcpdump 常用的选项有：\n-i 指定要捕获的目标网卡名，网卡名可以使用前面章节中介绍的 ifconfig 命令获得；如果要抓所有网卡的上的包，可以使用 any 关键字。\n## 抓取网卡ens33上的包 tcpdump -i ens33 ## 抓取所有网卡上的包 tcpdump -i any -X 以 ASCII 和十六进制的形式输出捕获的数据包内容，减去链路层的包头信息；-XX 以 ASCII 和十六进制的形式输出捕获的数据包内容，包括链路层的包头信息。\n-n 不要将 ip 地址显示成别名的形式；-nn 不要将 ip 地址和端口以别名的形式显示。\n-S 以绝对值显示包的 ISN 号（包序列号），默认以上一包的偏移量显示。\n-vv 抓包的信息详细地显示；-vvv 抓包的信息更详细地显示。\n-w 将抓取的包的原始信息（不解析，也不输出）写入文件中，后跟文件名：\ntcpdump -i any -w filename -r 从利用 -w 选项保存的包文件中读取数据包信息。\n除了可以使用选项以外，tcpdump 还支持各种数据包过滤的表达式，常见的形式如下：\n## 仅显示经过端口 8888 上的数据包（包括tcp:8888和udp:8888） tcpdump -i any \u0026#39;port 8888\u0026#39; ## 仅显示经过端口是 tcp:8888 上的数据包 tcpdump -i any \u0026#39;tcp port 8888\u0026#39; ## 仅显示从源端口是 tcp:8888 的数据包 tcpdump -i any \u0026#39;tcp src port 8888\u0026#39; ## 仅显示源端口是 tcp:8888 或目标端口是 udp:9999 的包 tcpdump -i any \u0026#39;tcp src port 8888 or udp dst port 9999\u0026#39; ## 仅显示地址是127.0.0.1 且源端口是 tcp:9999 的包 ，以 ASCII 和十六进制显示详细输出， ## 不显示 ip 地址和端口号的别名 tcpdump -i any \u0026#39;src host 127.0.0.1 and tcp src port 9999\u0026#39; -XX -nn -vv 下面我们通过三个具体的操作实例来演示一下使用 tcpdump 的抓包过程。\n实例一 ：连接一个正常的侦听端口\n假设我的服务器端的地址是 127.0.0.0.1:12345，使用 nc 命令在一个 shell 窗口创建一个服务器程序并在这个地址上进行侦听。\nnc –v -l 127.0.0.0.112345 效果如下图所示：\n在另外一个 shell 窗口开启 tcpdump 抓包：\ntcpdump -i any \u0026#39;port 12345\u0026#39; -XX -nn -vv 效果如下：\n然后再开一个 shell 窗口，利用 nc 命令创建一个客户端去连接服务器：\nnc -v 127.0.0.1 12345 效果如下：\n我们抓到的包如下：\n由于我们没有在客户端和服务器之间发送任何消息，其实抓到的包就是 TCP 连接的三次握手数据包，分析如下：\n三次握手过程是客户端先给服务器发送一个 SYN，然后服务器应答一个 SYN + ACK，应答的序列号是递增 1 的，表示应答哪个请求，即从 4004096087 递增到 4004096088，接着客户端再应答一个 ACK。这个时候，我们发现发包序列号和应答序列号都变成 1了，这是 tcpdump 使用相对序号，我们加上 -S 选项后就变成绝对序列号了。\n我们按 Ctrl + C 中断 tcpdump 抓包过程，并停止用 nc 开启的客户端和服务器程序，然后在前面的 tcpdump 命令后面加上 -S 选项重新开启抓包，使用命令如下：\ntcpdump -i any \u0026#39;port 12345\u0026#39; -XX -nn -vv -S 然后再按顺序用 nc 命令再次启动下服务器和客户端程序。再次得到抓包结果：\n这次得到的包的序号就是绝对序号了。\n实例二：连接一个不存在的侦听端口\n实例一演示的是正常的 TCP 连接三次握手过程捕获到的数据包。假如我们连接的服务器 ip 地址存在，但监听端口号不存在，我们看下 tcpdump 抓包结果。除了在一个 shell 窗口启动一个 tcpdump 抓包监测，在另外一个 shell 窗口用 nc 命令去连接一个不存在的侦听端口即可。\n抓包数据如下：\n这个时候客户端发送 SYN，服务器应答 ACK+RST，这个应答包会导致客户端的 connect 连接失败返回。\n实例三：连接一个很遥远的 ip，或者网络繁忙的情形\n实际情形中，还存在一种情况就是客户端访问一个很遥远的 ip，或者网络繁忙，服务器对客户端发送的 TCP 三次握手的网络 SYN 报文没有应答，会出现什么情况呢？\n我们通过设置防火墙规则来模拟一下这种情况。使用 iptables -F 先将防火墙的已有规则都清理掉，然后给防火墙的 INPUT 链上增加一个规则：丢弃本地网卡 lo（也就是 127.0.0.1 这个回环地址）上的所有 SYN 包。\niptables -F iptables -I INPUT -p tcp --syn -i lo -j DROP 如果读者对 CentOS 的防火墙 iptables 命令有兴趣，可以使用 man iptables 在 man 手册中查看更详细的帮助。\n在开启 tcpdump 抓包之后和设置防火墙规则之后，利用 nc 命令去连接 127.0.0.1:12345 这个地址。整个过程操作效果图如下：\n接着，我们得到 tcpdump 抓到的数据包如下：\n通过抓包数据我们可以看到：如果连接不上，一共重试了 5 次，重试的时间间隔是 1 秒，2秒，4秒，8秒，16秒，最后返回超时失败。这个重试次数在 /proc/sys/net/ipv4/tcp_syn_retries 内核参数中设置，默认为 6 。\nTCP 四次挥手与三次握手基本上类似，这里就不贴出 tcpdump 抓包的详情了，强烈建议不熟悉这块的读者实际练习一遍。\n","permalink":"https://haokiu.com/blog/6eecf1781f7d4e1691c367ebf702d4d2/","summary":"Linux tcpdump 使用介绍 tcpdump 是 Linux 系统提供一个非常强大的抓包工具，熟练使用它，对我们排查网络问题非常有用。如果你的机器上还没有安装，可以使用如下命令安装：\nyum install tcpdump 如果要使用 tcpdump 命令必须具有 sudo 权限。\ntcpdump 常用的选项有：\n-i 指定要捕获的目标网卡名，网卡名可以使用前面章节中介绍的 ifconfig 命令获得；如果要抓所有网卡的上的包，可以使用 any 关键字。\n## 抓取网卡ens33上的包 tcpdump -i ens33 ## 抓取所有网卡上的包 tcpdump -i any -X 以 ASCII 和十六进制的形式输出捕获的数据包内容，减去链路层的包头信息；-XX 以 ASCII 和十六进制的形式输出捕获的数据包内容，包括链路层的包头信息。\n-n 不要将 ip 地址显示成别名的形式；-nn 不要将 ip 地址和端口以别名的形式显示。\n-S 以绝对值显示包的 ISN 号（包序列号），默认以上一包的偏移量显示。\n-vv 抓包的信息详细地显示；-vvv 抓包的信息更详细地显示。\n-w 将抓取的包的原始信息（不解析，也不输出）写入文件中，后跟文件名：\ntcpdump -i any -w filename -r 从利用 -w 选项保存的包文件中读取数据包信息。\n除了可以使用选项以外，tcpdump 还支持各种数据包过滤的表达式，常见的形式如下：\n## 仅显示经过端口 8888 上的数据包（包括tcp:8888和udp:8888） tcpdump -i any \u0026#39;port 8888\u0026#39; ## 仅显示经过端口是 tcp:8888 上的数据包 tcpdump -i any \u0026#39;tcp port 8888\u0026#39; ## 仅显示从源端口是 tcp:8888 的数据包 tcpdump -i any \u0026#39;tcp src port 8888\u0026#39; ## 仅显示源端口是 tcp:8888 或目标端口是 udp:9999 的包 tcpdump -i any \u0026#39;tcp src port 8888 or udp dst port 9999\u0026#39; ## 仅显示地址是127.","title":"Linux tcpdump 使用介绍"},{"content":"Linux 网络故障排查的瑞士军刀 nc 即 netcat 命令，这个工具在排查网络故障时非常有用，功能非常强大，因而被业绩称为网络界的“瑞士军刀”，请读者务必掌握。默认系统是没有这个命令的，你需要安装一下，安装方法：\nyum install nc nc 命令常见的用法是模拟一个服务器程序被其他客户端连接，或者模拟一个客户端连接其他服务器，连接之后就可以进行数据收发。我们来逐一介绍一下：\n模拟一个服务器程序\n使用 -l 选项（单词 listen 的第一个字母）在某个 ip 地址和端口号上开启一个侦听服务，以便让其他客户端连接。通常为了显示更详细的信息，会带上 -v 选项。\n示例如下：\n[root@iZ238vnojlyZ ~]# nc -v -l 127.0.0.1 6000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on 127.0.0.1:6000 这样就在 6000 端口开启了一个侦听服务器，我们可以通过 127.0.0.1:6000 去连接上去；如果你的机器可以被外网访问，你可以使用 0.0.0.0 这样的侦听地址，示例：\n[root@iZ238vnojlyZ ~]# nc -v -l 0.0.0.0 6000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on 0.0.0.0:6000 模拟一个客户端程序\n用 nc 命令模拟一个客户端程序时，我们不需要使用 -l 选项，直接写上 ip 地址（或域名，nc 命令可以自动解析域名）和端口号即可，示例如下：\n## 连接百度 web 服务器 [root@iZ238vnojlyZ ~]# nc -v www.baidu.com 80 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 115.239.211.112:80. 输出提示我们成功连接上百度 Web 服务器。\n我们知道客户端连接服务器一般都是操作系统随机分配一个可用的端口号连接到服务器上去，使用 nc 命令作为客户端时可以使用 -p 选项指定使用哪个端口号连接服务器，例如，我们希望通过本地 5555 端口连接百度的 Web 服务器，可以这么输入：\n[root@iZ238vnojlyZ ~]# nc -v -p 5555 www.baidu.com 80 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 115.239.211.112:80. 再开一个 shell 窗口，我们使用上文中介绍的 lsof 命令验证一下，是否确实通过 5555 端口连接上了百度 Web 服务器。\n[root@iZ238vnojlyZ ~]# lsof -Pni | grep nc nc 32610 root 3u IPv4 113369437 0t0 TCP 120.55.94.78:5555-\u0026gt;115.239.211.112:80 (ESTABLISHED) 结果确实如我们所期望的。\n当然，当使用 nc 命令与对端建立连接后，我们可以发送消息。下面通过一个具体的例子来演示一下这个过程\n使用 nc -v -l 0.0.0.0 6000 模拟一个侦听服务，再新建一个 shell 窗口利用 nc -v 127.0.0.1 6000 模拟一个客户端程序连接刚才的服务器。 此时在客户端和服务器就可以相互发消息了。我们可以达到一个简化版的 IM 软件聊天效果： 客户端效果：\n服务器端效果：\n果你在使用 nc 命令发消息时不小心输入错误，可以使用 Ctrl + Backspace 键删除。\nnc 命令默认会将 \\n 作为每条消息的结束标志，如果你指定了 -C 选项，将会使用 \\r\\n 作为消息结束标志。\nnc 命令不仅可以发消息，同时也能发文件。我们也来演示一下：\n需要注意的是是接收文件的一方是服务器端，发送文件的一方是客户端。\n服务器端命令：\nnc -l ip地址 端口号 \u0026gt; 接收的文件名 客户端命令：\nnc ip地址 端口号 \u0026lt; 发送的文件名 服务器端效果：\n客户端效果：\n意：这里客户端发送一个文件叫 index.html，服务器端以文件名 xxx.html 来保存，也就是说服务器端保存接收的文件名时不一定要使用客户端发送的文件名。\n根据上面的介绍，当我们需要调试我们自己的服务器或者客户端程序时，又不想自己开发相应的对端，我们就可以使用 nc 命令去模拟。\n当然，nc 命令非常强大，其功能远非本节介绍的这些，读者如果有兴趣可以去 nc 的 man 手册上获取更多的信息。\n","permalink":"https://haokiu.com/blog/501d5d7dacf24f4098180740dba82434/","summary":"Linux 网络故障排查的瑞士军刀 nc 即 netcat 命令，这个工具在排查网络故障时非常有用，功能非常强大，因而被业绩称为网络界的“瑞士军刀”，请读者务必掌握。默认系统是没有这个命令的，你需要安装一下，安装方法：\nyum install nc nc 命令常见的用法是模拟一个服务器程序被其他客户端连接，或者模拟一个客户端连接其他服务器，连接之后就可以进行数据收发。我们来逐一介绍一下：\n模拟一个服务器程序\n使用 -l 选项（单词 listen 的第一个字母）在某个 ip 地址和端口号上开启一个侦听服务，以便让其他客户端连接。通常为了显示更详细的信息，会带上 -v 选项。\n示例如下：\n[root@iZ238vnojlyZ ~]# nc -v -l 127.0.0.1 6000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on 127.0.0.1:6000 这样就在 6000 端口开启了一个侦听服务器，我们可以通过 127.0.0.1:6000 去连接上去；如果你的机器可以被外网访问，你可以使用 0.0.0.0 这样的侦听地址，示例：\n[root@iZ238vnojlyZ ~]# nc -v -l 0.0.0.0 6000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on 0.0.0.0:6000 模拟一个客户端程序\n用 nc 命令模拟一个客户端程序时，我们不需要使用 -l 选项，直接写上 ip 地址（或域名，nc 命令可以自动解析域名）和端口号即可，示例如下：\n## 连接百度 web 服务器 [root@iZ238vnojlyZ ~]# nc -v www.baidu.com 80 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 115.239.211.112:80. 输出提示我们成功连接上百度 Web 服务器。\n我们知道客户端连接服务器一般都是操作系统随机分配一个可用的端口号连接到服务器上去，使用 nc 命令作为客户端时可以使用 -p 选项指定使用哪个端口号连接服务器，例如，我们希望通过本地 5555 端口连接百度的 Web 服务器，可以这么输入：","title":"Linux 网络故障排查的瑞士军刀"},{"content":"Memcached源码分析 00 服务器资源调整\n01 初始化参数解析\n02 网络监听的建立\n03 网络连接建立\n04 内存初始化\n05 资源初始化\n06 get过程\n07 cas属性\n08 内存池\n09 连接队列\n10 Hash表操作\n12 set操作\n13 do_item_alloc操作\n14 item结构\n15 Hash表扩容\n16 线程交互\n17 状态机\n​\n","permalink":"https://haokiu.com/blog/d10283bf526c437a9e64e40d5afa25c4/","summary":"Memcached源码分析 00 服务器资源调整\n01 初始化参数解析\n02 网络监听的建立\n03 网络连接建立\n04 内存初始化\n05 资源初始化\n06 get过程\n07 cas属性\n08 内存池\n09 连接队列\n10 Hash表操作\n12 set操作\n13 do_item_alloc操作\n14 item结构\n15 Hash表扩容\n16 线程交互\n17 状态机\n​","title":"Memcached源码分析"},{"content":"Memcached源码分析三 网络连接建立 接着上一篇继续分析，上一篇请参考 《Memcached源码阅读之网络监听的建立》，这篇主要分析TCP的连接建立（从前面的代码分析可以看出，这个过程是由主线程驱动的），UDP没有连接建立的过程，所以之间进行连接分发，我们后续分析，现在直接上代码进行讲解。\nconn *conn_new(const int sfd, enum conn_states init_state, const int event_flags, const int read_buffer_size, enum network_transport transport, struct event_base *base) { conn *c = conn_from_freelist(); //获取一个空闲连接，conn是Memcached内部对网络连接的一个封装 //如果没有空闲的连接 if (NULL == c) { if (!(c = (conn *)calloc(1, sizeof(conn))))//申请空间 { fprintf(stderr, \u0026#34;calloc()\\n\u0026#34;); return NULL; }MEMCACHED_CONN_CREATE(c); //进行一些初始化 c-\u0026gt;rbuf = c-\u0026gt;wbuf = 0; c-\u0026gt;ilist = 0; c-\u0026gt;suffixlist = 0; c-\u0026gt;iov = 0; c-\u0026gt;msglist = 0; c-\u0026gt;hdrbuf = 0; c-\u0026gt;rsize = read_buffer_size; c-\u0026gt;wsize = DATA_BUFFER_SIZE; c-\u0026gt;isize = ITEM_LIST_INITIAL; c-\u0026gt;suffixsize = SUFFIX_LIST_INITIAL; c-\u0026gt;iovsize = IOV_LIST_INITIAL; c-\u0026gt;msgsize = MSG_LIST_INITIAL; c-\u0026gt;hdrsize = 0; //每个conn都自带读入和输出缓冲区，在进行网络收发数据时，特别方便 c-\u0026gt;rbuf = (char *)malloc((size_t)c-\u0026gt;rsize); c-\u0026gt;wbuf = (char *)malloc((size_t)c-\u0026gt;wsize); c-\u0026gt;ilist = (item **)malloc(sizeof(item *) * c-\u0026gt;isize); c-\u0026gt;suffixlist = (char **)malloc(sizeof(char *) * c-\u0026gt;suffixsize); c-\u0026gt;iov = (struct iovec *) malloc(sizeof(struct iovec) * c-\u0026gt;iovsize); c-\u0026gt;msglist = (struct msghdr *) malloc( sizeof(struct msghdr) * c-\u0026gt;msgsize); if (c-\u0026gt;rbuf == 0 || c-\u0026gt;wbuf == 0 || c-\u0026gt;ilist == 0 || c-\u0026gt;iov == 0 || c-\u0026gt;msglist == 0 || c-\u0026gt;suffixlist == 0) { conn_free(c); fprintf(stderr, \u0026#34;malloc()\\n\u0026#34;); return NULL; } STATS_LOCK(); //统计变量更新 stats.conn_structs++; STATS_UNLOCK(); } c-\u0026gt;transport = transport; c-\u0026gt;protocol = settings.binding_protocol; if (!settings.socketpath) { c-\u0026gt;request_addr_size = sizeof(c-\u0026gt;request_addr); } else { c-\u0026gt;request_addr_size = 0; } //输出一些日志信息 if (settings.verbose \u0026gt; 1) { if (init_state == conn_listening) { fprintf(stderr, \u0026#34;\u0026lt;%d server listening (%s)\\n\u0026#34;, sfd, prot_text(c-\u0026gt;protocol)); } else if (IS_UDP(transport)) { fprintf(stderr, \u0026#34;\u0026lt;%d server listening (udp)\\n\u0026#34;, sfd); } else if (c-\u0026gt;protocol == negotiating_prot) { fprintf(stderr, \u0026#34;\u0026lt;%d new auto-negotiating client connection\\n\u0026#34;, sfd); } else if (c-\u0026gt;protocol == ascii_prot) { fprintf(stderr, \u0026#34;\u0026lt;%d new ascii client connection.\\n\u0026#34;, sfd); } else if (c-\u0026gt;protocol == binary_prot) { fprintf(stderr, \u0026#34;\u0026lt;%d new binary client connection.\\n\u0026#34;, sfd); } else { fprintf(stderr, \u0026#34;\u0026lt;%d new unknown (%d) client connection\\n\u0026#34;, sfd, c-\u0026gt;protocol); assert(false); } } c-\u0026gt;sfd = sfd; c-\u0026gt;state = init_state; c-\u0026gt;rlbytes = 0; c-\u0026gt;cmd = -1; c-\u0026gt;rbytes = c-\u0026gt;wbytes = 0; c-\u0026gt;wcurr = c-\u0026gt;wbuf; c-\u0026gt;rcurr = c-\u0026gt;rbuf; c-\u0026gt;ritem = 0; c-\u0026gt;icurr = c-\u0026gt;ilist; c-\u0026gt;suffixcurr = c-\u0026gt;suffixlist; c-\u0026gt;ileft = 0; c-\u0026gt;suffixleft = 0; c-\u0026gt;iovused = 0; c-\u0026gt;msgcurr = 0; c-\u0026gt;msgused = 0; c-\u0026gt;write_and_go = init_state; c-\u0026gt;write_and_free = 0; c-\u0026gt;item = 0; c-\u0026gt;noreply = false; //建立sfd描述符上面的event事件，事件回调函数为event_handler event_set(\u0026amp;c-\u0026gt;event, sfd, event_flags, event_handler, (void *)c); event_base_set(base, \u0026amp;c-\u0026gt;event); c-\u0026gt;ev_flags = event_flags; if (event_add(\u0026amp;c-\u0026gt;event, 0) == -1) { //如果建立libevent事件失败，将创建的conn添加到空闲列表中 if (conn_add_to_freelist(c)) { conn_free(c); } perror(\u0026#34;event_add\u0026#34;); return NULL; } STATS_LOCK(); //统计信息更新 stats.curr_conns++; stats.total_conns++; STATS_UNLOCK(); MEMCACHED_CONN_ALLOCATE(c-\u0026gt;sfd); return c; } //获得conn conn *conn_from_freelist() { conn *c; pthread_mutex_lock(\u0026amp;conn_lock);//操作链表，加锁，保持同步 //freecurr为静态全局变量 if (freecurr \u0026gt; 0) { //freeconns是在Memcached启动时初始化的 c = freeconns[--freecurr]; } else//没有conn { c = NULL; } pthread_mutex_unlock(\u0026amp;conn_lock); return c; } //添加conn到空闲链表中 bool conn_add_to_freelist(conn *c) { bool ret = true; pthread_mutex_lock(\u0026amp;conn_lock); //freeconns还有空间 if (freecurr \u0026lt; freetotal) { freeconns[freecurr++] = c;//直接添加 ret = false; } else { //没有多余空间，进行扩容，按目前容量的2倍进行扩容 size_t newsize = freetotal * 2; conn **new_freeconns = realloc(freeconns, sizeof(conn *) * newsize); if (new_freeconns) { freetotal = newsize; freeconns = new_freeconns; freeconns[freecurr++] = c; ret = false; } } pthread_mutex_unlock(\u0026amp;conn_lock); return ret; } //libevent事件回调函数的处理，回调函数被调用时，表明Memcached监听的端口号有网络事件到了 void event_handler(const int fd, const short which, void *arg) { conn *c; c = (conn *)arg; assert(c != NULL); c-\u0026gt;which = which; //这种情况应该很少出现 if (fd != c-\u0026gt;sfd) { if (settings.verbose \u0026gt; 0) fprintf(stderr, \u0026#34;Catastrophic: event fd doesn\u0026#39;t match conn fd!\\n\u0026#34;); conn_close(c); return; } //进入业务处理状态机 drive_machine(c); return; } ","permalink":"https://haokiu.com/blog/2a422d9fa3fe4cddbcbef326866d8943/","summary":"Memcached源码分析三 网络连接建立 接着上一篇继续分析，上一篇请参考 《Memcached源码阅读之网络监听的建立》，这篇主要分析TCP的连接建立（从前面的代码分析可以看出，这个过程是由主线程驱动的），UDP没有连接建立的过程，所以之间进行连接分发，我们后续分析，现在直接上代码进行讲解。\nconn *conn_new(const int sfd, enum conn_states init_state, const int event_flags, const int read_buffer_size, enum network_transport transport, struct event_base *base) { conn *c = conn_from_freelist(); //获取一个空闲连接，conn是Memcached内部对网络连接的一个封装 //如果没有空闲的连接 if (NULL == c) { if (!(c = (conn *)calloc(1, sizeof(conn))))//申请空间 { fprintf(stderr, \u0026#34;calloc()\\n\u0026#34;); return NULL; }MEMCACHED_CONN_CREATE(c); //进行一些初始化 c-\u0026gt;rbuf = c-\u0026gt;wbuf = 0; c-\u0026gt;ilist = 0; c-\u0026gt;suffixlist = 0; c-\u0026gt;iov = 0; c-\u0026gt;msglist = 0; c-\u0026gt;hdrbuf = 0; c-\u0026gt;rsize = read_buffer_size; c-\u0026gt;wsize = DATA_BUFFER_SIZE; c-\u0026gt;isize = ITEM_LIST_INITIAL; c-\u0026gt;suffixsize = SUFFIX_LIST_INITIAL; c-\u0026gt;iovsize = IOV_LIST_INITIAL; c-\u0026gt;msgsize = MSG_LIST_INITIAL; c-\u0026gt;hdrsize = 0; //每个conn都自带读入和输出缓冲区，在进行网络收发数据时，特别方便 c-\u0026gt;rbuf = (char *)malloc((size_t)c-\u0026gt;rsize); c-\u0026gt;wbuf = (char *)malloc((size_t)c-\u0026gt;wsize); c-\u0026gt;ilist = (item **)malloc(sizeof(item *) * c-\u0026gt;isize); c-\u0026gt;suffixlist = (char **)malloc(sizeof(char *) * c-\u0026gt;suffixsize); c-\u0026gt;iov = (struct iovec *) malloc(sizeof(struct iovec) * c-\u0026gt;iovsize); c-\u0026gt;msglist = (struct msghdr *) malloc( sizeof(struct msghdr) * c-\u0026gt;msgsize); if (c-\u0026gt;rbuf == 0 || c-\u0026gt;wbuf == 0 || c-\u0026gt;ilist == 0 || c-\u0026gt;iov == 0 || c-\u0026gt;msglist == 0 || c-\u0026gt;suffixlist == 0) { conn_free(c); fprintf(stderr, \u0026#34;malloc()\\n\u0026#34;); return NULL; } STATS_LOCK(); //统计变量更新 stats.","title":"Memcached源码分析三 网络连接建立"},{"content":"Memcached源码阅读一 初始化参数解析 Memcached启动时，有很多配置参数可以选择，这些配置参数严重影响着Memcached的使用，下面分析下这些参数的意义，开源软件版本之间差异比较大，我这次分析是基于1.4.15进行分析的，大家学习时记得核对版本。\n\u0026#34;a:\u0026#34; //unix socket的权限位信息，unix socket的权限位信息和普通文件的权限位信息一样 \u0026#34;p:\u0026#34; //memcached监听的TCP端口值，默认是11211 \u0026#34;s:\u0026#34; //unix socket监听的socket文件路径 \u0026#34;U:\u0026#34; //memcached监听的UDP端口值，默认是11211 \u0026#34;m:\u0026#34; //memcached使用的最大内存值，默认是64M \u0026#34;M\u0026#34; //当memcached的内存使用完时，不进行LRU淘汰数据，直接返回错误，该选项就是关闭LRU \u0026#34;c:\u0026#34; //memcached的最大连接数,如果不指定，按系统的最大值进行 \u0026#34;k\u0026#34; //是否锁定memcached所持有的内存，如果锁定了内存，其他业务持有的内存就会减小 \u0026#34;hi\u0026#34; //帮助信息 \u0026#34;r\u0026#34; //core文件的大小，如果不指定，按系统的最大值进行 \u0026#34;v\u0026#34; //调试信息 \u0026#34;d\u0026#34; //设定以daemon方式运行 \u0026#34;l:\u0026#34; //绑定的ip信息，如果服务器有多个ip，可以在多个ip上面启动多个Memcached实例，注意：这个不是可接收的IP地址 \u0026#34;u:\u0026#34; //memcached运行的用户，如果以root启动，需要指定用户，否则程序错误，退出。 \u0026#34;P:\u0026#34; //memcached以daemon方式运行时，保存pid的文件路径信息 \u0026#34;f:\u0026#34; //内存的扩容因子，这个关系到Memcached内部初始化空间时的一个变化，后面详细说明 \u0026#34;n:\u0026#34; //chunk的最小大小(byte)，后续的增长都是该值*factor来进行增长的 \u0026#34;t:\u0026#34; //内部worker线程的个数，默认是4个，最大值推荐不超过64个 \u0026#34;D:\u0026#34; //内部数据存储时的分割符 \u0026#34;L\u0026#34; //指定内存页的大小，默认内存页大小为4K，页最大不超过2M，调大页的大小，可有效减小页表的大小,提高内存访问的效率 \u0026#34;R:\u0026#34; //单个worker的最大请求个数 \u0026#34;C\u0026#34; //禁用业务的cas,即compare and set \u0026#34;b:\u0026#34; //listen操作缓存连接个数 \u0026#34;B:\u0026#34; //memcached内部使用的协议，支持二进制协议和文本协议，早期只有文本协议，二进制协议是后续加上的 \u0026#34;I:\u0026#34; //单个item的最大值，默认是1M,可以修改，修改的最小值为1k,最大值不能超过128M \u0026#34;S\u0026#34; //打开sasl安全协议 \u0026#34;o:\u0026#34; /** *有四个参数项可以设置: *maxconns_fast(如果连接数超过最大连接数，立即关闭新的连接) *hashpower(hash表的大小的指数值，是按1\u0026lt;\u0026lt;hashpower来创建hash表的，默认的hashpower为16，配置值建议不超过64) *slab_reassign（是否调整/平衡各个slab所占的内存） *slab_automove（是否自动移动各个slab，如果该选项打开，会有专门的线程来进行slab的调整） */ Memcached内部是通过settings来抽象上面的这些初始化参数。\nstruct settings { size_t maxbytes; int maxconns; int port; int udpport; char* inter; int verbose; rel_time_t oldest_live; /* ignore existing items older than this */ int evict_to_free; char* socketpath; /* path to unix socket if using local socket */ int access; /* access mask (a la chmod) for unix domain socket */ double factor; /* chunk size growth factor */ int chunk_size; int num_threads; /* number of worker (without dispatcher) libevent threads to run */ int num_threads_per_udp; /* number of worker threads serving each udp socket */ char prefix_delimiter; /* character that marks a key prefix (for stats) */ int detail_enabled; /* nonzero if we\u0026#39;re collecting detailed stats */ int reqs_per_event; /* Maximum number of io to process on each io-event.*/ bool use_cas; enum protocol binding_protocol; int backlog; int item_size_max; /* Maximum item size, and upper end for slabs */ bool sasl; /* SASL on/off */ bool maxconns_fast; /* Whether or not to early close connections */ bool slab_reassign; /* Whether or not slab reassignment is allowed */ int slab_automove; /* Whether or not to automatically move slabs */ int hashpower_init; /* Starting hash power level */ }; 改结构的初始化：\nstatic void settings_init(void) { settings.use_cas = true; settings.access = 0700; settings.port = 11211; settings.udpport = 11211; /* By default this string should be NULL for getaddrinfo() */ settings.inter = NULL; settings.maxbytes = 64 * 1024 * 1024; /* default is 64MB */ settings.maxconns = 1024; /* to limit connections-related memory to about 5MB */ settings.verbose = 0; settings.oldest_live = 0; settings.evict_to_free = 1; /* push old items out of cache when memory runs out */ settings.socketpath = NULL; /* by default, not using a unix socket */ settings.factor = 1.25; settings.chunk_size = 48; /* space for a modest key and value */ settings.num_threads = 4; /* N workers */ settings.num_threads_per_udp = 0; settings.prefix_delimiter = \u0026#39;:\u0026#39;; settings.detail_enabled = 0; settings.reqs_per_event = 20; settings.backlog = 1024; settings.binding_protocol = negotiating_prot; settings.item_size_max = 1024 * 1024; /* The famous 1MB upper limit. */ settings.maxconns_fast = false; settings.hashpower_init = 0; settings.slab_reassign = false; settings.slab_automove = 0; } 这些值都是一些默认值，后续按启动时所指定的进行修改，比如对监听端口号的修改：\ncase \u0026#39;a\u0026#39;: //修改unix socket的权限位信息 settings.access = strtol(optarg, NULL, 8); break; case \u0026#39;U\u0026#39;: //udp端口信息 settings.udpport = atoi(optarg); udp_specified = true; break; case \u0026#39;p\u0026#39;: //tcp端口信息 settings.port = atoi(optarg); tcp_specified = true; break; ","permalink":"https://haokiu.com/blog/778cf564240e4d19ad39e0e271d66b3d/","summary":"Memcached源码阅读一 初始化参数解析 Memcached启动时，有很多配置参数可以选择，这些配置参数严重影响着Memcached的使用，下面分析下这些参数的意义，开源软件版本之间差异比较大，我这次分析是基于1.4.15进行分析的，大家学习时记得核对版本。\n\u0026#34;a:\u0026#34; //unix socket的权限位信息，unix socket的权限位信息和普通文件的权限位信息一样 \u0026#34;p:\u0026#34; //memcached监听的TCP端口值，默认是11211 \u0026#34;s:\u0026#34; //unix socket监听的socket文件路径 \u0026#34;U:\u0026#34; //memcached监听的UDP端口值，默认是11211 \u0026#34;m:\u0026#34; //memcached使用的最大内存值，默认是64M \u0026#34;M\u0026#34; //当memcached的内存使用完时，不进行LRU淘汰数据，直接返回错误，该选项就是关闭LRU \u0026#34;c:\u0026#34; //memcached的最大连接数,如果不指定，按系统的最大值进行 \u0026#34;k\u0026#34; //是否锁定memcached所持有的内存，如果锁定了内存，其他业务持有的内存就会减小 \u0026#34;hi\u0026#34; //帮助信息 \u0026#34;r\u0026#34; //core文件的大小，如果不指定，按系统的最大值进行 \u0026#34;v\u0026#34; //调试信息 \u0026#34;d\u0026#34; //设定以daemon方式运行 \u0026#34;l:\u0026#34; //绑定的ip信息，如果服务器有多个ip，可以在多个ip上面启动多个Memcached实例，注意：这个不是可接收的IP地址 \u0026#34;u:\u0026#34; //memcached运行的用户，如果以root启动，需要指定用户，否则程序错误，退出。 \u0026#34;P:\u0026#34; //memcached以daemon方式运行时，保存pid的文件路径信息 \u0026#34;f:\u0026#34; //内存的扩容因子，这个关系到Memcached内部初始化空间时的一个变化，后面详细说明 \u0026#34;n:\u0026#34; //chunk的最小大小(byte)，后续的增长都是该值*factor来进行增长的 \u0026#34;t:\u0026#34; //内部worker线程的个数，默认是4个，最大值推荐不超过64个 \u0026#34;D:\u0026#34; //内部数据存储时的分割符 \u0026#34;L\u0026#34; //指定内存页的大小，默认内存页大小为4K，页最大不超过2M，调大页的大小，可有效减小页表的大小,提高内存访问的效率 \u0026#34;R:\u0026#34; //单个worker的最大请求个数 \u0026#34;C\u0026#34; //禁用业务的cas,即compare and set \u0026#34;b:\u0026#34; //listen操作缓存连接个数 \u0026#34;B:\u0026#34; //memcached内部使用的协议，支持二进制协议和文本协议，早期只有文本协议，二进制协议是后续加上的 \u0026#34;I:\u0026#34; //单个item的最大值，默认是1M,可以修改，修改的最小值为1k,最大值不能超过128M \u0026#34;S\u0026#34; //打开sasl安全协议 \u0026#34;o:\u0026#34; /** *有四个参数项可以设置: *maxconns_fast(如果连接数超过最大连接数，立即关闭新的连接) *hashpower(hash表的大小的指数值，是按1\u0026lt;\u0026lt;hashpower来创建hash表的，默认的hashpower为16，配置值建议不超过64) *slab_reassign（是否调整/平衡各个slab所占的内存） *slab_automove（是否自动移动各个slab，如果该选项打开，会有专门的线程来进行slab的调整） */ Memcached内部是通过settings来抽象上面的这些初始化参数。\nstruct settings { size_t maxbytes; int maxconns; int port; int udpport; char* inter; int verbose; rel_time_t oldest_live; /* ignore existing items older than this */ int evict_to_free; char* socketpath; /* path to unix socket if using local socket */ int access; /* access mask (a la chmod) for unix domain socket */ double factor; /* chunk size growth factor */ int chunk_size; int num_threads; /* number of worker (without dispatcher) libevent threads to run */ int num_threads_per_udp; /* number of worker threads serving each udp socket */ char prefix_delimiter; /* character that marks a key prefix (for stats) */ int detail_enabled; /* nonzero if we\u0026#39;re collecting detailed stats */ int reqs_per_event; /* Maximum number of io to process on each io-event.","title":"Memcached源码阅读一 初始化参数解析"},{"content":"Memcached源码阅读七 cas属性 cas即compare and set或者compare and swap,是实现乐观锁的一种技术，乐观锁是相对悲观锁来说的，所谓悲观锁是在数据处理过程中，完全锁定，这种能完全保证数据的一致性，但在多线程情况下，并发性能差，通常是使用各种锁技术实现；而乐观锁是通过版本号机制来实现数据一致性，过程中会使用CPU提供的原子操作指令，乐观锁能提高系统的并发性能，Memcached使用cas是保证数据的一致性，不是严格为了实现锁。\nMemcached是多客户端应用，在多个客户端修改同一个数据时，会出现相互覆盖的情况，在这种情况下，使用cas版本号验证，可以有效的保证数据的一致性，Memcached默认是打开cas属性的，每次存储数据时，都会生成其cas值并和item一起存储，后续的get操作会返回系统生成的cas值，在执行set等操作时，需要将cas值传入，下面我们看看Memcached内部是如何实现cas的，关于如何使用Mecached的CAS协议，请参考文章：Memcached的CAS协议（链接：http://langyu.iteye.com/blog/680052）。\n//为新的item生成cas值 uint64_t get_cas_id(void) { static uint64_t cas_id = 0; return ++cas_id; } //这段代码是store_item的代码片段，这里是执行cas存储时执行的判断逻辑， else if (ITEM_get_cas(it) == ITEM_get_cas(old_it))//cas值一致 { pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); c-\u0026gt;thread-\u0026gt;stats.slab_stats[old_it-\u0026gt;slabs_clsid].cas_hits++; pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); item_replace(old_it, it, hv);//执行存储逻辑 stored = STORED; } //cas值不一致，不进行实际的存储 else { pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); c-\u0026gt;thread-\u0026gt;stats.slab_stats[old_it-\u0026gt;slabs_clsid].cas_badval++; //更新统计信息 pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); if (settings.verbose \u0026gt; 1) { //打印错误日志 fprintf(stderr, \u0026#34;CAS: failure: expected %llu, got %llu\\n\u0026#34;, (unsigned long long) ITEM_get_cas(old_it), (unsigned long long) ITEM_get_cas(it)); } stored = EXISTS; } ","permalink":"https://haokiu.com/blog/4d2fa7e9284a4e7fb742bdda30d20da6/","summary":"Memcached源码阅读七 cas属性 cas即compare and set或者compare and swap,是实现乐观锁的一种技术，乐观锁是相对悲观锁来说的，所谓悲观锁是在数据处理过程中，完全锁定，这种能完全保证数据的一致性，但在多线程情况下，并发性能差，通常是使用各种锁技术实现；而乐观锁是通过版本号机制来实现数据一致性，过程中会使用CPU提供的原子操作指令，乐观锁能提高系统的并发性能，Memcached使用cas是保证数据的一致性，不是严格为了实现锁。\nMemcached是多客户端应用，在多个客户端修改同一个数据时，会出现相互覆盖的情况，在这种情况下，使用cas版本号验证，可以有效的保证数据的一致性，Memcached默认是打开cas属性的，每次存储数据时，都会生成其cas值并和item一起存储，后续的get操作会返回系统生成的cas值，在执行set等操作时，需要将cas值传入，下面我们看看Memcached内部是如何实现cas的，关于如何使用Mecached的CAS协议，请参考文章：Memcached的CAS协议（链接：http://langyu.iteye.com/blog/680052）。\n//为新的item生成cas值 uint64_t get_cas_id(void) { static uint64_t cas_id = 0; return ++cas_id; } //这段代码是store_item的代码片段，这里是执行cas存储时执行的判断逻辑， else if (ITEM_get_cas(it) == ITEM_get_cas(old_it))//cas值一致 { pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); c-\u0026gt;thread-\u0026gt;stats.slab_stats[old_it-\u0026gt;slabs_clsid].cas_hits++; pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); item_replace(old_it, it, hv);//执行存储逻辑 stored = STORED; } //cas值不一致，不进行实际的存储 else { pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); c-\u0026gt;thread-\u0026gt;stats.slab_stats[old_it-\u0026gt;slabs_clsid].cas_badval++; //更新统计信息 pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); if (settings.verbose \u0026gt; 1) { //打印错误日志 fprintf(stderr, \u0026#34;CAS: failure: expected %llu, got %llu\\n\u0026#34;, (unsigned long long) ITEM_get_cas(old_it), (unsigned long long) ITEM_get_cas(it)); } stored = EXISTS; } ","title":"Memcached源码阅读七 cas属性"},{"content":"Memcached源码阅读九 连接队列 Memcached中Master线程和Worker线程之间通信连接信息时，是通过连接队列来通信的，即Master线程投递一个消息到Worker线程的连接队列中，Worker线程从连接队列中读取链接信息来执行连接操作，下面我们简单分析下Memcached的连接队列结构。\ntypedef struct conn_queue_item CQ_ITEM;//每个连接信息的封装 struct conn_queue_item { int sfd;//accept之后的描述符 enum conn_states init_state;//连接的初始状态 int event_flags;//libevent标志 int read_buffer_size;//读取数据缓冲区大小 enum network_transport transport;//内部通信所用的协议 CQ_ITEM *next;//用于实现链表的指针 }; typedef struct conn_queue CQ;//连接队列的封装 struct conn_queue { CQ_ITEM *head;//头指针，注意这里是单链表，不是双向链表 CQ_ITEM *tail;//尾部指针， pthread_mutex_t lock;//锁 pthread_cond_t cond;//条件变量 }; //连接队列初始化 static void cq_init(CQ *cq) { pthread_mutex_init(\u0026amp;cq-\u0026gt;lock, NULL);//初始化锁 pthread_cond_init(\u0026amp;cq-\u0026gt;cond, NULL);//初始化条件变量 cq-\u0026gt;head = NULL; cq-\u0026gt;tail = NULL; } //获取一个连接 static CQ_ITEM *cq_pop(CQ *cq) { CQ_ITEM *item; pthread_mutex_lock(\u0026amp;cq-\u0026gt;lock);//执行加锁操作 item = cq-\u0026gt;head; //获得头部指针指向的数据 if (NULL != item) { //更新头指针信息 cq-\u0026gt;head = item-\u0026gt;next; //这里为空的话，则尾指针也为空，链表此时为空 if (NULL == cq-\u0026gt;head) cq-\u0026gt;tail = NULL; } //释放锁操作 pthread_mutex_unlock(\u0026amp;cq-\u0026gt;lock); return item; } //添加一个连接信息 static void cq_push(CQ *cq, CQ_ITEM *item) { item-\u0026gt;next = NULL; pthread_mutex_lock(\u0026amp;cq-\u0026gt;lock);//执行加锁操作 //如果链表目前是空的 if (NULL == cq-\u0026gt;tail) //则头指针指向该结点 cq-\u0026gt;head = item; else cq-\u0026gt;tail-\u0026gt;next = item;//添加到尾部 cq-\u0026gt;tail = item; //尾部指针后移 pthread_cond_signal(\u0026amp;cq-\u0026gt;cond); //唤醒条件变量，如果有阻塞在该条件变量的线程，则会唤醒该线程 pthread_mutex_unlock(\u0026amp;cq-\u0026gt;lock); } //创建连接队列 static CQ_ITEM *cqi_new(void) { CQ_ITEM *item = NULL; pthread_mutex_lock(\u0026amp;cqi_freelist_lock); //加锁，保持数据同步 if (cqi_freelist) { //更新空闲链表信息 item = cqi_freelist; cqi_freelist = item-\u0026gt;next; } pthread_mutex_unlock(\u0026amp;cqi_freelist_lock); //如果空闲链表没有多余的链接 if (NULL == item) { int i; //初始化64个空闲连接信息 item = malloc(sizeof(CQ_ITEM) * ITEMS_PER_ALLOC); if (NULL == item) return NULL; //将空闲的连接信息进行链接 for (i = 2; i \u0026lt; ITEMS_PER_ALLOC; i++) item[i - 1].next = \u0026amp;item[i]; pthread_mutex_lock(\u0026amp;cqi_freelist_lock); item[ITEMS_PER_ALLOC - 1].next = cqi_freelist;//加入到空闲链表中 cqi_freelist = \u0026amp;item[1]; pthread_mutex_unlock(\u0026amp;cqi_freelist_lock); } return item; } //释放item，也就是将item添加到空闲链表中 static void cqi_free(CQ_ITEM *item) { pthread_mutex_lock(\u0026amp;cqi_freelist_lock); item-\u0026gt;next = cqi_freelist; cqi_freelist = item; pthread_mutex_unlock(\u0026amp;cqi_freelist_lock); } 空闲链表类似于一种连接池的实现，服务器开发中经常需要各种池操作，大家在实现类似池时，可以做参考。\n","permalink":"https://haokiu.com/blog/596315b99d2f40dba9c9ea13e975bd9d/","summary":"Memcached源码阅读九 连接队列 Memcached中Master线程和Worker线程之间通信连接信息时，是通过连接队列来通信的，即Master线程投递一个消息到Worker线程的连接队列中，Worker线程从连接队列中读取链接信息来执行连接操作，下面我们简单分析下Memcached的连接队列结构。\ntypedef struct conn_queue_item CQ_ITEM;//每个连接信息的封装 struct conn_queue_item { int sfd;//accept之后的描述符 enum conn_states init_state;//连接的初始状态 int event_flags;//libevent标志 int read_buffer_size;//读取数据缓冲区大小 enum network_transport transport;//内部通信所用的协议 CQ_ITEM *next;//用于实现链表的指针 }; typedef struct conn_queue CQ;//连接队列的封装 struct conn_queue { CQ_ITEM *head;//头指针，注意这里是单链表，不是双向链表 CQ_ITEM *tail;//尾部指针， pthread_mutex_t lock;//锁 pthread_cond_t cond;//条件变量 }; //连接队列初始化 static void cq_init(CQ *cq) { pthread_mutex_init(\u0026amp;cq-\u0026gt;lock, NULL);//初始化锁 pthread_cond_init(\u0026amp;cq-\u0026gt;cond, NULL);//初始化条件变量 cq-\u0026gt;head = NULL; cq-\u0026gt;tail = NULL; } //获取一个连接 static CQ_ITEM *cq_pop(CQ *cq) { CQ_ITEM *item; pthread_mutex_lock(\u0026amp;cq-\u0026gt;lock);//执行加锁操作 item = cq-\u0026gt;head; //获得头部指针指向的数据 if (NULL != item) { //更新头指针信息 cq-\u0026gt;head = item-\u0026gt;next; //这里为空的话，则尾指针也为空，链表此时为空 if (NULL == cq-\u0026gt;head) cq-\u0026gt;tail = NULL; } //释放锁操作 pthread_mutex_unlock(\u0026amp;cq-\u0026gt;lock); return item; } //添加一个连接信息 static void cq_push(CQ *cq, CQ_ITEM *item) { item-\u0026gt;next = NULL; pthread_mutex_lock(\u0026amp;cq-\u0026gt;lock);//执行加锁操作 //如果链表目前是空的 if (NULL == cq-\u0026gt;tail) //则头指针指向该结点 cq-\u0026gt;head = item; else cq-\u0026gt;tail-\u0026gt;next = item;//添加到尾部 cq-\u0026gt;tail = item; //尾部指针后移 pthread_cond_signal(\u0026amp;cq-\u0026gt;cond); //唤醒条件变量，如果有阻塞在该条件变量的线程，则会唤醒该线程 pthread_mutex_unlock(\u0026amp;cq-\u0026gt;lock); } //创建连接队列 static CQ_ITEM *cqi_new(void) { CQ_ITEM *item = NULL; pthread_mutex_lock(\u0026amp;cqi_freelist_lock); //加锁，保持数据同步 if (cqi_freelist) { //更新空闲链表信息 item = cqi_freelist; cqi_freelist = item-\u0026gt;next; } pthread_mutex_unlock(\u0026amp;cqi_freelist_lock); //如果空闲链表没有多余的链接 if (NULL == item) { int i; //初始化64个空闲连接信息 item = malloc(sizeof(CQ_ITEM) * ITEMS_PER_ALLOC); if (NULL == item) return NULL; //将空闲的连接信息进行链接 for (i = 2; i \u0026lt; ITEMS_PER_ALLOC; i++) item[i - 1].","title":"Memcached源码阅读九 连接队列"},{"content":"Memcached源码阅读二 网络监听的建立 Memcahced是一个服务器程序，所以需要建立网络监听来接受其他客户端机器的连接，下面分析下其过程，这次分析是基于Memcached 1.4.15版本分析的。\n// 如果socketpath为空，则表示使用的TCP / UDP, 不是使用unix socket //如果socketpath为空，则表示使用的TCP/UDP,不是使用unix socket if (settings.socketpath == NULL) { //可以从环境变量读取端口文件所在的文件路径 const char *portnumber_filename = getenv(\u0026#34;MEMCACHED_PORT_FILENAME\u0026#34;); char temp_portnumber_filename[PATH_MAX]; FILE *portnumber_file = NULL; //如果端口文件不为空，则打开 if (portnumber_filename != NULL) { snprintf(temp_portnumber_filename, sizeof(temp_portnumber_filename), \u0026#34;%s.lck\u0026#34;, portnumber_filename); portnumber_file = fopen(temp_portnumber_filename, \u0026#34;a\u0026#34;); if (portnumber_file == NULL) { fprintf(stderr, \u0026#34;Failed to open \\\u0026#34;%s\\\u0026#34;: %s\\n\u0026#34;, temp_portnumber_filename, strerror(errno)); } } //settings.port表示Memcached采用的是TCP协议，创建TCP Socket，监听并且绑定 errno = 0; if (settings.port \u0026amp;\u0026amp; server_sockets(settings.port, tcp_transport, portnumber_file)) { vperror(\u0026#34;failed to listen on TCP port %d\u0026#34;, settings.port); exit(EX_OSERR); } //settings.udpport表示Memcached采用的是UDP协议，创建UDP Socket，监听并且绑定 errno = 0; if (settings.udpport \u0026amp;\u0026amp; server_sockets(settings.udpport, udp_transport, portnumber_file)) { vperror(\u0026#34;failed to listen on UDP port %d\u0026#34;, settings.udpport); exit(EX_OSERR); } //端口文件不为空 if (portnumber_file) { fclose(portnumber_file);//关闭文件 rename(temp_portnumber_filename, portnumber_filename);//重命名端口文件 } } //TCP和UDP使用的是同一个接口来创建监听和绑定 static int server_sockets(int port, enum network_transport transport, FILE *portnumber_file) { //settings.inter指定的是要绑定的ip地址信息，如果为空，则表示是绑定本机一个ip if (settings.inter == NULL) { //执行监听和绑定操作 return server_socket(settings.inter, port, transport, portnumber_file); } //如果服务器有多个ip信息，可以在每个(ip,port)上面绑定一个Memcached实例，下面是一些输入参数的解析，解析完毕之后，执行绑定 else { // tokenize them and bind to each one of them.. char *b; int ret = 0; char *list = strdup(settings.inter); if (list == NULL) { fprintf(stderr, \u0026#34;Failed to allocate memory for parsing server interface string\\n\u0026#34;); return 1; } for (char *p = strtok_r(list, \u0026#34;;,\u0026#34;, \u0026amp;b); p != NULL; p = strtok_r(NULL, \u0026#34;;,\u0026#34;, \u0026amp;b)) { int the_port = port; char *s = strchr(p, \u0026#39;:\u0026#39;); if (s != NULL) { *s = \u0026#39;\\0\u0026#39;; ++s; if (!safe_strtol(s, \u0026amp;the_port)) { fprintf(stderr, \u0026#34;Invalid port number: \\\u0026#34;%s\\\u0026#34;\u0026#34;, s); return 1; } } if (strcmp(p, \u0026#34;*\u0026#34;) == 0) { p = NULL; } //绑定多次,循环调用单个的绑定函数 ret |= server_socket(p, the_port, transport, portnumber_file); } free(list); return ret; } } //执行真正的绑定 static int server_socket(const char *interface, int port, enum network_transport transport, FILE *portnumber_file) { int sfd; struct linger ling = { 0, 0 }; struct addrinfo *ai; struct addrinfo *next; //设定协议无关，用于监听的标志位 struct addrinfo hints = { .ai_flags = AI_PASSIVE,.ai_family = AF_UNSPEC }; char port_buf[NI_MAXSERV]; int error; int success = 0; int flags = 1; //指定socket的类型，如果是udp，则用数据报协议，如果是tcp,则用数据流协议 hints.ai_socktype = IS_UDP(transport) ? SOCK_DGRAM : SOCK_STREAM; if (port == -1) { port = 0; } snprintf(port_buf, sizeof(port_buf), \u0026#34;%d\u0026#34;, port); //调用getaddrinfo,将主机地址和端口号映射成为socket地址信息，地址信息由ai带回 error = getaddrinfo(interface, port_buf, \u0026amp;hints, \u0026amp;ai); if (error != 0) { if (error != EAI_SYSTEM) fprintf(stderr, \u0026#34;getaddrinfo(): %s\\n\u0026#34;, gai_strerror(error)); else perror(\u0026#34;getaddrinfo()\u0026#34;); return 1; } /*getaddrinfo返回多个addrinfo的情形有如下两种： 1.如果与interface参数关联的地址有多个，那么适用于所请求地址簇的每个地址都返回一个对应的结构。 2.如果port_buf参数指定的服务支持多个套接口类型，那么每个套接口类型都可能返回一个对应的结构。 */ for (next = ai; next; next = next-\u0026gt;ai_next) { conn *listen_conn_add; //为每个地址信息建立socket if ((sfd = new_socket(next)) == -1) { //建立socket过程中可能发生的，比如打开文件描述符过多等 if (errno == EMFILE) { perror(\u0026#34;server_socket\u0026#34;); exit(EX_OSERR); } continue; } #ifdef IPV6_V6ONLY if (next-\u0026gt;ai_family == AF_INET6) { //设定IPV6的选项值，设置了IPV6_V6ONLY，表示只收发IPV6的数据包，此时IPV4和IPV6可以绑定到同一个端口而不影响数据的收发 error = setsockopt(sfd, IPPROTO_IPV6, IPV6_V6ONLY, (char *)\u0026amp;flags, sizeof(flags)); if (error != 0) { perror(\u0026#34;setsockopt\u0026#34;); close(sfd); continue; } } #endif //设定socket选项，SO_REUSEADDR表示重用地址信息，具体重用哪些东西自行学习，必须在bind操作之前设置 setsockopt(sfd, SOL_SOCKET, SO_REUSEADDR, (void *)\u0026amp;flags, sizeof(flags)); if (IS_UDP(transport)){ maximize_sndbuf(sfd);//扩大发送缓冲区 } else { //设定socket选项，SO_KEEPALIVE表示保活 error = setsockopt(sfd, SOL_SOCKET, SO_KEEPALIVE, (void *)\u0026amp;flags, sizeof(flags)); if (error != 0) perror(\u0026#34;setsockopt\u0026#34;); //设定socket选项，SO_LINGER表示执行close操作时，如果缓冲区还有数据，可以继续发送 error = setsockopt(sfd, SOL_SOCKET, SO_LINGER, (void *)\u0026amp;ling, sizeof(ling)); if (error != 0) perror(\u0026#34;setsockopt\u0026#34;); //设定IP选项，TCP_NODELAY表示禁用Nagle算法 error = setsockopt(sfd, IPPROTO_TCP, TCP_NODELAY, (void *)\u0026amp;flags, sizeof(flags)); if (error != 0) perror(\u0026#34;setsockopt\u0026#34;); } if (bind(sfd, next-\u0026gt;ai_addr, next-\u0026gt;ai_addrlen) == -1) { if (errno != EADDRINUSE) { perror(\u0026#34;bind()\u0026#34;); close(sfd); freeaddrinfo(ai); return 1; } close(sfd); continue; } else { success++; //如果不是UDP协议，则执行监听操作，监听队列为初始启动的值 if (!IS_UDP(transport) \u0026amp;\u0026amp; listen(sfd, settings.backlog) == -1) { perror(\u0026#34;listen()\u0026#34;); close(sfd); freeaddrinfo(ai); return 1; } if (portnumber_file != NULL \u0026amp;\u0026amp; (next-\u0026gt;ai_addr-\u0026gt;sa_family == AF_INET || next-\u0026gt;ai_addr-\u0026gt;sa_family == AF_INET6)) { union { struct sockaddr_in in; struct sockaddr_in6 in6; } my_sockaddr; socklen_t len = sizeof(my_sockaddr); //这时还没连接建立，调用getsockname不知道有什么用？ if (getsockname(sfd, (struct sockaddr*) \u0026amp;my_sockaddr, \u0026amp;len) == 0) { if (next-\u0026gt;ai_addr-\u0026gt;sa_family == AF_INET) { fprintf(portnumber_file, \u0026#34;%s INET: %u\\n\u0026#34;, IS_UDP(transport) ? \u0026#34;UDP\u0026#34; : \u0026#34;TCP\u0026#34;, ntohs(my_sockaddr.in.sin_port)); } else { fprintf(portnumber_file, \u0026#34;%s INET6: %u\\n\u0026#34;, IS_UDP(transport) ? \u0026#34;UDP\u0026#34; : \u0026#34;TCP\u0026#34;, ntohs(my_sockaddr.in6.sin6_port)); } } } } if (IS_UDP(transport)) { int c; for (c = 0; c \u0026lt; settings.num_threads_per_udp; c++) { //分发连接，因为UDP没有连接建立的过程，直接进行连接的分发 dispatch_conn_new(sfd, conn_read, EV_READ | EV_PERSIST, UDP_READ_BUFFER_SIZE, transport); } } else { //TCP,建立连接 if (!(listen_conn_add = conn_new(sfd, conn_listening, EV_READ | EV_PERSIST, 1, transport, main_base))) { fprintf(stderr, \u0026#34;failed to create listening connection\\n\u0026#34;); exit(EXIT_FAILURE); } //建立的连接组成链表 listen_conn_add-\u0026gt;next = listen_conn; listen_conn = listen_conn_add; //释放资源 freeaddrinfo(ai); return success == 0; } //建立socket static int new_socket(struct addrinfo *ai) { int sfd; int flags; //调用系统函数建立socket if ((sfd = socket(ai-\u0026gt;ai_family, ai-\u0026gt;ai_socktype, ai-\u0026gt;ai_protocol)) == -1) { return -1; } //设定socket为非阻塞的 if ((flags = fcntl(sfd, F_GETFL, 0)) \u0026lt; 0 || fcntl(sfd, F_SETFL, flags | O_NONBLOCK) \u0026lt; 0) { perror(\u0026#34;setting O_NONBLOCK\u0026#34;); close(sfd); return -1; } return sfd; } //如果是UDP协议，调整发送缓存到最大值 static void maximize_sndbuf(const int sfd) { socklen_t intsize = sizeof(int); int last_good = 0; int min, max, avg; int old_size; //读取socket的选项，SO_SNDBF表示发送缓存 if (getsockopt(sfd, SOL_SOCKET, SO_SNDBUF, \u0026amp;old_size, \u0026amp;intsize) != 0) { if (settings.verbose \u0026gt; 0) perror(\u0026#34;getsockopt(SO_SNDBUF)\u0026#34;); return; } //二分搜索来设定，很巧的设计 min = old_size; max = MAX_SENDBUF_SIZE; while (min \u0026lt;= max) { avg = ((unsigned int)(min + max)) / 2; if (setsockopt(sfd, SOL_SOCKET, SO_SNDBUF, (void *)\u0026amp;avg, intsize) == 0) { last_good = avg; min = avg + 1; } else { max = avg - 1; } } if (settings.verbose \u0026gt; 1) fprintf(stderr, \u0026#34;\u0026lt;%d send buffer was %d, now %d\\n\u0026#34;, sfd, old_size, last_good); } 至此，网络相关的部分已经完成，后向连接的建立（conn_new）和连接分发（dispatch_conn_new），我们放到其他文章中进行分析。\n","permalink":"https://haokiu.com/blog/9a03435a987949d28e30905f7a0c839b/","summary":"Memcached源码阅读二 网络监听的建立 Memcahced是一个服务器程序，所以需要建立网络监听来接受其他客户端机器的连接，下面分析下其过程，这次分析是基于Memcached 1.4.15版本分析的。\n// 如果socketpath为空，则表示使用的TCP / UDP, 不是使用unix socket //如果socketpath为空，则表示使用的TCP/UDP,不是使用unix socket if (settings.socketpath == NULL) { //可以从环境变量读取端口文件所在的文件路径 const char *portnumber_filename = getenv(\u0026#34;MEMCACHED_PORT_FILENAME\u0026#34;); char temp_portnumber_filename[PATH_MAX]; FILE *portnumber_file = NULL; //如果端口文件不为空，则打开 if (portnumber_filename != NULL) { snprintf(temp_portnumber_filename, sizeof(temp_portnumber_filename), \u0026#34;%s.lck\u0026#34;, portnumber_filename); portnumber_file = fopen(temp_portnumber_filename, \u0026#34;a\u0026#34;); if (portnumber_file == NULL) { fprintf(stderr, \u0026#34;Failed to open \\\u0026#34;%s\\\u0026#34;: %s\\n\u0026#34;, temp_portnumber_filename, strerror(errno)); } } //settings.port表示Memcached采用的是TCP协议，创建TCP Socket，监听并且绑定 errno = 0; if (settings.port \u0026amp;\u0026amp; server_sockets(settings.port, tcp_transport, portnumber_file)) { vperror(\u0026#34;failed to listen on TCP port %d\u0026#34;, settings.port); exit(EX_OSERR); } //settings.udpport表示Memcached采用的是UDP协议，创建UDP Socket，监听并且绑定 errno = 0; if (settings.udpport \u0026amp;\u0026amp; server_sockets(settings.udpport, udp_transport, portnumber_file)) { vperror(\u0026#34;failed to listen on UDP port %d\u0026#34;, settings.udpport); exit(EX_OSERR); } //端口文件不为空 if (portnumber_file) { fclose(portnumber_file);//关闭文件 rename(temp_portnumber_filename, portnumber_filename);//重命名端口文件 } } //TCP和UDP使用的是同一个接口来创建监听和绑定 static int server_sockets(int port, enum network_transport transport, FILE *portnumber_file) { //settings.","title":"Memcached源码阅读二 网络监听的建立"},{"content":"Memcached源码阅读五 资源初始化 Memcached内部有hash表，各种统计信息，工作线程，网络，连接，内存结构等，在memcached启动时(执行main函数)，会对这些资源进行初始化的，网络和内存的初始化操作放到后续分析，这次分析hash表，统计信息，工作线程，网络连接的初始化过程。\n1 hash表的初始化\n//hash表的初始化，传入的参数是启动时传入的 assoc_init(settings.hashpower_init); //hashsize的实现 #define hashsize(n) ((ub4)1\u0026lt;\u0026lt;(n)) //主hash表结构定义，在hash表扩容时，会有次hash表，所以有主次hash表区分，该结构是指针的指针，也即相当于数组指针 static item** primary_hashtable = 0; void assoc_init(const int hashtable_init) { if (hashtable_init) { //如果设置了初始化参数，则按设置的参数进行初始化 hashpower = hashtable_init; } //hashpower的默认值为16,如果未设置新值，则按默认值进行初始化 primary_hashtable = calloc(hashsize(hashpower), sizeof(void *)); if (! primary_hashtable) { fprintf(stderr, \u0026#34;Failed to init hashtable.\\n\u0026#34;); exit(EXIT_FAILURE); } STATS_LOCK();//全局统计信息加锁，保证数据同步 stats.hash_power_level = hashpower; stats.hash_bytes = hashsize(hashpower) * sizeof(void *); STATS_UNLOCK(); } 2 统计信息的初始化\nMemcached内部有很多全局的统计信息，用于实时获取各个资源的使用情况，后面将会看到，所有对统计信息的更新都需要加锁，而这些信息的更新是和Memcached的操作次数同数量级的，所以，在一定程度来说，这些统计信息对性能有影响。\nstats结构是对统计信息的一个抽象，各个字段都比较好理解，不做解释。\nstruct stats { pthread_mutex_t mutex; unsigned int curr_items; unsigned int total_items; uint64_t curr_bytes; unsigned int curr_conns; unsigned int total_conns; uint64_t rejected_conns; unsigned int reserved_fds; unsigned int conn_structs; uint64_t get_cmds; uint64_t set_cmds; uint64_t touch_cmds; uint64_t get_hits; uint64_t get_misses; uint64_t touch_hits; uint64_t touch_misses; uint64_t evictions; uint64_t reclaimed; time_t started; /* when the process was started */ bool accepting_conns; /* whether we are currently accepting */ uint64_t listen_disabled_num; unsigned int hash_power_level; /* Better hope it\u0026#39;s not over 9000 */ uint64_t hash_bytes; /* size used for hash tables */ bool hash_is_expanding; /* If the hash table is being expanded */ uint64_t expired_unfetched; /* items reclaimed but never touched */ uint64_t evicted_unfetched; /* items evicted but never touched */ bool slab_reassign_running; /* slab reassign in progress */ uint64_t slabs_moved; /* times slabs were moved around */ }; 统计信息的初始化也就是对stats变量的一个初始化。\n//全局对象的定义 struct stats stats; //全局变量的初始化，该全局变量在memcached启动之后，一直使用 static void stats_init(void) { stats.curr_items = stats.total_items = stats.curr_conns = stats.total_conns = stats.conn_structs = 0; stats.get_cmds = stats.set_cmds = stats.get_hits = stats.get_misses = stats.evictions = stats.reclaimed = 0; stats.touch_cmds = stats.touch_misses = stats.touch_hits = stats.rejected_conns = 0; stats.curr_bytes = stats.listen_disabled_num = 0; stats.hash_power_level = stats.hash_bytes = stats.hash_is_expanding = 0; stats.expired_unfetched = stats.evicted_unfetched = 0; stats.slabs_moved = 0; stats.accepting_conns = true; /* assuming we start in this state. */ stats.slab_reassign_running = false; /* make the time we started always be 2 seconds before we really did, so time(0) - time.started is never zero. if so, things like \u0026#39;settings.oldest_live\u0026#39; which act as booleans as well as values are now false in boolean context... */ process_started = time(0) - 2; stats_prefix_init(); } 3 工作线程的初始化\nMemcached采用了典型的Master-Worker的线程模式，Master就是由main线程来充当，而Worker线程则是通过Pthread创建的。\n//传入线程个数和libevent的main_base实例 thread_init(settings.num_threads, main_base); //工作线程初始化 void thread_init(int nthreads, struct event_base *main_base) { int i; int power; //初始化各种锁和条件变量 pthread_mutex_init(\u0026amp;cache_lock, NULL); pthread_mutex_init(\u0026amp;stats_lock, NULL); pthread_mutex_init(\u0026amp;init_lock, NULL); pthread_cond_init(\u0026amp;init_cond, NULL); pthread_mutex_init(\u0026amp;cqi_freelist_lock, NULL); cqi_freelist = NULL; //Memcached对hash桶的锁采用分段锁，按线程个数来分段，默认总共是1\u0026lt;\u0026lt;16个hash桶，而锁的数目是1\u0026lt;\u0026lt;power个 /* Want a wide lock table, but don\u0026#39;t waste memory */ if (nthreads \u0026lt; 3) { power = 10; } else if (nthreads \u0026lt; 4) { power = 11; } else if (nthreads \u0026lt; 5) { power = 12; } else { /* 8192 buckets, and central locks don\u0026#39;t scale much past 5 threads */ power = 13; } item_lock_count = hashsize(power); //申请1\u0026lt;\u0026lt;power个pthread_mutex_t锁，保存在item_locks数组。 item_locks = calloc(item_lock_count, sizeof(pthread_mutex_t)); if (! item_locks) { perror(\u0026#34;Can\u0026#39;t allocate item locks\u0026#34;); exit(1); } //对这些锁进行初始化，这部分可参考APUE的线程部分 for (i = 0; i \u0026lt; item_lock_count; i++) { pthread_mutex_init(\u0026amp;item_locks[i], NULL); } /*创建线程的局部变量，该局部变量的名称为item_lock_type_key,用于保存主hash表所持有的锁的类型 主hash表在进行扩容时，该锁类型会变为全局的锁，否则(不在扩容过程中)，则是局部锁*/ pthread_key_create(\u0026amp;item_lock_type_key, NULL); pthread_mutex_init(\u0026amp;item_global_lock, NULL); //申请nthreds个工作线程,LIBEVENT_THREAD是Memcached内部对工作线程的一个封装 threads = calloc(nthreads, sizeof(LIBEVENT_THREAD)); if (! threads) { perror(\u0026#34;Can\u0026#39;t allocate thread descriptors\u0026#34;); exit(1); } /*分发线程的初始化,分发线程的base为main_base 线程id为main线程的线程id*/ dispatcher_thread.base = main_base; dispatcher_thread.thread_id = pthread_self(); //工作线程的初始化,工作线程和主线程(main线程)是通过pipe管道进行通信的 for (i = 0; i \u0026lt; nthreads; i++) { int fds[2]; if (pipe(fds)) {//初始化pipe管道 perror(\u0026#34;Can\u0026#39;t create notify pipe\u0026#34;); exit(1); } threads[i].notify_receive_fd = fds[0];//读管道绑定到工作线程的接收消息的描述符 threads[i].notify_send_fd = fds[1];//写管道绑定到工作线程的发送消息的描述符 setup_thread(\u0026amp;threads[i]);//添加工作线程到libevent中 /* Reserve three fds for the libevent base, and two for the pipe */ stats.reserved_fds += 5;//统计信息更新 } //创建工作线程 for (i = 0; i \u0026lt; nthreads; i++) { create_worker(worker_libevent, \u0026amp;threads[i]); } //等待所有工作线程创建完毕 pthread_mutex_lock(\u0026amp;init_lock); wait_for_thread_registration(nthreads); pthread_mutex_unlock(\u0026amp;init_lock); } //Memcached内部工作线程的封装 typedef struct { pthread_t thread_id; //线程ID struct event_base *base; //libevent的不是线程安全的，每个工作线程持有一个libevent实例，用于pipe管道通信和socket通信 struct event notify_event; //用于监听pipe管道的libevent事件 int notify_receive_fd; //接收pipe管道消息描述符 int notify_send_fd; //发送pipe管道消息描述符 struct thread_stats stats; //每个线程对应的统计信息 struct conn_queue *new_conn_queue; //每个线程都有一个工作队列，主线程接受的连接，挂载到该消息队列中 cache_t *suffix_cache; //后缀cache uint8_t item_lock_type; //线程操作hash表持有的锁类型，有局部锁和全局锁 } LIBEVENT_THREAD; //分发线程的封装 typedef struct { pthread_t thread_id; //线程id struct event_base *base; //libevent实例 } LIBEVENT_DISPATCHER_THREAD; //工作线程绑定到libevent实例 static void setup_thread(LIBEVENT_THREAD *me) { me-\u0026gt;base = event_init();//创建libevent实例 if (! me-\u0026gt;base) { fprintf(stderr, \u0026#34;Can\u0026#39;t allocate event base\\n\u0026#34;); exit(1); } //创建管道读的libevent事件，事件的回调函数处理具体的业务信息，关于回调函数的处理，后续分析 event_set(\u0026amp;me-\u0026gt;notify_event, me-\u0026gt;notify_receive_fd, EV_READ | EV_PERSIST, thread_libevent_process, me); event_base_set(me-\u0026gt;base, \u0026amp;me-\u0026gt;notify_event);//设置libevent实例 //添加事件到libevent中 if (event_add(\u0026amp;me-\u0026gt;notify_event, 0) == -1) { fprintf(stderr, \u0026#34;Can\u0026#39;t monitor libevent notify pipe\\n\u0026#34;); exit(1); } //创建消息队列，用于接受主线程连接 me-\u0026gt;new_conn_queue = malloc(sizeof(struct conn_queue)); if (me-\u0026gt;new_conn_queue == NULL) { perror(\u0026#34;Failed to allocate memory for connection queue\u0026#34;); exit(EXIT_FAILURE); } cq_init(me-\u0026gt;new_conn_queue);//消息队列初始化 if (pthread_mutex_init(\u0026amp;me-\u0026gt;stats.mutex, NULL) != 0) { perror(\u0026#34;Failed to initialize mutex\u0026#34;); exit(EXIT_FAILURE); } //创建线程的后缀cache,没搞懂这个cache有什么作用。 me-\u0026gt;suffix_cache = cache_create(\u0026#34;suffix\u0026#34;, SUFFIX_SIZE, sizeof(char*), NULL, NULL); if (me-\u0026gt;suffix_cache == NULL) { fprintf(stderr, \u0026#34;Failed to create suffix cache\\n\u0026#34;); exit(EXIT_FAILURE); } } //创建工作线程 static void create_worker(void *(*func)(void *), void *arg) { pthread_t thread; pthread_attr_t attr; int ret; pthread_attr_init(\u0026amp;attr);//Posix线程部分，线程属性初始化 //通过pthread_create创建线程，线程处理函数是通过外部传入的处理函数为worker_libevent if ((ret = pthread_create(\u0026amp;thread, \u0026amp;attr, func, arg)) != 0) { fprintf(stderr, \u0026#34;Can\u0026#39;t create thread: %s\\n\u0026#34;, strerror(ret)); exit(1); } } //线程处理函数 static void *worker_libevent(void *arg) { LIBEVENT_THREAD *me = arg; //默认的hash表的锁为局部锁 me-\u0026gt;item_lock_type = ITEM_LOCK_GRANULAR; pthread_setspecific(item_lock_type_key, \u0026amp;me-\u0026gt;item_lock_type);//设定线程的属性 //用于控制工作线程初始化，通过条件变量来控制 register_thread_initialized(); //工作线程的libevent实例启动 event_base_loop(me-\u0026gt;base, 0); return NULL; } //阻塞工作线程 static void wait_for_thread_registration(int nthreads) { while (init_count \u0026lt; nthreads) { pthread_cond_wait(\u0026amp;init_cond, \u0026amp;init_lock);//在条件变量init_cond上面阻塞，阻塞个数为nthreads-init_count } } //唤醒工作线程 static void register_thread_initialized(void) { pthread_mutex_lock(\u0026amp;init_lock); init_count++; pthread_cond_signal(\u0026amp;init_cond); pthread_mutex_unlock(\u0026amp;init_lock); } //每个线程持有的统计信息 struct thread_stats { pthread_mutex_t mutex; uint64_t get_cmds; uint64_t get_misses; uint64_t touch_cmds; uint64_t touch_misses; uint64_t delete_misses; uint64_t incr_misses; uint64_t decr_misses; uint64_t cas_misses; uint64_t bytes_read; uint64_t bytes_written; uint64_t flush_cmds; uint64_t conn_yields; /* # of yields for connections (-R option)*/ uint64_t auth_cmds; uint64_t auth_errors; struct slab_stats slab_stats[MAX_NUMBER_OF_SLAB_CLASSES]; }; //每个slab的统计信息 struct slab_stats { uint64_t set_cmds; uint64_t get_hits; uint64_t touch_hits; uint64_t delete_hits; uint64_t cas_hits; uint64_t cas_badval; uint64_t incr_hits; uint64_t decr_hits; }; 4 连接的初始化\nstatic conn **freeconns;//空闲连接列表 //连接初始化 static void conn_init(void) { freetotal = 200;//空闲连接总数 freecurr = 0;//当前空闲的索引 //申请200个空间 if ((freeconns = calloc(freetotal, sizeof(conn *))) == NULL) { fprintf(stderr, \u0026#34;Failed to allocate connection structures\\n\u0026#34;); } return; } ","permalink":"https://haokiu.com/blog/f56b1e30eede4a21b7fd293a33a1e47a/","summary":"Memcached源码阅读五 资源初始化 Memcached内部有hash表，各种统计信息，工作线程，网络，连接，内存结构等，在memcached启动时(执行main函数)，会对这些资源进行初始化的，网络和内存的初始化操作放到后续分析，这次分析hash表，统计信息，工作线程，网络连接的初始化过程。\n1 hash表的初始化\n//hash表的初始化，传入的参数是启动时传入的 assoc_init(settings.hashpower_init); //hashsize的实现 #define hashsize(n) ((ub4)1\u0026lt;\u0026lt;(n)) //主hash表结构定义，在hash表扩容时，会有次hash表，所以有主次hash表区分，该结构是指针的指针，也即相当于数组指针 static item** primary_hashtable = 0; void assoc_init(const int hashtable_init) { if (hashtable_init) { //如果设置了初始化参数，则按设置的参数进行初始化 hashpower = hashtable_init; } //hashpower的默认值为16,如果未设置新值，则按默认值进行初始化 primary_hashtable = calloc(hashsize(hashpower), sizeof(void *)); if (! primary_hashtable) { fprintf(stderr, \u0026#34;Failed to init hashtable.\\n\u0026#34;); exit(EXIT_FAILURE); } STATS_LOCK();//全局统计信息加锁，保证数据同步 stats.hash_power_level = hashpower; stats.hash_bytes = hashsize(hashpower) * sizeof(void *); STATS_UNLOCK(); } 2 统计信息的初始化\nMemcached内部有很多全局的统计信息，用于实时获取各个资源的使用情况，后面将会看到，所有对统计信息的更新都需要加锁，而这些信息的更新是和Memcached的操作次数同数量级的，所以，在一定程度来说，这些统计信息对性能有影响。\nstats结构是对统计信息的一个抽象，各个字段都比较好理解，不做解释。\nstruct stats { pthread_mutex_t mutex; unsigned int curr_items; unsigned int total_items; uint64_t curr_bytes; unsigned int curr_conns; unsigned int total_conns; uint64_t rejected_conns; unsigned int reserved_fds; unsigned int conn_structs; uint64_t get_cmds; uint64_t set_cmds; uint64_t touch_cmds; uint64_t get_hits; uint64_t get_misses; uint64_t touch_hits; uint64_t touch_misses; uint64_t evictions; uint64_t reclaimed; time_t started; /* when the process was started */ bool accepting_conns; /* whether we are currently accepting */ uint64_t listen_disabled_num; unsigned int hash_power_level; /* Better hope it\u0026#39;s not over 9000 */ uint64_t hash_bytes; /* size used for hash tables */ bool hash_is_expanding; /* If the hash table is being expanded */ uint64_t expired_unfetched; /* items reclaimed but never touched */ uint64_t evicted_unfetched; /* items evicted but never touched */ bool slab_reassign_running; /* slab reassign in progress */ uint64_t slabs_moved; /* times slabs were moved around */ }; 统计信息的初始化也就是对stats变量的一个初始化。","title":"Memcached源码阅读五 资源初始化"},{"content":"Memcached源码阅读八 内存池 Memcached内部维护了一个内存池来减少频繁的malloc和free，在该内存池的基础上面实现了slab内存管理，下面简单介绍下内存池的实现，大家在实现类似结构时，可以做个参考。\nstatic void *mem_base = NULL;//mem_base指向新申请的内存空间，指向整个内存空间的头部 static void *mem_current = NULL;//指向已经分配过的空间，且指向已经分配了空间的尾部 static size_t mem_avail = 0;//剩余空间大小 //部分初始化操作 mem_limit = limit;//初始容量 mem_base = malloc(mem_limit);//申请内存空间 if (mem_base != NULL) //如果不为空 { mem_current = mem_base; //当前还没分配，所以其指向为整个空间 mem_avail = mem_limit; //可用空间为满 } else { fprintf(stderr, \u0026#34;Warning: Failed to allocate requested memory in\u0026#34; \u0026#34; one large chunk.\\nWill allocate in smaller chunks\\n\u0026#34;); } //分配空间的过程，分配size大小的空间 static void *memory_allocate(size_t size) { void *ret; //如果未初始化 if (mem_base == NULL) { ret = malloc(size); } else { ret = mem_current; if (size \u0026gt; mem_avail) { return NULL; } //执行对齐操作 if (size % CHUNK_ALIGN_BYTES) { size += CHUNK_ALIGN_BYTES - (size % CHUNK_ALIGN_BYTES); } mem_current = ((char*)mem_current) + size; if (size \u0026lt; mem_avail) { mem_avail -= size; } else { mem_avail = 0; } } return ret; } ","permalink":"https://haokiu.com/blog/63c41390d91c4392a0d3cc433c49a4ac/","summary":"Memcached源码阅读八 内存池 Memcached内部维护了一个内存池来减少频繁的malloc和free，在该内存池的基础上面实现了slab内存管理，下面简单介绍下内存池的实现，大家在实现类似结构时，可以做个参考。\nstatic void *mem_base = NULL;//mem_base指向新申请的内存空间，指向整个内存空间的头部 static void *mem_current = NULL;//指向已经分配过的空间，且指向已经分配了空间的尾部 static size_t mem_avail = 0;//剩余空间大小 //部分初始化操作 mem_limit = limit;//初始容量 mem_base = malloc(mem_limit);//申请内存空间 if (mem_base != NULL) //如果不为空 { mem_current = mem_base; //当前还没分配，所以其指向为整个空间 mem_avail = mem_limit; //可用空间为满 } else { fprintf(stderr, \u0026#34;Warning: Failed to allocate requested memory in\u0026#34; \u0026#34; one large chunk.\\nWill allocate in smaller chunks\\n\u0026#34;); } //分配空间的过程，分配size大小的空间 static void *memory_allocate(size_t size) { void *ret; //如果未初始化 if (mem_base == NULL) { ret = malloc(size); } else { ret = mem_current; if (size \u0026gt; mem_avail) { return NULL; } //执行对齐操作 if (size % CHUNK_ALIGN_BYTES) { size += CHUNK_ALIGN_BYTES - (size % CHUNK_ALIGN_BYTES); } mem_current = ((char*)mem_current) + size; if (size \u0026lt; mem_avail) { mem_avail -= size; } else { mem_avail = 0; } } return ret; } ","title":"Memcached源码阅读八 内存池"},{"content":"Memcached源码阅读六 get过程 我们在前面分析过，Memcached从网络读取完数据，解析数据，如果是get操作，则执行get操作，下面我们分析下get操作的流程。\n//根据key信息和key的长度信息读取数据 item *item_get(const char *key, const size_t nkey) { item *it; uint32_t hv; hv = hash(key, nkey, 0);//获得分段锁信息，如果未进行扩容，则item的hash表是多个hash桶共用同一个锁，即是分段的锁 item_lock(hv);//执行分段加锁 it = do_item_get(key, nkey, hv);//执行get操作 item_unlock(hv);//释放锁 return it; } //执行分段加锁 void item_lock(uint32_t hv) { uint8_t *lock_type = pthread_getspecific(item_lock_type_key); if (likely(*lock_type == ITEM_LOCK_GRANULAR)) { mutex_lock(\u0026amp;item_locks[(hv \u0026amp; hashmask(hashpower)) % item_lock_count]);//执行分段加锁 } else {//如果在扩容过程中 mutex_lock(\u0026amp;item_global_lock); } } //执行分段解锁 void item_unlock(uint32_t hv) { uint8_t *lock_type = pthread_getspecific(item_lock_type_key); if (likely(*lock_type == ITEM_LOCK_GRANULAR)) { mutex_unlock(\u0026amp;item_locks[(hv \u0026amp; hashmask(hashpower)) % item_lock_count]);//释放分段锁 } else {//如果在扩容过程中 mutex_unlock(\u0026amp;item_global_lock); } } //执行读取操作 item *do_item_get(const char *key, const size_t nkey, const uint32_t hv) { item *it = assoc_find(key, nkey, hv);//从Hash表中获取相应的结构 if (it != NULL) { refcount_incr(\u0026amp;it-\u0026gt;refcount);//item的引用次数+1 if (slab_rebalance_signal \u0026amp;\u0026amp; //如果正在进行slab调整，且该item是调整的对象 ((void *)it \u0026gt;= slab_rebal.slab_start \u0026amp;\u0026amp; (void *)it \u0026lt; slab_rebal.slab_end)) { do_item_unlink_nolock(it, hv);//将item从hashtable和LRU链中移除 do_item_remove(it);//删除item it = NULL;//置为空 } } int was_found = 0; //打印调试信息 if (settings.verbose \u0026gt; 2) { if (it == NULL) { fprintf(stderr, \u0026#34;\u0026gt; NOT FOUND %s\u0026#34;, key); } else { fprintf(stderr, \u0026#34;\u0026gt; FOUND KEY %s\u0026#34;, ITEM_key(it)); was_found++; } } if (it != NULL) { //判断Memcached初始化是否开启过期删除机制，如果开启，则执行删除相关操作 if (settings.oldest_live != 0 \u0026amp;\u0026amp; settings.oldest_live \u0026lt;= current_time \u0026amp;\u0026amp; it-\u0026gt;time \u0026lt;= settings.oldest_live) { do_item_unlink(it, hv);//将item从hashtable和LRU链中移除 do_item_remove(it);//删除item it = NULL; if (was_found) { fprintf(stderr, \u0026#34; -nuked by flush\u0026#34;); } //判断item是否过期 } else if (it-\u0026gt;exptime != 0 \u0026amp;\u0026amp; it-\u0026gt;exptime \u0026lt;= current_time) { do_item_unlink(it, hv);//将item从hashtable和LRU链中移除 do_item_remove(it);//删除item it = NULL; if (was_found) { fprintf(stderr, \u0026#34; -nuked by expire\u0026#34;); } } else { it-\u0026gt;it_flags |= ITEM_FETCHED;//item的标识修改为已经读取 DEBUG_REFCNT(it, \u0026#39;+\u0026#39;); } } if (settings.verbose \u0026gt; 2) fprintf(stderr, \u0026#34;\\n\u0026#34;); return it; } //移除item void do_item_remove(item *it) { MEMCACHED_ITEM_REMOVE(ITEM_key(it), it-\u0026gt;nkey, it-\u0026gt;nbytes); assert((it-\u0026gt;it_flags \u0026amp; ITEM_SLABBED) == 0);//判断item的状态是否正确 if (refcount_decr(\u0026amp;it-\u0026gt;refcount) == 0) {//修改item的引用次数 item_free(it);//释放item } } //释放item void item_free(item *it) { size_t ntotal = ITEM_ntotal(it);//获得item的大小 unsigned int clsid; assert((it-\u0026gt;it_flags \u0026amp; ITEM_LINKED) == 0);//判断item的状态是否正确 assert(it != heads[it-\u0026gt;slabs_clsid]);//item不能为LRU的头指针 assert(it != tails[it-\u0026gt;slabs_clsid]);//item不能为LRU的尾指针 assert(it-\u0026gt;refcount == 0);//释放时，需保证引用次数为0 /* so slab size changer can tell later if item is already free or not */ clsid = it-\u0026gt;slabs_clsid; it-\u0026gt;slabs_clsid = 0;//断开slabclass的链接 DEBUG_REFCNT(it, \u0026#39;F\u0026#39;); slabs_free(it, ntotal, clsid);//slabclass结构执行释放 } //slabclass结构释放 void slabs_free(void *ptr, size_t size, unsigned int id) { pthread_mutex_lock(\u0026amp;slabs_lock);//保持同步 do_slabs_free(ptr, size, id);//执行释放 pthread_mutex_unlock(\u0026amp;slabs_lock); } //slabclass结构释放 static void do_slabs_free(void *ptr, const size_t size, unsigned int id) { slabclass_t *p; item *it; assert(((item *)ptr)-\u0026gt;slabs_clsid == 0);//判断数据是否正确 assert(id \u0026gt;= POWER_SMALLEST \u0026amp;\u0026amp; id \u0026lt;= power_largest);//判断id合法性 if (id \u0026lt; POWER_SMALLEST || id \u0026gt; power_largest)//判断id合法性 return; MEMCACHED_SLABS_FREE(size, id, ptr); p = \u0026amp;slabclass[id]; it = (item *)ptr; it-\u0026gt;it_flags |= ITEM_SLABBED;//修改item的状态标识，修改为空闲 it-\u0026gt;prev = 0;//断开数据链表 it-\u0026gt;next = p-\u0026gt;slots; if (it-\u0026gt;next) it-\u0026gt;next-\u0026gt;prev = it; p-\u0026gt;slots = it; p-\u0026gt;sl_curr++;//空闲item个数+1 p-\u0026gt;requested -= size;//空间增加size return; } //将item从hashtable和LRU链中移除。是do_item_link的逆操作 void do_item_unlink(item *it, const uint32_t hv) { MEMCACHED_ITEM_UNLINK(ITEM_key(it), it-\u0026gt;nkey, it-\u0026gt;nbytes); mutex_lock(\u0026amp;cache_lock);//执行同步 if ((it-\u0026gt;it_flags \u0026amp; ITEM_LINKED) != 0) {//判断状态值，保证item还在LRU队列中 it-\u0026gt;it_flags \u0026amp;= ~ITEM_LINKED;//修改状态值 STATS_LOCK();//更新统计信息 stats.curr_bytes -= ITEM_ntotal(it); stats.curr_items -= 1; STATS_UNLOCK(); assoc_delete(ITEM_key(it), it-\u0026gt;nkey, hv);//从Hash表中删除 item_unlink_q(it);//将item从slabclass对应的LRU队列摘除 do_item_remove(it);//移除item } mutex_unlock(\u0026amp;cache_lock); } Memcached的get操作在读取数据时，会判断数据的有效性，使得不用额外去处理过期数据，get操作牵涉到Slab结构，Hash表，LRU队列的更新，我们后面专门分析这些的变更，这里暂不分析。\n","permalink":"https://haokiu.com/blog/9dbcb2b8ef6b4cdbab38c3845d520ef0/","summary":"Memcached源码阅读六 get过程 我们在前面分析过，Memcached从网络读取完数据，解析数据，如果是get操作，则执行get操作，下面我们分析下get操作的流程。\n//根据key信息和key的长度信息读取数据 item *item_get(const char *key, const size_t nkey) { item *it; uint32_t hv; hv = hash(key, nkey, 0);//获得分段锁信息，如果未进行扩容，则item的hash表是多个hash桶共用同一个锁，即是分段的锁 item_lock(hv);//执行分段加锁 it = do_item_get(key, nkey, hv);//执行get操作 item_unlock(hv);//释放锁 return it; } //执行分段加锁 void item_lock(uint32_t hv) { uint8_t *lock_type = pthread_getspecific(item_lock_type_key); if (likely(*lock_type == ITEM_LOCK_GRANULAR)) { mutex_lock(\u0026amp;item_locks[(hv \u0026amp; hashmask(hashpower)) % item_lock_count]);//执行分段加锁 } else {//如果在扩容过程中 mutex_lock(\u0026amp;item_global_lock); } } //执行分段解锁 void item_unlock(uint32_t hv) { uint8_t *lock_type = pthread_getspecific(item_lock_type_key); if (likely(*lock_type == ITEM_LOCK_GRANULAR)) { mutex_unlock(\u0026amp;item_locks[(hv \u0026amp; hashmask(hashpower)) % item_lock_count]);//释放分段锁 } else {//如果在扩容过程中 mutex_unlock(\u0026amp;item_global_lock); } } //执行读取操作 item *do_item_get(const char *key, const size_t nkey, const uint32_t hv) { item *it = assoc_find(key, nkey, hv);//从Hash表中获取相应的结构 if (it !","title":"Memcached源码阅读六 get过程"},{"content":"Memcached源码阅读十 Hash表操作 Memcached的Hash表用来提高数据访问性能，通过链接法来解决Hash冲突，当Hash表中数据多余Hash表容量的1.5倍时，Hash表就会扩容，Memcached的Hash表操作没什么特别的，我们这里简单介绍下Memcached里面的Hash表操作。\n//hash表插入元素 int assoc_insert(item *it, const uint32_t hv) { unsigned int oldbucket; //如果已经开始扩容，且扩容的桶编号大于目前的item所在桶的编号 if (expanding \u0026amp;\u0026amp; (oldbucket = (hv \u0026amp; hashmask(hashpower - 1))) \u0026gt;= expand_bucket) { //这里是类似单链表的，按单链表的操作进行插入 it-\u0026gt;h_next = old_hashtable[oldbucket]; old_hashtable[oldbucket] = it; } else { //已经扩容，则按新的Hash规则进行路由 it-\u0026gt;h_next = primary_hashtable[hv \u0026amp; hashmask(hashpower)]; //这里在新的Hash表中执行单链表插入 primary_hashtable[hv \u0026amp; hashmask(hashpower)] = it; } hash_items++;//元素个数+1 if (! expanding \u0026amp;\u0026amp; hash_items \u0026gt; (hashsize(hashpower) * 3) / 2) { //开始扩容 assoc_start_expand();//唤醒扩容条件变量 } MEMCACHED_ASSOC_INSERT(ITEM_key(it), it-\u0026gt;nkey, hash_items); return 1; } //hash表删除元素 void assoc_delete(const char *key, const size_t nkey, const uint32_t hv) { item **before = _hashitem_before(key, nkey, hv); //获得item对应的桶的前一个元素 if (*before) { item *nxt; hash_items--;//元素个数-1 MEMCACHED_ASSOC_DELETE(key, nkey, hash_items); nxt = (*before)-\u0026gt;h_next;//执行单链表的删除操作 (*before)-\u0026gt;h_next = 0; *before = nxt; return; } assert(*before != 0); } 像Hash表的扩容，初始化等已经在其他博客中介绍过了，这里就不在阐述。\n","permalink":"https://haokiu.com/blog/857ca75e1a154abc91281759ea864d5c/","summary":"Memcached源码阅读十 Hash表操作 Memcached的Hash表用来提高数据访问性能，通过链接法来解决Hash冲突，当Hash表中数据多余Hash表容量的1.5倍时，Hash表就会扩容，Memcached的Hash表操作没什么特别的，我们这里简单介绍下Memcached里面的Hash表操作。\n//hash表插入元素 int assoc_insert(item *it, const uint32_t hv) { unsigned int oldbucket; //如果已经开始扩容，且扩容的桶编号大于目前的item所在桶的编号 if (expanding \u0026amp;\u0026amp; (oldbucket = (hv \u0026amp; hashmask(hashpower - 1))) \u0026gt;= expand_bucket) { //这里是类似单链表的，按单链表的操作进行插入 it-\u0026gt;h_next = old_hashtable[oldbucket]; old_hashtable[oldbucket] = it; } else { //已经扩容，则按新的Hash规则进行路由 it-\u0026gt;h_next = primary_hashtable[hv \u0026amp; hashmask(hashpower)]; //这里在新的Hash表中执行单链表插入 primary_hashtable[hv \u0026amp; hashmask(hashpower)] = it; } hash_items++;//元素个数+1 if (! expanding \u0026amp;\u0026amp; hash_items \u0026gt; (hashsize(hashpower) * 3) / 2) { //开始扩容 assoc_start_expand();//唤醒扩容条件变量 } MEMCACHED_ASSOC_INSERT(ITEM_key(it), it-\u0026gt;nkey, hash_items); return 1; } //hash表删除元素 void assoc_delete(const char *key, const size_t nkey, const uint32_t hv) { item **before = _hashitem_before(key, nkey, hv); //获得item对应的桶的前一个元素 if (*before) { item *nxt; hash_items--;//元素个数-1 MEMCACHED_ASSOC_DELETE(key, nkey, hash_items); nxt = (*before)-\u0026gt;h_next;//执行单链表的删除操作 (*before)-\u0026gt;h_next = 0; *before = nxt; return; } assert(*before !","title":"Memcached源码阅读十 Hash表操作"},{"content":"Memcached源码阅读十一 LRU操作 LRU是最近最少使用的简称，该技术经常用来实现cache数据更新，Memcached使用LRU技术来淘汰老的数据，Memcached默认是启用LRU操作的，在这种情况下所有的set操作都会成功，如果Memcached的内存池已经使用完，则会淘汰老数据来存放新数据，如果关闭了Memcached的LRU，则当Memcached没有多余的内存空间时，Memcached之间返回错误，下面我们分析下LRU的相关操作。\n里面再附一张Memcached的内存结构图，从图中可以看到LRU队列保持这已经分配出去的item的结构（图中指针为单链表，这里画的有误，其实是双向链表），同时每个slabclass由两个指针来维护该表，即heads和tails指针，分别指向最老的数据和最新的数据，这样便于LRU链表的操作。\n//每个slabclass各有一个指针 static item *heads[LARGEST_ID]; static item *tails[LARGEST_ID]; //将item加入到对应classid的LRU链的head，这里是item加入到LRU链表中 static void item_link_q(item *it) { /* item is the new head */ item **head, **tail; assert(it-\u0026gt;slabs_clsid \u0026lt; LARGEST_ID); assert((it-\u0026gt;it_flags \u0026amp; ITEM_SLABBED) == 0); head = \u0026amp;heads[it-\u0026gt;slabs_clsid]; tail = \u0026amp;tails[it-\u0026gt;slabs_clsid]; assert(it != *head); assert((*head \u0026amp;\u0026amp; *tail) || (*head == 0 \u0026amp;\u0026amp; *tail == 0)); it-\u0026gt;prev = 0; it-\u0026gt;next = *head; if (it-\u0026gt;next) it-\u0026gt;next-\u0026gt;prev = it;//执行插入数据操作 *head = it; if (*tail == 0) *tail = it; sizes[it-\u0026gt;slabs_clsid]++; return; } //将item从对应classid的LRU链上移除，这里是item从LRU链表中删除 static void item_unlink_q(item *it) { item **head, **tail; assert(it-\u0026gt;slabs_clsid \u0026lt; LARGEST_ID); head = \u0026amp;heads[it-\u0026gt;slabs_clsid]; tail = \u0026amp;tails[it-\u0026gt;slabs_clsid]; if (*head == it) { assert(it-\u0026gt;prev == 0); *head = it-\u0026gt;next; } if (*tail == it) { assert(it-\u0026gt;next == 0); *tail = it-\u0026gt;prev; } assert(it-\u0026gt;next != it); assert(it-\u0026gt;prev != it); if (it-\u0026gt;next) it-\u0026gt;next-\u0026gt;prev = it-\u0026gt;prev;//断开连接 if (it-\u0026gt;prev) it-\u0026gt;prev-\u0026gt;next = it-\u0026gt;next; sizes[it-\u0026gt;slabs_clsid]--; return; } 注：图片链接自 http://kenby.iteye.com/blog/1423989\n","permalink":"https://haokiu.com/blog/1e01253c10f9435e84a4106aa149ab68/","summary":"Memcached源码阅读十一 LRU操作 LRU是最近最少使用的简称，该技术经常用来实现cache数据更新，Memcached使用LRU技术来淘汰老的数据，Memcached默认是启用LRU操作的，在这种情况下所有的set操作都会成功，如果Memcached的内存池已经使用完，则会淘汰老数据来存放新数据，如果关闭了Memcached的LRU，则当Memcached没有多余的内存空间时，Memcached之间返回错误，下面我们分析下LRU的相关操作。\n里面再附一张Memcached的内存结构图，从图中可以看到LRU队列保持这已经分配出去的item的结构（图中指针为单链表，这里画的有误，其实是双向链表），同时每个slabclass由两个指针来维护该表，即heads和tails指针，分别指向最老的数据和最新的数据，这样便于LRU链表的操作。\n//每个slabclass各有一个指针 static item *heads[LARGEST_ID]; static item *tails[LARGEST_ID]; //将item加入到对应classid的LRU链的head，这里是item加入到LRU链表中 static void item_link_q(item *it) { /* item is the new head */ item **head, **tail; assert(it-\u0026gt;slabs_clsid \u0026lt; LARGEST_ID); assert((it-\u0026gt;it_flags \u0026amp; ITEM_SLABBED) == 0); head = \u0026amp;heads[it-\u0026gt;slabs_clsid]; tail = \u0026amp;tails[it-\u0026gt;slabs_clsid]; assert(it != *head); assert((*head \u0026amp;\u0026amp; *tail) || (*head == 0 \u0026amp;\u0026amp; *tail == 0)); it-\u0026gt;prev = 0; it-\u0026gt;next = *head; if (it-\u0026gt;next) it-\u0026gt;next-\u0026gt;prev = it;//执行插入数据操作 *head = it; if (*tail == 0) *tail = it; sizes[it-\u0026gt;slabs_clsid]++; return; } //将item从对应classid的LRU链上移除，这里是item从LRU链表中删除 static void item_unlink_q(item *it) { item **head, **tail; assert(it-\u0026gt;slabs_clsid \u0026lt; LARGEST_ID); head = \u0026amp;heads[it-\u0026gt;slabs_clsid]; tail = \u0026amp;tails[it-\u0026gt;slabs_clsid]; if (*head == it) { assert(it-\u0026gt;prev == 0); *head = it-\u0026gt;next; } if (*tail == it) { assert(it-\u0026gt;next == 0); *tail = it-\u0026gt;prev; } assert(it-\u0026gt;next !","title":"Memcached源码阅读十一 LRU操作"},{"content":"Memcached源码阅读十七 状态机 按我们之前的描述，Master线程建立连接之后，分发给Worker线程，而Worker线程处理业务逻辑时，会进入状态机，状态机按不同的状态处理业务逻辑，我们在分析连接分发时，已经看到了Master线程进入状态机时在有新连接建立的时候，后续的状态都是业务逻辑的状态，其处理流程如下图所示：\n共有10个状态（代码中的状态不止这些，有些没什么用，此处就没展现），状态listenning状态是Master建立连接的过程，我们已经分析过了，我们接下来分不同的文章分析其余的9中状态。\nenum conn_states { conn_listening, //监听状态 conn_new_cmd, //为新连接做一些准备 conn_waiting, //等待读取一个数据包 conn_read, //读取网络数据 conn_parse_cmd, //解析缓冲区的数据 conn_write, //简单的回复数据 conn_nread, //读取固定数据的网络数据 conn_swallow, //处理不需要的写缓冲区的数据 conn_closing, //关闭连接 conn_mwrite, //顺序的写多个item数据 conn_max_state //最大状态，做断言使用 }; 这篇文件先分析conn_new_cmd和conn_wating状态，子线程最初进入的状态就是conn_new_cmd状态，这个状态主要是做一些清理。\ncase conn_new_cmd: //全局变量，记录每个libevent实例处理的事件，通过初始启动参数配置 --nreqs; //还可以处理请求 if (nreqs \u0026gt;= 0) { //整理缓冲区 reset_cmd_handler(c); } //拒绝请求 else { pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); c-\u0026gt;thread-\u0026gt;stats.conn_yields++;//更新统计数据 pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); //如果缓冲区有数据，则需要处理 if (c-\u0026gt;rbytes \u0026gt; 0) { //更新libevent状态 if (!update_event(c, EV_WRITE | EV_PERSIST)) { if (settings.verbose \u0026gt; 0) fprintf(stderr, \u0026#34;Couldn\u0026#39;t update event\\n\u0026#34;); conn_set_state(c, conn_closing);//关闭连接 } } stop = true; } break; //整理缓冲区 static void reset_cmd_handler(conn *c) { c-\u0026gt;cmd = -1; c-\u0026gt;substate = bin_no_state; //还有item if (c-\u0026gt;item != NULL) { //删除item，本篇不分析其实现，后续分析 item_remove(c-\u0026gt;item); c-\u0026gt;item = NULL; } //整理缓冲区 conn_shrink(c); //缓冲区还有数据 if (c-\u0026gt;rbytes \u0026gt; 0) { //更新状态 conn_set_state(c, conn_parse_cmd); } //如果没有数据 else { //进入等待状态，状态机没有数据要处理，就进入这个状态 conn_set_state(c, conn_waiting); } } //缩小缓冲区 static void conn_shrink(conn *c) { assert(c != NULL); //如果是UDP协议，不牵涉缓冲区管理 if (IS_UDP(c-\u0026gt;transport)) return; //读缓冲区空间大小\u0026gt;READ_BUFFER_HIGHWAT \u0026amp;\u0026amp; 已经读到的数据还没解析的数据小于 DATA_BUFFER_SIZE if (c-\u0026gt;rsize \u0026gt; READ_BUFFER_HIGHWAT \u0026amp;\u0026amp; c-\u0026gt;rbytes \u0026lt; DATA_BUFFER_SIZE) { char *newbuf; if (c-\u0026gt;rcurr != c-\u0026gt;rbuf) //目前数据是从rcurr开始的，移动数据到rbuf中 memmove(c-\u0026gt;rbuf, c-\u0026gt;rcurr, (size_t) c-\u0026gt;rbytes); //按DATA_BUFFER_SIZE扩大缓冲区 newbuf = (char *) realloc((void *) c-\u0026gt;rbuf, DATA_BUFFER_SIZE); if (newbuf) { //更新读缓冲区 c-\u0026gt;rbuf = newbuf; //更新读缓冲区大小 c-\u0026gt;rsize = DATA_BUFFER_SIZE; } c-\u0026gt;rcurr = c-\u0026gt;rbuf; } //需要写出的item的个数，也就是要发送给客户端的item的个数 if (c-\u0026gt;isize \u0026gt; ITEM_LIST_HIGHWAT) { //增大存放item的空间 item **newbuf = (item**) realloc((void *) c-\u0026gt;ilist,ITEM_LIST_INITIAL * sizeof(c-\u0026gt;ilist[0])); if (newbuf) { //更新信息 c-\u0026gt;ilist = newbuf; //更新信息 c-\u0026gt;isize = ITEM_LIST_INITIAL; } } //msghdr的个数，memcached发送消息是通过sendmsg批量发送的 if (c-\u0026gt;msgsize \u0026gt; MSG_LIST_HIGHWAT) { struct msghdr *newbuf = (struct msghdr *) realloc((void *) c-\u0026gt;msglist,MSG_LIST_INITIAL * sizeof(c-\u0026gt;msglist[0]));//增大空间 if (newbuf) { //更新信息 c-\u0026gt;msglist = newbuf; //更新信息 c-\u0026gt;msgsize = MSG_LIST_INITIAL; } } //msghdr里面iov的数量 if (c-\u0026gt;iovsize \u0026gt; IOV_LIST_HIGHWAT) { //增大空间 struct iovec *newbuf = (struct iovec *) realloc((void *) c-\u0026gt;iov,IOV_LIST_INITIAL * sizeof(c-\u0026gt;iov[0])); if (newbuf) { //更新信息 c-\u0026gt;iov = newbuf; //更新信息 c-\u0026gt;iovsize = IOV_LIST_INITIAL; } } } 从conn_new_cmd状态会进入conn_parse_cmd状态（如果有数据）或者conn_waiting（如果没有数据）状态，下面看看conn_waiting状态。\ncase conn_waiting: //修改libevent状态，读取数据 if (!update_event(c, EV_READ | EV_PERSIST)) { if (settings.verbose \u0026gt; 0) fprintf(stderr, \u0026#34;Couldn\u0026#39;t update event\\n\u0026#34;); conn_set_state(c, conn_closing); break; } //进入读数据状态 conn_set_state(c, conn_read); stop = true; break; //更新libevent状态，也就是删除libevent事件后，重新注册libevent事件 static bool update_event(conn *c, const int new_flags) { assert(c != NULL); struct event_base *base = c-\u0026gt;event.ev_base; if (c-\u0026gt;ev_flags == new_flags) return true; //删除旧的事件 if (event_del(\u0026amp;c-\u0026gt;event) == -1) return false; //注册新事件 event_set(\u0026amp;c-\u0026gt;event, c-\u0026gt;sfd, new_flags, event_handler, (void *) c); event_base_set(base, \u0026amp;c-\u0026gt;event); c-\u0026gt;ev_flags = new_flags; if (event_add(\u0026amp;c-\u0026gt;event, 0) == -1) return false; return true; } conn_wating状态是在等待读取数据，conn_wating通过修改libevent事件（修改为读事件）之后就进入了conn_read状态，该状态就是从网络中读取数据，下面我们详细分析conn_read状态。\ncase conn_read: res = IS_UDP(c-\u0026gt;transport) ? try_read_udp(c) : try_read_network(c);//判断采用UDP协议还是TCP协议 switch (res) { case READ_NO_DATA_RECEIVED://未读取到数据 conn_set_state(c, conn_waiting);//继续等待 break; case READ_DATA_RECEIVED://读取数据 conn_set_state(c, conn_parse_cmd);//开始解析数据 break; case READ_ERROR://读取发生错误 conn_set_state(c, conn_closing);//关闭连接 break; case READ_MEMORY_ERROR: //申请内存空间错误，继续尝试 break; } break; //采用TCP协议，从网络读取数据 static enum try_read_result try_read_network(conn *c) { enum try_read_result gotdata = READ_NO_DATA_RECEIVED; int res; int num_allocs = 0; assert(c != NULL); //rcurr标记读缓冲区的开始位置，如果不在，通过memmove调整 if (c-\u0026gt;rcurr != c-\u0026gt;rbuf) { if (c-\u0026gt;rbytes != 0) memmove(c-\u0026gt;rbuf, c-\u0026gt;rcurr, c-\u0026gt;rbytes); //rcurr指向读缓冲区起始位置 c-\u0026gt;rcurr = c-\u0026gt;rbuf; } //循环读取 while (1) { //已经读取到的数据大于读缓冲区的大小 if (c-\u0026gt;rbytes \u0026gt;= c-\u0026gt;rsize) { if (num_allocs == 4) { return gotdata; } ++num_allocs; //按2倍扩容空间 char *new_rbuf = realloc(c-\u0026gt;rbuf, c-\u0026gt;rsize * 2); //realloc发生错误，也就是申请内存失败 if (!new_rbuf) { if (settings.verbose \u0026gt; 0) fprintf(stderr, \u0026#34;Couldn\u0026#39;t realloc input buffer\\n\u0026#34;); //忽略已经读取到的数据 c-\u0026gt;rbytes = 0; out_string(c, \u0026#34;SERVER_ERROR out of memory reading request\u0026#34;); //下一个状态就是conn_closing状态 c-\u0026gt;write_and_go = conn_closing; return READ_MEMORY_ERROR; } //读缓冲区指向新的缓冲区 c-\u0026gt;rcurr = c-\u0026gt;rbuf = new_rbuf; //读缓冲区的大小扩大2倍 c-\u0026gt;rsize *= 2; } //读缓冲区剩余空间 int avail = c-\u0026gt;rsize - c-\u0026gt;rbytes; //执行网络读取，这个是非阻塞的读 res = read(c-\u0026gt;sfd, c-\u0026gt;rbuf + c-\u0026gt;rbytes, avail); //如果读取到了数据 if (res \u0026gt; 0) { pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); //更新线程的统计数据 c-\u0026gt;thread-\u0026gt;stats.bytes_read += res; pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); //返回读取到数据的状态 gotdata = READ_DATA_RECEIVED; //读取到的数据个数增加res c-\u0026gt;rbytes += res; //最多读取到avail个，如果已经读到了，则可以尝试继续读取 if (res == avail) { continue; } //否则，小于avail,表示已经没数据了，退出循环。 else { break; } } //表示已经断开网络连接了 if (res == 0) { return READ_ERROR; } //因为是非阻塞的，所以会返回下面的两个错误码 if (res == -1) { if (errno == EAGAIN || errno == EWOULDBLOCK) { break; } return READ_ERROR; } } return gotdata; } 上面描述的是TCP的数据读取，下面我们分析下UDP的数据读取，UDP是数据报的形式，读取到一个，就是一个完整的数据报，所以其处理过程简单。\n//UDP读取网络数据 static enum try_read_result try_read_udp(conn *c) { int res; assert(c != NULL); c-\u0026gt;request_addr_size = sizeof(c-\u0026gt;request_addr); //执行UDP的网络读取 res = recvfrom(c-\u0026gt;sfd, c-\u0026gt;rbuf, c-\u0026gt;rsize, 0, \u0026amp;c-\u0026gt;request_addr, \u0026amp;c-\u0026gt;request_addr_size); //UDP数据包大小大于8，已经有可能是业务数据包 if (res \u0026gt; 8) { unsigned char *buf = (unsigned char *)c-\u0026gt;rbuf; pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); //更新每个线程的统计数据 c-\u0026gt;thread-\u0026gt;stats.bytes_read += res; pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); /* Beginning of UDP packet is the request ID; save it. */ c-\u0026gt;request_id = buf[0] * 256 + buf[1]; //一些业务的特征信息判断 if (buf[4] != 0 || buf[5] != 1) { out_string(c, \u0026#34;SERVER_ERROR multi-packet request not supported\u0026#34;); return READ_NO_DATA_RECEIVED; } /* Don\u0026#39;t care about any of the rest of the header. */ res -= 8; //调整缓冲区 memmove(c-\u0026gt;rbuf, c-\u0026gt;rbuf + 8, res); c-\u0026gt;rbytes = res;//更新信息 c-\u0026gt;rcurr = c-\u0026gt;rbuf; return READ_DATA_RECEIVED; } return READ_NO_DATA_RECEIVED; } 从网络读取了数据之后，将会进入conn_parse_cmd状态，该状态是按协议来解析读取到的网络数据。\ncase conn_parse_cmd: //解析数据 if (try_read_command(c) == 0) { //如果读取到的数据不够，我们继续等待，等读取到的数据够了，再进行解 conn_set_state(c, conn_waiting); } break; //memcached支持二进制协议和文本协议 static int try_read_command(conn *c) { assert(c != NULL); assert(c-\u0026gt;rcurr \u0026lt;= (c-\u0026gt;rbuf + c-\u0026gt;rsize)); assert(c-\u0026gt;rbytes \u0026gt; 0); if (c-\u0026gt;protocol == negotiating_prot || c-\u0026gt;transport == udp_transport) { //二进制协议有标志，按标志进行区分 if ((unsigned char)c-\u0026gt;rbuf[0] == (unsigned char)PROTOCOL_BINARY_REQ) { c-\u0026gt;protocol = binary_prot;//二进制协议 } else { c-\u0026gt;protocol = ascii_prot;//文本协议 } if (settings.verbose \u0026gt; 1) { fprintf(stderr, \u0026#34;%d: Client using the %s protocol\\n\u0026#34;, c-\u0026gt;sfd, prot_text(c-\u0026gt;protocol)); } } //如果是二进制协议 if (c-\u0026gt;protocol == binary_prot) { //二进制协议读取到的数据小于二进制协议的头部长度 if (c-\u0026gt;rbytes \u0026lt; sizeof(c-\u0026gt;binary_header)) { //返回继续读数据 return 0; } else { #ifdef NEED_ALIGN //如果需要对齐，则按8字节对齐，对齐能提高CPU读取的效率 if (((long)(c-\u0026gt;rcurr)) % 8 != 0) { //调整缓冲区 memmove(c-\u0026gt;rbuf, c-\u0026gt;rcurr, c-\u0026gt;rbytes); c-\u0026gt;rcurr = c-\u0026gt;rbuf; if (settings.verbose \u0026gt; 1) { fprintf(stderr, \u0026#34;%d: Realign input buffer\\n\u0026#34;, c-\u0026gt;sfd); } } #endif protocol_binary_request_header* req;//二进制协议头 req = (protocol_binary_request_header*)c-\u0026gt;rcurr; //调试信息 if (settings.verbose \u0026gt; 1) { /* Dump the packet before we convert it to host order */ int ii; fprintf(stderr, \u0026#34;\u0026lt;%d Read binary protocol data:\u0026#34;, c-\u0026gt;sfd); for (ii = 0; ii \u0026lt; sizeof(req-\u0026gt;bytes); ++ii) { if (ii % 4 == 0) { fprintf(stderr, \u0026#34;\\n\u0026lt;%d \u0026#34;, c-\u0026gt;sfd); } fprintf(stderr, \u0026#34; 0x%02x\u0026#34;, req-\u0026gt;bytes[ii]); } fprintf(stderr, \u0026#34;\\n\u0026#34;); } c-\u0026gt;binary_header = *req; c-\u0026gt;binary_header.request.keylen = ntohs(req-\u0026gt;request.keylen); c-\u0026gt;binary_header.request.bodylen = ntohl(req-\u0026gt;request.bodylen); c-\u0026gt;binary_header.request.cas = ntohll(req-\u0026gt;request.cas); //判断魔数是否合法，魔数用来防止TCP粘包 if (c-\u0026gt;binary_header.request.magic != PROTOCOL_BINARY_REQ) { if (settings.verbose) { fprintf(stderr, \u0026#34;Invalid magic: %x\\n\u0026#34;, c-\u0026gt;binary_header.request.magic); } conn_set_state(c, conn_closing); return -1; } c-\u0026gt;msgcurr = 0; c-\u0026gt;msgused = 0; c-\u0026gt;iovused = 0; if (add_msghdr(c) != 0) { out_string(c, \u0026#34;SERVER_ERROR out of memory\u0026#34;); return 0; } c-\u0026gt;cmd = c-\u0026gt;binary_header.request.opcode; c-\u0026gt;keylen = c-\u0026gt;binary_header.request.keylen; c-\u0026gt;opaque = c-\u0026gt;binary_header.request.opaque; //清除客户端传递的cas值 c-\u0026gt;cas = 0; dispatch_bin_command(c);//协议数据处理 //更新已经读取到的字节数据 c-\u0026gt;rbytes -= sizeof(c-\u0026gt;binary_header); //更新缓冲区的路标信息 c-\u0026gt;rcurr += sizeof(c-\u0026gt;binary_header); } } } 文本协议的过程和二进制协议的过程类似，此处不分析，另外dispatch_bin_command是处理具体的（比如get,set等）操作的，和是二进制协议具体相关的，解析完一些数据之后，会进入到conn_nread的流程，也就是读取指定数目数据的过程，这个过程主要是做具体的操作了，比如get，add，set操作。\ncase bin_read_set_value: complete_update_bin(c);//执行Update操作 break; case bin_reading_get_key: process_bin_get(c);//执行get操作 break; 状态机的整个处理过程就介绍到这里，其他的状态我们就不介绍了，了解了这些之后，其实其他状态就相对容易很多。\n","permalink":"https://haokiu.com/blog/4547681a8a0d42759accab81b61267ab/","summary":"Memcached源码阅读十七 状态机 按我们之前的描述，Master线程建立连接之后，分发给Worker线程，而Worker线程处理业务逻辑时，会进入状态机，状态机按不同的状态处理业务逻辑，我们在分析连接分发时，已经看到了Master线程进入状态机时在有新连接建立的时候，后续的状态都是业务逻辑的状态，其处理流程如下图所示：\n共有10个状态（代码中的状态不止这些，有些没什么用，此处就没展现），状态listenning状态是Master建立连接的过程，我们已经分析过了，我们接下来分不同的文章分析其余的9中状态。\nenum conn_states { conn_listening, //监听状态 conn_new_cmd, //为新连接做一些准备 conn_waiting, //等待读取一个数据包 conn_read, //读取网络数据 conn_parse_cmd, //解析缓冲区的数据 conn_write, //简单的回复数据 conn_nread, //读取固定数据的网络数据 conn_swallow, //处理不需要的写缓冲区的数据 conn_closing, //关闭连接 conn_mwrite, //顺序的写多个item数据 conn_max_state //最大状态，做断言使用 }; 这篇文件先分析conn_new_cmd和conn_wating状态，子线程最初进入的状态就是conn_new_cmd状态，这个状态主要是做一些清理。\ncase conn_new_cmd: //全局变量，记录每个libevent实例处理的事件，通过初始启动参数配置 --nreqs; //还可以处理请求 if (nreqs \u0026gt;= 0) { //整理缓冲区 reset_cmd_handler(c); } //拒绝请求 else { pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); c-\u0026gt;thread-\u0026gt;stats.conn_yields++;//更新统计数据 pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); //如果缓冲区有数据，则需要处理 if (c-\u0026gt;rbytes \u0026gt; 0) { //更新libevent状态 if (!update_event(c, EV_WRITE | EV_PERSIST)) { if (settings.verbose \u0026gt; 0) fprintf(stderr, \u0026#34;Couldn\u0026#39;t update event\\n\u0026#34;); conn_set_state(c, conn_closing);//关闭连接 } } stop = true; } break; //整理缓冲区 static void reset_cmd_handler(conn *c) { c-\u0026gt;cmd = -1; c-\u0026gt;substate = bin_no_state; //还有item if (c-\u0026gt;item != NULL) { //删除item，本篇不分析其实现，后续分析 item_remove(c-\u0026gt;item); c-\u0026gt;item = NULL; } //整理缓冲区 conn_shrink(c); //缓冲区还有数据 if (c-\u0026gt;rbytes \u0026gt; 0) { //更新状态 conn_set_state(c, conn_parse_cmd); } //如果没有数据 else { //进入等待状态，状态机没有数据要处理，就进入这个状态 conn_set_state(c, conn_waiting); } } //缩小缓冲区 static void conn_shrink(conn *c) { assert(c !","title":"Memcached源码阅读十七 状态机"},{"content":"Memcached源码阅读十三 do_item_alloc操作 前面我们分析了Memcached的set操作，其set操作在经过所有的数据有效性检查之后，如果需要存储item，则会执行item的实际存储操作，我们下面分析下其过程。\n//执行item的存储操作,该操作会将item挂载到LRU表和slabcalss中 item *do_item_alloc(char *key, const size_t nkey, const int flags, const rel_time_t exptime, const int nbytes, const uint32_t cur_hv) { uint8_t nsuffix; item *it = NULL; char suffix[40]; //计算item的总大小(空间) size_t ntotal = item_make_header(nkey + 1, flags, nbytes, suffix, \u0026amp;nsuffix); //如果使用了cas if (settings.use_cas) { //增加cas的空间 ntotal += sizeof(uint64_t); } unsigned int id = slabs_clsid(ntotal); //那大小选择合适的slab if (id == 0) return 0; //执行LRU锁 mutex_lock(\u0026amp;cache_lock); //存储时，会尝试从LRU中选择合适的空间的空间 int tries = 5; //如果LRU中尝试5次还没合适的空间，则执行申请空间的操作 int tried_alloc = 0; item *search; void *hold_lock = NULL; //初始化时选择的过期时间 rel_time_t oldest_live = settings.oldest_live; search = tails[id];//第id个LRU表的尾部 for (; tries \u0026gt; 0 \u0026amp;\u0026amp; search != NULL; tries--, search=search-\u0026gt;prev) { uint32_t hv = hash(ITEM_key(search), search-\u0026gt;nkey, 0);//获取分段锁 //尝试执行锁操作，这里执行的乐观锁 if (hv != cur_hv \u0026amp;\u0026amp; (hold_lock = item_trylock(hv)) == NULL) continue; //判断item是否被锁住，item的引用次数其实充当的也是一种锁 if (refcount_incr(\u0026amp;search-\u0026gt;refcount) != 2) { refcount_decr(\u0026amp;search-\u0026gt;refcount);//更新it的引用次数 //如果it的添加时间比当前时间小于3*3600 if (search-\u0026gt;time + TAIL_REPAIR_TIME \u0026lt; current_time) { itemstats[id].tailrepairs++;//更新统计信息 search-\u0026gt;refcount = 1; do_item_unlink_nolock(search, hv);//执行分段解锁操作 } if (hold_lock) item_trylock_unlock(hold_lock);//执行分段解锁操作 continue; } //过期时间判断 if ((search-\u0026gt;exptime != 0 \u0026amp;\u0026amp; search-\u0026gt;exptime \u0026lt; current_time) || (search-\u0026gt;time \u0026lt;= oldest_live \u0026amp;\u0026amp; oldest_live \u0026lt;= current_time)) { //过期时间的判断 itemstats[id].reclaimed++; if ((search-\u0026gt;it_flags \u0026amp; ITEM_FETCHED) == 0) { itemstats[id].expired_unfetched++;//更新统计信息 } it = search; //slabclass申请合适的空间 slabs_adjust_mem_requested(it-\u0026gt;slabs_clsid, ITEM_ntotal(it), ntotal); //执行的Hash表的分段解锁操作 do_item_unlink_nolock(it, hv); it-\u0026gt;slabs_clsid = 0; } else if ((it = slabs_alloc(ntotal, id)) == NULL) { //申请失败一次 tried_alloc = 1; //关闭了LRU的 if (settings.evict_to_free == 0) { itemstats[id].outofmemory++; //统计信息更新 } else { itemstats[id].evicted++; //更新统计信息 itemstats[id].evicted_time = current_time - search-\u0026gt;time; if (search-\u0026gt;exptime != 0) itemstats[id].evicted_nonzero++; if ((search-\u0026gt;it_flags \u0026amp; ITEM_FETCHED) == 0) { itemstats[id].evicted_unfetched++; } it = search; slabs_adjust_mem_requested(it-\u0026gt;slabs_clsid, ITEM_ntotal(it), ntotal);//选择合适的slabclass空间 do_item_unlink_nolock(it, hv);//执行it的分段解锁操作 it-\u0026gt;slabs_clsid = 0; if (settings.slab_automove == 2)//如果打开了slab调整 slabs_reassign(-1, id);//唤醒调整线程 } } //更新引用次数 refcount_decr(\u0026amp;search-\u0026gt;refcount); if (hold_lock) item_trylock_unlock(hold_lock);//解分段锁 break; } //5次循环查找，未找到合适的空间 if (!tried_alloc \u0026amp;\u0026amp; (tries == 0 || search == NULL)) //则从内存池申请新的空间 it = slabs_alloc(ntotal, id); //内存池申请失败 if (it == NULL) { itemstats[id].outofmemory++;//更新统计信息 mutex_unlock(\u0026amp;cache_lock);//释放LRU锁 return NULL; } assert(it-\u0026gt;slabs_clsid == 0); assert(it != heads[id]); it-\u0026gt;refcount = 1;//更新it的引用次数 mutex_unlock(\u0026amp;cache_lock); it-\u0026gt;next = it-\u0026gt;prev = it-\u0026gt;h_next = 0;//执行初始化操作 it-\u0026gt;slabs_clsid = id;//it所属的slabclass为第id个 DEBUG_REFCNT(it, \u0026#39;*\u0026#39;); it-\u0026gt;it_flags = settings.use_cas ? ITEM_CAS : 0; it-\u0026gt;nkey = nkey;//it的key it-\u0026gt;nbytes = nbytes;//it的缓冲区的数据 memcpy(ITEM_key(it), key, nkey);//it的数据信息 it-\u0026gt;exptime = exptime;//it的过期时间 memcpy(ITEM_suffix(it), suffix, (size_t)nsuffix);//it的前缀信息 it-\u0026gt;nsuffix = nsuffix;//it的一些前缀信息 return it; } //计算item的大小 static size_t item_make_header(const uint8_t nkey, const int flags, const int nbytes, char *suffix, uint8_t *nsuffix) { //suffix限定了40个字节 *nsuffix = (uint8_t) snprintf(suffix, 40, \u0026#34; %d %d\\r\\n\u0026#34;, flags, nbytes - 2); //返回item的长度 return sizeof(item) + nkey + *nsuffix + nbytes; } //选择合适的slabclass unsigned int slabs_clsid(const size_t size) { int res = POWER_SMALLEST; if (size == 0) return 0; //按slabclass的size的选择 while (size \u0026gt; slabclass[res].size) //如果大于最大的slab的，则直接返回错误，按默认的，大于1M的申请空间失败 if (res++ == power_largest) return 0; return res; } //从内存池申请合适的空间 void slabs_adjust_mem_requested(unsigned int id, size_t old, size_t ntotal) { //slabclass加锁，保持同步 pthread_mutex_lock(\u0026amp;slabs_lock); slabclass_t *p; //判断数据合法性 if (id \u0026lt; POWER_SMALLEST || id \u0026gt; power_largest) { fprintf(stderr, \u0026#34;Internal error! Invalid slab class\\n\u0026#34;); abort(); } p = \u0026amp;slabclass[id]; //调整request信息，request表示的是old所在的slab申请空间大小 p-\u0026gt;requested = p-\u0026gt;requested - old + ntotal; pthread_mutex_unlock(\u0026amp;slabs_lock); } ","permalink":"https://haokiu.com/blog/50d829bedab44857aaf08cfd61e6c952/","summary":"Memcached源码阅读十三 do_item_alloc操作 前面我们分析了Memcached的set操作，其set操作在经过所有的数据有效性检查之后，如果需要存储item，则会执行item的实际存储操作，我们下面分析下其过程。\n//执行item的存储操作,该操作会将item挂载到LRU表和slabcalss中 item *do_item_alloc(char *key, const size_t nkey, const int flags, const rel_time_t exptime, const int nbytes, const uint32_t cur_hv) { uint8_t nsuffix; item *it = NULL; char suffix[40]; //计算item的总大小(空间) size_t ntotal = item_make_header(nkey + 1, flags, nbytes, suffix, \u0026amp;nsuffix); //如果使用了cas if (settings.use_cas) { //增加cas的空间 ntotal += sizeof(uint64_t); } unsigned int id = slabs_clsid(ntotal); //那大小选择合适的slab if (id == 0) return 0; //执行LRU锁 mutex_lock(\u0026amp;cache_lock); //存储时，会尝试从LRU中选择合适的空间的空间 int tries = 5; //如果LRU中尝试5次还没合适的空间，则执行申请空间的操作 int tried_alloc = 0; item *search; void *hold_lock = NULL; //初始化时选择的过期时间 rel_time_t oldest_live = settings.oldest_live; search = tails[id];//第id个LRU表的尾部 for (; tries \u0026gt; 0 \u0026amp;\u0026amp; search != NULL; tries--, search=search-\u0026gt;prev) { uint32_t hv = hash(ITEM_key(search), search-\u0026gt;nkey, 0);//获取分段锁 //尝试执行锁操作，这里执行的乐观锁 if (hv !","title":"Memcached源码阅读十三 do_item_alloc操作"},{"content":"Memcached源码阅读十二 set操作 之前分析了Memcached的get操作，下面分析set操作的流程。\n//存储item enum store_item_type store_item(item *item, int comm, conn* c) { enum store_item_type ret; uint32_t hv; hv = hash(ITEM_key(item), item-\u0026gt;nkey, 0);//获取Hash表的分段锁 item_lock(hv);//执行数据同步 ret = do_store_item(item, comm, c, hv);//存储item item_unlock(hv); return ret; } //存储item enum store_item_type do_store_item(item *it, int comm, conn *c,const uint32_t hv) { char *key = ITEM_key(it);//读取item对应的key item *old_it = do_item_get(key, it-\u0026gt;nkey, hv); //读取相应的item,如果没有相关的数据,old_it为NULL enum store_item_type stored = NOT_STORED;//item状态标记 item *new_it = NULL; int flags; //如果old_it不为NULL,且操作为add操作 if (old_it != NULL \u0026amp;\u0026amp; comm == NREAD_ADD) { do_item_update(old_it);//更新数据 } //old_it为空，且操作为REPLACE，则什么都不做 else if (!old_it \u0026amp;\u0026amp; (comm == NREAD_REPLACE || comm == NREAD_APPEND || comm == NREAD_PREPEND)) { //memcached的Replace操作是替换已有的数据，如果没有相关数据，则不做任何操作 } //以cas方式读取 else if (comm == NREAD_CAS) { if (old_it == NULL) //为空 { // LRU expired stored = NOT_FOUND;//修改状态 pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex);//更新Worker线程统计数据 c-\u0026gt;thread-\u0026gt;stats.cas_misses++; pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); } //old_it不为NULL，且cas属性一致 else if (ITEM_get_cas(it) == ITEM_get_cas(old_it)) { pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); c-\u0026gt;thread-\u0026gt;stats.slab_stats[old_it-\u0026gt;slabs_clsid].cas_hits++; //更新Worker线程统计信息 pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); item_replace(old_it, it, hv); //执行item的替换操作，用新的item替换老的item stored = STORED;//修改状态值 } else //old_it不为NULL,且cas属性不一致 { pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); c-\u0026gt;thread-\u0026gt;stats.slab_stats[old_it-\u0026gt;slabs_clsid].cas_badval++; //更新Worker线程统计信息 pthread_mutex_unlock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.mutex); if (settings.verbose \u0026gt; 1) { fprintf(stderr, \u0026#34;CAS: failure: expected %llu, got %llu\\n\u0026#34;, (unsigned long long) ITEM_get_cas(old_it), (unsigned long long) ITEM_get_cas(it)); } stored = EXISTS; //修改状态值，修改状态值为已经存在，且不存储最新的数据 } } else //执行其他操作的写 { //以追加的方式执行写 if (comm == NREAD_APPEND || comm == NREAD_PREPEND) { //验证cas有效性 if (ITEM_get_cas(it) != 0) { //cas验证不通过 if (ITEM_get_cas(it) != ITEM_get_cas(old_it)) { stored = EXISTS;//修改状态值为已存在 } } //状态值为没有存储,也就是cas验证通过，则执行写操作 if (stored == NOT_STORED) { flags = (int) strtol(ITEM_suffix(old_it), (char **) NULL, 10); //申请新的空间 new_it = do_item_alloc(key, it-\u0026gt;nkey, flags, old_it-\u0026gt;exptime,it-\u0026gt;nbytes + old_it-\u0026gt;nbytes - 2 , hv); if (new_it == NULL) { //空间不足 if (old_it != NULL) do_item_remove(old_it);//删除老的item return NOT_STORED; } if (comm == NREAD_APPEND)//追加方式 { memcpy(ITEM_data(new_it), ITEM_data(old_it),old_it-\u0026gt;nbytes);//老数据拷贝到新数据中 memcpy(ITEM_data(new_it) + old_it-\u0026gt;nbytes - 2,ITEM_data(it), it-\u0026gt;nbytes);//同时拷贝最近缓冲区已有的数据 } else { //这里和具体协议相关 memcpy(ITEM_data(new_it), ITEM_data(it), it-\u0026gt;nbytes);//拷贝it的数据到new_it中 memcpy(ITEM_data(new_it) + it-\u0026gt;nbytes - 2 ,ITEM_data(old_it), old_it-\u0026gt;nbytes);//同时拷贝最近缓冲区已有的数据 } it = new_it; } } if (stored == NOT_STORED) { if (old_it != NULL)//如果old_it不为空 item_replace(old_it, it, hv);//替换老的值 else do_item_link(it, hv);//重新存储数据 c-\u0026gt;cas = ITEM_get_cas(it);//获取cas值 stored = STORED; } } if (old_it != NULL) do_item_remove(old_it);//释放空间 if (new_it != NULL) do_item_remove(new_it);//释放空间 if (stored == STORED)//如果已经存储了 { c-\u0026gt;cas = ITEM_get_cas(it);//获取cas属性 } return stored; } //更新item，这个只更新时间 void do_item_update(item *it) { MEMCACHED_ITEM_UPDATE(ITEM_key(it), it-\u0026gt;nkey, it-\u0026gt;nbytes); if (it-\u0026gt;time \u0026lt; current_time - ITEM_UPDATE_INTERVAL) { //更新有时间限制 assert((it-\u0026gt;it_flags \u0026amp; ITEM_SLABBED) == 0); mutex_lock(\u0026amp;cache_lock);//保持同步 //更新LRU队列的Item if ((it-\u0026gt;it_flags \u0026amp; ITEM_LINKED) != 0) { item_unlink_q(it);//断开连接 it-\u0026gt;time = current_time;//更新item的时间 item_link_q(it);//重新添加 } mutex_unlock(\u0026amp;cache_lock); } } //用新的item替换老的item int do_item_replace(item *it, item *new_it, const uint32_t hv) { MEMCACHED_ITEM_REPLACE(ITEM_key(it), it-\u0026gt;nkey, it-\u0026gt;nbytes, ITEM_key(new_it), new_it-\u0026gt;nkey, new_it-\u0026gt;nbytes); //判断it是已经分配过的，如果未分配，则断言失败 assert((it-\u0026gt;it_flags \u0026amp; ITEM_SLABBED) == 0); do_item_unlink(it, hv);//断开连接 return do_item_link(new_it, hv);//重新添加 } 有些item的操作已经在get操作中有分析，我们此处不做分析，我们下一篇分析下Memcached内部如何选择合适的空间来存放item。\n","permalink":"https://haokiu.com/blog/a795d0b698914f3898a0896633cd92ad/","summary":"Memcached源码阅读十二 set操作 之前分析了Memcached的get操作，下面分析set操作的流程。\n//存储item enum store_item_type store_item(item *item, int comm, conn* c) { enum store_item_type ret; uint32_t hv; hv = hash(ITEM_key(item), item-\u0026gt;nkey, 0);//获取Hash表的分段锁 item_lock(hv);//执行数据同步 ret = do_store_item(item, comm, c, hv);//存储item item_unlock(hv); return ret; } //存储item enum store_item_type do_store_item(item *it, int comm, conn *c,const uint32_t hv) { char *key = ITEM_key(it);//读取item对应的key item *old_it = do_item_get(key, it-\u0026gt;nkey, hv); //读取相应的item,如果没有相关的数据,old_it为NULL enum store_item_type stored = NOT_STORED;//item状态标记 item *new_it = NULL; int flags; //如果old_it不为NULL,且操作为add操作 if (old_it != NULL \u0026amp;\u0026amp; comm == NREAD_ADD) { do_item_update(old_it);//更新数据 } //old_it为空，且操作为REPLACE，则什么都不做 else if (!old_it \u0026amp;\u0026amp; (comm == NREAD_REPLACE || comm == NREAD_APPEND || comm == NREAD_PREPEND)) { //memcached的Replace操作是替换已有的数据，如果没有相关数据，则不做任何操作 } //以cas方式读取 else if (comm == NREAD_CAS) { if (old_it == NULL) //为空 { // LRU expired stored = NOT_FOUND;//修改状态 pthread_mutex_lock(\u0026amp;c-\u0026gt;thread-\u0026gt;stats.","title":"Memcached源码阅读十二 set操作"},{"content":"Memcached源码阅读十六 线程交互 Memcached按之前的分析可以知道，其是典型的Master-Worker线程模型，这种模型很典型，其工作模型是Master绑定端口，监听网络连接，接受网络连接之后，通过线程间通信来唤醒Worker线程，Worker线程已经连接的描述符执行读写操作，这种模型简化了整个通信模型，下面分析下这个过程。\ncase conn_listening: addrlen = sizeof(addr); //Master线程(main)进入状态机之后执行accept操作，这个操作也是非阻塞的。 if ((sfd = accept(c-\u0026gt;sfd, (struct sockaddr *) \u0026amp;addr, \u0026amp;addrlen)) == -1) { //非阻塞模型，这个错误码继续等待 if (errno == EAGAIN || errno == EWOULDBLOCK) { stop = true; } //连接超载 else if (errno == EMFILE) { if (settings.verbose \u0026gt; 0) fprintf(stderr, \u0026#34;Too many open connections\\n\u0026#34;); accept_new_conns(false); stop = true; } else { perror(\u0026#34;accept()\u0026#34;); stop = true; } break; } //已经accept成功，将accept之后的描述符设置为非阻塞的 if ((flags = fcntl(sfd, F_GETFL, 0)) \u0026lt; 0 || fcntl(sfd, F_SETFL, flags | O_NONBLOCK) \u0026lt; 0) { perror(\u0026#34;setting O_NONBLOCK\u0026#34;); close(sfd); break; } //判断是否超过最大连接数 if (settings.maxconns_fast \u0026amp;\u0026amp; stats.curr_conns + stats.reserved_fd \u0026gt;= settings.maxconns - 1) { str = \u0026#34;ERROR Too many open connections\\r\\n\u0026#34;; res = write(sfd, str, strlen(str)); close(sfd); STATS_LOCK(); stats.rejected_conns++; STATS_UNLOCK(); } else { //直线连接分发 dispatch_conn_new(sfd, conn_new_cmd, EV_READ | EV_PERSIST, DATA_BUFFER_SIZE, tcp_transport); } stop = true; break; 这个是TCP的连接建立过程，由于UDP不需要建立连接，所以直接分发给Worker线程，让Worker线程进行读写操作，而TCP在建立连接之后，也执行连接分发（和UDP的一样），下面看看dispatch_conn_new内部是如何进行链接分发的。\nvoid dispatch_conn_new(int sfd, enum conn_states init_state, int event_flags, int read_buffer_size, enum network_transport transport) { //创建一个连接队列 CQ_ITEM *item = cqi_new(); char buf[1]; //通过round-robin算法选择一个线程 int tid = (last_thread + 1) % settings.num_threads; //thread数组存储了所有的工作线程 LIBEVENT_THREAD *thread = threads + tid; //缓存这次的线程编号，下次待用 last_thread = tid; //sfd表示accept之后的描述符 item-\u0026gt;sfd = sfd; item-\u0026gt;init_state = init_state; item-\u0026gt;event_flags = event_flags; item-\u0026gt;read_buffer_size = read_buffer_size; item-\u0026gt;transport = transport; //投递item信息到Worker线程的工作队列中 cq_push(thread-\u0026gt;new_conn_queue, item); MEMCACHED_CONN_DISPATCH(sfd, thread-\u0026gt;thread_id); buf[0] = \u0026#39;c\u0026#39;; //在Worker线程的notify_send_fd写入字符c，表示有连接 if (write(thread-\u0026gt;notify_send_fd, buf, 1) != 1) { perror(\u0026#34;Writing to thread notify pipe\u0026#34;); } } 投递到子线程的连接队列之后，同时，通过往子线程的PIPE管道写入字符c来，下面我们看看子线程是如何处理的？\n//子线程会在PIPE管道读上面建立libevent事件，事件回调函数是thread_libevent_process event_set(\u0026amp;me-\u0026gt;notify_event, me-\u0026gt;notify_receive_fd, EV_READ | EV_PERSIST, thread_libevent_process, me); static void thread_libevent_process(int fd, short which, void *arg) { LIBEVENT_THREAD *me = arg; CQ_ITEM *item; char buf[1]; //PIPE管道读取一个字节的数据 if (read(fd, buf, 1) != 1) if (settings.verbose \u0026gt; 0) fprintf(stderr, \u0026#34;Can\u0026#39;t read from libevent pipe\\n\u0026#34;); switch (buf[0]) { case \u0026#39;c\u0026#39;: //从连接队列读出Master线程投递的消息 item = cq_pop(me-\u0026gt;new_conn_queue); if (NULL != item) { conn *c = conn_new(item-\u0026gt;sfd, item-\u0026gt;init_state, item-\u0026gt;event_flags, item-\u0026gt;read_buffer_size, item-\u0026gt;transport, me-\u0026gt;base);//创建连接 if (c == NULL) { if (IS_UDP(item-\u0026gt;transport)) { fprintf(stderr, \u0026#34;Can\u0026#39;t listen for events on UDP socket\\n\u0026#34;); exit(1); } else { if (settings.verbose \u0026gt; 0) { fprintf(stderr, \u0026#34;Can\u0026#39;t listen for events on fd %d\\n\u0026#34;, item-\u0026gt;sfd); } close(item-\u0026gt;sfd); } } else { c-\u0026gt;thread = me; } cqi_free(item); } break; } } 之前分析过conn_new的执行流程，conn_new里面会建立sfd的网络监听libevent事件，事件回调函数为event_handler。\nevent_set(\u0026amp;c-\u0026gt;event, sfd, event_flags, event_handler, (void *) c); event_base_set(base, \u0026amp;c-\u0026gt;event); event_handler的执行流程最终会进入到业务处理的状态机中，关于状态机，后续分析。\n","permalink":"https://haokiu.com/blog/314f7e41e35f43db9facbca467726a7a/","summary":"Memcached源码阅读十六 线程交互 Memcached按之前的分析可以知道，其是典型的Master-Worker线程模型，这种模型很典型，其工作模型是Master绑定端口，监听网络连接，接受网络连接之后，通过线程间通信来唤醒Worker线程，Worker线程已经连接的描述符执行读写操作，这种模型简化了整个通信模型，下面分析下这个过程。\ncase conn_listening: addrlen = sizeof(addr); //Master线程(main)进入状态机之后执行accept操作，这个操作也是非阻塞的。 if ((sfd = accept(c-\u0026gt;sfd, (struct sockaddr *) \u0026amp;addr, \u0026amp;addrlen)) == -1) { //非阻塞模型，这个错误码继续等待 if (errno == EAGAIN || errno == EWOULDBLOCK) { stop = true; } //连接超载 else if (errno == EMFILE) { if (settings.verbose \u0026gt; 0) fprintf(stderr, \u0026#34;Too many open connections\\n\u0026#34;); accept_new_conns(false); stop = true; } else { perror(\u0026#34;accept()\u0026#34;); stop = true; } break; } //已经accept成功，将accept之后的描述符设置为非阻塞的 if ((flags = fcntl(sfd, F_GETFL, 0)) \u0026lt; 0 || fcntl(sfd, F_SETFL, flags | O_NONBLOCK) \u0026lt; 0) { perror(\u0026#34;setting O_NONBLOCK\u0026#34;); close(sfd); break; } //判断是否超过最大连接数 if (settings.maxconns_fast \u0026amp;\u0026amp; stats.curr_conns + stats.reserved_fd \u0026gt;= settings.maxconns - 1) { str = \u0026#34;ERROR Too many open connections\\r\\n\u0026#34;; res = write(sfd, str, strlen(str)); close(sfd); STATS_LOCK(); stats.","title":"Memcached源码阅读十六 线程交互"},{"content":"Memcached源码阅读十四 item结构 item是Memcached中抽象实际数据的结构，我们分析下item的一些特性，便于后续Memcached的其他特性分析。\ntypedef struct _stritem { struct _stritem *next;//item在slab中存储时，是以双链表的形式存储的,next即后向指针 struct _stritem *prev;//prev为前向指针 struct _stritem *h_next;//Hash桶中元素的链接指针 rel_time_t time;//最近访问时间 rel_time_t exptime;//过期时间 int nbytes;//数据大小 unsigned short refcount;//引用次数 uint8_t nsuffix;//不清楚什么意思? uint8_t it_flags;//不清楚什么意思? uint8_t slabs_clsid;//标记item属于哪个slabclass下 uint8_t nkey;//key的长度 union { uint64_t cas; char end; } data[];//真实的数据信息 } item; 其结构图如下所示：\nItem由两部分组成，item的属性信息和item的数据部分，属性信息解释如上，数据部分包括cas，key和真实的value信息，item在内存中的存储形式如下：\n这个图画出了部分结构，还有Hash表的结构没有画出。\n这里大概介绍了item的一些信息，后面我们会分析item插入Hash表等信息。\n","permalink":"https://haokiu.com/blog/3fee4e4314af42ee9fa58cda4aa0b839/","summary":"Memcached源码阅读十四 item结构 item是Memcached中抽象实际数据的结构，我们分析下item的一些特性，便于后续Memcached的其他特性分析。\ntypedef struct _stritem { struct _stritem *next;//item在slab中存储时，是以双链表的形式存储的,next即后向指针 struct _stritem *prev;//prev为前向指针 struct _stritem *h_next;//Hash桶中元素的链接指针 rel_time_t time;//最近访问时间 rel_time_t exptime;//过期时间 int nbytes;//数据大小 unsigned short refcount;//引用次数 uint8_t nsuffix;//不清楚什么意思? uint8_t it_flags;//不清楚什么意思? uint8_t slabs_clsid;//标记item属于哪个slabclass下 uint8_t nkey;//key的长度 union { uint64_t cas; char end; } data[];//真实的数据信息 } item; 其结构图如下所示：\nItem由两部分组成，item的属性信息和item的数据部分，属性信息解释如上，数据部分包括cas，key和真实的value信息，item在内存中的存储形式如下：\n这个图画出了部分结构，还有Hash表的结构没有画出。\n这里大概介绍了item的一些信息，后面我们会分析item插入Hash表等信息。","title":"Memcached源码阅读十四 item结构"},{"content":"Memcached源码阅读四 内存初始化 Memcached作为内存cache服务器，内存高效管理是其最重要的任务之一，Memcached使用SLAB管理其内存，SLAB内存管理直观的解释就是分配一块大的内存，之后按不同的块（48byte, 64byte, … 1M）等切分这些内存，存储业务数据时，按需选择合适的内存空间存储数据。\nMemcached首次默认分配64M的内存，之后所有的数据都是在这64M空间进行存储，在Memcached启动之后，不会对这些内存执行释放操作，这些内存只有到Memcached进程退出之后会被系统回收，下面分析下Memcached的内存初始化过程。\n//内存初始化，settings.maxbytes是Memcached初始启动参数指定的内存值大小,settings.factor是内存增长因子 slabs_init(settings.maxbytes, settings.factor, preallocate); #define POWER_SMALLEST 1 //最小slab编号 #define POWER_LARGEST 200 //首次初始化200个slab //实现内存池管理相关的静态全局变量 static size_t mem_limit = 0;//总的内存大小 static size_t mem_malloced = 0;//初始化内存的大小，这个貌似没什么用 static void *mem_base = NULL;//指向总的内存的首地址 static void *mem_current = NULL;//当前分配到的内存地址 static size_t mem_avail = 0;//当前可用的内存大小 static slabclass_t slabclass[MAX_NUMBER_OF_SLAB_CLASSES];//定义slab结合，总共200个 void slabs_init(const size_t limit, const double factor, const bool prealloc) { int i = POWER_SMALLEST - 1; //size表示申请空间的大小，其值由配置的chunk_size和单个item的大小来指定 unsigned int size = sizeof(item) + settings.chunk_size; mem_limit = limit;//mem_limit是全局变量 if (prealloc) { //支持预分配 mem_base = malloc(mem_limit);//申请地址，mem_base指向申请的地址 if (mem_base != NULL) { //mem_current指向当前地址 mem_current = mem_base; //可用内存大小为mem_limit mem_avail = mem_limit; } else { //支持预分配失败 fprintf(stderr, \u0026#34;Warning: Failed to allocate requested memory in\u0026#34; \u0026#34; one large chunk.\\nWill allocate in smaller chunks\\n\u0026#34;); } } //置空slabclass数组 memset(slabclass, 0, sizeof(slabclass)); //开始分配，i\u0026lt;200 \u0026amp;\u0026amp; 单个chunk的size\u0026lt;单个item最大大小/内存增长因子 while (++i \u0026lt; POWER_LARGEST \u0026amp;\u0026amp; size \u0026lt;= settings.item_size_max / factor) { //size执行8byte对齐 if (size % CHUNK_ALIGN_BYTES) size += CHUNK_ALIGN_BYTES - (size % CHUNK_ALIGN_BYTES); slabclass[i].size = size; //slab对应chunk的大小 slabclass[i].perslab = settings.item_size_max / slabclass[i].size; //slab对应的chunk的个数 size *= factor; //size下一个值为按增长因子的倍数增长 if (settings.verbose \u0026gt; 1) { //如果有打开调试信息，则输出调试信息 fprintf(stderr, \u0026#34;slab class %3d: chunk size %9u perslab %7u\\n\u0026#34;, i, slabclass[i].size, slabclass[i].perslab); } } //循环结束时，size已经增长到1M power_largest = i;//再增加一个slab slabclass[power_largest].size = settings.item_size_max; //slab的size为item_size_max slabclass[power_largest].perslab = 1;//chunk个数为1 //打印调试信息 if (settings.verbose \u0026gt; 1) { fprintf(stderr, \u0026#34;slab class %3d: chunk size %9u perslab %7u\\n\u0026#34;, i, slabclass[i].size, slabclass[i].perslab); } //读取环境变量T_MEMD_INITIAL_MALLOC的值 { char *t_initial_malloc = getenv(\u0026#34;T_MEMD_INITIAL_MALLOC\u0026#34;); if (t_initial_malloc) { mem_malloced = (size_t)atol(t_initial_malloc); } } if (prealloc) { //分配每个slab的内存空间，传入最大已经初始化的最大slab编号 slabs_preallocate(power_largest); } } //分配每个slab的内存空间 static void slabs_preallocate (const unsigned int maxslabs) { int i; unsigned int prealloc = 0; for (i = POWER_SMALLEST; i \u0026lt;= POWER_LARGEST; i++) { if (++prealloc \u0026gt; maxslabs) return; //执行分配操作，对第i个slabclass执行分配操作 if (do_slabs_newslab(i) == 0) { fprintf(stderr, \u0026#34;Error while preallocating slab memory!\\n\u0026#34; \u0026#34;If using -L or other prealloc options, max memory must be \u0026#34; \u0026#34;at least %d megabytes.\\n\u0026#34;, power_largest); exit(1); } } } //执行分配操作 static int do_slabs_newslab(const unsigned int id) { slabclass_t *p = \u0026amp;slabclass[id];//p指向第i个slabclass int len = settings.slab_reassign ? settings.item_size_max:p-\u0026gt;size*p-\u0026gt;perslab; char *ptr; //grow_slab_list初始化slabclass的slab_list，而slab_list中的指针指向每个slab //memory_allocate从内存池申请1M的空间 if ((mem_limit \u0026amp;\u0026amp; mem_malloced + len \u0026gt; mem_limit \u0026amp;\u0026amp; p-\u0026gt;slabs \u0026gt; 0) || (grow_slab_list(id) == 0) || ((ptr = memory_allocate((size_t)len)) == 0)) { MEMCACHED_SLABS_SLABCLASS_ALLOCATE_FAILED(id); return 0; } memset(ptr, 0, (size_t)len); //将申请的1M空间按slabclass的size进行切分 split_slab_page_into_freelist(ptr, id); p-\u0026gt;slab_list[p-\u0026gt;slabs++] = ptr;//循环分配 mem_malloced += len;//增加已经分配出去的内存数 MEMCACHED_SLABS_SLABCLASS_ALLOCATE(id); return 1; } //初始化slabclass的slab_class,而slab_list中的指针指向每个slab,id为slabclass的序号 static int grow_slab_list (const unsigned int id) { slabclass_t *p = \u0026amp;slabclass[id]; //p指向第id个slabclass; if (p-\u0026gt;slabs == p-\u0026gt;list_size) { size_t new_size = (p-\u0026gt;list_size != 0) ? p-\u0026gt;list_size * 2 : 16;//new_size如果是首次分配，则取16，否则按旧值的2倍扩容 void *new_list = realloc(p-\u0026gt;slab_list, new_size * sizeof(void *));//申请空间，这个空间是从系统分配，不是从内存池分配 if (new_list == 0) return 0; p-\u0026gt;list_size = new_size;//修改第id个slabclass的值 p-\u0026gt;slab_list = new_list; } return 1; } //从内存池分配size个空间 static void *memory_allocate(size_t size) { void *ret; if (mem_base == NULL) {//如果内存池没创建，则从系统分配 ret = malloc(size); } else { ret = mem_current; //size大于剩余的空间 if (size \u0026gt; mem_avail) { return NULL; } //按8字节对齐 if (size % CHUNK_ALIGN_BYTES) { size += CHUNK_ALIGN_BYTES - (size % CHUNK_ALIGN_BYTES); } //扣除size个空间 mem_current = ((char*)mem_current) + size; if (size \u0026lt; mem_avail) { mem_avail -= size;//更新剩余空间大小 } else { mem_avail = 0; } } return ret; } //将ptr指向的内存空间按第id个slabclass的size进行切分 static void split_slab_page_into_freelist(char *ptr, const unsigned int id) { slabclass_t *p = \u0026amp;slabclass[id]; int x; //每个slabclass有多个slab,对每个slab按slabclass对应的size进行切分 for (x = 0; x \u0026lt; p-\u0026gt;perslab; x++) { do_slabs_free(ptr, 0, id);//创建空闲item ptr += p-\u0026gt;size; } } //创建空闲item static void do_slabs_free(void *ptr, const size_t size, unsigned int id) { slabclass_t *p; item *it; assert(((item *)ptr)-\u0026gt;slabs_clsid == 0); assert(id \u0026gt;= POWER_SMALLEST \u0026amp;\u0026amp; id \u0026lt;= power_largest);//判断id有效性 if (id \u0026lt; POWER_SMALLEST || id \u0026gt; power_largest) return; MEMCACHED_SLABS_FREE(size, id, ptr); p = \u0026amp;slabclass[id]; it = (item *)ptr; it-\u0026gt;it_flags |= ITEM_SLABBED; it-\u0026gt;prev = 0; it-\u0026gt;next = p-\u0026gt;slots;//挂载到slabclass的空闲链表中 if (it-\u0026gt;next) it-\u0026gt;next-\u0026gt;prev = it; p-\u0026gt;slots = it; p-\u0026gt;sl_curr++;//空闲item个数+1 p-\u0026gt;requested -= size;//已经申请到的空间数量更新 return; } ","permalink":"https://haokiu.com/blog/c82fe349df914fb8943e4aa3231c9cad/","summary":"Memcached源码阅读四 内存初始化 Memcached作为内存cache服务器，内存高效管理是其最重要的任务之一，Memcached使用SLAB管理其内存，SLAB内存管理直观的解释就是分配一块大的内存，之后按不同的块（48byte, 64byte, … 1M）等切分这些内存，存储业务数据时，按需选择合适的内存空间存储数据。\nMemcached首次默认分配64M的内存，之后所有的数据都是在这64M空间进行存储，在Memcached启动之后，不会对这些内存执行释放操作，这些内存只有到Memcached进程退出之后会被系统回收，下面分析下Memcached的内存初始化过程。\n//内存初始化，settings.maxbytes是Memcached初始启动参数指定的内存值大小,settings.factor是内存增长因子 slabs_init(settings.maxbytes, settings.factor, preallocate); #define POWER_SMALLEST 1 //最小slab编号 #define POWER_LARGEST 200 //首次初始化200个slab //实现内存池管理相关的静态全局变量 static size_t mem_limit = 0;//总的内存大小 static size_t mem_malloced = 0;//初始化内存的大小，这个貌似没什么用 static void *mem_base = NULL;//指向总的内存的首地址 static void *mem_current = NULL;//当前分配到的内存地址 static size_t mem_avail = 0;//当前可用的内存大小 static slabclass_t slabclass[MAX_NUMBER_OF_SLAB_CLASSES];//定义slab结合，总共200个 void slabs_init(const size_t limit, const double factor, const bool prealloc) { int i = POWER_SMALLEST - 1; //size表示申请空间的大小，其值由配置的chunk_size和单个item的大小来指定 unsigned int size = sizeof(item) + settings.chunk_size; mem_limit = limit;//mem_limit是全局变量 if (prealloc) { //支持预分配 mem_base = malloc(mem_limit);//申请地址，mem_base指向申请的地址 if (mem_base != NULL) { //mem_current指向当前地址 mem_current = mem_base; //可用内存大小为mem_limit mem_avail = mem_limit; } else { //支持预分配失败 fprintf(stderr, \u0026#34;Warning: Failed to allocate requested memory in\u0026#34; \u0026#34; one large chunk.","title":"Memcached源码阅读四 内存初始化"},{"content":"Memcached源码阅读序 服务器资源调整 本篇作为Memcached源码分析的开篇，这次阅读的源码版本为: 1.4.15，开源软件各个版本之间差异比较大，同学们学习时，记得核对版本。\nmemcached的main函数位于memcached.c文件中，从main函数启动之后，会初始化一些资源和申请一些服务器资源，如下面所示：\n1 Core文件大小和进程打开文件个数限制的调整。\nif (maxcore != 0) { struct rlimit rlim_new; //获取当前Core文件大小的配置值 if (getrlimit(RLIMIT_CORE, \u0026amp;rlim) == 0) { //变量初始化为无限制 rlim_new.rlim_cur = rlim_new.rlim_max = RLIM_INFINITY; if (setrlimit(RLIMIT_CORE, \u0026amp;rlim_new) != 0)//如果设置失败 { //变量初始化为当前值的最大值 rlim_new.rlim_cur = rlim_new.rlim_max = rlim.rlim_max; (void) setrlimit(RLIMIT_CORE, \u0026amp;rlim_new);//重新进行设置 } } //再次确认Core文件允许的大小，如果当前的Core文件的大小为0，则不允许Core文件产生，和maxcore!=0不符，程序结束 if ((getrlimit(RLIMIT_CORE, \u0026amp;rlim) != 0) || rlim.rlim_cur == 0) { fprintf(stderr, \u0026#34;failed to ensure corefile creation\\n\u0026#34;); exit(EX_OSERR); } } //读取进程允许打开的文件数信息，读取失败，程序退出 if (getrlimit(RLIMIT_NOFILE, \u0026amp;rlim) != 0) { fprintf(stderr, \u0026#34;failed to getrlimit number of files\\n\u0026#34;); exit(EX_OSERR); } else { //按memcached启动时的指定的最大连接数进行设置 rlim.rlim_cur = settings.maxconns; rlim.rlim_max = settings.maxconns; if (setrlimit(RLIMIT_NOFILE, \u0026amp;rlim) != 0) { fprintf(stderr, \u0026#34;failed to set rlimit for open files. Try starting as root or requesting smaller maxconns value.\\n\u0026#34;); exit(EX_OSERR); } } 2 启动用户的选择。\n//uid==0表示以root运行程序 if (getuid() == 0 || geteuid() == 0) { //以root运行程序，同时未指定新的用户名称 if (username == 0 || *username == \u0026#39;\\0\u0026#39;) { fprintf(stderr, \u0026#34;can\u0026#39;t run as root without the -u switch\\n\u0026#34;); exit(EX_USAGE); } //判断是否存在指定的用户名称 if ((pw = getpwnam(username)) == 0) { fprintf(stderr, \u0026#34;can\u0026#39;t find the user %s to switch to\\n\u0026#34;, username); exit(EX_NOUSER); } //按新的用户修改memcached的执行权限位 if (setgid(pw-\u0026gt;pw_gid) \u0026lt; 0 || setuid(pw-\u0026gt;pw_uid) \u0026lt; 0) { fprintf(stderr, \u0026#34;failed to assume identity of user %s\\n\u0026#34;, username); exit(EX_OSERR); } } 3 以daemon的方式启动，daemon的实现如下，该daemon没有进行2次fork，APUE上面也有说第二次fork不是必须的。\nint daemonize(int nochdir, int noclose) { int fd; //首先fork一次 switch (fork()) { case -1://fork失败，程序结束 return (-1); case 0://子进程执行下面的流程 break; default://父进程安全退出 _exit(EXIT_SUCCESS); } //setsid调用成功之后，返回新的会话的ID，调用setsid函数的进程成为新的会话的领头进程，并与其父进程的会话组和进程组脱离 if (setsid() == -1) return (-1); if (nochdir == 0) { //进程的当前目录切换到根目录下，根目录是一直存在的，其他的目录就不保证 if(chdir(\u0026#34;/\u0026#34;) != 0) { perror(\u0026#34;chdir\u0026#34;); return (-1); } } if (noclose == 0 \u0026amp;\u0026amp; (fd = open(\u0026#34;/dev/null\u0026#34;, O_RDWR, 0)) != -1) { if(dup2(fd, STDIN_FILENO) \u0026lt; 0) {//将标准输入重定向到/dev/null下 perror(\u0026#34;dup2 stdin\u0026#34;); return (-1); } if(dup2(fd, STDOUT_FILENO) \u0026lt; 0) {//将标准输出重定向到/dev/null下 perror(\u0026#34;dup2 stdout\u0026#34;); return (-1); } if(dup2(fd, STDERR_FILENO) \u0026lt; 0) {//将标准错误重定向到/dev/null下 perror(\u0026#34;dup2 stderr\u0026#34;); return (-1); } if (fd \u0026gt; STDERR_FILENO) { if(close(fd) \u0026lt; 0) {//大于2的描述符都可以关闭 perror(\u0026#34;close\u0026#34;); return (-1); } } } return (0); } 4 锁定内存，默认分配的内存都是虚拟内存，在程序执行过程中可以按需换出，如果内存充足的话，可以锁定内存，不让系统将该进程所持有的内存换出。\nif (lock_memory) { #ifdef HAVE_MLOCKALL int res = mlockall(MCL_CURRENT | MCL_FUTURE); if (res != 0) { fprintf(stderr, \u0026#34;warning: -k invalid, mlockall() failed: %s\\n\u0026#34;, strerror(errno)); } #else fprintf(stderr, \u0026#34;warning: -k invalid, mlockall() not supported on this platform. proceeding without.\\n\u0026#34;); #endif } 5 忽略PIPE信号，PIPE信号是当网络连接一端已经断开，这时发送数据，会进行RST的重定向，再次发送数据，会触发PIPE信号，而PIPE信号的默认动作是退出进程，所以需要忽略该信号。\nif (sigignore(SIGPIPE) == -1) { perror(\u0026#34;failed to ignore SIGPIPE; sigaction\u0026#34;); exit(EX_OSERR); } 6 保存daemon进程的进程id到文件中，这样便于控制程序，读取文件内容，即可得到进程ID。\nif (pid_file != NULL) { save_pid(pid_file); } ","permalink":"https://haokiu.com/blog/8f65d01cc42d4c8782d95eed02dd4eb5/","summary":"Memcached源码阅读序 服务器资源调整 本篇作为Memcached源码分析的开篇，这次阅读的源码版本为: 1.4.15，开源软件各个版本之间差异比较大，同学们学习时，记得核对版本。\nmemcached的main函数位于memcached.c文件中，从main函数启动之后，会初始化一些资源和申请一些服务器资源，如下面所示：\n1 Core文件大小和进程打开文件个数限制的调整。\nif (maxcore != 0) { struct rlimit rlim_new; //获取当前Core文件大小的配置值 if (getrlimit(RLIMIT_CORE, \u0026amp;rlim) == 0) { //变量初始化为无限制 rlim_new.rlim_cur = rlim_new.rlim_max = RLIM_INFINITY; if (setrlimit(RLIMIT_CORE, \u0026amp;rlim_new) != 0)//如果设置失败 { //变量初始化为当前值的最大值 rlim_new.rlim_cur = rlim_new.rlim_max = rlim.rlim_max; (void) setrlimit(RLIMIT_CORE, \u0026amp;rlim_new);//重新进行设置 } } //再次确认Core文件允许的大小，如果当前的Core文件的大小为0，则不允许Core文件产生，和maxcore!=0不符，程序结束 if ((getrlimit(RLIMIT_CORE, \u0026amp;rlim) != 0) || rlim.rlim_cur == 0) { fprintf(stderr, \u0026#34;failed to ensure corefile creation\\n\u0026#34;); exit(EX_OSERR); } } //读取进程允许打开的文件数信息，读取失败，程序退出 if (getrlimit(RLIMIT_NOFILE, \u0026amp;rlim) != 0) { fprintf(stderr, \u0026#34;failed to getrlimit number of files\\n\u0026#34;); exit(EX_OSERR); } else { //按memcached启动时的指定的最大连接数进行设置 rlim.rlim_cur = settings.maxconns; rlim.rlim_max = settings.maxconns; if (setrlimit(RLIMIT_NOFILE, \u0026amp;rlim) != 0) { fprintf(stderr, \u0026#34;failed to set rlimit for open files.","title":"Memcached源码阅读序 服务器资源调整"},{"content":"Memcached阅读十五 Hash表扩容 Hash表是Memcached里面最重要的结构之一，其采用链接法来处理Hash冲突，当Hash表中的项太多时，也就是Hash冲突比较高的时候，Hash表的遍历就脱变成单链表，此时为了提供Hash的性能，Hash表需要扩容，Memcached的扩容条件是当表中元素个数超过Hash容量的1.5倍时就进行扩容，扩容过程由独立的线程来完成，扩容过程中会采用2个Hash表，将老表中的数据通过Hash算法映射到新表中，每次移动的桶的数目可以配置，默认是每次移动老表中的1个桶。\n//hash表中增加元素 int assoc_insert(item *it, const uint32_t hv) { unsigned int oldbucket; //如果已经进行扩容且目前进行扩容还没到需要插入元素的桶，则将元素添加到旧桶中 if (expanding \u0026amp;\u0026amp;(oldbucket = (hv \u0026amp; hashmask(hashpower - 1))) \u0026gt;= expand_bucket) { //添加元素 it-\u0026gt;h_next = old_hashtable[oldbucket]; old_hashtable[oldbucket] = it; } else { //如果没扩容，或者扩容已经到了新的桶中，则添加元素到新表中 it-\u0026gt;h_next = primary_hashtable[hv \u0026amp; hashmask(hashpower)];//添加元素 primary_hashtable[hv \u0026amp; hashmask(hashpower)] = it; } hash_items++;//元素数目+1 //还没开始扩容，且表中元素个数已经超过Hash表容量的1.5倍 if (! expanding \u0026amp;\u0026amp; hash_items \u0026gt; (hashsize(hashpower) * 3) / 2) { //唤醒扩容线程 assoc_start_expand(); } MEMCACHED_ASSOC_INSERT(ITEM_key(it), it-\u0026gt;nkey, hash_items); return 1; } //唤醒扩容线程 static void assoc_start_expand(void) { if (started_expanding) return; started_expanding = true; //唤醒信号量 pthread_cond_signal(\u0026amp;maintenance_cond); } //启动扩容线程，扩容线程在main函数中会启动，启动运行一遍之后会阻塞在条件变量maintenance_cond上面，插入元素超过规定，唤醒条件变量 static void *assoc_maintenance_thread(void *arg) { //do_run_maintenance_thread的值为1，即该线程持续运行 while (do_run_maintenance_thread) { int ii = 0; item_lock_global();//加Hash表的全局锁 mutex_lock(\u0026amp;cache_lock);//加cache_lock锁 //执行扩容时，每次按hash_bulk_move个桶来扩容 for (ii = 0; ii \u0026lt; hash_bulk_move \u0026amp;\u0026amp; expanding; ++ii) { item *it, *next; int bucket; //老表每次移动一个桶中的一个元素 for (it = old_hashtable[expand_bucket]; NULL != it; it = next) { //要移动的下一个元素 next = it-\u0026gt;h_next; //按新的Hash规则进行定位 bucket = hash(ITEM_key(it), it-\u0026gt;nkey, 0) \u0026amp; hashmask(hashpower); it-\u0026gt;h_next = primary_hashtable[bucket];//挂载到新的Hash表中 primary_hashtable[bucket] = it; } //旧表中的这个Hash桶已经按新规则完成了扩容 old_hashtable[expand_bucket] = NULL; //老表中的桶计数+1 expand_bucket++; //hash表扩容结束,expand_bucket从0开始,一直递增 if (expand_bucket == hashsize(hashpower - 1)) { //修改扩容标志 expanding = false; //释放老的表结构 free(old_hashtable); //更新一些统计信息 STATS_LOCK(); stats.hash_bytes -= hashsize(hashpower - 1) * sizeof(void *); stats.hash_is_expanding = 0; STATS_UNLOCK(); if (settings.verbose \u0026gt; 1) fprintf(stderr, \u0026#34;Hash table expansion done\\n\u0026#34;); } } mutex_unlock(\u0026amp;cache_lock);//释放cache_lock锁 item_unlock_global();//释放Hash表的全局锁 //完成扩容 if (!expanding) { //修改Hash表的锁类型，此时锁类型更新为分段锁，默认是分段锁，在进行扩容时，改为全局锁 switch_item_lock_type(ITEM_LOCK_GRANULAR); //释放用于扩容的锁 slabs_rebalancer_resume(); /* We are done expanding.. just wait for next invocation */ mutex_lock(\u0026amp;cache_lock); //加cache_lock锁，保护条件变量 started_expanding = false; //修改扩容标识 pthread_cond_wait(\u0026amp;maintenance_cond, \u0026amp;cache_lock); //阻塞扩容线程 mutex_unlock(\u0026amp;cache_lock); slabs_rebalancer_pause(); //加用于扩容的锁 switch_item_lock_type(ITEM_LOCK_GLOBAL); //修改锁类型为全局锁 mutex_lock(\u0026amp;cache_lock); //临时用来实现临界区 assoc_expand();//执行扩容 mutex_unlock(\u0026amp;cache_lock); } } return NULL; } //按2倍容量扩容Hash表 static void assoc_expand(void) { //old_hashtable指向主Hash表 old_hashtable = primary_hashtable; //申请新的空间 primary_hashtable = calloc(hashsize(hashpower + 1), sizeof(void *)); //空间申请成功 if (primary_hashtable) { if (settings.verbose \u0026gt; 1) fprintf(stderr, \u0026#34;Hash table expansion starting\\n\u0026#34;); hashpower++; //hash等级+1 expanding = true; //扩容标识打开 expand_bucket = 0; STATS_LOCK(); //更新全局统计信息 stats.hash_power_level = hashpower; stats.hash_bytes += hashsize(hashpower) * sizeof(void *); stats.hash_is_expanding = 1; STATS_UNLOCK(); } else { primary_hashtable = old_hashtable; } } ","permalink":"https://haokiu.com/blog/3ba1e9453dcc49edb8ee1597bb133cdd/","summary":"Memcached阅读十五 Hash表扩容 Hash表是Memcached里面最重要的结构之一，其采用链接法来处理Hash冲突，当Hash表中的项太多时，也就是Hash冲突比较高的时候，Hash表的遍历就脱变成单链表，此时为了提供Hash的性能，Hash表需要扩容，Memcached的扩容条件是当表中元素个数超过Hash容量的1.5倍时就进行扩容，扩容过程由独立的线程来完成，扩容过程中会采用2个Hash表，将老表中的数据通过Hash算法映射到新表中，每次移动的桶的数目可以配置，默认是每次移动老表中的1个桶。\n//hash表中增加元素 int assoc_insert(item *it, const uint32_t hv) { unsigned int oldbucket; //如果已经进行扩容且目前进行扩容还没到需要插入元素的桶，则将元素添加到旧桶中 if (expanding \u0026amp;\u0026amp;(oldbucket = (hv \u0026amp; hashmask(hashpower - 1))) \u0026gt;= expand_bucket) { //添加元素 it-\u0026gt;h_next = old_hashtable[oldbucket]; old_hashtable[oldbucket] = it; } else { //如果没扩容，或者扩容已经到了新的桶中，则添加元素到新表中 it-\u0026gt;h_next = primary_hashtable[hv \u0026amp; hashmask(hashpower)];//添加元素 primary_hashtable[hv \u0026amp; hashmask(hashpower)] = it; } hash_items++;//元素数目+1 //还没开始扩容，且表中元素个数已经超过Hash表容量的1.5倍 if (! expanding \u0026amp;\u0026amp; hash_items \u0026gt; (hashsize(hashpower) * 3) / 2) { //唤醒扩容线程 assoc_start_expand(); } MEMCACHED_ASSOC_INSERT(ITEM_key(it), it-\u0026gt;nkey, hash_items); return 1; } //唤醒扩容线程 static void assoc_start_expand(void) { if (started_expanding) return; started_expanding = true; //唤醒信号量 pthread_cond_signal(\u0026amp;maintenance_cond); } //启动扩容线程，扩容线程在main函数中会启动，启动运行一遍之后会阻塞在条件变量maintenance_cond上面，插入元素超过规定，唤醒条件变量 static void *assoc_maintenance_thread(void *arg) { //do_run_maintenance_thread的值为1，即该线程持续运行 while (do_run_maintenance_thread) { int ii = 0; item_lock_global();//加Hash表的全局锁 mutex_lock(\u0026amp;cache_lock);//加cache_lock锁 //执行扩容时，每次按hash_bulk_move个桶来扩容 for (ii = 0; ii \u0026lt; hash_bulk_move \u0026amp;\u0026amp; expanding; ++ii) { item *it, *next; int bucket; //老表每次移动一个桶中的一个元素 for (it = old_hashtable[expand_bucket]; NULL !","title":"Memcached阅读十五 Hash表扩容"},{"content":"此仓库是公众号【高性能服务器开发】文章汇总，如需下载全部文章，可以在公众号回复关键字“文章下载”即可得到下载链接。分享和转发文章时请保留作者信息，部分文章来源于网络，侵权请联系删除。\n我也专门建立了读者交流群，想加群的读者可以加我微信easy_coder\n在线阅读站点1：https://balloonwj.github.io/cpp-guide-web/\n在线阅读站点2: http://balloonwj.gitee.io/cpp-guide-web/\n备份站点：http://101.37.25.166/blog/\n如需下载该站点源码用于自己搭建站点，可以在【高性能服务器开发】微信公众号后台回复关键字“站点下载”即可得到下载链接。\nPart I C++必知必会的知识点\n如何成为一名合格的C/C++开发者？ 不定参数函数实现var_arg系列的宏 你一定要搞明白的C函数调用方式与栈原理 深入理解C/C++中的指针 详解C++11中的智能指针 C++17结构化绑定 C++必须掌握的pimpl惯用法 用Visual Studio调试Linux程序 如何使用Visual Studio管理和阅读开源项目代码 利用cmake工具生成Visual Studio工程文件 多线程\n后台C++开发你一定要知道的条件变量 整型变量赋值是原子操作吗？ 网络编程\nbind 函数重难点解析 connect 函数在阻塞和非阻塞模式下的行为 select 函数重难点解析 Linux epoll 模型（含LT 模式和 ET 模式详解） socket 的阻塞模式和非阻塞模式 非阻塞模式下 send 和 recv 函数的返回值 服务器开发通信协议设计介绍 TCP 协议如何解决粘包、半包问题 网络通信中收发数据的正确姿势 服务器端发数据时，如果对端一直不收，怎么办？ 程序员必知必会的网络命令\n利用telnet命令发电子邮件 做Java或者C++开发都应该知道的lsof命令 Linux网络故障排查的瑞士军刀nc命令 Linux tcpdump使用详解 从抓包的角度分析connect函数的连接过程 服务器开发中网络数据分析与故障排查经验漫谈 Part II 高性能服务器框架设计\n主线程与工作线程的分工 Reactor模式 实例：一个服务器程序的架构介绍 错误码系统的设计 日志系统的设计 如何设计断线自动重连机制 心跳包机制设计详解 业务数据处理一定要单独开线程吗 C++ 高性能服务器网络框架设计细节 服务器开发案例实战\n从零实现一个http服务器 从零实现一款12306刷票软件 从零实现一个邮件收发客户端 从零开发一个WebSocket服务器 从零学习开源项目系列（一）从一款多人联机实时对战游戏开始 从零学习开源项目系列（二）最后一战概况 从零学习开源项目系列（三） CSBattleMgr服务源码研究 从零学习开源项目系列（四）LogServer源码探究 Part III TeamTalk IM源码分析\n01 TeamTalk介绍 02 服务器端的程序的编译与部署 03 服务器端的程序架构介绍 04 服务器端db_proxy_server源码分析 05 服务器端msg_server源码分析 06 服务器端login_server源码分析 07 服务器端msfs源码分析 08 服务器端file_server源码分析 09 服务器端route_server源码分析 10 开放一个TeamTalk测试服务器地址和几个测试账号 11 pc客户端源码分析 libevent源码深度剖析\nlibevent源码深度剖析01 libevent源码深度剖析02 libevent源码深度剖析03 libevent源码深度剖析04 libevent源码深度剖析05 libevent源码深度剖析06 libevent源码深度剖析07 libevent源码深度剖析08 libevent源码深度剖析09 libevent源码深度剖析10 libevent源码深度剖析11 libevent源码深度剖析12 libevent源码深度剖析13 leveldb源码分析\nleveldb源码分析1 leveldb源码分析2 leveldb源码分析3 leveldb源码分析4 leveldb源码分析5 leveldb源码分析6 leveldb源码分析7 leveldb源码分析8 leveldb源码分析9 leveldb源码分析10 leveldb源码分析11 leveldb源码分析12 leveldb源码分析13 leveldb源码分析14 leveldb源码分析15 leveldb源码分析16 leveldb源码分析17 leveldb源码分析18 leveldb源码分析19 leveldb源码分析20 leveldb源码分析21 leveldb源码分析22 Memcached源码分析\n00 服务器资源调整 01 初始化参数解析 02 网络监听的建立 03 网络连接建立 04 内存初始化 05 资源初始化 06 get过程 07 cas属性 08 内存池 09 连接队列 10 Hash表操作 12 set操作 13 do_item_alloc操作 14 item结构 15 Hash表扩容 16 线程交互 17 状态机 游戏开发专题\n1 游戏服务器开发的基本体系与服务器端开发的一些建议 2 网络游戏服务器开发框架设计介绍 3 游戏后端开发需要掌握的知识 4 关于游戏服务端架构的整理 5 各类游戏对应的服务端架构 6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则 7 QQ游戏百万人同时在线服务器架构实现 8 大型多人在线游戏服务器架构设计 9 百万用户级游戏服务器架构设计 10 十万在线的WebGame的数据库设计思路 11 一种高性能网络游戏服务器架构设计 12 经典游戏服务器端架构概述 13 游戏跨服架构进化之路 Part IV 程序员面试题精讲\n腾讯后台开发实习生技能要求 聊聊如何拿大厂的 offer 网络通信题目集锦 我面试后端开发经理的经历 Linux C/C++后端开发面试问哪些问题 职业规划\n给工作 4 年迷茫的程序员们的一点建议 聊聊技术人员的常见的职业问题 写给那些傻傻想做服务器开发的朋友 自我提升与开源代码\n2020 年好好读一读开源代码吧 后端开发相关的书籍\n后台开发应该读的书 程序员的简历\n程序员如何写简历 程序员的薪资与年终奖那些事儿\n技术面试与HR谈薪资技巧 聊一聊程序员如何增加收入 谈一谈年终奖 程序员的烦心事\n拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？ 我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？ 作者的故事\n我的 2019 我是如何年薪五十万的 如果您在阅读上述文章的过程中有任何问题或者建议，可以加我微信easy_coder交流。\nEnjoy it!\n","permalink":"https://haokiu.com/blog/184a1ba071384d75b2da68fa7be54511/","summary":"此仓库是公众号【高性能服务器开发】文章汇总，如需下载全部文章，可以在公众号回复关键字“文章下载”即可得到下载链接。分享和转发文章时请保留作者信息，部分文章来源于网络，侵权请联系删除。\n我也专门建立了读者交流群，想加群的读者可以加我微信easy_coder\n在线阅读站点1：https://balloonwj.github.io/cpp-guide-web/\n在线阅读站点2: http://balloonwj.gitee.io/cpp-guide-web/\n备份站点：http://101.37.25.166/blog/\n如需下载该站点源码用于自己搭建站点，可以在【高性能服务器开发】微信公众号后台回复关键字“站点下载”即可得到下载链接。\nPart I C++必知必会的知识点\n如何成为一名合格的C/C++开发者？ 不定参数函数实现var_arg系列的宏 你一定要搞明白的C函数调用方式与栈原理 深入理解C/C++中的指针 详解C++11中的智能指针 C++17结构化绑定 C++必须掌握的pimpl惯用法 用Visual Studio调试Linux程序 如何使用Visual Studio管理和阅读开源项目代码 利用cmake工具生成Visual Studio工程文件 多线程\n后台C++开发你一定要知道的条件变量 整型变量赋值是原子操作吗？ 网络编程\nbind 函数重难点解析 connect 函数在阻塞和非阻塞模式下的行为 select 函数重难点解析 Linux epoll 模型（含LT 模式和 ET 模式详解） socket 的阻塞模式和非阻塞模式 非阻塞模式下 send 和 recv 函数的返回值 服务器开发通信协议设计介绍 TCP 协议如何解决粘包、半包问题 网络通信中收发数据的正确姿势 服务器端发数据时，如果对端一直不收，怎么办？ 程序员必知必会的网络命令\n利用telnet命令发电子邮件 做Java或者C++开发都应该知道的lsof命令 Linux网络故障排查的瑞士军刀nc命令 Linux tcpdump使用详解 从抓包的角度分析connect函数的连接过程 服务器开发中网络数据分析与故障排查经验漫谈 Part II 高性能服务器框架设计\n主线程与工作线程的分工 Reactor模式 实例：一个服务器程序的架构介绍 错误码系统的设计 日志系统的设计 如何设计断线自动重连机制 心跳包机制设计详解 业务数据处理一定要单独开线程吗 C++ 高性能服务器网络框架设计细节 服务器开发案例实战\n从零实现一个http服务器 从零实现一款12306刷票软件 从零实现一个邮件收发客户端 从零开发一个WebSocket服务器 从零学习开源项目系列（一）从一款多人联机实时对战游戏开始 从零学习开源项目系列（二）最后一战概况 从零学习开源项目系列（三） CSBattleMgr服务源码研究 从零学习开源项目系列（四）LogServer源码探究 Part III TeamTalk IM源码分析\n01 TeamTalk介绍 02 服务器端的程序的编译与部署 03 服务器端的程序架构介绍 04 服务器端db_proxy_server源码分析 05 服务器端msg_server源码分析 06 服务器端login_server源码分析 07 服务器端msfs源码分析 08 服务器端file_server源码分析 09 服务器端route_server源码分析 10 开放一个TeamTalk测试服务器地址和几个测试账号 11 pc客户端源码分析 libevent源码深度剖析","title":"Part I"},{"content":"pimpl 惯用法 现在这里有一个名为 CSocketClient 的网络通信类，定义如下：\n/** * 网络通信的基础类, SocketClient.h * zhangyl 2017.07.11 */ class CSocketClient { public: CSocketClient(); ~CSocketClient(); public: void SetProxyWnd(HWND hProxyWnd); bool Init(CNetProxy* pNetProxy); bool Uninit(); int Register(const char* pszUser, const char* pszPassword); void GuestLogin(); BOOL IsClosed(); BOOL\tConnect(int timeout = 3); void AddData(int cmd, const std::string\u0026amp; strBuffer); void AddData(int cmd, const char* pszBuff, int nBuffLen); void Close(); BOOL ConnectServer(int timeout = 3); BOOL SendLoginMsg(); BOOL RecvLoginMsg(int\u0026amp; nRet); BOOL Login(int\u0026amp; nRet); private: void LoadConfig(); static UINT CALLBACK SendDataThreadProc(LPVOID lpParam); static UINT CALLBACK RecvDataThreadProc(LPVOID lpParam); bool Send(); bool Recv(); bool CheckReceivedData(); void SendHeartbeatPackage(); private: SOCKET m_hSocket; short m_nPort; char m_szServer[64]; long m_nLastDataTime; //最近一次收发数据的时间 long m_nHeartbeatInterval; //心跳包时间间隔，单位秒 CRITICAL_SECTION m_csLastDataTime; //保护m_nLastDataTime的互斥体 HANDLE m_hSendDataThread; //发送数据线程 HANDLE m_hRecvDataThread; //接收数据线程 std::string m_strSendBuf; std::string m_strRecvBuf; HANDLE m_hExitEvent; bool m_bConnected; CRITICAL_SECTION m_csSendBuf; HANDLE m_hSemaphoreSendBuf; HWND m_hProxyWnd; CNetProxy* m_pNetProxy; int m_nReconnectTimeInterval; //重连时间间隔 time_t m_nLastReconnectTime; //上次重连时刻 CFlowStatistics* m_pFlowStatistics; }; 这段代码来源于笔者实际项目中开发的一个股票客户端的软件。\nCSocketClient 类的 public 方法提供对外接口供第三方使用，每个函数的具体实现在 SocketClient.cpp 中，对第三方使用者不可见。在 Windows 系统上作为提供给第三方使用的库，一般需要提供给使用者 .h、.lib 和 .dll 文件，在 Linux 系统上需要提供 .h、.a 或 .so 文件。\n不管是在哪个操作系统平台上，像 SocketClient.h 这样的头文件提供给第三方使用时，都会让库的作者心里隐隐不安——因为 SocketClient.h 文件中 SocketClient 类大量的成员变量和私有函数暴露了这个类太多的实现细节，很容易让使用者看出实现原理。这样的头文件，对于一些不想对使用者暴露核心技术实现的库和 sdk，是非常不好的。\n那有没有什么办法既能保持对外的接口不变，又能尽量不暴露一些关键性的成员变量和私有函数的实现方法呢？有的。我们可以将代码稍微修改一下：\n/** * 网络通信的基础类, SocketClient.h * zhangyl 2017.07.11 */ class Impl; class CSocketClient { public: CSocketClient(); ~CSocketClient(); public: void SetProxyWnd(HWND hProxyWnd); bool Init(CNetProxy* pNetProxy); bool Uninit(); int Register(const char* pszUser, const char* pszPassword); void GuestLogin(); BOOL IsClosed(); BOOL\tConnect(int timeout = 3); void AddData(int cmd, const std::string\u0026amp; strBuffer); void AddData(int cmd, const char* pszBuff, int nBuffLen); void Close(); BOOL ConnectServer(int timeout = 3); BOOL SendLoginMsg(); BOOL RecvLoginMsg(int\u0026amp; nRet); BOOL Login(int\u0026amp; nRet); private: Impl*\tm_pImpl; }; 上述代码中，所有的关键性成员变量已经没有了，取而代之的是一个类型为 Impl 的指针成员变量 m_pImpl。\n具体采用什么名称，读者完全可以根据自己的实际情况来定，不一定非要使用这里的 Impl 和 m_pImpl。\nImpl 类型现在是完全对使用者透明，为了在当前类中可以使用 Impl，使用了一个前置声明：\n//原代码第5行 class Impl; 然后我们就可以将刚才隐藏的成员变量放到这个类中去：\nclass Impl { public: Impl() { //TODO: 你可以在这里对成员变量做一些初始化工作 } ~Impl() { //TODO: 你可以在这里做一些清理工作 } public: SOCKET m_hSocket; short m_nPort; char m_szServer[64]; long m_nLastDataTime; //最近一次收发数据的时间 long m_nHeartbeatInterval; //心跳包时间间隔，单位秒 CRITICAL_SECTION m_csLastDataTime; //保护m_nLastDataTime的互斥体 HANDLE m_hSendDataThread; //发送数据线程 HANDLE m_hRecvDataThread; //接收数据线程 std::string m_strSendBuf; std::string m_strRecvBuf; HANDLE m_hExitEvent; bool m_bConnected; CRITICAL_SECTION m_csSendBuf; HANDLE m_hSemaphoreSendBuf; HWND m_hProxyWnd; CNetProxy* m_pNetProxy; int m_nReconnectTimeInterval; //重连时间间隔 time_t m_nLastReconnectTime; //上次重连时刻 CFlowStatistics* m_pFlowStatistics; }; 接着我们在 CSocketClient 的构造函数中创建这个 m_pImpl 对象，在 CSocketClient 析构函数中释放这个对象。\nCSocketClient::CSocketClient() { m_pImpl = new Impl(); } CSocketClient::~CSocketClient() { delete m_pImpl; } 这样，原来需要引用的成员变量，可以在 CSocketClient 内部使用 m_pImpl-\u0026gt;变量名 来引用了。\n这里仅仅以演示隐藏 CSocketClient 的成员变量为例，隐藏其私有方法与此类似，都是变成类 Impl 的方法。\n需要强调的是，在实际开发中，由于 Impl 类是 CSocketClient 的辅助类， Impl 类没有独立存在的必要，所以一般会将 Impl 类定义成 CSocketClient 的内部类。即采用如下形式：\n/** * 网络通信的基础类, SocketClient.h * zhangyl 2017.07.11 */ class CSocketClient { public: CSocketClient(); ~CSocketClient(); //重复的代码省略... private: class Impl; Impl*\tm_pImpl; }; 然后在 ClientSocket.cpp 中定义 Impl 类的实现：\n/** * 网络通信的基础类, SocketClient.cpp * zhangyl 2017.07.11 */ class CSocketClient::Impl { public: void LoadConfig() { //方法的具体实现 } //其他方法省略... public: SOCKET m_hSocket; short m_nPort; char m_szServer[64]; long m_nLastDataTime; //最近一次收发数据的时间 long m_nHeartbeatInterval; //心跳包时间间隔，单位秒 CRITICAL_SECTION m_csLastDataTime; //保护m_nLastDataTime的互斥体 HANDLE m_hSendDataThread; //发送数据线程 HANDLE m_hRecvDataThread; //接收数据线程 std::string m_strSendBuf; std::string m_strRecvBuf; HANDLE m_hExitEvent; bool m_bConnected; CRITICAL_SECTION m_csSendBuf; HANDLE m_hSemaphoreSendBuf; HWND m_hProxyWnd; CNetProxy* m_pNetProxy; int m_nReconnectTimeInterval; //重连时间间隔 time_t m_nLastReconnectTime; //上次重连时刻 CFlowStatistics* m_pFlowStatistics; } CSocketClient::CSocketClient() { m_pImpl = new Impl(); } CSocketClient::~CSocketClient() { delete m_pImpl; } 现在CSocketClient 这个类除了保留对外的接口以外，其内部实现用到的变量和方法基本上对使用者不可见了。C++ 中对类的这种封装方式，我们称之为 pimpl 惯用法，即 Pointer to Implementation （也有人认为是 Private Implementation）。\n在实际的开发中，Impl 类的声明和定义既可以使用 class 关键字也可以使用 struct 关键字。在 C++ 语言中，struct 类型可以定义成员方法，但 struct 所有成员变量和方法默认都是 public 的。\n现在来总结一下这个方法的优点：\n核心数据成员被隐藏；\n核心数据成员被隐藏，不必暴露在头文件中，对使用者透明，提高了安全性。\n降低编译依赖，提高编译速度；\n由于原来的头文件的一些私有成员变量可能是非指针非引用类型的自定义类型，需要在当前类的头文件中包含这些类型的头文件，使用了 pimpl 惯用法以后，这些私有成员变量被移动到当前类的 cpp 文件中，因此头文件不再需要包含这些成员变量的类型头文件，当前头文件变“干净”，这样其他文件在引用这个头文件时，依赖的类型变少，加快了编译速度。\n接口与实现分离。\n使用了 pimpl 惯用法之后，即使 CSocketClient 或者 Impl 类的实现细节发生了变化，对使用者都是透明的，对外的 CSocketClient 类声明仍然可以保持不变。例如我们可以增删改 Impl 的成员变量和成员方法而保持 SocketClient.h 文件内容不变；如果不使用 pimpl 惯用法，我们做不到不改变 SocketClient.h 文件而增删改 CSocketClient 类的成员。\n智能指针用于 pimpl 惯用法\nC++ 11 标准引入了智能指针对象，我们可以使用 std::unique_ptr 对象来管理上述用于隐藏具体实现的 m_pImpl 指针。\nSocketClient.h 文件可以修改成如下方式：\n#include \u0026lt;memory\u0026gt; //for std::unique_ptr class CSocketClient { public: CSocketClient(); ~CSocketClient(); //重复的代码省略... private: struct Impl; std::unique_ptr\u0026lt;Impl\u0026gt; m_pImpl; }; SocketClient.cpp 中修改 CSocketClient 对象的构造函数和析构函数的实现如下：\n构造函数\n如果你的编译器仅支持 C++ 11 标准，我们可以按如下修改：\nCSocketClient::CSocketClient() { //C++11 标准并未提供 std::make_unique()，该方法是 C++14 提供的 m_pImpl.reset(new Impl()); } 如果你的编译器支持 C++14 及以上标准，可以这么修改：\nCSocketClient::CSocketClient() : m_pImpl(std::make_unique\u0026lt;Impl\u0026gt;()) { } 由于已经使用了智能指针来管理 m_pImpl 指向的堆内存，因此析构函数中不再需要显式释放堆内存：\nCSocketClient::~CSocketClient() { //不再需要显式 delete 了 //delete m_pImpl; } pimp 惯用法是 C/C++ 项目开发中一种非常实用的代码编写策略，建议读者掌握它。\n","permalink":"https://haokiu.com/blog/4a2f5d00bb404b68a468bd72dfe357f8/","summary":"pimpl 惯用法 现在这里有一个名为 CSocketClient 的网络通信类，定义如下：\n/** * 网络通信的基础类, SocketClient.h * zhangyl 2017.07.11 */ class CSocketClient { public: CSocketClient(); ~CSocketClient(); public: void SetProxyWnd(HWND hProxyWnd); bool Init(CNetProxy* pNetProxy); bool Uninit(); int Register(const char* pszUser, const char* pszPassword); void GuestLogin(); BOOL IsClosed(); BOOL\tConnect(int timeout = 3); void AddData(int cmd, const std::string\u0026amp; strBuffer); void AddData(int cmd, const char* pszBuff, int nBuffLen); void Close(); BOOL ConnectServer(int timeout = 3); BOOL SendLoginMsg(); BOOL RecvLoginMsg(int\u0026amp; nRet); BOOL Login(int\u0026amp; nRet); private: void LoadConfig(); static UINT CALLBACK SendDataThreadProc(LPVOID lpParam); static UINT CALLBACK RecvDataThreadProc(LPVOID lpParam); bool Send(); bool Recv(); bool CheckReceivedData(); void SendHeartbeatPackage(); private: SOCKET m_hSocket; short m_nPort; char m_szServer[64]; long m_nLastDataTime; //最近一次收发数据的时间 long m_nHeartbeatInterval; //心跳包时间间隔，单位秒 CRITICAL_SECTION m_csLastDataTime; //保护m_nLastDataTime的互斥体 HANDLE m_hSendDataThread; //发送数据线程 HANDLE m_hRecvDataThread; //接收数据线程 std::string m_strSendBuf; std::string m_strRecvBuf; HANDLE m_hExitEvent; bool m_bConnected; CRITICAL_SECTION m_csSendBuf; HANDLE m_hSemaphoreSendBuf; HWND m_hProxyWnd; CNetProxy* m_pNetProxy; int m_nReconnectTimeInterval; //重连时间间隔 time_t m_nLastReconnectTime; //上次重连时刻 CFlowStatistics* m_pFlowStatistics; }; 这段代码来源于笔者实际项目中开发的一个股票客户端的软件。","title":"pimpl 惯用法"},{"content":"select 函数重难点解析 select 函数是网络通信编程中非常常用的一个函数，因此应该熟练掌握它。虽然它是 BSD 标准之一的 Socket 函数之一，但在 Linux 和 Windows 平台，其行为表现还是有点区别的。我们先来看一下 Linux 平台上的 select 函数。\nLinux 平台下的 select 函数 select 函数的作用是检测一组 socket 中某个或某几个是否有“事件”，这里的“**事件”**一般分为如下三类：\n可读事件，一般意味着可以调用 recv 或 read 函数从该 socket 上读取数据；如果该 socket 是侦听 socket（即调用了 bind 函数绑定过 ip 地址和端口号，并调用了 listen 启动侦听的 socket），可读意味着此时可以有新的客户端连接到来，此时可调用 accept 函数接受新连接。 可写事件，一般意味着此时调用 send 或 write 函数可以将数据“发出去”。 异常事件，某个 socket 出现异常。 函数签名如下：\nint select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); 参数说明：\n参数 nfds， Linux 下 socket 也称 fd，这个参数的值设置成所有需要使用 select 函数监听的 fd 中最大 fd 值加 1。\n参数 readfds，需要监听可读事件的 fd 集合。\n参数 writefds，需要监听可写事件的 fd 集合。\n参数 exceptfds，需要监听异常事件 fd 集合。\nreadfds、writefds 和 exceptfds 类型都是 fd_set，这是一个结构体信息，其定义位于 /usr/include/sys/select.h 中：\n/* The fd_set member is required to be an array of longs. */ typedef long int __fd_mask; /* Some versions of \u0026lt;linux/posix_types.h\u0026gt; define this macros. */ #undef __NFDBITS /* It\u0026#39;s easier to assume 8-bit bytes than to get CHAR_BIT. */ #define __NFDBITS (8 * (int) sizeof (__fd_mask)) #define __FD_ELT(d) ((d) / __NFDBITS) #define __FD_MASK(d) ((__fd_mask) 1 \u0026lt;\u0026lt; ((d) % __NFDBITS)) /* fd_set for select and pselect. */ typedef struct { /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */ #ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;fds_bits) #else // 在我的centOS 7.0 系统中的值： // __FD_SETSIZE = 1024 //__NFDBITS = 64 __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;__fds_bits) #endif } fd_set; /* Maximum number of file descriptors in \u0026#39;fd_set\u0026#39;. */ #define FD_SETSIZE __FD_SETSIZE 我们假设未定义宏 __USE_XOPEN，将上面的代码整理一下：\ntypedef struct { long int __fds_bits[16]; } fd_set; 将一个 fd 添加到 fd_set 这个集合中需要使用 FD_SET 宏，其定义如下：\nvoid FD_SET(int fd, fd_set *set); 其实现如下：\n#define FD_SET(fd,fdsetp) __FD_SET(fd,fdsetp) FD_SET 在内部又是通过宏 __FD_SET 来实现的，__FD_SET 的定义如下（位于 /usr/include/bits/select.h 中）：\n#if defined __GNUC__ \u0026amp;\u0026amp; __GNUC__ \u0026gt;= 2 # if __WORDSIZE == 64 # define __FD_ZERO_STOS \u0026#34;stosq\u0026#34; # else # define __FD_ZERO_STOS \u0026#34;stosl\u0026#34; # endif # define __FD_ZERO(fdsp) \\ do { \\ int __d0, __d1; \\ __asm__ __volatile__ (\u0026#34;cld; rep; \u0026#34; __FD_ZERO_STOS \\ : \u0026#34;=c\u0026#34; (__d0), \u0026#34;=D\u0026#34; (__d1) \\ : \u0026#34;a\u0026#34; (0), \u0026#34;0\u0026#34; (sizeof (fd_set) \\ / sizeof (__fd_mask)), \\ \u0026#34;1\u0026#34; (\u0026amp;__FDS_BITS (fdsp)[0]) \\ : \u0026#34;memory\u0026#34;); \\ } while (0) #else /* ! GNU CC */ /* We don\u0026#39;t use `memset\u0026#39; because this would require a prototype and the array isn\u0026#39;t too big. */ # define __FD_ZERO(set) \\ do { \\ unsigned int __i; \\ fd_set *__arr = (set); \\ for (__i = 0; __i \u0026lt; sizeof (fd_set) / sizeof (__fd_mask); ++__i) \\ __FDS_BITS (__arr)[__i] = 0; \\ } while (0) #endif /* GNU CC */ #define __FD_SET(d, set) \\ ((void) (__FDS_BITS (set)[__FD_ELT (d)] |= __FD_MASK (d))) #define __FD_CLR(d, set) \\ ((void) (__FDS_BITS (set)[__FD_ELT (d)] \u0026amp;= ~__FD_MASK (d))) #define __FD_ISSET(d, set) \\ ((__FDS_BITS (set)[__FD_ELT (d)] \u0026amp; __FD_MASK (d)) != 0) 重点看这一行：\n((void) (__FDS_BITS (set)[__FD_ELT (d)] |= __FD_MASK (d))) __FD_MASK 和 __FD_ELT 宏在上面的代码中已经给出定义：\n#define __FD_ELT(d) ((d) / __NFDBITS) #define __FD_MASK(d) ((__fd_mask) 1 \u0026lt;\u0026lt; ((d) % __NFDBITS)) __NFDBITS 的值是 64 （8 * 8），也就是说 __FD_MASK (d) 先计算 fd 与 64 的余数 n，然后执行 1 \u0026laquo; n，这一操作实际上是将 fd 的值放在 0～63 这 64 的位置上去，这个位置索引就是 fd 与 64 取模的结果；同理 __FD_ELT(d) 就是计算位置索引值了。举个例子，假设现在 fd 的 值是 57，那么在这 64 个位置的 57 位，其值在 64 个长度的二进制中置位是：\n0000 0010 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 0000 这个值就是 1 \u0026laquo; (57 % 64) 得到的数字。\n但是前面 fd 数组的定义是：\ntypedef struct { long int __fds_bits[16]; //可以看成是128 bit的数组 } fd_set; long int 占 8 个字节，一个 16 个 long int，如果换成二进制的位(bit)就是 8 * 16 = 128， 也就是这个数组只用了低 64 位， 高 64 位并没有使用。这说明在我的机器上，select 函数支持操作的最大 fd 数量是 64。\n同理，如果我们需要从 fd_set 上删除一个 fd，我们可以调用 FD_CLR，其定义如下：\nvoid FD_CLR(int fd, fd_set *set); 原理和 FD_SET 相同，即将对应的标志位由1变0即可。\n如果，我们需要将 fd_set 中所有的 fd 都清掉，则使用宏 FD_ZERO：\nvoid FD_ZERO(fd_set *set); 当 select 函数返回时， 我们使用 FD_ISSET 宏来判断某个 fd 是否有我们关心的事件，FD_ISSET 宏的定义如下：\nint FD_ISSET(int fd, fd_set *set); FD_ISSET 宏本质上就是检测对应的位置上是否置 1，实现如下：\n#define __FD_ISSET(d, set) \\ ((__FDS_BITS (set)[__FD_ELT (d)] \u0026amp; __FD_MASK (d)) != 0) 提醒一下： __FD_ELT 和 __FD_MASK 宏前文的代码已经给过具体实现了。\n参数 timeout，超时时间，即在这个参数设定的时间内检测这些 fd 的事件，超过这个时间后 select 函数将立即返回。这是一个 timeval 类型结构体，其定义如下：\nstruct timeval { long tv_sec; /* seconds */ long tv_usec; /* microseconds */ }; select 函数的总超时时间是 timeout-\u0026gt;tv_sec 和 timeout-\u0026gt;tv_usec 之和， 前者的时间单位是秒，后者的时间单位是微妙。\n说了这么多理论知识，我们先看一个具体的示例：\n/** * select函数示例，server端, select_server.cpp * zhangyl 2018.12.24 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;errno.h\u0026gt; //自定义代表无效fd的值 #define INVALID_FD -1 int main(int argc, char* argv[]) { //创建一个侦听socket int listenfd = socket(AF_INET, SOCK_STREAM, 0); if (listenfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //初始化服务器地址 struct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); bindaddr.sin_port = htons(3000); if (bind(listenfd, (struct sockaddr *)\u0026amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;bind listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(listenfd); return -1; } //启动侦听 if (listen(listenfd, SOMAXCONN) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;listen error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(listenfd); return -1; } //存储客户端socket的数组 std::vector\u0026lt;int\u0026gt; clientfds; int maxfd = listenfd; while (true) { fd_set readset; FD_ZERO(\u0026amp;readset); //将侦听socket加入到待检测的可读事件中去 FD_SET(listenfd, \u0026amp;readset); //将客户端fd加入到待检测的可读事件中去 int clientfdslength = clientfds.size(); for (int i = 0; i \u0026lt; clientfdslength; ++i) { if (clientfds[i] != INVALID_FD) { FD_SET(clientfds[i], \u0026amp;readset); } } timeval tm; tm.tv_sec = 1; tm.tv_usec = 0; //暂且只检测可读事件，不检测可写和异常事件 int ret = select(maxfd + 1, \u0026amp;readset, NULL, NULL, \u0026amp;tm); if (ret == -1) { //出错，退出程序。 if (errno != EINTR) break; } else if (ret == 0) { //select 函数超时，下次继续 continue; } else { //检测到某个socket有事件 if (FD_ISSET(listenfd, \u0026amp;readset)) { //侦听socket的可读事件，则表明有新的连接到来 struct sockaddr_in clientaddr; socklen_t clientaddrlen = sizeof(clientaddr); //4. 接受客户端连接 int clientfd = accept(listenfd, (struct sockaddr *)\u0026amp;clientaddr, \u0026amp;clientaddrlen); if (clientfd == -1) { //接受连接出错，退出程序 break; } //只接受连接，不调用recv收取任何数据 std:: cout \u0026lt;\u0026lt; \u0026#34;accept a client connection, fd: \u0026#34; \u0026lt;\u0026lt; clientfd \u0026lt;\u0026lt; std::endl; clientfds.push_back(clientfd); //记录一下最新的最大fd值，以便作为下一轮循环中select的第一个参数 if (clientfd \u0026gt; maxfd) maxfd = clientfd; } else { //假设对端发来的数据长度不超过63个字符 char recvbuf[64]; int clientfdslength = clientfds.size(); for (int i = 0; i \u0026lt; clientfdslength; ++i) { if (clientfds[i] != -1 \u0026amp;\u0026amp; FD_ISSET(clientfds[i], \u0026amp;readset)) { memset(recvbuf, 0, sizeof(recvbuf)); //非侦听socket，则接收数据 int length = recv(clientfds[i], recvbuf, 64, 0); if (length \u0026lt;= 0 \u0026amp;\u0026amp; errno != EINTR) { //收取数据出错了 std::cout \u0026lt;\u0026lt; \u0026#34;recv data error, clientfd: \u0026#34; \u0026lt;\u0026lt; clientfds[i] \u0026lt;\u0026lt; std::endl; close(clientfds[i]); //不直接删除该元素，将该位置的元素置位-1 clientfds[i] = INVALID_FD; continue; } std::cout \u0026lt;\u0026lt; \u0026#34;clientfd: \u0026#34; \u0026lt;\u0026lt; clientfds[i] \u0026lt;\u0026lt; \u0026#34;, recv data: \u0026#34; \u0026lt;\u0026lt; recvbuf \u0026lt;\u0026lt; std::endl; } } } } } //关闭所有客户端socket int clientfdslength = clientfds.size(); for (int i = 0; i \u0026lt; clientfdslength; ++i) { if (clientfds[i] != INVALID_FD) { close(clientfds[i]); } } //关闭侦听socket close(listenfd); return 0; } 我们编译并运行程序：\n[root@localhost testsocket]# g++ -g -o select_server select_server.cpp [root@localhost testsocket]# ./select_server 然后，我们再多开几个 shell 窗口，我们这里不再专门编写客户端程序了，我们使用 Linux 下的 nc 指令模拟出两个客户端。\nshell 窗口1，连接成功以后发送字符串 hello123：\n[root@localhost ~]# nc -v 127.0.0.1 3000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 127.0.0.1:3000. hello123 shell 窗口2，连接成功以后发送字符串 helloworld：\n[root@localhost ~]# nc -v 127.0.0.1 3000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Connected to 127.0.0.1:3000. helloworld 此时服务器端输出结果如下：\n注意，由于 nc 发送的数据是按换行符来区分的，每一个数据包默认的换行符以**\\n** 结束（当然，你可以 -C 选项换成\\r\\n），所以服务器收到数据后，显示出来的数据每一行下面都有一个空白行。\n当断开各个客户端连接时，服务器端 select 函数对各个客户端 fd 检测时，仍然会触发可读事件，此时对这些 fd 调用 recv 函数会返回 0（recv 函数返回0，表明对端关闭了连接，这是一个很重要的知识点，下文我们会有一章节专门介绍这些函数的返回值），服务器端也关闭这些连接就可以了。\n客户端断开连接后，服务器端的运行输出结果：\n以上代码是一个简单的服务器程序实现的基本流程，代码虽然简单，但是非常具有典型性和代表性，而且同样适用于客户端网络通信，如果用于客户端的话，只需要用 select 检测连接 socket 就可以了，如果连接 socket 有可读事件，调用 recv 函数来接收数据，剩下的逻辑都是一样的。上面的代码我们画一张流程图如下：\n关于上述代码在实际开发中有几个需要注意的事项，这里逐一来说明一下：\n1. select 函数调用前后会修改 readfds、writefds 和 exceptfds 这三个集合中的内容（如果有的话），所以如果您想下次调用 select 复用这个变量，记得在下次调用前再次调用 select 前先使用 FD_ZERO 将集合清零，然后调用 FD_SET 将需要检测事件的 fd 再次添加进去。\nselect 函数调用之后，readfds、writefds 和 exceptfds 这三个集合中存放的不是我们之前设置进去的 fd，而是有相关有读写或异常事件的 fd，也就是说 select 函数会修改这三个参数的内容，这也要求我们当一个 fd_set 被 select 函数调用后，这个 fd_set 就已经发生了改变，下次如果我们需要使用它，必须使用 FD_ZERO 宏先清零，再重新将我们关心的 fd 设置进去。这点我们从 FD_ISSET 源码也可以看出来：\n#define __FD_ISSET(d, set) \\ ((__FDS_BITS (set)[__FD_ELT (d)] \u0026amp; __FD_MASK (d)) != 0) 如果调用 select 函数之后没有改变 fd_set 集合，那么即使某个 socket 上没有事件，调用 select 函数之后我们用 FD_ISSET 检测，会原路得到原来设置上去的 socket。这是很多初学者在学习 select 函数容易犯的一个错误，我们通过一个示例来验证一下，这次我们把 select 函数用在客户端。\n/** * 验证调用select后必须重设fd_set，select_client.cpp * zhangyl 2018.12.24 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;string.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 int main(int argc, char* argv[]) { //创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); if (connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;connect socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); return -1; } fd_set readset; FD_ZERO(\u0026amp;readset); //将侦听socket加入到待检测的可读事件中去 FD_SET(clientfd, \u0026amp;readset); timeval tm; tm.tv_sec = 5; tm.tv_usec = 0; int ret; int count = 0; fd_set backup_readset; memcpy(\u0026amp;backup_readset, \u0026amp;readset, sizeof(fd_set)); while (true) { if (memcmp(\u0026amp;readset, \u0026amp;backup_readset, sizeof(fd_set)) == 0) { std::cout \u0026lt;\u0026lt; \u0026#34;equal\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;not equal\u0026#34; \u0026lt;\u0026lt; std::endl; } //暂且只检测可读事件，不检测可写和异常事件 ret = select(clientfd + 1, \u0026amp;readset, NULL, NULL, \u0026amp;tm); std::cout \u0026lt;\u0026lt; \u0026#34;tm.tv_sec: \u0026#34; \u0026lt;\u0026lt; tm.tv_sec \u0026lt;\u0026lt; \u0026#34;, tm.tv_usec: \u0026#34; \u0026lt;\u0026lt; tm.tv_usec \u0026lt;\u0026lt; std::endl; if (ret == -1) { //除了被信号中断的情形，其他情况都是出错 if (errno != EINTR) break; } else if (ret == 0){ //select函数超时 std::cout \u0026lt;\u0026lt; \u0026#34;no event in specific time interval, count：\u0026#34; \u0026lt;\u0026lt; count \u0026lt;\u0026lt; std::endl; ++count; continue; } else { if (FD_ISSET(clientfd, \u0026amp;readset)) { //检测到可读事件 char recvbuf[32]; memset(recvbuf, 0, sizeof(recvbuf)); //假设对端发数据的时候不超过31个字符。 int n = recv(clientfd, recvbuf, 32, 0); if (n \u0026lt; 0) { //除了被信号中断的情形，其他情况都是出错 if (errno != EINTR) break; } else if (n == 0) { //对端关闭了连接 break; } else { std::cout \u0026lt;\u0026lt; \u0026#34;recv data: \u0026#34; \u0026lt;\u0026lt; recvbuf \u0026lt;\u0026lt; std::endl; } } else { std::cout \u0026lt;\u0026lt; \u0026#34;other socket event.\u0026#34; \u0026lt;\u0026lt; std::endl; } } } //关闭socket close(clientfd); return 0; } 在 shell 窗口输入以下命令编译程序产生可执行文件 select_client：\ng++ -g -o select_client select_client.cpp 这次产生的是客户端程序，服务器程序我们这里使用 Linux nc 命令来模拟一下，由于客户端连接的是 127.0.0.1:3000 这个地址和端口号，所以我们在另外一个shell 窗口的 nc 命令的参数可以这么写：\nnc -v -l 0.0.0.0 3000 执行效果如下：接着我们启动客户端 select_client：\n[root@myaliyun testsocket]# ./select_client 需要注意的是，这里我故意将客户端代码中 select 函数的超时时间设置为5秒，以足够我们在这 5 秒内给客户端发一个数据。如果我们在 5 秒内给客户端发送 hello 字符串：\n客户端输出如下：\n[root@myaliyun testsocket]# ./select_client equal recv data: hello ...部分数据省略... not equal tm.tv_sec: 0, tm.tv_usec: 0 no event in specific time interval, count：31454 not equal tm.tv_sec: 0, tm.tv_usec: 0 no event in specific time interval, count：31455 not equal tm.tv_sec: 0, tm.tv_usec: 0 no event in specific time interval, count：31456 not equal tm.tv_sec: 0, tm.tv_usec: 0 no event in specific time interval, count：31457 ...部分输出省略... 除了第一次 select_client 会输出 equal 字样，后面再也没输出，而 select 函数以后的执行结果也是超时，即使此时服务器端再次给客户端发送数据。因此验证了：select 函数执行后，确实会对三个参数的 fd_set 进行修改 。select 函数修改某个 fd_set 集合可以使用如下两张图来说明一下：\n因此在调用 select 函数以后， 原来位置的的标志位可能已经不复存在，这也就是为什么我们的代码中调用一次 select 函数以后，即使服务器端再次发送数据过来，select 函数也不会再因为存在可读事件而返回了，因为第二次 clientfd 已经不在那个 read_set 中了。因此如果复用这些 fd_set 变量，必须按上文所说的重新清零再重新添加关心的 socket 到集合中去。\n2. select 函数也会修改 timeval 结构体的值，这也要求我们如果像复用这个变量，必须给 timeval 变量重新设置值。\n注意观察上面的例子的输出，我们在调用 select 函数一次之后，变量 tv 的值也被修改了。具体修改成多少，得看系统的表现。当然这种特性却不是跨平台的，在 Linux 系统中是这样的，而在其他操作系统上却不一定是这样（Windows 上就不会修改这个结构体的值），这点在 Linux man 手册 select 函数的说明中说的很清楚：\nOn Linux, select() modifies timeout to reflect the amount of time not slept; most other implementations do not do this. (POSIX.1-2001 permits either behavior.) This causes problems both when Linux code which reads timeout is ported to other operating systems, and when code is ported to Linux that reuses a struct timeval for multiple select()s in a loop without reinitializing it. Consider timeout to be undefined after select() returns. 由于不同系统的实现不一样，man 手册的建议将 select 函数修改 timeval 结构体的值的行为当作是未定义的，言下之意是如果你要下次使用 select 函数复用这个变量时，记得重新赋值。这是 select 函数需要注意的第二个地方。\n3. select 函数的 timeval 结构体的 tv_sec 和 tv_sec 如果两个值设置为 0，即检测事件总时间设置为0，其行为是 select 会检测一下相关集合中的 fd，如果没有需要的事件，则立即返回。\n我们将上述 select_client.cpp 修改一下，修改后的代码如下：\n/** * 验证select时间参数设置为0，select_client_tv0.cpp * zhangyl 2018.12.25 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;string.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 int main(int argc, char* argv[]) { //创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); if (connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;connect socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); return -1; } int ret; while (true) { fd_set readset; FD_ZERO(\u0026amp;readset); //将侦听socket加入到待检测的可读事件中去 FD_SET(clientfd, \u0026amp;readset); timeval tm; tm.tv_sec = 0; tm.tv_usec = 0; //暂且只检测可读事件，不检测可写和异常事件 ret = select(clientfd + 1, \u0026amp;readset, NULL, NULL, \u0026amp;tm); std::cout \u0026lt;\u0026lt; \u0026#34;tm.tv_sec: \u0026#34; \u0026lt;\u0026lt; tm.tv_sec \u0026lt;\u0026lt; \u0026#34;, tm.tv_usec: \u0026#34; \u0026lt;\u0026lt; tm.tv_usec \u0026lt;\u0026lt; std::endl; if (ret == -1) { //除了被信号中断的情形，其他情况都是出错 if (errno != EINTR) break; } else if (ret == 0){ //select函数超时 std::cout \u0026lt;\u0026lt; \u0026#34;no event in specific time interval.\u0026#34; \u0026lt;\u0026lt; std::endl; continue; } else { if (FD_ISSET(clientfd, \u0026amp;readset)) { //检测到可读事件 char recvbuf[32]; memset(recvbuf, 0, sizeof(recvbuf)); //假设对端发数据的时候不超过31个字符。 int n = recv(clientfd, recvbuf, 32, 0); if (n \u0026lt; 0) { //除了被信号中断的情形，其他情况都是出错 if (errno != EINTR) break; } else if (n == 0) { //对端关闭了连接 break; } else { std::cout \u0026lt;\u0026lt; \u0026#34;recv data: \u0026#34; \u0026lt;\u0026lt; recvbuf \u0026lt;\u0026lt; std::endl; } } else { std::cout \u0026lt;\u0026lt; \u0026#34;other socket event.\u0026#34; \u0026lt;\u0026lt; std::endl; } } } //关闭socket close(clientfd); return 0; } 执行结果确实如我们预期的，这里 select 函数只是简单地检测一下 clientfd，并不会等待固定的时间，然后立即返回。\n4. 如果将 select 函数的 timeval 参数设置为 NULL，则 select 函数会一直阻塞下去，直到我们需要的事件触发。\n我们将上述代码再修改一下：\n/** * 验证select时间参数设置为NULL，select_client_tvnull.cpp * zhangyl 2018.12.25 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;string.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 int main(int argc, char* argv[]) { //创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); if (connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;connect socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); return -1; } int ret; while (true) { fd_set readset; FD_ZERO(\u0026amp;readset); //将侦听socket加入到待检测的可读事件中去 FD_SET(clientfd, \u0026amp;readset); //timeval tm; //tm.tv_sec = 0; //tm.tv_usec = 0; //暂且只检测可读事件，不检测可写和异常事件 ret = select(clientfd + 1, \u0026amp;readset, NULL, NULL, NULL); if (ret == -1) { //除了被信号中断的情形，其他情况都是出错 if (errno != EINTR) break; } else if (ret == 0){ //select函数超时 std::cout \u0026lt;\u0026lt; \u0026#34;no event in specific time interval.\u0026#34; \u0026lt;\u0026lt; std::endl; continue; } else { if (FD_ISSET(clientfd, \u0026amp;readset)) { //检测到可读事件 char recvbuf[32]; memset(recvbuf, 0, sizeof(recvbuf)); //假设对端发数据的时候不超过31个字符。 int n = recv(clientfd, recvbuf, 32, 0); if (n \u0026lt; 0) { //除了被信号中断的情形，其他情况都是出错 if (errno != EINTR) break; } else if (n == 0) { //对端关闭了连接 break; } else { std::cout \u0026lt;\u0026lt; \u0026#34;recv data: \u0026#34; \u0026lt;\u0026lt; recvbuf \u0026lt;\u0026lt; std::endl; } } else { std::cout \u0026lt;\u0026lt; \u0026#34;other socket event.\u0026#34; \u0026lt;\u0026lt; std::endl; } } } //关闭socket close(clientfd); return 0; } 我们先在另外一个 shell 窗口用 nc 命令模拟一个服务器，监听的 ip 地址和端口号是 0.0.0.0:3000：\n[root@myaliyun ~]# nc -v -l 0.0.0.0 3000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on 0.0.0.0:3000 然后回到原来的 shell 窗口，编译上述 select_client_tvnull.cpp，并使用 gdb 运行程序，这次使用 gdb 运行程序的目的是为了当程序“卡”在某个位置时，我们可以使用 Ctrl + C 把程序中断下来看看程序阻塞在哪个函数调用处：\n[root@myaliyun testsocket]# g++ -g -o select_client_tvnull select_client_tvnull.cpp [root@myaliyun testsocket]# gdb select_client_tvnull Reading symbols from /root/testsocket/select_client_tvnull...done. (gdb) r Starting program: /root/testsocket/select_client_tvnull ^C Program received signal SIGINT, Interrupt. 0x00007ffff72e7783 in __select_nocancel () from /lib64/libc.so.6 Missing separate debuginfos, use: debuginfo-install glibc-2.17-196.el7_4.2.x86_64 libgcc-4.8.5-16.el7_4.1.x86_64 libstdc++-4.8.5-16.el7_4.1.x86_64 (gdb) bt #0 0x00007ffff72e7783 in __select_nocancel () from /lib64/libc.so.6 #1 0x0000000000400c75 in main (argc=1, argv=0x7fffffffe5f8) at select_client_tvnull.cpp:51 (gdb) c Continuing. recv data: hello ^C Program received signal SIGINT, Interrupt. 0x00007ffff72e7783 in __select_nocancel () from /lib64/libc.so.6 (gdb) c Continuing. recv data: world 如上输出结果所示，我们使用 gdb 的 r 命令（run）将程序跑起来后，程序卡在某个地方，我们按 Ctrl + C（代码中的 ^C）中断程序后使用 bt 命令查看当前程序的调用堆栈，发现确实阻塞在 select 函数调用处；接着我们在服务器端给客户端发送一个 hello 数据：\n[root@myaliyun ~]# nc -v -l 0.0.0.0 3000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on 0.0.0.0:3000 Ncat: Connection from 127.0.0.1. Ncat: Connection from 127.0.0.1:55968. hello 客户端收到数据后，select 函数满足条件，立即返回，并将数据输出来后继续进行下一轮 select 检测，我们使用 Ctrl + C 将程序中断，发现程序又阻塞在 select 调用处；输入 c 命令（continue）让程序继续运行， 此时，我们再用服务器端给客户端发送 world 字符串，select 函数再次返回，并将数据打印出来，然后继续进入下一轮 select 检测，并继续在 select 处阻塞。\n[root@myaliyun ~]# nc -v -l 0.0.0.0 3000 Ncat: Version 6.40 ( http://nmap.org/ncat ) Ncat: Listening on 0.0.0.0:3000 Ncat: Connection from 127.0.0.1. Ncat: Connection from 127.0.0.1:55968. hello world 5. 在 Linux 平台上，select 函数的第一个参数必须设置成需要检测事件的所有 fd 中的最大值加1。所以上文中 select_server.cpp 中，每新产生一个 clientfd，我都会与当前最大的 maxfd 作比较，如果大于当前的 maxfd 则将 maxfd 更新成这个新的最大值。其最终目的是为了在 select 调用时作为第一个参数（加 1）传进去。\n在 Windows 平台上，select 函数的第一个值传任意值都可以，Windows 系统本身不使用这个值，只是为了兼容性而保留了这个参数，但是在实际开发中为了兼容跨平台代码，也会按惯例，将这个值设置为最大 socket 加 1。这点请读者注意。\n以上是我总结的 Linux 下 select 使用的五个注意事项，希望读者能理解它们。\n","permalink":"https://haokiu.com/blog/2369cd70c2354e9c844815c14f31134c/","summary":"select 函数重难点解析 select 函数是网络通信编程中非常常用的一个函数，因此应该熟练掌握它。虽然它是 BSD 标准之一的 Socket 函数之一，但在 Linux 和 Windows 平台，其行为表现还是有点区别的。我们先来看一下 Linux 平台上的 select 函数。\nLinux 平台下的 select 函数 select 函数的作用是检测一组 socket 中某个或某几个是否有“事件”，这里的“**事件”**一般分为如下三类：\n可读事件，一般意味着可以调用 recv 或 read 函数从该 socket 上读取数据；如果该 socket 是侦听 socket（即调用了 bind 函数绑定过 ip 地址和端口号，并调用了 listen 启动侦听的 socket），可读意味着此时可以有新的客户端连接到来，此时可调用 accept 函数接受新连接。 可写事件，一般意味着此时调用 send 或 write 函数可以将数据“发出去”。 异常事件，某个 socket 出现异常。 函数签名如下：\nint select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); 参数说明：\n参数 nfds， Linux 下 socket 也称 fd，这个参数的值设置成所有需要使用 select 函数监听的 fd 中最大 fd 值加 1。\n参数 readfds，需要监听可读事件的 fd 集合。\n参数 writefds，需要监听可写事件的 fd 集合。\n参数 exceptfds，需要监听异常事件 fd 集合。\nreadfds、writefds 和 exceptfds 类型都是 fd_set，这是一个结构体信息，其定义位于 /usr/include/sys/select.h 中：\n/* The fd_set member is required to be an array of longs.","title":"select 函数重难点解析"},{"content":"socket 的阻塞模式和非阻塞模式 对 socket 在阻塞和非阻塞模式下的各个函数的行为差别深入的理解是掌握网络编程的基本要求之一，是重点也是难点。\n阻塞和非阻塞模式下，我们常讨论的具有不同行为表现的 socket 函数一般有如下几个，见下表：\nconnect accept send (Linux 平台上对 socket 进行操作时也包括 write 函数，下文中对 send 函数的讨论也适用于 write 函数) recv (Linux 平台上对 socket 进行操作时也包括 read 函数，下文中对 recv 函数的讨论也适用于 read 函数) 限于文章篇幅，本文只讨论 send 和recv函数，connect 和 accept 函数我们将在该系列的后面文章中讨论。在正式讨论之前，我们先解释一下阻塞模式和非阻塞模式的概念。所谓阻塞模式，就当某个函数“执行成功的条件”当前不能满足时，该函数会阻塞当前执行线程，程序执行流在超时时间到达或“执行成功的条件”满足后恢复继续执行。而非阻塞模式恰恰相反，即使某个函数的“执行成功的条件”不当前不能满足，该函数也不会阻塞当前执行线程，而是立即返回，继续运行执行程序流。如果读者不太明白这两个定义也没关系，后面我们会以具体的示例来讲解这两种模式的区别。\n如何将 socket 设置成非阻塞模式 无论是 Windows 还是 Linux 平台，默认创建的 socket 都是阻塞模式的。\n在 Linux 平台上，我们可以使用 fcntl() 函数或 ioctl() 函数给创建的 socket 增加 O_NONBLOCK 标志来将 socket 设置成非阻塞模式。示例代码如下：\nint oldSocketFlag = fcntl(sockfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; fcntl(sockfd, F_SETFL, newSocketFlag); ioctl() 函数 与 fcntl() 函数使用方式基本一致，这里就不再给出示例代码了。\n当然，Linux 下的 socket() 创建函数也可以直接在创建时将 socket 设置为非阻塞模式，socket() 函数的签名如下：\nint socket(int domain, int type, int protocol); 给 type 参数增加一个 SOCK_NONBLOCK 标志即可，例如：\nint s = socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, IPPROTO_TCP); 不仅如此，Linux 系统下利用 accept() 函数返回的代表与客户端通信的 socket 也提供了一个扩展函数 accept4()，直接将 accept 函数返回的 socket 设置成非阻塞的。\nint accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); int accept4(int sockfd, struct sockaddr *addr, socklen_t *addrlen, int flags); 只要将 accept4() 函数最后一个参数 flags 设置成 SOCK_NONBLOCK 即可。也就是说以下代码是等价的：\nsocklen_t addrlen = sizeof(clientaddr); int clientfd = accept4(listenfd, \u0026amp;clientaddr, \u0026amp;addrlen, SOCK_NONBLOCK); socklen_t addrlen = sizeof(clientaddr); int clientfd = accept(listenfd, \u0026amp;clientaddr, \u0026amp;addrlen); if (clientfd != -1) { int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; fcntl(clientfd, F_SETFL, newSocketFlag); } 在 Windows 平台上，可以调用 ioctlsocket() 函数 将 socket 设置成非阻塞模式，ioctlsocket() 签名如下：\nint ioctlsocket(SOCKET s, long cmd, u_long *argp); 将 cmd 参数设置为 FIONBIO，*argp* 设置为 0 即可将 socket 设置成阻塞模式，而将 argp 设置成非 0 即可设置成非阻塞模式。示例如下：\n//将 socket 设置成非阻塞模式 u_long argp = 1; ioctlsocket(s, FIONBIO, \u0026amp;argp); //将 socket 设置成阻塞模式 u_long argp = 0; ioctlsocket(s, FIONBIO, \u0026amp;argp); Windows 平台需要注意一个地方，如果对一个 socket 调用了 WSAAsyncSelect() 或 WSAEventSelect() 函数后，再调用 ioctlsocket() 函数将该 socket 设置为非阻塞模式会失败，你必须先调用 WSAAsyncSelect() 通过将 lEvent 参数为 0 或调用 WSAEventSelect() 通过设置 lNetworkEvents 参数为 0 来清除已经设置的 socket 相关标志位，再次调用 ioctlsocket() 将该 socket 设置成阻塞模式才会成功。因为调用 WSAAsyncSelect() 或WSAEventSelect() 函数会自动将 socket 设置成非阻塞模式。MSDN 上原文（https://docs.microsoft.com/en-us/windows/desktop/api/winsock/nf-winsock-ioctlsocket）如下：\nThe WSAAsyncSelect and WSAEventSelect functions automatically set a socket to nonblocking mode. If WSAAsyncSelect or WSAEventSelect has been issued on a socket, then any attempt to use ioctlsocket to set the socket back to blocking mode will fail with WSAEINVAL. To set the socket back to blocking mode, an application must first disable WSAAsyncSelect by calling WSAAsyncSelect with the lEvent parameter equal to zero, or disable WSAEventSelect by calling WSAEventSelect with the lNetworkEvents parameter equal to zero. 关于 WSAAsyncSelect() 和 WSAEventSelect() 这两个函数，后文中会详细讲解。\n注意事项：无论是 Linux 的 fcntl 函数，还是 Windows 的 ioctlsocket，建议读者在实际编码中判断一下函数返回值以确定是否调用成功。\nsend 和 recv 函数在阻塞和非阻塞模式下的行为\nsend 和 recv 函数其实名不符实。\nsend 函数本质上并不是往网络上发送数据，而是将应用层发送缓冲区的数据拷贝到内核缓冲区（下文为了叙述方便，我们以“网卡缓冲区”代指）中去，至于什么时候数据会从网卡缓冲区中真正地发到网络中去要根据 TCP/IP 协议栈的行为来确定，这种行为涉及到一个叫 nagel 算法和 TCP_NODELAY 的 socket 选项，我们将在《nagle算法与 TCP_NODELAY》章节详细介绍。\nrecv 函数本质上也并不是从网络上收取数据，而只是将内核缓冲区中的数据拷贝到应用程序的缓冲区中，当然拷贝完成以后会将内核缓冲区中该部分数据移除。\n可以用下面一张图来描述上述事实：\n通过上图我们知道，不同的程序进行网络通信时，发送的一方会将内核缓冲区的数据通过网络传输给接收方的内核缓冲区。在应用程序 A 与 应用程序 B 建立了 TCP 连接之后，假设应用程序 A 不断调用 send 函数，这样数据会不断拷贝至对应的内核缓冲区中，如果 B 那一端一直不调用 recv 函数，那么 B 的内核缓冲区被填满以后，A 的内核缓冲区也会被填满，此时 A 继续调用 send 函数会是什么结果呢？ 具体的结果取决于该 socket 是否是阻塞模式。我们这里先给出结论：\n当 socket 是阻塞模式的，继续调用 send/recv 函数会导致程序阻塞在 send/recv 调用处。 当 socket 是非阻塞模式，继续调用 send/recv 函数，send/recv 函数不会阻塞程序执行流，而是会立即出错返回，我们会得到一个相关的错误码，Linux 平台上该错误码为 EWOULDBLOCK 或 EAGAIN（这两个错误码值相同），Windows 平台上错误码为 WSAEWOULDBLOCK。 我们实际来编写一下代码来验证一下以上说的两种情况。\nsocket 阻塞模式下的 send 行为 服务端代码（blocking_server.cpp）如下：\n/** * 验证阻塞模式下send函数的行为，server端 * zhangyl 2018.12.17 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; int main(int argc, char* argv[]) { //1.创建一个侦听socket int listenfd = socket(AF_INET, SOCK_STREAM, 0); if (listenfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //2.初始化服务器地址 struct sockaddr_in bindaddr; bindaddr.sin_family = AF_INET; bindaddr.sin_addr.s_addr = htonl(INADDR_ANY); bindaddr.sin_port = htons(3000); if (bind(listenfd, (struct sockaddr *)\u0026amp;bindaddr, sizeof(bindaddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;bind listen socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(listenfd); return -1; } //3.启动侦听 if (listen(listenfd, SOMAXCONN) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;listen error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(listenfd); return -1; } while (true) { struct sockaddr_in clientaddr; socklen_t clientaddrlen = sizeof(clientaddr); //4. 接受客户端连接 int clientfd = accept(listenfd, (struct sockaddr *)\u0026amp;clientaddr, \u0026amp;clientaddrlen); if (clientfd != -1) { //只接受连接，不调用recv收取任何数据 std:: cout \u0026lt;\u0026lt; \u0026#34;accept a client connection.\u0026#34; \u0026lt;\u0026lt; std::endl; } } //7.关闭侦听socket close(listenfd); return 0; } 客户端代码（blocking_client.cpp）如下：\n/** * 验证阻塞模式下send函数的行为，client端 * zhangyl 2018.12.17 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 #define SEND_DATA \u0026#34;helloworld\u0026#34; int main(int argc, char* argv[]) { //1.创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); return -1; } //2.连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); if (connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;connect socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //3. 不断向服务器发送数据，或者出错退出 int count = 0; while (true) { int ret = send(clientfd, SEND_DATA, strlen(SEND_DATA), 0); if (ret != strlen(SEND_DATA)) { std::cout \u0026lt;\u0026lt; \u0026#34;send data error.\u0026#34; \u0026lt;\u0026lt; std::endl; break; } else { count ++; std::cout \u0026lt;\u0026lt; \u0026#34;send data successfully, count = \u0026#34; \u0026lt;\u0026lt; count \u0026lt;\u0026lt; std::endl; } } //5. 关闭socket close(clientfd); return 0; } 在 shell 中分别编译这两个 cpp 文件得到两个可执行程序 blocking_server 和 blocking_client：\ng++ -g -o blocking_server blocking_server.cpp g++ -g -o blocking_client blocking_client.cpp 我们先启动 blocking_server，然后用 gdb 启动 blocking_client，输入 run 命令让 blocking_client跑起来，blocking_client 会不断地向 blocking_server 发送\u0026quot;helloworld\u0026ldquo;字符串，每次 send 成功后，会将计数器 count 的值打印出来，计数器会不断增加，程序运行一段时间后，计数器 count 值不再增加且程序不再有输出。操作过程及输出结果如下：\nblocking_server 端：\n[root@localhost testsocket]# ./blocking_server accept a client connection. [root@localhost testsocket]# gdb blocking_client GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-100.el7_4.1 Copyright (C) 2013 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later \u0026lt;http://gnu.org/licenses/gpl.html\u0026gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type \u0026#34;show copying\u0026#34; and \u0026#34;show warranty\u0026#34; for details. This GDB was configured as \u0026#34;x86_64-redhat-linux-gnu\u0026#34;. For bug reporting instructions, please see: \u0026lt;http://www.gnu.org/software/gdb/bugs/\u0026gt;... Reading symbols from /root/testsocket/blocking_client...done. (gdb) run //输出结果太多，省略部分... send data successfully, count = 355384 send data successfully, count = 355385 send data successfully, count = 355386 send data successfully, count = 355387 send data successfully, count = 355388 send data successfully, count = 355389 send data successfully, count = 355390 此时程序不再有输出，说明我们的程序应该“卡在”某个地方，继续按 Ctrl + C 让 gdb 中断下来，输入 bt 命令查看此时的调用堆栈，我们发现我们的程序确实阻塞在 send 函数调用处：\n^C Program received signal SIGINT, Interrupt. 0x00007ffff72f130d in send () from /lib64/libc.so.6 (gdb) bt #0 0x00007ffff72f130d in send () from /lib64/libc.so.6 #1 0x0000000000400b46 in main (argc=1, argv=0x7fffffffe598) at blocking_client.cpp:41 (gdb) 上面的示例验证了如果一端一直发数据，而对端应用层一直不取数据（或收取数据的速度慢于发送速度），则很快两端的内核缓冲区很快就会被填满，导致发送端调用 send 函数被阻塞。这里说的“内核缓冲区” 其实有个专门的名字，即 TCP 窗口。也就是说 socket 阻塞模式下， send 函数在 TCP 窗口太小时的行为是阻塞当前程序执行流（即阻塞 send 函数所在的线程的执行）。\n说点题外话，上面的例子，我们每次发送一个“helloworld”（10个字节），一共发了 355390 次（每次测试的结果略有不同），我们可以粗略地算出 TCP 窗口的大小大约等于 1.7 M左右 （10 * 355390 / 2）。\n让我们再深入一点，我们利用 Linux tcpdump 工具来动态看一下这种情形下 TCP 窗口大小的动态变化。需要注意的是，Linux 下使用 tcpdump 这个命令需要有 root 权限。\n我们开启三个 shell 窗口，在第一个窗口先启动 blocking_server 进程，在第二个窗口用 tcpdump 抓经过 TCP 端口 3000 上的数据包：\n[root@localhost testsocket]# tcpdump -i any -nn -S \u0026#39;tcp port 3000\u0026#39; tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 接着在第三个 shell 窗口，启动 blocking_client。当 blocking_client 进程不再输出时，我们抓包的结果如下：\n[root@localhost testsocket]# tcpdump -i any -nn -S \u0026#39;tcp port 3000\u0026#39; tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on any, link-type LINUX_SLL (Linux cooked), capture size 262144 bytes 11:52:35.907381 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [S], seq 1394135076, win 43690, options [mss 65495,sackOK,TS val 78907688 ecr 0,nop,wscale 7], length 0 20:32:21.261484 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [S.], seq 1233000591, ack 1394135077, win 43690, options [mss 65495,sackOK,TS val 78907688 ecr 78907688,nop,wscale 7], length 0 11:52:35.907441 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [.], ack 1233000592, win 342, options [nop,nop,TS val 78907688 ecr 78907688], length 0 11:52:35.907615 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [P.], seq 1394135077:1394135087, ack 1233000592, win 342, options [nop,nop,TS val 78907688 ecr 78907688], length 10 11:52:35.907626 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1394135087, win 342, options [nop,nop,TS val 78907688 ecr 78907688], length 0 11:52:35.907785 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [P.], seq 1394135087:1394135097, ack 1233000592, win 342, options [nop,nop,TS val 78907688 ecr 78907688], length 10 11:52:35.907793 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1394135097, win 342, options [nop,nop,TS val 78907688 ecr 78907688], length 0 11:52:35.907809 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [P.], seq 1394135097:1394135107, ack 1233000592, win 342, options [nop,nop,TS val 78907688 ecr 78907688], length 10 11:52:35.907814 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1394135107, win 342, options [nop,nop,TS val 78907688 ecr 78907688], length 0 ...内容太长， 部分省略... 11:52:40.075794 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1395013717, win 374, options [nop,nop,TS val 78911856 ecr 78911816], length 0 11:52:40.075829 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [P.], seq 1395013717:1395030517, ack 1233000592, win 342, options [nop,nop,TS val 78911856 ecr 78911856], length 16800 11:52:40.115847 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1395030517, win 305, options [nop,nop,TS val 78911896 ecr 78911856], length 0 11:52:40.115866 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [P.], seq 1395030517:1395047317, ack 1233000592, win 342, options [nop,nop,TS val 78911896 ecr 78911896], length 16800 11:52:40.155703 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1395047317, win 174, options [nop,nop,TS val 78911936 ecr 78911896], length 0 11:52:40.155752 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [P.], seq 1395047317:1395064117, ack 1233000592, win 342, options [nop,nop,TS val 78911936 ecr 78911936], length 16800 11:52:40.195132 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1395064117, win 43, options [nop,nop,TS val 78911976 ecr 78911936], length 0 11:52:40.435748 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [P.], seq 1395064117:1395069621, ack 1233000592, win 342, options [nop,nop,TS val 78912216 ecr 78911976], length 5504 11:52:40.435782 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1395069621, win 0, options [nop,nop,TS val 78912216 ecr 78912216], length 0 11:52:40.670661 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [.], ack 1233000592, win 342, options [nop,nop,TS val 78912451 ecr 78912216], length 0 11:52:40.670674 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1395069621, win 0, options [nop,nop,TS val 78912451 ecr 78912216], length 0 11:52:41.141703 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [.], ack 1233000592, win 342, options [nop,nop,TS val 78912922 ecr 78912451], length 0 11:52:42.083643 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [.], ack 1233000592, win 342, options [nop,nop,TS val 78913864 ecr 78912451], length 0 11:52:42.083655 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1395069621, win 0, options [nop,nop,TS val 78913864 ecr 78912216], length 0 11:52:43.967506 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [.], ack 1233000592, win 342, options [nop,nop,TS val 78915748 ecr 78913864], length 0 11:52:43.967532 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1395069621, win 0, options [nop,nop,TS val 78915748 ecr 78912216], length 0 11:52:47.739259 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [.], ack 1233000592, win 342, options [nop,nop,TS val 78919520 ecr 78915748], length 0 11:52:47.739274 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1395069621, win 0, options [nop,nop,TS val 78919520 ecr 78912216], length 0 11:52:55.275863 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [.], ack 1233000592, win 342, options [nop,nop,TS val 78927056 ecr 78919520], length 0 11:52:55.275931 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [.], ack 1395069621, win 0, options [nop,nop,TS val 78927056 ecr 78912216], length 0 抓取到的前三个数据包是 blocking_client 与 blocking_server 建立三次握手的过程。\n11:52:35.907381 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [S], seq 1394135076, win 43690, options [mss 65495,sackOK,TS val 78907688 ecr 0,nop,wscale 7], length 0 20:32:21.261484 IP 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846: Flags [S.], seq 1233000591, ack 1394135077, win 43690, options [mss 65495,sackOK,TS val 78907688 ecr 78907688,nop,wscale 7], length 0 11:52:35.907441 IP 127.0.0.1.40846 \u0026gt; 127.0.0.1.3000: Flags [.], ack 1233000592, win 342, options [nop,nop,TS val 78907688 ecr 78907688], length 0 示意图如下：\n当每次 blocking_client 给 blocking_server 发数据以后，blocking_server 会应答 blocking_server，在每次应答的数据包中会带上自己的当前可用 TCP 窗口大小（看上文中结果从 127.0.0.1.3000 \u0026gt; 127.0.0.1.40846方向的数据包的 win 字段大小变化），由于 TCP 流量控制和拥赛控制机制的存在，blocking_server 端的 TCP 窗口大小短期内会慢慢增加，后面随着接收缓冲区中数据积压越来越多， TCP 窗口会慢慢变小，最终变为 0。\n另外，细心的读者如果实际去做一下这个实验会发现一个现象，即当 tcpdump 已经显示对端的 TCP 窗口是 0 时， blocking_client 仍然可以继续发送一段时间的数据，此时的数据已经不是在发往对端，而是逐渐填满到本端的内核发送缓冲区中去了，这也验证了 send 函数实际上是往内核缓冲区中拷贝数据这一行为。\nsocket 非阻塞模式下的 send 行为 我们再来验证一下非阻塞 socket 的 send 行为，server 端的代码不变，我们将 blocking_client.cpp 中 socket 设置成非阻塞的，修改后的代码如下：\n/** * 验证非阻塞模式下send函数的行为，client端，nonblocking_client.cpp * zhangyl 2018.12.17 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 #define SEND_DATA \u0026#34;helloworld\u0026#34; int main(int argc, char* argv[]) { //1.创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //2.连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); if (connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;connect socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); return -1; } //连接成功以后，我们再将 clientfd 设置成非阻塞模式， //不能在创建时就设置，这样会影响到 connect 函数的行为 int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(clientfd, F_SETFL, newSocketFlag) == -1) { close(clientfd); std::cout \u0026lt;\u0026lt; \u0026#34;set socket to nonblock error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //3. 不断向服务器发送数据，或者出错退出 int count = 0; while (true) { int ret = send(clientfd, SEND_DATA, strlen(SEND_DATA), 0); if (ret == -1) { //非阻塞模式下send函数由于TCP窗口太小发不出去数据，错误码是EWOULDBLOCK if (errno == EWOULDBLOCK) { std::cout \u0026lt;\u0026lt; \u0026#34;send data error as TCP Window size is too small.\u0026#34; \u0026lt;\u0026lt; std::endl; continue; } else if (errno == EINTR) { //如果被信号中断，我们继续重试 std::cout \u0026lt;\u0026lt; \u0026#34;sending data interrupted by signal.\u0026#34; \u0026lt;\u0026lt; std::endl; continue; } else { std::cout \u0026lt;\u0026lt; \u0026#34;send data error.\u0026#34; \u0026lt;\u0026lt; std::endl; break; } } if (ret == 0) { //对端关闭了连接，我们也关闭 std::cout \u0026lt;\u0026lt; \u0026#34;send data error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); break; } else { count ++; std::cout \u0026lt;\u0026lt; \u0026#34;send data successfully, count = \u0026#34; \u0026lt;\u0026lt; count \u0026lt;\u0026lt; std::endl; } } //5. 关闭socket close(clientfd); return 0; } 编译 nonblocking_client.cpp 得到可执行程序 nonblocking_client：\ng++ -g -o nonblocking_client nonblocking_client.cpp 运行 nonblocking_client，运行一段时间后，由于对端和本端的 TCP 窗口已满，数据发不出去了，但是 send 函数不会阻塞，而是立即返回，返回值是 -1（Windows 系统上 返回 SOCKET_ERROR，这个宏的值也是 -1），此时得到错误码是 EWOULDBLOCK。执行结果如下：\nsocket 阻塞模式下的 recv 行为 在了解了 send 函数的行为，我们再来看一下阻塞模式下的 recv 函数行为。服务器端代码不需要修改，我们修改一下客户端代码，如果服务器端不给客户端发数据，此时客户端调用 recv 函数执行流会阻塞在 recv 函数调用处。继续修改一下客户端代码：\n/** * 验证阻塞模式下recv函数的行为，client端，blocking_client_recv.cpp * zhangyl 2018.12.17 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 #define SEND_DATA \u0026#34;helloworld\u0026#34; int main(int argc, char* argv[]) { //1.创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //2.连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); if (connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;connect socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); return -1; } //直接调用recv函数，程序会阻塞在recv函数调用处 char recvbuf[32] = {0}; int ret = recv(clientfd, recvbuf, 32, 0); if (ret \u0026gt; 0) { std::cout \u0026lt;\u0026lt; \u0026#34;recv successfully.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;recv data error.\u0026#34; \u0026lt;\u0026lt; std::endl; } //5. 关闭socket close(clientfd); return 0; } 编译 blocking_client_recv.cpp 并使用启动，我们发现程序既没有打印 recv 调用成功的信息也没有调用失败的信息，将程序中断下来，使用 bt 命令查看此时的调用堆栈，发现程序确实阻塞在 recv 函数调用处。\n[root@localhost testsocket]# g++ -g -o blocking_client_recv blocking_client_recv.cpp [root@localhost testsocket]# gdb blocking_client_recv Reading symbols from /root/testsocket/blocking_client_recv...done. (gdb) r Starting program: /root/testsocket/blocking_client_recv ^C Program received signal SIGINT, Interrupt. 0x00007ffff72f119d in recv () from /lib64/libc.so.6 Missing separate debuginfos, use: debuginfo-install glibc-2.17-196.el7_4.2.x86_64 libgcc-4.8.5-16.el7_4.2.x86_64 libstdc++-4.8.5-16.el7_4.2.x86_64 (gdb) bt #0 0x00007ffff72f119d in recv () from /lib64/libc.so.6 #1 0x0000000000400b18 in main (argc=1, argv=0x7fffffffe588) at blocking_client_recv.cpp:40 socket 非阻塞模式下的 recv 行为 非阻塞模式下如果当前无数据可读，recv 函数将立即返回，返回值为 -1，错误码为 EWOULDBLOCK。将客户端代码修成一下：\n/** * 验证阻塞模式下recv函数的行为，client端，blocking_client_recv.cpp * zhangyl 2018.12.17 */ #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #define SERVER_ADDRESS \u0026#34;127.0.0.1\u0026#34; #define SERVER_PORT 3000 #define SEND_DATA \u0026#34;helloworld\u0026#34; int main(int argc, char* argv[]) { //1.创建一个socket int clientfd = socket(AF_INET, SOCK_STREAM, 0); if (clientfd == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;create client socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //2.连接服务器 struct sockaddr_in serveraddr; serveraddr.sin_family = AF_INET; serveraddr.sin_addr.s_addr = inet_addr(SERVER_ADDRESS); serveraddr.sin_port = htons(SERVER_PORT); if (connect(clientfd, (struct sockaddr *)\u0026amp;serveraddr, sizeof(serveraddr)) == -1) { std::cout \u0026lt;\u0026lt; \u0026#34;connect socket error.\u0026#34; \u0026lt;\u0026lt; std::endl; close(clientfd); return -1; } //连接成功以后，我们再将 clientfd 设置成非阻塞模式， //不能在创建时就设置，这样会影响到 connect 函数的行为 int oldSocketFlag = fcntl(clientfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; if (fcntl(clientfd, F_SETFL, newSocketFlag) == -1) { close(clientfd); std::cout \u0026lt;\u0026lt; \u0026#34;set socket to nonblock error.\u0026#34; \u0026lt;\u0026lt; std::endl; return -1; } //直接调用recv函数，程序会阻塞在recv函数调用处 while (true) { char recvbuf[32] = {0}; int ret = recv(clientfd, recvbuf, 32, 0); if (ret \u0026gt; 0) { //收到了数据 std::cout \u0026lt;\u0026lt; \u0026#34;recv successfully.\u0026#34; \u0026lt;\u0026lt; std::endl; } else if (ret == 0) { //对端关闭了连接 std::cout \u0026lt;\u0026lt; \u0026#34;peer close the socket.\u0026#34; \u0026lt;\u0026lt; std::endl; break; } else if (ret == -1) { if (errno == EWOULDBLOCK) { std::cout \u0026lt;\u0026lt; \u0026#34;There is no data available now.\u0026#34; \u0026lt;\u0026lt; std::endl; } else if (errno == EINTR) { //如果被信号中断了，则继续重试recv函数 std::cout \u0026lt;\u0026lt; \u0026#34;recv data interrupted by signal.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { //真的出错了 break; } } } //5. 关闭socket close(clientfd); return 0; } 执行结果与我们预期的一模一样， recv 函数在无数据可读的情况下并不会阻塞情绪，所以程序会一直有“There is no data available now.”相关的输出。\n","permalink":"https://haokiu.com/blog/7a9421787c4a4e7482e4f3ea6234c7ac/","summary":"socket 的阻塞模式和非阻塞模式 对 socket 在阻塞和非阻塞模式下的各个函数的行为差别深入的理解是掌握网络编程的基本要求之一，是重点也是难点。\n阻塞和非阻塞模式下，我们常讨论的具有不同行为表现的 socket 函数一般有如下几个，见下表：\nconnect accept send (Linux 平台上对 socket 进行操作时也包括 write 函数，下文中对 send 函数的讨论也适用于 write 函数) recv (Linux 平台上对 socket 进行操作时也包括 read 函数，下文中对 recv 函数的讨论也适用于 read 函数) 限于文章篇幅，本文只讨论 send 和recv函数，connect 和 accept 函数我们将在该系列的后面文章中讨论。在正式讨论之前，我们先解释一下阻塞模式和非阻塞模式的概念。所谓阻塞模式，就当某个函数“执行成功的条件”当前不能满足时，该函数会阻塞当前执行线程，程序执行流在超时时间到达或“执行成功的条件”满足后恢复继续执行。而非阻塞模式恰恰相反，即使某个函数的“执行成功的条件”不当前不能满足，该函数也不会阻塞当前执行线程，而是立即返回，继续运行执行程序流。如果读者不太明白这两个定义也没关系，后面我们会以具体的示例来讲解这两种模式的区别。\n如何将 socket 设置成非阻塞模式 无论是 Windows 还是 Linux 平台，默认创建的 socket 都是阻塞模式的。\n在 Linux 平台上，我们可以使用 fcntl() 函数或 ioctl() 函数给创建的 socket 增加 O_NONBLOCK 标志来将 socket 设置成非阻塞模式。示例代码如下：\nint oldSocketFlag = fcntl(sockfd, F_GETFL, 0); int newSocketFlag = oldSocketFlag | O_NONBLOCK; fcntl(sockfd, F_SETFL, newSocketFlag); ioctl() 函数 与 fcntl() 函数使用方式基本一致，这里就不再给出示例代码了。\n当然，Linux 下的 socket() 创建函数也可以直接在创建时将 socket 设置为非阻塞模式，socket() 函数的签名如下：\nint socket(int domain, int type, int protocol); 给 type 参数增加一个 SOCK_NONBLOCK 标志即可，例如：","title":"socket 的阻塞模式和非阻塞模式"},{"content":"TCP 协议如何解决粘包、半包问题 一 TCP 协议是流式协议 很多读者从接触网络知识以来，应该听说过这句话：TCP 协议是流式协议。那么这句话到底是什么意思呢？所谓流式协议，即协议的内容是像流水一样的字节流，内容与内容之间没有明确的分界标志，需要我们人为地去给这些协议划分边界。\n举个例子，A 与 B 进行 TCP 通信，A 先后给 B 发送了一个 100 字节和 200 字节的数据包，那么 B 是如何收到呢？B 可能先收到 100 字节，再收到 200 字节；也可能先收到 50 字节，再收到 250 字节；或者先收到 100 字节，再收到 100 字节，再收到 200 字节；或者先收到 20 字节，再收到 20 字节，再收到 60 字节，再收到 100 字节，再收到 50 字节，再收到 50 字节……\n不知道读者看出规律没有？规律就是 A 一共给 B 发送了 300 字节，B 可能以一次或者多次任意形式的总数为 300 字节收到。假设 A 给 B 发送的 100 字节和 200 字节分别都是一个数据包，对于发送端 A 来说，这个是可以区分的，但是对于 B 来说，如果不人为规定多长为一个数据包，B 每次是不知道应该把收到的数据中多少字节作为一个有效的数据包的。而规定每次把多少数据当成一个包就是协议格式规范的内容之一。\n经常会有新手写出类似下面这样的代码：\n发送端：\n//...省略创建socket，建立连接等部分不相关的逻辑... char buf[] = \u0026#34;the quick brown fox jumps over a lazy dog.\u0026#34;; int n = send(socket, buf, strlen(buf), 0); //...省略出错处理逻辑... 接收端：\n//省略创建socket，建立连接等部分不相关的逻辑... char recvBuf[50] = { 0 }; int n = recv(socket, recvBuf, 50, 0); //省略出错处理逻辑... printf(\u0026#34;recvBuf: %s\u0026#34;, recvBuf); 为了专注问题本身的讨论，我这里省略掉了建立连接和部分错误处理的逻辑。上述代码中发送端给接收端发送了一串字符”the quick brown fox jumps over a lazy dog.“，接收端收到后将其打印出来。\n类似这样的代码在本机一般会工作的很好，接收端也如期打印出来预料的字符串，但是一放到局域网或者公网环境就出问题了，即接收端可能打印出来字符串并不完整；如果发送端连续多次发送字符串，接收端会打印出来的字符串不完整或出现乱码。不完整的原因很好理解，即对端某次收到的数据小于完整字符串的长度，recvBuf 数组开始被清空成 0，收到部分字符串后，该字符串的末尾仍然是 0，printf 函数寻找以 0 为结束标志的字符结束输出；乱码的原因是如果某次收入的数据不仅包含一个完整的字符串，还包含下一个字符串部分内容，那么 recvBuf 数组将会被填满，printf 函数输出时仍然会寻找以 0 为结束标志的字符结束输出，这样读取的内存就越界了，一直找到为止，而越界后的内存可能是一些不可读字符，显示出来后就乱码了。\n我举这个例子希望你明白 能对TCP 协议是流式协议有一个直观的认识。正因为如此，所以我们需要人为地在发送端和接收端规定每一次的字节流边界，以便接收端知道从什么位置取出多少字节来当成一个数据包去解析，这就是我们设计网络通信协议格式的要做的工作之一。\n二 如何解决粘包问题 网络通信程序实际开发中，或者技术面试时，面试官通常会问的比较多的一个问题是：网络通信时，如何解决粘包？\n有的面试官可能会这么问：网络通信时，如何解决粘包、丢包或者包乱序问题？这个问题其实是面试官在考察面试者的网络基础知识，如果是 TCP 协议，在大多数场景下，是不存在丢包和包乱序问题的，TCP 通信是可靠通信方式，TCP 协议栈通过序列号和包重传确认机制保证数据包的有序和一定被正确发到目的地；如果是 UDP 协议，如果不能接受少量丢包，那就要自己在 UDP 的基础上实现类似 TCP 这种有序和可靠传输机制了（例如 RTP协议、RUDP 协议）。所以，问题拆解后，只剩下如何解决粘包的问题。\n先来解释一下什么是粘包，所谓粘包就是连续给对端发送两个或者两个以上的数据包，对端在一次收取中可能收到的数据包大于 1 个，大于 1 个，可能是几个（包括一个）包加上某个包的部分，或者干脆就是几个完整的包在一起。当然，也可能收到的数据只是一个包的部分，这种情况一般也叫半包。\n无论是半包还是粘包问题，其根源是上文介绍中 TCP 协议是流式数据格式。解决问题的思路还是想办法从收到的数据中把包与包的边界给区分出来。那么如何区分呢？目前主要有三种方法：\n固定包长的数据包\n顾名思义，即每个协议包的长度都是固定的。举个例子，例如我们可以规定每个协议包的大小是 64 个字节，每次收满 64 个字节，就取出来解析（如果不够，就先存起来）。\n这种通信协议的格式简单但灵活性差。如果包内容不足指定的字节数，剩余的空间需要填充特殊的信息，如 \\0（如果不填充特殊内容，如何区分包里面的正常内容与填充信息呢？）；如果包内容超过指定字节数，又得分包分片，需要增加额外处理逻辑——在发送端进行分包分片，在接收端重新组装包片（分包和分片内容在接下来会详细介绍）。\n以指定字符（串）为包的结束标志\n这种协议包比较常见，即字节流中遇到特殊的符号值时就认为到一个包的末尾了。例如，我们熟悉的 FTP协议，发邮件的 SMTP 协议，一个命令或者一段数据后面加上\u0026quot;\\r\\n\u0026quot;（即所谓的 CRLF）表示一个包的结束。对端收到后，每遇到一个”\\r\\n“就把之前的数据当做一个数据包。\n这种协议一般用于一些包含各种命令控制的应用中，其不足之处就是如果协议数据包内容部分需要使用包结束标志字符，就需要对这些字符做转码或者转义操作，以免被接收方错误地当成包结束标志而误解析。\n包头 + 包体格式\n这种格式的包一般分为两部分，即包头和包体，包头是固定大小的，且包头中必须含有一个字段来说明接下来的包体有多大。\n例如：\nstruct msg_header { int32_t bodySize; int32_t cmd; }; 这就是一个典型的包头格式，bodySize 指定了这个包的包体是多大。由于包头大小是固定的（这里是 size(int32_t) + sizeof(int32_t) = 8 字节），对端先收取包头大小字节数目（当然，如果不够还是先缓存起来，直到收够为止），然后解析包头，根据包头中指定的包体大小来收取包体，等包体收够了，就组装成一个完整的包来处理。在有些实现中，包头中的 bodySize可能被另外一个叫 packageSize 的字段代替，这个字段的含义是整个包的大小，这个时候，我们只要用 packageSize 减去包头大小（这里是 sizeof(msg_header)）就能算出包体的大小，原理同上。\n在使用大多数网络库时，通常你需要根据协议格式自己给数据包分界和解析，一般的网络库不提供这种功能是出于需要支持不同的协议，由于协议的不确定性，因此没法预先提供具体解包代码。当然，这不是绝对的，也有一些网络库提供了这种功能。在 Java Netty 网络框架中，提供了FixedLengthFrameDecoder 类去处理长度是定长的协议包，提供了 DelimiterBasedFrameDecoder 类去处理按特殊字符作为结束符的协议包，提供 ByteToMessageDecoder 去处理自定义格式的协议包（可用来处理包头 + 包体 这种格式的数据包），然而在继承 ByteToMessageDecoder 子类中你需要根据你的协议具体格式重写 decode() 方法来对数据包解包。\n这三种包格式，希望读者能在理解其原理和优缺点的基础上深入掌握。\n三 解包与处理 在理解了前面介绍的数据包的三种格式后，我们来介绍一下针对上述三种格式的数据包技术上应该如何处理。其处理流程都是一样的，这里我们以包头 + 包体 这种格式的数据包来说明。处理流程如下：\n假设我们的包头格式如下：\n//强制一字节对齐 #pragma pack(push, 1) //协议头 struct msg { int32_t bodysize; //包体大小 }; #pragma pack(pop) 那么上面的流程实现代码如下：\n//包最大字节数限制为10M #define MAX_PACKAGE_SIZE 10 * 1024 * 1024 void ChatSession::OnRead(const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn, Buffer* pBuffer, Timestamp receivTime) { while (true) { //不够一个包头大小 if (pBuffer-\u0026gt;readableBytes() \u0026lt; (size_t)sizeof(msg)) { //LOGI \u0026lt;\u0026lt; \u0026#34;buffer is not enough for a package header, pBuffer-\u0026gt;readableBytes()=\u0026#34; \u0026lt;\u0026lt; pBuffer-\u0026gt;readableBytes() \u0026lt;\u0026lt; \u0026#34;, sizeof(msg)=\u0026#34; \u0026lt;\u0026lt; sizeof(msg); return; } //取包头信息 msg header; memcpy(\u0026amp;header, pBuffer-\u0026gt;peek(), sizeof(msg)); //包头有错误，立即关闭连接 if (header.bodysize \u0026lt;= 0 || header.bodysize \u0026gt; MAX_PACKAGE_SIZE) { //客户端发非法数据包，服务器主动关闭之 LOGE(\u0026#34;Illegal package, bodysize: %lld, close TcpConnection, client: %s\u0026#34;, header.bodysize, conn-\u0026gt;peerAddress().toIpPort().c_str()); conn-\u0026gt;forceClose(); return; } //收到的数据不够一个完整的包 if (pBuffer-\u0026gt;readableBytes() \u0026lt; (size_t)header.bodysize + sizeof(msg)) return; pBuffer-\u0026gt;retrieve(sizeof(msg)); //inbuf用来存放当前要处理的包 std::string inbuf; inbuf.append(pBuffer-\u0026gt;peek(), header.bodysize); pBuffer-\u0026gt;retrieve(header.bodysize); //解包和业务处理 if (!Process(conn, inbuf.c_str(), inbuf.length())) { //客户端发非法数据包，服务器主动关闭之 LOGE(\u0026#34;Process package error, close TcpConnection, client: %s\u0026#34;, conn-\u0026gt;peerAddress().toIpPort().c_str()); conn-\u0026gt;forceClose(); return; } }// end while-loop } 上述流程代码的处理过程和流程图中是一致的，pBuffer 这里是一个自定义的接收缓冲区，这里的代码，已经将收到的数据放入了这个缓冲区，所以判断当前已收取的字节数目只需要使用这个对象的相应方法即可。上述代码有些细节我需要强调一下：\n取包头时，你应该拷贝一份数据包头大小的数据出来，而不是从缓冲区 pBuffer 中直接将数据取出来（即取出来的数据从 pBuffer 中移除），这是因为倘若接下来根据包头中的字段得到包体大小时，如果剩余数据不够一个包体大小，你又得把这个包头数据放回缓冲区。为了避免这种不必要的操作，只有缓冲区数据大小够整个包的大小（代码中：header.bodysize + sizeof(msg)）你才需要把整个包大小的数据从缓冲区移除，这也是这里的 pBuffer-\u0026gt;peek() 方法 peek 单词的含义（中文可以翻译成“瞟一眼”或者“偷窥”）。 通过包头得到包体大小时，你一定要对 bodysize 的数值进行校验，我这里要求 bodysize 必须大于 0 且不大于 10 * 1024 * 1024（即 10 M）。当然，实际开发中，你可以根据你自己的需求要决定 bodysize 的上下限（包体大小是 0 字节的包在某些业务场景下是允许的）。记住，一定要判断这个上下限，因为假设这是一个非法的客户端发来的数据，其 bodysize 设置了一个比较大的数值，例如 1 * 1024 * 1024 * 1024（即 1 G），你的逻辑会让你一直缓存该客户端发来的数据，那么很快你的服务器内存将会被耗尽，操作系统在检测到你的进程占用内存达到一定阈值时会杀死你的进程，导致服务不能再正常对外服务。如果你检测了 bodysize 字段的是否满足你设置的上下限，对于非法的 bodysize，直接关闭这路连接即可。这也是服务的一种自我保护措施，避免因为非法数据包带来的损失。 不知道你有没有注意到整个判断包头、包体以及处理包的逻辑放在一个 while 循环里面，这是必要的。如果没有这个 while 循环，当你一次性收到多个包时，你只会处理一个，下次接着处理就需要等到新一批数据来临时再次触发这个逻辑。这样造成的结果就是，对端给你发送了多个请求，你最多只能应答一个，后面的应答得等到对端再次给你发送数据时。这就是对粘包逻辑的正确处理。 以上逻辑和代码是最基本的粘包和半包处理机制，也就是所谓的技术上的解包处理逻辑（业务上的解包处理逻辑后面章节再介绍）。希望读者能理解他们，在理解了他们的基础之上，我们可以给解包拓展很多功能，例如，我们再给我们的协议包增加一个支持压缩的功能，我们的包头变成下面这个样子：\n#pragma pack(push, 1) //协议头 struct msg { char compressflag; //压缩标志，如果为1，则启用压缩，反之不启用压缩 int32_t originsize; //包体压缩前大小 int32_t compresssize; //包体压缩后大小 char reserved[16]; //保留字段，用于将来拓展 }; #pragma pack(pop) 修改后的代码如下：\nvoid ChatSession::OnRead(const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn, Buffer* pBuffer, Timestamp receivTime) { while (true) { //不够一个包头大小 if (pBuffer-\u0026gt;readableBytes() \u0026lt; (size_t)sizeof(msg)) { //LOGI \u0026lt;\u0026lt; \u0026#34;buffer is not enough for a package header, pBuffer-\u0026gt;readableBytes()=\u0026#34; \u0026lt;\u0026lt; pBuffer-\u0026gt;readableBytes() \u0026lt;\u0026lt; \u0026#34;, sizeof(msg)=\u0026#34; \u0026lt;\u0026lt; sizeof(msg); return; } //取包头信息 msg header; memcpy(\u0026amp;header, pBuffer-\u0026gt;peek(), sizeof(msg)); //数据包压缩过 if (header.compressflag == PACKAGE_COMPRESSED) { //包头有错误，立即关闭连接 if (header.compresssize \u0026lt;= 0 || header.compresssize \u0026gt; MAX_PACKAGE_SIZE || header.originsize \u0026lt;= 0 || header.originsize \u0026gt; MAX_PACKAGE_SIZE) { //客户端发非法数据包，服务器主动关闭之 LOGE(\u0026#34;Illegal package, compresssize: %lld, originsize: %lld, close TcpConnection, client: %s\u0026#34;, header.compresssize, header.originsize, conn-\u0026gt;peerAddress().toIpPort().c_str()); conn-\u0026gt;forceClose(); return; } //收到的数据不够一个完整的包 if (pBuffer-\u0026gt;readableBytes() \u0026lt; (size_t)header.compresssize + sizeof(msg)) return; pBuffer-\u0026gt;retrieve(sizeof(msg)); std::string inbuf; inbuf.append(pBuffer-\u0026gt;peek(), header.compresssize); pBuffer-\u0026gt;retrieve(header.compresssize); std::string destbuf; if (!ZlibUtil::UncompressBuf(inbuf, destbuf, header.originsize)) { LOGE(\u0026#34;uncompress error, client: %s\u0026#34;, conn-\u0026gt;peerAddress().toIpPort().c_str()); conn-\u0026gt;forceClose(); return; } //业务逻辑处理 if (!Process(conn, destbuf.c_str(), destbuf.length())) { //客户端发非法数据包，服务器主动关闭之 LOGE(\u0026#34;Process error, close TcpConnection, client: %s\u0026#34;, conn-\u0026gt;peerAddress().toIpPort().c_str()); conn-\u0026gt;forceClose(); return; } } //数据包未压缩 else { //包头有错误，立即关闭连接 if (header.originsize \u0026lt;= 0 || header.originsize \u0026gt; MAX_PACKAGE_SIZE) { //客户端发非法数据包，服务器主动关闭之 LOGE(\u0026#34;Illegal package, compresssize: %lld, originsize: %lld, close TcpConnection, client: %s\u0026#34;, header.compresssize, header.originsize, conn-\u0026gt;peerAddress().toIpPort().c_str()); conn-\u0026gt;forceClose(); return; } //收到的数据不够一个完整的包 if (pBuffer-\u0026gt;readableBytes() \u0026lt; (size_t)header.originsize + sizeof(msg)) return; pBuffer-\u0026gt;retrieve(sizeof(msg)); std::string inbuf; inbuf.append(pBuffer-\u0026gt;peek(), header.originsize); pBuffer-\u0026gt;retrieve(header.originsize); //业务逻辑处理 if (!Process(conn, inbuf.c_str(), inbuf.length())) { //客户端发非法数据包，服务器主动关闭之 LOGE(\u0026#34;Process error, close TcpConnection, client: %s\u0026#34;, conn-\u0026gt;peerAddress().toIpPort().c_str()); conn-\u0026gt;forceClose(); return; } }// end else }// end while-loop } 这段代码先根据包头的压缩标志字段判断包体是否有压缩，如果有压缩，则取出包体大小去解压，解压后的数据才是真正的业务数据。整个程序执行流程图如下：\n","permalink":"https://haokiu.com/blog/7b86f55ffdcd4434a17beb9dbf7b9527/","summary":"TCP 协议如何解决粘包、半包问题 一 TCP 协议是流式协议 很多读者从接触网络知识以来，应该听说过这句话：TCP 协议是流式协议。那么这句话到底是什么意思呢？所谓流式协议，即协议的内容是像流水一样的字节流，内容与内容之间没有明确的分界标志，需要我们人为地去给这些协议划分边界。\n举个例子，A 与 B 进行 TCP 通信，A 先后给 B 发送了一个 100 字节和 200 字节的数据包，那么 B 是如何收到呢？B 可能先收到 100 字节，再收到 200 字节；也可能先收到 50 字节，再收到 250 字节；或者先收到 100 字节，再收到 100 字节，再收到 200 字节；或者先收到 20 字节，再收到 20 字节，再收到 60 字节，再收到 100 字节，再收到 50 字节，再收到 50 字节……\n不知道读者看出规律没有？规律就是 A 一共给 B 发送了 300 字节，B 可能以一次或者多次任意形式的总数为 300 字节收到。假设 A 给 B 发送的 100 字节和 200 字节分别都是一个数据包，对于发送端 A 来说，这个是可以区分的，但是对于 B 来说，如果不人为规定多长为一个数据包，B 每次是不知道应该把收到的数据中多少字节作为一个有效的数据包的。而规定每次把多少数据当成一个包就是协议格式规范的内容之一。\n经常会有新手写出类似下面这样的代码：\n发送端：\n//...省略创建socket，建立连接等部分不相关的逻辑... char buf[] = \u0026#34;the quick brown fox jumps over a lazy dog.\u0026#34;; int n = send(socket, buf, strlen(buf), 0); //...省略出错处理逻辑... 接收端：\n//省略创建socket，建立连接等部分不相关的逻辑... char recvBuf[50] = { 0 }; int n = recv(socket, recvBuf, 50, 0); //省略出错处理逻辑.","title":"TCP 协议如何解决粘包、半包问题"},{"content":"TeamTalk源码解析 01 TeamTalk介绍\n02 服务器端的程序的编译与部署\n03 服务器端的程序架构介绍\n04 服务器端db_proxy_server源码分析\n05 服务器端msg_server源码分析\n06 服务器端login_server源码分析\n07 服务器端msfs源码分析\n08 服务器端file_server源码分析\n09 服务器端route_server源码分析\n10 开放一个TeamTalk测试服务器地址和几个测试账号\n11 pc客户端源码分析\n","permalink":"https://haokiu.com/blog/0da28a69a69242919c3333dc8e970a8f/","summary":"TeamTalk源码解析 01 TeamTalk介绍\n02 服务器端的程序的编译与部署\n03 服务器端的程序架构介绍\n04 服务器端db_proxy_server源码分析\n05 服务器端msg_server源码分析\n06 服务器端login_server源码分析\n07 服务器端msfs源码分析\n08 服务器端file_server源码分析\n09 服务器端route_server源码分析\n10 开放一个TeamTalk测试服务器地址和几个测试账号\n11 pc客户端源码分析","title":"TeamTalk源码解析"},{"content":"不定参数函数实现var_arg系列的宏 电驴的源码日志模块有一个叫 DebugLogError 函数，其签名如下：\n//代码位于easyMule-master/src/WorkLayer/Log.h 55行 void DebugLogError(LPCTSTR pszLine, ...); 电驴的源码可以在公众号【 高性能服务器开发 】后台回复“获取电驴源码”即可获取。\n这个函数的申明在 Log.h 头文件中，是一个全局函数，其实现代码在 Log.cpp 文件中：\n//代码位于easyMule-master/src/WorkLayer/Log.cpp 111行 void DebugLogError(LPCTSTR pszFmt, ...) { va_list argp; va_start(argp, pszFmt); LogV(LOG_DEBUG | LOG_ERROR, pszFmt, argp); va_end(argp); } 这个函数是一个具有不定参数的函数（也就是参数个数不确定），比如调用这个函数我们可以传入一个参数，也可以传入二个或者三个参数等等：\nDebugLogError(L\u0026#34;我喜欢你!\u0026#34;); DebugLogError(L\u0026#34;我喜欢你!\u0026#34;, L\u0026#34;你喜欢谁？\u0026#34;); DebugLogError(L\u0026#34;我喜欢你!\u0026#34;, L\u0026#34;你喜欢谁？\u0026#34;, L\u0026#34;萧雨萌!\u0026#34;); 与此类似， C 语言中最熟悉的函数 printf() 和 scanf() 就是能传入不定参数的函数的例子，可是你知道如何编写这样具有不定参数的函数么？\n你可以通过这段代码学习到编写方法，奥秘就在DebugLogError()中使用的几个你从来没见过的宏，让我们欢迎它们：\nva_list va_start va_end 这几个宏是C函数库提供的，位于头文件stdarg.h中。下面我们利用这几个宏自定义一个ShowLove()函数：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;tchar.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;locale.h\u0026gt; int ShowLove(wchar_t* szFirstSentence, ...) { //用来统计可变参数数量 int num = 0; //第一步： //申明一个va_list类型对象ap，用于对参数进行遍历 va_list ap; //第二步： //使用va_start对变量进行初始化 //这里需要注意的是: //在传统C语言中，va_start把ap中内部指针设置为传递给函数参数的【第一个实参】； //而在标准的C中，va_start接受一个额外参数，也就是最后一个【固定参数】的名称， //并把ap中的内部指针设置为传递给函数的第一个【可变参数】. //所以你在VC++ 6.0和VS2008等高版本的编译器中使用va_start需要注意区别 //这里使用标准C va_start(ap, szFirstSentence); //第三步： //使用va_arg宏返回实参列表中的下一个参数值，并把ap的内部指针推向下一个参数（如果有的话） //必须指定下一个参数的类型。 //在调用va_start之后第一次调用va_arg将返回第一个可变参数的值 wprintf(szFirstSentence); wchar_t* p = 0; while(p = va_arg(ap, wchar_t*)) { wprintf(L\u0026#34;%s\u0026#34;, p); num ++; } //第四步： //待所有可变参数都读取完毕以后，调用va_end宏对ap和va_list做必要的清理工作 va_end(ap); return num; } int main(int argc, char* argv[]) { setlocale(LC_ALL, \u0026#34;\u0026#34;); int z = ShowLoveL\u0026#34;我喜欢你！\\n\u0026#34;); int y = ShowLove(L\u0026#34;我喜欢你！\u0026#34;, L\u0026#34;你喜欢谁？\\n\u0026#34;); int l = ShowLove(L\u0026#34;我喜欢你！\u0026#34;, L\u0026#34;你喜欢谁？\u0026#34;, L\u0026#34;萧雨萌！\\n\u0026#34;); printf(\u0026#34;可变参数个数依次是：%d\\t%d\\t%d\\n\u0026#34;, z, y, l); return 0; } 上述代码的运行结果是：\n这里顺便补充下，va 的是英文 varied arguments （可变参数）的意思。关于 va_list 等宏的实现原理其实也很容易搞明白，这里不再讲解了。\n我们现在来看看函数 DebugLogError()：\nvoid DebugLogError(LPCTSTR pszFmt, ...) { va_list argp; va_start(argp, pszFmt);\tLogV(LOG_DEBUG | LOG_ERROR, pszFmt, argp); va_end(argp); } 其他的没什么，就是调用了一个函数叫 LogV()，LogV() 的的声明位于 Log.h 文件中，也是一个全局函数：\nvoid LogV(UINT uFlags, LPCTSTR pszFmt, va_list argp); 其实现代码位于 Log.cpp 文件中：\nvoid LogV(UINT uFlags, LPCTSTR pszFmt, va_list argp) { AddLogTextV(uFlags, DLP_DEFAULT, pszFmt, argp); } 这里又调用了一个函数 AddLogTextV()，这个函数的也声明在 Log.h 中：\nvoid AddLogTextV(UINT uFlags, EDebugLogPriority dlpPriority, LPCTSTR pszLine, va_list argptr)； 其实现代码在 Log.cpp 文件中：\nvoid AddLogTextV(UINT uFlags, EDebugLogPriority dlpPriority, LPCTSTR pszLine, va_list argptr) { ASSERT(pszLine != NULL); if ((uFlags \u0026amp; LOG_DEBUG) \u0026amp;\u0026amp; !thePrefs.GetVerbose() \u0026amp;\u0026amp; dlpPriority \u0026gt;= thePrefs.GetVerboseLogPriority()) return;\t//Xman Anti-Leecher-Log if ((uFlags \u0026amp; LOG_LEECHER) \u0026amp;\u0026amp; !thePrefs.GetAntiLeecherLog()) return;\t//Xman end TCHAR szLogLine[1000]; if (_vsntprintf(szLogLine, ARRSIZE(szLogLine), pszLine, argptr) == -1) szLogLine[ARRSIZE(szLogLine) - 1] = _T(\u0026#39;\\0\u0026#39;); if(CGlobalVariable::m_hListenWnd) UINotify(WM_ADD_LOGTEXT, uFlags, (LPARAM)new CString(szLogLine)); // Comment UI /*if (theApp.emuledlg) theApp.emuledlg-\u0026gt;AddLogText(uFlags, szLogLine); else*/ /*if(SendMessage(CGlobalVariable::m_hListenWnd, WM_ADD_LOGTEXT, uFlags, (LPARAM)szLogLine)==0)*/ else { TRACE(_T(\u0026#34;App Log: %s\\n\u0026#34;), szLogLine); TCHAR szFullLogLine[1060]; int iLen = _sntprintf(szFullLogLine, ARRSIZE(szFullLogLine), _T(\u0026#34;%s: %s\\r\\n\u0026#34;), CTime::GetCurrentTime().Format(thePrefs.GetDateTimeFormat4Log()), szLogLine); if (iLen \u0026gt;= 0) { //Xman Anti-Leecher-Log //Xman Code Improvement if (!((uFlags \u0026amp; LOG_DEBUG) || (uFlags \u0026amp; LOG_LEECHER))) { if (thePrefs.GetLog2Disk()) theLog.Log(szFullLogLine, iLen); } else if (thePrefs.GetVerbose()) // \u0026amp;\u0026amp; ((uFlags \u0026amp; LOG_DEBUG) || thePrefs.GetFullVerbose())) { if (thePrefs.GetDebug2Disk()) theVerboseLog.Log(szFullLogLine, iLen); } //Xman end } } } 我们从源头函数调用来理下思路：\n首先用下列参数调用 DebugLogError()： DebugLogError(L\u0026#34;Unable to load shell32.dll to retrieve the systemfolder locations, using fallbacks\u0026#34;); 然后在上述函数内部又调用： LogV(LOG_DEBUG | LOG_ERROR, L\u0026#34;Unable to load shell32.dll to retrieve the systemfolder locations, using fallbacks\u0026#34;, argp); 其中，argp 是函数 DebugLogError() 的内部变量，而 LOG_DEBUG 和 LOG_ERROR 是 Log.h 中定义几个宏，其类型为整形：\n// Log message type enumeration #define\tLOG_INFO\t0 #define\tLOG_WARNING\t1 #define\tLOG_ERROR\t2 #define\tLOG_SUCCESS\t3 #define\tLOGMSGTYPEMASK\t0x03 // Log message targets flags #define\tLOG_DEFAULT\t0x00 #define\tLOG_DEBUG\t0x10 #define\tLOG_STATUSBAR\t0x20 #define\tLOG_DONTNOTIFY\t0x40 #define LOG_LEECHER\t0x80 //Xman Anti-Leecher-Log 最后调用： AddLogTextV(LOG_DEBUG | LOG_ERROR, DLP_DEFAULT, L\u0026#34;Unable to load shell32.dll to retrieve the systemfolder locations, using fallbacks\u0026#34;, argp); 这个函数的第二个参数类型是一个定义在 Log.h 中的枚举变量 EDebugLogPriority，代表调试的记录级别，其取值如下：\nenum EDebugLogPriority{ DLP_VERYLOW = 0, DLP_LOW, DLP_DEFAULT, DLP_HIGH, DLP_VERYHIGH }; 这里提醒一点，由于枚举量 DLP_VERYLOW = 0，所以后面的 DLP_LOW、 DLP_DEFAULT、 DLP_HIGH、 DLP_VERYHIGH 就依次等于1、2、3、4，这是C语言规定的，C语言规定枚举量如果不赋初值，根据前面一个量的值依次递增。\n我们来实际看看AddTextLogText()函数的实现代码：\nvoid AddLogTextV(UINT uFlags, EDebugLogPriority dlpPriority, LPCTSTR pszLine, va_list argptr) { ASSERT(pszLine != NULL); if ((uFlags \u0026amp; LOG_DEBUG) \u0026amp;\u0026amp; !thePrefs.GetVerbose() \u0026amp;\u0026amp; dlpPriority \u0026gt;= thePrefs.GetVerboseLogPriority()) return;\t//Xman Anti-Leecher-Log if ((uFlags \u0026amp; LOG_LEECHER) \u0026amp;\u0026amp; !thePrefs.GetAntiLeecherLog()) return;\t//Xman end 首先是一个ASSERT断言，这个断言要求 pszLine （函数第三个参数）不能为空。\n接着如果同时满足下列两个条件，则函数返回：\n条件1：表达式 ((uFlags \u0026amp; LOG_DEBUG) || (uFlags \u0026amp; LOG_LEECHER)) 为真； 条件2：表达式 !(thePrefs.GetVerbose() \u0026amp;\u0026amp; dlpPriority \u0026gt;= thePrefs.GetVerboseLogPriority()) 为真。 我们先看条件1，很多年以前，我对这种按位或运算（|）和按位与运算（＆）来组合这些程序中的标志的原理一头雾水，虽然那个时候，我知道这些运算符的含义。\n现在就以这两个为例吧：\n按位或运算，就是把两个数在二进制层面上按位或，比如二进制数：\n11 | 10 = 11 第一个数字高位上 1 与第二个数字高位上的 1 来进行或运算，等于 1，放在高位；\n第一个数字低位上 1 与第二个数字低位上的 0 来进行或运算，等于 1，放在低位。\n同理，与运算：\n11 \u0026amp; 10 = 10 按位与，要求两个数字都是 1 才是 1；而按位或只要有一个是 1 就等于 1，除非两者都是 0，则为 0。\n看个复杂的：\n11001100 \u0026amp; 10101010 = 10001000 这种做法有个两个好处：\n第一，可以将某个位置的上的数字来代表当前的状态，比如电路中 1 代表开，0 代表关。那么我用下面数字 a ＝ 10001000 表示电路开关状态，你会发现电路是开的。\n再比如，颜色值 RGB 表示法：CD1298， 我想把其中绿色值单独提取出来，怎么做？\n方法：\nGreenValue = 0xCD1298 \u0026amp; 0x001200, 这样就可以做到了。\n第二，因为是二进制层次上的操作，所以速度非常快。\n我们现在分析下代码：\n(uFlags \u0026amp; LOG_DEBUG) || (uFlags \u0026amp; LOG_LEECHER) 先看第一部分：\nuFlags \u0026amp; LOG_DEBUG 再结合下面的定义：\n// Log message targets flags #define LOG_DEFAULT 0x00 #define LOG_DEBUG 0x10 #define LOG_STATUSBAR 0x20 #define LOG_DONTNOTIFY 0x40 #define LOG_LEECHER 0x80 //Xman Anti-Leecher-Log 这几个常量定义的数值是有讲究的，不是任何数值都行的。我们将它们都化成二进制：\nLOG_DEFAULT 0000 0000 LOG_DEBUG 0001 0000 LOG_STATUSBAR 0010 0000 LOG_DONTNOTIFY 0100 0000 LOG_LEECHER 1000 0000 这样假如 uFlags = 1010 0000，这样我要检测是否设置了LOG_DEBUG，我只要这样做：\nResult = uFlags \u0026amp; LOG_DEBUG 计算结果\nResult =\u0026gt; 0000 0000 =\u0026gt; 0 这样 if（RESULT）{} 中条件为假；说明我没有设置这个标志位；同理我需要检测是否设置 LOG_STATUSBAR 标志，则执行：\nResult = uFlags \u0026amp; LOG_STATUSBAR = 0001 0000 这个数字化为十进制不为 0，所以为真，因此在判断语句里面条件也为真，说明设置了这个标志位。\n这是正面检测，反过来我想设置这些标识位，而且可以一次设置多个标志位，比如\nuFlags = LOG_STATUSBAR | LOG_DONTNOTIFY | LOG_LEECHER = 1110 0000 是不是一目了然？\n而且我也可以很方便地从设置好的标志位中去掉某个或某些标识位，比如我想从上面的uFlags值中去掉LOG_DONTNOTIFY 标识，怎么办？这样做就可以了：\nuFlags \u0026amp; (~LOG_DONTNOTIFY) 来解释下～符号是二进制层次上求反，将对应位上的 1 改为 0，0 改为 1，那么：\n~ LOG_DONTNOTIFY = 1011 1111 然后与 uFlags 或起来等于 1010 0000，你看下是不是刚好把 LOG_DONTNOTIFY 去掉了呀？\n这种方法效率高不仅是因为在二进制层次上运算，而且它可以用一个较小的数据类型代表多个信息，对数据的利用程度精准到二进制位。\n","permalink":"https://haokiu.com/blog/e3f33300987a43d08044b27dbbc5e9ec/","summary":"不定参数函数实现var_arg系列的宏 电驴的源码日志模块有一个叫 DebugLogError 函数，其签名如下：\n//代码位于easyMule-master/src/WorkLayer/Log.h 55行 void DebugLogError(LPCTSTR pszLine, ...); 电驴的源码可以在公众号【 高性能服务器开发 】后台回复“获取电驴源码”即可获取。\n这个函数的申明在 Log.h 头文件中，是一个全局函数，其实现代码在 Log.cpp 文件中：\n//代码位于easyMule-master/src/WorkLayer/Log.cpp 111行 void DebugLogError(LPCTSTR pszFmt, ...) { va_list argp; va_start(argp, pszFmt); LogV(LOG_DEBUG | LOG_ERROR, pszFmt, argp); va_end(argp); } 这个函数是一个具有不定参数的函数（也就是参数个数不确定），比如调用这个函数我们可以传入一个参数，也可以传入二个或者三个参数等等：\nDebugLogError(L\u0026#34;我喜欢你!\u0026#34;); DebugLogError(L\u0026#34;我喜欢你!\u0026#34;, L\u0026#34;你喜欢谁？\u0026#34;); DebugLogError(L\u0026#34;我喜欢你!\u0026#34;, L\u0026#34;你喜欢谁？\u0026#34;, L\u0026#34;萧雨萌!\u0026#34;); 与此类似， C 语言中最熟悉的函数 printf() 和 scanf() 就是能传入不定参数的函数的例子，可是你知道如何编写这样具有不定参数的函数么？\n你可以通过这段代码学习到编写方法，奥秘就在DebugLogError()中使用的几个你从来没见过的宏，让我们欢迎它们：\nva_list va_start va_end 这几个宏是C函数库提供的，位于头文件stdarg.h中。下面我们利用这几个宏自定义一个ShowLove()函数：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;tchar.h\u0026gt; #include \u0026lt;stdarg.h\u0026gt; #include \u0026lt;locale.h\u0026gt; int ShowLove(wchar_t* szFirstSentence, ...) { //用来统计可变参数数量 int num = 0; //第一步： //申明一个va_list类型对象ap，用于对参数进行遍历 va_list ap; //第二步： //使用va_start对变量进行初始化 //这里需要注意的是: //在传统C语言中，va_start把ap中内部指针设置为传递给函数参数的【第一个实参】； //而在标准的C中，va_start接受一个额外参数，也就是最后一个【固定参数】的名称， //并把ap中的内部指针设置为传递给函数的第一个【可变参数】. //所以你在VC++ 6.0和VS2008等高版本的编译器中使用va_start需要注意区别 //这里使用标准C va_start(ap, szFirstSentence); //第三步： //使用va_arg宏返回实参列表中的下一个参数值，并把ap的内部指针推向下一个参数（如果有的话） //必须指定下一个参数的类型。 //在调用va_start之后第一次调用va_arg将返回第一个可变参数的值 wprintf(szFirstSentence); wchar_t* p = 0; while(p = va_arg(ap, wchar_t*)) { wprintf(L\u0026#34;%s\u0026#34;, p); num ++; } //第四步： //待所有可变参数都读取完毕以后，调用va_end宏对ap和va_list做必要的清理工作 va_end(ap); return num; } int main(int argc, char* argv[]) { setlocale(LC_ALL, \u0026#34;\u0026#34;); int z = ShowLoveL\u0026#34;我喜欢你！\\n\u0026#34;); int y = ShowLove(L\u0026#34;我喜欢你！\u0026#34;, L\u0026#34;你喜欢谁？\\n\u0026#34;); int l = ShowLove(L\u0026#34;我喜欢你！\u0026#34;, L\u0026#34;你喜欢谁？\u0026#34;, L\u0026#34;萧雨萌！\\n\u0026#34;); printf(\u0026#34;可变参数个数依次是：%d\\t%d\\t%d\\n\u0026#34;, z, y, l); return 0; } 上述代码的运行结果是：","title":"不定参数函数实现var_arg系列的宏"},{"content":"为什么你的简历没人看 程序员如何写简历 ","permalink":"https://haokiu.com/blog/15d5370937664a8d84891f5e983b87f4/","summary":"为什么你的简历没人看 程序员如何写简历 ","title":"为什么你的简历没人看"},{"content":"从抓包的角度分析connect()函数的连接过程 这篇文章主要是从tcp连接建立的角度来分析客户端程序如何利用connect函数和服务端程序建立tcp连接的，了解connect函数在建立连接的过程中底层协议栈做了哪些事情。\ntcp三次握手 在正式介绍connect函数时，我们先来看一下tcp三次握手的过程，下面这个实验是客户端通过telnet远程登录服务端的例子，telnet协议是基于tcp协议，我们可以通过wireshark抓包工具看到客户端和服务端之间三次握手的过程，12.1.1.1是客户端的ip地址，12.1.1.2是服务端的ip地址。\n下面是我们通过wireshark抓取到的tcp三次握手的数据包：\n我们看到客户端远程登录服务端时，首先发送了一个SYN报文，其中目标端口为23（远程登录telnet协议使用23端口），初始序号seq = 0，并设置自己的窗口rwnd = 4128（rwnd是一个对端通告的接收窗口，用于流量控制）。\n然后服务端回复了一个SYN + ACK报文，初始序号seq = 0，ack = 1（在前一个包的seq基础上加1），同时也设置自己的窗口rwnd = 4128。\n然后客户端收到服务端的SYN + ACK报文时，回复了一个ACK报文，表示确认建立tcp连接，序号为seq = 1， ack = 1*（在前一个包的seq基础上加1）*， 设置窗口rwnd = 4128，此时客户端和服务端之间已经建立tcp连接。\nconnect函数 前面我们在介绍tcp三次握手的时候说过，客户端在跟服务端建立tcp连接时，通常是由客户端主动向目标服务端发起tcp连接建立请求，服务端被动接受tcp连接请求；同时服务端也会发起tcp连接建立请求，表示服务端希望和客户端建立连接，然后客户端会接受连接并发送一个确认，这样双方就已经建立好连接，可以开始通信。\n这里说明一下：可能有的小伙伴会感到疑惑，为啥服务端也要跟客户端建立连接呢？其实这跟tcp采用全双工通信的方式有关。对于全双工通信，简单来说就是两端可以同时收发数据，如下图所示：\n我们再回到正题，那么在网络编程中，肯定也有对应的函数做到跟上面一样的事情，没错，就是connect（连接）。顾名思义，connect函数就是用于客户端程序和服务端程序建立tcp连接的。\n一般来说，客户端使用connect函数跟服务端建立连接，肯定要指定一个ip地址和端口号（相当于客户端的身份标识），要不然服务端都不知道你是谁？凭什么跟你建立连接。同时还得指明服务端的ip地址和端口号，也就是说，你要跟谁建立连接。\nconnect函数原型：\nint connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数说明： sockfd：客户端的套接字文件描述符 addr：要连接的套接字地址，这是一个传入参数，指定了要连接的套接字地址信息（例如IP地址和端口号） addrlen：是一个传入参数，参数addr的大小，即sizeof(addr)\n返回值说明：连接建立成功返回0，失败返回-1并设置errno\nconnect函数在建立tcp连接的过程中用到了一个非常重要的队列，那就是未决连接队列，这个队列用来管理tcp的连接，包括已完成三次握手的tcp连接和未完成三次握手的tcp连接，下面我们就来详细介绍一下未决连接队列。\n未决连接队列 未决连接队列是指服务器接收到客户端的连接请求，但是尚未被处理（也就是未被accept，后面会说）的连接，可以理解为未决连接队列是一个容器，这个容器存储着这些尚未被处理的链接。\n当一个客户端进程使用 connect 函数发起请求后，服务器进程就会收到连接请求，然后检查未决连接队列是否有空位，如果未决队列满了，就会拒绝连接，那么客户端调用的connect 函数返回失败。\n如果未决连接队列有空位，就将该连接加入未决连接队列。当 connect 函数成功返回后，表明tcp的“三次握手”连接已完成，此时accept函数获取到一个客户端连接并返回。\n在上图中，在未决连接队列中又分为2个队列：\n未完成队列（未决队列）：即客户端已经发出SYN报文并到达服务器，但是在tcp三次握手连接完成之前，这些套接字处于SYN_RCVD状态，服务器会将这些套接字加入到未完成队列。\n已完成队列：即刚刚完成tcp三次握手的tcp连接，这些套接字处于ESTABLISHED状态，服务器会将这些套接字加入到已完成队列。\n我们来看一下连接建立的具体过程，如图所示：\n服务端首先调用listen函数监听客户端的连接请求，然后调用accept函数阻塞等待取出未决连接队列中的客户端连接，如果未决连接队列一直为空，这意味着没有客户端和服务器建立连接，那么accept就会一直阻塞。\n当客户端一调用connect函数发起连接时，如果完成tcp三次握手，那么accept函数会取出一个客户端连接（注意：是已经建立好的连接）然后立即返回。\n上面就是客户端和服务端在网络中的状态变迁的具体过程，前面我们在学习tcp三次握手的过程中还知道，服务端和客户端在建立连接的时候会设置自己的一个接收缓冲区窗口rwnd的大小。\n服务端在发送SYN + ACK数据报文时会设置并告知对方自己的接收缓冲区窗口大小，客户端在发送ACK数据报文时也会设置并告知对方自己的接收缓冲区窗口大小。\n注意，accept函数调用成功，返回的是一个已经完成tcp三次握手的客户端连接。如果在三次握手的过程中(最后一步)，服务端没有接收到客户端的ACK，则说明三次握手还没有建立完成，accept函数依然会阻塞。\n关于tcp三次握手连接建立的几种状态：SYN_SENT，SYN_RCVD，ESTABLISHED。 SYN_SENT：当客户端调用connect函数向服务端发送SYN包时，客户端就会进入 SYN_SENT状态，并且还会等待服务器发送第二个SYN + ACK包，因此SYN_SENT状态就是表示客户端已经发送SYN包。\nSYN_RCVD：当服务端接收到客户端发送的SYN包并确认时，服务端就会进入 SYN_RCVD状态，这是tcp三次握手建立的一个很短暂的中间状态，一般很难看到， SYN_RCVD状态表示服务端已经确认收到客户端发送的SYN包。\nESTABLISHED：该状态表示tcp三次握手连接建立完成。\n对于这两个队列需要注意几点注意：\n1. 未完成队列和已完成队列的总和不超过listen函数的backlog参数的大小。listen函数的签名如下：\nint listen(int sockfd, int backlog); 2. 一旦该连接的tcp三次握手完成，就会从未完成队列加入到已完成队列中\n3. 如果未决连接队列已满，当又接收到一个客户端SYN时，服务端的tcp将会忽略该SYN，也就是不会理客户端的SYN，但是服务端并不会发送RST报文，原因是：客户端tcp可以重传SYN，并期望在超时前未决连接队列找到空位与服务端建立连接，这当然是我们所希望看到的。如果服务端直接发送一个RST的话，那么客户端的connect函数将会立即返回一个错误，而不会让tcp有机会重传SYN，显然我们也并不希望这样做。\n但是不排除有些linux实现在未决连接队列满时，的确会发送RST。但是这种做法是不正确的，因此我们最好忽略这种情况，处理这种额外情况的代码也会降低客户端程序的健壮性。\nconnect函数出错情况 由于connect函数是在建立tcp连接成功或失败才返回，返回成功的情况本文上面已经介绍过了。这里我们介绍connect函数返回失败的几种情况： 第一种 当客户端发送了SYN报文后，没有收到确认则返回ETIMEDOUT错误，值得注意的是，失败一次并不会马上返回ETIMEDOUT错误。即当你调用了connect函数，客户端发送了一个SYN报文，没有收到确认就等6s后再发一个SYN报文，还没有收到就等24s再发一个（不同的linux系统设置的时间可能有所不同，这里以BSD系统为主）。这个时间是累加的，如果总共等了75s后还是没收到确认，那么客户端将返回ETIMEDOUT错误。\n对于linux系统，改变这个系统上限值也比较容易，由于需要改变系统配置参数，你需要root权限。 相关的命令是sysctl net.ipv4.tcp_syn_retries(针对于ipv4)。 在设置该值时还是要比较保守的，因为每次syn包重试的间隔都会增大(比如BSD类的系统实现中间隔会以2到3倍增加)，所有tcp_syn_retries的一个微小变化对connect超时时间的影响都非常大，不过扩大这个值也不会有什么坏处，因为你代码中设置的超时值都能够生效。但是如果代码中没有设置connect的超时值，那么connect就会阻塞很久，你发现对端机器down掉的间隔就更长。 作者建议设置这个值到6或者7，最多8。6对应的connect超时为45s，7对应90s，8对应190s。\n你能通过以下命令修改该值:\nsysctl -w net.ipv4.tcp_syn_retries=6 查看该值的命令是:\nsysctl net.ipv4.tcp_syn_retries 如果希望重启后生效，将net.ipv4.tcp_syn_retries = 6放入**/etc/sysctl.conf**中。\n这种情况一般是发生在服务端的可能性比较大，也就是服务端当前所处网络环境流量负载过高，网络拥塞了，然后服务端收到了客户端的SYN报文却来不及响应，或者发送的响应报文在网络传输过程中老是丢失，导致客户端迟迟收不到确认，最后返回ETIMEDOUT错误。\n我们可以简单复现一下这种情况，这个实验是基于CentOS系统进行的，具体过程如下所示：\n首先通过iptables -F把Centos上的防火墙规则清理掉，然后再通过iptables -I INPUT -p tcp \u0026ndash;syn -i lo -j DROP命令把本地的所有SYN包都过滤掉（模拟服务端当前网络不稳定）。 执行以下命令：\n1iptables -F 2iptables -I INPUT -p tcp --syn -i lo -j DROP 然后通过nc命令向本地的环回地址127.0.0.1发起tcp连接请求（相当于自己跟自己发起tcp连接），来模拟客户端跟服务端发起tcp连接，但是服务器端就是不响应，最后导致客户端的tcp连接建立请求超时，并终止tcp连接。\n然后再通过tcpdump工具把客户端和服务端建立tcp连接过程中的数据报都抓取下来，由于我们设置的服务器侦听端口号是10086，这里我们可以通过tcpdump -i any port 10086命令来过滤所有网卡的10086端口的数据包。\n如上图所示，localhost.39299代表客户端，localhost.10086代表服务端，客户端总共向服务端发送了6个SYN报文，这6个SYN包的间隔时间分别是1s，2s，4s，8s，16s，这些时间累积加起来总共为31s，其实客户端在发送最后一个SYN报文时还等待了一段时间，然后才超时。也就是说，客户端在发送了第一个SYN报文时，会设置了一个计时器并开始计时，在最后一个SYN报文还没收到服务端的确认时，这个计时器就会超时，然后关闭tcp连接。\n第二种 客户端连接一个服务器没有侦听的端口。\n过程是：客户端发送了一个SYN报文后，然后服务端回复了一个RST报文，说明这是一个异常的tcp连接，服务端发送了RST报文重置这个异常的tcp连接。\n这种情况一般为拒绝连接请求，比如：客户端想和服务端建立tcp连接，但是客户端的连接请求中使用了一个不存在或没有侦听的端口（比如：这个端口超出65535的范围），那么服务端就可以发送RST报文段拒绝这个请求。\n拒绝连接一般是由服务器主动发起的，因为客户端发起请求连接携带的目的端口，可能服务器并没有开启LISTEN状态。因此服务器在收到这样的报文段后会发送一个RST报文段，在这个报文里把RST和ACK都置为1，它确认了SYN报文段并同时重置了该tcp连接，然后服务器等待另一个连接。客户端在收到RST+ACK报文段后就会进入CLOSED状态。\n这里以通过20000不存在的端口远程登录为例：\ntcpdump抓取到的数据包如下：\n113:35:08.609549 IP 192.168.98.137.49057 \u0026gt; 192.168.0.102.dnp: Flags [S], seq 2919679902, win 14600, options [mss 1460,sackOK,TS val 39134059 ecr 0,nop,wscale 6], length 0 213:35:09.610018 IP 192.168.98.137.49057 \u0026gt; 192.168.0.102.dnp: Flags [S], seq 2919679902, win 14600, options [mss 1460,sackOK,TS val 39135059 ecr 0,nop,wscale 6], length 0 313:35:09.610115 IP 192.168.0.102.dnp \u0026gt; 192.168.98.137.49057: Flags [R.], seq 1766537774, ack 2919679903, win 64240, length 0 413:35:10.610188 IP 192.168.0.102.dnp \u0026gt; 192.168.98.137.49057: Flags [R.], seq 3482791532, ack 1, win 64240, length 0 通过分析tcpdump工具抓取的数据发现，RST报文段不携带数据。\n第三种 如果客户端调用connect函数向服务端发送了一个SYN报文，这个SYN报文在网络传输过程中经过某个路由器时，正好这个路由器出问题了，缺少到达目的地的路由，不能把这个SYN报文转发给目的地址，那么该路由器会丢弃这个SYN报文，并同时给客户端发送一个Destination unreachable（主机不可达）的ICMP差错报文。客户端的linux内核会保存这个Destination unreachable的ICMP差错报文，同时按第一种情况继续发送SYN报文，如果在规定的时间超时后还没收到服务端的响应报文，那么linux内核会把保存的ICMP差错报文作为EHOSTUNREACH或ENETUNREACH错误返回给客户端的应用进程。\n下面的这个实验就是用来说明第三种情况，帮助理解，大家能看明白就行了，可以不用去做这个实验，当然，有兴趣的同学可以去模拟一下。\n然后client远程登录server成功。\n上图中没有指定telnet端口号，使用默认端口号23。\n这是抓取到的数据包，client在远程登录server时，发起了SYN连接请求。\n现在我们来模拟client设备出故障，删除R1设备到server的路由信息\nno ip route 12.1.3.0 255.255.255.0 12.1.2.2 client再登录server时就会失败，我们从抓取到的数据包可以发现，client发送了一个SYN报文，然后R1设备收到这个SYN报文时，发现自己不能到达server，于是会把这个SYN报文丢弃掉，并向client发送了一个目标主机不可达的ICMP差错报文，于是client发送了RST报文来关闭这条异常的tcp连接。\n学习知识不仅要知其然也要知其所以然，这是我想通过这篇文章传达的一个理念，文中一步步的实验探索体现了学习知识动手实践的重要性，这是非常值得提倡的。\n","permalink":"https://haokiu.com/blog/f3b5fbeb80e645c9b5bd3d1feea7b387/","summary":"从抓包的角度分析connect()函数的连接过程 这篇文章主要是从tcp连接建立的角度来分析客户端程序如何利用connect函数和服务端程序建立tcp连接的，了解connect函数在建立连接的过程中底层协议栈做了哪些事情。\ntcp三次握手 在正式介绍connect函数时，我们先来看一下tcp三次握手的过程，下面这个实验是客户端通过telnet远程登录服务端的例子，telnet协议是基于tcp协议，我们可以通过wireshark抓包工具看到客户端和服务端之间三次握手的过程，12.1.1.1是客户端的ip地址，12.1.1.2是服务端的ip地址。\n下面是我们通过wireshark抓取到的tcp三次握手的数据包：\n我们看到客户端远程登录服务端时，首先发送了一个SYN报文，其中目标端口为23（远程登录telnet协议使用23端口），初始序号seq = 0，并设置自己的窗口rwnd = 4128（rwnd是一个对端通告的接收窗口，用于流量控制）。\n然后服务端回复了一个SYN + ACK报文，初始序号seq = 0，ack = 1（在前一个包的seq基础上加1），同时也设置自己的窗口rwnd = 4128。\n然后客户端收到服务端的SYN + ACK报文时，回复了一个ACK报文，表示确认建立tcp连接，序号为seq = 1， ack = 1*（在前一个包的seq基础上加1）*， 设置窗口rwnd = 4128，此时客户端和服务端之间已经建立tcp连接。\nconnect函数 前面我们在介绍tcp三次握手的时候说过，客户端在跟服务端建立tcp连接时，通常是由客户端主动向目标服务端发起tcp连接建立请求，服务端被动接受tcp连接请求；同时服务端也会发起tcp连接建立请求，表示服务端希望和客户端建立连接，然后客户端会接受连接并发送一个确认，这样双方就已经建立好连接，可以开始通信。\n这里说明一下：可能有的小伙伴会感到疑惑，为啥服务端也要跟客户端建立连接呢？其实这跟tcp采用全双工通信的方式有关。对于全双工通信，简单来说就是两端可以同时收发数据，如下图所示：\n我们再回到正题，那么在网络编程中，肯定也有对应的函数做到跟上面一样的事情，没错，就是connect（连接）。顾名思义，connect函数就是用于客户端程序和服务端程序建立tcp连接的。\n一般来说，客户端使用connect函数跟服务端建立连接，肯定要指定一个ip地址和端口号（相当于客户端的身份标识），要不然服务端都不知道你是谁？凭什么跟你建立连接。同时还得指明服务端的ip地址和端口号，也就是说，你要跟谁建立连接。\nconnect函数原型：\nint connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数说明： sockfd：客户端的套接字文件描述符 addr：要连接的套接字地址，这是一个传入参数，指定了要连接的套接字地址信息（例如IP地址和端口号） addrlen：是一个传入参数，参数addr的大小，即sizeof(addr)\n返回值说明：连接建立成功返回0，失败返回-1并设置errno\nconnect函数在建立tcp连接的过程中用到了一个非常重要的队列，那就是未决连接队列，这个队列用来管理tcp的连接，包括已完成三次握手的tcp连接和未完成三次握手的tcp连接，下面我们就来详细介绍一下未决连接队列。\n未决连接队列 未决连接队列是指服务器接收到客户端的连接请求，但是尚未被处理（也就是未被accept，后面会说）的连接，可以理解为未决连接队列是一个容器，这个容器存储着这些尚未被处理的链接。\n当一个客户端进程使用 connect 函数发起请求后，服务器进程就会收到连接请求，然后检查未决连接队列是否有空位，如果未决队列满了，就会拒绝连接，那么客户端调用的connect 函数返回失败。\n如果未决连接队列有空位，就将该连接加入未决连接队列。当 connect 函数成功返回后，表明tcp的“三次握手”连接已完成，此时accept函数获取到一个客户端连接并返回。\n在上图中，在未决连接队列中又分为2个队列：\n未完成队列（未决队列）：即客户端已经发出SYN报文并到达服务器，但是在tcp三次握手连接完成之前，这些套接字处于SYN_RCVD状态，服务器会将这些套接字加入到未完成队列。\n已完成队列：即刚刚完成tcp三次握手的tcp连接，这些套接字处于ESTABLISHED状态，服务器会将这些套接字加入到已完成队列。\n我们来看一下连接建立的具体过程，如图所示：\n服务端首先调用listen函数监听客户端的连接请求，然后调用accept函数阻塞等待取出未决连接队列中的客户端连接，如果未决连接队列一直为空，这意味着没有客户端和服务器建立连接，那么accept就会一直阻塞。\n当客户端一调用connect函数发起连接时，如果完成tcp三次握手，那么accept函数会取出一个客户端连接（注意：是已经建立好的连接）然后立即返回。\n上面就是客户端和服务端在网络中的状态变迁的具体过程，前面我们在学习tcp三次握手的过程中还知道，服务端和客户端在建立连接的时候会设置自己的一个接收缓冲区窗口rwnd的大小。\n服务端在发送SYN + ACK数据报文时会设置并告知对方自己的接收缓冲区窗口大小，客户端在发送ACK数据报文时也会设置并告知对方自己的接收缓冲区窗口大小。\n注意，accept函数调用成功，返回的是一个已经完成tcp三次握手的客户端连接。如果在三次握手的过程中(最后一步)，服务端没有接收到客户端的ACK，则说明三次握手还没有建立完成，accept函数依然会阻塞。\n关于tcp三次握手连接建立的几种状态：SYN_SENT，SYN_RCVD，ESTABLISHED。 SYN_SENT：当客户端调用connect函数向服务端发送SYN包时，客户端就会进入 SYN_SENT状态，并且还会等待服务器发送第二个SYN + ACK包，因此SYN_SENT状态就是表示客户端已经发送SYN包。\nSYN_RCVD：当服务端接收到客户端发送的SYN包并确认时，服务端就会进入 SYN_RCVD状态，这是tcp三次握手建立的一个很短暂的中间状态，一般很难看到， SYN_RCVD状态表示服务端已经确认收到客户端发送的SYN包。\nESTABLISHED：该状态表示tcp三次握手连接建立完成。\n对于这两个队列需要注意几点注意：\n1. 未完成队列和已完成队列的总和不超过listen函数的backlog参数的大小。listen函数的签名如下：\nint listen(int sockfd, int backlog); 2. 一旦该连接的tcp三次握手完成，就会从未完成队列加入到已完成队列中\n3. 如果未决连接队列已满，当又接收到一个客户端SYN时，服务端的tcp将会忽略该SYN，也就是不会理客户端的SYN，但是服务端并不会发送RST报文，原因是：客户端tcp可以重传SYN，并期望在超时前未决连接队列找到空位与服务端建立连接，这当然是我们所希望看到的。如果服务端直接发送一个RST的话，那么客户端的connect函数将会立即返回一个错误，而不会让tcp有机会重传SYN，显然我们也并不希望这样做。\n但是不排除有些linux实现在未决连接队列满时，的确会发送RST。但是这种做法是不正确的，因此我们最好忽略这种情况，处理这种额外情况的代码也会降低客户端程序的健壮性。\nconnect函数出错情况 由于connect函数是在建立tcp连接成功或失败才返回，返回成功的情况本文上面已经介绍过了。这里我们介绍connect函数返回失败的几种情况： 第一种 当客户端发送了SYN报文后，没有收到确认则返回ETIMEDOUT错误，值得注意的是，失败一次并不会马上返回ETIMEDOUT错误。即当你调用了connect函数，客户端发送了一个SYN报文，没有收到确认就等6s后再发一个SYN报文，还没有收到就等24s再发一个（不同的linux系统设置的时间可能有所不同，这里以BSD系统为主）。这个时间是累加的，如果总共等了75s后还是没收到确认，那么客户端将返回ETIMEDOUT错误。\n对于linux系统，改变这个系统上限值也比较容易，由于需要改变系统配置参数，你需要root权限。 相关的命令是sysctl net.ipv4.tcp_syn_retries(针对于ipv4)。 在设置该值时还是要比较保守的，因为每次syn包重试的间隔都会增大(比如BSD类的系统实现中间隔会以2到3倍增加)，所有tcp_syn_retries的一个微小变化对connect超时时间的影响都非常大，不过扩大这个值也不会有什么坏处，因为你代码中设置的超时值都能够生效。但是如果代码中没有设置connect的超时值，那么connect就会阻塞很久，你发现对端机器down掉的间隔就更长。 作者建议设置这个值到6或者7，最多8。6对应的connect超时为45s，7对应90s，8对应190s。","title":"从抓包的角度分析connect()函数的连接过程"},{"content":"从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始 写在前面的话\n经常有学生或者初学者问我如何去阅读和学习一个开源软件的代码，也有不少朋友在工作岗位时面对前同事留下的项目，由于文档不完善、代码注释少、工程数量大，而无从下手。本文将来通过一个多人联机实时对战游戏——最后一战，来解答以上问题。\n其实，我以上问题在我是一个学生时，我也同样因此而困惑，但是后来，我发现，对于文档缺失、注释缺失的项目，需要自己摸索，虽然是挑战，同时也是机遇——一个不错的学习机会。因为至少有代码，正如侯捷大师所说的的，“源码面前，了无秘密”，所以我们应该**“read the fucking code”**。\n所以，这个系列的文章，我们分析“最后一战”这个游戏源码时，我们不会按照传统的思路：先介绍总结的程序结构，再介绍各个模块的细节，因为，当我们面对一套陌生的源码时，尤其是在文档缺失的情况下，我们根本无法开始就掌握这个项目的总体结构，我们只能从零开始一个个模块的对代码进行阅读和调试，所以我们这个系列的文章也按这个思路来分析，以真实的案例来教会新手一步步读懂一个开源项目的代码。\n我们先来看下这个游戏的内容吧，下面给出游戏画面的部分截图：\n这是一款类似于王者荣耀、dota之类的5v5实时RPG竞技游戏。\n客户端的逻辑比较简单，主要是一些游戏特效和动画（基于Unity 3D），所以这里我们主要分析游戏的服务器端源码。\n先介绍一下推荐的源码的运行和开发环境（我的配置）：\nWindows 7\nVisual Studio 2010\n服务器端有非常多的模块，这里先截一张主要模块的项目图示：\n从下一篇文章开始，我们将介绍如何学习这样的源码。\n欢迎阅读下一篇**《从零学习开源项目系列（二） 最后一战概况》**。\n源码下载方法：\n微信搜索公众号**『高性能服务器开发』(中文名：高性能服务器开发)，关注公众号后，在公众号中回复『英雄联盟』**，即可得到下载链接。（喷子和代码贩子请远离！）\n","permalink":"https://haokiu.com/blog/416ada8e33704bdcadd3202dd2413740/","summary":"从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始 写在前面的话\n经常有学生或者初学者问我如何去阅读和学习一个开源软件的代码，也有不少朋友在工作岗位时面对前同事留下的项目，由于文档不完善、代码注释少、工程数量大，而无从下手。本文将来通过一个多人联机实时对战游戏——最后一战，来解答以上问题。\n其实，我以上问题在我是一个学生时，我也同样因此而困惑，但是后来，我发现，对于文档缺失、注释缺失的项目，需要自己摸索，虽然是挑战，同时也是机遇——一个不错的学习机会。因为至少有代码，正如侯捷大师所说的的，“源码面前，了无秘密”，所以我们应该**“read the fucking code”**。\n所以，这个系列的文章，我们分析“最后一战”这个游戏源码时，我们不会按照传统的思路：先介绍总结的程序结构，再介绍各个模块的细节，因为，当我们面对一套陌生的源码时，尤其是在文档缺失的情况下，我们根本无法开始就掌握这个项目的总体结构，我们只能从零开始一个个模块的对代码进行阅读和调试，所以我们这个系列的文章也按这个思路来分析，以真实的案例来教会新手一步步读懂一个开源项目的代码。\n我们先来看下这个游戏的内容吧，下面给出游戏画面的部分截图：\n这是一款类似于王者荣耀、dota之类的5v5实时RPG竞技游戏。\n客户端的逻辑比较简单，主要是一些游戏特效和动画（基于Unity 3D），所以这里我们主要分析游戏的服务器端源码。\n先介绍一下推荐的源码的运行和开发环境（我的配置）：\nWindows 7\nVisual Studio 2010\n服务器端有非常多的模块，这里先截一张主要模块的项目图示：\n从下一篇文章开始，我们将介绍如何学习这样的源码。\n欢迎阅读下一篇**《从零学习开源项目系列（二） 最后一战概况》**。\n源码下载方法：\n微信搜索公众号**『高性能服务器开发』(中文名：高性能服务器开发)，关注公众号后，在公众号中回复『英雄联盟』**，即可得到下载链接。（喷子和代码贩子请远离！）","title":"从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始"},{"content":"从零学习开源项目系列（三） CSBattleMgr服务源码研究 服务器项目工程如下图所示：\n如上图所示，这篇文章我们将介绍CSBattleMgr的情况，但是我们不会去研究这个服务器的特别细节的东西（这些细节我们将在后面的文章中介绍）。阅读一个未知的项目源码如果我们开始就纠结于各种细节，那么我们最终会陷入“横看成岭侧成峰，远近高低各不同”的尴尬境界，浪费时间不说，可能收获也是事倍功半。所以，尽管我们不熟悉这套代码，我们还是尽量先从整体来把握，先大致了解各个服务的功能，细节部分回头再针对性地去研究。\n这个系列的第二篇文章《从零学习开源项目系列（二） 最后一战概况》中我们介绍了，这套游戏的服务需要使用redis和mysql，我们先看下mysql是否准备好了（mysql服务启动起来，数据库建表数据存在，具体细节请参考第二篇文章）。打开Windows的cmd程序，输入以下指令连接mysql：\nmysql -uroot -p123321 连接成功以后，如下图所示：\n然后我们输入以下指令，查看我们需要的数据库是否创建成功：\nshow databases; 这些都是基本的sql语句，如果您不熟悉的话，可能需要专门学习一下。\n数据库创建成功后如下图所示：\n至于数据库中的表是否创建成功，我们这里先不关注，后面我们实际用到哪张数据表，我们再去研究。\nmysql没问题了，接下来我们要启动一下redis，通过第二篇文章我们知道redis需要启动两次，也就是一共两个redis进程，我们游戏服务中分别称为redis-server和redis-login-server（它们的配置文件信息不一样），我们可以在Server\\Bin\\x64\\Release目录下手动cmd命令行执行下列语句：\nstart /min \u0026#34;redis-server\u0026#34; \u0026#34;redis-server.exe\u0026#34; redis.conf start /min \u0026#34;redis-Logicserver\u0026#34; \u0026#34;redis-server.exe\u0026#34; redis-logic.conf 但是这样比较麻烦，我将这两句拷贝出来，放入一个叫start-redis.bat文件中了，每次启动只要执行一下这个bat文件就可以：\nredis和redis-logic服务启动后如下图所示：\n我们常见的redis服务都是linux下的源码，微软公司对redis源码进行了改造，出了一个Windows版本，稍微有点不尽人意（例如：Windows下没有完全与linux的fork()相匹配的API，所以只能用CreateProcess()去替代）。关于windows版本的redis源码官方下载地址为：https://github.com/MicrosoftArchive/redis/releases。\n在启动好了mysql和redis后，我们现在正式来看一下CSBattleMgr这个服务。读者不禁可能要问，那么多服务，你怎么知道要先看这个服务呢？我们上一篇文章中也说过，我们再start.bat文件中发现除了redis以外，这是第三个需要启动的服务，所以我们先研究它（start.bat我们可以认为是源码作者为我们留下的部署步骤“文档”）：\n我们打开CSBattleMgr服务main.cpp文件，找到入口main函数，内容如下：\nint main(){ DbgLib::CDebugFx::SetExceptionHandler(true); DbgLib::CDebugFx::SetExceptionCallback(ExceptionCallback, NULL); GetCSKernelInstance(); GetCSUserMgrInstance(); GetBattleMgrInstance(); GetCSKernelInstance()-\u0026gt;Initialize(); GetBattleMgrInstance()-\u0026gt;Initialize(); GetCSUserMgrInstance()-\u0026gt;Initialize(); GetCSKernelInstance()-\u0026gt;Start(); mysql_library_init(0, NULL, NULL); GetCSKernelInstance()-\u0026gt;MainLoop(); } 通过调试，我们发下这个函数大致做了以下任务：\n//1. 设置程序异常处理函数 //2. 初始化一系列单例对象 //3. 初始化mysql //4. 进入一个被称作“主循环”的无限循环 步骤1设置程序异常处理函数没有好介绍的，我们看一下步骤2初始化一系列单例对象，总共初始化了三个类的对象CCSKernel、CCSUserMgr和CCSBattleMgr。单例模式本身没啥好介绍的，但是有人要提单例模式的线程安全性，所以出现很多通过加锁的单例模式代码，我个人觉得没必要；认为要加锁的朋友可能认为单例对象如果在第一次初始化时同时被多个线程调用就会有问题，我觉得加锁带来的开销还不如像上面的代码一样，在整个程序初始化初期获取一下单例对象，让单例对象生成出来，后面即使多个线程获取这个单例对象也都是读操作，无需加锁。以GetCSKernelInstance();为例：\nCCSKernel* GetCSKernelInstance(){ return \u0026amp;CCSKernel::GetInstance(); } CCSKernel\u0026amp; CCSKernel::GetInstance(){ if (NULL == pInstance){ pInstance = new CCSKernel; } return *pInstance; } GetCSKernelInstance()-\u0026gt;Initialize()的初始化动作其实是加载各种配置信息和事先设置一系列的回调函数和定时器：\nINT32 CCSKernel::Initialize() { //JJIAZ加载配置的时候 不要随便调整顺序 CCSCfgMgr::getInstance().Initalize(); INT32 n32Init = LoadCfg(); if (eNormal != n32Init) { ELOG(LOG_ERROR,\u0026#34; loadCfg()............failed!\u0026#34;); return n32Init; } if(m_sCSKernelCfg.un32MaxSSNum \u0026gt; 0 ) { m_psSSNetInfoList = new SSSNetInfo[m_sCSKernelCfg.un32MaxSSNum]; memset(m_psSSNetInfoList, 0, sizeof(SSSNetInfo) * m_sCSKernelCfg.un32MaxSSNum); m_psGSNetInfoList = new SGSNetInfo[m_sCSKernelCfg.un32MaxGSNum]; memset(m_psGSNetInfoList, 0, sizeof(SGSNetInfo) * m_sCSKernelCfg.un32MaxGSNum); m_psRCNetInfoList = new SRCNetInfo[10]; } m_GSMsgHandlerMap[GSToCS::eMsgToCSFromGS_AskRegiste] = std::bind(\u0026amp;CCSKernel::OnMsgFromGS_AskRegiste, this, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3); m_GSMsgHandlerMap[GSToCS::eMsgToCSFromGS_AskPing] = std::bind(\u0026amp;CCSKernel::OnMsgFromGS_AskPing, this, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3); m_GSMsgHandlerMap[GSToCS::eMsgToCSFromGS_ReportGCMsg] = std::bind(\u0026amp;CCSKernel::OnMsgFromGS_ReportGCMsg, this, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3); m_SSMsgHandlerMap[SSToCS::eMsgToCSFromSS_AskPing] = std::bind(\u0026amp;CCSKernel::OnMsgFromSS_AskPing, this, std::placeholders::_1, std::placeholders::_2, std::placeholders::_3); AddTimer(std::bind(\u0026amp;CCSKernel::ProfileReport, this, std::placeholders::_1, std::placeholders::_2), 5000, true); return eNormal; } 如上图所示，这些配置信息都是游戏术语，包括各种技能、英雄、模型等信息。\nGetBattleMgrInstance()-\u0026gt;Initialize()其实是帮CSKernel对象启动一个定时器：\nINT32 CCSBattleMgr::Initialize(){ GetCSKernelInstance()-\u0026gt;AddTimer(std::bind(\u0026amp;CCSMatchMgr::Update, m_pMatchMgr, std::placeholders::_1, std::placeholders::_2), c_matcherDelay, true); return eNormal; } GetCSUserMgrInstance()-\u0026gt;Initialize()是初始化mysql和redis的一些相关信息，由于redis是做服务的缓存的，所以我们一般在项目中看到cacheServer这样的字眼指的都是redis：\nvoid CCSUserMgr::Initialize(){ SDBCfg cfgGameDb = CCSCfgMgr::getInstance().GetDBCfg(eDB_GameDb); SDBCfg cfgCdkeyDb=CCSCfgMgr::getInstance().GetDBCfg(eDB_CdkeyDb); m_UserCacheDBActiveWrapper = new DBActiveWrapper( std::bind(\u0026amp;CCSUserMgr::UserCacheDBAsynHandler, this, std::placeholders::_1), cfgGameDb, std::bind(\u0026amp;CCSUserMgr::DBAsyn_QueryWhenThreadBegin, this) ); m_UserCacheDBActiveWrapper-\u0026gt;Start(); m_CdkeyWrapper = new DBActiveWrapper( std::bind(\u0026amp;CCSUserMgr::UserAskDBAsynHandler, this, std::placeholders::_1), cfgCdkeyDb, std::bind(\u0026amp;CCSUserMgr::CDKThreadBeginCallback, this) ); m_CdkeyWrapper-\u0026gt;Start(); for (int i = 0; i \u0026lt; gThread ; i++) { DBActiveWrapper* pThreadDBWrapper(new DBActiveWrapper(std::bind(\u0026amp;CCSUserMgr::UserAskDBAsynHandler, this, std::placeholders::_1), cfgGameDb)); pThreadDBWrapper-\u0026gt;Start(); m_pUserAskDBActiveWrapperVec.push_back(pThreadDBWrapper); } } 注意一点：不知道大家有没有发现，我们代码中大量使用C++11中的std::bind()这样函数，注意由于我们使用的Visual Studio版本是2010，2010这个版本是不支持C++11的，所以这里的std::bind不是C++11的，而是C++11发布之前的草案tr1中的，所以全部的命名空间应该是tr1::std::bind，其他的类似C++11的功能也是一样，所以你在代码中可以看到这样引入命名空间的语句：\nGetCSKernelInstance()-\u0026gt;Start();是初始化所有的网络连接的Session管理器，所谓Session，中文译为“会话”，其下层对应网络通信的连接，每一路连接对应一个Session，而管理这些Session的对象就是Session Manager，在我们的代码中是CSNetSessionMgr，它继承自接口类INetSessionMgr：\nclass CSNetSessionMgr : public INetSessionMgr { public: CSNetSessionMgr(); virtual ~CSNetSessionMgr(); public: virtual ISDSession* UCAPI CreateSession(ISDConnection* pConnection) { return NULL; /*重写*/} virtual ICliSession* UCAPI CreateConnectorSession(SESSION_TYPE type); virtual bool CreateConnector(SESSION_TYPE type, const char* ip, int port, int recvsize, int sendsize, int logicId); private: CSParser m_CSParser; }; 初始化CSNetSessionMgr的代码如下：\nINT32 CCSKernel::Start() { CSNetSessionMgr* pNetSession = new CSNetSessionMgr; GetBattleMgrInstance()-\u0026gt;RegisterMsgHandle(m_SSMsgHandlerMap, m_GSMsgHandlerMap, m_GCMsgHandlerMap, m_RCMsgHandlerMap); GetCSUserMgrInstance()-\u0026gt;RegisterMsgHandle(m_SSMsgHandlerMap, m_GSMsgHandlerMap, m_GCMsgHandlerMap, m_RCMsgHandlerMap); ELOG(LOG_INFO, \u0026#34;success!\u0026#34;); return 0; } 连接数据库成功以后，我们的CSBattleMgr程序的控制台会显示一行提示mysql连接成功：\n读者看上图会发现，这些日志信息有三个颜色，出错信息使用红色，重要的正常信息使用绿色，一般的输出信息使用灰色。这是如何实现的呢？我们将在下一篇文章《从零学习开源项目系列（三） LogServer服务源码研究》中介绍具体实现原理，这也是一种不错的日志级别提醒方式。\n介绍完了初始化流程，我们介绍一下这个服务的主体部分MainLoop()函数，先看一下整体代码：\nvoid CCSKernel::MainLoop(){ TIME_TICK tHeartBeatCDTick = 10; //侦听端口10002 INetSessionMgr::GetInstance()-\u0026gt;CreateListener(m_sCSKernelCfg.n32GSNetListenerPort, 1024000, 10240000, 0, \u0026amp;gGateSessionFactory); //侦听端口10001 INetSessionMgr::GetInstance()-\u0026gt;CreateListener(m_sCSKernelCfg.n32SSNetListenerPort, 1024000, 10240000, 1, \u0026amp;gSceneSessionFactory); //侦听端口10010 INetSessionMgr::GetInstance()-\u0026gt;CreateListener(m_sCSKernelCfg.n32RCNetListenerPort, 1024000, 10240000, 2, \u0026amp;gRemoteConsoleFactory); //连接LogServer 1234端口 INetSessionMgr::GetInstance()-\u0026gt;CreateConnector(ST_CLIENT_C2Log, m_sCSKernelCfg.LogAddress.c_str(), m_sCSKernelCfg.LogPort, 102400, 102400, 0); //连接redis 6379 if (m_sCSKernelCfg.redisAddress != \u0026#34;0\u0026#34;){ INetSessionMgr::GetInstance()-\u0026gt;CreateConnector(ST_CLIENT_C2R, m_sCSKernelCfg.redisAddress.c_str(), m_sCSKernelCfg.redisPort, 102400, 102400, 0); } //连接redis 6380，也是redis-logic if (m_sCSKernelCfg.redisLogicAddress != \u0026#34;0\u0026#34;){ INetSessionMgr::GetInstance()-\u0026gt;CreateConnector(ST_CLIENT_C2LogicRedis, m_sCSKernelCfg.redisLogicAddress.c_str(), m_sCSKernelCfg.redisLogicPort, 102400, 102400, 0); } while (true) { if (kbhit()) { static char CmdArray[1024] = { 0 }; static int CmdPos = 0; char CmdOne = getche(); CmdArray[CmdPos++] = CmdOne; bool bRet = 0; if (CmdPos \u0026gt;= 1024 || CmdOne == 13) { CmdArray[--CmdPos] = 0; bRet = DoUserCmd(CmdArray); CmdPos = 0; if (bRet) break; } } INetSessionMgr::GetInstance()-\u0026gt;Update(); GetCSUserMgrInstance()-\u0026gt;OnHeartBeatImmediately(); ++m_RunCounts; m_BattleTimer.Run(); Sleep(1); } } 这个函数虽然叫MainLoop()，但是实际MainLoop()只是后半部分，前半部分总共创建三个侦听端口和三个连接器，也就是所谓的Listener和Connector，这些对象都是由上文提到的CSNetSessionMgr管理，所谓Listener就是这个服务使用socket API bind()和listen()函数在某个地址+端口号的二元组上绑定，供其他程序连接（其他程序可能是其他服务程序也可能是客户端，具体是哪个，我们后面的文章再进一步挖掘），侦听端口统计如下：\n侦听端口10002 侦听端口10001 侦听端口10010 连接器（Connector）也有三个，分别连接的服务和端口号是：\n连接redis的6379号端口 连接redis-logic的6380端口 连接某服务的1234端口 这个1234端口到底是哪个服务的呢？通过代码我们可以看出是LogServer的，那么到底是不是LogServer的呢，我们后面具体求证一下。\nINetSessionMgr::GetInstance()-\u0026gt;CreateConnector( ST_CLIENT_C2Log, m_sCSKernelCfg.LogAddress.c_str(), m_sCSKernelCfg.LogPort, 102400, 102400, 0); 接着我们就正式进入了一个while循环：\nwhile (true) { if (kbhit()) { static char CmdArray[1024] = { 0 }; static int CmdPos = 0; char CmdOne = getche(); CmdArray[CmdPos++] = CmdOne; bool bRet = 0; if (CmdPos \u0026gt;= 1024 || CmdOne == 13) { CmdArray[--CmdPos] = 0; bRet = DoUserCmd(CmdArray); CmdPos = 0; if (bRet) break; } } INetSessionMgr::GetInstance()-\u0026gt;Update(); GetCSUserMgrInstance()-\u0026gt;OnHeartBeatImmediately(); ++m_RunCounts; m_BattleTimer.Run(); Sleep(1); } 循环具体做了啥，我们先看**INetSessionMgr::GetInstance()-\u0026gt;Update();**代码：\nvoid INetSessionMgr::Update() { mNetModule-\u0026gt;Run(); vector\u0026lt;char*\u0026gt; tempQueue; EnterCriticalSection(\u0026amp;mNetworkCs); tempQueue.swap(m_SafeQueue); LeaveCriticalSection(\u0026amp;mNetworkCs); for (auto it=tempQueue.begin();it!=tempQueue.end();++it){ char* pBuffer = (*it); int nType = *(((int*)pBuffer)+0); int nSessionID = *(((int*)pBuffer)+1); Send((SESSION_TYPE)nType,nSessionID,pBuffer+2*sizeof(int)); delete []pBuffer; } auto \u0026amp;map = m_AllSessions.GetPointerMap(); for (auto it=map.begin();it!=map.end();++it) { (*it)-\u0026gt;Update(); } } 通过这段代码我们看出，这个函数先是使用std::vector对象的swap()方法把一个公共队列中的数据倒换到一个临时队列中，这是一个很常用的技巧，目的是减小锁的粒度：由于公共的队列需要被生产者和消费者同时使用，我们为了减小加锁的粒度和时间，把当前队列中已有的数据一次性倒换到消费者本地的一个临时队列中来，这样消费者就可以使用这个临时队列了，从而避免了每次都要通过加锁从公共队列中取数据了，提高了效率。接着，我们发现这个队列中的数据是一个个的Session对象，遍历这些Session对象个每个Session对象的连接的对端发数据，同时执行Session对象的Update()方法。具体发了些什么数据，我们后面的文章再研究。\n我们再看一下循环中的第二个函数GetCSUserMgrInstance()-\u0026gt;OnHeartBeatImmediately();，其代码如下：\nINT32 CCSUserMgr::OnHeartBeatImmediately() { OnTimeUpdate(); SynUserAskDBCallBack(); return eNormal; } 这些名字都是自解释的，先是同步时间，再同步数据库的一些操作：\nINT32 CCSUserMgr::SynUserAskDBCallBack(){ while (!m_DBCallbackQueue.empty()){ Buffer* pBuffer = NULL; m_DBCallbackQueue.try_pop(pBuffer); switch (pBuffer-\u0026gt;m_LogLevel) { case DBToCS::eQueryUser_DBCallBack: SynHandleQueryUserCallback(pBuffer); break; case DBToCS::eQueryAllAccount_CallBack: SynHandleAllAccountCallback(pBuffer); break; case DBToCS::eMail_CallBack: SynHandleMailCallback(pBuffer); break; case DBToCS::eQueryNotice_CallBack: DBCallBack_QueryNotice(pBuffer); break; default: ELOG(LOG_WARNNING, \u0026#34;not hv handler:%d\u0026#34;, pBuffer-\u0026gt;m_LogLevel); break; } if (pBuffer){ m_DBCallbackQueuePool.ReleaseObejct(pBuffer); } } return 0; } 再看一下while循环中第三个函数m_BattleTimer.Run()；其代码如下：\nvoid CBattleTimer::Run(){ TimeKey nowTime = GetInternalTime(); while(!m_ThreadTimerQueue.empty()){ ThreadTimer\u0026amp; sThreadTimer = m_ThreadTimerQueue.top(); if (!m_InvalidTimerSet.empty()){ auto iter = m_InvalidTimerSet.find(sThreadTimer.sequence); if (iter != m_InvalidTimerSet.end()){ m_InvalidTimerSet.erase(iter); m_ThreadTimerQueue.pop(); continue; } } if (nowTime \u0026gt;= sThreadTimer.nextexpiredTime){ m_PendingTimer.push_back(sThreadTimer); m_ThreadTimerQueue.pop(); } else{ break; } } if (!m_PendingTimer.empty()){ for (auto iter = m_PendingTimer.begin(); iter != m_PendingTimer.end(); ++iter){ ThreadTimer\u0026amp; sThreadTimer = *iter; nowTime = GetInternalTime(); int64_t tickSpan = nowTime - sThreadTimer.lastHandleTime; sThreadTimer.pHeartbeatCallback(nowTime, tickSpan); if (sThreadTimer.ifPersist){ TimeKey newTime = nowTime + sThreadTimer.interval; sThreadTimer.lastHandleTime = nowTime; sThreadTimer.nextexpiredTime = newTime; m_ThreadTimerQueue.push(sThreadTimer); } } m_PendingTimer.clear(); } if (!m_ToAddTimer.empty()){ for (auto iter = m_ToAddTimer.begin(); iter != m_ToAddTimer.end(); ++iter){ m_ThreadTimerQueue.push(*iter); } m_ToAddTimer.clear(); } } 这也是一个与时间有关的操作。具体细节我们也在后面文章中介绍。\nCSBattleMgr服务跑起来之后，cmd窗口显示如下：\n上图中我们看到Mysql和redis服务均已连上，但是程序会一直提示连接127.0.0.1:1234端口连不上。由此我们断定，这个使用1234端口的服务没有启动。这不是我们介绍的重点，重点是说明这个服务会定时自动重连这个1234端口，自动重连机制是我们做服务器开发必须熟练开发的一个功能。所以我建议大家好好看一看这一块的代码。这里我带着大家简单梳理一遍吧。\n首先，我们根据提示找到INetSessionMgr::LogText的42行，并在那里加一个断点：\n很快，由于重连机制，触发这个断点，我们看下此时的调用堆栈：\n我们切换到如图箭头所示的堆栈处代码：\n箭头所示说明是mNetModule-\u0026gt;Run();调用产生的日志输出。我们看下这个的调用：\nbool CUCODENetWin::Run(INT32 nCount) { CConnDataMgr::Instance()-\u0026gt;RunConection(); do { // #ifdef UCODENET_HAS_GATHER_SEND // #pragma message(\u0026#34;[preconfig]sdnet collect buffer, has a internal timer\u0026#34;) // if (m_pTimerModule) // { // m_pTimerModule-\u0026gt;Run(); // } // #endif #ifdef UCODENET_HAS_GATHER_SEND static INT32 sendCnt = 0; ++sendCnt; if (sendCnt == 10) { sendCnt = 0; UINT32 now = GetTickCount(); if (now \u0026lt; m_dwLastTick) { /// 溢出了,发生了数据回绕 \\/// m_dwLastTick = now; } if ((now - m_dwLastTick) \u0026gt; 50) { m_dwLastTick = now; FlushBufferedData(); } } #endif // //SNetEvent stEvent; SNetEvent *pstEvent = CEventMgr::Instance()-\u0026gt;PopFrontNetEvt(); if (pstEvent == NULL) { return false; } SNetEvent \u0026amp; stEvent = *pstEvent; switch(stEvent.nType) { case NETEVT_RECV: _ProcRecvEvt(\u0026amp;stEvent.stUn.stRecv); break; case NETEVT_SEND: _ProcSendEvt(\u0026amp;stEvent.stUn.stSend); break; case NETEVT_ESTABLISH: _ProcEstablishEvt(\u0026amp;stEvent.stUn.stEstablish); break; case NETEVT_ASSOCIATE: _ProcAssociateEvt(\u0026amp;stEvent.stUn.stAssociate); break; case NETEVT_TERMINATE: _ProcTerminateEvt(\u0026amp;stEvent.stUn.stTerminate); break; case NETEVT_CONN_ERR: _ProcConnErrEvt(\u0026amp;stEvent.stUn.stConnErr); break; case NETEVT_ERROR: _ProcErrorEvt(\u0026amp;stEvent.stUn.stError); break; case NETEVT_BIND_ERR: _ProcBindErrEvt(\u0026amp;stEvent.stUn.stBindErr); break; default: SDASSERT(false); break; } CEventMgr::Instance()-\u0026gt;ReleaseNetEvt(pstEvent); }while(--nCount != 0); return true; } 我们看到**SNetEvent *pstEvent = CEventMgr::Instance()-\u0026gt;PopFrontNetEvt();**时，看到这里我们大致可以看出这又是一个生产者消费者模型，只不过这里是消费者——从队列中取出数据，对应的switch-case分支是：\ncase NETEVT_CONN_ERR: _ProcConnErrEvt(\u0026amp;stEvent.stUn.stConnErr); 即连接失败。那么在哪里连接的呢？我们只需要看看这个队列的生产者在哪里就能找到了，因为连接不成功，往队列中放入一条连接出错的数据，我们看一下**CEventMgr::Instance()-\u0026gt;PopFrontNetEvt()**的实现，找到具体的队列名称：\n/** * @brief 获取一个未处理的网络事件(目前为最先插入的网络事件) * @return 返回一个未处理的网络事件.如果处理失败,返回NULL * @remark 由于此类只有在主线程中调用,所以,此函数内部并未保证线程安全 */ inline SNetEvent* PopFrontNetEvt() { return (SNetEvent*)m_oEvtQueue.PopFront(); } 通过这段代码我们发现队列的名字叫m_oEvtQueue，我们通过搜索这个队列的名字找到生产者，然后在生产者往队列中加入数据那里加上一个断点：\n等断点触发以后，我们看下此时的调用堆栈：\n我们切换到上图中箭头所指向的代码处：\n到这里我们基本上认识了，这里连接使用的异步connect()，即在线程A中将连接socket，然后使用WSAEventSelect绑定该socket并设置该socket为非阻塞模式，等连接有结果了（成功或失败）使用Windows API WSAEnumNetworkEvents去检测这个socket的连接事件（FD_CONNECT），然后将判断结果加入队列m_oEvtQueue中，另外一个线程B从队列中取出判断结果打印出日志。如果您不清楚这个流程，请学习一下异步connect的使用方法和WSAEventSelect、WSAEnumNetworkEvents的用法。那么这个异步connect在哪里呢？我们搜索一下socket API connect函数（其实我可以一开始就搜索connect函数的，但是我之所以不这么做是想让您了解一下我研究一个不熟悉的项目代码的思路），得到如下图：\n我们在上述标红的地方加个断点：\n通过上图中的端口信息1234，我们验证了的确是上文说的流程。然后我们观察一下这个调用堆栈：\n发现这里又是一个消费者，又存在一个队列！\n同样的道理，我们通过队列名称m_oReqQueue找到生产者：\n我们看下这个时候的生产者的调用堆栈：\n切换到如图所示的代码处：\nbool ICliSession::Reconnect() { if (IsHadRecon() \u0026amp;\u0026amp; mReconnectTag) { UINT32 curTime = GetTickCount(); if (curTime\u0026gt;mReconTime) { mReconTime = curTime+10000; if (m_poConnector-\u0026gt;ReConnect()) { //printf(\u0026#34;client reconnect server(%s)...\\n\u0026#34;,mRemoteEndPointer.c_str()); ResetRecon(); return true; } } } return false; } 在这里我们终于可以好好看一下重连的逻辑如何设计了。具体代码读者自己分析哈，限于篇幅这里就不介绍了。\n看到这里，可能很多读者在对照我提供的代码时，会产生一个困难：同样的代码为啥在我手中可以这样分析，但是到你们手中可能就磕磕绊绊了？只能说经验和自我学习这是相辅相成的过程，例如上文中说的生产者消费者模式、任务队列，我曾经也和你们一样，也不熟悉这些东西，但是当我知道这些东西时我就去学习这些我认为的“基础”知识，并且反复练习，这样也就慢慢积累经验了。所以，孔子说的没错：学而不思则罔，思而不学则殆。什么时候该去学习，什么时候该去思考，古人诚不欺我也。\n到这里我们也大致清楚了CSBattleMgr做了哪些事情。后面我们把所有的服务都过一遍之后再从整体来介绍。下一篇文章我们将继续研究这个侦听1234端口的LogServer，敬请期待。\n限于作者经验水平有限，文章中可能有错漏的地方，欢迎批评指正。\n欢迎阅读下一篇《从零学习开源项目系列（四） LogServer源码探究》。\n源码下载方法：\n微信搜索公众号 『高性能服务器开发』(中文名：高性能服务器开发)，关注公众号后，在公众号中回复**『英雄联盟』** ，即可得到下载链接。（喷子和代码贩子请远离！）\n","permalink":"https://haokiu.com/blog/86a8b9de9c914f8ab93a3d36b455838b/","summary":"从零学习开源项目系列（三） CSBattleMgr服务源码研究 服务器项目工程如下图所示：\n如上图所示，这篇文章我们将介绍CSBattleMgr的情况，但是我们不会去研究这个服务器的特别细节的东西（这些细节我们将在后面的文章中介绍）。阅读一个未知的项目源码如果我们开始就纠结于各种细节，那么我们最终会陷入“横看成岭侧成峰，远近高低各不同”的尴尬境界，浪费时间不说，可能收获也是事倍功半。所以，尽管我们不熟悉这套代码，我们还是尽量先从整体来把握，先大致了解各个服务的功能，细节部分回头再针对性地去研究。\n这个系列的第二篇文章《从零学习开源项目系列（二） 最后一战概况》中我们介绍了，这套游戏的服务需要使用redis和mysql，我们先看下mysql是否准备好了（mysql服务启动起来，数据库建表数据存在，具体细节请参考第二篇文章）。打开Windows的cmd程序，输入以下指令连接mysql：\nmysql -uroot -p123321 连接成功以后，如下图所示：\n然后我们输入以下指令，查看我们需要的数据库是否创建成功：\nshow databases; 这些都是基本的sql语句，如果您不熟悉的话，可能需要专门学习一下。\n数据库创建成功后如下图所示：\n至于数据库中的表是否创建成功，我们这里先不关注，后面我们实际用到哪张数据表，我们再去研究。\nmysql没问题了，接下来我们要启动一下redis，通过第二篇文章我们知道redis需要启动两次，也就是一共两个redis进程，我们游戏服务中分别称为redis-server和redis-login-server（它们的配置文件信息不一样），我们可以在Server\\Bin\\x64\\Release目录下手动cmd命令行执行下列语句：\nstart /min \u0026#34;redis-server\u0026#34; \u0026#34;redis-server.exe\u0026#34; redis.conf start /min \u0026#34;redis-Logicserver\u0026#34; \u0026#34;redis-server.exe\u0026#34; redis-logic.conf 但是这样比较麻烦，我将这两句拷贝出来，放入一个叫start-redis.bat文件中了，每次启动只要执行一下这个bat文件就可以：\nredis和redis-logic服务启动后如下图所示：\n我们常见的redis服务都是linux下的源码，微软公司对redis源码进行了改造，出了一个Windows版本，稍微有点不尽人意（例如：Windows下没有完全与linux的fork()相匹配的API，所以只能用CreateProcess()去替代）。关于windows版本的redis源码官方下载地址为：https://github.com/MicrosoftArchive/redis/releases。\n在启动好了mysql和redis后，我们现在正式来看一下CSBattleMgr这个服务。读者不禁可能要问，那么多服务，你怎么知道要先看这个服务呢？我们上一篇文章中也说过，我们再start.bat文件中发现除了redis以外，这是第三个需要启动的服务，所以我们先研究它（start.bat我们可以认为是源码作者为我们留下的部署步骤“文档”）：\n我们打开CSBattleMgr服务main.cpp文件，找到入口main函数，内容如下：\nint main(){ DbgLib::CDebugFx::SetExceptionHandler(true); DbgLib::CDebugFx::SetExceptionCallback(ExceptionCallback, NULL); GetCSKernelInstance(); GetCSUserMgrInstance(); GetBattleMgrInstance(); GetCSKernelInstance()-\u0026gt;Initialize(); GetBattleMgrInstance()-\u0026gt;Initialize(); GetCSUserMgrInstance()-\u0026gt;Initialize(); GetCSKernelInstance()-\u0026gt;Start(); mysql_library_init(0, NULL, NULL); GetCSKernelInstance()-\u0026gt;MainLoop(); } 通过调试，我们发下这个函数大致做了以下任务：\n//1. 设置程序异常处理函数 //2. 初始化一系列单例对象 //3. 初始化mysql //4. 进入一个被称作“主循环”的无限循环 步骤1设置程序异常处理函数没有好介绍的，我们看一下步骤2初始化一系列单例对象，总共初始化了三个类的对象CCSKernel、CCSUserMgr和CCSBattleMgr。单例模式本身没啥好介绍的，但是有人要提单例模式的线程安全性，所以出现很多通过加锁的单例模式代码，我个人觉得没必要；认为要加锁的朋友可能认为单例对象如果在第一次初始化时同时被多个线程调用就会有问题，我觉得加锁带来的开销还不如像上面的代码一样，在整个程序初始化初期获取一下单例对象，让单例对象生成出来，后面即使多个线程获取这个单例对象也都是读操作，无需加锁。以GetCSKernelInstance();为例：\nCCSKernel* GetCSKernelInstance(){ return \u0026amp;CCSKernel::GetInstance(); } CCSKernel\u0026amp; CCSKernel::GetInstance(){ if (NULL == pInstance){ pInstance = new CCSKernel; } return *pInstance; } GetCSKernelInstance()-\u0026gt;Initialize()的初始化动作其实是加载各种配置信息和事先设置一系列的回调函数和定时器：\nINT32 CCSKernel::Initialize() { //JJIAZ加载配置的时候 不要随便调整顺序 CCSCfgMgr::getInstance().Initalize(); INT32 n32Init = LoadCfg(); if (eNormal != n32Init) { ELOG(LOG_ERROR,\u0026#34; loadCfg()............failed!\u0026#34;); return n32Init; } if(m_sCSKernelCfg.un32MaxSSNum \u0026gt; 0 ) { m_psSSNetInfoList = new SSSNetInfo[m_sCSKernelCfg.","title":"从零学习开源项目系列（三） CSBattleMgr服务源码研究"},{"content":"从零学习开源项目系列（二） 最后一战概况 这份代码我也是无意中来自一个朋友，据他说也是来源于互联网，服务器端代码原来是Linux版本的，但被厉害的大神修改成可以在Windows上运行。（如果不小心侵犯了您的版权，请联系我删除）。好在，这份代码中使用的大多数方法和接口都是可以跨Windows和Linux两个平台的，所以Linux开发下的朋友请不要感到不适，我们学习这份代码更多的不是纠结细节而是学习思路和原理。\n游戏主solution文件用Visual Studio打开后如下图所示：\n这里总共有10个工程项目，模块比较多。**我们应该从何处入手呢？**我们先看下源码目录：\n我们进入Server目录，发现如下一个文件：\n我们打开看一下内容：\ncd Bin\\x64\\Release start.bat 这个代码进入Bin\\x64\\Release目录，执行另外一个start.bat，我们进入这个目录去看下这个文件内容：\ntaskkill /f /t /im redis-server.exe taskkill /f /t /im CSBattleMgr.exe taskkill /f /t /im SSBattleMgr.exe taskkill /f /t /im GSConsole.exe taskkill /f /t /im BalanceServer.exe taskkill /f /t /im LoginServer.exe taskkill /f /t /im GSKernel.exe taskkill /f /t /im RobotConsole.exe taskkill /f /t /im LogServer.exe ping -n 1 127.0\u0026gt;nul start /min \u0026#34;redis-server\u0026#34; \u0026#34;redis-server.exe\u0026#34; redis.conf ping -n 1 127.0\u0026gt;nul start /min \u0026#34;redis-Logicserver\u0026#34; \u0026#34;redis-server.exe\u0026#34; redis-logic.conf ping -n 1 127.0\u0026gt;nul echo \u0026#34;start CSBattleMgr.exe\u0026#34; start /min \u0026#34;CSBattleMgr\u0026#34; \u0026#34;CSBattleMgr.exe\u0026#34; ping -n 1 127.0\u0026gt;nul echo \u0026#34;start SSBattleMgr.exe\u0026#34; start /min \u0026#34;SSBattleMgr\u0026#34; \u0026#34;SSBattleMgr.exe\u0026#34; ping -n 1 127.0\u0026gt;nul echo \u0026#34;start GSKernel.exe\u0026#34; start /min \u0026#34;GSKernel\u0026#34; \u0026#34;GSKernel.exe\u0026#34; ping -n 1 127.0\u0026gt;nul echo \u0026#34;start BalanceServer.exe\u0026#34; start /min \u0026#34;BalanceServer\u0026#34; \u0026#34;BalanceServer.exe\u0026#34; ping -n 1 127.0\u0026gt;nul echo \u0026#34;start LoginServer.exe\u0026#34; start /min \u0026#34;LoginServer\u0026#34; \u0026#34;LoginServer.exe\u0026#34; ping -n 1 127.0\u0026gt;nul echo \u0026#34;start LogServer.exe\u0026#34; start /min \u0026#34;LogServer\u0026#34; \u0026#34;LogServer.exe\u0026#34; 通过这个脚本，我们得到了这个服务器项目的一些信息，这个服务器由以下一些服务组成：\nredis-server（启动两个） CSBattleMgr SSBattleMgr GSKernel BalanceServer LoginServer LogServer 这些服务器具体是做啥的，我现在也不知道，后面我们会教大家如何阅读。\n另外在Bin/x64/Release/dbsql目录我们发下一些sql文件：\n我们打开建表的createdb.sql：\ndrop database if exists fball_gamedb; drop database if exists fball_logdb; drop database if exists fball_accountdb; create database fball_accountdb character set utf8; drop database if exists fball_chargedb; create database fball_chargedb character set utf8; drop database if exists fball_robedb; create database fball_robedb character set utf8; drop database if exists fball_gamedb_1; create database fball_gamedb_1 character set utf8; drop database if exists fball_gamedb_2; create database fball_gamedb_2 character set utf8; drop database if exists fball_gamedb_3; create database fball_gamedb_3 character set utf8; drop database if exists fball_logdb_1; create database fball_logdb_1 character set utf8; drop database if exists fball_logdb_2; create database fball_logdb_2 character set utf8; drop database if exists fball_logdb_3; create database fball_logdb_3 character set utf8; 也就是说，这套服务需要使用mysql，我们安装一个mysql，并执行这个Rebuild.bat把这些库创建一下，Rebuild.bat内容如下：\n@echo off :begin @echo ----------1, create all game database------------ mysql -uroot -p123321\u0026lt;createdb.sql mysql -uroot -p123321\u0026lt;grantuser.sql mysql -uroot -p123321\u0026lt;fball_accountdb.sql mysql -uroot -p123321\u0026lt;fball_chargedb.sql mysql -uroot -p123321\u0026lt;fball_robedb.sql mysql -uroot -p123321 fball_accountdb \u0026lt; fball_accountdb.sql mysql -uroot -p123321 fball_chargedb \u0026lt; fball_chargedb.sql mysql -uroot -p123321 fball_robedb \u0026lt; fball_robedb.sql mysql -uroot -p123321 fball_gamedb_1 \u0026lt; fball_gamedb.sql mysql -uroot -p123321 fball_gamedb_2 \u0026lt; fball_gamedb.sql mysql -uroot -p123321 fball_gamedb_3 \u0026lt; fball_gamedb.sql mysql -uroot -p123321 fball_logdb_1 \u0026lt; fball_logdb.sql mysql -uroot -p123321 fball_logdb_2 \u0026lt; fball_logdb.sql mysql -uroot -p123321 fball_logdb_3 \u0026lt; fball_logdb.sql 通过这个，我们发现这里mysql的root用户的密码123321。你在创建mysql时，需要建议将密码也设置成这个。\n我们下载mysql community版本（免费的），下载地址：\nhttps://dev.mysql.com/downloads/mysql/\n类型我们选Microsoft：\n注意，这套服务也使用了redis，我们不用专门下载和编译redis windows版本，我们的程序目录下已经提供了windows版本的redis的服务程序和配置文件：\n我们搞清楚基本服务器概况后，各个服务的作用以及服务之间的关系如何，我们下一篇文章继续分析。\n欢迎阅读下一篇**《从零学习开源项目系列（三） CSBattleMgr和LogServer》。**\n源码下载方法：\n微信搜索公众号**『高性能服务器开发』(中文名：高性能服务器开发)，关注公众号后，在公众号中回复『英雄联盟』**，即可得到下载链接。（喷子和代码贩子请远离！）\n","permalink":"https://haokiu.com/blog/92d9492b21aa444d81eb4f31c1bfabb1/","summary":"从零学习开源项目系列（二） 最后一战概况 这份代码我也是无意中来自一个朋友，据他说也是来源于互联网，服务器端代码原来是Linux版本的，但被厉害的大神修改成可以在Windows上运行。（如果不小心侵犯了您的版权，请联系我删除）。好在，这份代码中使用的大多数方法和接口都是可以跨Windows和Linux两个平台的，所以Linux开发下的朋友请不要感到不适，我们学习这份代码更多的不是纠结细节而是学习思路和原理。\n游戏主solution文件用Visual Studio打开后如下图所示：\n这里总共有10个工程项目，模块比较多。**我们应该从何处入手呢？**我们先看下源码目录：\n我们进入Server目录，发现如下一个文件：\n我们打开看一下内容：\ncd Bin\\x64\\Release start.bat 这个代码进入Bin\\x64\\Release目录，执行另外一个start.bat，我们进入这个目录去看下这个文件内容：\ntaskkill /f /t /im redis-server.exe taskkill /f /t /im CSBattleMgr.exe taskkill /f /t /im SSBattleMgr.exe taskkill /f /t /im GSConsole.exe taskkill /f /t /im BalanceServer.exe taskkill /f /t /im LoginServer.exe taskkill /f /t /im GSKernel.exe taskkill /f /t /im RobotConsole.exe taskkill /f /t /im LogServer.exe ping -n 1 127.0\u0026gt;nul start /min \u0026#34;redis-server\u0026#34; \u0026#34;redis-server.exe\u0026#34; redis.conf ping -n 1 127.0\u0026gt;nul start /min \u0026#34;redis-Logicserver\u0026#34; \u0026#34;redis-server.exe\u0026#34; redis-logic.conf ping -n 1 127.0\u0026gt;nul echo \u0026#34;start CSBattleMgr.exe\u0026#34; start /min \u0026#34;CSBattleMgr\u0026#34; \u0026#34;CSBattleMgr.exe\u0026#34; ping -n 1 127.0\u0026gt;nul echo \u0026#34;start SSBattleMgr.exe\u0026#34; start /min \u0026#34;SSBattleMgr\u0026#34; \u0026#34;SSBattleMgr.exe\u0026#34; ping -n 1 127.","title":"从零学习开源项目系列（二） 最后一战概况"},{"content":"从零学习开源项目系列（四）LogServer源码探究 这是从零学习开源项目的第四篇，上一篇是《从零学习开源项目系列（三） CSBattleMgr服务源码研究》，这篇文章我们一起来学习LogServer，中文意思可能是“日志服务器”。那么这个日志服务器到底做了哪些工作呢？\n我们在Visual Studio中将LogServer设置为启动项，然后按F5将LogServer启动起来，启动成功后显示如下图：\n从上图中，我们可以到大致做了三件事：\n1. 创建一个侦听端口（端口号1234） 2. 连接mysql数据库 3. 初始化日志处理程序 我们来验证一下这三件事的细节。我们再Visual Studio中将程序中断（【调试】菜单-【全部中断】，快捷键Ctrl + Alt + Break）。然后在线程窗口查看这个程序所有的线程，如下图所示：\n所有用红色旗帜标记的线程都是用户线程，我们可以查看这些线程的调用堆栈。我们从最上面的主线程开始：\n切换到main函数，我们可以看出这里是一个循环：\nint main() { auto res = CLogHandler::GetInstance().Init(); if (res) { while(true) { INetSessionMgr::GetInstance()-\u0026gt;Update(); Sleep(1); } } return 0; } 这里一个是初始化动作，一个循环中Update动作，它们具体做了些什么，我们先不管，我们先看其他线程做了什么，再回过头来看这里的代码。\n我们接着看下一个线程的内容：\n从调用堆栈来看，这是一个使用boost::thread启动的线程，这个线程函数代码如下：\nvoid Active::Run() { if (m_BeginInThreadCallback){ m_BeginInThreadCallback(); } while (true){ Consume(); } } 我们先看下这个线程函数做了什么，主要是m_BeginInThreadCallback和**Consume()函数，看下Consume()**函数：\nvoid Active::Consume(){ boost::mutex::scoped_lock lock(m_IOMutex); while(m_Queue.empty()){ m_ConditionVar.wait(lock); } m_SwapQueue.swap(m_Queue); lock.unlock(); while(!m_SwapQueue.empty()){ Buffer* pBuffer = m_SwapQueue.front(); m_SwapQueue.pop(); m_Callback(pBuffer); --m_PendingWorkNum; if (pBuffer){ m_pBufferPool.ReleaseObejct(pBuffer); } } } 这段代码很好理解，先使用条件变量挂起当前线程，条件变量触发后，如果消费者和生产者共有队列m_Queue中有数据，将公用的队列m_Queue临时倒换到本地的一个局部队列m_SwapQueue中，然后挨个处理队列m_SwapQueue中的数据。\n这个线程在哪里创建的呢？通过搜索线程函数，我们找到如下代码：\nvoid Active::Start(){ bool ifHvTimer = !m_ThreadTimer.IsEmpty(); if (ifHvTimer){ m_Thread = boost::thread(\u0026amp;Active::RunWithUpdate, this); } else{ m_Thread = boost::thread(\u0026amp;Active::Run, this); } m_ThreadID = get_native_thread_id(m_Thread); char sThreadName[30]; sprintf(sThreadName, \u0026#34;%s-%d\u0026#34;, \u0026#34;Actor-Run\u0026#34;, GetActorID()); _SetThreadName(m_ThreadID, sThreadName); } 在上面这个函数中添加断点，重启下程序，很快会触发断点，我们看下断点触发时的调用堆栈：\n通过调用堆栈，我们发现这个线程在一个全局变量的构造函数中初始化的，这个全局变量在DllMain()函数中初始化：\n而这个dll是ELogging项目生成的：\n也就是说，这是一个与日志处理相关的线程。生产者产生日志记录，然后由这个线程作为消费者，来处理日志。\n我们接着看下一个线程的内容：\nvoid CConnectCtrl::OnExecute() { while(!m_bTerminate) { _ProcRequests(); _ProcEvents(); //CCPSockMgr::Instance()-\u0026gt;CheckDelayRelease(); Sleep(1); } } 这也是一个循环，先看下_ProcRequests()函数：\nvoid CConnectCtrl::_ProcRequests() { while(m_dwSockCount \u0026lt; (UINT32)MAX_CONNECTION) { SConnReq* pstConnReq = (SConnReq*)m_oReqQueue.PopFront(); if(NULL == pstConnReq) { break; } SOCKET hSock = socket(PF_INET, SOCK_STREAM, IPPROTO_IP); if(INVALID_SOCKET == hSock) { CRITICAL(_SDT(\u0026#34;CConnectCtrl::_ProcRequests, socket failed, errno %d\u0026#34;), WSAGetLastError()); CEventMgr::Instance()-\u0026gt;PushConnErrEvt(WSAGetLastError(), pstConnReq-\u0026gt;dwConnectorID); m_oFreeQueue.PushBack(pstConnReq); break; } //// 2009-04-02 cwy modify for general use if (pstConnReq-\u0026gt;bNeedBind) { if ( false == BindAddress(hSock, pstConnReq-\u0026gt;pszBindIP, pstConnReq-\u0026gt;wBindPort) ) { _OnSockError(hSock, pstConnReq); break; } } if (g_bNodelay) { const CHAR szOpt = 1; if (0 != ::setsockopt(hSock, IPPROTO_TCP, TCP_NODELAY, (char *)\u0026amp;szOpt, sizeof(char))) { WARN(_SDT(\u0026#34;setsockopt for new socket on UpdateConetext failed, errno=%d\u0026#34;), ::WSAGetLastError()); } } WSAEVENT hEvent = WSACreateEvent(); if(WSA_INVALID_EVENT == hEvent) { _OnSockError(hSock, pstConnReq); break; } if(SOCKET_ERROR == WSAEventSelect(hSock, hEvent, FD_CONNECT)) { _OnSockError(hSock, pstConnReq); WSACloseEvent(hEvent); break; } sockaddr_in stAddr = {0}; stAddr.sin_family = AF_INET; stAddr.sin_addr.s_addr = pstConnReq-\u0026gt;dwIP; stAddr.sin_port = htons(pstConnReq-\u0026gt;wPort); if( SOCKET_ERROR == connect(hSock, (sockaddr*)\u0026amp;stAddr, sizeof(stAddr)) ) { if(WSAEWOULDBLOCK != WSAGetLastError()) { _OnSockError(hSock, pstConnReq); WSACloseEvent(hEvent); break; } } m_pProcReqArray[m_dwSockCount] = pstConnReq; m_pSockArray[m_dwSockCount] = hSock; m_pEventsArray[m_dwSockCount] = hEvent; ++m_dwSockCount; } } 这段函数的逻辑也是比较容易懂，先从一个队列中取出数据，然后处理，只不过这些数据都是与连接相关的信息。\n再看下while循环中第二个函数_ProcEvents：\nvoid CConnectCtrl::_ProcEvents() { if(0 == m_dwSockCount) { return; } WSANETWORKEVENTS stNetworkEvents; WSAEVENT* pEvents; UINT32 dwCount; UINT32 dwIndex; UINT32 dwStart = 0; do { pEvents = \u0026amp;m_pEventsArray[dwStart]; if(dwStart + WSA_MAXIMUM_WAIT_EVENTS \u0026gt; m_dwSockCount) { dwCount = m_dwSockCount - dwStart; } else { dwCount = WSA_MAXIMUM_WAIT_EVENTS; } dwIndex = WSAWaitForMultipleEvents(dwCount, pEvents, false, 0, false); if(WSA_WAIT_FAILED == dwIndex || WSA_WAIT_TIMEOUT == dwIndex) { dwStart += dwCount; continue; } dwIndex -= WSA_WAIT_EVENT_0; dwIndex += dwStart; ++dwStart; SDASSERT(m_pProcReqArray[dwIndex] != NULL \u0026amp;\u0026amp; m_pSockArray[dwIndex] != INVALID_SOCKET \u0026amp;\u0026amp; m_pEventsArray[dwIndex] != WSA_INVALID_EVENT); if(SOCKET_ERROR == WSAEnumNetworkEvents(m_pSockArray[dwIndex], m_pEventsArray[dwIndex], \u0026amp;stNetworkEvents)) { if(WSAEWOULDBLOCK != WSAGetLastError()) { CEventMgr::Instance()-\u0026gt;PushConnErrEvt(WSAGetLastError(), m_pProcReqArray[dwIndex]-\u0026gt;dwConnectorID); _CloseEvent(dwIndex); } continue; } if(stNetworkEvents.lNetworkEvents \u0026amp; FD_CONNECT) { if(stNetworkEvents.iErrorCode[FD_CONNECT_BIT] != 0) { CEventMgr::Instance()-\u0026gt;PushConnErrEvt(stNetworkEvents.iErrorCode[FD_CONNECT_BIT], m_pProcReqArray[dwIndex]-\u0026gt;dwConnectorID); _CloseEvent(dwIndex); continue; } // // 连接成功 // SConnReq* pstReq = m_pProcReqArray[dwIndex]; CConnData * pConnData = CConnDataMgr::Instance()-\u0026gt;Alloc(pstReq-\u0026gt;dwRecvBufSize, pstReq-\u0026gt;dwSendBufSize); if (pConnData == NULL) { CRITICAL(_SDT(\u0026#34;CConnectCtrl::_ProcEvents, create ConnData failed\u0026#34;)); CEventMgr::Instance()-\u0026gt;PushConnErrEvt(0, pstReq-\u0026gt;dwConnectorID); _CloseEvent(dwIndex); continue; } CCPSock *poSock = \u0026amp;pConnData-\u0026gt;sock; CUCConnection * poConnection = \u0026amp;pConnData-\u0026gt;connection; poSock-\u0026gt;SetSock(m_pSockArray[dwIndex]); m_oFreeQueue.PushBack(m_pProcReqArray[dwIndex]); WSACloseEvent(m_pEventsArray[dwIndex]); m_pProcReqArray[dwIndex] = NULL; m_pSockArray[dwIndex] = INVALID_SOCKET; m_pEventsArray[dwIndex] = WSA_INVALID_EVENT; sockaddr_in stAddr = {0}; INT32 nAddrLen = sizeof(stAddr); getsockname(poSock-\u0026gt;GetSock(), (sockaddr*)\u0026amp;stAddr, \u0026amp;nAddrLen); poConnection-\u0026gt;SetAccept(false); poConnection-\u0026gt;SetParentID(pstReq-\u0026gt;dwConnectorID); poConnection-\u0026gt;SetSession(pstReq-\u0026gt;poSession); poConnection-\u0026gt;SetLocalIP(stAddr.sin_addr.s_addr); poConnection-\u0026gt;SetLocalPort(SDNtohs(stAddr.sin_port)); poConnection-\u0026gt;SetRemoteIP(pstReq-\u0026gt;dwIP); poConnection-\u0026gt;SetRemotePort(pstReq-\u0026gt;wPort); //poConnection-\u0026gt;SetCpSock(poSock); //poSock-\u0026gt;SetConnection(poConnection); poSock-\u0026gt;SetPacketParser(pstReq-\u0026gt;poPacketParser); poSock-\u0026gt;SetConnect(TRUE); //CEventMgr::Instance()-\u0026gt;PushEstablishEvt(pConnData, false, pstReq-\u0026gt;dwConnectorID); if(false == poSock-\u0026gt;AssociateWithIocp()) { poSock-\u0026gt;Close(); } else { if(false == poSock-\u0026gt;PostRecv()) { poSock-\u0026gt;Close(); } } } }while(dwStart \u0026lt; m_dwSockCount); _CompressEvent(); } 这个函数，对上一个函数中发起的连接结果做出判断并处理。如果连接成功，则向完成端口上投递一个recv事件。这个循环的代码，我建议读者好好研究一下，非常好的重连实例，同时也组合了完成端口的模型，还有一些重要的网络编程细节（如nodelay选项等）。\n那么这个线程在哪里启动的呢？通过搜索OnExecute函数名我们发现真正的线程函数：\nunsigned CConnectCtrl::ThreadFunc(LPVOID pParam) { CConnectCtrl* poCtrl = (CConnectCtrl*)pParam; poCtrl-\u0026gt;OnExecute(); return 0; } 进而搜索到：\nbool CConnectCtrl::Init() { INT32 nMaxRequest = MAX_CONNECTION * 2; m_pAllReqArray = new SConnReq[nMaxRequest]; if(NULL == m_pAllReqArray) { return false; } if(false == m_oFreeQueue.Init(nMaxRequest+1)) { return false; } if(false == m_oReqQueue.Init(nMaxRequest+1)) { return false; } INT32 i; for(i = 0; i \u0026lt; nMaxRequest; i++) { m_oFreeQueue.PushBack(\u0026amp;m_pAllReqArray[i]); } m_pProcReqArray = new SConnReq*[MAX_CONNECTION]; if(NULL == m_pProcReqArray) { CRITICAL(_SDT(\u0026#34;CConnectCtrl::Init, new SConnReq*[%d] failed\u0026#34;), MAX_CONNECTION); return false; } m_pEventsArray = new WSAEVENT[MAX_CONNECTION]; if(NULL == m_pEventsArray) { CRITICAL(_SDT(\u0026#34;CConnectCtrl::Init, new WSAEVENT[%d] failed\u0026#34;), MAX_CONNECTION); return false; } m_pSockArray = new SOCKET[MAX_CONNECTION]; if(NULL == m_pSockArray) { CRITICAL(_SDT(\u0026#34;CConnectCtrl::Init, new SOCKET[%d] failed\u0026#34;), MAX_CONNECTION); return false; } for(i = 0; i \u0026lt; MAX_CONNECTION; i++) { m_pProcReqArray[i] = NULL; m_pEventsArray[i] = WSA_INVALID_EVENT; m_pSockArray[i] = INVALID_SOCKET; } m_dwSockCount = 0; m_bTerminate = false; UINT dwThreadID = 0; m_hThread = (HANDLE)_beginthreadex( NULL, // Security 0, // Stack size - use default ThreadFunc, // Thread fn entry point (void*)this, // Param for thread 0, // Init flag \u0026amp;dwThreadID); // Thread address if(NULL == m_hThread) { CRITICAL(_SDT(\u0026#34;CConnectCtrl::Init, _beginthreadex failed\u0026#34;)); return false; } return true; } 我们在**CConnectCtrl::Init()**处加个断点，然后重启一下程序，看下调用堆栈：\n在CUCODENETWin::_InitComponent()中我们看到整个网络通信框架的初始化，初始化CConnDataMgr、CEventMgr、CConnectCtrl和CIocpCtrl。\nbool CUCODENetWin::_InitComponent() { if (false == CConnDataMgr::Instance()-\u0026gt;Init()) { CRITICAL(_SDT(\u0026#34;CUCODENetWin::_InitComponent, Init CConnDataMgr failed\u0026#34; )); return false; } if(false == CEventMgr::Instance()-\u0026gt;Init(MAX_NET_EVENT)) { CRITICAL(_SDT(\u0026#34;CUCODENetWin::_InitComponent, Init CEventMgr %d failed\u0026#34;), MAX_NET_EVENT); return false; } if(false == CConnectCtrl::Instance()-\u0026gt;Init()) { CRITICAL(_SDT(\u0026#34;CUCODENetWin::_InitComponent, Init CConnectCtrl failed\u0026#34;)); return false; } if(false == CIocpCtrl::Instance()-\u0026gt;Init()) { CRITICAL(_SDT(\u0026#34;CUCODENetWin::_InitComponent, Init CIocpCtrl failed\u0026#34;)); return false; } return true; } 而所有的这些初始化，都是在所谓的CLogNetSessionMgr中初始化的：\n我们最终追溯到最上层的代码中：\n到这里，终于找到家了。\n最后一批介绍的四个线程是完成端口线程，如下图所示：\n精华部分全在其线程函数中：\nvoid CIocpCtrl::OnExecute() { SPerHandleData* pstPerHandleData; SPerIoData* pstPerIoData; CCPSock* poSock; CCpListener* poListener; BOOL bRet; DWORD dwByteTrabsferred; while(true) { pstPerHandleData = NULL; pstPerIoData = NULL; dwByteTrabsferred = 0; bRet = GetQueuedCompletionStatus( m_hCompletionPort, \u0026amp;dwByteTrabsferred, (PULONG_PTR)\u0026amp;pstPerHandleData, (LPOVERLAPPED*)\u0026amp;pstPerIoData, INFINITE); // 检查是否是线程退出 if(NULL == pstPerHandleData) { return; } //当有客户端请求创建连接时 if(pstPerHandleData-\u0026gt;bListen) { // for listen event poListener = (CCpListener*)pstPerHandleData-\u0026gt;ptr; if(NULL != poListener \u0026amp;\u0026amp; NULL != pstPerIoData) { poListener-\u0026gt;OnAccept(bRet, pstPerIoData); //printf(\u0026#34;Accpet Count:%d \\n\u0026#34;, InterlockedIncrement((LONG*)\u0026amp;m_acceptCount) ); } else { SDASSERT(false); } } else { //for non-listen event poSock = (CCPSock*)pstPerHandleData-\u0026gt;ptr; if ( NULL == poSock ) { continue; } if( FALSE == bRet || NULL == pstPerIoData ) { if (::WSAGetLastError()!=ERROR_IO_PENDING) { INFO(_SDT(\u0026#34;[%s:%d]CCPSock connID=%d error %d, close it\u0026#34;), MSG_MARK, poSock-\u0026gt;GetConnectionID(), ::WSAGetLastError()); poSock-\u0026gt;OnClose(); } } else { switch(pstPerIoData-\u0026gt;nOp) { case IOCP_RECV: { poSock-\u0026gt;DecPostRecv(); if (dwByteTrabsferred \u0026gt; 0) { poSock-\u0026gt;OnRecv(dwByteTrabsferred); } else { INFO(_SDT(\u0026#34;[%s:%d]CCPSock connID=%d error %d, close it, socket :%d \u0026#34;), MSG_MARK, poSock-\u0026gt;GetConnectionID(), ::WSAGetLastError(), poSock-\u0026gt;GetSock()); poSock-\u0026gt;OnClose(); } } break; case IOCP_SEND: { poSock-\u0026gt;DecPostSend(); if (dwByteTrabsferred \u0026gt; 0) { poSock-\u0026gt;OnSend(dwByteTrabsferred); } else { INFO(_SDT(\u0026#34;[%s:%d]CCPSock connID=%d error %d, close it\u0026#34;), MSG_MARK, poSock-\u0026gt;GetConnectionID(), ::WSAGetLastError()); poSock-\u0026gt;OnClose(); } } break; case IOCP_CLOSE: { poSock-\u0026gt;OnClose(false); } break; default: ; } } } } } 我始终觉得，**完成端口模型即使不从事Windows开发的linux服务器开发人员应该也要掌握一下。**尤其是linux服务器开发人员需要给客户端人员设计网络通信层的企业。\n我们看下，这四个线程在哪里启动的。\n同样的方法，我们通过搜索，先找到：\nunsigned CIocpCtrl::ThreadFunc(LPVOID pParam) { CIocpCtrl* poCtrl = (CIocpCtrl*)pParam; poCtrl-\u0026gt;m_threadBufPool.CreateThreadBuffer(); poCtrl-\u0026gt;OnExecute(); poCtrl-\u0026gt;m_threadBufPool.ReleaseThreadBuffer(); return 0; } 进而进一步找到：\nbool CIocpCtrl::Init() { //创建IO完成端口句柄 m_hCompletionPort = CreateIoCompletionPort(INVALID_HANDLE_VALUE, NULL, 0, 0); if (m_hCompletionPort == NULL) { CRITICAL(_SDT(\u0026#34;CIocpCtrl::Init, CreateIoCompletionPort failed, Error %d \\n\u0026#34;), ::WSAGetLastError()); return false; } //获取当前服务器的CPU核数 SYSTEM_INFO stSysInfo; GetSystemInfo(\u0026amp;stSysInfo); m_nNumberOfWorkers = stSysInfo.dwNumberOfProcessors * THREAD_PER_CPU; if (g_nThreadNum \u0026gt; 0) { m_nNumberOfWorkers = g_nThreadNum; } m_WorkerArray = new HANDLE[m_nNumberOfWorkers]; for (INT32 i = 0; i \u0026lt; m_nNumberOfWorkers; i++) { m_WorkerArray[i] = INVALID_HANDLE_VALUE; } //创建m_nNumberOfWorkers个线程 UINT dwThreadID = 0; for (INT32 j = 0; j \u0026lt; m_nNumberOfWorkers; j++) { m_WorkerArray[j] = (HANDLE)_beginthreadex( NULL, // Security 0, // Stack size - use default ThreadFunc, // Thread fn entry point (void*)this, // Param for thread 0, // Init flag \u0026amp;dwThreadID); // Thread address if (NULL == m_WorkerArray[j]) { m_nNumberOfWorkers = j; this-\u0026gt;Uninit(); CRITICAL(_SDT(\u0026#34;CIocpCtrl::Init, Create Worker thread failed, Close Handler\\n\u0026#34;)); return false; } } return true; } 然后同样的方法在CIocpCtrl::Init()处加个断点，重新跑下程序，得到如下调用堆栈：\n我们上文中已经介绍过了，这里就不再重复说明：\n通过分析，我们知道LogServer大致的技术框架，业务细节和技术细节，我们在后面的文章中会接着介绍。我们当前的目的是快速把所有的服务的技术框架给熟悉一遍。\n源码下载方法：\n微信搜索公众号**『高性能服务器开发』(中文名：高性能服务器开发)，关注公众号后，在公众号中回复『英雄联盟』**，即可得到下载链接。（喷子和代码贩子请远离！）\n","permalink":"https://haokiu.com/blog/fea618d6d104410cb5df6bc54d9529f2/","summary":"从零学习开源项目系列（四）LogServer源码探究 这是从零学习开源项目的第四篇，上一篇是《从零学习开源项目系列（三） CSBattleMgr服务源码研究》，这篇文章我们一起来学习LogServer，中文意思可能是“日志服务器”。那么这个日志服务器到底做了哪些工作呢？\n我们在Visual Studio中将LogServer设置为启动项，然后按F5将LogServer启动起来，启动成功后显示如下图：\n从上图中，我们可以到大致做了三件事：\n1. 创建一个侦听端口（端口号1234） 2. 连接mysql数据库 3. 初始化日志处理程序 我们来验证一下这三件事的细节。我们再Visual Studio中将程序中断（【调试】菜单-【全部中断】，快捷键Ctrl + Alt + Break）。然后在线程窗口查看这个程序所有的线程，如下图所示：\n所有用红色旗帜标记的线程都是用户线程，我们可以查看这些线程的调用堆栈。我们从最上面的主线程开始：\n切换到main函数，我们可以看出这里是一个循环：\nint main() { auto res = CLogHandler::GetInstance().Init(); if (res) { while(true) { INetSessionMgr::GetInstance()-\u0026gt;Update(); Sleep(1); } } return 0; } 这里一个是初始化动作，一个循环中Update动作，它们具体做了些什么，我们先不管，我们先看其他线程做了什么，再回过头来看这里的代码。\n我们接着看下一个线程的内容：\n从调用堆栈来看，这是一个使用boost::thread启动的线程，这个线程函数代码如下：\nvoid Active::Run() { if (m_BeginInThreadCallback){ m_BeginInThreadCallback(); } while (true){ Consume(); } } 我们先看下这个线程函数做了什么，主要是m_BeginInThreadCallback和**Consume()函数，看下Consume()**函数：\nvoid Active::Consume(){ boost::mutex::scoped_lock lock(m_IOMutex); while(m_Queue.empty()){ m_ConditionVar.wait(lock); } m_SwapQueue.swap(m_Queue); lock.unlock(); while(!m_SwapQueue.empty()){ Buffer* pBuffer = m_SwapQueue.front(); m_SwapQueue.pop(); m_Callback(pBuffer); --m_PendingWorkNum; if (pBuffer){ m_pBufferPool.ReleaseObejct(pBuffer); } } } 这段代码很好理解，先使用条件变量挂起当前线程，条件变量触发后，如果消费者和生产者共有队列m_Queue中有数据，将公用的队列m_Queue临时倒换到本地的一个局部队列m_SwapQueue中，然后挨个处理队列m_SwapQueue中的数据。\n这个线程在哪里创建的呢？通过搜索线程函数，我们找到如下代码：\nvoid Active::Start(){ bool ifHvTimer = !m_ThreadTimer.IsEmpty(); if (ifHvTimer){ m_Thread = boost::thread(\u0026amp;Active::RunWithUpdate, this); } else{ m_Thread = boost::thread(\u0026amp;Active::Run, this); } m_ThreadID = get_native_thread_id(m_Thread); char sThreadName[30]; sprintf(sThreadName, \u0026#34;%s-%d\u0026#34;, \u0026#34;Actor-Run\u0026#34;, GetActorID()); _SetThreadName(m_ThreadID, sThreadName); } 在上面这个函数中添加断点，重启下程序，很快会触发断点，我们看下断点触发时的调用堆栈：","title":"从零学习开源项目系列（四）LogServer源码探究"},{"content":"从零实现一个http服务器 我始终觉得，天生的出身很重要，但后天的努力更加重要，所以如今的很多“科班”往往不如后天努力的“非科班”。所以，我们需要重新给“专业”和“专家”下一个定义：所谓专业，就是别人不搞你搞，这就是你的“专业”；你和别人同时搞，你比别人搞的好，就是“专家”。\n说到http协议和http请求，很多人都知道，但是他们真的“知道”吗？我面试过很多求职者，一说到http协议，他们能滔滔不绝，然后我问他http协议的具体格式是啥样子的？很多人不清楚，不清楚就不清楚吧，他甚至能将http协议的头扯到html文档头部。当我问http GET和POST请求的时候，GET请求是什么形式一般人都可以答出来，但是POST请求的数据放在哪里，服务器如何识别和解析这些POST数据，很多人又说不清道不明了。当说到http服务器时，很多人离开了apache、Nginx这样现成的http server之外，自己实现一个http服务器无从下手，如果实际应用场景有需要使用到一些简单http请求时，使用apache、Nginx这样重量级的http服务器程序实在劳师动众，你可以尝试自己实现一个简单的。\n上面提到的问题，如果您不能清晰地回答出来，可以阅读一下这篇文章，这篇文章在不仅介绍http的格式，同时带领大家从零实现一个简单的http服务器程序。\n一、项目背景 最近很多朋友希望我的flamingo服务器支持http协议，我自己也想做一个微信小程序，小程序通过http协议连接通过我的flamingo服务器进行聊天。flamingo是一个开源的即时通讯软件，目前除了服务器端，还有pc端、android端，后面会支持更多的终端。关于flamingo的介绍您可以参考这里: https://github.com/baloonwj/flamingo，更新日志：https://github.com/baloonwj/flamingo/issues/1。下面是flamingo的部分截图：\n二、http协议介绍 1. http协议是应用层协议，一般建立在tcp协议的基础之上（当然你的实现非要基于udp也是可以的），也就是说http协议的数据收发是通过tcp协议的。\n2. http协议也分为head和body两部分，但是我们一般说的html中的和标记不是http协议的头和身体，它们都是http协议的body部分。\n那么http协议的头到底长啥样子呢？我们来介绍一下http协议吧。\nhttp协议的格式如下：\nGET或POST 请求的url路径（一般是去掉域名的路径） HTTP协议版本号\\r\\n\r字段1名: 字段1值\\r\\n\r字段2名: 字段2值\\r\\n\r…\r字段n名 : 字段n值\\r\\n\r\\r\\n\rhttp协议包体内容 也就是说http协议由两部分组成：包头和包体，包头与包体之间使用一个\\r\\n分割，由于http协议包头的每一行都是以**\\r\\n结束，所以http协议包头一般以\\r\\n\\r\\n**结束。\n举个例子，比如我们在浏览器中请求http://www.hootina.org/index_2013.php这个网址，这是一个典型的GET方法，浏览器组装的http数据包格式如下：\nGET /index_2013.php HTTP/1.1\\r\\n\rHost: www.hootina.org\\r\\n\rConnection: keep-alive\\r\\n\rUpgrade-Insecure-Requests: 1\\r\\n\rUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36\\r\\n\rAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\\r\\n\rAccept-Encoding: gzip, deflate\\r\\n\rAccept-Language: zh-CN,zh;q=0.9,en;q=0.8\\r\\n\r\\r\\n 上面这个请求只有包头没有包体，http协议的包体不是必须的，也就是说GET请求一般没有包体。\n如果GET请求带参数，那么一般是附加在请求的url后面，参数与参数之间使用\u0026amp;分割，例如请求http://www.hootina.org/index_2013.php?param1=value1\u0026amp;param2=value2\u0026amp;param3=value3，我们看下这个请求组装的的http协议包格式：\nGET /index_2013.php?param1=value1\u0026amp;param2=value2\u0026amp;param3=value3 HTTP/1.1\\r\\n\rHost: www.hootina.org\\r\\n\rConnection: keep-alive\\r\\n\rUpgrade-Insecure-Requests: 1\\r\\n\rUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36\\r\\n\rAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\\r\\n\rAccept-Encoding: gzip, deflate\\r\\n\rAccept-Language: zh-CN,zh;q=0.9,en;q=0.8\\r\\n\r\\r\\n 对比一下，你现在知道http协议的GET参数放在协议包的什么位置了吧。\n那么POST的数据放在什么位置呢？我们再12306网站https://kyfw.12306.cn/otn/login/init中登陆输入用户名和密码：\n然后发现浏览器以POST方式组装了http协议包发送了我们的用户名、密码和其他一些信息，组装的包格式如下：\nPOST /passport/web/login HTTP/1.1\\r\\n\rHost: kyfw.12306.cn\\r\\n\rConnection: keep-alive\\r\\n\rContent-Length: 55\\r\\n\rAccept: application/json, text/javascript, */*; q=0.01\\r\\n\rOrigin: https://kyfw.12306.cn\\r\\n\rX-Requested-With: XMLHttpRequest\\r\\n\rUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36\\r\\n\rContent-Type: application/x-www-form-urlencoded; charset=UTF-8\\r\\n\rReferer: https://kyfw.12306.cn/otn/login/init\\r\\n\rAccept-Encoding: gzip, deflate, br\\r\\n\rAccept-Language: zh-CN,zh;q=0.9,en;q=0.8\\r\\n\rCookie: _passport_session=0b2cc5b86eb74bcc976bfa9dfef3e8a20712; _passport_ct=18d19b0930954d76b8057c732ce4cdcat8137; route=6f50b51faa11b987e576cdb301e545c4; RAIL_EXPIRATION=1526718782244; RAIL_DEVICEID=QuRAhOyIWv9lwWEhkq03x5Yl_livKZxx7gW6_-52oTZQda1c4zmVWxdw5Zk79xSDFHe9LJ57F8luYOFp_yahxDXQAOmEV8U1VgXavacuM2UPCFy3knfn42yTsJM3EYOy-hwpsP-jTb2OXevJj5acf40XsvsPDcM7; BIGipServerpool_passport=300745226.50215.0000; BIGipServerotn=1257243146.38945.0000; BIGipServerpassport=1005060362.50215.0000\\r\\n\r\\r\\n\rusername=balloonwj%40qq.com\u0026amp;password=iloveyou\u0026amp;appid=otn 其中username=balloonwj%40qq.com\u0026amp;password=iloveyou\u0026amp;appid=otn就是我们的POST数据，但是大家需要注意的以下几种，不要搞错： **1. 我的用户名是balloonwj@qq.com，到POST里面变成balloonwj%40qq.com，其中%40是@符号的16进制转码形式。这个码表可以参考这里：**http://www.w3school.com.cn/tags/html_ref_urlencode.html\n2.这里有三个变量，分别是username、password和appid，他们之间使用\u0026amp;符号分割，但是请注意的是，这不意味着传递多个POST变量时必须使用\u0026amp;符号分割，只不过这里是浏览器html表单（输入用户名和密码的文本框是html表单的一种）分割多个变量采用的默认方式而已。你可以根据你的需求，来自由定制，只要让服务器知道你的解析方式即可。比如可以这么分割：\n方法一\n1username=balloonwj%40qq.com|password=iloveyou|appid=otn 方法二\nusername:balloonwj%40qq.com\\r\\n\rpassword:iloveyou\\r\\n\rappid:otn\\r\\n 方法三\n1username,password,appid=balloonwj%40qq.com,iloveyou,otn 不管怎么分割，只要你能自己按一定的规则解析出来就可以了。\n不知道你注意到没有，上面的POST数据放在http包体中，服务器如何解析呢？可能你没明白我的意思，看下图：\n如上图所示，由于http协议是基于tcp协议的，tcp协议是流式协议，包头部分可以通过多出的\\r\\n来分界，包体部分如何分界呢？这是协议本身要解决的问题。目前一般有两种方式，第一种方式就是在包头中有个content-Length字段，这个字段的值的大小标识了POST数据的长度，上图中55就是数据username=balloonwj%40qq.com\u0026amp;password=iloveyou\u0026amp;appid=otn的长度，服务器收到一个数据包后，先从包头解析出这个字段的值，再根据这个值去读取相应长度的作为http协议的包体数据。还有一个格式叫做http chunked技术（分块），大致意思是将大包分成小包，具体的详情有兴趣的读者可以自行搜索学习。\n三、http客户端实现 如果您能掌握以上说的http协议，你就可以自己通过代码组装http协议发送http请求了（也是各种开源http库的做法）。我们先简单地介绍一下如何模拟发送http。举个例子，我们要请求http://www.hootina.org/index_2013.php，那么我们可以先通过域名得到ip地址，即通过socket API gethostbyname()得到www.hootina.org的ip地址，由于http服务器默认的端口号是80，有了域名和ip地址之后，我们使用socket API connect()去连接服务器，然后根据上面介绍的格式组装成http协议包，利用socket API send()函数发出去，如果服务器有应答，我们可以使用socket API recv()去接受数据，接下来就是解析数据（先解析包头和包体）。\n四、http服务器实现 我们这里简化一些问题，假设客户端发送的请求都是GET请求，当客户端发来http请求之后，我们拿到http包后就做相应的处理。我们以为我们的flamingo服务器实现一个支持http格式的注册请求为例。假设用户在浏览器里面输入以下网址，就可以实现一个注册功能：\nhttp://120.55.94.78:12345/register.do?p={\u0026ldquo;username\u0026rdquo;: \u0026ldquo;13917043329\u0026rdquo;, \u0026ldquo;nickname\u0026rdquo;: \u0026ldquo;balloon\u0026rdquo;, \u0026ldquo;password\u0026rdquo;: \u0026ldquo;123\u0026rdquo;}\n这里我们的http协议使用的是12345端口号而不是默认的80端口。如何侦听12345端口，这个是非常基础的知识了，这里就不介绍了。当我们收到数据以后：\nvoid HttpSession::OnRead(const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn, Buffer* pBuffer, Timestamp receivTime)\r{\r//LOG_INFO \u0026lt;\u0026lt; \u0026#34;Recv a http request from \u0026#34; \u0026lt;\u0026lt; conn-\u0026gt;peerAddress().toIpPort();\rstring inbuf;\r//先把所有数据都取出来\rinbuf.append(pBuffer-\u0026gt;peek(), pBuffer-\u0026gt;readableBytes());\r//因为一个http包头的数据至少\\r\\n\\r\\n，所以大于4个字符\r//小于等于4个字符，说明数据未收完，退出，等待网络底层接着收取\rif (inbuf.length() \u0026lt;= 4)\rreturn;\r//我们收到的GET请求数据包一般格式如下：\r/*\rGET /register.do?p={%22username%22:%20%2213917043329%22,%20%22nickname%22:%20%22balloon%22,%20%22password%22:%20%22123%22} HTTP/1.1\\r\\n\rHost: 120.55.94.78:12345\\r\\n\rConnection: keep-alive\\r\\n\rUpgrade-Insecure-Requests: 1\\r\\n\rUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36\\r\\n\rAccept-Encoding: gzip, deflate\\r\\n\rAccept-Language: zh-CN, zh; q=0.9, en; q=0.8\\r\\n\r\\r\\n\r*/\r//检查是否以\\r\\n\\r\\n结束，如果不是说明包头不完整，退出\rstring end = inbuf.substr(inbuf.length() - 4);\rif (end != \u0026#34;\\r\\n\\r\\n\u0026#34;)\rreturn;\r//以\\r\\n分割每一行\rstd::vector\u0026lt;string\u0026gt; lines;\rStringUtil::Split(inbuf, lines, \u0026#34;\\r\\n\u0026#34;);\rif (lines.size() \u0026lt; 1 || lines[0].empty())\r{\rconn-\u0026gt;forceClose();\rreturn;\r}\rstd::vector\u0026lt;string\u0026gt; chunk;\rStringUtil::Split(lines[0], chunk, \u0026#34; \u0026#34;);\r//chunk中至少有三个字符串：GET+url+HTTP版本号\rif (chunk.size() \u0026lt; 3)\r{\rconn-\u0026gt;forceClose();\rreturn;\r}\rLOG_INFO \u0026lt;\u0026lt; \u0026#34;url: \u0026#34; \u0026lt;\u0026lt; chunk[1] \u0026lt;\u0026lt; \u0026#34; from \u0026#34; \u0026lt;\u0026lt; conn-\u0026gt;peerAddress().toIpPort();\r//inbuf = /register.do?p={%22username%22:%20%2213917043329%22,%20%22nickname%22:%20%22balloon%22,%20%22password%22:%20%22123%22}\rstd::vector\u0026lt;string\u0026gt; part;\r//通过?分割成前后两端，前面是url，后面是参数\rStringUtil::Split(chunk[1], part, \u0026#34;?\u0026#34;);\r//chunk中至少有三个字符串：GET+url+HTTP版本号\rif (part.size() \u0026lt; 2)\r{\rconn-\u0026gt;forceClose();\rreturn;\r}\rstring url = part[0];\rstring param = part[1].substr(2);\rif (!Process(conn, url, param))\r{\rLOG_ERROR \u0026lt;\u0026lt; \u0026#34;handle http request error, from:\u0026#34; \u0026lt;\u0026lt; conn-\u0026gt;peerAddress().toIpPort() \u0026lt;\u0026lt; \u0026#34;, request: \u0026#34; \u0026lt;\u0026lt; pBuffer-\u0026gt;retrieveAllAsString();\r}\r//短连接，处理完关闭连接\rconn-\u0026gt;forceClose();\r} 代码注释都写的很清楚，我们先利用\\r\\n分割得到每一行，其中第一行的数据是：\nGET /register.do?p={%22username%22:%20%2213917043329%22,%20%22nickname%22:%20%22balloon%22,%20%22password%22:%20%22123%22} HTTP/1.1 其中%22是双引号的url转码形式，%20是空格的url转码形式，然后我们根据空格分成三段，其中第二段就是我们的网址和参数：\n/register.do?p={%22username%22:%20%2213917043329%22,%20%22nickname%22:%20%22balloon%22,%20%22password%22:%20%22123%22} 然后我们根据网址与参数之间的问号将这个分成两段：第一段是网址，第二段是参数：\nbool HttpSession::Process(const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn, const std::string\u0026amp; url, const std::string\u0026amp; param)\r{\rif (url.empty())\rreturn false;\rif (url == \u0026#34;/register.do\u0026#34;)\r{\rOnRegisterResponse(param, conn);\r}\relse if (url == \u0026#34;/login.do\u0026#34;)\r{\rOnLoginResponse(param, conn);\r}\relse if (url == \u0026#34;/getfriendlist.do\u0026#34;)\r{\r}\relse if (url == \u0026#34;/getgroupmembers.do\u0026#34;)\r{\r}\relse\rreturn false;\rreturn true;\r} 然后我们根据url匹配网址，如果是注册请求，会走注册处理逻辑：\nvoid HttpSession::OnRegisterResponse(const std::string\u0026amp; data, const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn)\r{\rstring retData;\rstring decodeData;\rURLEncodeUtil::Decode(data, decodeData);\rBussinessLogic::RegisterUser(decodeData, conn, false, retData);\rif (!retData.empty())\r{\rstd::string response;\rURLEncodeUtil::Encode(retData, response);\rMakeupResponse(retData, response);\rconn-\u0026gt;send(response);\rLOG_INFO \u0026lt;\u0026lt; \u0026#34;Response to client: cmd=msg_type_register\u0026#34; \u0026lt;\u0026lt; \u0026#34;, data=\u0026#34; \u0026lt;\u0026lt; retData \u0026lt;\u0026lt; conn-\u0026gt;peerAddress().toIpPort();;\r}\r} 注册结果放在retData中，为了发给客户端，我们将结果中的特殊字符如双引号转码，如返回结果是：\n{\u0026#34;code\u0026#34;:0, \u0026#34;msg\u0026#34;:\u0026#34;ok\u0026#34;} 会被转码成：\n{%22code%22:0,%20%22msg%22:%22ok%22} 然后，将数据组装成http协议发给客户端，给客户端的应答协议与http请求协议有一点点差别，就是将请求的url路径换成所谓的http响应码，如200表示应答正常返回、404页面不存在。应答协议格式如下：\nGET或POST 响应码 HTTP协议版本号\\r\\n\r字段1名: 字段1值\\r\\n\r字段2名: 字段2值\\r\\n\r…\r字段n名 : 字段n值\\r\\n\r\\r\\n\rhttp协议包体内容 举个例子如：\nHTTP/1.1 200 OK\\r\\n\rContent-Type: text/html\\r\\n\rContent-Length:42\\r\\n\r\\r\\n\r{%22code%22:%200,%20%22msg%22:%20%22ok%22} 注意，包头中的Content-Length长度必须正好是包体{%22code%22:%200,%20%22msg%22:%20%22ok%22}的长度，这里是42。这也符合我们浏览器的返回结果：\n当然，需要注意的是，我们一般说http连接一般是短连接，这里我们也实现了这个功能（看上面的代码：conn-\u0026gt;forceClose();），不管一个http请求是否成功，服务器处理后立马就关闭连接。\n当然，这里还有一些没处理好的地方，如果你仔细观察上面的代码就会发现这个问题，就是不满足一个http包头时的处理，如果某个客户端（不是使用浏览器）通过程序模拟了一个连接请求，但是迟迟不发含有\\r\\n\\r\\n的数据，这路连接将会一直占用。我们可以判断收到的数据长度，防止别有用心的客户端给我们的服务器乱发数据。我们假定，我们能处理的最大url长度是2048，如果用户发送的数据累积不含\\r\\n\\r\\n，且超过2048个，我们认为连接非法，将连接断开。代码修改成如下形式：\nvoid HttpSession::OnRead(const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn, Buffer* pBuffer, Timestamp receivTime)\r{\r//LOG_INFO \u0026lt;\u0026lt; \u0026#34;Recv a http request from \u0026#34; \u0026lt;\u0026lt; conn-\u0026gt;peerAddress().toIpPort();\rstring inbuf;\r//先把所有数据都取出来\rinbuf.append(pBuffer-\u0026gt;peek(), pBuffer-\u0026gt;readableBytes());\r//因为一个http包头的数据至少\\r\\n\\r\\n，所以大于4个字符\r//小于等于4个字符，说明数据未收完，退出，等待网络底层接着收取\rif (inbuf.length() \u0026lt;= 4)\rreturn;\r//我们收到的GET请求数据包一般格式如下：\r/*\rGET /register.do?p={%22username%22:%20%2213917043329%22,%20%22nickname%22:%20%22balloon%22,%20%22password%22:%20%22123%22} HTTP/1.1\\r\\n\rHost: 120.55.94.78:12345\\r\\n\rConnection: keep-alive\\r\\n\rUpgrade-Insecure-Requests: 1\\r\\n\rUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36\\r\\n\rAccept-Encoding: gzip, deflate\\r\\n\rAccept-Language: zh-CN, zh; q=0.9, en; q=0.8\\r\\n\r\\r\\n\r*/\r//检查是否以\\r\\n\\r\\n结束，如果不是说明包头不完整，退出\rstring end = inbuf.substr(inbuf.length() - 4);\rif (end != \u0026#34;\\r\\n\\r\\n\u0026#34;)\rreturn;\r//超过2048个字符，且不含\\r\\n\\r\\n，我们认为是非法请求\relse if (inbuf.length() \u0026gt;= MAX_URL_LENGTH)\r{\rconn-\u0026gt;forceClose();\rreturn;\r}\r//以\\r\\n分割每一行\rstd::vector\u0026lt;string\u0026gt; lines;\rStringUtil::Split(inbuf, lines, \u0026#34;\\r\\n\u0026#34;);\rif (lines.size() \u0026lt; 1 || lines[0].empty())\r{\rconn-\u0026gt;forceClose();\rreturn;\r}\rstd::vector\u0026lt;string\u0026gt; chunk;\rStringUtil::Split(lines[0], chunk, \u0026#34; \u0026#34;);\r//chunk中至少有三个字符串：GET+url+HTTP版本号\rif (chunk.size() \u0026lt; 3)\r{\rconn-\u0026gt;forceClose();\rreturn;\r}\rLOG_INFO \u0026lt;\u0026lt; \u0026#34;url: \u0026#34; \u0026lt;\u0026lt; chunk[1] \u0026lt;\u0026lt; \u0026#34; from \u0026#34; \u0026lt;\u0026lt; conn-\u0026gt;peerAddress().toIpPort();\r//inbuf = /register.do?p={%22username%22:%20%2213917043329%22,%20%22nickname%22:%20%22balloon%22,%20%22password%22:%20%22123%22}\rstd::vector\u0026lt;string\u0026gt; part;\r//通过?分割成前后两端，前面是url，后面是参数\rStringUtil::Split(chunk[1], part, \u0026#34;?\u0026#34;);\r//chunk中至少有三个字符串：GET+url+HTTP版本号\rif (part.size() \u0026lt; 2)\r{\rconn-\u0026gt;forceClose();\rreturn;\r}\rstring url = part[0];\rstring param = part[1].substr(2);\rif (!Process(conn, url, param))\r{\rLOG_ERROR \u0026lt;\u0026lt; \u0026#34;handle http request error, from:\u0026#34; \u0026lt;\u0026lt; conn-\u0026gt;peerAddress().toIpPort() \u0026lt;\u0026lt; \u0026#34;, request: \u0026#34; \u0026lt;\u0026lt; pBuffer-\u0026gt;retrieveAllAsString();\r}\r//短连接，处理完关闭连接\rconn-\u0026gt;forceClose();\r} 但这只能解决发送非法数据的情况，如果一个客户端连上来不给我们发任何数据，这段逻辑就无能为力了。如果不断有客户端这么做，会浪费我们大量的连接资源，所以我们还需要一个定时器去定时检测哪些http连接超过一定时间内没给我们发数据，找到后将连接断开。这又涉及到服务器定时器如何设计了，关于这部分请参考我写的其他文章。\n限于作者经验水平有限，文中难免有错乱之处，欢迎拍砖。另外，关于上面的代码，可以去github上下载，地址是：\nhttps://github.com/baloonwj/flamingo\n","permalink":"https://haokiu.com/blog/2ec66b5605c8455e833f06d2a23fff09/","summary":"从零实现一个http服务器 我始终觉得，天生的出身很重要，但后天的努力更加重要，所以如今的很多“科班”往往不如后天努力的“非科班”。所以，我们需要重新给“专业”和“专家”下一个定义：所谓专业，就是别人不搞你搞，这就是你的“专业”；你和别人同时搞，你比别人搞的好，就是“专家”。\n说到http协议和http请求，很多人都知道，但是他们真的“知道”吗？我面试过很多求职者，一说到http协议，他们能滔滔不绝，然后我问他http协议的具体格式是啥样子的？很多人不清楚，不清楚就不清楚吧，他甚至能将http协议的头扯到html文档头部。当我问http GET和POST请求的时候，GET请求是什么形式一般人都可以答出来，但是POST请求的数据放在哪里，服务器如何识别和解析这些POST数据，很多人又说不清道不明了。当说到http服务器时，很多人离开了apache、Nginx这样现成的http server之外，自己实现一个http服务器无从下手，如果实际应用场景有需要使用到一些简单http请求时，使用apache、Nginx这样重量级的http服务器程序实在劳师动众，你可以尝试自己实现一个简单的。\n上面提到的问题，如果您不能清晰地回答出来，可以阅读一下这篇文章，这篇文章在不仅介绍http的格式，同时带领大家从零实现一个简单的http服务器程序。\n一、项目背景 最近很多朋友希望我的flamingo服务器支持http协议，我自己也想做一个微信小程序，小程序通过http协议连接通过我的flamingo服务器进行聊天。flamingo是一个开源的即时通讯软件，目前除了服务器端，还有pc端、android端，后面会支持更多的终端。关于flamingo的介绍您可以参考这里: https://github.com/baloonwj/flamingo，更新日志：https://github.com/baloonwj/flamingo/issues/1。下面是flamingo的部分截图：\n二、http协议介绍 1. http协议是应用层协议，一般建立在tcp协议的基础之上（当然你的实现非要基于udp也是可以的），也就是说http协议的数据收发是通过tcp协议的。\n2. http协议也分为head和body两部分，但是我们一般说的html中的和标记不是http协议的头和身体，它们都是http协议的body部分。\n那么http协议的头到底长啥样子呢？我们来介绍一下http协议吧。\nhttp协议的格式如下：\nGET或POST 请求的url路径（一般是去掉域名的路径） HTTP协议版本号\\r\\n\r字段1名: 字段1值\\r\\n\r字段2名: 字段2值\\r\\n\r…\r字段n名 : 字段n值\\r\\n\r\\r\\n\rhttp协议包体内容 也就是说http协议由两部分组成：包头和包体，包头与包体之间使用一个\\r\\n分割，由于http协议包头的每一行都是以**\\r\\n结束，所以http协议包头一般以\\r\\n\\r\\n**结束。\n举个例子，比如我们在浏览器中请求http://www.hootina.org/index_2013.php这个网址，这是一个典型的GET方法，浏览器组装的http数据包格式如下：\nGET /index_2013.php HTTP/1.1\\r\\n\rHost: www.hootina.org\\r\\n\rConnection: keep-alive\\r\\n\rUpgrade-Insecure-Requests: 1\\r\\n\rUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36\\r\\n\rAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\\r\\n\rAccept-Encoding: gzip, deflate\\r\\n\rAccept-Language: zh-CN,zh;q=0.9,en;q=0.8\\r\\n\r\\r\\n 上面这个请求只有包头没有包体，http协议的包体不是必须的，也就是说GET请求一般没有包体。\n如果GET请求带参数，那么一般是附加在请求的url后面，参数与参数之间使用\u0026amp;分割，例如请求http://www.hootina.org/index_2013.php?param1=value1\u0026amp;param2=value2\u0026amp;param3=value3，我们看下这个请求组装的的http协议包格式：\nGET /index_2013.php?param1=value1\u0026amp;param2=value2\u0026amp;param3=value3 HTTP/1.1\\r\\n\rHost: www.hootina.org\\r\\n\rConnection: keep-alive\\r\\n\rUpgrade-Insecure-Requests: 1\\r\\n\rUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36\\r\\n\rAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\\r\\n\rAccept-Encoding: gzip, deflate\\r\\n\rAccept-Language: zh-CN,zh;q=0.9,en;q=0.8\\r\\n\r\\r\\n 对比一下，你现在知道http协议的GET参数放在协议包的什么位置了吧。\n那么POST的数据放在什么位置呢？我们再12306网站https://kyfw.12306.cn/otn/login/init中登陆输入用户名和密码：\n然后发现浏览器以POST方式组装了http协议包发送了我们的用户名、密码和其他一些信息，组装的包格式如下：\nPOST /passport/web/login HTTP/1.1\\r\\n\rHost: kyfw.","title":"从零实现一个http服务器"},{"content":"从零实现一个邮件收发客户端 与邮件收发有关的协议有 POP3、SMPT 和 IMAP 等。\nPOP3\nPOP3全称是 Post Office Protocol 3 ，即邮局协议的第 3 个版本，它规定怎样将个人计算机连接到 Internet 的邮件服务器和下载电子邮件的电子协议，它是因特网电子邮件的第一个离线协议标准，POP3 允许用户从服务器上把邮件存储到本地主机（即自己的计算机）上，同时删除保存在邮件服务器上的邮件，而 POP3 服务器则是遵循 POP3 协议的接收邮件服务器，用来接收电子邮件的。\nSMTP\nSMTP 的全称是 Simple Mail Transfer Protocol，即简单邮件传输协议。它是一组用于从源地址到目的地址传输邮件的规范，它帮助每台计算机在发送或中转邮件时找到下一个目的地。SMTP 服务器就是遵循 SMTP 协议的发送邮件服务器。SMTP 需要认证，简单地说就是要求必须在提供了账户名和密码之后才可以登录 SMTP 服务器，这就使得那些垃圾邮件的散播者无可乘之机，使用户避免受到垃圾邮件的侵扰。\nIMAP\nIMAP全称是 Internet Mail Access Protocol，即交互式邮件存取协议，它是跟 POP3 类似邮件访问标准协议之一。不同的是，开启了 IMAP 后，在电子邮件客户端收取的邮件仍然保留在服务器上，同时在客户端上的操作都会反馈到服务器上，如：删除邮件，标记已读等，服务器上的邮件也会做相应的动作。所以无论从浏览器登录邮箱或者客户端软件登录邮箱，看到的邮件以及状态都是一致的。而 POP3 对邮件的操作只会在本地邮件客户端起作用。\n读者如果需要自己编写相关的邮件收发客户端，需要登录对应的邮件服务器开启相应的 POP3/SMTP/IMAP 服务。以 163 邮箱为例：\n请登录 163 邮箱(http://mail.163.com/)，点击页面正上方的“设置”，再点击左侧上“POP3/SMTP/IMAP”，其中“开启 SMTP 服务”是系统默认勾选开启的。读者可勾选图中另两个选项，点击确定，即可开启成功。不勾选图中两个选项，点击确定，可关闭成功。\n网易163免费邮箱相关服务器信息：\n163免费邮客户端设置的POP3、SMTP、IMAP地址\nPOP3、SMTP、IMAP 协议就是我们前面介绍的以指定字符（串）为包的结束标志的协议典型例子。我们来以 SMTP 协议和 POP3 协议为例来讲解一下。\nSMTP 协议 先来介绍 SMTP 协议吧，SMTP 全称是 Simple Mail Transfer Protocol，即简单邮件传输协议，该协议用于发送邮件。\nSMTP 协议的格式：\n关键字 自定义内容\\r\\n “自定义内容”根据“关键字”的类型是否设置，对于使用 SMTP 作为客户端的一方常用的“关键字“如下所示：\n//连接上邮件服务器之后登录服务器之前向服务器发送的问候信息 HELO 自定义问候语\\r\\n //请求登录邮件服务器 AUTH LOGIN\\r\\n base64形式的用户名\\r\\n base64形式的密码\\r\\n //设置发件人邮箱地址 MAIL FROM:发件人地址\\r\\n //设置收件人地址，每次发送可设置一个收件人地址，如果有多个收件地址，要分别设置对应次数 rcpt to:收件人地址\\r\\n //发送邮件正文开始标志 DATA\\r\\n //发送邮件正文，注意邮件正文以.\\r\\n结束 邮件正文\\r\\n.\\r\\n //登出服务器 QUIT\\r\\n 使用 SMTP 作为邮件服务器的一方常用的“关键字“是定义的各种应答码，应答码后面可以带上自己的信息，然后以\\r\\n作为结束，格式如下：\n应答码 自定义消息\\r\\n 常用的应答码含义如下所示：\n211 帮助返回系统状态 214 帮助信息 220 服务准备就绪 221 关闭连接 235 用户验证成功 250 请求操作就绪 251 用户不在本地，转寄到其他路径 334 等待用户输入验证信息 354 开始邮件输入 421 服务不可用 450 操作未执行，邮箱忙 451 操作中止，本地错误 452 操作未执行，存储空间不足 500 命令不可识别或语言错误 501 参数语法错误 502 命令不支技 503 命令顺序错误 504 命令参数不支持 550 操作未执行，邮箱不可用 551 非本地用户 552 中止存储空间不足 553 操作未执行，邮箱名不正确 554 传输失败 更多的 SMTP 协议的细节可以参考相应的 RFC 文档。\n下面我们来看一个具体的使用 SMTP 发送邮件的代码示例，假设我们现在要实现一个邮件报警系统，根据上文的介绍，我们实现一个 SmtpSocket 类来综合常用邮件的功能：\nSmtpSocket.h\n/** * 发送邮件类，SmtpSocket.h * zhangyl 2019.05.11 */ #pragma once #include \u0026lt;string\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026#34;Platform.h\u0026#34; class SmtpSocket final { public: static bool sendMail(const std::string\u0026amp; server, short port, const std::string\u0026amp; from, const std::string\u0026amp; fromPassword, const std::vector\u0026lt;std::string\u0026gt;\u0026amp; to, const std::string\u0026amp; subject, const std::string\u0026amp; mailData); public: SmtpSocket(void); ~SmtpSocket(void); bool isConnected() const { return m_hSocket; } bool connect(const char* pszUrl, short port = 25); bool logon(const char* pszUser, const char* pszPassword); bool setMailFrom(const char* pszFrom); bool setMailTo(const std::vector\u0026lt;std::string\u0026gt;\u0026amp; sendTo); bool send(const std::string\u0026amp; subject, const std::string\u0026amp; mailData); void closeConnection(); void quit();\t//退出 private: /** *\t验证从服务器返回的前三位代码和传递进来的参数是否一样 */ bool checkResponse(const char* recvCode); private:\tbool\tm_bConnected; SOCKET\tm_hSocket; std::string m_strUser; std::string m_strPassword; std::string m_strFrom; std::vector\u0026lt;std::string\u0026gt; m_strTo;; }; SmtpSocket.cpp\n#include \u0026#34;SmtpSocket.h\u0026#34; #include \u0026lt;sstream\u0026gt; #include \u0026lt;time.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026#34;Base64Util.h\u0026#34; #include \u0026#34;Platform.h\u0026#34; bool SmtpSocket::sendMail(const std::string\u0026amp; server, short port, const std::string\u0026amp; from, const std::string\u0026amp; fromPassword, const std::vector\u0026lt;std::string\u0026gt;\u0026amp; to, const std::string\u0026amp; subject, const std::string\u0026amp; mailData) { size_t atSymbolPos = from.find_first_of(\u0026#34;@\u0026#34;); if (atSymbolPos == std::string::npos) return false; std::string strUser = from.substr(0, atSymbolPos); SmtpSocket smtpSocket; //smtp.163.com 25 if (!smtpSocket.connect(server.c_str(), port)) return false; //testformybook 2019hhxxttxs if (!smtpSocket.logon(strUser.c_str(), fromPassword.c_str())) return false; //testformybook@163.com if (!smtpSocket.setMailFrom(from.c_str())) return false; if (!smtpSocket.setMailTo(to)) return false; if (!smtpSocket.send(subject, mailData)) return false; return true; } SmtpSocket::SmtpSocket() : m_bConnected(false), m_hSocket(-1) { } SmtpSocket::~SmtpSocket() { quit(); } bool SmtpSocket::checkResponse(const char* recvCode) { char recvBuffer[1024] = { 0 }; long lResult = 0; lResult = recv(m_hSocket, recvBuffer, 1024, 0); if (lResult == SOCKET_ERROR || lResult \u0026lt; 3) return false; return recvCode[0] == recvBuffer[0] \u0026amp;\u0026amp; \\ recvCode[1] == recvBuffer[1] \u0026amp;\u0026amp; \\ recvCode[2] == recvBuffer[2] ? true : false; } void SmtpSocket::quit() { if (m_hSocket \u0026lt; 0) return; //退出 if (::send(m_hSocket, \u0026#34;QUIT\\r\\n\u0026#34;, strlen(\u0026#34;QUIT\\r\\n\u0026#34;), 0) == SOCKET_ERROR) { closeConnection(); return; } if (!checkResponse(\u0026#34;221\u0026#34;)) return; } bool SmtpSocket::logon(const char* pszUser, const char* pszPassword) { if (m_hSocket \u0026lt; 0) return false; //发送\u0026#34;AUTH LOGIN\u0026#34; if (::send(m_hSocket, \u0026#34;AUTH LOGIN\\r\\n\u0026#34;, strlen(\u0026#34;AUTH LOGIN\\r\\n\u0026#34;), 0) == SOCKET_ERROR) return false; if (!checkResponse(\u0026#34;334\u0026#34;)) return false; //发送经base64编码的用户名 char szUserEncoded[64] = { 0 }; Base64Util::encode(szUserEncoded, pszUser, strlen(pszUser), \u0026#39;=\u0026#39;, 64); strncat(szUserEncoded, \u0026#34;\\r\\n\u0026#34;, 64); //MailLogNormalA(\u0026#34;[SmtpSocket::Logon] Logon [User:%s].\u0026#34;, lpUser); if (::send(m_hSocket, szUserEncoded, strlen(szUserEncoded), 0) == SOCKET_ERROR) return false; if (!checkResponse(\u0026#34;334\u0026#34;)) return false; //发送经base64编码的密码 //验证密码 char szPwdEncoded[64] = { 0 }; Base64Util::encode(szPwdEncoded, pszPassword, strlen(pszPassword), \u0026#39;=\u0026#39;, 64); strncat(szPwdEncoded, \u0026#34;\\r\\n\u0026#34;, 64); //MailLogNormalA(\u0026#34;[SmtpSocket::Logon] Logon [User:%s] [Pass:*****].\u0026#34;, lpUser); if (::send(m_hSocket, szPwdEncoded, strlen(szPwdEncoded), 0) == SOCKET_ERROR) return false; if (!checkResponse(\u0026#34;235\u0026#34;)) return false; m_strUser = pszUser; m_strPassword = pszPassword; return true; } void SmtpSocket::closeConnection() { if (m_hSocket \u0026gt;= 0) { closesocket(m_hSocket); m_hSocket = -1; m_bConnected = false; } } bool SmtpSocket::connect(const char* pszUrl, short port/* = 25*/) { //MailLogNormalA(\u0026#34;[SmtpSocket::Connect] Start connect [%s:%d].\u0026#34;, lpUrl, lPort); struct sockaddr_in server = { 0 }; struct hostent* pHostent = NULL; unsigned int addr = 0; closeConnection(); m_hSocket = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP); if (m_hSocket \u0026lt; 0) return false; long tmSend(15 * 1000L), tmRecv(15 * 1000L), noDelay(1); setsockopt(m_hSocket, IPPROTO_TCP, TCP_NODELAY, (char*)\u0026amp; noDelay, sizeof(long)); setsockopt(m_hSocket, SOL_SOCKET, SO_SNDTIMEO, (char*)\u0026amp; tmSend, sizeof(long)); setsockopt(m_hSocket, SOL_SOCKET, SO_RCVTIMEO, (char*)\u0026amp; tmRecv, sizeof(long)); if (inet_addr(pszUrl) == INADDR_NONE) { pHostent = gethostbyname(pszUrl); } else { addr = inet_addr(pszUrl); pHostent = gethostbyaddr((char*)\u0026amp; addr, sizeof(addr), AF_INET); } if (!pHostent) return false; server.sin_family = AF_INET; server.sin_port = htons((u_short)port); server.sin_addr.s_addr = *((unsigned long*)pHostent-\u0026gt;h_addr); if (::connect(m_hSocket, (struct sockaddr*) \u0026amp; server, sizeof(server)) == SOCKET_ERROR) return false; if (!checkResponse(\u0026#34;220\u0026#34;)) return false; //向服务器发送\u0026#34;HELO \u0026#34;+服务器名 //string strTmp=\u0026#34;HELO \u0026#34;+SmtpAddr+\u0026#34;\\r\\n\u0026#34;; char szSend[256] = { 0 }; snprintf(szSend, sizeof(szSend), \u0026#34;HELO %s\\r\\n\u0026#34;, pszUrl); if (::send(m_hSocket, szSend, strlen(szSend), 0) == SOCKET_ERROR) return false; if (!checkResponse(\u0026#34;250\u0026#34;)) return false; m_bConnected = true; return true; } bool SmtpSocket::setMailFrom(const char* pszFrom) { if (m_hSocket \u0026lt; 0) return false; char szSend[256] = { 0 }; snprintf(szSend, sizeof(szSend), \u0026#34;MAIL FROM:\u0026lt;%s\u0026gt;\\r\\n\u0026#34;, pszFrom); if (::send(m_hSocket, szSend, strlen(szSend), 0) == SOCKET_ERROR) return false; if (!checkResponse(\u0026#34;250\u0026#34;)) return false; m_strFrom = pszFrom; return true; } bool SmtpSocket::setMailTo(const std::vector\u0026lt;std::string\u0026gt;\u0026amp; sendTo) { if (m_hSocket \u0026lt; 0) return false; char szSend[256] = { 0 }; for (const auto\u0026amp; iter : sendTo) { snprintf(szSend, sizeof(szSend), \u0026#34;rcpt to: \u0026lt;%s\u0026gt;\\r\\n\u0026#34;, iter.c_str()); if (::send(m_hSocket, szSend, strlen(szSend), 0) == SOCKET_ERROR) return false; if (!checkResponse(\u0026#34;250\u0026#34;)) return false; } m_strTo = sendTo; return true; } bool SmtpSocket::send(const std::string\u0026amp; subject, const std::string\u0026amp; mailData) { if (m_hSocket \u0026lt; 0) return false; std::ostringstream osContent; //注意：邮件正文内容与其他附属字样之间一定要空一行 osContent \u0026lt;\u0026lt; \u0026#34;Date: \u0026#34; \u0026lt;\u0026lt; time(nullptr) \u0026lt;\u0026lt; \u0026#34;\\r\\n\u0026#34;; osContent \u0026lt;\u0026lt; \u0026#34;from: \u0026#34; \u0026lt;\u0026lt; m_strFrom \u0026lt;\u0026lt; \u0026#34;\\r\\n\u0026#34;; osContent \u0026lt;\u0026lt; \u0026#34;to: \u0026#34;; for (const auto\u0026amp; iter : m_strTo) { osContent \u0026lt;\u0026lt; iter \u0026lt;\u0026lt; \u0026#34;;\u0026#34;; } osContent \u0026lt;\u0026lt; \u0026#34;\\r\\n\u0026#34;; osContent \u0026lt;\u0026lt; \u0026#34;subject: \u0026#34; \u0026lt;\u0026lt; subject \u0026lt;\u0026lt; \u0026#34;\\r\\n\u0026#34;; osContent \u0026lt;\u0026lt; \u0026#34;Content-Type: text/plain; charset=UTF-8\\r\\n\u0026#34;; osContent \u0026lt;\u0026lt; \u0026#34;Content-Transfer-Encoding: quoted-printable\\r\\n\\r\\n\u0026#34;; osContent \u0026lt;\u0026lt; mailData \u0026lt;\u0026lt; \u0026#34;\\r\\n.\\r\\n\u0026#34;; std::string data = osContent.str(); const char* lpSendBuffer = data.c_str(); //发送\u0026#34;DATA\\r\\n\u0026#34; if (::send(m_hSocket, \u0026#34;DATA\\r\\n\u0026#34;, strlen(\u0026#34;DATA\\r\\n\u0026#34;), 0) == SOCKET_ERROR) return false; if (!checkResponse(\u0026#34;354\u0026#34;)) return false; long dwSend = 0; long dwOffset = 0; long lTotal = data.length(); long lResult = 0; const long SEND_MAX_SIZE = 1024 * 100000; while ((long)dwOffset \u0026lt; lTotal) { if (lTotal - dwOffset \u0026gt; SEND_MAX_SIZE) dwSend = SEND_MAX_SIZE; else dwSend = lTotal - dwOffset; lResult = ::send(m_hSocket, lpSendBuffer + dwOffset, dwSend, 0); if (lResult == SOCKET_ERROR) return false; dwOffset += lResult; } if (!checkResponse(\u0026#34;250\u0026#34;)) return false; return true; } 然后我们使用另外一个类 MailMonitor 对 SmtpSocket 对象的功能进行高层抽象：\nMailMonitor.h\n/** * 邮件监控线程, MailMonitor.h * zhangyl 2019.05.11 */ #pragma once #include \u0026lt;string\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;list\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;mutex\u0026gt; #include \u0026lt;condition_variable\u0026gt; #include \u0026lt;thread\u0026gt; struct MailItem { std::string subject; std::string content; }; class MailMonitor final { public: static MailMonitor\u0026amp; getInstance(); private: MailMonitor() = default; ~MailMonitor() = default; MailMonitor(const MailMonitor \u0026amp; rhs) = delete; MailMonitor\u0026amp; operator=(const MailMonitor \u0026amp; rhs) = delete; public: bool initMonitorMailInfo(const std::string\u0026amp; servername, const std::string\u0026amp; mailserver, short mailport, const std::string\u0026amp; mailfrom, const std::string\u0026amp; mailfromPassword, const std::string\u0026amp; mailto); void uninit(); void wait(); void run(); bool alert(const std::string\u0026amp; subject, const std::string\u0026amp; content); private: void alertThread(); void split(const std::string\u0026amp; str, std::vector\u0026lt;std::string\u0026gt;\u0026amp; v, const char* delimiter = \u0026#34;|\u0026#34;); private: std::string m_strMailName; //用于标识是哪一台服务器发送的邮件 std::string m_strMailServer; short m_nMailPort; std::string m_strFrom; std::string m_strFromPassword; std::vector\u0026lt;std::string\u0026gt; m_strMailTo; std::list\u0026lt;MailItem\u0026gt; m_listMailItemsToSend; //待写入的日志 std::shared_ptr\u0026lt;std::thread\u0026gt; m_spMailAlertThread; std::mutex m_mutexAlert; std::condition_variable m_cvAlert; bool m_bExit; //退出标志 bool m_bRunning; //运行标志 }; MailMonitor.cpp\n#include \u0026#34;MailMonitor.h\u0026#34; #include \u0026lt;functional\u0026gt; #include \u0026lt;sstream\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026#34;SmtpSocket.h\u0026#34; MailMonitor\u0026amp; MailMonitor::getInstance() { static MailMonitor instance; return instance; } bool MailMonitor::initMonitorMailInfo(const std::string\u0026amp; servername, const std::string\u0026amp; mailserver, short mailport, const std::string\u0026amp; mailfrom, const std::string\u0026amp; mailfromPassword, const std::string\u0026amp; mailto) { if (servername.empty() || mailserver.empty() || mailport \u0026lt; 0 || mailfrom.empty() || mailfromPassword.empty() || mailto.empty()) { std::cout \u0026lt;\u0026lt; \u0026#34;Mail account info is not config, not start MailAlert\u0026#34; \u0026lt;\u0026lt; std::endl; return false; } m_strMailName = servername; m_strMailServer = mailserver; m_nMailPort = mailport; m_strFrom = mailfrom; m_strFromPassword = mailfromPassword; split(mailto, m_strMailTo, \u0026#34;;\u0026#34;); std::ostringstream osSubject; osSubject \u0026lt;\u0026lt; \u0026#34;[\u0026#34; \u0026lt;\u0026lt; m_strMailName \u0026lt;\u0026lt; \u0026#34;]\u0026#34;; SmtpSocket::sendMail(m_strMailServer, m_nMailPort, m_strFrom, m_strFromPassword, m_strMailTo, osSubject.str(), \u0026#34;You have started Mail Alert System.\u0026#34;); return true; } void MailMonitor::uninit() { m_bExit = true; m_cvAlert.notify_one(); if (m_spMailAlertThread-\u0026gt;joinable()) m_spMailAlertThread-\u0026gt;join(); } void MailMonitor::wait() { if (m_spMailAlertThread-\u0026gt;joinable()) m_spMailAlertThread-\u0026gt;join(); } void MailMonitor::run() { m_spMailAlertThread.reset(new std::thread(std::bind(\u0026amp;MailMonitor::alertThread, this))); } void MailMonitor::alertThread() { m_bRunning = true; while (true) { MailItem mailItem; { std::unique_lock\u0026lt;std::mutex\u0026gt; guard(m_mutexAlert); while (m_listMailItemsToSend.empty()) { if (m_bExit) return; m_cvAlert.wait(guard); } mailItem = m_listMailItemsToSend.front(); m_listMailItemsToSend.pop_front(); } std::ostringstream osSubject; osSubject \u0026lt;\u0026lt; \u0026#34;[\u0026#34; \u0026lt;\u0026lt; m_strMailName \u0026lt;\u0026lt; \u0026#34;]\u0026#34; \u0026lt;\u0026lt; mailItem.subject; SmtpSocket::sendMail(m_strMailServer, m_nMailPort, m_strFrom, m_strFromPassword, m_strMailTo, osSubject.str(), mailItem.content); }// end outer-while-loop m_bRunning = false; } bool MailMonitor::alert(const std::string\u0026amp; subject, const std::string\u0026amp; content) { if (m_strMailServer.empty() || m_nMailPort \u0026lt; 0 || m_strFrom.empty() || m_strFromPassword.empty() || m_strMailTo.empty()) return false; MailItem mailItem; mailItem.subject = subject; mailItem.content = content; { std::lock_guard\u0026lt;std::mutex\u0026gt; lock_guard(m_mutexAlert); m_listMailItemsToSend.push_back(mailItem); m_cvAlert.notify_one(); } return true; } void MailMonitor::split(const std::string\u0026amp; str, std::vector\u0026lt;std::string\u0026gt;\u0026amp; v, const char* delimiter/* = \u0026#34;|\u0026#34;*/) { if (delimiter == NULL || str.empty()) return; std::string buf(str); size_t pos = std::string::npos; std::string substr; int delimiterlength = strlen(delimiter); while (true) { pos = buf.find(delimiter); if (pos != std::string::npos) { substr = buf.substr(0, pos); if (!substr.empty()) v.push_back(substr); buf = buf.substr(pos + delimiterlength); } else { if (!buf.empty()) v.push_back(buf); break; } } } 程序中另外用到的两个辅助类文件如下：\nBase64Util.h\n#pragma once class Base64Util final { private: Base64Util() = delete; ~Base64Util() = delete; Base64Util(const Base64Util\u0026amp; rhs) = delete; Base64Util\u0026amp; operator=(const Base64Util\u0026amp; rhs) = delete; public: static int encode(char* pDest, const char* pSource, int lenSource, char chMask, int maxDest); static int decode(char* pDest, const char* pSource, int lenSource, char chMask, int maxDest); static bool check(char* lpString); }; Base64Util.cpp\n#include \u0026#34;Base64Util.h\u0026#34; ///////////////////////////////////////////////////////////////////////////////////////////////// static const char __DeBase64Tab__[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 62, // \u0026#39;+\u0026#39; 0, 0, 0, 63, // \u0026#39;/\u0026#39; 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, // \u0026#39;0\u0026#39;-\u0026#39;9\u0026#39; 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, // \u0026#39;A\u0026#39;-\u0026#39;Z\u0026#39; 0, 0, 0, 0, 0, 0, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, // \u0026#39;a\u0026#39;-\u0026#39;z\u0026#39; }; static const char __EnBase64Tab__[] = { \u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\u0026#34; }; int Base64Util::encode(char* pDest, const char* pSource, int lenSource, char chMask, int maxDest) { char c1, c2, c3; int i = 0, lenDest(0), lDiv(lenSource / 3), lMod(lenSource % 3); for (; i \u0026lt; lDiv; ++i, lenDest += 4) { if (lenDest + 4 \u0026gt;= maxDest) return 0; c1 = *pSource++; c2 = *pSource++; c3 = *pSource++; *pDest++ = __EnBase64Tab__[c1 \u0026gt;\u0026gt; 2]; *pDest++ = __EnBase64Tab__[((c1 \u0026lt;\u0026lt; 4) | (c2 \u0026gt;\u0026gt; 4)) \u0026amp; 0X3F]; *pDest++ = __EnBase64Tab__[((c2 \u0026lt;\u0026lt; 2) | (c3 \u0026gt;\u0026gt; 6)) \u0026amp; 0X3F]; *pDest++ = __EnBase64Tab__[c3 \u0026amp; 0X3F]; } if (lMod == 1) { if (lenDest + 4 \u0026gt;= maxDest) return(0); c1 = *pSource++; *pDest++ = __EnBase64Tab__[(c1 \u0026amp; 0XFC) \u0026gt;\u0026gt; 2]; *pDest++ = __EnBase64Tab__[((c1 \u0026amp; 0X03) \u0026lt;\u0026lt; 4)]; *pDest++ = chMask; *pDest++ = chMask; lenDest += 4; } else if (lMod == 2) { if (lenDest + 4 \u0026gt;= maxDest) return(0); c1 = *pSource++; c2 = *pSource++; *pDest++ = __EnBase64Tab__[(c1 \u0026amp; 0XFC) \u0026gt;\u0026gt; 2]; *pDest++ = __EnBase64Tab__[((c1 \u0026amp; 0X03) \u0026lt;\u0026lt; 4) | ((c2 \u0026amp; 0XF0) \u0026gt;\u0026gt; 4)]; *pDest++ = __EnBase64Tab__[((c2 \u0026amp; 0X0F) \u0026lt;\u0026lt; 2)]; *pDest++ = chMask; lenDest += 4; } *pDest = 0; return(lenDest); } int Base64Util::decode(char* pDest, const char* pSource, int lenSource, char chMask, int maxDest) { int lenDest = 0, nValue = 0, i = 0; for (; i \u0026lt; lenSource; i += 4) { nValue = __DeBase64Tab__[(int)(*pSource)] \u0026lt;\u0026lt; 18; pSource++; nValue += __DeBase64Tab__[(int)*pSource] \u0026lt;\u0026lt; 12; pSource++; if (++lenDest \u0026gt;= maxDest) break; *pDest++ = char((nValue \u0026amp; 0X00FF0000) \u0026gt;\u0026gt; 16); if (*pSource != chMask) { nValue += __DeBase64Tab__[(int)*pSource] \u0026lt;\u0026lt; 6; pSource++; if (++lenDest \u0026gt;= maxDest) break; *pDest++ = (nValue \u0026amp; 0X0000FF00) \u0026gt;\u0026gt; 8; if (*pSource != chMask) { nValue += __DeBase64Tab__[(int)*pSource]; pSource++; if (++lenDest \u0026gt;= maxDest) break; *pDest++ = nValue \u0026amp; 0X000000FF; } } } *pDest = 0; return(lenDest); } bool Base64Util::check(char* lpString) { for (; *lpString; ++lpString) { switch (*lpString) { case\t\u0026#39;+\u0026#39;: *lpString = \u0026#39;@\u0026#39;;\tbreak; case\t\u0026#39;@\u0026#39;: *lpString = \u0026#39;+\u0026#39;;\tbreak; case\t\u0026#39;=\u0026#39;: *lpString = \u0026#39;$\u0026#39;;\tbreak; case\t\u0026#39;$\u0026#39;: *lpString = \u0026#39;=\u0026#39;;\tbreak; case\t\u0026#39;/\u0026#39;: *lpString = \u0026#39;#\u0026#39;;\tbreak; case\t\u0026#39;#\u0026#39;: *lpString = \u0026#39;/\u0026#39;;\tbreak; default: if (*lpString \u0026gt;= \u0026#39;A\u0026#39; \u0026amp;\u0026amp; *lpString \u0026lt;= \u0026#39;Z\u0026#39;) * lpString = *lpString - \u0026#39;A\u0026#39; + \u0026#39;a\u0026#39;; else if (*lpString \u0026gt;= \u0026#39;a\u0026#39; \u0026amp;\u0026amp; *lpString \u0026lt;= \u0026#39;z\u0026#39;) * lpString = *lpString - \u0026#39;a\u0026#39; + \u0026#39;A\u0026#39;; else if (*lpString \u0026gt;= \u0026#39;0\u0026#39; \u0026amp;\u0026amp; *lpString \u0026lt;= \u0026#39;4\u0026#39;) * lpString = *lpString - \u0026#39;0\u0026#39; + \u0026#39;5\u0026#39;; else if (*lpString \u0026gt;= \u0026#39;5\u0026#39; \u0026amp;\u0026amp; *lpString \u0026lt;= \u0026#39;9\u0026#39;) * lpString = *lpString - \u0026#39;5\u0026#39; + \u0026#39;0\u0026#39;; else return false; } } return true; } Platform.h\n#pragma once #include \u0026lt;stdint.h\u0026gt; #if defined(__GNUC__) #pragma GCC diagnostic push #pragma GCC diagnostic ignored \u0026#34;-Wdeprecated-declarations\u0026#34; #elif defined(_MSC_VER) #pragma warning(disable : 4996) #endif #ifdef WIN32 #pragma comment(lib, \u0026#34;Ws2_32.lib\u0026#34;) #pragma comment(lib, \u0026#34;Shlwapi.lib\u0026#34;) //remove warning C4996 on Windows //#define _CRT_SECURE_NO_WARNINGS typedef int socklen_t; //typedef uint64_t ssize_t; typedef unsigned int in_addr_t; //Windows 上没有这些结构的定义，为了移植方便，手动定义这些结构 #define XPOLLIN 1 #define XPOLLPRI 2 #define XPOLLOUT 4 #define XPOLLERR 8 #define XPOLLHUP 16 #define XPOLLNVAL 32 #define XPOLLRDHUP 8192 #define XEPOLL_CTL_ADD 1 #define XEPOLL_CTL_DEL 2 #define XEPOLL_CTL_MOD 3 #pragma pack(push, 1) typedef union epoll_data { void* ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; struct epoll_event { uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; #pragma pack(pop) #include \u0026lt;winsock2.h\u0026gt; #include \u0026lt;ws2tcpip.h\u0026gt; #include \u0026lt;Windows.h\u0026gt; #include \u0026lt;Ws2ipdef.h\u0026gt; #include \u0026lt;io.h\u0026gt; //_pipe #include \u0026lt;fcntl.h\u0026gt; //for O_BINARY #include \u0026lt;shlwapi.h\u0026gt; class NetworkInitializer { public: NetworkInitializer(); ~NetworkInitializer(); }; #else typedef int SOCKET; #define SOCKET_ERROR -1 #define closesocket(s) close(s) #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;netinet/tcp.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdint.h\u0026gt; #include \u0026lt;endian.h\u0026gt; #include \u0026lt;poll.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;inttypes.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;dirent.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;sys/select.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/eventfd.h\u0026gt; #include \u0026lt;sys/stat.h\u0026gt; #include \u0026lt;sys/uio.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; #include \u0026lt;sys/syscall.h\u0026gt; //for ubuntu readv not found #ifdef __UBUNTU #include \u0026lt;sys/uio.h\u0026gt; #endif #define XPOLLIN POLLIN #define XPOLLPRI POLLPRI #define XPOLLOUT POLLOUT #define XPOLLERR POLLERR #define XPOLLHUP POLLHUP #define XPOLLNVAL POLLNVAL #define XPOLLRDHUP POLLRDHUP #define XEPOLL_CTL_ADD EPOLL_CTL_ADD #define XEPOLL_CTL_DEL EPOLL_CTL_DEL #define XEPOLL_CTL_MOD EPOLL_CTL_MOD //Linux下没有这两个函数，定义之 #define ntohll(x) be64toh(x) #define htonll(x) htobe64(x) #endif Platform.cpp\n#include \u0026#34;Platform.h\u0026#34; #ifdef WIN32 NetworkInitializer::NetworkInitializer() { WORD wVersionRequested = MAKEWORD(2, 2); WSADATA wsaData; ::WSAStartup(wVersionRequested, \u0026amp;wsaData); } NetworkInitializer::~NetworkInitializer() { ::WSACleanup(); } #endif 我们在 main 函数模拟产生一条新的报警邮件：\nmain.cpp\n/** * 邮件报警demo * zhangyl 2020.04.09 **/ #include \u0026lt;iostream\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026#34;Platform.h\u0026#34; #include \u0026#34;MailMonitor.h\u0026#34; //Winsock网络库初始化 #ifdef WIN32 NetworkInitializer windowsNetworkInitializer; #endif #ifndef WIN32 void prog_exit(int signo) { std::cout \u0026lt;\u0026lt; \u0026#34;program recv signal [\u0026#34; \u0026lt;\u0026lt; signo \u0026lt;\u0026lt; \u0026#34;] to exit.\u0026#34; \u0026lt;\u0026lt; std::endl; //停止邮件发送服务 MailMonitor::getInstance().uninit(); } #endif const std::string servername = \u0026#34;MailAlertSysem\u0026#34;; const std::string mailserver = \u0026#34;smtp.163.com\u0026#34;; const short mailport = 25; const std::string mailuser = \u0026#34;testformybook@163.com\u0026#34;; const std::string mailpassword = \u0026#34;2019hhxxttxs\u0026#34;; const std::string mailto = \u0026#34;balloonwj@qq.com;analogous_love@qq.com\u0026#34;; int main(int argc, char* argv[]) { #ifndef WIN32 //设置信号处理 signal(SIGCHLD, SIG_DFL); signal(SIGPIPE, SIG_IGN); signal(SIGINT, prog_exit); signal(SIGTERM, prog_exit); #endif bool bInitSuccess = MailMonitor::getInstance().initMonitorMailInfo(servername, mailserver, mailport, mailuser, mailpassword, mailto); if (bInitSuccess) MailMonitor::getInstance().run(); const std::string subject = \u0026#34;Alert Mail\u0026#34;; const std::string content = \u0026#34;This is an alert mail from \u0026#34; + mailuser; MailMonitor::getInstance().alert(subject, content); //等待报警邮件线程退出 MailMonitor::getInstance().wait(); return 0; } 上述代码使用了 163 邮箱账号 testformybook@163.com 给 QQ 邮箱账户 balloonwj@qq.com 和 analogous_love@qq.com 分别发送邮件，发送给邮件的函数是 MailMonitor::alert() 函数，实际发送邮件的函数是 SmtpSocket::send() 函数。\n无论在 Windows 或者 Linux 上编译运行程序，我们的两个邮箱都会分别收到两封邮件，如下图所示：\n产生第一封邮件的原因是我们在 main 函数中调用 MailMonitor::getInstance().initMonitorMailInfo() 初始化邮箱服务器名、地址、端口号、用户名和密码时，MailMonitor::initMonitorMailInfo() 函数内部会调用 SmtpSocket::sendMail() 函数发送一封邮件通知指定联系人邮件报警系统已经启动：\nbool MailMonitor::initMonitorMailInfo(const std::string\u0026amp; servername, const std::string\u0026amp; mailserver, short mailport, const std::string\u0026amp; mailfrom, const std::string\u0026amp; mailfromPassword, const std::string\u0026amp; mailto) { //...无关代码省略... SmtpSocket::sendMail(m_strMailServer, m_nMailPort, m_strFrom, m_strFromPassword, m_strMailTo, osSubject.str(), \u0026#34;You have started Mail Alert System.\u0026#34;); return true; } 产生第二封邮件则是我们在 main 函数中主动调用产生报警邮件的函数：\nconst std::string subject = \u0026#34;Alert Mail\u0026#34;; const std::string content = \u0026#34;This is an alert mail from \u0026#34; + mailuser; MailMonitor::getInstance().alert(subject, content); 我们以第一封邮件为例来说明整个邮件发送过程中，我们的程序（客户端）与 163 邮件服务器之间的协议数据的交换内容，核心的邮件发送功能在 SmtpSocket::sendMail() 函数中：\nbool SmtpSocket::sendMail(const std::string\u0026amp; server, short port, const std::string\u0026amp; from, const std::string\u0026amp; fromPassword, const std::vector\u0026lt;std::string\u0026gt;\u0026amp; to, const std::string\u0026amp; subject, const std::string\u0026amp; mailData) { size_t atSymbolPos = from.find_first_of(\u0026#34;@\u0026#34;); if (atSymbolPos == std::string::npos) return false; std::string strUser = from.substr(0, atSymbolPos); SmtpSocket smtpSocket; //smtp.163.com 25 if (!smtpSocket.connect(server.c_str(), port)) return false; //testformybook 2019hhxxttxs if (!smtpSocket.logon(strUser.c_str(), fromPassword.c_str())) return false; //testformybook@163.com if (!smtpSocket.setMailFrom(from.c_str())) return false; if (!smtpSocket.setMailTo(to)) return false; if (!smtpSocket.send(subject, mailData)) return false; return true; } 这个函数先创建 socket，再使用邮箱的地址和端口后去连接服务器（smtpSocket.connect() 函数内部额外做了一步将域名解析成 ip 地址的工作），连接成功后开始和服务器端进行数据交换：\nclient: 尝试连接服务器 client: 连接成功 server: 220\\r\\n client: helo自定义问候语\\r\\n server: 250\\r\\n client: AUTH LOGIN\\r\\n server: 334\\r\\n client: base64编码后的用户名\\r\\n server: 334\\r\\n client: base64编码后的密码\\r\\n server: 235\\r\\n client: MAIL FROM:\u0026lt;发件人地址\u0026gt;\\r\\n server: 250\\r\\n client: rcpt to:\u0026lt;收件人地址1\u0026gt;\\r\\n server: 250\\r\\n client: rcpt to:\u0026lt;收件人地址2\u0026gt;\\r\\n server: 250\\r\\n client: DATA\\r\\n server: 354\\r\\n client: 邮件正文\\r\\n.\\r\\n server: 250\\r\\n client：QUIT\\r\\n server：221\\r\\n 我们将上述过程绘制成如下示意图：\n最终邮件就发出去了，这里我们模拟了客户端使用 smtp 协议给服务器端发送邮件，我们自己实现服务器端接收客户端发送的邮件请求也是一样的道理。这就是 SMTP 协议的格式，SMTP 协议是以特定标记作为分隔符的协议格式典型。\n读者可以在 Windows 上或者 Linux 主机上测试上述程序，如果读者在阿里云这样的云主机上测试，阿里云等云主机为了避免在网络上产生大量垃圾邮件默认是禁止发往其他服务器的 25 号端口的数据的，读者需要申请解除该端口限制，或者将邮件服务器的 25 端口改成其他端口（一般改成 465 端口）。\n完整的发送邮件编解码 SMTP 协议示例代码请在【**高性能服务器开发】**公众号后台回复关键字“SMTP”。\n上文我们介绍了 SMTP 协议常用的协议命令，SMTP 协议支持的完整命令列表读者可以参考 rfc5321 文档：https://tools.ietf.org/html/rfc5321 。\nPOP3 协议 我们再来看下 POP3 协议：\nclient：连接邮箱pop服务器，连接成功 server：+OK Welcome to coremail Mail Pop3 Server (163coms[10774b260cc7a37d26d71b52404dcf5cs])\\r\\n client：USER 用户名\\r\\n server：+OK core mail client：PASS 密码\\r\\n server：+OK 202 message(s) [3441786 byte(s)]\\r\\n client：LIST\\r\\n server：+OK 5 30284\\r\\n1 8284\\r\\n2 11032\\r\\n3 2989\\r\\n4 3871\\r\\n5 4108\\r\\n.\\r\\n client：RETR 100\\r\\n server： +OK 4108 octets\\r\\n Received: from sonic310-21.consmr.mail.gq1.yahoo.com (unknown [98.137.69.147]) by mx29 (Coremail) with SMTP id T8CowABHlztmml5erAoHAQ--.23443S3; Wed, 04 Mar 2020 01:56:57 +0800 (CST)\\r\\n DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=yahoo.com; s=s2048; t=1583258213; bh=ABL3sF+YL/syl+mwknwxiAlvKPRNYq4AYTujNrPA86g=; h=Date:From:Reply-To:Subject:References:From:Subject;\\r\\n b=OrAQTs0GJnA9yVA08gRolpsoe9E2PQhc3BLvK0msqlZkIYPYVLD1SHAHc7eI3imH4b+hggrFA6wUeiSqqq2du3tOokCU8ckq3LrbdI82EZ013M3KL6o2y+/wdPIj9Mo1TeGbmqtthYBOpGvEgwzsQMNnydkJdy5tDaW6IBT2Ux+IaP0K+jp71eYXcWjdR0mSyu3aMhLqc0z4l5HlZYpZRQG1hjxZOaCH/UjgBAdr98JecVvuRp4s5iGe6OIxc0p3xzRZBxTlLdgdHjmTKHQ00eTNCfFYai2rMxf4830lMYTwKI6O/iu3jUbTA2yjxx0LrYBFTiWzFetwAQupKLw3Qg==\\r\\n X-YMail-OSG: 7HG016cVM1nEI.fdz8BF9PN3tO6MvrppAOwu_jpQ09s4eVdYvLXavghvjDvWrRW B7PF6pZKuhiLjV7yCErxEmbWUKPLzX.WL4RJ9u4tnPC4NyVp30cLaoGZVIapWeFtqRpKlh31orVY WTsWE9FcDuHts5p2MPAd7Si52EZfyPuoffEIWrd481hx1IdSsRQN_V7mpfxihvReOIoQ5rCWuMzd oK5kXOho8iOwXlEVPzdTs33RD5rQmwbycPtLS7.FARNxWl9yO9Lrd25gDYa1hXvgG4aQptJQK5aD cHQpZUYqdiaNUaEoGoIDQR_HVndus53gTyzUzmJONpDo6wQM39O.pih7VGCrgLqB2_hHeJdPEUIk jCcwkqNn0cfDyc4QwBdQ65jcgm2cJDPFgoODhxDIqTqeFVbXFr2cXLand8vAqARi3tlnmsOUA7ZI DiSvhSx8eYGd4_frX1LfP.TpctO9Uuc3ZP6iP_K24F9HE9HNN9_swBUEPlBOB3jjSPSOdmiEMteF NWj1qOJ8i47BwMBILtx0dZheRRSxvfzSA.JmnUghFo80EgaGRgXYIEAzt8hpvxdZbtwrg0k0WPeF Y4LC2my.A9XcsnF58558bweJDaDHCJyLGFnE8__ZQI163vMPqY6QbU3OP0EJz2OE1rPBOrq9PUol TZjOEu6ghV1PG2HhX0Ydc.vvq5mloqbKusdzV5EgtpFZjLdp1_RQWuI1LG865Ig756HBaozMU6RG 0FUMn86pvXRBbNMPD6ADwcw4rdw.Xqk5TRZkqJpSp6KX82OjAgFu0xxMiZnQ7LNemrsJ2UQK9Y2_ nm8nrwOIX03Ol6Z2KspWUcPNkqPIZ6vGAr9FO9qqE_elB3K4hh04lq_KS5Tv_XoI3deD4r3J6RTb O9xp5O6cbe0Svy7FS7DosvJfK958_57Kk_6vk6wxxc3D8cx_k6P.yPbphTCLYFdfnbV5sRKNvUKT .apHpO8d0GUf29QtSc3dwBDrLEcRSpguJ3tMKBc2GZPCwUMOgf2b24zFZ49.D7MRQbZifaHsk4dJ L9jxS2qdN5pSjhZUjbLCUQ2YGcYgmNnTbfjAIaxqUWNSgpypIYNmi.lgG4bM_gW7sXH_Y3TULcsC .1GXTSjZUdUvvkr7BDnzUy3FGqv9Eyfb7GOwPzTXLzdurcd6eHx0ejCmC6gVJIwoIh9S0YSK659a K2usThSAyogrxqQ664fZr70CrLJehr5OZNLstPt3fiJhyUR1DXrlm6myQ9uSQ5vPTl0p2.DemDaY k84mtcZO0EEjKIzqeSvZ505Fex0u.66Mzu2lmr07WwMCE7wgqwOSWRnYNCz2rWcLmXA_TVDtdJ85 bHZ79FY6Vs5pGJjp.7YgDnVqysBp95w--\\r\\n Received: from sonic.gate.mail.ne1.yahoo.com by sonic310.consmr.mail.gq1.yahoo.com with HTTP; Tue, 3 Mar 2020 17:56:53 +0000\\r\\n Date: Tue, 3 Mar 2020 17:56:49 +0000 (UTC)\\r\\n From: Peter Edward Copley \u0026lt;noodlelife@yahoo.com\u0026gt;\\r\\n Reply-To: Peter Edward Copley \u0026lt;pshun3592@gmail.com\u0026gt;\\r\\n Message-ID: \u0026lt;729348196.5391236.1583258209467@mail.yahoo.com\u0026gt;\\r\\n Subject: Re:Hello\\r\\n MIME-Version: 1.0\\r\\n Content-Type: multipart/alternative; \\r\\n boundary=\u0026#34;----=_Part_5391235_1821490954.1583258209466\u0026#34;\\r\\n References: \u0026lt;729348196.5391236.1583258209467.ref@mail.yahoo.com\u0026gt;\\r\\n X-Mailer: WebService/1.1.15302 YMailNorrin Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.122 Safari/537.36\\r\\n X-CM-TRANSID:T8CowABHlztmml5erAoHAQ--.23443S3\\r\\n Authentication-Results: mx29; spf=pass smtp.mail=noodlelife@yahoo.com;\\r\\n dkim=pass header.i=@yahoo.com\\r\\n X-Coremail-Antispam: 1Uf129KBjDUn29KB7ZKAUJUUUUU529EdanIXcx71UUUUU7v73 VFW2AGmfu7bjvjm3AaLaJ3UbIYCTnIWIevJa73UjIFyTuYvjxU-NtIUUUUU\\r\\n \\r\\n ------=_Part_5391235_1821490954.1583258209466\\r\\n .\\r\\n client：QUIT\\r\\n server：+OK core mail\\r\\n 上述过程如下示意图所示：\n当我们收取邮件正文之后，我们就可以根据邮件正文中的各种 tag 来解析邮件内容得到邮件的 MessageID、收件人、发件人、邮件主题、正文和附件，注意附件内容也会被拆成特定的编码格式放在邮件中。邮件正文里面按所谓的 boundary 来分成多个块，例如上文中的 boundary=\u0026quot;----=_Part_5391235_1821490954.1583258209466\u0026quot;。\n我们来看一个具体的例子吧。\n上述邮件的主题是“测试邮件”，内容是纯文本“这是一封测试邮件，含有两个附件。”，还有两个附件，一张名为 self.jpg 的图片，一个名为 test.docx 的文档。我们将邮件下载下来后得到邮件原文是：\n+OK 93763 octets Received: from qq.com (unknown [183.3.226.165]) by mx27 (Coremail) with SMTP id TcCowABHJo+dMqReI+72Bg--.18000S3; Sat, 25 Apr 2020 20:52:45 +0800 (CST) DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed; d=qq.com; s=s201512; t=1587819165; bh=RLNDml5+GusG7KQTgkjeS/Mpn1m/LmqBUaz6Nmo6ukY=; h=From:To:Subject:Mime-Version:Date:Message-ID; b=K3sJK+aPQ9zHu1GUvKckofm3cfocpze10XBp9FufVVVYS423myQnFWMaREpGGbeaS vrCGdjawcfhXpkvGZnhOkJZrtut1er5zWZRkmsDnqvoekRURXKt3wWyOv5WUuSPHZI NzGjMQbtYmbWjFla7zs1Cg81UQKRtg1s5KxWwGVQ= X-QQ-FEAT: CPmoSFXLZ/TSSc3nxNJn8bUc57myjtkH8mxkmSC9/G9nP1mNDXcYVAAERmmiE 038rlXj8w6qkTmh1317bdJp9MqMMEUSgpJC5DulJn4k6WCURo4NEYDiuUQK/J+YfUQnpETt w4aQYpj6nKAIqKgorGGK0zy6oQWavfOgssyvSU15d6wqlw904x6aZhS3KAUAM4+eGitBRk9 fxUEABnV/opGuLtZ/fex+UsUAVgXFbTZPoYjhxoM4ZKJsDEJ38x/9QHR1FymBebmAvNzzbB JT45M4OYwynKE/mrFR1FPSeXA= X-QQ-SSF: 00010000000000F000000000000000Z X-HAS-ATTACH: no X-QQ-BUSINESS-ORIGIN: 2 X-Originating-IP: 255.21.142.175 X-QQ-STYLE: X-QQ-mid: webmail504t1587819163t7387219 From: \u0026#34;=?gb18030?B?1/PRp7fG?=\u0026#34; \u0026lt;balloonwj@qq.com\u0026gt; To: \u0026#34;=?gb18030?B?dGVzdGZvcm15Ym9vaw==?=\u0026#34; \u0026lt;testformybook@163.com\u0026gt; Subject: =?gb18030?B?suLK1NPKvP4=?= Mime-Version: 1.0 Content-Type: multipart/mixed; boundary=\u0026#34;----=_NextPart_5EA4329B_0FBAC2B8_51634C9D\u0026#34; Content-Transfer-Encoding: 8Bit Date: Sat, 25 Apr 2020 20:52:43 +0800 X-Priority: 3 Message-ID: \u0026lt;tencent_855A7727508F28D762951979338305E06B08@qq.com\u0026gt; X-QQ-MIME: TCMime 1.0 by Tencent X-Mailer: QQMail 2.x X-QQ-Mailer: QQMail 2.x X-QQ-SENDSIZE: 520 Received: from qq.com (unknown [127.0.0.1]) by smtp.qq.com (ESMTP) with SMTP id ; Sat, 25 Apr 2020 20:52:44 +0800 (CST) Feedback-ID: webmail:qq.com:bgweb:bgweb16 X-CM-TRANSID:TcCowABHJo+dMqReI+72Bg--.18000S3 Authentication-Results: mx27; spf=pass smtp.mail=balloonwj@qq.com; dki m=pass header.i=@qq.com X-Coremail-Antispam: 1Uf129KBjDUn29KB7ZKAUJUUUUU529EdanIXcx71UUUUU7v73 VFW2AGmfu7bjvjm3AaLaJ3UbIYCTnIWIevJa73UjIFyTuYvjxU-LIDUUUUU This is a multi-part message in MIME format. ------=_NextPart_5EA4329B_0FBAC2B8_51634C9D Content-Type: multipart/alternative; boundary=\u0026#34;----=_NextPart_5EA4329B_0FBAC2B8_71508FA9\u0026#34;; ------=_NextPart_5EA4329B_0FBAC2B8_71508FA9 Content-Type: text/plain; charset=\u0026#34;gb18030\u0026#34; Content-Transfer-Encoding: base64 1eLKx9K7t+Ky4srU08q8/qOsuqzT0MG9uPa4vbz+oaM= ------=_NextPart_5EA4329B_0FBAC2B8_71508FA9 Content-Type: text/html; charset=\u0026#34;gb18030\u0026#34; Content-Transfer-Encoding: base64 PG1ldGEgaHR0cC1lcXVpdj0iQ29udGVudC1UeXBlIiBjb250ZW50PSJ0ZXh0L2h0bWw7IGNo YXJzZXQ9R0IxODAzMCI+PGRpdj7V4srH0ru34rLiytTTyrz+o6y6rNPQwb249ri9vP6hozwv ZGl2Pg== ------=_NextPart_5EA4329B_0FBAC2B8_71508FA9-- ------=_NextPart_5EA4329B_0FBAC2B8_51634C9D Content-Type: application/octet-stream; charset=\u0026#34;gb18030\u0026#34;; name=\u0026#34;self.jpg\u0026#34; Content-Disposition: attachment; filename=\u0026#34;self.jpg\u0026#34; Content-Transfer-Encoding: base64 /9j/4AAQSkZJRgABAQEAYABgAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRof Hh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwh MjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAAR CAEXAR8DASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAA AgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkK FhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWG h4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl 5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREA AgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYk NOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOE hYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk 3nOqryf+eEvH/jlX4PHfhIS（限于篇幅，省去部分内容...）F11n5mOMG3lwMf8AAKKKmOxDKeq+PPDtxPA0OuBIYz+8T7PL8/8A45Uj/ETwzDCWOqqV64EE v/xFFFO5q3eIknj7wy8AH9qrsccjyJeP/HKhsvGHhWyT93qwyflX9xLwP++KKKaqS5TFxVwv PiBoLRMbTUonkzgBoJQPr9ysXWvGGg30kVumpqoLh2byZP8A4iiikpNS0GtjpNM8c+FraHB1 f/yBL/8AEVej+InhUf8AMWXGf+feX/4iiihslmVrPj3wzLGETVlPPeCX/wCIrMl8YeH5rdBD rCLInIzBL/8AEUUU7msNyRPGugi2/eaohbG5R5EnHt9ym3vjPw3JZAHUtp2hvlhk6/8AfFFF RzNNWJfvT1Kz+LvDctsBHqW0p0Bik/8AiKrr4v0HH/H+P+/Mn+FFFZz3Gf/Z ------=_NextPart_5EA4329B_0FBAC2B8_51634C9D Content-Type: application/octet-stream; charset=\u0026#34;gb18030\u0026#34;; name=\u0026#34;test.docx\u0026#34; Content-Disposition: attachment; filename=\u0026#34;test.docx\u0026#34; Content-Transfer-Encoding: base64 UEsDBBQABgAIAAAAIQCshlBXjgEAAMAFAAATAAgCW0NvbnRlbnRfVHlwZXNdLnhtbCCiBAIo oAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA AAAAAAAAAAAAAAAAA（限于篇幅，省去部分内容...） V5cAEAAOECAAARAAAAAAAAAAAAAAAAAHyyAABk b2NQcm9wcy9jb3JlLnhtbFBLAQItABQABgAIAAAAIQAKRdqw1gcAAGM8AAAPAAAAAAAAAAAA AAAAACO1AAB3b3JkL3N0eWxlcy54bWxQSwECLQAUAAYACAAAACEAISmu3xsCAADFBQAAEgAA AAAAAAAAAAAAAAAmvQAAd29yZC9mb250VGFibGUueG1sUEsBAi0AFAAGAAgAAAAhAMB9S4Zw AQAAxQIAABAAAAAAAAAAAAAAAAAAcb8AAGRvY1Byb3BzL2FwcC54bWxQSwUGAAAAAA0ADQBM AwAAF8IAAAAA ------=_NextPart_5EA4329B_0FBAC2B8_51634C9D-- . 我们如何去解析这样的邮件格式呢？\n这封邮件内容主要由两部分组成，第一部分是“OK”关键字，第二部分是邮件内容，邮件内容以 点 + \\r\\n 结束。其中邮件内容中前面一部分是一个的 tag 和 tag 值，我们可以从这些 tag 中得到邮件的 MessageID、收件人姓名和地址、发件人姓名和地址、邮件主题，例如：\nFrom: \u0026#34;=?gb18030?B?1/PRp7fG?=\u0026#34; \u0026lt;balloonwj@qq.com\u0026gt; To: \u0026#34;=?gb18030?B?dGVzdGZvcm15Ym9vaw==?=\u0026#34; \u0026lt;testformybook@163.com\u0026gt; Subject: =?gb18030?B?suLK1NPKvP4=?= Date: Sat, 25 Apr 2020 20:52:43 +0800 Message-ID: \u0026lt;tencent_855A7727508F28D762951979338305E06B08@qq.com\u0026gt; 其中像邮件的收发人姓名（From 和 To）使用了 base64 编码，我们使用 base64 解码即可还原其内容。\nContent-Type: multipart/mixed; 说明邮件有多个部分组成。\n我们先根据boundary=\u0026quot;----=_NextPart_5EA4329B_0FBAC2B8_71508FA9\u0026quot;;中指定的 ----=_NextPart_5EA4329B_0FBAC2B8_71508FA9 分隔符得到除了邮件附件内容外的邮件正文内容，一共有两段：\n正文段一\nContent-Type: text/plain; charset=\u0026#34;gb18030\u0026#34; Content-Transfer-Encoding: base64 1eLKx9K7t+Ky4srU08q8/qOsuqzT0MG9uPa4vbz+oaM= 这段内容为纯文本格式（text/plain），使用 base64 编码，字符集格式为 gb18030，解码之后得到正文即：\n正文段二\nContent-Type: text/html; charset=\u0026#34;gb18030\u0026#34; Content-Transfer-Encoding: base64 PG1ldGEgaHR0cC1lcXVpdj0iQ29udGVudC1UeXBlIiBjb250ZW50PSJ0ZXh0L2h0bWw7IGNo YXJzZXQ9R0IxODAzMCI+PGRpdj7V4srH0ru34rLiytTTyrz+o6y6rNPQwb249ri9vP6hozwv ZGl2Pg== 这段内容为富文本格式（text/html），使用 base64 编码，字符集格式为 gb18030，解码之后得到正文即邮件中的那个带超级链接的英语广告，这是我使用的 163 邮件服务器自动插入到邮件正文中的：\n接下来就是两个附件的内容了，使用的编码格式也是 base64，我们使用 base64 解码还原成 ASCII 字节流后作为文件的内容，再取 tag 中附件文件名生成对应的文件即可还原成附件内容。\n完整的邮件解码及 POP3 协议收发示例代码请在【**高性能服务器开发】**公众号后台回复关键字“POP3”。\n上文我们介绍了 POP3 协议常用的命令，POP3 完整的命令读者可以参考 rfc1939 文档 https://tools.ietf.org/html/rfc1939。\n邮件客户端 上面我们介绍了 POP3 和 SMTP 协议，IMAP 与此类似这里就不再介绍了，读者可以参考 rfc3501：https://tools.ietf.org/html/rfc3501 。\n除了上面说的三种协议，邮件还有使用 Exchange 协议的，具体可以参考这里：https://docs.microsoft.com/en-us/openspecs/exchange_server_protocols/ms-asemail/f3d27369-e0f5-4164-aa5e-9b1abda16f5f。\n在理解了上述邮件协议之后，我们就可以编写自己的邮件客户端了，且可以自由定制邮件展示功能（如上文中 163 邮箱在收到的邮件内部插入自定义英语广告）。\n","permalink":"https://haokiu.com/blog/e1e38f7ff0e941c8ad6e51923070551d/","summary":"从零实现一个邮件收发客户端 与邮件收发有关的协议有 POP3、SMPT 和 IMAP 等。\nPOP3\nPOP3全称是 Post Office Protocol 3 ，即邮局协议的第 3 个版本，它规定怎样将个人计算机连接到 Internet 的邮件服务器和下载电子邮件的电子协议，它是因特网电子邮件的第一个离线协议标准，POP3 允许用户从服务器上把邮件存储到本地主机（即自己的计算机）上，同时删除保存在邮件服务器上的邮件，而 POP3 服务器则是遵循 POP3 协议的接收邮件服务器，用来接收电子邮件的。\nSMTP\nSMTP 的全称是 Simple Mail Transfer Protocol，即简单邮件传输协议。它是一组用于从源地址到目的地址传输邮件的规范，它帮助每台计算机在发送或中转邮件时找到下一个目的地。SMTP 服务器就是遵循 SMTP 协议的发送邮件服务器。SMTP 需要认证，简单地说就是要求必须在提供了账户名和密码之后才可以登录 SMTP 服务器，这就使得那些垃圾邮件的散播者无可乘之机，使用户避免受到垃圾邮件的侵扰。\nIMAP\nIMAP全称是 Internet Mail Access Protocol，即交互式邮件存取协议，它是跟 POP3 类似邮件访问标准协议之一。不同的是，开启了 IMAP 后，在电子邮件客户端收取的邮件仍然保留在服务器上，同时在客户端上的操作都会反馈到服务器上，如：删除邮件，标记已读等，服务器上的邮件也会做相应的动作。所以无论从浏览器登录邮箱或者客户端软件登录邮箱，看到的邮件以及状态都是一致的。而 POP3 对邮件的操作只会在本地邮件客户端起作用。\n读者如果需要自己编写相关的邮件收发客户端，需要登录对应的邮件服务器开启相应的 POP3/SMTP/IMAP 服务。以 163 邮箱为例：\n请登录 163 邮箱(http://mail.163.com/)，点击页面正上方的“设置”，再点击左侧上“POP3/SMTP/IMAP”，其中“开启 SMTP 服务”是系统默认勾选开启的。读者可勾选图中另两个选项，点击确定，即可开启成功。不勾选图中两个选项，点击确定，可关闭成功。\n网易163免费邮箱相关服务器信息：\n163免费邮客户端设置的POP3、SMTP、IMAP地址\nPOP3、SMTP、IMAP 协议就是我们前面介绍的以指定字符（串）为包的结束标志的协议典型例子。我们来以 SMTP 协议和 POP3 协议为例来讲解一下。\nSMTP 协议 先来介绍 SMTP 协议吧，SMTP 全称是 Simple Mail Transfer Protocol，即简单邮件传输协议，该协议用于发送邮件。\nSMTP 协议的格式：\n关键字 自定义内容\\r\\n “自定义内容”根据“关键字”的类型是否设置，对于使用 SMTP 作为客户端的一方常用的“关键字“如下所示：\n//连接上邮件服务器之后登录服务器之前向服务器发送的问候信息 HELO 自定义问候语\\r\\n //请求登录邮件服务器 AUTH LOGIN\\r\\n base64形式的用户名\\r\\n base64形式的密码\\r\\n //设置发件人邮箱地址 MAIL FROM:发件人地址\\r\\n //设置收件人地址，每次发送可设置一个收件人地址，如果有多个收件地址，要分别设置对应次数 rcpt to:收件人地址\\r\\n //发送邮件正文开始标志 DATA\\r\\n //发送邮件正文，注意邮件正文以.\\r\\n结束 邮件正文\\r\\n.\\r\\n //登出服务器 QUIT\\r\\n 使用 SMTP 作为邮件服务器的一方常用的“关键字“是定义的各种应答码，应答码后面可以带上自己的信息，然后以\\r\\n作为结束，格式如下：","title":"从零实现一个邮件收发客户端"},{"content":"从零实现一款12306刷票软件 写在前面的话\n每年逢年过节，一票难求读者肯定不陌生。这篇文章，我们带领读者从零实现一款12306刷票软件，其核心原理是通过发送http请求模拟登录12306网站的购票的过程，最后买到票。\n关于http请求的格式和如何组装http数据包给服务器发送请求，我们在上一篇文章《从零实现一个http服务器》中已经详细介绍过了，如果还不明白的朋友可以去那篇文章看下。\n郑重申明一下：这里介绍的技术仅供用于学习，不可用于恶意攻击12306服务器，请勿滥用本文介绍的技术。对12306服务器造成的任何损失，后果自负。\n当然，由于12306服务器用户量巨大，为了防止黄牛和其他一些非法攻击者，12306的很多url和在购票过程中各个步骤的协议细节经常发生变化。所以，本文中介绍的一些具体的url，可能在你看到本文时已经失效。但是这并没有关系，只要你掌握了本文中介绍的分析方法，您就可以灵活地修改您的代码，以适应最新的12306服务器的要求。\n举个例子，如12306的查票接口目前的url是：\nhttps://kyfw.12306.cn/otn/leftTicket/query 可能过几天就变成了\nhttps://kyfw.12306.cn/otn/leftTicket/queryX 再过几天又可能变成\nhttps://kyfw.12306.cn/otn/leftTicket/queryY 然后一个星期后又可能变成\nhttps://kyfw.12306.cn/otn/leftTicket/queryZ 这些笔者都见过。所以，重在原理的学习，掌握了原理，不管12306的相关url变成什么样，都可以以不变应万变。哎，12306在与黄牛的斗争中越走越远啊T_T\n本文将使用以下工具来分析12306购票的过程，然后使用C++语言，模拟相关的过程，最终购票。\nChrome浏览器（其他的浏览器也可以，都有类似的界面，如Chrome，装了httpwatch的IE浏览器等） 一个可以登录12306网址并且可以购票的12306账号 Visual Studio（版本随意，我这里用的是VS 2013） 一、查票与站点信息接口\n之所以先分析这个接口，是因为查票不需要用户登录的，相对来说最简单。我们在Chrome浏览器中打开12306余票查询页面，网址是：https://kyfw.12306.cn/otn/leftTicket/init，如下图所示：\n然后在页面中右键菜单中选择【检查】菜单，打开后，选择【网络】选项卡。如下图所示：\n打开后页面变成二分窗口了，左侧是正常的网页页面，右侧是浏览器自带的控制台，当我们在左侧页面中进行操作后，右侧会显示我们浏览器发送的各种http请求和应答。我们这里随便查一个票吧，如查2018年5月20日从上海到北京的票，点击12306网页中【查询】按钮后，我们发现右侧是这样的：\n通过图中列表的type值是xhr，我们可以得出这是一个ajax请求（ajax是一种浏览器原生支持的异步技术，具体细节请读者自行搜索）。我们选择这个请求，你能看到这个请求的细节——请求和响应结果：\n在reponse中，我们可以看到我们的这个http的去除http头的响应结果（包体，可能是解压缩或者解码后的）：\n这是一个json格式，我们找个json格式化工具，把这个json格式化后贴出来给大家看一下，其实您后面会发现12306的http请求结果中与购票相关的数据基本上都是json格式。这里的json如下：\n{ \u0026#34;validateMessagesShowId\u0026#34;: \u0026#34;_validatorMessage\u0026#34;, \u0026#34;status\u0026#34;: true, \u0026#34;httpstatus\u0026#34;: 200, \u0026#34;data\u0026#34;: { \u0026#34;result\u0026#34;: [\u0026#34;null|23:00-06:00系统维护时间|5l0000G10270|G102|AOH|VNP|AOH|VNP|06:26|12:29|06:03|IS_TIME_NOT_BUY|RLVVIt093U2EZuy2NE+VQyRloXyqTzFp6YyNk6J52QcHEA01|20180520|3|HZ|01|11|1|0|||||||||||1|有|13||O090M0|O9M|0\u0026#34;,(内容太长，这里省略) \u0026#34;], \u0026#34;flag\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;map\u0026#34;: { \u0026#34;AOH\u0026#34;: \u0026#34;上海虹桥\u0026#34;, \u0026#34;BJP\u0026#34;: \u0026#34;北京\u0026#34;, \u0026#34;VNP\u0026#34;: \u0026#34;北京南\u0026#34;, \u0026#34;SHH\u0026#34;: \u0026#34;上海\u0026#34; } }, \u0026#34;messages\u0026#34;: [], \u0026#34;validateMessages\u0026#34;: {} } 其中含有的余票信息在result节点中，这是一个数组。每个节点以|分割，我们可以格式化后显示在自己的界面上：\n我这里做的界面比较简陋，读者如果有兴趣可以做更精美的界面。我们列下这个请求发送的http数据包和应答包：\n请求包：\nGET /otn/leftTicket/query?leftTicketDTO.train_date=2018-05-20\u0026amp;leftTicketDTO.from_station=SHH\u0026amp;leftTicketDTO.to_station=BJP\u0026amp;purpose_codes=ADULT HTTP/1.1 Host: kyfw.12306.cn Connection: keep-alive Cache-Control: no-cache Accept: */* X-Requested-With: XMLHttpRequest If-Modified-Since: 0 User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36 Referer: https://kyfw.12306.cn/otn/leftTicket/init Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cookie: RAIL_EXPIRATION=1526978933395; RAIL_DEVICEID=WKxIYg-q1zjIPVu7VjulZ9PqEGvW2gUB9LvoM1Vx8fa7l3SUwnO_BVSatbTq506c6VYNOaxAiRaUcGFTMjCz9cPayEIc9vJ0pHaXdSqDlujJP8YrIoXbpAAs60l99z8bEtnHgAJzxLzKiv2nka5nmLY_BMNur8b8; _jc_save_fromStation=%u4E0A%u6D77%2CSHH; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_fromDate=2018-05-20; _jc_save_toDate=2018-05-19; _jc_save_wfdc_flag=dc 应答包：\nHTTP/1.1 200 OK Date: Sat, 19 May 2018 15:23:58 GMT Content-Type: application/json;charset=UTF-8 Transfer-Encoding: chunked ct: C1_217_85_8 Content-Encoding: gzip Age: 1 X-Via: 1.1 houdianxin183:6 (Cdn Cache Server V2.0) Connection: keep-alive X-Dscp-Value: 0 X-Cdn-Src-Port: 33963 Cache-Control: no-cache, no-store 通过上一篇文章《从零实现一个http服务器》我们知道这是一个http GET请求，其中在url后面是请求附带的参数：\nleftTicketDTO.train_date: 2018-05-20 leftTicketDTO.from_station: SHH leftTicketDTO.to_station: BJP purpose_codes: ADULT 这四个参数分别是购票日期、出发站、到达站和票类型（这里是成人票（即普通票）），正好对应我们界面上的查询信息：\n但是，读者可能会问，这里的出发站和到达站分别是SHH和BJP，这些站点代码，我如何获得呢？因为只有知道这些站点编码我才能自己购买指定出发站和到达站的火车票啊。如果您是一位细心的人，您肯定会想到，我们查票的时候再进入查票页面，这些站点信息就已经有了，那么可能是在这个查票页面加载时，从服务器请求的站点信息，所以我们刷新下查票页面，发现果然是这样：\n进入查票页面之前，浏览器从 https://kyfw.12306.cn/otn/resources/js/framework/station_name.js?station_version=1.9053 下载一个叫 station.name.js 文件，这是一个javascript脚本，里面只有一行代码，就是定义了一个station_names的js变量，之所以url地址后面加一个station_version=1.9053，你可以理解成版本号，但是主要是通过一个随机值1.9053，让浏览器不要使用缓存中的station_name.js，而是每次都从服务器重新加载下这个文件，这样的话如果站点信息有更新，也可以避免因为缓存问题，导致本地的缓存与服务器上的站点信息不一致。由于站点信息比较多，我们截个图把：\n看上图，我们可以看出来，每个站点信息都是通过**@符号分割，然后通过|分割每一个站点的各种信息。这样的话，根据上文的格式假如我们要查询2018年5月30日从长春到南京**的火车普通票，就可以通过网址：\nhttps://kyfw.12306.cn/otn/leftTicket/query?leftTicketDTO.train_date=2018-05-30\u0026amp;leftTicketDTO.from_station=CCT\u0026amp;leftTicketDTO.to_station=NJH\u0026amp;purpose_codes=ADULT 当然，这里需要说明一下的就是，由于全国的火车站点信息文件比较大，我们程序解析起来时间较长，加上火车站编码信息并不是经常变动，所以，我们我们没必要每次都下载这个station_name.js，所以我在写程序模拟这个请求时，一般先看本地有没有这个文件，如果有就使用本地的，没有才发http请求向12306服务器请求。这里我贴下我请求站点信息的程序代码（C++代码）：\n/** * 获取全国车站信息 * @param si 返回的车站信息 * @param bForceDownload 强制从网络上下载，即不使用本地副本 */ bool GetStationInfo(vector\u0026lt;stationinfo\u0026gt;\u0026amp; si, bool bForceDownload = false); #define URL_STATION_NAMES \u0026#34;https://kyfw.12306.cn/otn/resources/js/framework/station_name.js?station_version=1.9053\u0026#34; bool Client12306::GetStationInfo(vector\u0026lt;stationinfo\u0026gt;\u0026amp; si, bool bForceDownload/* = false*/) { FILE* pfile; pfile = fopen(\u0026#34;station_name.js\u0026#34;, \u0026#34;rt+\u0026#34;); //文件不存在，则必须下载 if (pfile == NULL) { bForceDownload = true; } string strResponse; if (bForceDownload) { if (pfile != NULL) fclose(pfile); pfile = fopen(\u0026#34;station_name.js\u0026#34;, \u0026#34;wt+\u0026#34;); if (pfile == NULL) { LogError(\u0026#34;Unable to create station_name.js\u0026#34;); return false; } CURLcode res; CURL* curl = curl_easy_init(); if (NULL == curl) { fclose(pfile); return false; } //URL_STATION_NAMES curl_easy_setopt(curl, CURLOPT_URL, URL_STATION_NAMES); //响应结果中保留头部信息 //curl_easy_setopt(curl, CURLOPT_HEADER, 1); curl_easy_setopt(curl, CURLOPT_COOKIEFILE, \u0026#34;\u0026#34;); curl_easy_setopt(curl, CURLOPT_READFUNCTION, NULL); curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, OnWriteData); curl_easy_setopt(curl, CURLOPT_WRITEDATA, (void *)\u0026amp;strResponse); curl_easy_setopt(curl, CURLOPT_NOSIGNAL, 1); //设定为不验证证书和HOST curl_easy_setopt(curl, CURLOPT_SSL_VERIFYPEER, false); curl_easy_setopt(curl, CURLOPT_SSL_VERIFYHOST, false); curl_easy_setopt(curl, CURLOPT_CONNECTTIMEOUT, 10); curl_easy_setopt(curl, CURLOPT_TIMEOUT, 10); res = curl_easy_perform(curl); bool bError = false; if (res == CURLE_OK) { int code; res = curl_easy_getinfo(curl, CURLINFO_RESPONSE_CODE, \u0026amp;code); if (code != 200) { bError = true; LogError(\u0026#34;http response code is not 200, code=%d\u0026#34;, code); } } else { LogError(\u0026#34;http request error, error code = %d\u0026#34;, res); bError = true; } curl_easy_cleanup(curl); if (bError) { fclose(pfile); return !bError; } if (fwrite(strResponse.data(), strResponse.length(), 1, pfile) != 1) { LogError(\u0026#34;Write data to station_name.js error\u0026#34;); return false; } fclose(pfile); } //直接读取文件 else { //得到文件大小 fseek(pfile, 0, SEEK_END); int length = ftell(pfile); if (length \u0026lt; 0) { LogError(\u0026#34;invalid station_name.js file\u0026#34;); fclose(pfile); } fseek(pfile, 0, SEEK_SET); length++; char* buf = new char[length]; memset(buf, 0, length*sizeof(char)); if (fread(buf, length-1, 1, pfile) != 1) { LogError(\u0026#34;read station_name.js file error\u0026#34;); fclose(pfile); return false; } strResponse = buf; fclose(pfile); } /* 返回结果为一个js文件， var station_names = \u0026#39;@bjb|北京北|VAP|beijingbei|bjb|0@bjd|北京东|BOP|beijingdong|bjd|1@bji|北京|BJP|beijing|bj|2\u0026#34; */ //LogInfo(\u0026#34;recv json = %s\u0026#34;, strResponse.c_str()); OutputDebugStringA(strResponse.c_str()); vector\u0026lt;string\u0026gt; singleStation; split(strResponse, \u0026#34;@\u0026#34;, singleStation); size_t size = singleStation.size(); for (size_t i = 1; i \u0026lt; size; ++i) { vector\u0026lt;string\u0026gt; v; split(singleStation[i], \u0026#34;|\u0026#34;, v); if (v.size() \u0026lt; 6) continue; stationinfo st; st.code1 = v[0]; st.hanzi = v[1]; st.code2 = v[2]; st.pingyin = v[3]; st.simplepingyin = v[4]; st.no = atol(v[5].c_str()); si.push_back(st); } return true; } 这里用了一个站点信息结构体stationinfo，定义如下：\n//var station_names = \u0026#39;@bjb|北京北|VAP|beijingbei|bjb|0@bjd|北京东|BOP|beijingdong|bjd|1@bji|北京|BJP|beijing|bj|2 struct stationinfo { string code1; string hanzi; string code2; string pingyin; string simplepingyin; int no; }; 因为我们这里目的是为了模拟http请求做买火车票相关的操作，而不是技术方面本身，所以为了快速实现我们的目的，我们就使用curl库。这个库是一个强大的http相关的库，例如12306服务器返回的数据可能是分块的（chunked），这个库也能帮我们组装好；再例如，服务器返回的数据是使用gzip格式压缩的，curl也会帮我们自动解压好。所以，接下来的所有12306的接口，都基于我封装的curl库一个接口：\n/** * 发送一个http请求 *@param url 请求的url *@param strResponse http响应结果 *@param get true为GET，false为POST *@param headers 附带发送的http头信息 *@param postdata post附带的数据 *@param bReserveHeaders http响应结果是否保留头部信息 *@param timeout http请求超时时间 */ bool HttpRequest(const char* url, string\u0026amp; strResponse, bool get = true, const char* headers = NULL, const char* postdata = NULL, bool bReserveHeaders = false, int timeout = ); 函数各种参数已经在函数注释中写的清清楚楚了，这里就不一一解释了。这个函数的实现代码如下：\nbool Client12306::HttpRequest(const char* url, string\u0026amp; strResponse, bool get/* = true*/, const char* headers/* = NULL*/, const char* postdata/* = NULL*/, bool bReserveHeaders/* = false*/, int timeout/* = 10*/) { CURLcode res; CURL* curl = curl_easy_init(); if (NULL == curl) { LogError(\u0026#34;curl lib init error\u0026#34;); return false; } curl_easy_setopt(curl, CURLOPT_URL, url); //响应结果中保留头部信息 if (bReserveHeaders) curl_easy_setopt(curl, CURLOPT_HEADER, 1); curl_easy_setopt(curl, CURLOPT_COOKIEFILE, \u0026#34;\u0026#34;); curl_easy_setopt(curl, CURLOPT_READFUNCTION, NULL); curl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, OnWriteData); curl_easy_setopt(curl, CURLOPT_WRITEDATA, (void *)\u0026amp;strResponse); curl_easy_setopt(curl, CURLOPT_NOSIGNAL, 1); //设定为不验证证书和HOST curl_easy_setopt(curl, CURLOPT_SSL_VERIFYPEER, false); curl_easy_setopt(curl, CURLOPT_SSL_VERIFYHOST, false); //设置超时时间 curl_easy_setopt(curl, CURLOPT_CONNECTTIMEOUT, timeout); curl_easy_setopt(curl, CURLOPT_TIMEOUT, timeout); curl_easy_setopt(curl, CURLOPT_REFERER, URL_REFERER); //12306早期版本是不需要USERAGENT这个字段的，现在必须了，估计是为了避免一些第三方的非法刺探吧。 //如果没有这个字段，会返回 /* HTTP/1.0 302 Moved Temporarily Location: http://www.12306.cn/mormhweb/logFiles/error.html Server: Cdn Cache Server V2.0 Mime-Version: 1.0 Date: Fri, 18 May 2018 02:52:05 GMT Content-Type: text/html Content-Length: 0 Expires: Fri, 18 May 2018 02:52:05 GMT X-Via: 1.0 PSshgqdxxx63:10 (Cdn Cache Server V2.0) Connection: keep-alive X-Dscp-Value: 0 */ curl_easy_setopt(curl, CURLOPT_USERAGENT, \u0026#34;Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.146 Safari/537.36\u0026#34;); //不设置接收的编码格式或者设置为空，libcurl会自动解压压缩的格式，如gzip //curl_easy_setopt(curl, CURLOPT_ACCEPT_ENCODING, \u0026#34;gzip, deflate, br\u0026#34;); //添加自定义头信息 if (headers != NULL) { //LogInfo(\u0026#34;http custom header: %s\u0026#34;, headers); struct curl_slist *chunk = NULL; chunk = curl_slist_append(chunk, headers); curl_easy_setopt(curl, CURLOPT_HTTPHEADER, chunk); } if (!get \u0026amp;\u0026amp; postdata != NULL) { //LogInfo(\u0026#34;http post data: %s\u0026#34;, postdata); curl_easy_setopt(curl, CURLOPT_POSTFIELDS, postdata); } LogInfo(\u0026#34;http %s: url=%s, headers=%s, postdata=%s\u0026#34;, get ? \u0026#34;get\u0026#34; : \u0026#34;post\u0026#34;, url, headers != NULL ? headers : \u0026#34;\u0026#34;, postdata!=NULL?postdata : \u0026#34;\u0026#34;); res = curl_easy_perform(curl); bool bError = false; if (res == CURLE_OK) { int code; res = curl_easy_getinfo(curl, CURLINFO_RESPONSE_CODE, \u0026amp;code); if (code != 200 \u0026amp;\u0026amp; code != 302) { bError = true; LogError(\u0026#34;http response code is not 200 or 302, code=%d\u0026#34;, code); } } else { LogError(\u0026#34;http request error, error code = %d\u0026#34;, res); bError = true; } curl_easy_cleanup(curl); LogInfo(\u0026#34;http response: %s\u0026#34;, strResponse.c_str()); return !bError; } 正如上面注释中所提到的，浏览器在发送http请求时带的某些字段，不是必须的，我们在模拟这个请求时可以不添加，如查票接口浏览器可能会发以下http数据包：\nGET /otn/leftTicket/query?leftTicketDTO.train_date=2018-05-30\u0026amp;leftTicketDTO.from_station=SHH\u0026amp;leftTicketDTO.to_station=BJP\u0026amp;purpose_codes=ADULT HTTP/1.1 Host: kyfw.12306.cn Connection: keep-alive Cache-Control: no-cache Accept: */* X-Requested-With: XMLHttpRequest If-Modified-Since: 0 User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36 Referer: https://kyfw.12306.cn/otn/leftTicket/init Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cookie: JSESSIONID=ACD9CB098169C4D73CDE80D6F6C38E5A; RAIL_EXPIRATION=1526978933395; RAIL_DEVICEID=WKxIYg-q1zjIPVu7VjulZ9PqEGvW2gUB9LvoM1Vx8fa7l3SUwnO_BVSatbTq506c6VYNOaxAiRaUcGFTMjCz9cPayEIc9vJ0pHaXdSqDlujJP8YrIoXbpAAs60l99z8bEtnHgAJzxLzKiv2nka5nmLY_BMNur8b8; _jc_save_fromStation=%u4E0A%u6D77%2CSHH; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_wfdc_flag=dc; route=c5c62a339e7744272a54643b3be5bf64; BIGipServerotn=1708720394.50210.0000; _jc_save_fromDate=2018-05-30; _jc_save_toDate=2018-05-20 其中像Connection、Cache-Control、Accept、If-Modified-Since等字段都不是必须的，所以我们在模拟我们自己的http请求时可以不用可以添加这些字段，当然据我观察，12306服务器现在对发送过来的http数据包要求越来越严格了，如去年的时候，User-Agent这个字段还不是必须的，现在如果你不带上这个字段，可能12306返回的结果就不一定正确。当然，不正确的结果中一定不会有明确的错误信息，充其量可能会告诉你页面不存在或者系统繁忙请稍后再试，这是服务器自我保护的一种重要的措施，试想你做服务器程序，会告诉非法用户明确的错误信息吗？那样不就给了非法攻击服务器的人不断重试的机会了嘛。\n需要特别注意的是：查票接口发送的http协议的头还有一个字段叫Cookie，其值是一串非常奇怪的东西：\nJSESSIONID=ACD9CB098169C4D73CDE80D6F6C38E5A; RAIL_EXPIRATION=1526978933395; RAIL_DEVICEID=WKxIYg-q1zjIPVu7VjulZ9PqEGvW2gUB9LvoM1Vx8fa7l3SUwnO_BVSatbTq506c6VYNOaxAiRaUcGFTMjCz9cPayEIc9vJ0pHaXdSqDlujJP8YrIoXbpAAs60l99z8bEtnHgAJzxLzKiv2nka5nmLY_BMNur8b8; _jc_save_fromStation=%u4E0A%u6D77%2CSHH; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_wfdc_flag=dc; route=c5c62a339e7744272a54643b3be5bf64; BIGipServerotn=1708720394.50210.0000; _jc_save_fromDate=2018-05-30; _jc_save_toDate=2018-05-2 注意：原代码中各个字段都是连在一起的，我这里为了读者方便阅读，将各个字段单独放在一行。在这串字符中有一个JSESSIONID，在不需要登录的查票接口，我们可以传或者不传这个字段值。但是在购票以及查询常用联系人这些需要在已经登录的情况下才能进行的操作，我们必须带上这个数据，这是服务器给你的token（验证令牌），而这个令牌是在刚进入12306站点时，服务器发过来的，你后面的登录等操作必须带上这个token，否则服务器会认为您的请求是非法请求。我第一次去研究12306的买票流程时，即使在用户名、密码和图片验证码正确的情况下，也无法登录就是这个原因。这是12306为了防止非法登录使用的一个安全措施。\n二、登录与拉取图片验证码接口\n我的登录页面效果如下：\n12306的图片验证码一般由八个图片组成，像上面的“龙舟”文字，也是图片，这两处的图片（文字图片和验证码）都是在服务器上拼装后，发给客户端的，12306服务器上这种类型的小图片有一定的数量，虽然数量比较大，但是是有限的。如果你要做验证码自动识别功能，可以尝试着下载大部分图片，然后做统计规律。所以，我这里并没有做图片自动识别功能。有兴趣的读者可自行尝试。\n先说下，拉取验证码的接口。我们打开Chrome浏览器12306的登录界面：\nhttps://kyfw.12306.cn/otn/login/init 如下图所示：\n可以得到拉取验证码的接口：\n我们可以看到发送的http请求数据包格式是：\nGET /passport/captcha/captcha-image?login_site=E\u0026amp;module=login\u0026amp;rand=sjrand\u0026amp;0.7520968747611347 HTTP/1.1 Host: kyfw.12306.cn Connection: keep-alive User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36 Accept: image/webp,image/apng,image/*,*/*;q=0.8 Referer: https://kyfw.12306.cn/otn/login/init Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cookie: _passport_session=badc97f6a852499297796ee852515f957153; _passport_ct=9cf4ea17c0dc47b6980cac161483f522t9022; RAIL_EXPIRATION=1526978933395; RAIL_DEVICEID=WKxIYg-q1zjIPVu7VjulZ9PqEGvW2gUB9LvoM1Vx8fa7l3SUwnO_BVSatbTq506c6VYNOaxAiRaUcGFTMjCz9cPayEIc9vJ0pHaXdSqDlujJP8YrIoXbpAAs60l99z8bEtnHgAJzxLzKiv2nka5nmLY_BMNur8b8; _jc_save_fromStation=%u4E0A%u6D77%2CSHH; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_wfdc_flag=dc; route=c5c62a339e7744272a54643b3be5bf64; BIGipServerotn=1708720394.50210.0000; _jc_save_fromDate=2018-05-30; _jc_save_toDate=2018-05-20; BIGipServerpassport=837288202.50215.0000 这里也是一个http GET请求，Host、Referer和Cookie这三个字段是必须的，且Cookie字段必须带上上文说的JSESSIONID，下载图片验证码和下文中各个步骤也必须在Cookie字段中带上这个JSESSIONID值，否则无法从12306服务器得到正确的应答。后面会介绍如何拿到这个这。这个拉取图片验证码的http GET请求需要三个参数，如上面的代码段所示，即login_site、module、rand和一个类似于0.7520968747611347的随机值，前三个字段的值都是固定的，module字段表示当前是哪个模块，当前是登录模块，所以值是login，后面获取最近联系人时取值是passenger。这里还有一个需要注意的地方是，如果您验证图片验证码失败时，重新请求图片时，必须也重新请求下JSESSIONID。这个url是\nhttps://kyfw.12306.cn/otn/login/init http请求和应答包如下：\n请求包：\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8 Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cache-Control: max-age=0 Connection: keep-alive Cookie: RAIL_EXPIRATION=1526978933395; RAIL_DEVICEID=WKxIYg-q1zjIPVu7VjulZ9PqEGvW2gUB9LvoM1Vx8fa7l3SUwnO_BVSatbTq506c6VYNOaxAiRaUcGFTMjCz9cPayEIc9vJ0pHaXdSqDlujJP8YrIoXbpAAs60l99z8bEtnHgAJzxLzKiv2nka5nmLY_BMNur8b8; _jc_save_fromStation=%u4E0A%u6D77%2CSHH; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_wfdc_flag=dc; route=c5c62a339e7744272a54643b3be5bf64; BIGipServerotn=1708720394.50210.0000; _jc_save_fromDate=2018-05-30; _jc_save_toDate=2018-05-20; BIGipServerpassport=837288202.50215.0000 Host: kyfw.12306.cn Referer: https://kyfw.12306.cn/otn/passport?redirect=/otn/login/loginOut Upgrade-Insecure-Requests: 1 User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36 应答包：\nHTTP/1.1 200 OK Date: Sun, 20 May 2018 02:23:53 GMT Content-Type: text/html;charset=utf-8 Transfer-Encoding: chunked Set-Cookie: JSESSIONID=D5AE154D66F67DE53BF70420C772158F; Path=/otn ct: C1_217_101_6 Content-Language: zh-CN Content-Encoding: gzip X-Via: 1.1 houdianxin184:4 (Cdn Cache Server V2.0) Connection: keep-alive X-Dscp-Value: 0 X-Cdn-Src-Port: 46480 这个值在应答包字段Set-Cookie中拿到：\nSet-Cookie: JSESSIONID=D5AE154D66F67DE53BF70420C772158F; Path=/otn 所以，我们每次请求图片验证码时，都重新请求一下这个JSESSIONID，代码如下：\n#define URL_LOGIN_INIT \u0026#34;https://kyfw.12306.cn/otn/login/init\u0026#34; bool Client12306::loginInit() { string strResponse; if (!HttpRequest(URL_LOGIN_INIT, strResponse, true, \u0026#34;Upgrade-Insecure-Requests: 1\u0026#34;, NULL, true, 10)) { LogError(\u0026#34;loginInit failed\u0026#34;); return false; } if (!GetCookies(strResponse)) { LogError(\u0026#34;parse login init cookie error, url=%s\u0026#34;, URL_LOGIN_INIT); return false; } return true; } bool Client12306::GetCookies(const string\u0026amp; data) { if (data.empty()) { LogError(\u0026#34;http data is empty\u0026#34;); return false; } //解析http头部 string str; str.append(data.c_str(), data.length()); size_t n = str.find(\u0026#34;\\r\\n\\r\\n\u0026#34;); string header = str.substr(0, n); str.erase(0, n + 4); //m_cookie.clear(); //获取http头中的JSESSIONID=21AC68643BBE893FBDF3DA9BCF654E98; vector\u0026lt;string\u0026gt; v; while (true) { size_t index = header.find(\u0026#34;\\r\\n\u0026#34;); if (index == string::npos) break; string tmp = header.substr(0, index); v.push_back(tmp); header.erase(0, index + 2); if (header.empty()) break; } string jsessionid; string BIGipServerotn; string BIGipServerportal; string current_captcha_type; size_t m; OutputDebugStringA(\u0026#34;\\nresponse http headers:\\n\u0026#34;); for (size_t i = 0; i \u0026lt; v.size(); ++i) { OutputDebugStringA(v[i].c_str()); OutputDebugStringA(\u0026#34;\\n\u0026#34;); m = v[i].find(\u0026#34;Set-Cookie: \u0026#34;); if (m == string::npos) continue; string tmp = v[i].substr(11); Trim(tmp); m = tmp.find(\u0026#34;JSESSIONID\u0026#34;); if (m != string::npos) { size_t comma = tmp.find(\u0026#34;;\u0026#34;); if (comma != string::npos) jsessionid = tmp.substr(0, comma); } m = tmp.find(\u0026#34;BIGipServerotn\u0026#34;); if (m != string::npos) { size_t comma = tmp.find(\u0026#34;;\u0026#34;); if (comma != string::npos) BIGipServerotn = tmp.substr(m, comma); else BIGipServerotn = tmp; } m = tmp.find(\u0026#34;BIGipServerportal\u0026#34;); if (m != string::npos) { size_t comma = tmp.find(\u0026#34;;\u0026#34;); if (comma != string::npos) BIGipServerportal = tmp.substr(m, comma); else BIGipServerportal = tmp; } m = tmp.find(\u0026#34;current_captcha_type\u0026#34;); if (m != string::npos) { size_t comma = tmp.find(\u0026#34;;\u0026#34;); if (comma != string::npos) current_captcha_type = tmp.substr(m, comma); else current_captcha_type = tmp; } } if (!jsessionid.empty()) { m_strCookies = jsessionid; m_strCookies += \u0026#34;; \u0026#34;; m_strCookies += BIGipServerotn; if (!BIGipServerportal.empty()) { m_strCookies += \u0026#34;; \u0026#34;; m_strCookies += BIGipServerportal; } m_strCookies += \u0026#34;; \u0026#34;; m_strCookies += current_captcha_type; return true; } LogError(\u0026#34;jsessionid is empty\u0026#34;); return false; } #define URL_GETPASSCODENEW \u0026#34;https://kyfw.12306.cn/passport/captcha/captcha-image\u0026#34; bool Client12306::DownloadVCodeImage(const char* module) { if (module == NULL) { LogError(\u0026#34;module is invalid\u0026#34;); return false; } //https://kyfw.12306.cn/passport/captcha/captcha-image?login_site=E\u0026amp;module=login\u0026amp;rand=sjrand\u0026amp;0.06851784300754482 ostringstream osUrl; osUrl \u0026lt;\u0026lt; URL_GETPASSCODENEW; osUrl \u0026lt;\u0026lt; \u0026#34;?login_site=E\u0026amp;module=\u0026#34;; osUrl \u0026lt;\u0026lt; module; //购票验证码 if (strcmp(module, \u0026#34;passenger\u0026#34;) != 0) { osUrl \u0026lt;\u0026lt; \u0026#34;\u0026amp;rand=sjrand\u0026amp;\u0026#34;; } //登录验证码 else { osUrl \u0026lt;\u0026lt; \u0026#34;\u0026amp;rand=randp\u0026amp;\u0026#34;; } double d = rand() * 1.000000 / RAND_MAX; osUrl.precision(17); osUrl \u0026lt;\u0026lt; d; string strResponse; string strCookie = \u0026#34;Cookie: \u0026#34;; strCookie += m_strCookies; if (!HttpRequest(osUrl.str().c_str(), strResponse, true, strCookie.c_str(), NULL, false, 10)) { LogError(\u0026#34;DownloadVCodeImage failed\u0026#34;); return false; } //写入文件 time_t now = time(NULL); struct tm* tblock = localtime(\u0026amp;now); memset(m_szCurrVCodeName, 0, sizeof(m_szCurrVCodeName)); #ifdef _DEBUG sprintf(m_szCurrVCodeName, \u0026#34;vcode%04d%02d%02d%02d%02d%02d.jpg\u0026#34;, 1900 + tblock-\u0026gt;tm_year, 1 + tblock-\u0026gt;tm_mon, tblock-\u0026gt;tm_mday, tblock-\u0026gt;tm_hour, tblock-\u0026gt;tm_min, tblock-\u0026gt;tm_sec); #else sprintf(m_szCurrVCodeName, \u0026#34;vcode%04d%02d%02d%02d%02d%02d.v\u0026#34;, 1900 + tblock-\u0026gt;tm_year, 1 + tblock-\u0026gt;tm_mon, tblock-\u0026gt;tm_mday, tblock-\u0026gt;tm_hour, tblock-\u0026gt;tm_min, tblock-\u0026gt;tm_sec); #endif FILE* fp = fopen(m_szCurrVCodeName, \u0026#34;wb\u0026#34;); if (fp == NULL) { LogError(\u0026#34;open file %s error\u0026#34;, m_szCurrVCodeName); return false; } const char* p = strResponse.data(); size_t count = fwrite(p, strResponse.length(), 1, fp); if (count != 1) { LogError(\u0026#34;write file %s error\u0026#34;, m_szCurrVCodeName); fclose(fp); return false; } fclose(fp); return true; } 我们再看下验证码去服务器验证的接口\nhttps://kyfw.12306.cn/passport/captcha/captcha-check 请求头：\nPOST /passport/captcha/captcha-check HTTP/1.1 Host: kyfw.12306.cn Connection: keep-alive Content-Length: 50 Accept: application/json, text/javascript, */*; q=0.01 Origin: https://kyfw.12306.cn X-Requested-With: XMLHttpRequest User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36 Content-Type: application/x-www-form-urlencoded; charset=UTF-8 Referer: https://kyfw.12306.cn/otn/login/init Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cookie: _passport_session=3e39a33a25bf4ea79146bd9362c11ad62327; _passport_ct=c5c7940e08ce44db9ad05d213c1296ddt4410; RAIL_EXPIRATION=1526978933395; RAIL_DEVICEID=WKxIYg-q1zjIPVu7VjulZ9PqEGvW2gUB9LvoM1Vx8fa7l3SUwnO_BVSatbTq506c6VYNOaxAiRaUcGFTMjCz9cPayEIc9vJ0pHaXdSqDlujJP8YrIoXbpAAs60l99z8bEtnHgAJzxLzKiv2nka5nmLY_BMNur8b8; _jc_save_fromStation=%u4E0A%u6D77%2CSHH; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_wfdc_flag=dc; route=c5c62a339e7744272a54643b3be5bf64; BIGipServerotn=1708720394.50210.0000; _jc_save_fromDate=2018-05-30; _jc_save_toDate=2018-05-20; BIGipServerpassport=837288202.50215.0000 这是一个POST请求，其中POST数据带上的输入的图片验证码选择的坐标X和Y值：\nanswer: 175,58,30,51 login_site: E rand: sjrand 这里我选择了两张图片，所以有两组坐标值，（175，58）是一组，（30，51）是另外一组，这个坐标系如下：\n因为每个图片的尺寸都一样，所以，我可以给每个图片设置一个坐标范围，当选择了一个图片，给一个在其中的坐标即可，不一定是鼠标点击时的准确位置：\n//刷新验证码 登录状态下的验证码传入”randp“，非登录传入”sjrand“ 具体参看原otsweb中的传入参数 struct VCodePosition { int x; int y; }; const VCodePosition g_pos[] = { { 39, 40 }, { 114, 43 }, { 186, 42 }, { 252, 47 }, { 36, 120 }, { 115, 125 }, { 194, 125 }, { 256, 120 } }; //验证码图片八个区块的位置 struct VCODE_SLICE_POS { int xLeft; int xRight; int yTop; int yBottom; }; const VCODE_SLICE_POS g_VCodeSlicePos[] = { {0, 70, 0, 70}, {71, 140, 0, 70 }, {141, 210, 0, 70 }, {211, 280, 0, 70 }, { 0, 70, 70, 140 }, {71, 140, 70, 140 }, {141, 210, 70, 140 }, {211, 280, 70, 140 } }; //8个验证码区块的鼠标点击状态 bool g_bVodeSlice1Pressed[8] = { false, false, false, false, false, false, false, false}; 验证的图片验证码的接口代码是：\nint Client12306::checkRandCodeAnsyn(const char* vcode) { string param; param = \u0026#34;randCode=\u0026#34;; param += vcode; param += \u0026#34;\u0026amp;rand=sjrand\u0026#34;; //passenger:randp string strResponse; string strCookie = \u0026#34;Cookie: \u0026#34;; strCookie += m_strCookies; if (!HttpRequest(URL_CHECKRANDCODEANSYN, strResponse, false, strCookie.c_str(), param.c_str(), false, 10)) { LogError(\u0026#34;checkRandCodeAnsyn failed\u0026#34;); return -1; } ///** 成功返回 //HTTP/1.1 200 OK //Date: Thu, 05 Jan 2017 07:44:16 GMT //Server: Apache-Coyote/1.1 //X-Powered-By: Servlet 2.5; JBoss-5.0/JBossWeb-2.1 //ct: c1_103 //Content-Type: application/json;charset=UTF-8 //Content-Length: 144 //X-Via: 1.1 jiandianxin29:6 (Cdn Cache Server V2.0) //Connection: keep-alive //X-Cdn-Src-Port: 19153 //参数无效 //{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;result\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;\u0026#34;},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} //验证码过期 //{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;result\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;EXPIRED\u0026#34;},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} //验证码错误 //{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;result\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;FALSE\u0026#34;},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} //验证码正确 //{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;result\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;TRUE\u0026#34;},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} Json::Reader JsonReader; Json::Value JsonRoot; if (!JsonReader.parse(strResponse, JsonRoot)) return -1; //{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;, \u0026#34;status\u0026#34; : true, \u0026#34;httpstatus\u0026#34; : 200, \u0026#34;data\u0026#34; : {\u0026#34;result\u0026#34;:\u0026#34;1\u0026#34;, \u0026#34;msg\u0026#34; : \u0026#34;TRUE\u0026#34;}, \u0026#34;messages\u0026#34; : [], \u0026#34;validateMessages\u0026#34; : {}} if (JsonRoot[\u0026#34;status\u0026#34;].isNull() || JsonRoot[\u0026#34;status\u0026#34;].asBool() != true) return -1; if (JsonRoot[\u0026#34;httpstatus\u0026#34;].isNull() || JsonRoot[\u0026#34;httpstatus\u0026#34;].asInt() != 200) return -1; if (JsonRoot[\u0026#34;data\u0026#34;].isNull() || !JsonRoot[\u0026#34;data\u0026#34;].isObject()) return -1; if (JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;result\u0026#34;].isNull()) return -1; if (JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;result\u0026#34;].asString() != \u0026#34;1\u0026#34; \u0026amp;\u0026amp; JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;result\u0026#34;].asString() != \u0026#34;0\u0026#34;) return -1; if (JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;msg\u0026#34;].isNull()) return -1; //if (JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;msg\u0026#34;].asString().empty()) // return -1; if (JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;msg\u0026#34;].asString() == \u0026#34;\u0026#34;) return 0; else if (JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;msg\u0026#34;].asString() == \u0026#34;FALSE\u0026#34;) return 1; return 1; } 同理，这里也给出验证用户名和密码的接口实现代码：\nint Client12306::loginAysnSuggest(const char* user, const char* pass, const char* vcode) { string param = \u0026#34;loginUserDTO.user_name=\u0026#34;; param += user; param += \u0026#34;\u0026amp;userDTO.password=\u0026#34;; param += pass; param += \u0026#34;\u0026amp;randCode=\u0026#34;; param += vcode; string strResponse; string strCookie = \u0026#34;Cookie: \u0026#34;; strCookie += m_strCookies; if (!HttpRequest(URL_LOGINAYSNSUGGEST, strResponse, false, strCookie.c_str(), param.c_str(), false, 10)) { LogError(\u0026#34;loginAysnSuggest failed\u0026#34;); return 2; } ///** 成功返回 //HTTP/1.1 200 OK //Date: Thu, 05 Jan 2017 07:49:53 GMT //Server: Apache-Coyote/1.1 //X-Powered-By: Servlet 2.5; JBoss-5.0/JBossWeb-2.1 //ct: c1_103 //Content-Type: application/json;charset=UTF-8 //Content-Length: 146 //X-Via: 1.1 f186:10 (Cdn Cache Server V2.0) //Connection: keep-alive //X-Cdn-Src-Port: 48361 //邮箱不存在 //{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{},\u0026#34;messages\u0026#34;:[\u0026#34;该邮箱不存在。\u0026#34;],\u0026#34;validateMessages\u0026#34;:{}} //密码错误 //{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{},\u0026#34;messages\u0026#34;:[\u0026#34;密码输入错误。如果输错次数超过4次，用户将被锁定。\u0026#34;],\u0026#34;validateMessages\u0026#34;:{}} //登录成功 //{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;otherMsg\u0026#34;:\u0026#34;\u0026#34;,loginCheck:\u0026#34;Y\u0026#34;},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} //WCHAR* psz1 = Utf8ToAnsi(strResponse.c_str()); //wstring str = psz1; //delete[] psz1; Json::Reader JsonReader; Json::Value JsonRoot; if (!JsonReader.parse(strResponse, JsonRoot)) return 2; //{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;, \u0026#34;status\u0026#34; : true, //\u0026#34;httpstatus\u0026#34; : 200, \u0026#34;data\u0026#34; : {\u0026#34;otherMsg\u0026#34;:\u0026#34;\u0026#34;, loginCheck : \u0026#34;Y\u0026#34;}, \u0026#34;messages\u0026#34; : [], \u0026#34;validateMessages\u0026#34; : {}} if (JsonRoot[\u0026#34;status\u0026#34;].isNull()) return -1; bool bStatus = JsonRoot[\u0026#34;status\u0026#34;].asBool(); if (!bStatus) return -1; if (JsonRoot[\u0026#34;httpstatus\u0026#34;].isNull() || JsonRoot[\u0026#34;httpstatus\u0026#34;].asInt() != 200) return 2; if (JsonRoot[\u0026#34;data\u0026#34;].isNull() || !JsonRoot[\u0026#34;data\u0026#34;].isObject()) return 2; if (JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;otherMsg\u0026#34;].isNull() || JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;otherMsg\u0026#34;].asString() != \u0026#34;\u0026#34;) return 2; if (JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;loginCheck\u0026#34;].isNull() || JsonRoot[\u0026#34;data\u0026#34;][\u0026#34;loginCheck\u0026#34;].asString() != \u0026#34;Y\u0026#34;) return 1; return 0; } 这里还有个注意细节，就是通过POST请求发送的数据需要对一些符号做URL Encode，这个我在上一篇文章《从零实现一个http服务器》也详细做了介绍，还不清楚的可以参见上一篇文章。所以对于向图片验证码坐标信息中含有的逗号信息就要进行URL编码，从\nanswer=114,54,44,46\u0026amp;login_site=E\u0026amp;rand=sjrand 变成\nanswer=114%2C54%2C44%2C46\u0026amp;login_site=E\u0026amp;rand=sjrand 所以，在http包头中指定的Content-Length字段的值应该是编码后的字符串长度，而不是原始的长度，这个地方特别容易出错。\n如果验证成功后，接下来就是查票和购票了。这里就不一一介绍了，所有的原理都是一样的，作者可以自行探索。当然，我已经将大多数的接口都探索完了，并实现了，我这里贴一下吧：\n/** *@desc: 封装获取验证码、校验验证码、登录等12306各个请求的类，Client12306.h文件 *@author: zhangyl *@date: 2017.01.17 */ #ifndef __CLIENT_12306_H__ #define __CLIENT_12306_H__ #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; using namespace std; //车次类型 #define TRAIN_GC 0x00000001 #define TRAIN_D (0x00000001 \u0026lt;\u0026lt; 1) #define TRAIN_Z (0x00000001 \u0026lt;\u0026lt; 2) #define TRAIN_T (0x00000001 \u0026lt;\u0026lt; 3) #define TRAIN_K (0x00000001 \u0026lt;\u0026lt; 4) #define TRAIN_OTHER (0x00000001 \u0026lt;\u0026lt; 5) #define TRAIN_ALL (TRAIN_GC | TRAIN_D | TRAIN_Z | TRAIN_T | TRAIN_K | TRAIN_OTHER) //票信息 struct queryLeftNewDTO { string train_no; string station_train_code; string start_station_telecode; //始发站 string start_station_name; string end_station_telecode; //终点站 string end_station_name; string from_station_telecode; //出发站 string from_station_name; //到达站 string to_station_telecode; string to_station_name; string start_time; string arrive_time; string day_difference; string train_class_name; string lishi; string canWebBuy; string lishiValue; string yp_info; string control_train_day; string start_train_date; string seat_feature; string yp_ex; string train_seat_feature; string seat_types; string location_code; string from_station_no; string to_station_no; string control_day; string sale_time; string is_support_card; string controlled_train_flag; string controlled_train_message; string train_type_code; string start_province_code; string start_city_code; string end_province_code; string end_city_code; string swz_num; //商务座 string rz_num; //软座 string yz_num; //硬座 string gr_num; //高级软卧 string rw_num; //软卧 string yw_num; //硬卧 string tz_num; //特等座 string zy_num; //一等座 string ze_num; //二等座 string wz_num; //无座 string gg_num; string yb_num; string qt_num; }; struct ticketinfo { queryLeftNewDTO DTO; string secretStr; string buttonTextInfo; }; //var station_names = \u0026#39;@bjb|北京北|VAP|beijingbei|bjb|0@bjd|北京东|BOP|beijingdong|bjd|1@bji|北京|BJP|beijing|bj|2 struct stationinfo { string code1; string hanzi; string code2; string pingyin; string simplepingyin; int no; }; struct passenager { string code; //\u0026#34;8\u0026#34; string passenger_name; //\u0026#34;范蠡\u0026#34; string sex_code;// \u0026#34;M\u0026#34; string sex_name; // \u0026#34;男\u0026#34; string born_date; //\u0026#34;1989-12-08 00:00:00\u0026#34; string country_code;// \u0026#34;CN\u0026#34; string passenger_id_type_code;// \u0026#34;1\u0026#34; string passenger_id_type_name; // \u0026#34;二代身份证\u0026#34; string passenger_id_no; // \u0026#34;34262319781108812X\u0026#34; string passenger_type; // \u0026#34;1\u0026#34; string passenger_flag; // \u0026#34;0\u0026#34; string passenger_type_name; // \u0026#34;成人\u0026#34; string mobile_no; // \u0026#34;13917043320\u0026#34; string phone_no; string email; // \u0026#34;balloonwj@qq.com\u0026#34; string address; // \u0026#34;\u0026#34; string postalcode; // \u0026#34;\u0026#34; string first_letter;// \u0026#34;\u0026#34; string recordCount;// \u0026#34;13\u0026#34; string total_times;// \u0026#34;99\u0026#34; string index_id;// \u0026#34;0\u0026#34; }; class Client12306 { public: static Client12306\u0026amp; GetInstance(); private: Client12306(); ~Client12306(); private: Client12306(const Client12306\u0026amp;); Client12306\u0026amp; operator=(const Client12306\u0026amp;); public: bool ReloadVCodeImage(); /** * 游客查票 * https://kyfw.12306.cn/otn/leftTicket/query?leftTicketDTO.train_date=2017-05-24\u0026amp;leftTicketDTO.from_station=BJP\u0026amp;leftTicketDTO.to_station=SHH\u0026amp;purpose_codes=ADULT * 应答：{“validateMessagesShowId”:”_validatorMessage”,”status”:true,”httpstatus”:200,”messages”:[],”validateMessages”:{}} *@param: train_date列车发车日期，格式：2017-01-28 *@param: from_station出发站，格式：SHH 对应上海 *@parma: to_station到站,格式：BJP 对应北京 *@param: purpose_codes 票类型，成人票：ADULT 学生票：0X00 *@param: v 查票结果 */ bool GuestQueryTicket(const char* train_date, const char* from_station, const char* to_station, const char* purpose_codes, vector\u0026lt;ticketinfo\u0026gt;\u0026amp; v); /** * 初始化session，获取JSESSIONID */ bool loginInit(); bool DownloadVCodeImage(const char* module = \u0026#34;login\u0026#34;); /** *@return 0校验成功；1校验失败；2校验出错 */ int checkRandCodeAnsyn(const char* vcode); /** *@return 0校验成功；1校验失败；2校验出错 */ int loginAysnSuggest(const char* user, const char* pass, const char* vcode); /** * 正式登录 */ bool userLogin(); /** * 模拟12306跳转 */ bool initMy12306(); /** * 拉取乘客买票验证码 */ //bool GetVCodeImage(); /** * 拉取乘客买票验证码 */ /** * 查询余票第一步 * https://kyfw.12306.cn/otn/leftTicket/log?leftTicketDTO.train_date=2017-02-08\u0026amp;leftTicketDTO.from_station=SHH\u0026amp;leftTicketDTO.to_station=NJH\u0026amp;purpose_codes=ADULT * 应答：{“validateMessagesShowId”:”_validatorMessage”,”status”:true,”httpstatus”:200,”messages”:[],”validateMessages”:{}} *@param: train_date列车发车日期，格式：2017-01-28 *@param: from_station出发站，格式：SHH 对应上海 *@parma: to_station到站,格式：BJP 对应北京 *@param: purpose_codes 票类型，成人票：ADULT 学生票：0X00 */ bool QueryTickets1(const char* train_date, const char* from_station, const char* to_station, const char* purpose_codes); /** * 查询余票第二步 * 这几种情形都有可能，所以应该都尝试一下 * https://kyfw.12306.cn/otn/leftTicket/queryZ?leftTicketDTO.train_date=2017-02-08\u0026amp;leftTicketDTO.from_station=SHH\u0026amp;leftTicketDTO.to_station=NJH\u0026amp;purpose_codes=ADULT * https://kyfw.12306.cn/otn/leftTicket/queryX?leftTicketDTO.train_date=2017-02-08\u0026amp;leftTicketDTO.from_station=SHH\u0026amp;leftTicketDTO.to_station=NJH\u0026amp;purpose_codes=ADULT * https://kyfw.12306.cn/otn/leftTicket/query?leftTicketDTO.train_date=2017-02-08\u0026amp;leftTicketDTO.from_station=SHH\u0026amp;leftTicketDTO.to_station=NJH\u0026amp;purpose_codes=ADULT * {\u0026#34;status\u0026#34;:false,\u0026#34;c_url\u0026#34;:\u0026#34;leftTicket/query\u0026#34;,\u0026#34;c_name\u0026#34;:\u0026#34;CLeftTicketUrl\u0026#34;} * {\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;messages\u0026#34;:[\u0026#34;非法请求\u0026#34;],\u0026#34;validateMessages\u0026#34;:{}} * 应答中含有实际余票信息 *@param: train_date列车发车日期，格式：2017-01-28 *@param: from_station出发站，格式：SHH 对应上海 *@parma: to_station到站,格式：BJP 对应北京 *@param: purpose_codes 票类型，成人票：ADULT 学生票：0X00 */ bool QueryTickets2(const char* train_date, const char* from_station, const char* to_station, const char* purpose_codes, vector\u0026lt;ticketinfo\u0026gt;\u0026amp; v); /** * 检测用户是否登录 * https://kyfw.12306.cn/otn/login/checkUser POST _json_att= * Cookie: JSESSIONID=0A01D967FCD9827FC664E43DEE3C7C6EF950F677C2; __NRF=86A7CBA739653C1CC2C3C3AA7C88A1E3; BIGipServerotn=1742274826.64545.0000; BIGipServerportal=3134456074.17695.0000; current_captcha_type=Z; _jc_save_fromStation=%u4E0A%u6D77%2CSHH; _jc_save_toStation=%u5357%u4EAC%2CNJH; _jc_save_fromDate=2017-01-22; _jc_save_toDate=2017-01-22; _jc_save_wfdc_flag=dc * {\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;flag\u0026#34;:true},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} */ bool checkUser(); /** * 预提交订单 POST * https://kyfw.12306.cn/otn/leftTicket/submitOrderRequest?secretStr=secretStr\u0026amp;train_date=2017-01-21\u0026amp;back_train_date=2016-12-23\u0026amp;tour_flag=dc\u0026amp;purpose_codes=ADULT\u0026amp;query_from_station_name=深圳\u0026amp;query_to_station_name=武汉\u0026amp;undefined= */ bool submitOrderRequest(const char* secretStr, const char* train_date, const char* back_train_date, const char* tour_flag, const char* purpose_codes, const char* query_from_station_name, const char* query_to_station_name); /** * 模拟跳转页面InitDc，Post */ bool initDc(); /** * 拉取常用联系人 POST * https://kyfw.12306.cn/otn/confirmPassenger/getPassengerDTOs?_json_att=\u0026amp;REPEAT_SUBMIT_TOKEN=SubmitToken */ bool getPassengerDTOs(vector\u0026lt;passenager\u0026gt;\u0026amp; v); /** * 购票人确定 * https://kyfw.12306.cn/otn/confirmPassenger/checkOrderInfo @param oldPassengerStr oldPassengerStr组成的格式：乘客名,passenger_id_type_code,passenger_id_no,passenger_type，’_’ 示例： 张远龙,1,342623198912088150,1_ @param passengerTicketStr passengerTicketStr组成的格式：seatType,0,票类型（成人票填1）,乘客名,passenger_id_type_code,passenger_id_no,mobile_no,’N’ 示例： O,0,1,张远龙,1,342623198912088150,13917043320,N 101 @tour_flag dc表示单程票 应答：{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;ifShowPassCode\u0026#34;:\u0026#34;N\u0026#34;,\u0026#34;canChooseBeds\u0026#34;:\u0026#34;N\u0026#34;,\u0026#34;canChooseSeats\u0026#34;:\u0026#34;N\u0026#34;,\u0026#34;choose_Seats\u0026#34;:\u0026#34;MOP9\u0026#34;,\u0026#34;isCanChooseMid\u0026#34;:\u0026#34;N\u0026#34;,\u0026#34;ifShowPassCodeTime\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;submitStatus\u0026#34;:true,\u0026#34;smokeStr\u0026#34;:\u0026#34;\u0026#34;},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} */ bool checkOrderInfo(const char* oldPassengerStr, const char* passengerTicketStr, const char* tour_flag, bool\u0026amp; bVerifyVCode); /** * 准备进入排队 * https://kyfw.12306.cn/otn/confirmPassenger/getQueueCount _json_att 10 fromStationTelecode VNP 23 leftTicket enu80ehMzuVJlK2Q43c6kn5%2BzQF41LEI6Nr14JuzThrooN57 63 purpose_codes 00 16 REPEAT_SUBMIT_TOKEN 691c09b5605e46bfb2ec2380ee65de0e 52 seatType O 10 stationTrainCode G5 19 toStationTelecode AOH 21 train_date Fri Feb 10 00:00:00 UTC+0800 2017 50 train_location P2 17 train_no 24000000G502 21 应答：{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;count\u0026#34;:\u0026#34;4\u0026#34;,\u0026#34;ticket\u0026#34;:\u0026#34;669\u0026#34;,\u0026#34;op_2\u0026#34;:\u0026#34;false\u0026#34;,\u0026#34;countT\u0026#34;:\u0026#34;0\u0026#34;,\u0026#34;op_1\u0026#34;:\u0026#34;true\u0026#34;},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} */ bool getQueueCount(const char* fromStationTelecode, const char* leftTicket, const char* purpose_codes, const char* seatType, const char* stationTrainCode, const char* toStationTelecode, const char* train_date, const char* train_location, const char* train_no); /** * 确认购买 * https://kyfw.12306.cn/otn/confirmPassenger/confirmSingleForQueue _json_att 10 choose_seats 13 dwAll N 7 key_check_isChange 7503FD317E01E290C3D95CAA1D26DD8CFA9470C3643BA9799D3FB753 75 leftTicketStr enu80ehMzuVJlK2Q43c6kn5%2BzQF41LEI6Nr14JuzThrooN57 66 oldPassengerStr 张远龙,1,342623198912088150,1_ 73 passengerTicketStr O,0,1,张远龙,1,342623198912088150,13917043320,N 101 purpose_codes 00 16 randCode 9 REPEAT_SUBMIT_TOKEN 691c09b5605e46bfb2ec2380ee65de0e 52 roomType 00 11 seatDetailType 000 18 train_location P2 17 应答：{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;submitStatus\u0026#34;:true},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} */ bool confirmSingleForQueue(const char* leftTicketStr, const char* oldPassengerStr, const char* passengerTicketStr, const char* purpose_codes, const char* train_location); /** * 查询订单状态： https://kyfw.12306.cn/otn/confirmPassenger/queryOrderWaitTime?random=1486368851278\u0026amp;tourFlag=dc\u0026amp;_json_att=\u0026amp;REPEAT_SUBMIT_TOKEN=691c09b5605e46bfb2ec2380ee65de0e GET _json_att random 1486368851278 REPEAT_SUBMIT_TOKEN 691c09b5605e46bfb2ec2380ee65de0e tourFlag dc 响应：{\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;queryOrderWaitTimeStatus\u0026#34;:true,\u0026#34;count\u0026#34;:0,\u0026#34;waitTime\u0026#34;:-1,\u0026#34;requestId\u0026#34;:6234282826330508533,\u0026#34;waitCount\u0026#34;:0,\u0026#34;tourFlag\u0026#34;:\u0026#34;dc\u0026#34;,\u0026#34;orderId\u0026#34;:\u0026#34;E061149209\u0026#34;},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} */ bool queryOrderWaitTime(const char* tourflag, string\u0026amp; orderId); /** * https://kyfw.12306.cn/otn/confirmPassenger/resultOrderForDcQueue POST _json_att 10 orderSequence_no E061149209 27 REPEAT_SUBMIT_TOKEN 691c09b5605e46bfb2ec2380ee65de0e 52 {\u0026#34;validateMessagesShowId\u0026#34;:\u0026#34;_validatorMessage\u0026#34;,\u0026#34;status\u0026#34;:true,\u0026#34;httpstatus\u0026#34;:200,\u0026#34;data\u0026#34;:{\u0026#34;submitStatus\u0026#34;:true},\u0026#34;messages\u0026#34;:[],\u0026#34;validateMessages\u0026#34;:{}} */ //bool resultOrderForDcQueue(); /** * 未完成的订单页面 https://kyfw.12306.cn/otn/queryOrder/initNoComplete GET * 获取未完成的订单 https://kyfw.12306.cn/otn/queryOrder/queryMyOrderNoComplete POST _json_att= */ /* { \u0026#34;validateMessagesShowId\u0026#34;: \u0026#34;_validatorMessage\u0026#34;, \u0026#34;status\u0026#34;: true, \u0026#34;httpstatus\u0026#34;: 200, \u0026#34;data\u0026#34;: { \u0026#34;orderDBList\u0026#34;: [ { \u0026#34;sequence_no\u0026#34;: \u0026#34;E079331507\u0026#34;, \u0026#34;order_date\u0026#34;: \u0026#34;2017-02-09 10:10:55\u0026#34;, \u0026#34;ticket_totalnum\u0026#34;: 1, \u0026#34;ticket_price_all\u0026#34;: 55300, \u0026#34;cancel_flag\u0026#34;: \u0026#34;Y\u0026#34;, \u0026#34;resign_flag\u0026#34;: \u0026#34;4\u0026#34;, \u0026#34;return_flag\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;print_eticket_flag\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;pay_flag\u0026#34;: \u0026#34;Y\u0026#34;, \u0026#34;pay_resign_flag\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;confirm_flag\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;tickets\u0026#34;: [ { \u0026#34;stationTrainDTO\u0026#34;: { \u0026#34;trainDTO\u0026#34;: {}, \u0026#34;station_train_code\u0026#34;: \u0026#34;G41\u0026#34;, \u0026#34;from_station_telecode\u0026#34;: \u0026#34;VNP\u0026#34;, \u0026#34;from_station_name\u0026#34;: \u0026#34;北京南\u0026#34;, \u0026#34;start_time\u0026#34;: \u0026#34;1970-01-01 09:16:00\u0026#34;, \u0026#34;to_station_telecode\u0026#34;: \u0026#34;AOH\u0026#34;, \u0026#34;to_station_name\u0026#34;: \u0026#34;上海虹桥\u0026#34;, \u0026#34;arrive_time\u0026#34;: \u0026#34;1970-01-01 14:48:00\u0026#34;, \u0026#34;distance\u0026#34;: \u0026#34;1318\u0026#34; }, \u0026#34;passengerDTO\u0026#34;: { \u0026#34;passenger_name\u0026#34;: \u0026#34;范蠡\u0026#34;, \u0026#34;passenger_id_type_code\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;passenger_id_type_name\u0026#34;: \u0026#34;二代身份证\u0026#34;, \u0026#34;passenger_id_no\u0026#34;: \u0026#34;34262319781108815X\u0026#34;, \u0026#34;total_times\u0026#34;: \u0026#34;98\u0026#34; }, \u0026#34;ticket_no\u0026#34;: \u0026#34;E079331507110008B\u0026#34;, \u0026#34;sequence_no\u0026#34;: \u0026#34;E079331507\u0026#34;, \u0026#34;batch_no\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;train_date\u0026#34;: \u0026#34;2017-02-11 00:00:00\u0026#34;, \u0026#34;coach_no\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;coach_name\u0026#34;: \u0026#34;10\u0026#34;, \u0026#34;seat_no\u0026#34;: \u0026#34;008B\u0026#34;, \u0026#34;seat_name\u0026#34;: \u0026#34;08B号\u0026#34;, \u0026#34;seat_flag\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;seat_type_code\u0026#34;: \u0026#34;O\u0026#34;, \u0026#34;seat_type_name\u0026#34;: \u0026#34;二等座\u0026#34;, \u0026#34;ticket_type_code\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;ticket_type_name\u0026#34;: \u0026#34;成人票\u0026#34;, \u0026#34;reserve_time\u0026#34;: \u0026#34;2017-02-09 10:10:55\u0026#34;, \u0026#34;limit_time\u0026#34;: \u0026#34;2017-02-09 10:10:55\u0026#34;, \u0026#34;lose_time\u0026#34;: \u0026#34;2017-02-09 10:40:55\u0026#34;, \u0026#34;pay_limit_time\u0026#34;: \u0026#34;2017-02-09 10:40:55\u0026#34;, \u0026#34;ticket_price\u0026#34;: 55300, \u0026#34;print_eticket_flag\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;resign_flag\u0026#34;: \u0026#34;4\u0026#34;, \u0026#34;return_flag\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;confirm_flag\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;pay_mode_code\u0026#34;: \u0026#34;Y\u0026#34;, \u0026#34;ticket_status_code\u0026#34;: \u0026#34;i\u0026#34;, \u0026#34;ticket_status_name\u0026#34;: \u0026#34;待支付\u0026#34;, \u0026#34;cancel_flag\u0026#34;: \u0026#34;Y\u0026#34;, \u0026#34;amount_char\u0026#34;: 0, \u0026#34;trade_mode\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;start_train_date_page\u0026#34;: \u0026#34;2017-02-11 09:16\u0026#34;, \u0026#34;str_ticket_price_page\u0026#34;: \u0026#34;553.0\u0026#34;, \u0026#34;come_go_traveller_ticket_page\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;return_deliver_flag\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;deliver_fee_char\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;is_need_alert_flag\u0026#34;: false, \u0026#34;is_deliver\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;dynamicProp\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;fee_char\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;insure_query_no\u0026#34;: \u0026#34;\u0026#34; } ], \u0026#34;reserve_flag_query\u0026#34;: \u0026#34;p\u0026#34;, \u0026#34;if_show_resigning_info\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;recordCount\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;isNeedSendMailAndMsg\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;array_passser_name_page\u0026#34;: [ \u0026#34;张远龙\u0026#34; ], \u0026#34;from_station_name_page\u0026#34;: [ \u0026#34;北京南\u0026#34; ], \u0026#34;to_station_name_page\u0026#34;: [ \u0026#34;上海虹桥\u0026#34; ], \u0026#34;start_train_date_page\u0026#34;: \u0026#34;2017-02-11 09:16\u0026#34;, \u0026#34;start_time_page\u0026#34;: \u0026#34;09:16\u0026#34;, \u0026#34;arrive_time_page\u0026#34;: \u0026#34;14:48\u0026#34;, \u0026#34;train_code_page\u0026#34;: \u0026#34;G41\u0026#34;, \u0026#34;ticket_total_price_page\u0026#34;: \u0026#34;553.0\u0026#34;, \u0026#34;come_go_traveller_order_page\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;canOffLinePay\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;if_deliver\u0026#34;: \u0026#34;N\u0026#34;, \u0026#34;insure_query_no\u0026#34;: \u0026#34;\u0026#34; } ], \u0026#34;to_page\u0026#34;: \u0026#34;db\u0026#34; }, \u0026#34;messages\u0026#34;: [], \u0026#34;validateMessages\u0026#34;: {} } */ /** * 已完成订单（改/退） : https://kyfw.12306.cn/otn/queryOrder/queryMyOrder POST * queryType 1 按订票日期 2 按乘车日期 * 查询日期queryStartDate=2017-02-09\u0026amp;queryEndDate=2017-02-09 * come_from_flag: my_order 全部 my_resign 可改签 my_cs_resign 可变更到站 my_refund 可退票 * \u0026amp;pageSize=8\u0026amp;pageIndex=0\u0026amp; * query_where G 未出行订单 H 历史订单 * sequeue_train_name 订单号/车次/乘客姓名 */ /* 历史订单格式 参见[历史订单.txt] */ /** * 获取全国车站信息 *@param si 返回的车站信息 *@param bForceDownload 强制从网络上下载，即不使用本地副本 */ bool GetStationInfo(vector\u0026lt;stationinfo\u0026gt;\u0026amp; si, bool bForceDownload = false); /** * 获取所有高校信息 https://kyfw.12306.cn/otn/userCommon/schoolNames POST provinceCode=11\u0026amp;_json_att= */ /** * 获取所有城市信息 https://kyfw.12306.cn/otn/userCommon/allCitys POST station_name=\u0026amp;_json_att= */ /** * 查询常用联系人 */ bool QueryPassengers(int pageindex = 2, int pagesize = 10); bool GetVCodeFileName(char* pszDst, int nLength); private: bool GetCookies(const string\u0026amp; data); /** * 发送一个http请求 *@param url 请求的url *@param strResponse http响应结果 *@param get true为GET，false为POST *@param headers 附带发送的http头信息 *@param postdata post附带的数据 *@param bReserveHeaders http响应结果是否保留头部信息 *@param timeout http请求超时时间 */ bool HttpRequest(const char* url, string\u0026amp; strResponse, bool get = true, const char* headers = NULL, const char* postdata = NULL, bool bReserveHeaders = false, int timeout = 10); private: char m_szCurrVCodeName[256]; //当前验证码图片的名称 string m_strCookies; string m_strGlobalRepeatSubmitToken; string m_strKeyCheckIsChange; }; #endif //!__CLIENT_12306_H__ 具体的实现代码就不在文章中贴出来了，您可以下载我的代码。下载地址在微信公众号『easyserverdev』中回复『12306源码』即可得到下载地址，当然，由于12306的接口经常发生改变，当你拿到代码时，可能12306服务器的接口已经稍微发生了改变，您可以按上面介绍的原理做响应的修改。\n最后当您实现了基本的登录和购票功能后，你就可以不断模拟某些请求去进行刷票了，这就是刷票的基本原理。\n","permalink":"https://haokiu.com/blog/42f423476e5d4262bcb032f3cf4c40d3/","summary":"从零实现一款12306刷票软件 写在前面的话\n每年逢年过节，一票难求读者肯定不陌生。这篇文章，我们带领读者从零实现一款12306刷票软件，其核心原理是通过发送http请求模拟登录12306网站的购票的过程，最后买到票。\n关于http请求的格式和如何组装http数据包给服务器发送请求，我们在上一篇文章《从零实现一个http服务器》中已经详细介绍过了，如果还不明白的朋友可以去那篇文章看下。\n郑重申明一下：这里介绍的技术仅供用于学习，不可用于恶意攻击12306服务器，请勿滥用本文介绍的技术。对12306服务器造成的任何损失，后果自负。\n当然，由于12306服务器用户量巨大，为了防止黄牛和其他一些非法攻击者，12306的很多url和在购票过程中各个步骤的协议细节经常发生变化。所以，本文中介绍的一些具体的url，可能在你看到本文时已经失效。但是这并没有关系，只要你掌握了本文中介绍的分析方法，您就可以灵活地修改您的代码，以适应最新的12306服务器的要求。\n举个例子，如12306的查票接口目前的url是：\nhttps://kyfw.12306.cn/otn/leftTicket/query 可能过几天就变成了\nhttps://kyfw.12306.cn/otn/leftTicket/queryX 再过几天又可能变成\nhttps://kyfw.12306.cn/otn/leftTicket/queryY 然后一个星期后又可能变成\nhttps://kyfw.12306.cn/otn/leftTicket/queryZ 这些笔者都见过。所以，重在原理的学习，掌握了原理，不管12306的相关url变成什么样，都可以以不变应万变。哎，12306在与黄牛的斗争中越走越远啊T_T\n本文将使用以下工具来分析12306购票的过程，然后使用C++语言，模拟相关的过程，最终购票。\nChrome浏览器（其他的浏览器也可以，都有类似的界面，如Chrome，装了httpwatch的IE浏览器等） 一个可以登录12306网址并且可以购票的12306账号 Visual Studio（版本随意，我这里用的是VS 2013） 一、查票与站点信息接口\n之所以先分析这个接口，是因为查票不需要用户登录的，相对来说最简单。我们在Chrome浏览器中打开12306余票查询页面，网址是：https://kyfw.12306.cn/otn/leftTicket/init，如下图所示：\n然后在页面中右键菜单中选择【检查】菜单，打开后，选择【网络】选项卡。如下图所示：\n打开后页面变成二分窗口了，左侧是正常的网页页面，右侧是浏览器自带的控制台，当我们在左侧页面中进行操作后，右侧会显示我们浏览器发送的各种http请求和应答。我们这里随便查一个票吧，如查2018年5月20日从上海到北京的票，点击12306网页中【查询】按钮后，我们发现右侧是这样的：\n通过图中列表的type值是xhr，我们可以得出这是一个ajax请求（ajax是一种浏览器原生支持的异步技术，具体细节请读者自行搜索）。我们选择这个请求，你能看到这个请求的细节——请求和响应结果：\n在reponse中，我们可以看到我们的这个http的去除http头的响应结果（包体，可能是解压缩或者解码后的）：\n这是一个json格式，我们找个json格式化工具，把这个json格式化后贴出来给大家看一下，其实您后面会发现12306的http请求结果中与购票相关的数据基本上都是json格式。这里的json如下：\n{ \u0026#34;validateMessagesShowId\u0026#34;: \u0026#34;_validatorMessage\u0026#34;, \u0026#34;status\u0026#34;: true, \u0026#34;httpstatus\u0026#34;: 200, \u0026#34;data\u0026#34;: { \u0026#34;result\u0026#34;: [\u0026#34;null|23:00-06:00系统维护时间|5l0000G10270|G102|AOH|VNP|AOH|VNP|06:26|12:29|06:03|IS_TIME_NOT_BUY|RLVVIt093U2EZuy2NE+VQyRloXyqTzFp6YyNk6J52QcHEA01|20180520|3|HZ|01|11|1|0|||||||||||1|有|13||O090M0|O9M|0\u0026#34;,(内容太长，这里省略) \u0026#34;], \u0026#34;flag\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;map\u0026#34;: { \u0026#34;AOH\u0026#34;: \u0026#34;上海虹桥\u0026#34;, \u0026#34;BJP\u0026#34;: \u0026#34;北京\u0026#34;, \u0026#34;VNP\u0026#34;: \u0026#34;北京南\u0026#34;, \u0026#34;SHH\u0026#34;: \u0026#34;上海\u0026#34; } }, \u0026#34;messages\u0026#34;: [], \u0026#34;validateMessages\u0026#34;: {} } 其中含有的余票信息在result节点中，这是一个数组。每个节点以|分割，我们可以格式化后显示在自己的界面上：\n我这里做的界面比较简陋，读者如果有兴趣可以做更精美的界面。我们列下这个请求发送的http数据包和应答包：\n请求包：\nGET /otn/leftTicket/query?leftTicketDTO.train_date=2018-05-20\u0026amp;leftTicketDTO.from_station=SHH\u0026amp;leftTicketDTO.to_station=BJP\u0026amp;purpose_codes=ADULT HTTP/1.1 Host: kyfw.12306.cn Connection: keep-alive Cache-Control: no-cache Accept: */* X-Requested-With: XMLHttpRequest If-Modified-Since: 0 User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.181 Safari/537.36 Referer: https://kyfw.12306.cn/otn/leftTicket/init Accept-Encoding: gzip, deflate, br Accept-Language: zh-CN,zh;q=0.9,en;q=0.8 Cookie: RAIL_EXPIRATION=1526978933395; RAIL_DEVICEID=WKxIYg-q1zjIPVu7VjulZ9PqEGvW2gUB9LvoM1Vx8fa7l3SUwnO_BVSatbTq506c6VYNOaxAiRaUcGFTMjCz9cPayEIc9vJ0pHaXdSqDlujJP8YrIoXbpAAs60l99z8bEtnHgAJzxLzKiv2nka5nmLY_BMNur8b8; _jc_save_fromStation=%u4E0A%u6D77%2CSHH; _jc_save_toStation=%u5317%u4EAC%2CBJP; _jc_save_fromDate=2018-05-20; _jc_save_toDate=2018-05-19; _jc_save_wfdc_flag=dc 应答包：","title":"从零实现一款12306刷票软件"},{"content":"从零开发一个WebSocket服务器 WebSocket 协议是为了解决 http 协议的无状态、短连接（通常是）和服务端无法主动给客户端推送数据等问题而开发的新型协议，其通信基础也是基于 TCP。由于较旧的浏览器可能不支持 WebSocket 协议，所以使用 WebSocket 协议的通信双方在进行 TCP 三次握手之后，还要再额外地进行一次握手，这一次的握手通信双方的报文格式是基于 HTTP 协议改造的。\nWebSocket 握手过程 TCP 三次握手的过程我们就不在这里赘述了，任何一本网络通信书籍上都有详细的介绍。我们这里来介绍一下 WebSocket 通信最后一次的握手过程。\n握手开始后，一方给另外一方发送一个 http 协议格式的报文，这个报文格式大致如下：\nGET /realtime HTTP/1.1\\r\\n Host: 127.0.0.1:9989\\r\\n Connection: Upgrade\\r\\n Pragma: no-cache\\r\\n Cache-Control: no-cache\\r\\n User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64)\\r\\n Upgrade: websocket\\r\\n Origin: http://xyz.com\\r\\n Sec-WebSocket-Version: 13\\r\\n Accept-Encoding: gzip, deflate, br\\r\\n Accept-Language: zh-CN,zh;q=0.9,en;q=0.8\\r\\n Sec-WebSocket-Key: IqcAWodjyPDJuhGgZwkpKg==\\r\\n Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits\\r\\n \\r\\n 对这个格式有如下要求：\n握手必须是一个有效的 HTTP 请求； 请求的方法必须为 GET，且 HTTP 版本必须是 1.1； 请求必须包含 Host 字段信息； 请求必须包含 Upgrade字段信息，值必须为 websocket； 请求必须包含 Connection 字段信息，值必须为 Upgrade； 请求必须包含 Sec-WebSocket-Key 字段，该字段值是客户端的标识编码成 base64 格式； 请求必须包含 Sec-WebSocket-Version 字段信息，值必须为 13； 请求必须包含 Origin 字段； 请求可能包含 Sec-WebSocket-Protocol 字段，规定子协议； 请求可能包含 Sec-WebSocket-Extensions字段规定协议扩展； 请求可能包含其他字段，如 cookie 等。 对端收到该数据包后如果支持 WebSocket 协议，会回复一个 http 格式的应答，这个应答报文的格式大致如下：\nHTTP/1.1 101 Switching Protocols\\r\\n Upgrade: websocket\\r\\n Connection: Upgrade\\r\\n Sec-WebSocket-Accept: 5wC5L6joP6tl31zpj9OlCNv9Jy4=\\r\\n \\r\\n 上面列出了应答报文中必须包含的几个字段和对应的值，即 Upgrade、Connection、Sec-WebSocket-Accept，注意：第一行必须是 HTTP/1.1 101 Switching Protocols\\r\\n。\n对于字段 Sec-WebSocket-Accept 字段，其值是根据对端传过来的 Sec-WebSocket-Key 的值经过一定的算法计算出来的，这样应答的双方才能匹配。算法如下：\n将 Sec-WebSocket-Key 值与固定字符串“258EAFA5-E914-47DA-95CA-C5AB0DC85B11” 进行拼接； 将拼接后的字符串进行 SHA-1 处理，然后将结果再进行 base64 编码。 算法公式：\nmask = \u0026#34;258EAFA5-E914-47DA-95CA-C5AB0DC85B11\u0026#34;; // 这是算法中要用到的固定字符串 accept = base64( sha1( Sec-WebSocket-Key + mask ) ); 我用 C++ 实现了该算法：\nnamespace uWS { struct WebSocketHandshake { template \u0026lt;int N, typename T\u0026gt; struct static_for { void operator()(uint32_t *a, uint32_t *b) { static_for\u0026lt;N - 1, T\u0026gt;()(a, b); T::template f\u0026lt;N - 1\u0026gt;(a, b); } }; template \u0026lt;typename T\u0026gt; struct static_for\u0026lt;0, T\u0026gt; { void operator()(uint32_t *a, uint32_t *hash) {} }; template \u0026lt;int state\u0026gt; struct Sha1Loop { static inline uint32_t rol(uint32_t value, size_t bits) {return (value \u0026lt;\u0026lt; bits) | (value \u0026gt;\u0026gt; (32 - bits));} static inline uint32_t blk(uint32_t b[16], size_t i) { return rol(b[(i + 13) \u0026amp; 15] ^ b[(i + 8) \u0026amp; 15] ^ b[(i + 2) \u0026amp; 15] ^ b[i], 1); } template \u0026lt;int i\u0026gt; static inline void f(uint32_t *a, uint32_t *b) { switch (state) { case 1: a[i % 5] += ((a[(3 + i) % 5] \u0026amp; (a[(2 + i) % 5] ^ a[(1 + i) % 5])) ^ a[(1 + i) % 5]) + b[i] + 0x5a827999 + rol(a[(4 + i) % 5], 5); a[(3 + i) % 5] = rol(a[(3 + i) % 5], 30); break; case 2: b[i] = blk(b, i); a[(1 + i) % 5] += ((a[(4 + i) % 5] \u0026amp; (a[(3 + i) % 5] ^ a[(2 + i) % 5])) ^ a[(2 + i) % 5]) + b[i] + 0x5a827999 + rol(a[(5 + i) % 5], 5); a[(4 + i) % 5] = rol(a[(4 + i) % 5], 30); break; case 3: b[(i + 4) % 16] = blk(b, (i + 4) % 16); a[i % 5] += (a[(3 + i) % 5] ^ a[(2 + i) % 5] ^ a[(1 + i) % 5]) + b[(i + 4) % 16] + 0x6ed9eba1 + rol(a[(4 + i) % 5], 5); a[(3 + i) % 5] = rol(a[(3 + i) % 5], 30); break; case 4: b[(i + 8) % 16] = blk(b, (i + 8) % 16); a[i % 5] += (((a[(3 + i) % 5] | a[(2 + i) % 5]) \u0026amp; a[(1 + i) % 5]) | (a[(3 + i) % 5] \u0026amp; a[(2 + i) % 5])) + b[(i + 8) % 16] + 0x8f1bbcdc + rol(a[(4 + i) % 5], 5); a[(3 + i) % 5] = rol(a[(3 + i) % 5], 30); break; case 5: b[(i + 12) % 16] = blk(b, (i + 12) % 16); a[i % 5] += (a[(3 + i) % 5] ^ a[(2 + i) % 5] ^ a[(1 + i) % 5]) + b[(i + 12) % 16] + 0xca62c1d6 + rol(a[(4 + i) % 5], 5); a[(3 + i) % 5] = rol(a[(3 + i) % 5], 30); break; case 6: b[i] += a[4 - i]; } } }; /** * sha1 函数的实现 */ static inline void sha1(uint32_t hash[5], uint32_t b[16]) { uint32_t a[5] = {hash[4], hash[3], hash[2], hash[1], hash[0]}; static_for\u0026lt;16, Sha1Loop\u0026lt;1\u0026gt;\u0026gt;()(a, b); static_for\u0026lt;4, Sha1Loop\u0026lt;2\u0026gt;\u0026gt;()(a, b); static_for\u0026lt;20, Sha1Loop\u0026lt;3\u0026gt;\u0026gt;()(a, b); static_for\u0026lt;20, Sha1Loop\u0026lt;4\u0026gt;\u0026gt;()(a, b); static_for\u0026lt;20, Sha1Loop\u0026lt;5\u0026gt;\u0026gt;()(a, b); static_for\u0026lt;5, Sha1Loop\u0026lt;6\u0026gt;\u0026gt;()(a, hash); } /** * base64 编码函数 */ static inline void base64(unsigned char *src, char *dst) { const char *b64 = \u0026#34;ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\u0026#34;; for (int i = 0; i \u0026lt; 18; i += 3) { *dst++ = b64[(src[i] \u0026gt;\u0026gt; 2) \u0026amp; 63]; *dst++ = b64[((src[i] \u0026amp; 3) \u0026lt;\u0026lt; 4) | ((src[i + 1] \u0026amp; 240) \u0026gt;\u0026gt; 4)]; *dst++ = b64[((src[i + 1] \u0026amp; 15) \u0026lt;\u0026lt; 2) | ((src[i + 2] \u0026amp; 192) \u0026gt;\u0026gt; 6)]; *dst++ = b64[src[i + 2] \u0026amp; 63]; } *dst++ = b64[(src[18] \u0026gt;\u0026gt; 2) \u0026amp; 63]; *dst++ = b64[((src[18] \u0026amp; 3) \u0026lt;\u0026lt; 4) | ((src[19] \u0026amp; 240) \u0026gt;\u0026gt; 4)]; *dst++ = b64[((src[19] \u0026amp; 15) \u0026lt;\u0026lt; 2)]; *dst++ = \u0026#39;=\u0026#39;; } public: /** * 生成 Sec-WebSocket-Accept 算法 * @param input 对端传过来的Sec-WebSocket-Key值 * @param output 存放生成的 Sec-WebSocket-Accept 值 */ static inline void generate(const char input[24], char output[28]) { uint32_t b_output[5] = { 0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0 }; uint32_t b_input[16] = { 0, 0, 0, 0, 0, 0, 0x32353845, 0x41464135, 0x2d453931, 0x342d3437, 0x44412d39, 0x3543412d, 0x43354142, 0x30444338, 0x35423131, 0x80000000 }; for (int i = 0; i \u0026lt; 6; i++) { b_input[i] = (input[4 * i + 3] \u0026amp; 0xff) | (input[4 * i + 2] \u0026amp; 0xff) \u0026lt;\u0026lt; 8 | (input[4 * i + 1] \u0026amp; 0xff) \u0026lt;\u0026lt; 16 | (input[4 * i + 0] \u0026amp; 0xff) \u0026lt;\u0026lt; 24; } sha1(b_output, b_input); uint32_t last_b[16] = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 480}; sha1(b_output, last_b); for (int i = 0; i \u0026lt; 5; i++) { uint32_t tmp = b_output[i]; char *bytes = (char *) \u0026amp;b_output[i]; bytes[3] = tmp \u0026amp; 0xff; bytes[2] = (tmp \u0026gt;\u0026gt; 8) \u0026amp; 0xff; bytes[1] = (tmp \u0026gt;\u0026gt; 16) \u0026amp; 0xff; bytes[0] = (tmp \u0026gt;\u0026gt; 24) \u0026amp; 0xff; } base64((unsigned char *) b_output, output); } }; 握手完成之后，通信双方就可以保持连接并相互发送数据了。\nWebSocket 协议格式 WebSocket 协议格式的 RFC 文档可以参见：[]https://tools.ietf.org/html/rfc6455。\n常听人说 WebSocket 协议是基于 http 协议的，因此我在刚接触 WebSocket 协议时总以为每个 WebSocket 数据包都是 http 格式，其实不然，WebSocket 协议除了上文中提到的这次握手过程中使用的数据格式是 http 协议格式，之后的通信双方使用的是另外一种自定义格式。每一个 WebSocket 数据包我们称之为一个 Frame（帧），其格式图如下：\n我们来逐一介绍一下上文中各字段的含义：\n第一个字节内容：\nFIN 标志，占第一个字节中的第一位（bit），即一字节中的最高位（一字节等于 8 位），该标志置 0 时表示当前包未结束后续有该包的分片，置 1 时表示当前包已结束后续无该包的分片。我们在解包时，如果发现该标志为 1，则需要将当前包的“包体”数据（即图中 Payload Data）缓存起来，与后续包分片组装在一起，才是一个完整的包体数据。\nRSV1、RSV2、RSV3 每个占一位，一共三位，这三个位是保留字段（默认都是 0），你可以用它们作为通信的双方协商好的一些特殊标志；\nopCode 操作类型，占四位，目前操作类型及其取值如下：\n// 4 bits enum OpCode { //表示后续还有新的 Frame CONTINUATION_FRAME = 0x0, //包体是文本类型的Frame TEXT_FRAME = 0x1, //包体是二进制类型的 Frame BINARY_FRAME = 0x2, //保留值 RESERVED1 = 0x3, RESERVED2 = 0x4, RESERVED3 = 0x5, RESERVED4 = 0x6, RESERVED5 = 0x7, //建议对端关闭的 Frame CLOSE = 0x8, //心跳包中的 ping Frame PING = 0x9, //心跳包中的 pong Frame PONG = 0xA, //保留值 RESERVED6 = 0xB, RESERVED7 = 0xC, RESERVED8 = 0xD, RESERVED9 = 0xE, RESERVED10 = 0xF }; 第二个字节内容：\nmask 标志，占一位，该标志为 1 时，表明该 Frame 在包体长度字段后面携带 4 个字节的 masking-key 信息，为 0 时则没有 masking-key 信息。masking-key 信息下文会介绍。\nPayload len，占七位，该字段表示包体的长度信息。由于 Payload length 值使用了一个字节的低七位（7 bit），因此其能表示的长度范围是 0 ~ 127，其中 126 和 127 被当做特殊标志使用。\n当该字段值是 0~125 时，表示跟在 masking-key 字段后面的就是包体内容长度；当该值是 126 时，接下来的 2 个字节内容表示跟在 masking-key 字段后面的包体内容的长度（即图中的 Extended Payload Length）。由于 2 个字节最大表示的无符号整数是 0xFFFF（十进制是 65535， 编译器提供了一个宏 UINT16_MAX 来表示这个值）。如果包体长度超过 65535，包长度就记录不下了，此时应该将 Payload length 设置为 127，以使用更多的字节数来表示包体长度。\n当 Payload length 是 127 时，接下来则用 8 个字节内容表示跟在 masking-key 字段后面的包体内容的长度（Extended Payload Length）。\n总结起来，Payload length = 0 ~ 125，Extended Payload Length 不存在， 0 字节；Payload length = 126, Extended Payload Length 占 2 字节；Payload length = 127 时，Extended Payload Length 占 8 字节。\n另外需要注意的是，当 Payload length = 125 或 126 时接下来存储实际包长的 2 字节或 8 字节，其值必须转换为网络字节序（Big Endian）。\nMasking-key ，如果前面的 mask 标志设置成 1，则该字段存在，占 4 个字节；反之，则 Frame 中不存在存储 masking-key 字段的字节。 网络上一些资料说，客户端（主动发起握手请求的一方）给服务器（被动接受握手的另一方）发的 frame 信息（包信息），mask 标志必须是 1，而服务器给客户端发送的 frame 信息中 mask 标志是 0。因此，客户端发给服务器端的数据帧中存在 4 字节的 masking-key，而服务器端发给客户端的数据帧中不存在 masking-key 信息。\n我在 Websocket 协议的 RFC 文档中并没有看到有这种强行规定，另外在研究了一些 websocket 库的实现后发现，此结论并不一定成立，客户端发送的数据也可能没有设置 mask 标志。\n如果存在 masking-key 信息，则数据帧中的数据（图中 Payload Data）都是经过与 masking-key 进行运算后的内容。无论是将原始数据与 masking-key 运算后得到传输的数据，还是将传输的数据还原成原始数据，其算法都是一样的。算法如下：\n假设： original-octet-i：为原始数据的第 i 字节。 transformed-octet-i：为转换后的数据的第 i 字节。 j：为i mod 4的结果。 masking-key-octet-j：为 mask key 第 j 字节。 算法描述为：original-octet-i 与 masking-key-octet-j 异或后，得到 transformed-octet-i。\nj = i MOD 4 transformed-octet-i = original-octet-i XOR masking-key-octet-j 我用 C++ 实现了该算法：\n/** * @param src 函数调用前是原始需要传输的数据，函数调用后是mask或者unmask后的内容 * @param maskingKey 四字节 */ void maskAndUnmaskData(std::string\u0026amp; src, const char* maskingKey) { char j; for (size_t n = 0; n \u0026lt; src.length(); ++n) { j = n % 4; src[n] = src[n] ^ maskingKey[j]; } } 使用上面的描述可能还不是太清楚，我们举个例子，假设有一个客户端发送给服务器的数据包，那么 mask = 1，即存在 4 字节的 masking-key，当包体数据长度在 0 ~ 125 之间时，该包的结构：\n第 1 个字节第 0 位 =\u0026gt; FIN 第 1 个字节第 1 ~ 3位 =\u0026gt; RSV1 + RSV2 + RSV3 第 1 个字节第 4 ~ 7位 =\u0026gt; opcode 第 2 个字节第 0 位 =\u0026gt; mask(等于 1) 第 2 个字节第 1 ~ 7位 =\u0026gt; 包体长度 第 3 ~ 6 个字节 =\u0026gt; masking-key 第 7 个字节及以后 =\u0026gt; 包体内容 这种情形，包头总共 6 个字节。\n当包体数据长度大于125 且小于等于 UINT16_MAX 时，该包的结构：\n第 1 个字节第 0 位 =\u0026gt; FIN 第 1 个字节第 1 ~ 3位 =\u0026gt; RSV1 + RSV2 + RSV3 第 1 个字节第 4 ~ 7位 =\u0026gt; opcode 第 2 个字节第 0 位 =\u0026gt; mask(等于 1) 第 2 个字节第 1 ~ 7位 =\u0026gt; 开启扩展包头长度标志，值为 126 第 3 ~ 4 个字节 =\u0026gt; 包头长度 第 5 ~ 8 个字节 =\u0026gt; masking-key 第 9 个字节及以后 =\u0026gt; 包体内容 这种情形，包头总共 8 个字节。\n当包体数据长度大于 UINT16_MAX 时，该包的结构：\n第 1 个字节第 0 位 =\u0026gt; FIN 第 1 个字节第 1 ~ 3位 =\u0026gt; RSV1 + RSV2 + RSV3 第 1 个字节第 4 ~ 7位 =\u0026gt; opcode 第 2 个字节第 0 位 =\u0026gt; mask(等于 1) 第 2 个字节第 1 ~ 7位 =\u0026gt; 开启扩展包头长度标志，值为 127 第 3 ~ 10 个字节 =\u0026gt; 包头长度 第 11 ~ 14 个字节 =\u0026gt; masking-key 第 15 个字节及以后 =\u0026gt; 包体内容 这种情形，包头总共 14 个字节。由于存储包体长度使用 8 字节存储（无符号），因此最大包体长度是 0xFFFFFFFFFFFFFFFF，这是一个非常大的数字，但实际开发中，我们用不到这么长的包体，且当包体超过一定值时，我们就应该分包（分片）了。\n分包的逻辑经过前面的分析也很简单，假设将一个包分成 3 片，那么应将第一个和第二个包片的第一个字节的第一位 FIN 设置为 0，OpCode 设置为 CONTINUATION_FRAME（也是 0）；第三个包片 FIN 设置为 1，表示该包至此就结束了，OpCode 设置为想要的类型（如 TEXT_FRAME、BINARY_FRAME 等）。对端收到该包时，如果发现标志 FIN = 0 或 OpCode = 0，将该包包体的数据暂存起来，直到收到 FIN = 1，OpCode ≠ 0 的包，将该包的数据与前面收到的数据放在一起，组装成一个完整的业务数据。示例代码如下：\n//某次解包后得到包体 payloadData，根据 FIN 标志判断， //如果 FIN = true，则说明一个完整的业务数据包已经收完整， //调用 processPackage() 函数处理该业务数据 //否则，暂存于 m_strParsedData 中 //每次处理完一个完整的业务包数据，即将暂存区m_strParsedData中的数据清空 if (FIN) { m_strParsedData.append(payloadData); processPackage(m_strParsedData); m_strParsedData.clear(); } else { m_strParsedData.append(payloadData); } WebSocket 压缩格式 WebSocket 对于包体也支持压缩的，是否需要开启压缩需要通信双方在握手时进行协商。让我们再看一下握手时主动发起一方的包内容：\nGET /realtime HTTP/1.1\\r\\n Host: 127.0.0.1:9989\\r\\n Connection: Upgrade\\r\\n Pragma: no-cache\\r\\n Cache-Control: no-cache\\r\\n User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64)\\r\\n Upgrade: websocket\\r\\n Origin: http://xyz.com\\r\\n Sec-WebSocket-Version: 13\\r\\n Accept-Encoding: gzip, deflate, br\\r\\n Accept-Language: zh-CN,zh;q=0.9,en;q=0.8\\r\\n Sec-WebSocket-Key: IqcAWodjyPDJuhGgZwkpKg==\\r\\n Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits\\r\\n \\r\\n 在该包中 Sec-WebSocket-Extensions 字段中有一个值 permessage-deflate，如果发起方支持压缩，在发起握手时将包中带有该标志，对端收到后，如果也支持压缩，则在应答的包也带有该字段，反之不带该标志即表示不支持压缩。例如：\nHTTP/1.1 101 Switching Protocols\\r\\n Upgrade: websocket\\r\\n Connection: Upgrade\\r\\n Sec-WebSocket-Accept: 5wC5L6joP6tl31zpj9OlCNv9Jy4=\\r\\n Sec-WebSocket-Extensions: permessage-deflate; client_no_context_takeover \\r\\n 如果双方都支持压缩，此后通信的包中的包体部分都是经过压缩后的，反之是未压缩过的。在解完包得到包体（即 Payload Data） 后，如果有握手时有压缩标志并且乙方也回复了支持压缩，则需要对该包体进行解压；同理，在发数据组装 WebSocket 包时，需要先将包体（即 Payload Data）进行压缩。\n收到包需要解压示例代码：\nbool MyWebSocketSession::processPackage(const std::string\u0026amp; data) { std::string out; //m_bClientCompressed在握手确定是否支持压缩 if (m_bClientCompressed) { //解压 if (!ZlibUtil::inflate(data, out)) { LOGE(\u0026#34;uncompress failed, dataLength: %d\u0026#34;, data.length()); return false; } } else out = data; //如果不需要解压，则out=data，反之则out是解压后的数据 LOGI(\u0026#34;receid data: %s\u0026#34;, out.c_str()); return Process(out); } 对包进行压缩的算法：\nsize_t dataLength = data.length(); std::string destbuf; if (m_bClientCompressed) { //按需压缩 if (!ZlibUtil::deflate(data, destbuf)) { LOGE(\u0026#34;compress buf error, data: %s\u0026#34;, data.c_str()); return; } } else destbuf = data; LOGI(\u0026#34;destbuf.length(): %d\u0026#34;, destbuf.length()); 压缩和解压算法即 gzip 压缩算法。\n由于公众号文章最大是 5000 字数限制，本文原文一共有 12000 字，公众号发文时有省略。如果想获取完整的文章请在【高性能服务器开发】公众号后台回复 关键字【websocket协议分析】。获取文中完整源码，请在公众号后台回复关键字【websocket源码】。\n","permalink":"https://haokiu.com/blog/f8c9189db8404c76867e71440f136a2c/","summary":"从零开发一个WebSocket服务器 WebSocket 协议是为了解决 http 协议的无状态、短连接（通常是）和服务端无法主动给客户端推送数据等问题而开发的新型协议，其通信基础也是基于 TCP。由于较旧的浏览器可能不支持 WebSocket 协议，所以使用 WebSocket 协议的通信双方在进行 TCP 三次握手之后，还要再额外地进行一次握手，这一次的握手通信双方的报文格式是基于 HTTP 协议改造的。\nWebSocket 握手过程 TCP 三次握手的过程我们就不在这里赘述了，任何一本网络通信书籍上都有详细的介绍。我们这里来介绍一下 WebSocket 通信最后一次的握手过程。\n握手开始后，一方给另外一方发送一个 http 协议格式的报文，这个报文格式大致如下：\nGET /realtime HTTP/1.1\\r\\n Host: 127.0.0.1:9989\\r\\n Connection: Upgrade\\r\\n Pragma: no-cache\\r\\n Cache-Control: no-cache\\r\\n User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64)\\r\\n Upgrade: websocket\\r\\n Origin: http://xyz.com\\r\\n Sec-WebSocket-Version: 13\\r\\n Accept-Encoding: gzip, deflate, br\\r\\n Accept-Language: zh-CN,zh;q=0.9,en;q=0.8\\r\\n Sec-WebSocket-Key: IqcAWodjyPDJuhGgZwkpKg==\\r\\n Sec-WebSocket-Extensions: permessage-deflate; client_max_window_bits\\r\\n \\r\\n 对这个格式有如下要求：\n握手必须是一个有效的 HTTP 请求； 请求的方法必须为 GET，且 HTTP 版本必须是 1.1； 请求必须包含 Host 字段信息； 请求必须包含 Upgrade字段信息，值必须为 websocket； 请求必须包含 Connection 字段信息，值必须为 Upgrade； 请求必须包含 Sec-WebSocket-Key 字段，该字段值是客户端的标识编码成 base64 格式； 请求必须包含 Sec-WebSocket-Version 字段信息，值必须为 13； 请求必须包含 Origin 字段； 请求可能包含 Sec-WebSocket-Protocol 字段，规定子协议； 请求可能包含 Sec-WebSocket-Extensions字段规定协议扩展； 请求可能包含其他字段，如 cookie 等。 对端收到该数据包后如果支持 WebSocket 协议，会回复一个 http 格式的应答，这个应答报文的格式大致如下：","title":"从零开发一个WebSocket服务器"},{"content":"作者的故事 我的 2019\n我是如何年薪五十万的\n","permalink":"https://haokiu.com/blog/745f468dc9234e4f95ac9d848e64fa0b/","summary":"作者的故事 我的 2019\n我是如何年薪五十万的","title":"作者的故事"},{"content":"你一定要搞明白的C函数调用方式与栈原理 写在前面的话\n这绝对不是标题党。而是C/C++开发中你必须要掌握的基础知识，也是高级技术岗位面试中高频题。我真的真的真的希望无论是学生还是广大C/C++开发者，都该掌握此文中介绍的知识。\n正文\n这篇blog试图讲明当一个c函数被调用时，一个**栈帧(stack frame)**是如何被建立，又如何被消除的。这些细节跟操作系统平台及编译器的实现有关，下面的描述是针对运行在Intel奔腾芯片上Linux的gcc编译器而言。c语言的标准并没有描述实现的方式，所以，不同的编译器，处理器，操作系统都可能有自己的建立栈帧的方式。\n一个典型的栈帧 图1是一个典型的栈帧，图中，栈顶在上，地址空间往下增长。 这是如下一个函数调用时的栈的内容：\nint foo(int arg1, int arg2, int arg3); 并且，foo有两个局部的int变量（4个字节）。在这个简化的场景中，main调用foo，而程序的控制仍在foo中。这里，main是调用者（caller），foo是被调用者（callee）。 ESP被foo使用来指示栈顶。EBP相当于一个“基准指针”。从main传递到foo的参数以及foo本身的局部变量都可以通过这个基准指针为参考，加上偏移量找到。 由于被调用者允许使用EAX，ECX和EDX寄存器，所以如果调用者希望保存这些寄存器的值，就必须在调用子函数之前显式地把他们保存在栈中。另一方面，如果除了上面提到的几个寄存器，被调用者还想使用别的寄存器，比如EBX，ESI和EDI，那么，被调用者就必须在栈中保存这些被额外使用的寄存器，并在调用返回前回复他们。也就是说，如果被调用者只使用约定的EAX，ECX和EDX寄存器，他们由调用者负责保存并回复，但如果被调用这还额外使用了别的寄存器，则必须有他们自己保存并回复这些寄存器的值。 传递给foo的参数被压到栈中，最后一个参数先进栈，所以第一个参数是位于栈顶的。foo中声明的局部变量以及函数执行过程中需要用到的一些临时变量也都存在栈中。 小于等于4个字节的返回值会被保存到EAX中，如果大于4字节，小于8字节，那么EDX也会被用来保存返回值。如果返回值占用的空间还要大，那么调用者会向被调用者传递一个额外的参数，这个额外的参数指向将要保存返回值的地址。用C语言来说，就是函数调用：\nx = foo(a, b, c); 被转化为：\nfoo(\u0026amp;x, a, b, c); 注意，这仅仅在返回值占用大于8个字节时才发生。有的编译器不用EDX保存返回值，所以当返回值大于4个字节时，就用这种转换。 当然，并不是所有函数调用都直接赋值给一个变量，还可能是直接参与到某个表达式的计算中，如：\nm = foo(a, b, c) + foo(d, e, f); 有或者作为另外的函数的参数， 如：\nfooo(foo(a, b, c), 3); 这些情况下，foo的返回值会被保存在一个临时变量中参加后续的运算，所以，foo(a, b, c)还是可以被转化成foo(\u0026amp;tmp, a, b, c)。\n让我们一步步地看一下在c函数调用过程中，一个栈帧是如何建立及消除的。\n函数调用前调用者的动作 在我们的例子中，调用者是main，它准备调用函数foo。在函数调用前，main正在用ESP和EBP寄存器指示它自己的栈帧。\n首先，main把EAX，ECX和EDX压栈。这是一个可选的步骤，只在这三个寄存器内容需要保留的时候执行此步骤。 接着，main把传递给foo的参数一一进栈，最后的参数最先进栈。例如，我们的函数调用是：\na = foo(12, 15, 18); 相应的汇编语言指令是：\npush dword 18 push dword 15 push dword 12 最后，main用call指令调用子函数：\ncall foo 当call指令执行的时候，EIP指令指针寄存器的内容被压入栈中。因为EIP寄存器是指向main中的下一条指令，所以现在返回地址就在栈顶了。在call指令执行完之后，下一个执行周期将从名为foo的标记处开始。 图2展示了call指令完成后栈的内容。图2及后续图中的粗线指示了函数调用前栈顶的位置。我们将会看到，当整个函数调用过程结束后，栈顶又回到了这个位置。\n被调用者在函数调用后的动作 当函数foo，也就是被调用者取得程序的控制权，它必须做3件事：建立它自己的栈帧，为局部变量分配空间，最后，如果需要，保存寄存器EBX，ESI和EDI的值。 首先foo必须建立它自己的栈帧。EBP寄存器现在正指向main的栈帧中的某个位置，这个值必须被保留，因此，EBP进栈。然后ESP的内容赋值给了EBP。这使得函数的参数可以通过对EBP附加一个偏移量得到，而栈寄存器ESP便可以空出来做其他事情。如此一来，几乎所有的c函数都由如下两个指令开始：\npush ebp mov ebp, esp 此时的栈入图3所示。在这个场景中，第一个参数的地址是EBP加8，因为main的EBP和返回地址各在栈中占了4个字节。\n​\n下一步，foo必须为它的局部变量分配空间，同时，也必须为它可能用到的一些临时变量分配空间。比如，foo中的一些C语句可能包括复杂的表达式，其子表达式的中间值就必须得有地方存放。这些存放中间值的地方同城被称为临时的，因为他们可以为下一个复杂表达式所复用。为说明方便，我们假设我们的foo中有两个int类型（每个4字节）的局部变量，需要额外的12字节的临时存储空间。简单地把栈指针减去20便为这20个字节分配了空间：\nsub esp, 20 现在，局部变量和临时存储都可以通过基准指针EBP加偏移量找到了。 最后，如果foo用到EBX，ESI和EDI寄存器，则它f必须在栈里保存它们。结果，现在的栈如图4所示。\n​\nfoo的函数体现在可以执行了。这其中也许有进栈、出栈的动作，栈指针ESP也会上下移动，但EBP是保持不变的。这意味着我们可以一直用[EBP+8]找到第一个参数，而不管在函数中有多少进出栈的动作。 函数foo的执行也许还会调用别的函数，甚至递归地调用foo本身。然而，只要EBP寄存器在这些子调用返回时被恢复，就可以继续用EBP加上偏移量的方式访问实际参数，局部变量和临时存储。\n被调用者返回前的动作 在把程序控制权返还给调用者前，被调用者foo必须先把返回值保存在EAX寄存器中。我们前面已经讨论过，当返回值占用多于4个或8个字节时，接收返回值的变量地址会作为一个额外的指针参数被传到函数中，而函数本身就不需要返回值了。这种情况下，被调用者直接通过内存拷贝把返回值直接拷贝到接收地址，从而省去了一次通过栈的中转拷贝。 其次，foo必须恢复EBX，ESI和EDI寄存器的值。如果这些寄存器被修改，正如我们前面所说，我们会在foo执行开始时把它们的原始值压入栈中。如果ESP寄存器指向如图4所示的正确位置，寄存器的原始值就可以出栈并恢复。可见，在foo函数的执行过程中正确地跟踪ESP是多么的重要————也就是说，进栈和出栈操作的次数必须保持平衡。 这两步之后，我们不再需要foo的局部变量和临时存储了，我们可以通过下面的指令消除栈帧：\nmov esp, ebp pop ebp 其结果就是现在栈里的内容跟图2中所示的栈完全一样。现在可以执行返回指令了。从栈里弹出返回地址，赋值给EIP寄存器。栈如图5所示：\ni386指令集有一条**“leave”**指令，它与上面提到的mov和pop指令所作的动作完全相同。所以，C函数通常以这样的指令结束：\nleave ret 调用者在返回后的动作 在程序控制权返回到调用者（也就是我们例子中的main）后，栈如图5所示。这时，传递给foo的参数通常已经不需要了。我们可以把3个参数一起弹出栈，这可以通过把栈指针加12（=3个4字节）实现：\nadd esp, 12 如果在函数调用前，EAX，ECX和EDX寄存器的值被保存在栈中，调用者main函数现在可以把它们弹出。这个动作之后，栈顶就回到了我们开始整个函数调用过程前的位置，也就是图5中粗线的位置。\n看个具体的实例：\n这段代码反汇编后，代码是什么呢？\n#include \u0026lt;stdio.h\u0026gt; long test(int a, int b) { a = a + 3; b = b + 5; return a + b; } int main(int argc, char* argv[]) { printf(\u0026#34;%d\u0026#34;, test(10,90)); return 0; } 先来看一个概貌：\n9: int main(int argc, char* argv[]) 10: { 00401070 push ebp 00401071 mov ebp,esp 00401073 sub esp,40h 00401076 push ebx 00401077 push esi 00401078 push edi 00401079 lea edi,[ebp-40h] 0040107C mov ecx,10h 00401081 mov eax,0CCCCCCCCh 00401086 rep stos dword ptr [edi] 11: printf(\u0026#34;%d\u0026#34;,test(10,90)); 00401088 push 5Ah 0040108A push 0Ah 0040108C call @ILT+0(test) (00401005) 00401091 add esp,8 00401094 push eax 00401095 push offset string \u0026#34;%d\u0026#34; (0042201c) 0040109A call printf (004010d0) 0040109F add esp,8 12: return 0; 004010A2 xor eax,eax 13: } 下面来解释一下，\n开始进入Main函数 esp=0x12FF84 ebp=0x12FFC0 完成椭圆形框起来的部分：\n00401070 push ebp ebp的值入栈，保存现场(调用现场，从test函数看，如红线所示，即保存的0x12FF80用于从test函数堆栈返回到main函数)：\n00401071 mov ebp,esp 此时ebp＝0x12FF80 此时ebp就是“当前函数堆栈”的基址 以便访问堆栈中的信息；还有就是从当前函数栈顶返回到栈底：\n00401073 sub esp,40h 函数使用的堆栈，默认64个字节，堆栈上就是16个横条（密集线部分）此时esp=0x12FF40。 在上图中，上面密集线是test函数堆栈空间，下面是Main的堆栈空间(补充，其实这个就叫做 Stack Frame)：\n00401076 push ebx 00401077 push esi 00401078 push edi 入栈 00401079 lea edi,[ebp-40h] 0040107C mov ecx,10h 00401081 mov eax,0CCCCCCCCh 00401086 rep stos dword ptr [edi] 初始化用于该函数的栈空间为0XCCCCCCCC，即从0x12FF40~0x12FF80所有的值均为0xCCCCCCCC：\n11: printf(\u0026#34;%d\u0026#34;,test(10,90)); 00401088 push 5Ah 参数入栈 从右至左 先90 后10 0040108A push 0Ah 0040108C call @ILT+0(test) (00401005) 函数调用，转向eip 00401005 。 注意，此时仍入栈，入栈的是call test 指令下一条指令的地址00401091下一条指令是add esp,8。 @ILT+0(?test@@YAJHH@Z):\n00401005 jmp test (00401020) 即转向被调函数test：\n2: long test(int a,int b) 3: { 00401020 push ebp 00401021 mov ebp,esp 00401023 sub esp,40h 00401026 push ebx 00401027 push esi 00401028 push edi 00401029 lea edi,[ebp-40h] 0040102C mov ecx,10h 00401031 mov eax,0CCCCCCCCh 00401036 rep stos dword ptr [edi] //这些和上面一样 4: a = a + 3; 00401038 mov eax,dword ptr [ebp+8] //ebp=0x12FF24 加8 [0x12FF30]即取到了参数10 0040103B add eax,3 0040103E mov dword ptr [ebp+8],eax 5: b = b + 5; 00401041 mov ecx,dword ptr [ebp+0Ch] 00401044 add ecx,5 00401047 mov dword ptr [ebp+0Ch],ecx 6: return a + b; 0040104A mov eax,dword ptr [ebp+8] 0040104D add eax,dword ptr [ebp+0Ch] //最后的结果保存在eax, 结果得以返回 7: } 00401050 pop edi 00401051 pop esi 00401052 pop ebx 00401053 mov esp,ebp //esp指向0x12FF24, test函数的堆栈空间被放弃，从当前函数栈顶返回到栈底 00401055 pop ebp //此时ebp=0x12FF80, 恢复现场 esp=0x12FF28 00401056 ret //ret负责栈顶0x12FF28之值00401091弹出到指令寄存器中，esp=0x12FF30 因为win32汇编一般用eax返回结果 所以如果最终结果不是在eax里面的话 还要把它放到eax。\n注意，从被调函数返回时，是弹出EBP,恢复堆栈到函数调用前的地址，弹出返回地址到EIP以继续执行程序。\n从test函数返回，执行：\n00401091 add esp,8 清栈，清除两个压栈的参数10 90 调用者main负责。 (所谓__cdecl调用由调用者负责恢复栈，调用者负责清理的只是入栈的参数，test函数自己的堆栈空间自己返回时自己已经清除，靠！一直理解错)\n00401094 push eax //入栈，计算结果108入栈，即printf函数的参数之一入栈 00401095 push offset string \u0026#34;%d\u0026#34; (0042201c)//入栈，参数 \u0026#34;%d\u0026#34; 当然其实是％d的地址 0040109A call printf (004010d0)//函数调用 printf(\u0026#34;%d\u0026#34;,108) 因为printf函数时 0040109F add esp,8 //清栈，清除参数 (\u0026#34;%d\u0026#34;, 108) 19: return 0; 004010A2 xor eax,eax //eax清零 20: } main函数执行完毕 此时esp=0x12FF34 ebp=0x12FF80：\n004010A4 pop edi 004010A5 pop esi 004010A6 pop ebx 004010A7 add esp,40h //为啥不用mov esp, ebp? 是为了下面的比较 004010AA cmp ebp,esp //比较，若不同则调用chkesp抛出异常 004010AC call __chkesp (00401150) 004010B1 mov esp,ebp 004010B3 pop ebp //ESP=0X12FF84 EBP=0x12FFC0 尘归尘 土归土 一切都恢复最初的平静了 :)\n004010B4 ret 另：\n如果函数调用方式是**__stdcall**不同之处在于main函数call 后面没有了add esp, 8；test函数最后一句是 ret 8 (由test函数清栈, ret 8意思是执行ret后，esp+8)。 运行过程中0x12FF28 保存了指令地址 00401091是怎么保存的？栈每个空间保存4个字节（粒度4字节） 例如下一个栈空间0x12FF2C保存参数10，因此： 0x12FF28 0x12FF29 0x12FF2A 0x12FF2B 91 10 40 00 little-endian 认为其读的第一个字节为最小的那位上的数。\nchar a[] = \u0026ldquo;abcde\u0026rdquo; 对局部字符数组变量（栈变量）赋值，是利用寄存器从全局数据内存区把字符串“abcde”拷贝到栈内存中的。 int szNum[5] = { 1, 2, 3, 4, 5 }; 栈中是如何分布的？ 00401798 mov dword ptr [ebp-14h],1 0040179F mov dword ptr [ebp-10h],2 004017A6 mov dword ptr [ebp-0Ch],3 004017AD mov dword ptr [ebp-8],4 004017B4 mov dword ptr [ebp-4],5 可以看出来是从右边开始入栈，所以是 5 4 3 2 1 入栈，\nint *ptrA = (int*)(\u0026amp;szNum+1); int *ptrB = (int*)((int)szNum + 1); std::cout\u0026lt;\u0026lt; ptrA[-1] \u0026lt;\u0026lt; *ptrB \u0026lt;\u0026lt; std::endl; 结果如何？\n28: int *ptrA = (int*)(\u0026amp;szNum+1); 004017BB lea eax,[ebp] 004017BE mov dword ptr [ebp-18h],eax \u0026amp;szNum是指向数组指针；加1是加一个数组宽度；\u0026amp;szNum+1指向移动5个int单位之后的那个地方， 就是把EBP的地址赋给指针； ptrA[-1]是回退一个int*宽度，即ebp-4；\n29: int *ptrB = (int*)((int)szNum + 1); 004017C1 lea ecx,[ebp-13h] 004017C4 mov dword ptr [ebp-1Ch],ecx 如果上面是指针算术，那这里就是地址算术，只是首地址+1个字节的offset，即ebp-13h给指针。实际保存是这样的：\n01 00 00 00 02 00 00 00 ebp-14h ebp-13h ebp-10h 注意，是int*类型的，最后获得的是 00 00 00 02，由于Little-endian, 实际上逻辑数是02000000，转换为十进制数就为33554432，最后输出533554432。\n","permalink":"https://haokiu.com/blog/2d2976c6ad824a1b9e2c44ffad106432/","summary":"你一定要搞明白的C函数调用方式与栈原理 写在前面的话\n这绝对不是标题党。而是C/C++开发中你必须要掌握的基础知识，也是高级技术岗位面试中高频题。我真的真的真的希望无论是学生还是广大C/C++开发者，都该掌握此文中介绍的知识。\n正文\n这篇blog试图讲明当一个c函数被调用时，一个**栈帧(stack frame)**是如何被建立，又如何被消除的。这些细节跟操作系统平台及编译器的实现有关，下面的描述是针对运行在Intel奔腾芯片上Linux的gcc编译器而言。c语言的标准并没有描述实现的方式，所以，不同的编译器，处理器，操作系统都可能有自己的建立栈帧的方式。\n一个典型的栈帧 图1是一个典型的栈帧，图中，栈顶在上，地址空间往下增长。 这是如下一个函数调用时的栈的内容：\nint foo(int arg1, int arg2, int arg3); 并且，foo有两个局部的int变量（4个字节）。在这个简化的场景中，main调用foo，而程序的控制仍在foo中。这里，main是调用者（caller），foo是被调用者（callee）。 ESP被foo使用来指示栈顶。EBP相当于一个“基准指针”。从main传递到foo的参数以及foo本身的局部变量都可以通过这个基准指针为参考，加上偏移量找到。 由于被调用者允许使用EAX，ECX和EDX寄存器，所以如果调用者希望保存这些寄存器的值，就必须在调用子函数之前显式地把他们保存在栈中。另一方面，如果除了上面提到的几个寄存器，被调用者还想使用别的寄存器，比如EBX，ESI和EDI，那么，被调用者就必须在栈中保存这些被额外使用的寄存器，并在调用返回前回复他们。也就是说，如果被调用者只使用约定的EAX，ECX和EDX寄存器，他们由调用者负责保存并回复，但如果被调用这还额外使用了别的寄存器，则必须有他们自己保存并回复这些寄存器的值。 传递给foo的参数被压到栈中，最后一个参数先进栈，所以第一个参数是位于栈顶的。foo中声明的局部变量以及函数执行过程中需要用到的一些临时变量也都存在栈中。 小于等于4个字节的返回值会被保存到EAX中，如果大于4字节，小于8字节，那么EDX也会被用来保存返回值。如果返回值占用的空间还要大，那么调用者会向被调用者传递一个额外的参数，这个额外的参数指向将要保存返回值的地址。用C语言来说，就是函数调用：\nx = foo(a, b, c); 被转化为：\nfoo(\u0026amp;x, a, b, c); 注意，这仅仅在返回值占用大于8个字节时才发生。有的编译器不用EDX保存返回值，所以当返回值大于4个字节时，就用这种转换。 当然，并不是所有函数调用都直接赋值给一个变量，还可能是直接参与到某个表达式的计算中，如：\nm = foo(a, b, c) + foo(d, e, f); 有或者作为另外的函数的参数， 如：\nfooo(foo(a, b, c), 3); 这些情况下，foo的返回值会被保存在一个临时变量中参加后续的运算，所以，foo(a, b, c)还是可以被转化成foo(\u0026amp;tmp, a, b, c)。\n让我们一步步地看一下在c函数调用过程中，一个栈帧是如何建立及消除的。\n函数调用前调用者的动作 在我们的例子中，调用者是main，它准备调用函数foo。在函数调用前，main正在用ESP和EBP寄存器指示它自己的栈帧。\n首先，main把EAX，ECX和EDX压栈。这是一个可选的步骤，只在这三个寄存器内容需要保留的时候执行此步骤。 接着，main把传递给foo的参数一一进栈，最后的参数最先进栈。例如，我们的函数调用是：\na = foo(12, 15, 18); 相应的汇编语言指令是：\npush dword 18 push dword 15 push dword 12 最后，main用call指令调用子函数：\ncall foo 当call指令执行的时候，EIP指令指针寄存器的内容被压入栈中。因为EIP寄存器是指向main中的下一条指令，所以现在返回地址就在栈顶了。在call指令执行完之后，下一个执行周期将从名为foo的标记处开始。 图2展示了call指令完成后栈的内容。图2及后续图中的粗线指示了函数调用前栈顶的位置。我们将会看到，当整个函数调用过程结束后，栈顶又回到了这个位置。\n被调用者在函数调用后的动作 当函数foo，也就是被调用者取得程序的控制权，它必须做3件事：建立它自己的栈帧，为局部变量分配空间，最后，如果需要，保存寄存器EBX，ESI和EDI的值。 首先foo必须建立它自己的栈帧。EBP寄存器现在正指向main的栈帧中的某个位置，这个值必须被保留，因此，EBP进栈。然后ESP的内容赋值给了EBP。这使得函数的参数可以通过对EBP附加一个偏移量得到，而栈寄存器ESP便可以空出来做其他事情。如此一来，几乎所有的c函数都由如下两个指令开始：\npush ebp mov ebp, esp 此时的栈入图3所示。在这个场景中，第一个参数的地址是EBP加8，因为main的EBP和返回地址各在栈中占了4个字节。\n​\n下一步，foo必须为它的局部变量分配空间，同时，也必须为它可能用到的一些临时变量分配空间。比如，foo中的一些C语句可能包括复杂的表达式，其子表达式的中间值就必须得有地方存放。这些存放中间值的地方同城被称为临时的，因为他们可以为下一个复杂表达式所复用。为说明方便，我们假设我们的foo中有两个int类型（每个4字节）的局部变量，需要额外的12字节的临时存储空间。简单地把栈指针减去20便为这20个字节分配了空间：\nsub esp, 20 现在，局部变量和临时存储都可以通过基准指针EBP加偏移量找到了。 最后，如果foo用到EBX，ESI和EDI寄存器，则它f必须在栈里保存它们。结果，现在的栈如图4所示。\n​\nfoo的函数体现在可以执行了。这其中也许有进栈、出栈的动作，栈指针ESP也会上下移动，但EBP是保持不变的。这意味着我们可以一直用[EBP+8]找到第一个参数，而不管在函数中有多少进出栈的动作。 函数foo的执行也许还会调用别的函数，甚至递归地调用foo本身。然而，只要EBP寄存器在这些子调用返回时被恢复，就可以继续用EBP加上偏移量的方式访问实际参数，局部变量和临时存储。\n被调用者返回前的动作 在把程序控制权返还给调用者前，被调用者foo必须先把返回值保存在EAX寄存器中。我们前面已经讨论过，当返回值占用多于4个或8个字节时，接收返回值的变量地址会作为一个额外的指针参数被传到函数中，而函数本身就不需要返回值了。这种情况下，被调用者直接通过内存拷贝把返回值直接拷贝到接收地址，从而省去了一次通过栈的中转拷贝。 其次，foo必须恢复EBX，ESI和EDI寄存器的值。如果这些寄存器被修改，正如我们前面所说，我们会在foo执行开始时把它们的原始值压入栈中。如果ESP寄存器指向如图4所示的正确位置，寄存器的原始值就可以出栈并恢复。可见，在foo函数的执行过程中正确地跟踪ESP是多么的重要————也就是说，进栈和出栈操作的次数必须保持平衡。 这两步之后，我们不再需要foo的局部变量和临时存储了，我们可以通过下面的指令消除栈帧：","title":"你一定要搞明白的C函数调用方式与栈原理"},{"content":"做 Java 或者 C++ 开发都应该知道的 lsof 命令 lsof 命令是 Linux 系统的扩展工具，它的含义是 list opened filedesciptor （列出已经打开的文件描述符），在 Linux 系统中，所有的与资源句柄相关的东西都可以统一抽象成文件描述符（filedescriptor，简称 fd）。一个文件句柄是一个 fd，一个 socket 对象也可以称之为 fd 等等。\n默认情况下，系统是不存在这个命令的，你需要安装一下，使用如下命令安装：\nyum install lsof 我们来看一下这个命令的使用效果：\nCOMMAND PID TID USER FD TYPE DEVICE SIZE/OFF NODE NAME systemd 1 root cwd DIR 202,1 4096 2 / nscd 453 469 nscd 8u netlink 0t0 11017 ROUTE nscd 453 470 nscd cwd DIR 202,1 4096 2 / nscd 453 470 nscd rtd DIR 202,1 4096 2 / nscd 453 470 nscd txt REG 202,1 180272 146455 /usr/sbin/nscd nscd 453 470 nscd mem REG 202,1 217032 401548 /var/db/nscd/hosts nscd 453 470 nscd mem REG 202,1 90664 132818 /usr/lib64/libz.so.1.2.7 nscd 453 470 nscd mem REG 202,1 68192 133155 /usr/lib64/libbz2.so.1.0.6 nscd 453 470 nscd mem REG 202,1 153192 133002 /usr/lib64/liblzma.so.5.0.99 nscd 453 470 nscd mem REG 202,1 91496 133088 nscd 453 471 nscd 5u a_inode 0,9 0 4796 [eventpoll] nscd 453 471 nscd 6r REG 202,1 217032 401548 /var/db/nscd/hosts nscd 453 471 nscd 7u unix 0xffff880037497440 0t0 11015 /var/run/nscd/socket nscd 453 471 nscd 8u netlink 0t0 11017 ROUTE imgserver 611 zhangyl cwd DIR 202,1 4096 1059054 /home/zhangyl/flamingoserver imgserver 611 zhangyl rtd DIR 202,1 4096 2 / imgserver 611 zhangyl txt REG 202,1 4788917 1057044 /home/zhangyl/flamingoserver/imgserver imgserver 611 zhangyl 24u a_inode 0,9 0 4796 [eventfd] imgserver 611 zhangyl 25u IPv4 55707643 0t0 TCP *:commtact-http (LISTEN) imgserver 611 zhangyl 26r CHR 1,3 0t0 4800 /dev/null imgserver 611 613 zhangyl 32w REG 202,1 131072 2754609 /home/zhangyl/flamingoserver/imgcache/258bfb8945288a117d98d440986d7a03 结果显示中列出了各个进程打开的各种 fd 类型，对于 Uinx Socket，lsof 命令会显示出其详细的路径，打开的文件 fd 亦是如此。\n使用 lsof 命令有三点需要注意：\n默认情况下，lsof 的输出比较多，我们可以使用 grep 命令过滤我们想要查看的进程打开的 fd 信息，如：\nlsof -i | grep myapp 或者使用 lsof -p pid 也能过滤出指定的进程打开的 fd 信息：\n[root@iZ238vnojlyZ ~]# lsof -p 26621 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME chatserve 26621 zhangyl cwd DIR 202,1 4096 1059054 /home/zhangyl/flamingoserver chatserve 26621 zhangyl rtd DIR 202,1 4096 2 / chatserve 26621 zhangyl txt REG 202,1 8027035 1051942 /home/zhangyl/flamingoserver/chatserver chatserve 26621 zhangyl mem REG 202,1 61928 141417 /usr/lib64/libnss_files-2.17.so chatserve 26621 zhangyl mem REG 202,1 44096 143235 /usr/lib64/librt-2.17.so chatserve 26621 zhangyl mem REG 202,1 19520 137064 /usr/lib64/libdl-2.17.so chatserve 26621 zhangyl mem REG 202,1 2112384 132824 /usr/lib64/libc-2.17.so chatserve 26621 zhangyl mem REG 202,1 142304 132850 /usr/lib64/libpthread-2.17.so chatserve 26621 zhangyl mem REG 202,1 88720 135291 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 chatserve 26621 zhangyl mem REG 202,1 1141560 137077 /usr/lib64/libm-2.17.so chatserve 26621 zhangyl mem REG 202,1 999944 140059 /usr/lib64/libstdc++.so.6.0.19 chatserve 26621 zhangyl mem REG 202,1 9879756 269001 /usr/lib64/mysql/libmysqlclient.so.20.3.4 chatserve 26621 zhangyl mem REG 202,1 164440 133622 /usr/lib64/ld-2.17.so chatserve 26621 zhangyl 0u CHR 1,3 0t0 4800 /dev/null chatserve 26621 zhangyl 1u CHR 1,3 0t0 4800 /dev/null chatserve 26621 zhangyl 2u CHR 1,3 0t0 4800 /dev/null chatserve 26621 zhangyl 3u a_inode 0,9 0 4796 [eventpoll] chatserve 26621 zhangyl 4u a_inode 0,9 0 4796 [timerfd] chatserve 26621 zhangyl 5u a_inode 0,9 0 4796 [eventfd] chatserve 26621 zhangyl 7u a_inode 0,9 0 4796 [eventpoll] lsof 命令只能查看到当前用户有权限查看到的进程 fd 信息，对于其没有权限的进程，最右边一列会显示 “Permission denied”。如下所示：\nsshd 26759 root cwd unknown /proc/26759/cwd (readlink: Permission denied) sshd 26759 root rtd unknown /proc/26759/root (readlink: Permission denied) sshd 26759 root txt unknown /proc/26759/exe (readlink: Permission denied) sshd 26759 root NOFD /proc/26759/fd (opendir: Permission denied) bash 26761 root cwd unknown /proc/26761/cwd (readlink: Permission denied) bash 26761 root rtd unknown /proc/26761/root (readlink: Permission denied) bash 26761 root txt unknown /proc/26761/exe (readlink: Permission denied) bash 26761 root NOFD /proc/26761/fd (opendir: Permission denied) lsof 命令第一栏进程名在显示的时候，默认显示前 n 个字符，这样如果我们需要显示完整的进程名以方便过滤的话，可以使用 +c 选项。用法如下：\n#最左侧的程序名最大显示 15 个字符 [zhangyl@iZ238vnojlyZ ~]$ lsof +c 15 当然，如果你设置值太大， lsof 便不会采用你设置的最大值，而是使用默认最大值。\n上文也介绍了，socket 也是一种 fd，如果需要仅显示系统的网络连接信息，使用的是 -i 选项即可，这个选项可以形象地显示出系统当前的出入连接情况：\n看到图中的连接方向了吧？\n当然，和 netstat 命令一样，lsof -i 默认也会显示 ip 地址和端口号的别名，我们只要使用 -n 和 -P 选项就能相对应地显示 ip 地址和端口号了，综合起来就是 lsof -Pni：\n","permalink":"https://haokiu.com/blog/a21d8fb5077b4bdfacf0cd5f4583f1cc/","summary":"做 Java 或者 C++ 开发都应该知道的 lsof 命令 lsof 命令是 Linux 系统的扩展工具，它的含义是 list opened filedesciptor （列出已经打开的文件描述符），在 Linux 系统中，所有的与资源句柄相关的东西都可以统一抽象成文件描述符（filedescriptor，简称 fd）。一个文件句柄是一个 fd，一个 socket 对象也可以称之为 fd 等等。\n默认情况下，系统是不存在这个命令的，你需要安装一下，使用如下命令安装：\nyum install lsof 我们来看一下这个命令的使用效果：\nCOMMAND PID TID USER FD TYPE DEVICE SIZE/OFF NODE NAME systemd 1 root cwd DIR 202,1 4096 2 / nscd 453 469 nscd 8u netlink 0t0 11017 ROUTE nscd 453 470 nscd cwd DIR 202,1 4096 2 / nscd 453 470 nscd rtd DIR 202,1 4096 2 / nscd 453 470 nscd txt REG 202,1 180272 146455 /usr/sbin/nscd nscd 453 470 nscd mem REG 202,1 217032 401548 /var/db/nscd/hosts nscd 453 470 nscd mem REG 202,1 90664 132818 /usr/lib64/libz.","title":"做 Java 或者 C++ 开发都应该知道的 lsof 命令"},{"content":"利用 cmake 工具生成 Visual Studio 工程文件 对于习惯了 Visual Studio 强大的管理项目、编码和调试功能的读者来说，在 Linux 下使用 gcc/g++ 编译、使用 gdb 调试是一件何其痛苦的事情，对于大多数的开源 C/C++ 项目，如果我们不在意 Windows 和 Linux 在一些底层 API 接口上的使用差别，想熟悉该项目的执行脉络和原理，在 Windows 上使用 Visual Studio 调试该项目也未尝不可。凡是可以使用 CMake 工具编译的 Linux 程序（即提供了 CMakeLists.txt 文件），我们同样也可以利用 CMake 工具生成 Windows 上的 Visual Studio 工程文件。\n这里我们以著名的开源网络库 libuv 为例。\n从 libuv 的官方地址提供的下载链接：https://dist.libuv.org/dist/ 下载最新的 libuv 的源码得到文件 libuv-v1.31.0.tar.gz（笔者写作此书时，libuv 最新版本是 1.31.0），解压该文件。作者的机器上我将代码解压至 *F:\\mycode\\libuv-v1.31.0* ，解压后的目录中确实存在一个 CMakeLists.txt 文件，如下图所示：\n启动 Windows 上的 CMake 图形化工具（cmake-gui），按下图进行设置：\n设置完成之后，点击界面上的Configure 按钮，会提示 vsprojects 目录不存在，提示是否创建，我们点击 Yes 进行创建。\n如果您的机器上安装了多个版本的Visual Studio，接下来会弹窗对话框让我们选择要生成的工程文件对应的 Visual Studio 版本号。读者可以根据自己的实际情况按需选择。我这里选择 Visual Studio 2019。\n点击 Finish 按钮后开始启动 CMake 的检测和配置工作。等待一会儿，CMake 底部的输出框中提示 “Configuring Done” 表示配置工作已经完成。\n接下来点击 Generate 按钮即可生成所选版本的 Visual Studio 工程文件，生成的文件位于 vsprojects 目录。\n我们可以在界面上点击按钮 Open Project 按钮直接打开工程文件，也可以找到对应目录下的 libuv.sln 打开。\n打开后如下图所示：\n接下来，我们就可以使用 Visual Studio 愉快地进行编译和调试了。\n让我们再深入聊一下上述过程：在点击 Configure 按钮之后，和在 Linux 下执行 cmake 命令一样，CMake 工具也是在检测所在的系统环境是否匹配 CMakeLists.txt 中定义的各种环境，本质上是生成了一份可以在 Windows 上编译和运行的代码（也就是说该源码支持在 Windows 上运行） 。因此，对于很多虽然提供了 CMakeLists.txt 文件但并不支持在 Windows 上运行的的 Linux 工程，虽然利用上述方法也能最终生成 Visual Studio 工程文件，但是这些文件并不能在 Windows 上直接无错编译和调试。\n由于不同的 CMake 版本支持的 CMakeLists.txt 中的语法可能略有细微差别，有些 CMakeLists.txt 文件在使用上述方法 configure 时可能会产生一些错误，需要读者做些修改才能通过。\n","permalink":"https://haokiu.com/blog/cf3a65cd7c2a40d1a4dbfd708c471c01/","summary":"利用 cmake 工具生成 Visual Studio 工程文件 对于习惯了 Visual Studio 强大的管理项目、编码和调试功能的读者来说，在 Linux 下使用 gcc/g++ 编译、使用 gdb 调试是一件何其痛苦的事情，对于大多数的开源 C/C++ 项目，如果我们不在意 Windows 和 Linux 在一些底层 API 接口上的使用差别，想熟悉该项目的执行脉络和原理，在 Windows 上使用 Visual Studio 调试该项目也未尝不可。凡是可以使用 CMake 工具编译的 Linux 程序（即提供了 CMakeLists.txt 文件），我们同样也可以利用 CMake 工具生成 Windows 上的 Visual Studio 工程文件。\n这里我们以著名的开源网络库 libuv 为例。\n从 libuv 的官方地址提供的下载链接：https://dist.libuv.org/dist/ 下载最新的 libuv 的源码得到文件 libuv-v1.31.0.tar.gz（笔者写作此书时，libuv 最新版本是 1.31.0），解压该文件。作者的机器上我将代码解压至 *F:\\mycode\\libuv-v1.31.0* ，解压后的目录中确实存在一个 CMakeLists.txt 文件，如下图所示：\n启动 Windows 上的 CMake 图形化工具（cmake-gui），按下图进行设置：\n设置完成之后，点击界面上的Configure 按钮，会提示 vsprojects 目录不存在，提示是否创建，我们点击 Yes 进行创建。\n如果您的机器上安装了多个版本的Visual Studio，接下来会弹窗对话框让我们选择要生成的工程文件对应的 Visual Studio 版本号。读者可以根据自己的实际情况按需选择。我这里选择 Visual Studio 2019。\n点击 Finish 按钮后开始启动 CMake 的检测和配置工作。等待一会儿，CMake 底部的输出框中提示 “Configuring Done” 表示配置工作已经完成。\n接下来点击 Generate 按钮即可生成所选版本的 Visual Studio 工程文件，生成的文件位于 vsprojects 目录。\n我们可以在界面上点击按钮 Open Project 按钮直接打开工程文件，也可以找到对应目录下的 libuv.sln 打开。","title":"利用 cmake 工具生成 Visual Studio 工程文件"},{"content":"利用 telnet 命令发电子邮件 telnet 命令是我们最常用的网络调试命令之一。如果你的机器上还没有安装 telnet 命令，可以使用如下命令安装一下：\nyum install telnet 如果一个服务程序对外开启了侦听服务，我们都可以使用 telnet ip port 来连接上去，例如：\n[root@localhost ~]# telnet 120.55.94.78 8888 Trying 120.55.94.78... Connected to 120.55.94.78. Escape character is \u0026#39;^]\u0026#39;. 如果不指定端口号，telnet 会使用默认 23 号端口。\n反过来说，可以通过 telnet 命令去检测指定 ip 地址和端口号的侦听服务是否存在。知道这点很重要，我们可以利用这个去检测一个服务是否可以正常连接。举个例子，比如某次从某处得到一个代码下载地址，这是一个 svn 地址：svn://120.55.94.78/mycode/mybook。为了检测这个 svn 服务是否还能正常对外服务，我们可以先用 ping 命令去检测一下到达这个 ip：120.55.94.78 的网络是否畅通：\n[root@localhost ~]# ping 120.55.94.78 PING 120.55.94.78 (120.55.94.78) 56(84) bytes of data. 64 bytes from 120.55.94.78: icmp_seq=1 ttl=128 time=15.3 ms 64 bytes from 120.55.94.78: icmp_seq=2 ttl=128 time=14.3 ms 64 bytes from 120.55.94.78: icmp_seq=3 ttl=128 time=16.4 ms 64 bytes from 120.55.94.78: icmp_seq=4 ttl=128 time=16.1 ms 64 bytes from 120.55.94.78: icmp_seq=5 ttl=128 time=15.5 ms ^C --- 120.55.94.78 ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 4007ms rtt min/avg/max/mdev = 14.343/15.568/16.443/0.723 ms 如果网络畅通，我们再用 telnet 去连接上去，由于 svn 服务器使用的默认端口是 3690，我们执行如下命令：\n[root@localhost ~]# telnet 120.55.94.78 3690 Trying 120.55.94.78... Connected to 120.55.94.78. Escape character is \u0026#39;^]\u0026#39;. ( success ( 2 2 ( ) ( edit-pipeline svndiff1 absent-entries commit-revprops depth log-revprops atomic-revprops partial-replay ) ) ) 如上所示，证明这个 svn 服务是正常开启对外服务的。反之，如果 telnet 命令连不上，说明这个服务不能被外部网络正常连接，我们就没必要去做进一步的尝试了。\n同样的道理，对于一个 Web 服务，如 baidu.com，由于我们平常都可以通过 www.baidu.com 去访问百度的页面，Web 服务器默认的端口号是 80，我们使用 telnet www.baidu.com 80 应该也可以连接成功的：\n[root@localhost ~]# telnet www.baidu.com 80 Trying 115.239.211.112... Connected to www.baidu.com. Escape character is \u0026#39;^]\u0026#39;. hello HTTP/1.1 400 Bad Request Connection closed by foreign host. 我们使用 telnet 命令连接上以后，我们随意发送了一个 hello 消息，由于是非法的 http 请求，被服务器关闭了连接。\ntelnet 命令不仅可以连接某个服务器，还能与服务器进行交互，这通常用于操作一些接受纯文本数据的服务器程序，如 FTP 服务、邮件服务等等。为了演示如何利用 telnet 命令收发数据，我们这里利用 telnet 命令来模拟给某个邮箱发送一封邮件，发送邮件我们通常使用的是 SMTP 协议，该协议默认使用的端口为 25。\n假设我们的发件地址是：testformybook@163.com，收件地址是：balloonwj@qq.com。\n其中发件地址是一个 163 邮箱，如果你没有的话可以去申请一个，申请后进入邮箱，在设置页面获得网易邮箱的 smtp 服务的服务器地址：\n我们得到的地址 smptp 地址是 smtp.163.com，端口号是 25。\n同时，我们需要开启客户端授权，设置一个客户端授权码：\n我们这里将授权码设置为 2019hhxxttxs。\n早些年很多邮件服务器允许在其他客户端登陆只需要输入正确的邮件服务器地址、用户名和密码就可以了，后来出于安全考虑，很多邮箱采用了授权码机制，在其他第三方客户端登陆该邮箱时需要输入授权码（不是密码），且需要用户主动打开允许第三方客户端登陆的配置选项。\n配置完成以后，我们现在就可以利用 telnet 命令连接 163 邮件服务器并发送邮件了，由于在登陆的过程中需要验证用户名和授权码，而且用户名和授权码必须使用 base64 编码之后的，我们先将用户名和授权码的 base64 码准备好，用的时候直接拷贝过去：\n原文 base64 码 testformybook dGVzdGZvcm15Ym9vaw== 2019hhxxttxs MjAxOWhoeHh0dHhz 如果你不知道 base64 编码的原理，可以从网上搜索找一个 base64 编解码工具，例如：https://base64.supfree.net/。\n在整个演示过程我们一共需要使用如下 SMTP 协议命令：\n命令 含义 helo 向 smtp 服务器发送问候信息 auth login 请求登陆验证 data 请求输入邮件正文 SMTP 协议 是文本协议，每一个数据包以 \\r\\n 结束（Windows 系统下默认换行符）。\n我们来看一下演示过程：\n[root@localhost ~]# telnet smtp.163.com 25 Trying 220.181.12.14... Connected to smtp.163.com. Escape character is \u0026#39;^]\u0026#39;. 220 163.com Anti-spam GT for Coremail System (163com[20141201]) helo 163.com 250 OK auth login 334 dXNlcm5hbWU6 dGVzdGZvcm15Ym9vaw== 334 UGFzc3dvcmQ6 MjAxOWhoeHh0dHhz 235 Authentication successful mail from: \u0026lt;testformybook@163.com\u0026gt; 250 Mail OK rcpt to: \u0026lt;balloonwj@qq.com\u0026gt; 250 Mail OK data 354 End data with \u0026lt;CR\u0026gt;\u0026lt;LF\u0026gt;.\u0026lt;CR\u0026gt;\u0026lt;LF\u0026gt; from:testformybook@163.com to: balloonwj@qq.com subject: Test Hello, this is a message from 163. . 250 Mail OK queued as smtp10,DsCowADHAgQS1IBcwtExJA--.62308S2 1551946998 Connection closed by foreign host. [root@localhost ~]# 我们来分析一下上述操作过程：\n使用 telnet smtp.163.com 25 连接 163 邮件服务器；连接成功以后，服务器给我们发送了一条欢迎消息：\n220 163.com Anti-spam GT for Coremail System (163com[20141201])\\r\\n 接着，必须向服务器发送一条问候消息，使用 helo 163.com，当然 163.com 这个是问候内容，可以随意填写，然后回车，最终组成的数据包内容是：\nhelo 163.com\\r\\n 接着服务器会回复一条状态码是 250 的消息，这里是：\n250 OK\\r\\n 我们再输入命令 auth login 请求验证，然后按回车，实际发送给服务器的是：\nauth login\\r\\n 服务器应答状态码 334：\n334 dXNlcm5hbWU6\\r\\n dXNlcm5hbWU6 是字符串 **username: ** 的 base64 码。\n我们输入我们的用户名 testformybook 的 base64 码，然后按回车：\ndGVzdGZvcm15Ym9vaw==\\r\\n 服务器应答状态码 334：\n334 UGFzc3dvcmQ6\\r\\n UGFzc3dvcmQ6 是字符串 Password: 的 base64 码。这里实际上要求我们输入的是上文介绍的授权码，而不是密码。\n我们输入 MjAxOWhoeHh0dHhz，并回车：\nMjAxOWhoeHh0dHhz\\r\\n 服务器提示我们授权成功（应答状态码 235）：\n235 Authentication successful\\r\\n 接着输入邮件的发件地址和收件地址，服务器也会给我们响应的应答（应答状态码 250）：\nmail from: \u0026lt;testformybook@163.com\u0026gt;\\r\\n 250 Mail OK\\r\\n rcpt to: \u0026lt;balloonwj@qq.com\u0026gt;\\r\\n 250 Mail OK\\r\\n 接着输入 data 命令设置邮件的主题、正文、对方收到邮件后显示的的发件人信息等：\ndata\\r\\n 354 End data with \u0026lt;CR\u0026gt;\u0026lt;LF\u0026gt;.\u0026lt;CR\u0026gt;\u0026lt;LF\u0026gt; 服务器应答 354，并且提示，如果确定结束输入邮件正文就先按一个回车键，再输入一个点 .，再接着回车，这样邮件就发送出去了。\n服务器应答 250：\n250 Mail OK queued as smtp10,DsCowADHAgQS1IBcwtExJA--.62308S2 1551946998 如果我们想退出，输入 quit 或 close 都可以。\n最终，这封邮件就发出去了，我们去 balloonwj@qq.com 这个邮箱查看一下：\n如果你在实际实验时，对端没有收到邮件，请查看下你的垃圾箱或者邮箱反垃圾邮件设置，有可能被邮箱反垃圾邮件机制给拦截了。\n上述在组装 SMTP 协议包时涉及到很多状态码，常见的 SMTP 状态码含义如下：\n211 帮助返回系统状态 214 帮助信息 220 服务准备就绪 221 关闭连接 235 用户验证成功 250 请求操作就绪 251 用户不在本地，转寄到其他路径 334 等待用户输入验证信息 354 开始邮件输入 421 服务不可用 450 操作未执行，邮箱忙 451 操作中止，本地错误 452 操作未执行，存储空间不足 500 命令不可识别或语言错误 501 参数语法错误 502 命令不支技 503 命令顺序错误 504 命令参数不支持 550 操作未执行，邮箱不可用 551 非本地用户 552 中止存储空间不足 553 操作未执行，邮箱名不正确 554 传输失败 由于我们使用的开发机器以 Windows 居多，默认情况下，Windows 系统的 telnet 命令是没有开启的，我们可以在【控制面板】- 【程序】- 【程序和功能】- 【打开或关闭Windows功能】中打开telnet功能。如下图所示：\n","permalink":"https://haokiu.com/blog/966ed73cc54b4cf5bdae1e1e5adba616/","summary":"利用 telnet 命令发电子邮件 telnet 命令是我们最常用的网络调试命令之一。如果你的机器上还没有安装 telnet 命令，可以使用如下命令安装一下：\nyum install telnet 如果一个服务程序对外开启了侦听服务，我们都可以使用 telnet ip port 来连接上去，例如：\n[root@localhost ~]# telnet 120.55.94.78 8888 Trying 120.55.94.78... Connected to 120.55.94.78. Escape character is \u0026#39;^]\u0026#39;. 如果不指定端口号，telnet 会使用默认 23 号端口。\n反过来说，可以通过 telnet 命令去检测指定 ip 地址和端口号的侦听服务是否存在。知道这点很重要，我们可以利用这个去检测一个服务是否可以正常连接。举个例子，比如某次从某处得到一个代码下载地址，这是一个 svn 地址：svn://120.55.94.78/mycode/mybook。为了检测这个 svn 服务是否还能正常对外服务，我们可以先用 ping 命令去检测一下到达这个 ip：120.55.94.78 的网络是否畅通：\n[root@localhost ~]# ping 120.55.94.78 PING 120.55.94.78 (120.55.94.78) 56(84) bytes of data. 64 bytes from 120.55.94.78: icmp_seq=1 ttl=128 time=15.3 ms 64 bytes from 120.55.94.78: icmp_seq=2 ttl=128 time=14.3 ms 64 bytes from 120.55.94.78: icmp_seq=3 ttl=128 time=16.4 ms 64 bytes from 120.55.94.78: icmp_seq=4 ttl=128 time=16.1 ms 64 bytes from 120.55.94.78: icmp_seq=5 ttl=128 time=15.5 ms ^C --- 120.55.94.78 ping statistics --- 5 packets transmitted, 5 received, 0% packet loss, time 4007ms rtt min/avg/max/mdev = 14.","title":"利用 telnet 命令发电子邮件"},{"content":"后台C++开发你一定要知道的条件变量 今天因为工作需要，需要帮同事用C语言（不是C++）写一个生产者消费者的任务队列工具库，考虑到不能使用任何第三库和C++的任何特性，所以我将任务队列做成一个链表，生产者在队列尾部加入任务，消费者在队列头部取出任务。很快就写好了，代码如下：\n/**\r* 线程池工具, ctrip_thread_pool.h\r* zhangyl 2018.03.23\r*/\r#ifndef __CTRIP_THREAD_POOL_H__\r#define __CTRIP_THREAD_POOL_H__\r#include \u0026lt;pthread.h\u0026gt;\r#ifndef NULL\r#define NULL 0\r#endif\r#define PUBLIC PUBLIC struct ctrip_task\r{\rstruct ctrip_task* pNext;\rint value;\r};\rstruct ctrip_thread_info\r{\r//线程退出标志\rint thread_running;\rint thread_num;\rint tasknum;\rstruct ctrip_task* tasks;\rpthread_t* threadid;\rpthread_mutex_t mutex;\rpthread_cond_t cond;\r};\r/* 初始化线程池线程数目\r* @param thread_num 线程数目, 默认为8个\r*/\rPUBLIC void ctrip_init_thread_pool(int thread_num);\r/* 销毁线程池\r*/\rPUBLIC void ctrip_destroy_thread_pool();\r/**向任务池中增加一个任务\r* @param t 需要增加的任务\r*/\rPUBLIC void ctrip_thread_pool_add_task(struct ctrip_task* t);\r/**从任务池中取出一个任务\r* @return 返回得到的任务\r*/\rstruct ctrip_task* ctrip_thread_pool_retrieve_task();\r/**执行任务池中的任务\r* @param t 需要执行的任务\r*/\rPUBLIC void ctrip_thread_pool_do_task(struct ctrip_task* t);\r/**线程函数\r* @param thread_param 线程参数\r*/\rvoid* ctrip_thread_routine(void* thread_param);\r#endif //!__CTRIP_THREAD_POOL_H__\r/**\r* 线程池工具, ctrip_thread_pool.c\r* zhangyl 2018.03.23\r*/\r#include \u0026#34;ctrip_thread_pool.h\u0026#34;\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\rstruct ctrip_thread_info g_threadinfo;\rint thread_running = 0;\rvoid ctrip_init_thread_pool(int thread_num)\r{\rif (thread_num \u0026lt;= 0)\rthread_num = 5;\rpthread_mutex_init(\u0026amp;g_threadinfo.mutex, NULL);\rpthread_cond_init(\u0026amp;g_threadinfo.cond, NULL);\rg_threadinfo.thread_num = thread_num;\rg_threadinfo.thread_running = 1;\rg_threadinfo.tasknum = 0;\rg_threadinfo.tasks = NULL;\rthread_running = 1;\rg_threadinfo.threadid = (pthread_t*)malloc(sizeof(pthread_t) * thread_num);\rint i;\rfor (i = 0; i \u0026lt; thread_num; ++i)\r{\rpthread_create(\u0026amp;g_threadinfo.threadid[i], NULL, ctrip_thread_routine, NULL);\r}\r}\rvoid ctrip_destroy_thread_pool()\r{\rg_threadinfo.thread_running = 0;\rthread_running = 0;\rpthread_cond_broadcast(\u0026amp;g_threadinfo.cond);\rint i;\rfor (i = 0; i \u0026lt; g_threadinfo.thread_num; ++i)\r{\rpthread_join(g_threadinfo.threadid[i], NULL);\r}\rfree(g_threadinfo.threadid);\rpthread_mutex_destroy(\u0026amp;g_threadinfo.mutex);\rpthread_cond_destroy(\u0026amp;g_threadinfo.cond);\r}\rvoid ctrip_thread_pool_add_task(struct ctrip_task* t)\r{\rif (t == NULL)\rreturn;\rpthread_mutex_lock(\u0026amp;g_threadinfo.mutex);\rstruct ctrip_task* head = g_threadinfo.tasks;\rif (head == NULL)\rg_threadinfo.tasks = t;\relse\r{\rwhile (head-\u0026gt;pNext != NULL)\r{\rhead = head-\u0026gt;pNext;\r}\rhead-\u0026gt;pNext = t;\r}\r++g_threadinfo.tasknum;\r//当有变化后，使用signal通知wait函数\rpthread_cond_signal(\u0026amp;g_threadinfo.cond);\rpthread_mutex_unlock(\u0026amp;g_threadinfo.mutex);\r}\rstruct ctrip_task* ctrip_thread_pool_retrieve_task()\r{\rstruct ctrip_task* head = g_threadinfo.tasks;\rif (head != NULL)\r{\rg_threadinfo.tasks = head-\u0026gt;pNext;\r--g_threadinfo.tasknum;\rprintf(\u0026#34;retrieve a task, task value is [%d]\\n\u0026#34;, head-\u0026gt;value);\rreturn head;\r}\rprintf(\u0026#34;no task\\n\u0026#34;);\rreturn NULL;\r}\rvoid* ctrip_thread_routine(void* thread_param)\r{\rprintf(\u0026#34;thread NO.%d start.\\n\u0026#34;, (int)pthread_self());\rwhile (thread_running/*g_threadinfo.thread_running*/)\r{\rstruct ctrip_task* current = NULL;\rpthread_mutex_lock(\u0026amp;g_threadinfo.mutex);\rwhile (g_threadinfo.tasknum \u0026lt;= 0)\r{\r//如果获得了互斥锁，但是条件不合适的话，wait会释放锁，不往下执行。\r//当变化后，条件合适，将直接获得锁。\rpthread_cond_wait(\u0026amp;g_threadinfo.cond, \u0026amp;g_threadinfo.mutex);\rif (!g_threadinfo.thread_running)\rbreak;\rcurrent = ctrip_thread_pool_retrieve_task();\rif (current != NULL)\rbreak;\r}// end inner-while-loop\rpthread_mutex_unlock(\u0026amp;g_threadinfo.mutex);\rctrip_thread_pool_do_task(current);\r}// end outer-while-loop\rprintf(\u0026#34;thread NO.%d exit.\\n\u0026#34;, (int)pthread_self());\r}\rvoid ctrip_thread_pool_do_task(struct ctrip_task* t)\r{\rif (t == NULL)\rreturn;\r//TODO: do your work here\rprintf(\u0026#34;task value is [%d]\\n\u0026#34;, t-\u0026gt;value);\r//TODO：如果t需要释放，记得在这里释放\r} 测试代码如下：\n// ctrip_thread_pool.cpp : Defines the entry point for the console application.\r//\r//#include \u0026#34;stdafx.h\u0026#34;\r#include \u0026#34;ctrip_thread_pool.h\u0026#34;\r#include \u0026lt;stdlib.h\u0026gt;\r#include \u0026lt;unistd.h\u0026gt;\rint main(int argc, char* argv[])\r{\rctrip_init_thread_pool(5);\rstruct ctrip_task* task = NULL;\rint i;\rfor (i = 0; i \u0026lt; 100; ++i)\r{\rtask = (struct ctrip_task*)malloc(sizeof(struct ctrip_task));\rtask-\u0026gt;value = i + 1;\rtask-\u0026gt;pNext = NULL;\rprintf(\u0026#34;add task, task value [%d]\\n\u0026#34;, task-\u0026gt;value);\rctrip_thread_pool_add_task(task);\r}\rsleep(10);\rctrip_destroy_thread_pool();\rreturn 0;\r} 代码很快就写好了，但是每次程序只能执行前几个加到任务池子里面的任务，导致池子有不少任务积累在池子里面。甚是奇怪，我也看了半天才看出结果。聪明的你，能看出上述代码为啥只能执行加到池子里面的前几个任务？先不要看答案，自己想一会儿。\nlinux条件变量是做后台开发必须熟练掌握的基础知识，而条件变量使用存在以下几个非常让人迷惑的地方，讲解如下\n第一、必须要结合一个互斥体一起使用。使用流程如下：\npthread_mutex_lock(\u0026amp;g_threadinfo.mutex) pthread_cond_wait(\u0026amp;g_threadinfo.cond, \u0026amp;g_threadinfo.mutex);\rpthread_mutex_unlock(\u0026amp;g_threadinfo.mutex); 上面的代码，我们分为一二三步，当条件不满足是pthread_cond_wait会挂起线程，但是不知道你有没有注意到，如果在第二步挂起线程的话，第一步的mutex已经被上锁，谁来解锁？mutex的使用原则是谁上锁谁解锁，所以不可能在其他线程来给这个mutex解锁，但是这个线程已经挂起了，这就死锁了。所以pthread_cond_wait在挂起之前，额外做的一个事情就是给绑定的mutex解锁。反过来，如果条件满足，pthread_cond_wait不挂起线程，pthread_cond_wait将什么也不做，这样就接着走pthread_mutex_unlock解锁的流程。而在这个加锁和解锁之间的代码就是我们操作受保护资源的地方。\n第二，不知道你有没有注意到pthread_cond_wait是放在一个while循环里面的：\npthread_mutex_lock(\u0026amp;g_threadinfo.mutex);\rwhile (g_threadinfo.tasknum \u0026lt;= 0)\r{\r//如果获得了互斥锁，但是条件不合适的话，wait会释放锁，不往下执行。\r//当变化后，条件合适，将直接获得锁。\rpthread_cond_wait(\u0026amp;g_threadinfo.cond, \u0026amp;g_threadinfo.mutex);\rif (!g_threadinfo.thread_running)\rbreak;\rcurrent = ctrip_thread_pool_retrieve_task();\rif (current != NULL)\rbreak;\r}// end inner-while-loop\rpthread_mutex_unlock(\u0026amp;g_threadinfo.mutex); 注意，我说的是内层的while循环，不是外层的。pthread_cond_wait一定要放在一个while循环里面吗？一定要的。这里有一个非常重要的关于条件变量的基础知识，叫条件变量的虚假唤醒（spurious wakeup），那啥叫条件变量的虚假唤醒呢？假设pthread_cond_wait不放在这个while循环里面，正常情况下，pthread_cond_wait因为条件不满足，挂起线程。然后，外部条件满足以后，调用pthread_cond_signal或pthread_cond_broadcast来唤醒挂起的线程。这没啥问题。但是条件变量可能在某些情况下也被唤醒，这个时候pthread_cond_wait处继续往下执行，但是这个时候，条件并不满足（比如任务队列中仍然为空）。这种唤醒我们叫“虚假唤醒”。为了避免虚假唤醒时，做无意义的动作，我们将pthread_cond_wait放到while循环条件中，这样即使被虚假唤醒了，由于while条件（比如任务队列是否为空，资源数量是否大于0）仍然为true，导致线程进行继续挂起。有人说条件变量是最不可能用错的线程之间同步技术，我却觉得这是最容易使用错误的线程之间同步技术。\n上述代码存在的问题是，只考虑了任务队列开始为空，生产者后来添加了任务，条件变量被唤醒，然后消费者取任务执行的逻辑。假如一开始池中就有任务呢？这个原因导致，只有开始的几个添加到任务队列中任务被执行。因为一旦任务队列不为空。内层while循环条件将不再满足，导致消费者线程不再从任务队列中取任务消费。正确的代码如下：\n/**\r* 线程池工具, ctrip_thread_pool.c（修正后的代码）\r* zhangyl 2018.03.23\r*/\r#include \u0026#34;ctrip_thread_pool.h\u0026#34;\r#include \u0026lt;stdio.h\u0026gt;\r#include \u0026lt;stdlib.h\u0026gt;\rstruct ctrip_thread_info g_threadinfo;\rvoid ctrip_init_thread_pool(int thread_num)\r{\rif (thread_num \u0026lt;= 0)\rthread_num = 5;\rpthread_mutex_init(\u0026amp;g_threadinfo.mutex, NULL);\rpthread_cond_init(\u0026amp;g_threadinfo.cond, NULL);\rg_threadinfo.thread_num = thread_num;\rg_threadinfo.thread_running = 1;\rg_threadinfo.tasknum = 0;\rg_threadinfo.tasks = NULL;\rg_threadinfo.threadid = (pthread_t*)malloc(sizeof(pthread_t) * thread_num);\rint i;\rfor (i = 0; i \u0026lt; thread_num; ++i)\r{\rpthread_create(\u0026amp;g_threadinfo.threadid[i], NULL, ctrip_thread_routine, NULL);\r}\r}\rvoid ctrip_destroy_thread_pool()\r{\rg_threadinfo.thread_running = 0;\rpthread_cond_broadcast(\u0026amp;g_threadinfo.cond);\rint i;\rfor (i = 0; i \u0026lt; g_threadinfo.thread_num; ++i)\r{\rpthread_join(g_threadinfo.threadid[i], NULL);\r}\rfree(g_threadinfo.threadid);\rpthread_mutex_destroy(\u0026amp;g_threadinfo.mutex);\rpthread_cond_destroy(\u0026amp;g_threadinfo.cond);\r}\rvoid ctrip_thread_pool_add_task(struct ctrip_task* t)\r{\rif (t == NULL)\rreturn;\rpthread_mutex_lock(\u0026amp;g_threadinfo.mutex);\rstruct ctrip_task* head = g_threadinfo.tasks;\rif (head == NULL)\rg_threadinfo.tasks = t;\relse\r{\rwhile (head-\u0026gt;pNext != NULL)\r{\rhead = head-\u0026gt;pNext;\r}\rhead-\u0026gt;pNext = t;\r}\r++g_threadinfo.tasknum;\r//当有变化后，使用signal通知wait函数\rpthread_cond_signal(\u0026amp;g_threadinfo.cond);\rpthread_mutex_unlock(\u0026amp;g_threadinfo.mutex);\r}\rstruct ctrip_task* ctrip_thread_pool_retrieve_task()\r{\rstruct ctrip_task* head = g_threadinfo.tasks;\rif (head != NULL)\r{\rg_threadinfo.tasks = head-\u0026gt;pNext;\r--g_threadinfo.tasknum;\rprintf(\u0026#34;retrieve a task, task value is [%d]\\n\u0026#34;, head-\u0026gt;value);\rreturn head;\r}\rprintf(\u0026#34;no task\\n\u0026#34;);\rreturn NULL;\r}\rvoid* ctrip_thread_routine(void* thread_param)\r{\rprintf(\u0026#34;thread NO.%d start.\\n\u0026#34;, (int)pthread_self());\rwhile (g_threadinfo.thread_running)\r{\rstruct ctrip_task* current = NULL;\rpthread_mutex_lock(\u0026amp;g_threadinfo.mutex);\rwhile (g_threadinfo.tasknum \u0026lt;= 0)\r{\r//如果获得了互斥锁，但是条件不合适的话，wait会释放锁，不往下执行。\r//当变化后，条件合适，将直接获得锁。\rpthread_cond_wait(\u0026amp;g_threadinfo.cond, \u0026amp;g_threadinfo.mutex);\rif (!g_threadinfo.thread_running)\rbreak;\r}// end inner-while-loop\rcurrent = ctrip_thread_pool_retrieve_task();\rpthread_mutex_unlock(\u0026amp;g_threadinfo.mutex);\rctrip_thread_pool_do_task(current);\r}// end outer-while-loop\rprintf(\u0026#34;thread NO.%d exit.\\n\u0026#34;, (int)pthread_self());\r}\rvoid ctrip_thread_pool_do_task(struct ctrip_task* t)\r{\rif (t == NULL)\rreturn;\r//TODO: do your work here\rprintf(\u0026#34;task value is [%d]\\n\u0026#34;, t-\u0026gt;value);\r//TODO：如果t需要释放，记得在这里释放\r} ok，不知道你有没有看明白呀？\n","permalink":"https://haokiu.com/blog/3418f291fe18455999e74a1f1dbad72a/","summary":"后台C++开发你一定要知道的条件变量 今天因为工作需要，需要帮同事用C语言（不是C++）写一个生产者消费者的任务队列工具库，考虑到不能使用任何第三库和C++的任何特性，所以我将任务队列做成一个链表，生产者在队列尾部加入任务，消费者在队列头部取出任务。很快就写好了，代码如下：\n/**\r* 线程池工具, ctrip_thread_pool.h\r* zhangyl 2018.03.23\r*/\r#ifndef __CTRIP_THREAD_POOL_H__\r#define __CTRIP_THREAD_POOL_H__\r#include \u0026lt;pthread.h\u0026gt;\r#ifndef NULL\r#define NULL 0\r#endif\r#define PUBLIC PUBLIC struct ctrip_task\r{\rstruct ctrip_task* pNext;\rint value;\r};\rstruct ctrip_thread_info\r{\r//线程退出标志\rint thread_running;\rint thread_num;\rint tasknum;\rstruct ctrip_task* tasks;\rpthread_t* threadid;\rpthread_mutex_t mutex;\rpthread_cond_t cond;\r};\r/* 初始化线程池线程数目\r* @param thread_num 线程数目, 默认为8个\r*/\rPUBLIC void ctrip_init_thread_pool(int thread_num);\r/* 销毁线程池\r*/\rPUBLIC void ctrip_destroy_thread_pool();\r/**向任务池中增加一个任务\r* @param t 需要增加的任务\r*/\rPUBLIC void ctrip_thread_pool_add_task(struct ctrip_task* t);\r/**从任务池中取出一个任务\r* @return 返回得到的任务\r*/\rstruct ctrip_task* ctrip_thread_pool_retrieve_task();\r/**执行任务池中的任务\r* @param t 需要执行的任务\r*/\rPUBLIC void ctrip_thread_pool_do_task(struct ctrip_task* t);\r/**线程函数\r* @param thread_param 线程参数\r*/\rvoid* ctrip_thread_routine(void* thread_param);\r#endif //!","title":"后台C++开发你一定要知道的条件变量"},{"content":"后台开发应该读的书 根据我的经验来谈一谈，先介绍一下我的情况，坐标上海，后台开发（也带团队了），某知名互联网公司。\n目前主流的有C++和JAVA，C++我的经验稍微多一点。我就说说我关于C++方面的学习经验。如果您是学生，临近毕业，没有那么多时间读许多书，可以按下面列举的重要程度来参考。\n首先，我觉得你应该好好准备算法和数据结构，做到常见的算法和数据结构知识点都能非常熟悉，这样的话你毕业求职的时候可以轻松拿一些大厂（BAT等）的offer。我本人非科班出身，一毕业之后各种摸爬滚打。一毕业去大厂个人觉得有两个好处，第一，你的收入会比一般的的小公司高很多，小公司招人要求相对低一些，薪资给的也少很多，它们是实实在在招能干本职工作活儿的人。第二，你的起点也会比一般进入小厂的同学高。我这里并不是歧视小厂，只是说一种普遍的情况。我本人也是从小厂一路过来的。这里我是强调算法和数据结构的重要性。尤其是应届生求职，更应该去好好准备一下这个，因为这个东西是原理性的基础。企业在面试应届生时不会过分要求项目经验和各种操作系统原理、网络通信原理之类的东西，而唯一能考察一个人的基本功的就是这个了。我是社招进大厂，基本上算法和数据结构这类问题问的比项目经验本身要多许多。但是社招又不太一样，因为除了要准备算法和数据结构以外，还得准备有项目经验、了解操作系统原理、熟悉网络通信、了解数据库、熟悉要求的各种开源框架和技术等等，实在太多了，即使再怎么准备也不一定能一举拿下。相反，应届生基本上只要好好准备算法和数据结构的东西，大学其他专业课学的不是太差，这基本上就是进大厂的捷径。图书方面，你可以使用你们计算机专业的相关教材，也可以使用《数据结构与算法分析:C语言描述》《算法导论》这一类严谨的教材，当然，平心而论我是不敢推荐《算法导论》的，因为这一本书实在是太大部头了，没有好的数学知识，真的很难啃。如果想看一下比较幽默轻松类的书，可以看看程杰的《大话数据结构》。\n其次，如果你学有余力，可以看看操作系统原理方面的书籍，当然也可以使用你们的教材，我这里推荐一本我看过的吧，Tanenbaum.A.S《现代操作系统》，Tanenbaum是荷兰人，也是Linux之父Linus Torvalds操作系统方面的启蒙老师。当然，我的建议是这种书毕竟流于理论知识，也不一定要看完，但**一定将一些基础概念，如进程线程内存模式等基础概念看懂理解。**你如果还有时间强烈推荐看看俞甲子的《程序员的自我修养:链接、装载与库》，这本书同时涉及到了Windows和linux两个操作系统平台，用各种辅助工具剖析了程序从源码到二进制文件再到装载到进程地址空间里面的各个细节，甚至连进程地址空间中的堆结构、栈结构也分析得清清楚楚，同时也分析了C Runtime（CRT）、glibc这样的操作系统接口库的原理和执行逻辑，是一本实实在在难得的帮你实战操作系统原理的一本好书。我特别喜欢这个书中序言的一段话：\n“CPU体系结构、汇编、C语言（包括C++）和操作系统，永远都是编程大师们的护身法宝，就如同少林寺的《易筋经》，是最为上乘的武功；学会了《易筋经》，你将无所不能，任你创造武功；学会了编程“易筋经”，大师们可以任意开发操作系统、编译器，甚至是开发一种新的程序设计语言！”\n再次，你学这些东西是为了将来实践并有产出的，而落实这个产出的东西就是编程语言，如果是入门，我首推C/C++。你只有熟练使用一门编程语言，你才能将你的想法变成现实。注意这里我把C和C++放在一起，但是严格意义上说，C和C++还是有点区别的，但是除了语法上的一些细节差异，基本上可以认为是相通的。个人觉得C语言是所有想成为高手最应该使用的入门语言，不要和我说现在很火的python、go这类语言，“玄都观里桃千树，尽是刘郎去后栽”。我这里也推荐一本C语言方面的图书吧，有兴趣的可以参考一下：《C语言程序设计:现代方法》。至于谭浩强的书就不要提了，还有就是大部头的《C++ Primer》，它虽然是一本好书，但实在是太大部头了。语法层面的东西学会很快，stl库的东西需要实战，也不是翻这类字典一样的书就能很好地掌握的。当然，如果你想掌握好C++，《深度探索C++对象模型》是一定要看的。C++实际编码技巧还有另外一本非常好的书，介绍了常见的C++编码技巧《提高C++性能的编程技术》，建议C++开发的把书中说的技巧全部掌握。\n接着说，我们再说说网络方面的，首先网络基础方面的书籍，我就没啥推荐了，现在很多计算机学院也开始使用《计算机网络:自顶向下方法》这本不错的教材，如果没有看过的可以看下。当然还是那句话你一定要看懂而不是看完。比如三次握手和四次挥手的细节，你一定要很清楚。然后你就可以找一本网络编程的实战书来看下，如果你没有使用任何socket api编程的经验，你可以看看韩国人尹圣雨写的这本《TCP/IP网络编程》，这本书从基础的socket api介绍到比较高级的io复用技术，有非常详细和生动的例子。如果你是初级水平，强烈建议看看这本书。网络编程的细节需要注意的地方实在太多了，这本书上都有介绍。很多人尤其是一些学生，写了一些可以相互聊天的小程序就觉得自己熟悉网络通信了，但是这类程序拿到互联网上或者离开局域网，不是连接出错，就是数据总是收发不全。我当年也是这么过来的，看看这本书，你就能明白许多网络故障的原因。等你有了一定的网络编程以后（熟练使用常见socket API），你可以看看游双的《Linux高性能服务器编程》，这本书给没有基础的人或者基础不扎实的人的感觉是，尤其是书的前三章，这书怎么这么垃圾，又把网络理论书上面的东西搬过来凑字数，但是如果你有基础再按照书上的步骤在机器上实践一遍，你会发现，真是一本难得的、良心的书，桃李不言下自成蹊吧。如果你掌握了这本说上说的这些知识，你再看陈硕老师的《Linux多线程服务端编程》或者去看像libevent这样的开源网络库，你会进一步的得到提升。这也是我学习网络编程的一些经验和经历吧。注意这里有必要提一下：像UNP、APUE、还有《TCP/IP详解》这一类书，如果你将来不是专门做网络方面的工作或研究，其实是非常不建议抱着他们看的，因为部头太大，其次太多理论和Unix的东西，花的时间产出投入比很低的。\n接着说，以上说的都是一些基础的东西。其实不管是什么开发，后台开发也不例外，你都是需要基于特定的操作系统的，这里不提Windows系统，单单拿linux操作系统来说，既然你选择做这个方面的开发，你需要熟悉这个操作系统平台提供的一些常用的API函数，网络通信方面上文已经说过，除了网络通信还有如操作文件、操作内存、字符串操作、进程线程系列、线程同步系列（如互斥体、条件变量、信号量）、管道等常用的各种API接口函数。这里的意思是，不是要你背诵记忆每一个接口函数的签名，而是你要知道何时该用哪个接口，如何用，有什么注意事项。我入门的时候看的是Robert Love的《Linux系统编程》，熟悉这个人的应该知道，google的工程师，他还有另外一本非常有名的书《Linux内核设计与实现》。\n最后，我强调一下，如果你是快毕业的学生，面临着找工作的压力，应该以算法和数据结构为主。如果你是大一大二或研一这个阶段的学生，我上面推荐的书，你还是可以考虑好好咀嚼一下。标准是看懂而不是看完。\n再补充一些我觉得要成为高手应该要掌握的东西，先说汇编。虽然第三代第四代语言越来越多，硬件性能越来越好。但是如果你熟练掌握汇编，你就比其他人多很多优势，你会能透彻地知道你写的每一行C/C++代码背后的机器指令的效率。无论是做安全工程还是自己技术提升上都是非常不错的。这里推荐一本王爽老师的《汇编语言(第3版)》，这本书不厚，语言通俗易懂，你也不用刻意去记忆，基本上当小说书看一下就能很快看完了。汇编实战类图书还有另外一本《老\u0026quot;码\u0026quot;识途:从机器码到框架的系统观逆向修炼之路》。我个人是非常喜欢这本书的。当年读这本书的时候，真的有一种“笑看妻子愁何在？漫卷诗书喜欲狂”的感觉。尽管那个时候连女朋友都没有——！\n另外补充一些我学生时代看过的书吧，我本人是熟悉Windows和linux两个平台的开发，这也归功于我学生时代看过的一些经典书籍，可能有点跑题了，如果不介意，我可以和你说说：\n《Windows程序设计》第五版（第六版以后，这个不再是用Windows Native API写C程序了，而是转到C#平台上了），这本书是中国第一代程序的windows启蒙书籍，你所看到的大多数桌面软件，如QQ，的开发者可能都是通过阅读这本书启蒙起来的。 《Windows核心编程》，这本书搞Windows开发的一定都知道这本书的分量。 《linux内核情景分析》毛德操老师的书，非常的实在，另外他写了一套关于Windows源码分析的书，这本书是基于开源的“Windows”ReactOS，书名叫《Windows内核情景分析》。 《编译系统透视：图解编译原理》，编译原理方面的实践书。 《编程之美》，关于面试的，主要是一些算法和逻辑思维题实战。 《重构：改善既有代码设计》，没有实际写代码经验不推荐看。 《程序员的修炼之道——从小工到专家》这本书特别推荐学生看一下，能大幅度地提高你实际编码的技巧和编码风格。 《代码整洁之道》同上 《大话设计模式》 《Windows PE文件权威指南》 《Java编程思想》 《Effective C++》系列 《80x86汇编语言程序设计教程》 总的来看，我学生时代主要是侧重基础知识来读书的。本科四年、硕士三年，多谢这些书帮助我成长，记得大学毕业的时候，我光读书笔记就有满满十个笔记本。\n工作以后，也读了像redis、netty、分布式这一类书。但是那都是工作需要吧。由于我扎实的基础，当然也可能是因为运气成分吧吧，所以得到一些注重扎实的技术基础公司的青睐，给了目前这个阶段看起来还不错的薪资（当然可能还有人比我更厉害，那我这里就贻笑大方了，所以请不喜勿喷）。同时非常感谢我一路上遇到的公司和同事给我的技术上和生活上的帮助。薪资本身不能说明一个人是否成功，我码这么多字，**希望广大的开发者注重基础，勿在浮沙筑高台。尤其是学生，你有大把读书的机会，一定要珍惜大学时光。毕竟工作以后，尤其是毕业后，面临着工作、家庭等各种问题，你可能再也没有心思和完整的时间去学习和提升了。**所以前期的积累很重要，毕竟选择技术这条路，提高技术是升职加薪改善生活水平最直接的方法。最后用我学生时代看到一个技术前辈写的一首诗来结束吧：\n仗鼠红尘已是癫，\n有网平步上青天。\n游星戏斗弄日月，\n醉卧云端笑人间。\n七载寻梦像扑火，\n九州谁共我疯癫？\n以上是我的经历，我也曾迷惘和无助过。也有很多朋友找到我，希望我做一些经验分享和职业规划指导，有需要的小伙伴可以加我微信 easy_coder。\n","permalink":"https://haokiu.com/blog/b46f16d0f9f8415e94eb76455deea0f0/","summary":"后台开发应该读的书 根据我的经验来谈一谈，先介绍一下我的情况，坐标上海，后台开发（也带团队了），某知名互联网公司。\n目前主流的有C++和JAVA，C++我的经验稍微多一点。我就说说我关于C++方面的学习经验。如果您是学生，临近毕业，没有那么多时间读许多书，可以按下面列举的重要程度来参考。\n首先，我觉得你应该好好准备算法和数据结构，做到常见的算法和数据结构知识点都能非常熟悉，这样的话你毕业求职的时候可以轻松拿一些大厂（BAT等）的offer。我本人非科班出身，一毕业之后各种摸爬滚打。一毕业去大厂个人觉得有两个好处，第一，你的收入会比一般的的小公司高很多，小公司招人要求相对低一些，薪资给的也少很多，它们是实实在在招能干本职工作活儿的人。第二，你的起点也会比一般进入小厂的同学高。我这里并不是歧视小厂，只是说一种普遍的情况。我本人也是从小厂一路过来的。这里我是强调算法和数据结构的重要性。尤其是应届生求职，更应该去好好准备一下这个，因为这个东西是原理性的基础。企业在面试应届生时不会过分要求项目经验和各种操作系统原理、网络通信原理之类的东西，而唯一能考察一个人的基本功的就是这个了。我是社招进大厂，基本上算法和数据结构这类问题问的比项目经验本身要多许多。但是社招又不太一样，因为除了要准备算法和数据结构以外，还得准备有项目经验、了解操作系统原理、熟悉网络通信、了解数据库、熟悉要求的各种开源框架和技术等等，实在太多了，即使再怎么准备也不一定能一举拿下。相反，应届生基本上只要好好准备算法和数据结构的东西，大学其他专业课学的不是太差，这基本上就是进大厂的捷径。图书方面，你可以使用你们计算机专业的相关教材，也可以使用《数据结构与算法分析:C语言描述》《算法导论》这一类严谨的教材，当然，平心而论我是不敢推荐《算法导论》的，因为这一本书实在是太大部头了，没有好的数学知识，真的很难啃。如果想看一下比较幽默轻松类的书，可以看看程杰的《大话数据结构》。\n其次，如果你学有余力，可以看看操作系统原理方面的书籍，当然也可以使用你们的教材，我这里推荐一本我看过的吧，Tanenbaum.A.S《现代操作系统》，Tanenbaum是荷兰人，也是Linux之父Linus Torvalds操作系统方面的启蒙老师。当然，我的建议是这种书毕竟流于理论知识，也不一定要看完，但**一定将一些基础概念，如进程线程内存模式等基础概念看懂理解。**你如果还有时间强烈推荐看看俞甲子的《程序员的自我修养:链接、装载与库》，这本书同时涉及到了Windows和linux两个操作系统平台，用各种辅助工具剖析了程序从源码到二进制文件再到装载到进程地址空间里面的各个细节，甚至连进程地址空间中的堆结构、栈结构也分析得清清楚楚，同时也分析了C Runtime（CRT）、glibc这样的操作系统接口库的原理和执行逻辑，是一本实实在在难得的帮你实战操作系统原理的一本好书。我特别喜欢这个书中序言的一段话：\n“CPU体系结构、汇编、C语言（包括C++）和操作系统，永远都是编程大师们的护身法宝，就如同少林寺的《易筋经》，是最为上乘的武功；学会了《易筋经》，你将无所不能，任你创造武功；学会了编程“易筋经”，大师们可以任意开发操作系统、编译器，甚至是开发一种新的程序设计语言！”\n再次，你学这些东西是为了将来实践并有产出的，而落实这个产出的东西就是编程语言，如果是入门，我首推C/C++。你只有熟练使用一门编程语言，你才能将你的想法变成现实。注意这里我把C和C++放在一起，但是严格意义上说，C和C++还是有点区别的，但是除了语法上的一些细节差异，基本上可以认为是相通的。个人觉得C语言是所有想成为高手最应该使用的入门语言，不要和我说现在很火的python、go这类语言，“玄都观里桃千树，尽是刘郎去后栽”。我这里也推荐一本C语言方面的图书吧，有兴趣的可以参考一下：《C语言程序设计:现代方法》。至于谭浩强的书就不要提了，还有就是大部头的《C++ Primer》，它虽然是一本好书，但实在是太大部头了。语法层面的东西学会很快，stl库的东西需要实战，也不是翻这类字典一样的书就能很好地掌握的。当然，如果你想掌握好C++，《深度探索C++对象模型》是一定要看的。C++实际编码技巧还有另外一本非常好的书，介绍了常见的C++编码技巧《提高C++性能的编程技术》，建议C++开发的把书中说的技巧全部掌握。\n接着说，我们再说说网络方面的，首先网络基础方面的书籍，我就没啥推荐了，现在很多计算机学院也开始使用《计算机网络:自顶向下方法》这本不错的教材，如果没有看过的可以看下。当然还是那句话你一定要看懂而不是看完。比如三次握手和四次挥手的细节，你一定要很清楚。然后你就可以找一本网络编程的实战书来看下，如果你没有使用任何socket api编程的经验，你可以看看韩国人尹圣雨写的这本《TCP/IP网络编程》，这本书从基础的socket api介绍到比较高级的io复用技术，有非常详细和生动的例子。如果你是初级水平，强烈建议看看这本书。网络编程的细节需要注意的地方实在太多了，这本书上都有介绍。很多人尤其是一些学生，写了一些可以相互聊天的小程序就觉得自己熟悉网络通信了，但是这类程序拿到互联网上或者离开局域网，不是连接出错，就是数据总是收发不全。我当年也是这么过来的，看看这本书，你就能明白许多网络故障的原因。等你有了一定的网络编程以后（熟练使用常见socket API），你可以看看游双的《Linux高性能服务器编程》，这本书给没有基础的人或者基础不扎实的人的感觉是，尤其是书的前三章，这书怎么这么垃圾，又把网络理论书上面的东西搬过来凑字数，但是如果你有基础再按照书上的步骤在机器上实践一遍，你会发现，真是一本难得的、良心的书，桃李不言下自成蹊吧。如果你掌握了这本说上说的这些知识，你再看陈硕老师的《Linux多线程服务端编程》或者去看像libevent这样的开源网络库，你会进一步的得到提升。这也是我学习网络编程的一些经验和经历吧。注意这里有必要提一下：像UNP、APUE、还有《TCP/IP详解》这一类书，如果你将来不是专门做网络方面的工作或研究，其实是非常不建议抱着他们看的，因为部头太大，其次太多理论和Unix的东西，花的时间产出投入比很低的。\n接着说，以上说的都是一些基础的东西。其实不管是什么开发，后台开发也不例外，你都是需要基于特定的操作系统的，这里不提Windows系统，单单拿linux操作系统来说，既然你选择做这个方面的开发，你需要熟悉这个操作系统平台提供的一些常用的API函数，网络通信方面上文已经说过，除了网络通信还有如操作文件、操作内存、字符串操作、进程线程系列、线程同步系列（如互斥体、条件变量、信号量）、管道等常用的各种API接口函数。这里的意思是，不是要你背诵记忆每一个接口函数的签名，而是你要知道何时该用哪个接口，如何用，有什么注意事项。我入门的时候看的是Robert Love的《Linux系统编程》，熟悉这个人的应该知道，google的工程师，他还有另外一本非常有名的书《Linux内核设计与实现》。\n最后，我强调一下，如果你是快毕业的学生，面临着找工作的压力，应该以算法和数据结构为主。如果你是大一大二或研一这个阶段的学生，我上面推荐的书，你还是可以考虑好好咀嚼一下。标准是看懂而不是看完。\n再补充一些我觉得要成为高手应该要掌握的东西，先说汇编。虽然第三代第四代语言越来越多，硬件性能越来越好。但是如果你熟练掌握汇编，你就比其他人多很多优势，你会能透彻地知道你写的每一行C/C++代码背后的机器指令的效率。无论是做安全工程还是自己技术提升上都是非常不错的。这里推荐一本王爽老师的《汇编语言(第3版)》，这本书不厚，语言通俗易懂，你也不用刻意去记忆，基本上当小说书看一下就能很快看完了。汇编实战类图书还有另外一本《老\u0026quot;码\u0026quot;识途:从机器码到框架的系统观逆向修炼之路》。我个人是非常喜欢这本书的。当年读这本书的时候，真的有一种“笑看妻子愁何在？漫卷诗书喜欲狂”的感觉。尽管那个时候连女朋友都没有——！\n另外补充一些我学生时代看过的书吧，我本人是熟悉Windows和linux两个平台的开发，这也归功于我学生时代看过的一些经典书籍，可能有点跑题了，如果不介意，我可以和你说说：\n《Windows程序设计》第五版（第六版以后，这个不再是用Windows Native API写C程序了，而是转到C#平台上了），这本书是中国第一代程序的windows启蒙书籍，你所看到的大多数桌面软件，如QQ，的开发者可能都是通过阅读这本书启蒙起来的。 《Windows核心编程》，这本书搞Windows开发的一定都知道这本书的分量。 《linux内核情景分析》毛德操老师的书，非常的实在，另外他写了一套关于Windows源码分析的书，这本书是基于开源的“Windows”ReactOS，书名叫《Windows内核情景分析》。 《编译系统透视：图解编译原理》，编译原理方面的实践书。 《编程之美》，关于面试的，主要是一些算法和逻辑思维题实战。 《重构：改善既有代码设计》，没有实际写代码经验不推荐看。 《程序员的修炼之道——从小工到专家》这本书特别推荐学生看一下，能大幅度地提高你实际编码的技巧和编码风格。 《代码整洁之道》同上 《大话设计模式》 《Windows PE文件权威指南》 《Java编程思想》 《Effective C++》系列 《80x86汇编语言程序设计教程》 总的来看，我学生时代主要是侧重基础知识来读书的。本科四年、硕士三年，多谢这些书帮助我成长，记得大学毕业的时候，我光读书笔记就有满满十个笔记本。\n工作以后，也读了像redis、netty、分布式这一类书。但是那都是工作需要吧。由于我扎实的基础，当然也可能是因为运气成分吧吧，所以得到一些注重扎实的技术基础公司的青睐，给了目前这个阶段看起来还不错的薪资（当然可能还有人比我更厉害，那我这里就贻笑大方了，所以请不喜勿喷）。同时非常感谢我一路上遇到的公司和同事给我的技术上和生活上的帮助。薪资本身不能说明一个人是否成功，我码这么多字，**希望广大的开发者注重基础，勿在浮沙筑高台。尤其是学生，你有大把读书的机会，一定要珍惜大学时光。毕竟工作以后，尤其是毕业后，面临着工作、家庭等各种问题，你可能再也没有心思和完整的时间去学习和提升了。**所以前期的积累很重要，毕竟选择技术这条路，提高技术是升职加薪改善生活水平最直接的方法。最后用我学生时代看到一个技术前辈写的一首诗来结束吧：\n仗鼠红尘已是癫，\n有网平步上青天。\n游星戏斗弄日月，\n醉卧云端笑人间。\n七载寻梦像扑火，\n九州谁共我疯癫？\n以上是我的经历，我也曾迷惘和无助过。也有很多朋友找到我，希望我做一些经验分享和职业规划指导，有需要的小伙伴可以加我微信 easy_coder。","title":"后台开发应该读的书"},{"content":"后端开发相关的书籍 后台开发应该读的书 ","permalink":"https://haokiu.com/blog/624d2104f4a54c50940f5de425c06ab0/","summary":"后端开发相关的书籍 后台开发应该读的书 ","title":"后端开发相关的书籍"},{"content":"多线程 后台C++开发你一定要知道的条件变量\n整型变量赋值是原子操作吗？\n","permalink":"https://haokiu.com/blog/dd345ae60ca14a61866fcc2f232aed74/","summary":"多线程 后台C++开发你一定要知道的条件变量\n整型变量赋值是原子操作吗？","title":"多线程"},{"content":"如何使用 Visual Studio 管理和阅读开源项目代码 对于 Linux C/C++ 项目，虽然我们在 Linux 系统中使用 gdb 去调试，但是通常情况下对于 C/C++ 项目笔者一般习惯使用 Visual Studio 去做项目管理，Visual Studio 提供了强大的 C/C++ 项目开发和管理能力。这里以 redis 源码为例，介绍一下如何将这种开源项目整体添加到 Visual Studio 的解决方案中去。\n启动 Visual Studio 新建一个空的 Win32 控制台程序。(工程建好后，关闭该工程防止接下来的步骤中文件占用导致的无法移动。) \\2. 这样会在 redis 源码目录下会根据你设置的名称生成一个文件夹（这里是 redis-4.0.1），将该文件夹中所有文件拷贝到 redis 源码根目录，然后删掉生成的这个文件夹。\n\\3. 再次用 Visual Studio 打开 redis-4.0.1.sln 文件，然后在解决方案资源管理器视图中点击显示所有文件按钮并保持该按钮选中。（如果找不到解决方案资源管理器视图，可以在【视图】菜单中打开，快捷键 Ctrl + Alt + L。）\n\\4. 然后选中所有需要添加到解决方案中的文件，右键选择菜单【包括在项目中】即可，如果文件比较多，Visual Studio 可能需要一会儿才能完成，为了减少等待时间，读者也可以一批一批的添加。\n5.接着选择【文件】菜单【全部保存】菜单项保存即可（快捷键 Ctrl + Shift + S ）。\n最终效果如下图所示：\n这样我们就能利用 Visual Studio 强大的功能管理和阅读我们的源码了。\n这里要提醒一下读者：C/C++ 开源项目中一般会使用各种宏去条件编译一些代码，实际生成的二进制文件中不一定包含这些代码，所以在 Visual Studio 中看到某段代码的行号与实际在 gdb 中调试的代码行号不一定相同，在给某一行代码设置断点时请以 gdb 中 list 命令看到的代码行号为准。\n","permalink":"https://haokiu.com/blog/9a2768ae509d48689a05cf010b262b09/","summary":"如何使用 Visual Studio 管理和阅读开源项目代码 对于 Linux C/C++ 项目，虽然我们在 Linux 系统中使用 gdb 去调试，但是通常情况下对于 C/C++ 项目笔者一般习惯使用 Visual Studio 去做项目管理，Visual Studio 提供了强大的 C/C++ 项目开发和管理能力。这里以 redis 源码为例，介绍一下如何将这种开源项目整体添加到 Visual Studio 的解决方案中去。\n启动 Visual Studio 新建一个空的 Win32 控制台程序。(工程建好后，关闭该工程防止接下来的步骤中文件占用导致的无法移动。) \\2. 这样会在 redis 源码目录下会根据你设置的名称生成一个文件夹（这里是 redis-4.0.1），将该文件夹中所有文件拷贝到 redis 源码根目录，然后删掉生成的这个文件夹。\n\\3. 再次用 Visual Studio 打开 redis-4.0.1.sln 文件，然后在解决方案资源管理器视图中点击显示所有文件按钮并保持该按钮选中。（如果找不到解决方案资源管理器视图，可以在【视图】菜单中打开，快捷键 Ctrl + Alt + L。）\n\\4. 然后选中所有需要添加到解决方案中的文件，右键选择菜单【包括在项目中】即可，如果文件比较多，Visual Studio 可能需要一会儿才能完成，为了减少等待时间，读者也可以一批一批的添加。\n5.接着选择【文件】菜单【全部保存】菜单项保存即可（快捷键 Ctrl + Shift + S ）。\n最终效果如下图所示：\n这样我们就能利用 Visual Studio 强大的功能管理和阅读我们的源码了。\n这里要提醒一下读者：C/C++ 开源项目中一般会使用各种宏去条件编译一些代码，实际生成的二进制文件中不一定包含这些代码，所以在 Visual Studio 中看到某段代码的行号与实际在 gdb 中调试的代码行号不一定相同，在给某一行代码设置断点时请以 gdb 中 list 命令看到的代码行号为准。","title":"如何使用 Visual Studio 管理和阅读开源项目代码"},{"content":"如何成为一名合格的 C/C++ 开发者？ 写在前面的话 在大多数开发或者准开发人员的认识中，C/C++ 是一门非常难的编程语言，很多人知道它的强大，但因为认为“难”造成的恐惧让很多人放弃。\n笔者从学生时代开始接触 C/C++，工作以后先后担任过 C++ 客户端和服务器的开发经理并带队开发，至今已经有十多年了。虽然时至今日哪种编程语言对我来说已经不再重要（我目前主要从事 Java 开发），但 C/C++ 仍然是笔者最喜欢的编程语言。在我看来，C/C++ 一旦学成，其妙无穷，就像武侠小说中的“九阳神功”一样，有了这个基础，您可以快速学习任何语言和编程技术。\nC/C++ 的当前应用领域 需要注意的是本文不细分 C与 C++ 的区别，通常情况下，C++ 可以看成是 C 的一个超集，在古典时期，可以认为 C++ 就是 C with classes。虽然如今的 C++ 从功能层面上来看，离 C 越来越远了；但是从语法层面来上来看，大多数 C++ 语法还是与 C 基本一致的——所谓 C++ 的面向对象特性，如果细究 C++ 类方法的具体语法还是 C 的过程式语法。当然，面向对象是一种思想，语言本身对其支持的程度固然重要，能否熟练使用更要看开发者的水平。\nC 语言目前主要用于像操作系统一类偏底层的应用开发，包括像 Windows/Linux 这样的大型商业操作系统，以及嵌入式操作系统、嵌入式设备上的应用。还有一些开源的软件，也会选择 C 开发，这些系统主要优先考虑程序执行效率和生成的可执行文件的体积（C 代码生成的可执行文件体积相对更小），当然还有一些是历史技术选型问题，这类软件像 Redis、libevent、Nginx，目前像国内的电信服务商所使用的电话呼叫系统，一般也是基于一款叫 FreeSWITCH 的开源 C 程序做的二次开发（项目地址：https://freeswitch.com/ ）。\nC++ 面向对象的语法与 C 相比较起来，在将高级语言翻译成机器二进制码的时候，C++ 编译器在背后偷偷地做了大量工作，生成了大量的额外机器码，而这种机器码相对于 C 来说不是必须的。例如，对于一个 C++ 类的实例方法，编译器在生成这个方法的机器码时，会将函数的第一个参数设置成对象的 this 指针地址，以此来实现对象与函数的绑定。正因为如此，许多开发者会优化和调整编译器生成的汇编代码。\n我们再来说说 C++。C++ 的应用领域目前有三大类，第一类就是我们目前见到的各种桌面应用软件，尤其 Windows 桌面软件，如 QQ、安全类杀毒类软件（如金山的安全卫士，已开源，其代码地址：http://code.ijinshan.com/source/source.html ）、各种浏览器等；另外就是一些基础软件和高级语言的运行时环境，如大型数据库软件、Java 虚拟机、C# 的 CLR、Python 编译器和运行时环境等；第三类就是一些业务型应用软件的后台，像游戏的服务器后台，如魔兽世界的服务器（代码地址：https://github.com/azerothcore/azerothcore-wotlk ）和一些企业内部的应用系统。笔者曾在某交易所从事后台开发，其交易系统和行情系统就是基于 C++ 开发的。\nC++ 与操作系统平台 从上面的介绍可以看出，与 Java、Python 等语言相比，C/C++ 语言是离操作系统最近的一种高级语言，因此其执行效率也比较高。但是有得必有失，因为如此，C/C++ 这门语言存在如下特点。\n**C/C++ 整套的语法不具备“功能完备性”，单纯地使用这门语言本身提供的功能无法创建任何有意义的程序，必须借助操作系统的 API 接口函数来达到相应的功能。**当然，随着 C++ 语言标准和版本的不断更新升级，这种现状正在改变；而像 Java、Python 这类语言，其自带的 SDK 提供了各种操作系统的功能。\n举个例子，C/C++ 语言本身不具备网络通信功能，必须使用操作系统提供的网络通信函数（如 Socket 系列函数）；而对于 Java 来说，其 JDK 自带的 java.net 和 java.io 等包则提供了完整的网络通信功能。我在读书的时候常常听人说，QQ、360 安全卫士这类软件是用 C/C++ 开发的，但是当我学完整本 C/C++ 教材以后，仍然写不出来一个像样的窗口程序。许多过来人应该都有类似的困惑吧？其原因是一般 C/C++ 的教材不会教你如何使用操作系统 API 函数的内容。\n**C/C++ 语言需要直接使用操作系统的接口功能，这就造成了 C/C++ 语言繁、难的地方。**如操作内存不当容易引起程序宕机，不同操作系统的 API 接口使用习惯和风格也不一样。接口函数种类繁多，开发者如果想开发跨平台的程序，必须要学习多个平台的接口函数和对应的系统原理。\n**在应用层开发，直接使用操作系统接口的函数，往往执行效率高、控制力度大。**而开发能力仅仅限制于操作系统本身，Java 这类语言，很多功能即使操作系统提供了，如果 Java 虚拟机不提供，开发人员也无法使用。正如著名的编程大师 Charles Petzold 所说：\n“显而易见，究竟用哪种方式编写应用程序最好，其实并无一定之规。应用程序本身的特性应该是决定采用何种编程工具的最主要因素，但是无论将来你采用什么样的编程工具，通过了解操作系统 API 从而深入理解操作系统的工作原理，这本身就有很重要的意义。操作系统是一个非常复杂的系统，在 API 之上加一层编程语言并不能消除其复杂性，最多不过是把复杂性隐藏起来而已。说不定什么时候，复杂的那一面迟早会蹦出来拖你的后腿，懂得系统 API 能让你到时候可以更快地挣脱困境。\n在基本操作系统 API 之上的任何软件层或多或少都会限制你使用操作系统的全部功能。比如，你或许发现采用 Visual Basic 来编写你的应用程序非常理想，但是就有那么一两项非常基本的功能 Visual Basic 无法支持。往往这个时候你得非要调用基本 API 。作为直接使用操作系统 API 的程序员，我们的活动空间完全由 API 来规范，再没有什么其他方式比直接调用 API 更有效、更灵活多样了。”\n总结起来，C/C++ 语言的开发核心建立在直接调用操作系统 API 的基础上，优点是执行效率高、发挥空间大；缺点是，需要经过系统深入的学习，学习周期长，编写代码较复杂，容易出错。\nLinux C++ 与 Windows C++ 领域之争 我之所以把这个标题单独列出来，是想纠正现在很多 C/C++ 新人和初学者一些不当的认识，一般有以下几种观点：\nLinux C++ 开发就是后台开发，而 Windows C++ 开发就是客户端开发； 后端开发比客户端开发（前端）高级，因此后端开发行业薪资水平比客户端开发薪资要高； 我只学 Linux，不学 Windows。 我相信对于 80 和 90 的这一代开发者来说，当初接触计算机并进入软件行业，都是从接触 Windows 开始的。时至今日，大数据、人工智能等各种新技术方兴未艾，移动互联网如火如荼。无论是 Linux 还是 Windows，尤其是 Windows，仍然是我们大多数人工作、学习、娱乐使用最多的操作系统——我们每天都会使用其上的各种软件。使用这些软件像喝水、呼吸空气一样自然，所以很多人就忽视了这类软件的 “基础作用”。\nWindows 上的软件开发发展了很多年了，这些领域也比较成熟，一般不再招初中级开发，而是需要水平较高、经验较丰富的高级开发者。这让很多人造成了“Windows C++”开发市场需求已经很小了的错觉。试问，QQ PC 部门这些年对外招了多少人？\nLinux C++ 和 Windows C++ 一样，没有孰高孰低之分，只是两种不同的操作系统而已，不要觉得在 Linux 下敲命令就比在 Windows 的图形化界面点击鼠标达高级。\n**图形化界面之于命令行，是人们对更高级、更方便的工具追求的必然结果。**Linux C++ 也不一定就是后台开发，Windows C++ 也不一定就是客户端开发；所谓的服务器与客户端是个相对的概念，即谁给谁提供服务，提供服务的我们认为是服务端（后台），被服务的我们认为是客户端（前台）。而 Windows 作为后台服务的应用也比比皆是，如笔者之前所在的某交易所的服务器后台都是 Windows 下的 C++ 程序；另外如一些游戏类的服务器端，也不少是 Windows 的。\n借用《UNIX 编程艺术》这本书的观点，Windows 和 Linux 的哲学理念不一样，Windows 是假设你不会操作，它教你如何操作，而 Linux 是假设你会操作然后进行操作。根据这个理念，Windows 一般是普通人用的多，而 Linux 是程序员用的多。\n从编程的角度来说，Windows 的代码风格是所谓的匈牙利命名法，而 Linux 是短小精悍的连字符风格。例如同一个表示屏幕尺寸的整型变量，Windows 上可能被命名为 iScreen 或 cxScreen ，而 Linux 可能是 screen；再例如 Windows 上创建线程的函数叫 CreateThread，Linux 下叫 pthread_create。有时候，我觉得 Windows 的匈牙利命名法反而更容易理解代码。\n这里既然提到前端（客户端）开发和后端开发，这里不得不提一下，这二者没有优劣之分。其侧重点和开发思维是不一样的，前端（客户端）开发一般有较多的界面逻辑，它们是直接与用户打交道，因而一款客户端软件的好坏很大程度上取决于其界面的易用性和流畅性，开发者只要把这一端的“一亩三分地”给管理好即可；而后端服务，对于普通用户是透明的，开发者的程序必须尽量体现“服务”这个字眼，即更有效地为更多的客户端服务，这就要求兼顾请求响应的正确性、及时性和流畅性。\n由于服务软件也是运行在某台物理机器上的程序，鉴于 CPU、内存、网络带宽资源有限，而服务程序一般是长周期运行的，因此必须合理地分配和使用资源（如尽量回收不再使用的各种资源）。开发者应从全局考虑，不能在某个“客户端”这一棵树上“吊死”。\n从个人的职业发展来看，建议从事客户端开发的人员适当地了解一下服务器开发的思路，反过来也建议从事后端开发的人员去学习一下客户端开发，二者相得益彰。从个人的技术提高来说，也是很有帮助的。\n例如您要学习一套开源的软件代码，如果您熟悉客户端和服务器的基本开发和调试技巧，您可以更好地学习它。而在工作上，一个项目，往往是由客户端和服务器程序组成，如果您都熟悉，您可以站在一个更高的角度去审视它、规划它，这也是架构师的基本要求之一。\n最后就是很多读者关心的客户端和服务器的薪资问题，这个没有绝对的谁高谁低，因人而异，因能力而异，因岗位而异。\n如何看待 C++ 11/14/17 新标准 C++ 开发者有个不成文的规定：即使您对 C++ 很熟悉，也不要在简历上写上您精通 C++，原因很简单—— C++ 这门语言包含的东西实在太多了，没有人能真正“精通”所有。\nC++ 既支持面向对象设计（OOP），也支持以模板语法为代表的泛型编程（GP）。而且新的 C++ 标准和遵循 C++ 新标准的编译器也层出不穷，这些年，C++ 变化越来越大、越来越快，从最初业界和开发者翘首以盼的 C++11 标准，历经 C++14、C++17 到今天的 C++20，这门语言与之前的版本差别越来越大，更多原来需要使用第三库的功能也被陆续添加到 C++ 标准库中。以致于 C++ 之父 Bjarne Stroustrup 也开始对这门语言表示担忧：\n“C++11 开始的基础建设尚未完成，而 C++17 在使基础更加稳固、规范性和完整性方面，基本没有做出改善。相反地，却增加了重要接口的复杂度，让人们需要学习的特性数量越来越多。C++ 可能在这种不成熟提议的重压之下崩溃，我们不应该花费大量的时间为专家级用户们（比如我们自己）去创建越来越复杂的东西。（还要考虑普通用户的学习曲线，越复杂的东西越不易普及。）”\n文章参看这里：https://zhuanlan.zhihu.com/p/48793948，在 Bjarne Stroustrup 的信中，他担心 C++ 会像历史的瓦萨号军舰一样，某天新的标准刚启航（发布）便立即沉没。\n当然，我们不用有这种担忧，毕竟我们既不是 C++ 标准委员会成员，也不是 C++ 编译器开发厂商。就我个人经验来说，对于C++11、C++14、C++17 乃至 C++20，我们学习它们的准则应该是以实用为主，也就是说我们应该学习其实用的部分，至于新标准提到的一些高级特性和各种复杂的模板，我们大可不必去了解。我们并不是做学术研究，我们学习 C++ 是为了投入实际的生产开发，所以应该去学习 C++ 新标准中实用的语法和工具库。关于 C++11 常用一些知识点，这里也简单地给读者列举一下。\nauto 关键字 for-each 循环 右值及移动构造函数 + std::forward + std::move + stl 容器新增的 emplace_back() 方法 std::thread 库、std::chrono 库 智能指针系列（std::shared_ptr/std::unique_ptr/std::weak_ptr），智能指针的实现原理一定要知道，最好是自己实现过 线程库 std::thread + 线程同步技术库 std::mutex/std::condition_variable/std::lock_guard 等 Lamda 表达式（Java 中现在也常常考察 Lamda 表达式的作用） std::bind/std::function 库 其他的就是一些关键字的用法（override、final、delete），还有就是一些细节如可以像 Java 一样在类成员变量定义处给出初始化值。\nC++ 语言基础与进阶 基础 这里说的基础不是狭义上的 C++ 语言基础，而是包括 C++ 开发这一生态体系的基础，笔者认为的基础包括：\nC++ 语言本身熟练使用程度。 前面也介绍了单纯的 C++ 您啥也干不了，您必须结合一个具体的操作系统平台，所以得熟悉某个操作系统平台的 API 函数，比如Linux，以及该操作系统的原理。这里说的操作系统的原理不局限于您在操作系统原理图书上看的知识，而是实实在在与系统 API 关联起来的，如熟练使用各种进程与线程函数、多线程资源同步函数、文件操作函数、系统时间函数、窗口自绘与操作函数（这点针对 Windows）、内存分配与管理函数、PE 或 ELF 文件的编译、链接原理等等。 网络通信，网络通信在这里具体一点就是 Socket 编程。这里的 Socket 编程不仅要求熟练使用各种网络 API 函数，还要求理解和灵活运用像三次握手四次挥手等各种基础网络通信协议与原理。关于 Socket 编程实践，《TCP/IP 网络编程》这本书是非常好的入门教材。 说了这么多，您可能会觉得很抽象。笔者在这里举个具体例子。假设我们现在要开发一个类似电驴这样的软件，软件界面如下图：\n如上图所示，假设操作系统选择 Windows，使用语言使用 C++，这就要求您必须熟悉 C++ 常用的语法，如果还不熟悉，就需要补充这方面的知识。\n电驴的源码可以在公众号【 高性能服务器开发 】后台回复“获取电驴源码”即可获取。\n在熟悉 C++ 语法的前提下，从这款产品实现技术来看，我们的目标产品分为 UI 和网络通信部分。下面将详细介绍这两部分。\nUI 部分 对于 UI 部分，我们的认识是，这里需要使用 Windows 的窗口技术。可以直接使用原生的 Win 32 API 来制作自己的界面库，也可以选择一些熟悉的界面框架，如 MFC、WTL、Duilib、wxWidgets 等。无论您是在阅读别人的项目还是需要自己开发这样的项目，在确定了这款软件使用的 UI 库（或者使用原生 Win 32 API），您就需要对 Windows 的窗口、对话框、消息产生、派发与处理机制进行了解。同样的道理，如果不熟悉您需要补充相关的知识（关于这一点，下文不再赘述）。\n接着，根据上图中的软件功能，大致分为三大模块，即资源、下载和分享。这三大块是可以使用一个 Windows Tab 控件去组织，这个时候您需要了解 Windows Tab 控件的特性。\n对于资源模块，本质上是一个窗口中嵌入了一个浏览器控件（WebBrowser 控件），那么您需要了解这一个功能点的相关知识。当用户点击了某个列表中某个具体的资源，可以对其进行下载。这就又涉及到 WebBrowser 控件与 C++ 宿主程序的交互了，那么如何实现呢？可以选择使用 ActiveX 技术，也可以使用 JavaScript 与 C++ 交互技术。 再来看下载模块，当产生一个下载操作时，界面上会产生以下下载列表，每个列表项会实时显示下载进度、下载速率等参数，同时正在下载的项目也可以被暂停、停止和删除。那么这又涉及到 ListView 控件的相关功能，以及 ListView 如何与后台网络通信的逻辑交互。 分享模块是将本地资源分享到服务器或者给其他用户。界面左侧是文件系统的一个快照，那么这又涉及到如何遍历文件系统（了解枚举文件系统的 API），右侧也是一个 ListView 控件，这里不再赘述。 网络通信部分 网络通信部分，主要有两大块，第一个是程序启动时，与服务端的交互；第二个就是文件下载与分享的 P2P 网络。您在阅读或开发的过程中，如果对这些技术比较陌生，您需要补充这些知识，具体的就是 Socket 的各种 API 函数，以及基于这些 API 逻辑的组合。当然可能也会用到操作系统平台所特有的网络 API 函数，如 WSAAsyncSelect 网络模型。\n另外一点，网络通信部分如何与 UI 部分进行数据交换，是使用队列？全局变量？或者相应的 Windows 操作平台提供的特殊通信技术，如 PostMessage 函数、管道？如果使用队列，多线程之间如何保持资源的一致性和解决资源竞态，使用 Event、CriticalSection、Mutex、Semaphore 等？\n当然，笔者这里只列举了这个软件的主干部分，还有许多方方面面的细节需要考虑。这就需要读者根据自己的情况，斟酌和筛选了。您想达到什么目的，就要去学习和研究相关的代码。\n总结起来，可以得到如下公式：\n一款 C++ 软件 = C++ 语法 + 操作系统 API 函数调用\n进阶 如果您达到了我上面说的三点后，可以再找一些高质量的开源项目去实战一下。需要注意的是，最好找一些没有复杂业务或者您熟悉其业务的开源项目（如开源的 IM 系统）。如果你不熟悉其业务，不仅要学习其业务（软件功能），还需要再去学习它的源码，最后可能让我们迷失了最初学习这款软件的目的。\n学习这些项目的同时，读者应该先确定自己的学习目的，如果您的目的是学习和借鉴这款软件的架构，那么先从整体去把握，不要一开始就迷失在细枝末节中，这类我称之为“粗读”；或者您的目的是学习开源软件在一些细节上的处理与做法，这个时候，您可以针对性地去阅读您感兴趣的模块，深入到每一行代码上。\n学习开源软件存在一种风气，许多新手喜欢道听途说，一听别人说这个软件不好，那个软件存在某某瑕疵就放弃阅读它的打算了。然后到了实际开发中，因为心中没有任何已有软件开发问题的解决方案，产生挫败感，久而久之就对本来喜欢的 C/C++ 开发失去了兴趣。\n学习的过程是先接触，再熟悉，再模仿，再创造。不管什么开源项目，在您心中没有任何思路或者解决方案时，您应该先接触熟悉，不断模仿，做到至少心中有一套对于某场景的解决方案，然后再来谈创新谈批判、改造别人的项目。\n我个人学习一套陌生的开源项目时，总是喜欢将程序用调试器正常跑起来，然后再中断下来，统计当前的线程数目，然后通过程序入口 main 函数从主线程追踪其他工作线程是如何创建的；接着，分析和研究每个线程的用途以及线程之间交互的，这就是整体把握，接着找我感兴趣的细节去学习。\n这里我以学习 Redis 为例。将 Redis 源码从官网下载下来以后，使用喜欢的代码阅读器进行管理。我这里使用的是 Visual Studio，如下图所示：\n在大致了解了 Redis 有哪些代码模块以后，我们把代码拷贝到 Linux 平台，然后编译并使用 GDB 调试器跑起来。如下图所示：\n然后按 CTRL+C 将 GDB 中断下来，输入 info threads 查看当前程序的所有线程：\n接着挨个使用 thread + 线程编号 和 bt 命令去查看每个线程的上下文调用堆栈：\n对照每个线程的上下文堆栈，搞清楚其逻辑，并结合主线程，看看每个线程是在何时启动的，端口在何时启动侦听的，等等。做完这一步，关于 redis-server 的框架也基本清楚了。\n接着我们可以选择一个自己感兴趣的命令，搞清楚 redis-cli 与 redis-server 命令的交互流程。\n最后，如果对 redis-server 源码中各种数据结构和细节感兴趣，我们可以进一步深入到具体的代码细节。\n当然，不熟悉 GDB 的读者看笔者这段操作流程比较困难，这是正常的，说明如果想通过调试去研究 Redis 这一款开源软件，您需要去补充一点 GDB 调试的知识。这就是我上文中所说的，针对性地补缺补差。\nC++ 面试 关于 C++ 面试，面试的要求到底是侧重代码量、项目经验，还是侧重操作系统、数据结构这种基础知识？我在知乎上曾经专门写过一篇文章来介绍我曾经的 C++ 面试经历和经验，有兴趣的读者可以点击这里查看：https://www.zhihu.com/question/264198516/answer/341999235。\n关于 C++ 面试常见的面试题，可以参考这里：https://zhuanlan.zhihu.com/p/45668078，这篇文章问题点整理得非常详细，读者可以参考一下。\n需要注意的是，不仅仅是 C++ 面试，其他语言开发面试也是一样。如果您是想进入大型互联网公司的应届生，那么您应该优先好好准备算法和数据结构知识以应对面试，这是大型互联网公司面试频率最高的考察范围。至于其他的基础知识，如操作系统原理、网络通信等（作为计算机相关专业的学生，这些应该是您的专业课），如果您已经在平时的学习中掌握得很好，那就不用担心，这类问题一般对于应届生求职不会问得太深；倘若您尚未学得扎实，而春招或秋招又时间临近，没有足够的时间去准备这些，您应该只是尽量去补，实在来不及也没关系，还是应该把重心放在好好准备算法和数据结构等知识上。\n对于社会人士参加的 C++ 职位的面试，如果是大型互联网公司，虽然社会招聘问的更多的是项目经验，适当地为一些基础的算法和数据结构知识做一些准备也是非常有用的。举个例子，如果问到二分查找这一类基础算法，如果答不出来未免会让面试官印象不太好，场面也比较尴尬。另外，C++ 是一门讲究深度的编程技能，对于有一定工作年限的面试者，面试官往往会问很多原理性的细节，这就要求广大 C++ 开发者在平常多留心、多积累、多思考技术背后的原理。\n对于大多数小型企业，无论是应届生还是社会人士，只要有能力胜任一定的工作即可。一般只要对所面试的公司项目有类似经验或者相关的技术能力，基本上就可以通过面试。大多数小公司在乎的是您来了能不能干活，所以这类公司对实际项目经验和技能要求更高一点。\n关于项目经验，许多人可能觉得项目经验一定是自己参与的项目，其实不然，项目经验也可以来源于您阅读和学习其他人的项目代码或者开源软件，只要您能看懂并理解它们，在面试的时候提及到，能条理清晰、自圆其说即可。当然，如果不熟悉或者只是了解些皮毛，切记不可信口开河、胡编乱造甚至张冠李戴。\n我曾经面试过一些开发者，看简历项目经验丰富，实际一问的时候，只是把别人的框架或者库拿来包装调用一下，问及其技术原理时，不是顾左右而言他就是说不清道不明模棱两可含糊不清，这一类人往往比不知道还让人讨厌，面试官一般反感这一类面试者所谓的项目经验。\n学生与社会人士学习 C++ 方式的区别 作为学生有充裕的时间，建议除了把 C++ 语法学好，系统地多读一点基础的书籍，如操作系统原理、网络编程、数据结构与算法等相关各方各面的经典书籍。\n可以参考下这里：\nhttps://mp.weixin.qq.com/s/EjgtX2Wghia7ajn2AugCtw\n尽量做到等您毕业走出校园以后，至少熟悉一门编程语言和其相应的开发环境，这就是一个基础扎实、理论清晰、编码能力强的求职者。可惜的是，从现在的各种招聘反馈来看，大多数学生在求职时，对相关开发工具和语言的陌生程度实在让人瞠目结舌，面试官在面试的时候会很纳闷：这位学生大学四年（或者七年）到底是否调试过程序？\n社会人士由于已经走上工作岗位，家庭、工作的琐事繁多，没有太多的时间去系统地阅读一些相关基础书籍，如果您当前工作正好是从事 C/C++ 开发，那么请结合您当前的项目来学习，搞清楚项目的体系结构、吸收项目中优秀的实现细节，针对性地补充相关知识，这是进步最快的方式。\n但是实际情形中，很多人觉得公司的项目代码又烂又杂，不愿意去研究。这种思想千万不能有的，在您没有自己足够好的能力给公司提供更好的解决方案，请先学习和模仿，我们此时要保持“空杯”心态，公司的代码再烂，它也是公司的商业价值所在；即使是纯粹的业务代码，也有它的可取之处，择其善者而从之，其不善者而改之。尤其是开发者处于一些初中级的开发岗位时，可能接触不到公司核心框架的源码，此时千万不要盲目地去排斥。学业务，补基础，时刻意识清醒自己所需，明白自己想要学的东西。\n如果从事的不是 C++ 相关的开发，那么可以挤出一些时间去学习一些开源的代码，在阅读开源代码的过程中，针对性地补缺补差。不建议系统地去看《C++ Primer 中文版》《UNIX 环境高级编程》诸如此类的大部头书籍，实际开发中不需要太多这类书中的细枝末节，阅读这类书往往只会事倍功半，甚至最后因书籍太厚、时间不够，最后坚持不下去，最终放弃。\n当然，对于社会人士，当您有一定的时间的时候一定要去补充一些基础的、原理性的东西，千万不要沉溺于“面向搜索引擎编程”或者“面向工资编程”，有些问题虽然当时通过搜索引擎解决了，但如果想在技术或职业上有长足的发展，一定要系统地去读一些经典的、轻量级的书籍（如《C++ 对象模型》）。长期在网上的文章中寻章摘句，只会让您的知识结构碎片化、凌乱化，甚至混乱化。而且互联网上的技术文章质量良莠不齐，有时候也容易对自己形成误导和依赖。总而言之，作为技术开发人员，提高自己技术水平是改变现状、改善生活最直接的途径。\n小结 关于 C/C++，暂且就讨论这么多。最后再强调一遍，C++ 是一门讲究深度的语言，其“深度”不是体现在会多少 C++ 语法，而是能够洞察您所写的 C++ 代码背后的系统原理，这是需要长期不断的积累的，没有速成之法。反过来一旦学成，可以快速地学习其他语言和框架。个人觉得，如果自主创业或者想在二三线城市长期发展的读者，C/C++ 应该是优选语言，有了它作为基础，您可以跳出依赖各种环境和框架的窠臼，快速地学习和开发您想要的软件，完成您想要的业务产品。\n最后，限于笔者经验水平有限，欢迎读者就文中的观点提出宝贵的建议和意见。如果想获得更多的学习资源或者想与我做进一步交流，可以加我微信 easy_coder 一起交流。\n文中提到的电驴的源码可以在公众号【 高性能服务器开发 】后台回复“获取电驴源码”即可获取。\n","permalink":"https://haokiu.com/blog/79cb378b756e457cbcb3a3c669a8e4c0/","summary":"如何成为一名合格的 C/C++ 开发者？ 写在前面的话 在大多数开发或者准开发人员的认识中，C/C++ 是一门非常难的编程语言，很多人知道它的强大，但因为认为“难”造成的恐惧让很多人放弃。\n笔者从学生时代开始接触 C/C++，工作以后先后担任过 C++ 客户端和服务器的开发经理并带队开发，至今已经有十多年了。虽然时至今日哪种编程语言对我来说已经不再重要（我目前主要从事 Java 开发），但 C/C++ 仍然是笔者最喜欢的编程语言。在我看来，C/C++ 一旦学成，其妙无穷，就像武侠小说中的“九阳神功”一样，有了这个基础，您可以快速学习任何语言和编程技术。\nC/C++ 的当前应用领域 需要注意的是本文不细分 C与 C++ 的区别，通常情况下，C++ 可以看成是 C 的一个超集，在古典时期，可以认为 C++ 就是 C with classes。虽然如今的 C++ 从功能层面上来看，离 C 越来越远了；但是从语法层面来上来看，大多数 C++ 语法还是与 C 基本一致的——所谓 C++ 的面向对象特性，如果细究 C++ 类方法的具体语法还是 C 的过程式语法。当然，面向对象是一种思想，语言本身对其支持的程度固然重要，能否熟练使用更要看开发者的水平。\nC 语言目前主要用于像操作系统一类偏底层的应用开发，包括像 Windows/Linux 这样的大型商业操作系统，以及嵌入式操作系统、嵌入式设备上的应用。还有一些开源的软件，也会选择 C 开发，这些系统主要优先考虑程序执行效率和生成的可执行文件的体积（C 代码生成的可执行文件体积相对更小），当然还有一些是历史技术选型问题，这类软件像 Redis、libevent、Nginx，目前像国内的电信服务商所使用的电话呼叫系统，一般也是基于一款叫 FreeSWITCH 的开源 C 程序做的二次开发（项目地址：https://freeswitch.com/ ）。\nC++ 面向对象的语法与 C 相比较起来，在将高级语言翻译成机器二进制码的时候，C++ 编译器在背后偷偷地做了大量工作，生成了大量的额外机器码，而这种机器码相对于 C 来说不是必须的。例如，对于一个 C++ 类的实例方法，编译器在生成这个方法的机器码时，会将函数的第一个参数设置成对象的 this 指针地址，以此来实现对象与函数的绑定。正因为如此，许多开发者会优化和调整编译器生成的汇编代码。\n我们再来说说 C++。C++ 的应用领域目前有三大类，第一类就是我们目前见到的各种桌面应用软件，尤其 Windows 桌面软件，如 QQ、安全类杀毒类软件（如金山的安全卫士，已开源，其代码地址：http://code.ijinshan.com/source/source.html ）、各种浏览器等；另外就是一些基础软件和高级语言的运行时环境，如大型数据库软件、Java 虚拟机、C# 的 CLR、Python 编译器和运行时环境等；第三类就是一些业务型应用软件的后台，像游戏的服务器后台，如魔兽世界的服务器（代码地址：https://github.com/azerothcore/azerothcore-wotlk ）和一些企业内部的应用系统。笔者曾在某交易所从事后台开发，其交易系统和行情系统就是基于 C++ 开发的。\nC++ 与操作系统平台 从上面的介绍可以看出，与 Java、Python 等语言相比，C/C++ 语言是离操作系统最近的一种高级语言，因此其执行效率也比较高。但是有得必有失，因为如此，C/C++ 这门语言存在如下特点。\n**C/C++ 整套的语法不具备“功能完备性”，单纯地使用这门语言本身提供的功能无法创建任何有意义的程序，必须借助操作系统的 API 接口函数来达到相应的功能。**当然，随着 C++ 语言标准和版本的不断更新升级，这种现状正在改变；而像 Java、Python 这类语言，其自带的 SDK 提供了各种操作系统的功能。\n举个例子，C/C++ 语言本身不具备网络通信功能，必须使用操作系统提供的网络通信函数（如 Socket 系列函数）；而对于 Java 来说，其 JDK 自带的 java.","title":"如何成为一名合格的 C/C++ 开发者？"},{"content":"我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？ 以下内容来自于一名群友的求助，经当事人同意首发于『高性能服务器开发』公众号，文字略有改动，未经许可，不得转载。\n（以下文中的“我”乃当事人本人，非文章作者。）\n群主，您好。我是一名上海一名 C++ 客户端开发，最近遇到了点私人问题，请群主帮我参考一下。以下是我的问题：\n我是一名程序员，很爱我的女友，谈婚论嫁时，女友要求我用两年的工资作为彩礼，我该不该答应？\n（一）\n我老家是湖北黄石的，大学就读于武汉某学校，2018 年 7 月毕业，辗转来到上海。由于学历不太好，加上大学荒废了四年，在上海找了近一个月工作之后，终于 2018 年 7 月底上海找了一份 做 PC 客户端开发的工作，使用 C++ 语言。公司是做金融系统平台定制的，主要业务是股票交易系统，为此招了很多数据分析师，女孩子比较多。我就在这家公司认识了我现在的女朋友，她也是一名数据分析师，她是江苏人，也是在武汉上的学，大学毕业时在券商实习做过柜台，所以业务比较熟悉。平常她需要和我们这些开发进行对接，一来二去我们就熟悉了。有一次无意中一起下班，发现我们顺路，后来我们就经常一起加班下班，我向她请教业务问题，她和我了解系统实现逻辑。\n后来一段时间，我发现她每天早上来的很晚，而且总是眼睛红红的或者像是没休息好的样子。于是，我趁着下班的机会，问她怎么了，可是她总是说没事。终于有一天晚上我们一起下班回家的日子，她告诉我原因了：她前男友那段时间总是打电话找她，请求复合，她已经和前男友分手快一年了，她前男友回了老家，她来到了上海。现在她男朋友生了病，据她描述应该病的不轻，她拒绝了他的复合要求，但是她心里觉得很过意不去，对于一个病人这样做是不是太残忍了。但是，她又不想复合，虽然她的前男友平常对她很好，但前男友是个喜怒无常且无任何人生规划的人，还有一点点家庭暴力倾向。（画外音：小方群主看到这里惊呆了，好狗血的剧情。。。）\n后来，某天晚上在公司附近的公园的草坪上我不断的安慰她，让她想开一点，既然分手了，又有顾忌，就不要再想前一段感情了，建议她向前看。\n又过了几天，她说她想通了，这次决定放下。那天晚上，我去了她租的房子。之前，她每次只允许我走到她小区门口，从不允许我进去，调侃我说我“图谋不轨”。那天晚上，我真是感到受宠若惊，聊的比较晚。后来不知道因为什么事情，她又说起了她的前男友如何可怜，我当时很生气，抓起我的书包就准备走。她突然一把抱住我，并且强吻了我。我当时就木头了，单身二十三年，女孩子手都没摸过，更不用说和女孩子接吻了。那感觉，当时脑子就不清醒了。然后，她反问我：XXX，你是不是想追我？我当时小心翼翼地回答是。她说让她考虑一下，然后就让我先回去了。\n我一宿未眠，不知道她如何想的。第二天一大早就去了公司，可是一上午都没看到她来公司，我给她发微信打电话也没人回。终于，下午她终于来公司了，而且看起来精神状态不错。她神秘兮兮的和我说晚上一起吃饭。\n晚上我们一起在公司的楼下食堂吃饭，她说她和她前男友好好的聊了一下，把事情说清楚了。她不会再想她的前男友，并且接受我的追求。那天，当她告诉我她愿意接受我的时候，我非常的开心。\n（二）\n接下来的日子，应该是我人生中最开心的一段日子了。我发现，我们对文学都很感兴趣，我们一起聊《红楼梦》《雷雨》《巴黎圣母院》《飘》《百年孤独》《海上钢琴师》等一些国内外的经典著作和电影，她和我聊她之前在深圳和小伙伴们的趣事，还有一些我从未听过的文学作品，她的学识令我佩服。\n那段时候，下班以后，我俩骑着共享单车在华师和同济大学的校园里漫游，有时候手拉手在河边散步，无话不谈，真的佩服她的文学素养和对世界的认识。而且让我惊喜的是，她有一手好厨艺，我琢磨着和她自小的家庭环境有关系吧。周末她烧饭时，从来不让我洗碗，而且一个人全包了从买菜到炒菜煮饭、饭后洗碗、打扫的全过程。我们一起玩王者荣耀和英雄联盟，她对这两个游戏也很感兴趣。\n周末有的时候我们会一起去南京路步行街逛街、看看电影，我觉得她是个非常独立的人，她每次买东西都不会让我付钱，而且我之前断断续续借给她五六千块钱，在一次闹矛盾后也一分不少的还给我了。当然后来，我们又和好了。\n在交往中，我知道了她的家庭状况。家在苏北农村，父母务农。家里有一个哥哥，高中没读完就辍学了。父母比较对哥哥比较宠爱，从小对她管不多，她经常和家里吵架。她从小的愿望就是将来离开家。所以她一个人去武汉上学，毕业后一个人去深圳，干了一年来到上海。但是，她的哥哥从小对他很好，她很感激。唉，这个\u0026quot;好\u0026quot;字，埋下了我后来的悲剧。\n在一个周五的晚上，我们去了一家很有特色的古风饭店吃了顿饭，我们一起喝了点店里的招牌酒水——女儿红。她貌似喝醉了，脸红扑扑的，回来的路上，她一边挽着我的手一边给我唱王菲的情歌。那天星光下，她穿着一套白色的裙子，像个仙子一样美丽。那天，我也很开心，心里想：她的独立自强以及读了那么多书，具有一种一般女孩不具有的知性美，还有她的勤劳质朴，在现在的女大学生中实在太少了，这应该是我理想中的对象吧。\n顺理成章，那天晚上，我们在她的租的房子里面发生了关系，我很意外的是，她竟然还是个chu。我问她后不后悔，她意味深长的问我，你知道女儿红这酒名的来历吗？我说不知道。她说，古时候，穷人家的父亲会在女儿出生的那一天，把一坛白酒用红色的布包好藏在地窖里，等女儿长大出嫁那一天会拿出来，送给出嫁的女儿和女婿。所以，她不后悔，并安慰我她爱我，这是迟早的事情。那天我暗暗下定决心，一定一辈子对她好。\n（三）\n后来，有了第一次以后，我就经常在她那里过夜了，只不过我们隐藏的很好，公司没人知道我们的关系，我因为工作表现好，工资从六千涨到一万。后来，闲聊时，她和我说她哥哥对她的好，她虽然恨她的父母，但是她觉得她的哥哥挺可怜的，她想嫁给我，但希望我给她家 20 万的彩礼，她哥哥也可以拿着这笔钱娶老婆，她哥哥比她大五岁，她父母很着急，由于她哥哥学历不高没什么文化，又没啥手艺，生活过的很一般，年纪比较大了，家庭状况也不好，所以还没找到老婆，所以她父母压着她希望她在她哥哥的经济上照顾，她想着从小哥哥就照顾她，所以希望能帮哥哥一把。我当时听了这个话，不知道如何回答。20 万的彩礼对我来说，有点多，差不多相当于我现在快两年多的工资收入。我也是农村家庭，父母辛辛苦苦供我上大学。现在毕业了，父母年纪也大了，还有三万多的助学贷款没还完。\n我带她回了趟老家，父母很满意，非常开心。在家里催婚的状况下，我尝试着和她沟通过很多次，能不能彩礼钱少一点，结婚本身也要花钱的，她似乎并不想让步。我不敢告诉我的父母，不想让他们本来很开心的心情泼一盆冷水。我很爱她，但是她的这个条件我确实有点为难。甚至有时候，我在想，本来好好的一场可以开花结果的恋爱，怎么感觉有种卖女儿的感觉？\n另外还有件事，让我一直耿耿于怀，群主你不要笑（画外音：群主尽量忍住）。有次和她 XXOO 的时候，正在做的时候，她说她哥真的需要一个老婆，我有这方面的生理需求，她哥哥也有的。所以，她希望我能答应她的请求，她想和我过一辈子，但是希望我能理解下她，同意她的要求。我当时听了这话，像吃了苍蝇，立马没兴趣 XO 了。\n这个月，她提出来双方父母见个面，希望我们可以定下来，可是我现在很纠结：我不想和她分手，我爱她，而且她的第一次给了我，但是我又不能满足她的彩礼要求。我不敢想这些事，现在上班也没心思。群主作为过来人和各位读者，能给我点建议吗？\n","permalink":"https://haokiu.com/blog/5b6afa35b0644098b8b4d0c853f20358/","summary":"我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？ 以下内容来自于一名群友的求助，经当事人同意首发于『高性能服务器开发』公众号，文字略有改动，未经许可，不得转载。\n（以下文中的“我”乃当事人本人，非文章作者。）\n群主，您好。我是一名上海一名 C++ 客户端开发，最近遇到了点私人问题，请群主帮我参考一下。以下是我的问题：\n我是一名程序员，很爱我的女友，谈婚论嫁时，女友要求我用两年的工资作为彩礼，我该不该答应？\n（一）\n我老家是湖北黄石的，大学就读于武汉某学校，2018 年 7 月毕业，辗转来到上海。由于学历不太好，加上大学荒废了四年，在上海找了近一个月工作之后，终于 2018 年 7 月底上海找了一份 做 PC 客户端开发的工作，使用 C++ 语言。公司是做金融系统平台定制的，主要业务是股票交易系统，为此招了很多数据分析师，女孩子比较多。我就在这家公司认识了我现在的女朋友，她也是一名数据分析师，她是江苏人，也是在武汉上的学，大学毕业时在券商实习做过柜台，所以业务比较熟悉。平常她需要和我们这些开发进行对接，一来二去我们就熟悉了。有一次无意中一起下班，发现我们顺路，后来我们就经常一起加班下班，我向她请教业务问题，她和我了解系统实现逻辑。\n后来一段时间，我发现她每天早上来的很晚，而且总是眼睛红红的或者像是没休息好的样子。于是，我趁着下班的机会，问她怎么了，可是她总是说没事。终于有一天晚上我们一起下班回家的日子，她告诉我原因了：她前男友那段时间总是打电话找她，请求复合，她已经和前男友分手快一年了，她前男友回了老家，她来到了上海。现在她男朋友生了病，据她描述应该病的不轻，她拒绝了他的复合要求，但是她心里觉得很过意不去，对于一个病人这样做是不是太残忍了。但是，她又不想复合，虽然她的前男友平常对她很好，但前男友是个喜怒无常且无任何人生规划的人，还有一点点家庭暴力倾向。（画外音：小方群主看到这里惊呆了，好狗血的剧情。。。）\n后来，某天晚上在公司附近的公园的草坪上我不断的安慰她，让她想开一点，既然分手了，又有顾忌，就不要再想前一段感情了，建议她向前看。\n又过了几天，她说她想通了，这次决定放下。那天晚上，我去了她租的房子。之前，她每次只允许我走到她小区门口，从不允许我进去，调侃我说我“图谋不轨”。那天晚上，我真是感到受宠若惊，聊的比较晚。后来不知道因为什么事情，她又说起了她的前男友如何可怜，我当时很生气，抓起我的书包就准备走。她突然一把抱住我，并且强吻了我。我当时就木头了，单身二十三年，女孩子手都没摸过，更不用说和女孩子接吻了。那感觉，当时脑子就不清醒了。然后，她反问我：XXX，你是不是想追我？我当时小心翼翼地回答是。她说让她考虑一下，然后就让我先回去了。\n我一宿未眠，不知道她如何想的。第二天一大早就去了公司，可是一上午都没看到她来公司，我给她发微信打电话也没人回。终于，下午她终于来公司了，而且看起来精神状态不错。她神秘兮兮的和我说晚上一起吃饭。\n晚上我们一起在公司的楼下食堂吃饭，她说她和她前男友好好的聊了一下，把事情说清楚了。她不会再想她的前男友，并且接受我的追求。那天，当她告诉我她愿意接受我的时候，我非常的开心。\n（二）\n接下来的日子，应该是我人生中最开心的一段日子了。我发现，我们对文学都很感兴趣，我们一起聊《红楼梦》《雷雨》《巴黎圣母院》《飘》《百年孤独》《海上钢琴师》等一些国内外的经典著作和电影，她和我聊她之前在深圳和小伙伴们的趣事，还有一些我从未听过的文学作品，她的学识令我佩服。\n那段时候，下班以后，我俩骑着共享单车在华师和同济大学的校园里漫游，有时候手拉手在河边散步，无话不谈，真的佩服她的文学素养和对世界的认识。而且让我惊喜的是，她有一手好厨艺，我琢磨着和她自小的家庭环境有关系吧。周末她烧饭时，从来不让我洗碗，而且一个人全包了从买菜到炒菜煮饭、饭后洗碗、打扫的全过程。我们一起玩王者荣耀和英雄联盟，她对这两个游戏也很感兴趣。\n周末有的时候我们会一起去南京路步行街逛街、看看电影，我觉得她是个非常独立的人，她每次买东西都不会让我付钱，而且我之前断断续续借给她五六千块钱，在一次闹矛盾后也一分不少的还给我了。当然后来，我们又和好了。\n在交往中，我知道了她的家庭状况。家在苏北农村，父母务农。家里有一个哥哥，高中没读完就辍学了。父母比较对哥哥比较宠爱，从小对她管不多，她经常和家里吵架。她从小的愿望就是将来离开家。所以她一个人去武汉上学，毕业后一个人去深圳，干了一年来到上海。但是，她的哥哥从小对他很好，她很感激。唉，这个\u0026quot;好\u0026quot;字，埋下了我后来的悲剧。\n在一个周五的晚上，我们去了一家很有特色的古风饭店吃了顿饭，我们一起喝了点店里的招牌酒水——女儿红。她貌似喝醉了，脸红扑扑的，回来的路上，她一边挽着我的手一边给我唱王菲的情歌。那天星光下，她穿着一套白色的裙子，像个仙子一样美丽。那天，我也很开心，心里想：她的独立自强以及读了那么多书，具有一种一般女孩不具有的知性美，还有她的勤劳质朴，在现在的女大学生中实在太少了，这应该是我理想中的对象吧。\n顺理成章，那天晚上，我们在她的租的房子里面发生了关系，我很意外的是，她竟然还是个chu。我问她后不后悔，她意味深长的问我，你知道女儿红这酒名的来历吗？我说不知道。她说，古时候，穷人家的父亲会在女儿出生的那一天，把一坛白酒用红色的布包好藏在地窖里，等女儿长大出嫁那一天会拿出来，送给出嫁的女儿和女婿。所以，她不后悔，并安慰我她爱我，这是迟早的事情。那天我暗暗下定决心，一定一辈子对她好。\n（三）\n后来，有了第一次以后，我就经常在她那里过夜了，只不过我们隐藏的很好，公司没人知道我们的关系，我因为工作表现好，工资从六千涨到一万。后来，闲聊时，她和我说她哥哥对她的好，她虽然恨她的父母，但是她觉得她的哥哥挺可怜的，她想嫁给我，但希望我给她家 20 万的彩礼，她哥哥也可以拿着这笔钱娶老婆，她哥哥比她大五岁，她父母很着急，由于她哥哥学历不高没什么文化，又没啥手艺，生活过的很一般，年纪比较大了，家庭状况也不好，所以还没找到老婆，所以她父母压着她希望她在她哥哥的经济上照顾，她想着从小哥哥就照顾她，所以希望能帮哥哥一把。我当时听了这个话，不知道如何回答。20 万的彩礼对我来说，有点多，差不多相当于我现在快两年多的工资收入。我也是农村家庭，父母辛辛苦苦供我上大学。现在毕业了，父母年纪也大了，还有三万多的助学贷款没还完。\n我带她回了趟老家，父母很满意，非常开心。在家里催婚的状况下，我尝试着和她沟通过很多次，能不能彩礼钱少一点，结婚本身也要花钱的，她似乎并不想让步。我不敢告诉我的父母，不想让他们本来很开心的心情泼一盆冷水。我很爱她，但是她的这个条件我确实有点为难。甚至有时候，我在想，本来好好的一场可以开花结果的恋爱，怎么感觉有种卖女儿的感觉？\n另外还有件事，让我一直耿耿于怀，群主你不要笑（画外音：群主尽量忍住）。有次和她 XXOO 的时候，正在做的时候，她说她哥真的需要一个老婆，我有这方面的生理需求，她哥哥也有的。所以，她希望我能答应她的请求，她想和我过一辈子，但是希望我能理解下她，同意她的要求。我当时听了这话，像吃了苍蝇，立马没兴趣 XO 了。\n这个月，她提出来双方父母见个面，希望我们可以定下来，可是我现在很纠结：我不想和她分手，我爱她，而且她的第一次给了我，但是我又不能满足她的彩礼要求。我不敢想这些事，现在上班也没心思。群主作为过来人和各位读者，能给我点建议吗？","title":"我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？"},{"content":"我是如何年薪五十万的 以下经历希望对广大程序员同行有点启发。\n1\n我姓方，码农一枚，14 年硕士毕业于某 211 学校，哎，这里就不提母校了。人到中年，还没混出什么名堂，就不给学校丢脸了。经常很多人问我现在的收入多少，这个嘛，男人的收入就和女人的身高一样是个秘密。不过，今天姑且聊一聊这个话题。\n2\n我的第一家公司做 Windows C/C++ 开发，第二家公司做 Linux C++ 开发，第三家公司是某大型互联网公司，以 C++ 技术专家的加入，同时从事 C++ 和 Java 开发。我大学学的非计算机专业，非科班出身的劣势就是参加大厂的校招时，筛选简历那一关直接给你 pass 掉了，这也是我毕业时未通过校招去大厂的原因之一。之所以走到今天靠的是自己的兴趣加上一些运气，当然也离不开很多人的帮助。大学时早年自学 Web ，熟悉 html 5 标准前的各类前端开发技术和 PS 等软件，后痴迷 Flash 编程，做过很多 Flash 动画自娱自乐，2011 年大学毕业时先后在上海一家开发 Flash 整站和一家做网页游戏公司任 Flash 程序员，第一家公司实习工资 1500，第二家公司正式员工月薪 3000。许多年后，我和第二家公司的 Flash 主程再聚首时，他告诉我其实我当时作为一名应届生 3000 的工资并不低，当时他作为项目负责人工资也才 8000。当然，据他说，经过这么多年后，在经历了几次创业失败后他也回归于平淡，在张江一家做游戏的公司安安心心地上班。\n3\n我的大学后半段时间，真的非常痴迷于 Flash，那个时候觉得 Flash 就是整个人生的意义，并为此写过很多轻狂的话，像什么“你 flash一下子，我爱你一辈子，真像个傻子”、“让我们高举 Flash 伟大旗帜，紧密地团结在以 Adobe 为核心的富媒体公司周围，紧随乔纳森．盖伊的脚步，不舍昼夜的编程，把我国的 RIA 事业全面推向现代化！” 那个时候，坐五个小时的火车来上海，就为去上海书城买一本全英文版的《Flash 编程精髓》，甚至为了一份 flash 开发的工作差点儿放弃读研究生。时过境迁，八年后的今天，浏览器原生支持很多以前仅能通过 flash 实现的技术和效果，Adobe 公司宣布不再更新 flash，各个浏览器逐步禁用乃至不再支持 flash。真是让人唏嘘不已啊。\n大四正式离校的前一天晚上在逛蓝色理想站点时，发现有人在一篇帖子上推荐《Windows 程序设计》（第五版）这本书，看了下目录，果断购买，听说过这本书的读者应该知道，这本书一百多块钱，老厚了。这本书可谓是改变我整个人生轨迹的一本书吧，这本书介绍了 Windows 操作系统上程序运行的原理，直接利用操作系统提供的 API 进行编程。愈看这本书，我愈喜欢，它介绍了很多操作系统层面的原理，从前很多在 flash 平台不明白的东西一下子变得清晰起来，从前很多 flash 平台提供的类库不知道该如何使用一下子明白了为什么要那么设计了，后面又陆陆续续地看了《Windows 核心编程》等书。整个人更意识到对底层原理和计算机基础科学的掌握的重要性。于是等到硕士毕业时，我可以去一些公家单位从事地质相关的工作，去互联网业务做前端开发（也包括 flash 开发），但是我还是很倔强啊，薪资高低和工作地点并不是我考虑的因为，我就要做 Windows C++ 开发。当年非 flash 不嫁，如今却非要嫁给另外一个人。哎，人这辈子啊，真的可能会爱上很多人，工作、兴趣亦如是。\n4\n让我们来复盘一下这段经历，整个学生生涯，大学期间学的是 web 开发和 flash 编程，硕士期间学的是 Windows C++，并针对性地补充很多计算机科学的基础知识，也看了不少“闲杂知识”，如汇编、逆向、安全工程等等，当然都是自学。人的经历是有限的，自学的太多其他东西，很可能让你的专业课就变得一塌糊涂。我也是这样，所以，我特别理解 CSDN 上那位叫 moreWindows 的前辈在读研期间的痛苦，好几次想辍学去做开发。但是，作为过来人，我也想劝来者：如果你有机会读研一定去读个研究生，哪怕是自费或者非全日制的，你现在不明白，会有明白的一天，我们大多数人都不是命运的幸运儿，所以有时候学历还是有点用的。\n前期学习 Web 开发技术，让我对 html、javascript、CSS 等非常熟悉，而且我读了非常多的 web 方面的经典书籍，也熟悉 web 标准，那个时候讲究的是三层分离（即表现层、样式层和行为层要分离），加上后来又学习了 web 后端开发技术（主要是 php），我的水平具备开发一个商业的 web 整站的水平。这段经历，让我熟悉了很多计算机和软件开发的一些基础理论和设计原则，如 URL、相对路径等概念。\n后来，深入系统地学习了 Flash ActionScript 编程。这门语言的语法和类库，我现在已逐渐忘记了。但是这门语言让我深刻地理解了什么是面向对象编程，让我在后来学习 C++ 和 MFC 轻松了许多。读研期间，我也读了不少经典的计算机书籍，如《代码大全》、《整洁代码之道》、《程序员的自我修养》等等。这些书，与其说是从技术上影响了我，不如说从思想上影响了我，在我学生时代，让我对自己的编码无论是从效率还是从风格都严格要求自己。因此，它们带给我的正向效应也体现在我的第一份工作中。\n5\n由于我硕士毕业时，第一份工作非 Windows C++ 不做，但是很多公司要求有工作经验，挑来挑去，最后在上海（我是不愿意去二三线城市的）闵行的一家公司安定下来。离职的人千万不要说自己之前的公司多么不好，就和席慕蓉说年轻时被迫和爱过的一个人分开不要心存怨恨一样，那样只会显得自己多么差劲和眼瞎。这家公司做的是炒股软件，男怕入错行，女怕嫁错郎，刚毕业的男孩子们一定要做好职业规划，选好自己的职业和方向，从那以后，我虽然在短暂时间内离开互联网金融行业几次，但是我从未真正离开过。尽管这家公司存在很多问题，老板也不是很 nice，但是这家公司老板和两个 leader 都是做技术的，并且非常乐于传道授业解惑，定期的给各位新同事讲解开发知识；几年以后，成为技术 leader 的我，对于那些勤奋好学的组员，我也是愿意多给他们讲讲技术的。可惜职场中真正知道自己想要什么、明白自己为谁而干活的人太少，大多数都是重复着一圈又一圈的年轮，重复着冗杂业务代码的开发，工作做的不好也不坏，渐渐地变成了职场老油条或转行，留下来的老油条然后告诉新来的人，啊，程序员到了四十岁有职业危机啊。我一个硕士学历进入这家公司的薪资只有 5200 元，2014 年一个名牌大学的硕士从事 IT 行业拿这样的薪水还是有点低的，五千多出来的两百还是我和人事讨价还价要来的上下班公交费呢。那个时候为了省一点房租，我住的很远，可就是这样我仍旧每天加班到很晚，周末也会去公司。之前在书中看到的各种技术理论，慢慢地在项目代码中找到了应用，而这些代码就向对我打开的天堂之门。我如饥似渴地学习着。由于表现的好，加上公司人事调动，我很快成了整个客户端项目的负责人，并且为了更好地开发，老板也给我开了服务器代码权限。二个月后薪资涨到 7200，去北京出差回来，涨到 8000, 2015 年 10 月份，向老板提加薪 4000，老板也答应了。公司整体环境加上自己的努力和一点点运气，我熟悉了从 Windows 客户端到 Windows 服务器开发的一整套流程和常用技术。这里不得不提醒一下各位即将从事这个行业的读者，看懂别人的代码是一回事，自己会写会设计是另外一回事。我也是，举个例子，我们老板一直告诫我们 Windows 的完成端口模型一定要自己多练习几遍才能掌握，为此我练习了五遍，并且在后来的新项目中顶着项目进度的压力将底层网络通信框架重构了三个版本。在北京出差的那段日子里，我经常周日孤零零地坐在甲方的办公楼里写代码、调试代码到深夜。\n由于这家公司使用的是 Windows C++ 技术栈，后来公司与某个证券公司合作要开发一个新的项目，后台使用 Linux C++ 开发，为此招了两名 Linux C++ 开发，同时招了两名手机开发人员（安卓和 IOS 各一名），PC 端由我带领另外一名同事一起开发，我同时兼任整个项目的负责人。现在想想，当时真是初生牛犊不怕虎，那个时候谁都敢喷，作为一名客户端开发人员，竟然有时候会喷站在更高角度的后端开发人员。不过，回过头来想想，那时候这个项目的后端开发设计的协议确实不方便使用。\n6\n在之后，2015 年年底快过年了，发生了一件因为年终奖被克扣 80% 的问题，让我对老板很失望，在做完项目并交付后，我离职了。此时，我的月薪是 12 k。由于在第一家公司磨练出一身技术，加上扎实的基本功，经历三天的面试，锁定了两家单位，一家是上海张江的某家网络公司（为了叙述方便，以下称 A 公司），另外一家是东方财富网，前者给月薪 14 k，后者给月薪 18 k，由于学生时代感受到 A 公司插件的”厉害之处“，向往其犀利的技术，再加上东方财富国企式的面试风格和办事效率让我没有好感，在经过短暂几天纠结之后，选择去了 A 公司。这次是拒绝了东财的客户端职位，一年后又再次拒绝了东财的 23k 的后端开发职位，真是对不住那个可爱的人事小姐姐，两次都是同一个人事。\n但是干了一段时间后，A 公司让我觉得特别不舒服，这种不舒服不是在于 A 公司的待遇不好。平心而论，A 公司的工作没什么压力，负责的项目已经很稳定，而且是多个人负责一个项目甚至一个模块，每天可以准点下班，且每天下午都有较长时间的下午茶时间，每天每人一袋水果，常见的水果都有。每天晚上超过八点，可以享用公司的加班餐，加班餐很丰富，20 元一份的水果拼盘可以让两人吃到撑。年终奖是保底 14 薪，平均下来是 16 薪。真是个适合养生的好去处啊。\n我之所以觉得不舒服，是因为开发模式，第一，整个项目的框架由 A 公司的基础架构部给你开发好，另外 A 公司有个巨大的 RCFL 库，这个库封装了几乎所有常用的工具类，上层开发直接调用这个库里面的类。问题是，我们看不到这个库的代码。我并不想在这里养老，而且我也讨厌日复一日的业务开发且还看不到底层框架代码，并且那个时候，受在第一家公司 Linux 服务器开发的同事的影响，我有点不想继续做客户端开发了，我想去试试 Linux C++ 开发。于是，任性的我，这次决定离职了，虽然同事和部门 leader 意外的眼神让我觉得很对不住他们。但是，Linux 操作系统我并不熟悉，而且 Linux 的很多编程原理我也不清楚，于是我在 A 公司偷偷摸摸地学习了三个月 Linux 开发。三个月后人事告诉我可以转正了，我却告诉他她不想转正，我要离职了。那是 2016 年 5 月份的事情了。那个时候，上海的天气已经有点热了。社会人士求职要求的更多的是工作经验，所以我求职 Linux 开发的经历还是比较坎坷的。当时，女朋友还调侃我说，我要失业了。在寻找了好几个星期之后，我终于在另外一家公司以 16 k 入职。\n7\n这段工作经历，让我熟悉了 Linux C++ 后台开发的流程，加上自己爱研究，很快就对服务器后端的框架举一反三了。先后在这家公司做了两个项目，可惜好景不长，由于当时我们做的是现货业务，一年后由于国家政策收缩，公司业务被砍，大批量裁员。但是我呢，由于既可以做后端开发又可以做 pc 和 web 开发，被留下来了。当时另外一家公司正在高薪招技术好的全栈开发，这家公司工作压力确实很大，我最终以 26k * 15 被挖过去。我在这家公司做直播的后端开发，同时负责各个平台（pc、mac、安卓、ios等多操作系统多语言（主要是 C++ 和 Java 的开发））的 sdk 的维护。这家公司的技术我是从心底里佩服，全公司 90% 都是技术人员，同事要么毕业于各种名牌大学要么就是各个领域的技术专家。一家百人不到的公司，可以做到年盈利 3 亿。\n但是我很快从这家公司离职了，离职的原因是我和我的 leader 总是吵架，leader 也是一个性情中人，总是不分场合的骂人，导致项目组同事陆续离职，最后项目被合并。离职还有另外一个原因，就是我认为我理解了 C++，我想去把 Java 好好学一下。于是这次，我要找 Java 方面的职位，哪怕降薪也可以，于是我后来去了很多公司，把大大小小的互联网公司都撸了一遍。其中月薪最高的是一家 37 k 的创业公司技术主管，但是这不符合我的职业规划，我要学 Java，我要去大厂镀金。我没有去这家公司，但是我推荐给另外一位朋友去了这家公司。我之所以没去是当时想：如果我去了，是能在几年内赚点快钱，小公司的业务量和技术难度能让我在技术上提高多少？若干年后，我又该何去何从？而推荐给这个朋友去的原因是他的年龄比我大不少，他当时已经不想去什么大公司了，赚钱对他来说是第一要务。\n8\n最终，我以 C++ 技术专家的身份去了某大型互联网基础框架部，主要工作任务是维护一套 C 系统，同时参与各种新项目开发（以 Java 语言为主），既能立足于我从前的基础，也满足了我深入实践下 Java 的愿望。薪水是 33 k * 15 = 49.5，算上股票，年薪 50 W +。此时，我工作了四年。当然，由于我的技术比较好，面试官很满意，我也提了两点入职要求：1. 我要能看到我负责项目的全部源码；2. 所在的项目一定至少是有百万级业务量的，我需要挑战更高的技术难度。这家公司的体量和规模加上面试官的 level 都能满足我。\n把时间放长的话，例如工作八年到十年，对于做技术开发来说，年薪五十万并不难。但是，难点是如何毕业的前四五年内年薪 50 W。当然，年薪 50 W 的人到处都是，而且这个群体，多数人生活并不轻松。\n现在的生活，平静如水，我也继续积累和沉淀着。现在对自己的期许是做好当下事，莫问前程。\n9\n今年是 2019 年，算起来一共工作五年了，总结一下我的一些经验和感悟：\n要喜爱技术，兴趣在任何时候都是最好的动力，作为一名开发人员，一定要把技术学好，它是你吃饭的家伙，提高你的技能，能让你在职场上和收入上有立竿见影的效果；提高自己实质性的东西，在职场中成为某些职位无可替代者；踏踏实实做技术，不要附庸风雅地整各种技术名词，弄懂技术背后的原理；精益求精反复总结，你需要定期总结和提炼你的技术知识。\n职业规划要趁早，明确自己想要什么，成为什么样的人；有脱离自己舒适区的毅力，不要为了一点蝇头小利去一个地方选择一份工作，为自己的技能提高做投资。职业生涯的早些年，决定你去选择一份工作一定是因为有利于你成长，而不是工资高。我的几份工作都是为了习得某一种技术栈而做的选择，当然这种选择会有痛苦，但是只要你最终能达到目标，所有的痛苦都会成为你宝贵的人生经历。因此，悠闲舒适的地方我不去，看不到大多数源码让我觉得无法提高的地方我不去。经常玩知乎的人应该知道，知乎上各种”技术大神“动辄月薪三五万，还有学生群体讨论某某同学、师兄拿到 sp，年薪四五十万，这是典型的臆断妄想症，当然不排除少数天才和各种研究性人才。试想，年薪四五十万平均到每个月是多少钱？换位思考一下，在 IT 行业从原来的高级脑力活动变成工厂式的制作流程，干同样的活，一个几千或稍高工资就能招来的人干的活，如果你是老板，你会花高价招干同样活的人吗？人人都渴望高薪，但多数人都停留在嘴上或者想法中，凤毛麟角的人付诸于行动。\n不要停止学习基础知识，不要盲目去跟风时下流行的技术，注重内功培养，肯为自己的提高投入时间和金钱；在学习上对自己抠门的人，时间久了，必将泯然众人矣。正因为很多职场新人分不清楚哪是内功，哪是流行技术，我不建议一开始工作就去从事像 python、go 这样的语种的开发。\n做技术要有产品思维，技术本身不会给你带来财富，相应的业务可以，一般某一行技术好的人很多，但是既熟悉业务又懂技术的人就难能可贵了。\n10\n另外，给大家推荐一个高质量关于后台开发的学习公众号【高性能服务器开发】，非常 nice，从前我是一个服务器开发小白，我认真地把他写的每篇技术文章都看了一下（当然也有一些广告文，我直接忽略，哈哈），能感受到作者细腻的技术和厚实的基本功，特别赞同他说学习技术的准则：推崇基础学习与原理理解，不谈大而空的架构与技术术语，分享接地气的服务器开发实战技巧与项目经验，实实在在分享可用于实际编码的编程知识。作者承诺是凡是第一个发现他公众号中所有原创文章中的技术错误，可以获得他送的书。\n他有个很大的 QQ 群，群里面除了不定期技术分享外，讨论话题只能是技术或者职业规划相关的话题，禁止任何形式的灌水，同时为了鼓励群友学习，他会在每逢过节时给群友赠书（当然，只有他认为勤奋好学的群友才有机会获得赠书），书都是被赠者自己选的，群号是 578019391，有兴趣的知友也可以加一下。\n我和公众号作者在上海有过一面之缘，是个其貌不扬的憨憨的“大叔”（与我相比），我在找工作的过程中得到了他的很多帮助，不过他有时候脾气也很暴躁，他不解决别人的伸手党问题，只会给你说思路和解决问题的方法，完了还得自己动手。哎，真是奇怪又奇妙的人。T_T 虽然我不赞同他的很多观点和做法，但是人与人本来就是不同的，大家共同的目标是为了提高技术，增加收入，求同存异嘛。\n以上是自己真实的经历，文中观点难免一家之言，欢迎温和地提出意见和建议。\n最后，用冰心的话和大家一起共勉：成功的花儿，人们只惊羡她现时的明艳，然而当初她的芽儿，浸透了奋斗的泪泉，洒遍了牺牲的血雨。祝所有可爱的程序员同行们都能成功。\n","permalink":"https://haokiu.com/blog/7a566da932f2481388ca678c2dc2c1ac/","summary":"我是如何年薪五十万的 以下经历希望对广大程序员同行有点启发。\n1\n我姓方，码农一枚，14 年硕士毕业于某 211 学校，哎，这里就不提母校了。人到中年，还没混出什么名堂，就不给学校丢脸了。经常很多人问我现在的收入多少，这个嘛，男人的收入就和女人的身高一样是个秘密。不过，今天姑且聊一聊这个话题。\n2\n我的第一家公司做 Windows C/C++ 开发，第二家公司做 Linux C++ 开发，第三家公司是某大型互联网公司，以 C++ 技术专家的加入，同时从事 C++ 和 Java 开发。我大学学的非计算机专业，非科班出身的劣势就是参加大厂的校招时，筛选简历那一关直接给你 pass 掉了，这也是我毕业时未通过校招去大厂的原因之一。之所以走到今天靠的是自己的兴趣加上一些运气，当然也离不开很多人的帮助。大学时早年自学 Web ，熟悉 html 5 标准前的各类前端开发技术和 PS 等软件，后痴迷 Flash 编程，做过很多 Flash 动画自娱自乐，2011 年大学毕业时先后在上海一家开发 Flash 整站和一家做网页游戏公司任 Flash 程序员，第一家公司实习工资 1500，第二家公司正式员工月薪 3000。许多年后，我和第二家公司的 Flash 主程再聚首时，他告诉我其实我当时作为一名应届生 3000 的工资并不低，当时他作为项目负责人工资也才 8000。当然，据他说，经过这么多年后，在经历了几次创业失败后他也回归于平淡，在张江一家做游戏的公司安安心心地上班。\n3\n我的大学后半段时间，真的非常痴迷于 Flash，那个时候觉得 Flash 就是整个人生的意义，并为此写过很多轻狂的话，像什么“你 flash一下子，我爱你一辈子，真像个傻子”、“让我们高举 Flash 伟大旗帜，紧密地团结在以 Adobe 为核心的富媒体公司周围，紧随乔纳森．盖伊的脚步，不舍昼夜的编程，把我国的 RIA 事业全面推向现代化！” 那个时候，坐五个小时的火车来上海，就为去上海书城买一本全英文版的《Flash 编程精髓》，甚至为了一份 flash 开发的工作差点儿放弃读研究生。时过境迁，八年后的今天，浏览器原生支持很多以前仅能通过 flash 实现的技术和效果，Adobe 公司宣布不再更新 flash，各个浏览器逐步禁用乃至不再支持 flash。真是让人唏嘘不已啊。\n大四正式离校的前一天晚上在逛蓝色理想站点时，发现有人在一篇帖子上推荐《Windows 程序设计》（第五版）这本书，看了下目录，果断购买，听说过这本书的读者应该知道，这本书一百多块钱，老厚了。这本书可谓是改变我整个人生轨迹的一本书吧，这本书介绍了 Windows 操作系统上程序运行的原理，直接利用操作系统提供的 API 进行编程。愈看这本书，我愈喜欢，它介绍了很多操作系统层面的原理，从前很多在 flash 平台不明白的东西一下子变得清晰起来，从前很多 flash 平台提供的类库不知道该如何使用一下子明白了为什么要那么设计了，后面又陆陆续续地看了《Windows 核心编程》等书。整个人更意识到对底层原理和计算机基础科学的掌握的重要性。于是等到硕士毕业时，我可以去一些公家单位从事地质相关的工作，去互联网业务做前端开发（也包括 flash 开发），但是我还是很倔强啊，薪资高低和工作地点并不是我考虑的因为，我就要做 Windows C++ 开发。当年非 flash 不嫁，如今却非要嫁给另外一个人。哎，人这辈子啊，真的可能会爱上很多人，工作、兴趣亦如是。\n4\n让我们来复盘一下这段经历，整个学生生涯，大学期间学的是 web 开发和 flash 编程，硕士期间学的是 Windows C++，并针对性地补充很多计算机科学的基础知识，也看了不少“闲杂知识”，如汇编、逆向、安全工程等等，当然都是自学。人的经历是有限的，自学的太多其他东西，很可能让你的专业课就变得一塌糊涂。我也是这样，所以，我特别理解 CSDN 上那位叫 moreWindows 的前辈在读研期间的痛苦，好几次想辍学去做开发。但是，作为过来人，我也想劝来者：如果你有机会读研一定去读个研究生，哪怕是自费或者非全日制的，你现在不明白，会有明白的一天，我们大多数人都不是命运的幸运儿，所以有时候学历还是有点用的。\n前期学习 Web 开发技术，让我对 html、javascript、CSS 等非常熟悉，而且我读了非常多的 web 方面的经典书籍，也熟悉 web 标准，那个时候讲究的是三层分离（即表现层、样式层和行为层要分离），加上后来又学习了 web 后端开发技术（主要是 php），我的水平具备开发一个商业的 web 整站的水平。这段经历，让我熟悉了很多计算机和软件开发的一些基础理论和设计原则，如 URL、相对路径等概念。","title":"我是如何年薪五十万的"},{"content":"我的 2019 2019 年就这么悄无声息的过去了，我并不是一个喜欢缅怀过去的人，很多人喜欢回忆过去经历的困难，但就我倒是认为如果过去的苦难不能对将来生活质量或者人生经验有帮助，那这些苦难其实相当于白挨了。\n从学生时代开始，每年在年末时都会总结一下过去的一年，给自己复盘，总结一下过去一年的得失。成年人的生活没有谁是容易的，而成年人的工作和交往大多数都是逐利的，只是有些是直接的，有些是间接的。当然，这也无可厚非，大家的目的虽然功利却也高尚，都希望给自己和家人或者爱的人提供更好的生活质量。\n工作 先来说说我的工作吧。我是一名地地道道的程序员。我于 2018 年 12 月底从携程旅行网离职，应朋友邀请一起合伙创业，投资人是一知名大佬，创业的项目是基于区块链的期货交易系统，项目从 2018 年年底开始启动，从零开始开发，于 2019 年 8 月份正式全球上线，8 月后开始优化和重构部分框架。\n整个交易系统分为场上系统和场下系统，场上系统是交易系统的核心系统，一共有多个服务，从功能上有下单服务、清算服务、撮合服务、条件单服务、K 线服务和行情推送服务，场下系统为交易非核心系统，包括指数服务、管理系统等。使用的开发语言是 Java 和 C++，行情服务使用的是 C++，其他所有服务使用的是 Java，另外我们的客户端有 Web 端和手机端（安卓和 ios）。服务与服务之间使用 Kafka 作为消息中间件，数据存储和查询使用 mysql 和 ElasticSearch。交易核心系统开发要求比较高，无论是对性能还是代码的质量的要求比较高，交易系统非核心部分，例如管理系统，由于只是给内部运营团队使用，要求不高做的相对来说粗糙一些，其技术原理也比较简单（各种对数据库进行增删改查的 RESTFUL 接口），但由于功能比较多，工作量也比较大。除了这些技术栈外，还用到了 zookeeper、consul、Prometheus 等。\n互联网时代市场动态和风口转瞬即逝，因此我们需要尽快把产品做出来。从立项之初，我们自己公司技术人员加上我一共有 3 位，另外一位是邀请我的朋友，还有一位是我从携程\u0026quot;忽悠”过来的一位玩的比较好的同事。为了加快开发进度，加上起初我们对部分业务不是很熟悉或者经验不足，我们花了大约四百万在上海找了一个专门做交易系统的外包团队，外包团队负责主要开发，我们负责 review 代码和把控整体开发进度。原来外包团队承诺我们的是，项目可以在五月份完成，但是由于外包团队本身的质量问题导致后来我们不得不强力干预，甚至完全自己接手。由于外包团队中开发人员的素养问题以及外包团队的 leader 的管理和待遇问题，导致我们直到五月初还看不到一个可以走通基本流程的产品。于是后来我们的策略做了调整，与外包团队所在的公司进行了沟通，吸纳了外包团队中部分还不错的开发人员，对于无法达到我们要求的开发人员停止合作，最终我接手了条件单、撮合服务、K 线服务、行情推送服务等 4 个核心服务的开发，其中行情推送服务使用的是 C++，目前的人员配置中了，只有我同时拥有 C++ 和 Java 技术栈，因此只能我来接手行情推送服务。\n其实从我们与外包团队的合作的刚开始的两个月后，我们就觉得行情服务外包团队在预定的工期内无法完成，因此在那个时候我就被安排开始接手这个服务的开发，起初他们给我的一套程序是他们根据之前做过的一个股票服务的行情代码精简来的一个空架子，加上他们的代码有大量我们不需要的无用功能，加上其通信协议与我们的业务并不完全契合，在我花了一周时间熟悉后，我一边在原来的老的上面开发，另外有自己重新设计了一套，经过大家的试用后完全采用了我新的设计。由于 C++ 是我的技术专长，在行情服务基本开发完毕后，八月份上线后到目前没有出现任何问题，所以基本未做过任何的修改。这样为我腾出大量的时间去集中精力去开发和优化条件单、撮合和 K 线服务。\n先来说撮合服务吧。在大多数交易系统中，撮合服务是非常核心的一轮。所谓撮合，即根据一定的交易规则（常见的规则是时间优先、价格优先），将用户的报单进行成交，产生成交等相关信息，如果不能成交，则成为市场上的挂单。最初负责这个服务的外包同事，哎，但是由于其工作态度和代码素养问题，写出来的代码真的是\u0026quot;惨不忍睹\u0026quot;。我们与外包团队约定的要求是，撮合服务必须至少达到每秒可以处理 3000 ～ 5000 笔报单的性能。但是其交付后我们测试发现，每秒三百到五百的速度都达不到。但是这个事情的结果在我们整个公司，包括 CEO 都引起来非常大的恐慌。项目上线在即，如果按这个速度，我们的系统注定是个失败的产品。于是后来，CEO 给外包团队的领导施压，强行把这么同事给\u0026quot;撵走\u0026quot;了，并由我来接手，当然压力也落在我的身上，我记得我最初接手的那几周内，CEO 每天跑我工位上来问我撮合现在最新的进展怎样，有时候一天可能会跑两次。我在阅读其撮合代码的过程中，发现这个代码的质量非常差。当然造成撮合效率如此之低有两个主要原因：一是他使用的一个链表去存储所有用户的报单，这样的话，改单或者撤单，寻找某个订单时需要遍历这个链表，当订单数量多的时候，这个过程会很慢。哎，数据结构和算法不用心学的开发人员，真是贻害无穷啊。二是他往 Kafka 中写数据时使用了 Future 接口的 get 方法，熟悉 Java 的同学可能知道，这个是需要等待的，也就是说每往 Kafka 发一次数据都要等待结果返回。这种同步的做法，让整个撮合系统对报单的吞吐量变得很低。于是，在全公司上下尤其是 CEO 的\u0026quot;密切\u0026quot;注视下，我花了大概三个月时间基本重写了撮合服务的所有业务逻辑，而这个外包同事已经做这个做了半年了。\n剩下的是条件单服务，所谓条件单就是用户发起的、根据一定规则（例如某个价格指数达到一定值时）才会产生的报单。这个服务也是上文中开发撮合服务的外包同事做的，条件单和撮合服务存在同样的问题，我也重写了全部的业务逻辑，但是由于时间来不及，18 年 8 月份我们上线时由于还没重构完成，我们第一次没有上线这个功能，第一次上线后的一周后我们上线了这个功能。\n剩下的就是不太重要的 K 线服务了，K 线服务本身业务并不复杂，但是数据量非常大，原来是外包团队的另外一位同事开发的。原来我们的注意力并没有在这个上面有特别多的关注，主要是其比较简单。但是某天公司的产品同事，在群里发了几张关于我们生产环境的 K 线服务的图，结果某些大周期的 K 线数据竟然和小周期的 K 线数据竟然对不上，我当时真的是无语了。于是我又被安排维护 K 线服务，K 线服务的代码质量其实还是不错的，只不过一些核心的算法竟然不对，例如计算从某天到某天之间有多少小时，这都能算错，而且如果自己稍微验证一下就很容易发现问题。\n上面说的四个服务，除了行情推送服务由于早期就使用我开发的版本因此对我来说，很轻松，大家也很放心，但是撮合、条件单和 K 线这三个服务让我承受了很大的压力。我没预料到的是，一个外包团队的某些开发人员开发水平能不靠谱到如此程度，而且还是工作多年的程序员。好在一切都过来了，项目也成功上线了。后来，我们陆续招聘了前端开发人员、测试团队、补齐了自己的产品团队和运营团队，后来我们又招了客服团队。\n由于项目任务比较多，我们采用的是 996 模式，但是在 2018 年上半年，我基本上在晚上 12 点之前是没回去过的。当然，我并不认为工作时间与实际的产出会成正比，在团队扩大的过程中也暴露了很多的问题，有我自己的，也有 CEO 和团队其他一些负责人的。有的时候，我其实挺想和 CEO 说让大家每周多休息一天，但是看到当前的现状，我最终还是没开口。\n陶渊明说：种豆南山下，草盛豆苗稀；晨兴理荒秽，带月荷锄归；道狭草木长，夕露沾我衣；衣沾不足惜，但使愿无违。有的时候一些事情并不是我个人能力而能改变的，希望我们或者他们可以成功吧。\n陈述事情如果不能进行一次总结，那其实也没有意义的。让我们来复盘一下这一段的工作经历吧。应该很多人都有一个创业的梦想，这一年多的折腾我想说的是：\n创业的话一定要找靠谱的人，所有的 CEO 都会画饼，当你以为他很慎重的对待你的时候，他此时此刻和你说过的话，也许已经和其他人说过了。 创业团队的成员一定要有共同的信念和理想，如果最初的团队，大家都各自想着自己的利益，那么最终项目一定是做不好的； 创业团队的 leader 或者前辈一定要虚心接受他人意见，而不是根据自己所谓丰富的行业经验压制其他人的建议。 如果你的朋友在创业团队中没有很大的话语权，慎重接受他拉你去创业的邀请。 同样的道理，如果你的朋友在创业团队中没有很大的话语权，你如果接受和他一起创业，但是请慎重再邀请你其他的朋友或者同事去创业。 知识付费和自媒体 除了忙碌的工作以外，我在我那少的可怜的闲暇时间还维护着公众号和写了几个付费课程。\n先来说公众号吧，我从 2018 年 3 月份开始做公众号，我做公众号比较佛系，很少去通过一些专门的运营手段来运营。因此做了快两年了，目前粉丝只有三万四千左右。好在写的一些原创文章由于质量比较高，加上用心维护的 QQ 群氛围比较好，平均阅读量也有 1500+ 左右。当然，相比较 2018 年，2019 年写的原创文章就比较少了，同时也接了一些广告。广告是公众号的目前的主要收入来源，只有公众号作者有收入了，才会有更多的动力去给读者写更多的优质文章，做更多的优质分享。所以希望我的读者，如果你不想看我公众号发广告，可以不看，实在不喜欢就取关，实在没必要在后台喷。2020 年争取给大家创作更多的优质技术文章。\n另外，就是在 GitChat 上写作了两个付费课程，一个是关于 GDB 调试的，另外一个是关于多线程编程的。由于 GitChat 的方式，我个人觉得付出的时间成本和收入其实是不太匹配的。\n另外，就是运营我的知识星球——小方说服务器开发，由于个人精力有限，为了更好的为每一位球友服务，我的星球定价偏高，325一年，这样可以过滤掉一部分叶公好龙的人；当然如果真正愿意想学东西的，这个价格并不高。\n最后就是从年初到现在一直在写作一本关于高性能服务器开发方面的图书，我的写作特点是人云亦云的东西我不写，我诚惶诚恐的使用\u0026quot;著\u0026quot;一词，书的内容是我几年做 C++ 服务器方面的经验总结，当然这本书可能并不适合初级读者，可能做了几年 C++ 服务器开发后，遇到了一些问题，可能通过此书与我产生共鸣，到目前为止，我统计了一下，大概写了有 120 万字了。\n生活 我上次在公司和另外一位同事说，你要兼顾生活和工作，他回敬我：现在这种工作强度，我有鸡毛的生活。我竟然无法反驳，确实，今年大半年无论是平常还是节假日都是在加班中度过了，在此感谢我的媳妇对家庭的照顾和对我的支持。如果读者朋友遇到一位愿意和你一起在大城市打拼的姑娘一定要好好珍惜。\n2020 的计划 2020 年的计划之一是把书写完，出版出来。\n另外，继续完善自己的技术栈。自媒体和知识付费确实给我带来了一部分收入，但是与很其他的一些技术公众号主相比，让副业的收入达到或者超过主业的收入，对我来说那基本不可能。而且我个人是一个非常喜欢编码的人，我喜欢在技术上能达到一定的造诣。所以，自媒体不会成为我的重心。所以认认真真的再研究点代码，看几本好书，做些挑战性的项目，也是我 2020 的计划。\n最后，锻炼身体，当然，希望我能坚持。\n新的一年，大家一起加油，张小方与你同在。\n如果你想和我聊一聊，可以加我微信 easy_coder。\n","permalink":"https://haokiu.com/blog/fce122b624fd44a88df285c221d765b8/","summary":"我的 2019 2019 年就这么悄无声息的过去了，我并不是一个喜欢缅怀过去的人，很多人喜欢回忆过去经历的困难，但就我倒是认为如果过去的苦难不能对将来生活质量或者人生经验有帮助，那这些苦难其实相当于白挨了。\n从学生时代开始，每年在年末时都会总结一下过去的一年，给自己复盘，总结一下过去一年的得失。成年人的生活没有谁是容易的，而成年人的工作和交往大多数都是逐利的，只是有些是直接的，有些是间接的。当然，这也无可厚非，大家的目的虽然功利却也高尚，都希望给自己和家人或者爱的人提供更好的生活质量。\n工作 先来说说我的工作吧。我是一名地地道道的程序员。我于 2018 年 12 月底从携程旅行网离职，应朋友邀请一起合伙创业，投资人是一知名大佬，创业的项目是基于区块链的期货交易系统，项目从 2018 年年底开始启动，从零开始开发，于 2019 年 8 月份正式全球上线，8 月后开始优化和重构部分框架。\n整个交易系统分为场上系统和场下系统，场上系统是交易系统的核心系统，一共有多个服务，从功能上有下单服务、清算服务、撮合服务、条件单服务、K 线服务和行情推送服务，场下系统为交易非核心系统，包括指数服务、管理系统等。使用的开发语言是 Java 和 C++，行情服务使用的是 C++，其他所有服务使用的是 Java，另外我们的客户端有 Web 端和手机端（安卓和 ios）。服务与服务之间使用 Kafka 作为消息中间件，数据存储和查询使用 mysql 和 ElasticSearch。交易核心系统开发要求比较高，无论是对性能还是代码的质量的要求比较高，交易系统非核心部分，例如管理系统，由于只是给内部运营团队使用，要求不高做的相对来说粗糙一些，其技术原理也比较简单（各种对数据库进行增删改查的 RESTFUL 接口），但由于功能比较多，工作量也比较大。除了这些技术栈外，还用到了 zookeeper、consul、Prometheus 等。\n互联网时代市场动态和风口转瞬即逝，因此我们需要尽快把产品做出来。从立项之初，我们自己公司技术人员加上我一共有 3 位，另外一位是邀请我的朋友，还有一位是我从携程\u0026quot;忽悠”过来的一位玩的比较好的同事。为了加快开发进度，加上起初我们对部分业务不是很熟悉或者经验不足，我们花了大约四百万在上海找了一个专门做交易系统的外包团队，外包团队负责主要开发，我们负责 review 代码和把控整体开发进度。原来外包团队承诺我们的是，项目可以在五月份完成，但是由于外包团队本身的质量问题导致后来我们不得不强力干预，甚至完全自己接手。由于外包团队中开发人员的素养问题以及外包团队的 leader 的管理和待遇问题，导致我们直到五月初还看不到一个可以走通基本流程的产品。于是后来我们的策略做了调整，与外包团队所在的公司进行了沟通，吸纳了外包团队中部分还不错的开发人员，对于无法达到我们要求的开发人员停止合作，最终我接手了条件单、撮合服务、K 线服务、行情推送服务等 4 个核心服务的开发，其中行情推送服务使用的是 C++，目前的人员配置中了，只有我同时拥有 C++ 和 Java 技术栈，因此只能我来接手行情推送服务。\n其实从我们与外包团队的合作的刚开始的两个月后，我们就觉得行情服务外包团队在预定的工期内无法完成，因此在那个时候我就被安排开始接手这个服务的开发，起初他们给我的一套程序是他们根据之前做过的一个股票服务的行情代码精简来的一个空架子，加上他们的代码有大量我们不需要的无用功能，加上其通信协议与我们的业务并不完全契合，在我花了一周时间熟悉后，我一边在原来的老的上面开发，另外有自己重新设计了一套，经过大家的试用后完全采用了我新的设计。由于 C++ 是我的技术专长，在行情服务基本开发完毕后，八月份上线后到目前没有出现任何问题，所以基本未做过任何的修改。这样为我腾出大量的时间去集中精力去开发和优化条件单、撮合和 K 线服务。\n先来说撮合服务吧。在大多数交易系统中，撮合服务是非常核心的一轮。所谓撮合，即根据一定的交易规则（常见的规则是时间优先、价格优先），将用户的报单进行成交，产生成交等相关信息，如果不能成交，则成为市场上的挂单。最初负责这个服务的外包同事，哎，但是由于其工作态度和代码素养问题，写出来的代码真的是\u0026quot;惨不忍睹\u0026quot;。我们与外包团队约定的要求是，撮合服务必须至少达到每秒可以处理 3000 ～ 5000 笔报单的性能。但是其交付后我们测试发现，每秒三百到五百的速度都达不到。但是这个事情的结果在我们整个公司，包括 CEO 都引起来非常大的恐慌。项目上线在即，如果按这个速度，我们的系统注定是个失败的产品。于是后来，CEO 给外包团队的领导施压，强行把这么同事给\u0026quot;撵走\u0026quot;了，并由我来接手，当然压力也落在我的身上，我记得我最初接手的那几周内，CEO 每天跑我工位上来问我撮合现在最新的进展怎样，有时候一天可能会跑两次。我在阅读其撮合代码的过程中，发现这个代码的质量非常差。当然造成撮合效率如此之低有两个主要原因：一是他使用的一个链表去存储所有用户的报单，这样的话，改单或者撤单，寻找某个订单时需要遍历这个链表，当订单数量多的时候，这个过程会很慢。哎，数据结构和算法不用心学的开发人员，真是贻害无穷啊。二是他往 Kafka 中写数据时使用了 Future 接口的 get 方法，熟悉 Java 的同学可能知道，这个是需要等待的，也就是说每往 Kafka 发一次数据都要等待结果返回。这种同步的做法，让整个撮合系统对报单的吞吐量变得很低。于是，在全公司上下尤其是 CEO 的\u0026quot;密切\u0026quot;注视下，我花了大概三个月时间基本重写了撮合服务的所有业务逻辑，而这个外包同事已经做这个做了半年了。\n剩下的是条件单服务，所谓条件单就是用户发起的、根据一定规则（例如某个价格指数达到一定值时）才会产生的报单。这个服务也是上文中开发撮合服务的外包同事做的，条件单和撮合服务存在同样的问题，我也重写了全部的业务逻辑，但是由于时间来不及，18 年 8 月份我们上线时由于还没重构完成，我们第一次没有上线这个功能，第一次上线后的一周后我们上线了这个功能。\n剩下的就是不太重要的 K 线服务了，K 线服务本身业务并不复杂，但是数据量非常大，原来是外包团队的另外一位同事开发的。原来我们的注意力并没有在这个上面有特别多的关注，主要是其比较简单。但是某天公司的产品同事，在群里发了几张关于我们生产环境的 K 线服务的图，结果某些大周期的 K 线数据竟然和小周期的 K 线数据竟然对不上，我当时真的是无语了。于是我又被安排维护 K 线服务，K 线服务的代码质量其实还是不错的，只不过一些核心的算法竟然不对，例如计算从某天到某天之间有多少小时，这都能算错，而且如果自己稍微验证一下就很容易发现问题。\n上面说的四个服务，除了行情推送服务由于早期就使用我开发的版本因此对我来说，很轻松，大家也很放心，但是撮合、条件单和 K 线这三个服务让我承受了很大的压力。我没预料到的是，一个外包团队的某些开发人员开发水平能不靠谱到如此程度，而且还是工作多年的程序员。好在一切都过来了，项目也成功上线了。后来，我们陆续招聘了前端开发人员、测试团队、补齐了自己的产品团队和运营团队，后来我们又招了客服团队。\n由于项目任务比较多，我们采用的是 996 模式，但是在 2018 年上半年，我基本上在晚上 12 点之前是没回去过的。当然，我并不认为工作时间与实际的产出会成正比，在团队扩大的过程中也暴露了很多的问题，有我自己的，也有 CEO 和团队其他一些负责人的。有的时候，我其实挺想和 CEO 说让大家每周多休息一天，但是看到当前的现状，我最终还是没开口。","title":"我的 2019"},{"content":"我面试后端开发经理的经历 我去年12月份从上一家公司离职，一直到今年3月份，基本上都在面试中度过来的。\n先交代下背景：坐标上海，做技术开发，我本人面试的职位是linux服务器开发，最倾向的职位是服务器开发主程或技术经理。我本人也是上几家公司的面试官，因为接下来几年面临着成家，技术上也到了瓶颈期，虽然拿了不少offer，但是想综合比对一下，于是就参加了很多的面试。我先后去了如下一些公司：腾讯、百度、饿了么、爱奇艺、360、携程网、京东、华为、bilibili、上海黄金交易所、东方财富网、zilliz、掌门集团(做无线万能钥匙的那一家)、喜马拉雅听书、峰果网络、华尔街新闻、万得财经、汇正财经、逗屋网络、朝阳永续，还有数家小规模的公司或创业公司吧。\n为了避免引起不必要的纠纷，下面我就不说具体的公司名称了。技术面试的细节我尽量写的详细一点，希望对大家有参考价值，技术面试大致有三种情形：\n经验分享 一、以百度、爱奇艺等为代表的，以数据结构和算法为主。\n首先是简单地了解下你之前的工作经历和项目经验，然后就是算法和数据结构题目，具体涉及到以下内容：\n01\n快速排序\n快速排序（包括算法步骤、平均算法复杂度、最好和最坏的情形），有人说校招要把算法写出来，我是社招，所以描述一下算法步骤即可。\n02\n二分查找算法\n写二分查找算法，这个尽管是社招，但是一般也不难，所以要求面试者写出来。但是很多公司，比如不会直接让你写算法，而是结合一个具体场景来提问，然后让你自己联想到二分查找，比如求一个数的平方根。\n03\n链表\n链表，常见的面试题有写一个链表中删除一个节点的算法、单链表倒转、两个链表找相交的部分，这个一般必须得完全无误的情况下写出来。\n04\n自己实现一些基础的函数\n自己实现一些基础的函数，例如strcpy / memcpy / memmov / atoi，同样的道理，这些必须完全无误且高效地写出来，比如你的实现中会动态分配堆内存，那么这道题目就算答错。\n第3点和第4点的门道一般在于考察你的代码风格、对边界条件的处理，比如判断指针是否为空，千万不要故意不考虑这种情形，即使你知道也不行，只要你不写，一般面试官就认为你的思路不周详，容错率低；再比如，单链表的倒转，最后的返回值肯定是倒转后的链表头结点，这样才能引用一个链表，这些都是面试官想考虑的重点。\n05\n哈希表\n哈希表，对哈希表的细节要求很高，比如哈希表的冲突检测、哈希函数常用实现、算法复杂度；比如百度二面就让我写一个哈希表插入元素算法，元素类型是任意类型。\n06\nAVL树和B树的概念、细节\nAVL树和B树的概念、细节，比如会问mysql数据库的索引的实现原理，基本上就等于问你B树了。\n07\n红黑树\n红黑树，这个基本上必问的一个数据结构，包括红黑树的概念、平均算法复杂度、最好最坏情况下的算法复杂度、、左右旋转、颜色变换。面试官常见的算法套路有：你熟悉C++的stl吗？你说熟悉，ok，stl的map用过吧？用过，ok，那map是如何实现的？红黑树，ok，那什么是红黑树？这样提问红黑树就开始了。Java的也类似。\n二、以饿了么、bilibli、喜马拉雅、360、携程等为代表的，兼顾算法数据结构和其他开发技术。\n算法和数据结构部分上文提过了，下面提一下其他技术，大致包括以下东西：\n01\n基础的C++问题\n以C++语言为例（不是C++开发的朋友可以跳过这一点），第一类是基础的C++问题，常见的有C++的继承体系中virtual关键字的作用（如继承关系中析构函数为什么要申明成virtual函数，如果不申明为virtual会有什么影响)、在涉及到父子类时构造与析构函数的执行顺序、多重继承时类的成员列表在地址空间的排列；static关键字的作用，static_cast / reinterpret_cast / dynamic_cast等几个转换符的使用场景;问的最多的就是虚表的布局，尤其是菱形继承(B和C继承A，D继承B和C)时每个对象的空间结构分布，比如问D有几份虚表，D中B和C的成员空间排布。\n另外，如果你应聘的职位使用C++开发，很多公司会问你一些C++11的东西（或者问boost库，基本上都一样），这个你用过就用过，没有用过就说没用过不要装X，常见的C++11需要掌握的一些技术库我也列举一下吧（JAVA及其他语言的读者可以忽略）：\nauto关键字、for-each循环、右值及移动构造函数 + std::forward + std::move + stl容器新增的emplace_back()方法、std::thread库、std::chrono库、智能指针系列（std::shared_ptr/std::unique_ptr/std::weak_ptr）(智能指针的实现原理一定要知道，最好是自己实现过)、线程库std::thread+线程同步技术库std::mutex/std::condition_variable/std::lock_guard等、lamda表达式（JAVA中现在也常常考察lamda表达式的作用）、std::bind/std::function库、其他的就是一些关键字的用法(override、final、delete)，还有就是一些细节如可以像JAVA一样在类成员变量定义处给出初始化值。\n02\n网络通信问题\n网络通信问题，比如协议栈的层级关系，三次握手和四次挥手的【细节】，注意我说的是细节，比如CLOSE_WAIT和TIME_WAIT状态（bilibili问了这样一个问题，你可以感受一下：A与B建立了正常连接后，从未相互发过数据，这个时候B突然机器重启，问A此时的tcp状态处于什么状态？如何消除服务器程序中的这个状态？\n万得问过流量拥塞和控制机制、腾讯问过tcp和ip包头常见有哪些字段），阻塞和非阻塞socket在send、recv函数上的行为表现，异步connect函数的写法，select函数的用法，epoll与select的区别，基本上只要问到epoll，必问epoll的水平模式和边缘模式的区别；一些socket选项的用法，nagle / keepalive / linger等选项的区别；tcp / udp的区别和适用场景；通信协议如何设计避免粘包；http协议的get和post方法的区别（问的比较深的会让你画出http协议的格式，参照这篇文章中关于http协议格式的讲解：http://blog.csdn.net/analogous_love/article/details/72540130）；windows用户可能会问到完成端口模型(IOCP)，网络通信方面的问题，我专门开了一个知乎live系统地总结了一下，有兴趣的朋友可以看这里：https://www.zhihu.com/lives/922110858308485120 和 这里：https://www.zhihu.com/lives/902113324999778304。\n总之，网络通信问题能搞的多清楚就可以搞的多清楚，最起码把tcp应用层的各种socket API的用法细节搞清楚。\n03\n操作系统原理性的东西\n比如linux下elf文件的节结构，映射到进程地址空间后，分别对应哪些段，相关的问题还有，全局变量、静态存储在进程地址空间的哪里；堆和栈的区别，栈的结构，栈的细节一点要搞的特别清楚，因为一些对技术要求比较高的公司会问的比较深入，例如京东的一面是让我先写一个从1加到100的求和函数，然后让我写出这个函数的汇编代码（JAVA开发的同学可能会让你试着去写一点JVM的指令），如果你对栈的结构（如函数参数入栈顺序、函数局部变量在栈中的布局、栈帧指针和栈顶指针的位置）不熟悉的话，这题目就无法答对了；栈的问题，可能会以常见的函数调用方式来提问，常见的函数调用有如下__cdecl/__stdcall/__thiscall/__fastcall的区别，比如像printf这样具有不定参数的函数为什么不能使用__stdcall；还有就是进程和线程的联系与区别，问的最多的就是线程之间的一些同步技术，如互斥体、信号量、条件变量等(Windows上还有事件、临界区等)，这些东西你必须熟悉到具体的API函数使用的层面上来，从另外一个角度来说，这是咱们实际工作中编码最常用的东西，如果你连这个都不能熟练使用，那么你肯定不是一个合格的开发者；这类问题还可以引申为什么是死锁、如何避免死锁；进程之间通信的常用技术也需要掌握，常用的通信方式（linux下）有共享内存、匿名和具名管道、socket、消息队列等等，管道和socket是两个必须深入掌握的考察点（与上面网络通信有点重复）；linux系统下可能还会问什么是daemon进程，如何产生daemo进程，什么是僵尸进程，僵尸进程如何产生和消除（bilibili问过）。\nCAS机制（饿了么二面问过）。\n04\n使用过的开源技术\n第四类就是一个使用过的开源技术，比如代表nosql技术的redis；网络库libevent等等；数据库如mysql的一些东西。这个一般不做硬性要求，但是这里必须强调的就是redis，熟练使用redis甚至研究过redis源码，现在一般是做后台开发的技术标配或者说不可缺少的部分，基于redis的面试题既可以聊算法与数据结构，也可以聊网络框架等等一类东西。我面试的公司中基本上百分之九十以上都问到了redis，只是深浅不一而已，比如喜马拉雅问了redis的数据存储结构、rehash；bilibili问了redis的事务与集群。\n三、只问一些做过的业务或者项目经验。\n这类公司他们招人其实对技术要求不高（资深及主管级开发除外），只要你过往的项目与当前应聘职位匹配，可以过来直接上手干活就可以了，当然薪资也就不会给很多。比如游戏公司会关心你是否有某某类型的游戏开发经验、股票类公司会关心你是否有过证券或者交易系统的开发经验等。我的经验就是这类公司，能去的话可以去，不能去的话就当积累面试经验。业务开发哪里都能找到，真正的重视技术的公司，应该是广大做技术尤其是初中级开发的朋友应该值得关心的事情。\n不靠谱型公司。 我遇到的大致有四类：\n01\n装X忽悠型\n第一类：装X忽悠型\n面试过程冗长繁琐，比如号称每一百份简历中才发一个面试邀请，号称每一百个面试者发一个offer，号称硅谷风格，我面试的有一家公司就是这个样子，先是一轮长长的电话面试，然后是五轮技术面试，前三轮是刷leetcode上原题，然后后几轮面试，面试官从基本的操作系统的中断、GDT、LDT、分表分页机制问到上层高并发海量数据的架构，说的不好听，真是从外太空聊到内子宫，最后问具体职位做什么时，要么遮遮掩掩要么原型毕露；或者讨论薪资时，要么面露难色要么各种画饼，但是实际就给不了多少薪水的。\n02\n佛性公司\n第二类：佛性公司\n面试下来，全程面试官面带微笑，问你的问题你回答的面试官也很赞同，但最后你就没通过，我猜测要么公司不是很缺人，想观望一下是否有合适的人才；要么招聘信息上开的薪资给不到。\n03\n老奶奶裹脚布型公司\n第三类：老奶奶裹脚布型公司\n其特点是面试周期长，往往第一轮面试通知你过了，让你回去等上十天半个月后，给你打电话通知你来第二轮面试，面试要求穿正装，带好各种证件，面试前必须先查验你的身份证、学历证学位证，甚至是四六级考试证等等，麻烦至极，即使你一路过关斩将过了终面，薪资也给不了多少。大家都是要养家糊口的，都是忙着找工作，谁有时间和你耗上十天半个月呢？\n04\n不尊重人类型公司\n第四类：不尊重人类型公司\n我这里说的不尊重人，不是指的是面试过程中对你人身攻击，而是不根据你的工作年限和经验随意安排面试官，举个例子，比如你工作十年，你去面试一个技术总监的职位，对方公司安排一个工作不满两年的部门职员作为面试官，这个面试官如果是走过场可以理解，但是非要和你纠结一个如二进制位移、现代编译器要不要在子类析构函数前加virtual关键字这些技术细节就没必要了。还有一类就是故意问一些刁钻的问题，或者全场都心不在焉、玩手机、漫不经心的面试官，比如问你tcp协议头有多少个字段，每个字段是干啥的。遇到这一类面试官我的经验就是要么婉拒，要么直接怼回去。\n注意细节 下面再说下面试中需要注意的一些细节：\n01\n把目光放长远一点\n第一，如果你的工作年限不长，尤其是渴望在技术方面有一定的造诣，那么你首先考虑的应该是新的单位是否能有利于你技术上的成长，而不是两份同样的工作，薪资上的上下相差的三五千、五六千。如果想转行的同学（比如从客户端转服务器，从C++转JAVA），不要因为薪资突然变低而拒绝这种阵痛，要把目光放长远一点。\n02\n可能最终会因为薪资达不到不被录取\n第二，一些公司虽然招聘信息上写了最多能给到多少多少，但实际即使你全程面试下来都很完美，可能最终你也会因为薪资达不到不被录取。\n03\n多面试积累经验\n第三，一些根本不想去的公司，如果你有时间的话，去面试积累下经验也不是什么坏事。\n04\n警惕技术天花板\n第四，面试的时候，同时也是你在考察面试官，一般面试官问你的问题，你能回答出来的在百分之八十左右，这样的公司可以考虑去入职，你进去的话可能才会在技术上有一些提升。如果你全场秒杀面试官的题目，你的技术天花板可能也在那里。\n05\n聊清楚将来的职位内容\n第五，面试的时候聊清楚你将来的职位内容，避免进去客串一些不想做的工作。\n06\n不会的面试题尝试去和面试官沟通\n第六，遇到不会的面试题，不要直接就否定自己，可以尝试着去和面试官沟通一下，或者要求给点提示或者思路。\n07\n不要轻视笔试中的数学智力题\n第七，不要轻视笔试中的一些数学智力题目，认真作答，试问算法不也是数学智力题吗？\n08\n自信点\n第八，自信一点，每个人的经历和经验都是独一无二的，面试的时候，一些特定领域的问题，回答不出来也不要太在意。\n希望对阅读的朋友有所帮助。因为个人经验能力有限，所说的也可能只是一家之言，说的不妥当的地方还请温和地提出建议，如果读者有任何问题可以加我微信 easy_coder 交流。\n","permalink":"https://haokiu.com/blog/b9e6c063ac4a43aca14c01cc45b2f8fa/","summary":"我面试后端开发经理的经历 我去年12月份从上一家公司离职，一直到今年3月份，基本上都在面试中度过来的。\n先交代下背景：坐标上海，做技术开发，我本人面试的职位是linux服务器开发，最倾向的职位是服务器开发主程或技术经理。我本人也是上几家公司的面试官，因为接下来几年面临着成家，技术上也到了瓶颈期，虽然拿了不少offer，但是想综合比对一下，于是就参加了很多的面试。我先后去了如下一些公司：腾讯、百度、饿了么、爱奇艺、360、携程网、京东、华为、bilibili、上海黄金交易所、东方财富网、zilliz、掌门集团(做无线万能钥匙的那一家)、喜马拉雅听书、峰果网络、华尔街新闻、万得财经、汇正财经、逗屋网络、朝阳永续，还有数家小规模的公司或创业公司吧。\n为了避免引起不必要的纠纷，下面我就不说具体的公司名称了。技术面试的细节我尽量写的详细一点，希望对大家有参考价值，技术面试大致有三种情形：\n经验分享 一、以百度、爱奇艺等为代表的，以数据结构和算法为主。\n首先是简单地了解下你之前的工作经历和项目经验，然后就是算法和数据结构题目，具体涉及到以下内容：\n01\n快速排序\n快速排序（包括算法步骤、平均算法复杂度、最好和最坏的情形），有人说校招要把算法写出来，我是社招，所以描述一下算法步骤即可。\n02\n二分查找算法\n写二分查找算法，这个尽管是社招，但是一般也不难，所以要求面试者写出来。但是很多公司，比如不会直接让你写算法，而是结合一个具体场景来提问，然后让你自己联想到二分查找，比如求一个数的平方根。\n03\n链表\n链表，常见的面试题有写一个链表中删除一个节点的算法、单链表倒转、两个链表找相交的部分，这个一般必须得完全无误的情况下写出来。\n04\n自己实现一些基础的函数\n自己实现一些基础的函数，例如strcpy / memcpy / memmov / atoi，同样的道理，这些必须完全无误且高效地写出来，比如你的实现中会动态分配堆内存，那么这道题目就算答错。\n第3点和第4点的门道一般在于考察你的代码风格、对边界条件的处理，比如判断指针是否为空，千万不要故意不考虑这种情形，即使你知道也不行，只要你不写，一般面试官就认为你的思路不周详，容错率低；再比如，单链表的倒转，最后的返回值肯定是倒转后的链表头结点，这样才能引用一个链表，这些都是面试官想考虑的重点。\n05\n哈希表\n哈希表，对哈希表的细节要求很高，比如哈希表的冲突检测、哈希函数常用实现、算法复杂度；比如百度二面就让我写一个哈希表插入元素算法，元素类型是任意类型。\n06\nAVL树和B树的概念、细节\nAVL树和B树的概念、细节，比如会问mysql数据库的索引的实现原理，基本上就等于问你B树了。\n07\n红黑树\n红黑树，这个基本上必问的一个数据结构，包括红黑树的概念、平均算法复杂度、最好最坏情况下的算法复杂度、、左右旋转、颜色变换。面试官常见的算法套路有：你熟悉C++的stl吗？你说熟悉，ok，stl的map用过吧？用过，ok，那map是如何实现的？红黑树，ok，那什么是红黑树？这样提问红黑树就开始了。Java的也类似。\n二、以饿了么、bilibli、喜马拉雅、360、携程等为代表的，兼顾算法数据结构和其他开发技术。\n算法和数据结构部分上文提过了，下面提一下其他技术，大致包括以下东西：\n01\n基础的C++问题\n以C++语言为例（不是C++开发的朋友可以跳过这一点），第一类是基础的C++问题，常见的有C++的继承体系中virtual关键字的作用（如继承关系中析构函数为什么要申明成virtual函数，如果不申明为virtual会有什么影响)、在涉及到父子类时构造与析构函数的执行顺序、多重继承时类的成员列表在地址空间的排列；static关键字的作用，static_cast / reinterpret_cast / dynamic_cast等几个转换符的使用场景;问的最多的就是虚表的布局，尤其是菱形继承(B和C继承A，D继承B和C)时每个对象的空间结构分布，比如问D有几份虚表，D中B和C的成员空间排布。\n另外，如果你应聘的职位使用C++开发，很多公司会问你一些C++11的东西（或者问boost库，基本上都一样），这个你用过就用过，没有用过就说没用过不要装X，常见的C++11需要掌握的一些技术库我也列举一下吧（JAVA及其他语言的读者可以忽略）：\nauto关键字、for-each循环、右值及移动构造函数 + std::forward + std::move + stl容器新增的emplace_back()方法、std::thread库、std::chrono库、智能指针系列（std::shared_ptr/std::unique_ptr/std::weak_ptr）(智能指针的实现原理一定要知道，最好是自己实现过)、线程库std::thread+线程同步技术库std::mutex/std::condition_variable/std::lock_guard等、lamda表达式（JAVA中现在也常常考察lamda表达式的作用）、std::bind/std::function库、其他的就是一些关键字的用法(override、final、delete)，还有就是一些细节如可以像JAVA一样在类成员变量定义处给出初始化值。\n02\n网络通信问题\n网络通信问题，比如协议栈的层级关系，三次握手和四次挥手的【细节】，注意我说的是细节，比如CLOSE_WAIT和TIME_WAIT状态（bilibili问了这样一个问题，你可以感受一下：A与B建立了正常连接后，从未相互发过数据，这个时候B突然机器重启，问A此时的tcp状态处于什么状态？如何消除服务器程序中的这个状态？\n万得问过流量拥塞和控制机制、腾讯问过tcp和ip包头常见有哪些字段），阻塞和非阻塞socket在send、recv函数上的行为表现，异步connect函数的写法，select函数的用法，epoll与select的区别，基本上只要问到epoll，必问epoll的水平模式和边缘模式的区别；一些socket选项的用法，nagle / keepalive / linger等选项的区别；tcp / udp的区别和适用场景；通信协议如何设计避免粘包；http协议的get和post方法的区别（问的比较深的会让你画出http协议的格式，参照这篇文章中关于http协议格式的讲解：http://blog.csdn.net/analogous_love/article/details/72540130）；windows用户可能会问到完成端口模型(IOCP)，网络通信方面的问题，我专门开了一个知乎live系统地总结了一下，有兴趣的朋友可以看这里：https://www.zhihu.com/lives/922110858308485120 和 这里：https://www.zhihu.com/lives/902113324999778304。\n总之，网络通信问题能搞的多清楚就可以搞的多清楚，最起码把tcp应用层的各种socket API的用法细节搞清楚。\n03\n操作系统原理性的东西\n比如linux下elf文件的节结构，映射到进程地址空间后，分别对应哪些段，相关的问题还有，全局变量、静态存储在进程地址空间的哪里；堆和栈的区别，栈的结构，栈的细节一点要搞的特别清楚，因为一些对技术要求比较高的公司会问的比较深入，例如京东的一面是让我先写一个从1加到100的求和函数，然后让我写出这个函数的汇编代码（JAVA开发的同学可能会让你试着去写一点JVM的指令），如果你对栈的结构（如函数参数入栈顺序、函数局部变量在栈中的布局、栈帧指针和栈顶指针的位置）不熟悉的话，这题目就无法答对了；栈的问题，可能会以常见的函数调用方式来提问，常见的函数调用有如下__cdecl/__stdcall/__thiscall/__fastcall的区别，比如像printf这样具有不定参数的函数为什么不能使用__stdcall；还有就是进程和线程的联系与区别，问的最多的就是线程之间的一些同步技术，如互斥体、信号量、条件变量等(Windows上还有事件、临界区等)，这些东西你必须熟悉到具体的API函数使用的层面上来，从另外一个角度来说，这是咱们实际工作中编码最常用的东西，如果你连这个都不能熟练使用，那么你肯定不是一个合格的开发者；这类问题还可以引申为什么是死锁、如何避免死锁；进程之间通信的常用技术也需要掌握，常用的通信方式（linux下）有共享内存、匿名和具名管道、socket、消息队列等等，管道和socket是两个必须深入掌握的考察点（与上面网络通信有点重复）；linux系统下可能还会问什么是daemon进程，如何产生daemo进程，什么是僵尸进程，僵尸进程如何产生和消除（bilibili问过）。\nCAS机制（饿了么二面问过）。\n04\n使用过的开源技术\n第四类就是一个使用过的开源技术，比如代表nosql技术的redis；网络库libevent等等；数据库如mysql的一些东西。这个一般不做硬性要求，但是这里必须强调的就是redis，熟练使用redis甚至研究过redis源码，现在一般是做后台开发的技术标配或者说不可缺少的部分，基于redis的面试题既可以聊算法与数据结构，也可以聊网络框架等等一类东西。我面试的公司中基本上百分之九十以上都问到了redis，只是深浅不一而已，比如喜马拉雅问了redis的数据存储结构、rehash；bilibili问了redis的事务与集群。\n三、只问一些做过的业务或者项目经验。\n这类公司他们招人其实对技术要求不高（资深及主管级开发除外），只要你过往的项目与当前应聘职位匹配，可以过来直接上手干活就可以了，当然薪资也就不会给很多。比如游戏公司会关心你是否有某某类型的游戏开发经验、股票类公司会关心你是否有过证券或者交易系统的开发经验等。我的经验就是这类公司，能去的话可以去，不能去的话就当积累面试经验。业务开发哪里都能找到，真正的重视技术的公司，应该是广大做技术尤其是初中级开发的朋友应该值得关心的事情。\n不靠谱型公司。 我遇到的大致有四类：\n01\n装X忽悠型\n第一类：装X忽悠型\n面试过程冗长繁琐，比如号称每一百份简历中才发一个面试邀请，号称每一百个面试者发一个offer，号称硅谷风格，我面试的有一家公司就是这个样子，先是一轮长长的电话面试，然后是五轮技术面试，前三轮是刷leetcode上原题，然后后几轮面试，面试官从基本的操作系统的中断、GDT、LDT、分表分页机制问到上层高并发海量数据的架构，说的不好听，真是从外太空聊到内子宫，最后问具体职位做什么时，要么遮遮掩掩要么原型毕露；或者讨论薪资时，要么面露难色要么各种画饼，但是实际就给不了多少薪水的。\n02\n佛性公司\n第二类：佛性公司\n面试下来，全程面试官面带微笑，问你的问题你回答的面试官也很赞同，但最后你就没通过，我猜测要么公司不是很缺人，想观望一下是否有合适的人才；要么招聘信息上开的薪资给不到。\n03\n老奶奶裹脚布型公司\n第三类：老奶奶裹脚布型公司\n其特点是面试周期长，往往第一轮面试通知你过了，让你回去等上十天半个月后，给你打电话通知你来第二轮面试，面试要求穿正装，带好各种证件，面试前必须先查验你的身份证、学历证学位证，甚至是四六级考试证等等，麻烦至极，即使你一路过关斩将过了终面，薪资也给不了多少。大家都是要养家糊口的，都是忙着找工作，谁有时间和你耗上十天半个月呢？\n04\n不尊重人类型公司\n第四类：不尊重人类型公司\n我这里说的不尊重人，不是指的是面试过程中对你人身攻击，而是不根据你的工作年限和经验随意安排面试官，举个例子，比如你工作十年，你去面试一个技术总监的职位，对方公司安排一个工作不满两年的部门职员作为面试官，这个面试官如果是走过场可以理解，但是非要和你纠结一个如二进制位移、现代编译器要不要在子类析构函数前加virtual关键字这些技术细节就没必要了。还有一类就是故意问一些刁钻的问题，或者全场都心不在焉、玩手机、漫不经心的面试官，比如问你tcp协议头有多少个字段，每个字段是干啥的。遇到这一类面试官我的经验就是要么婉拒，要么直接怼回去。\n注意细节 下面再说下面试中需要注意的一些细节：\n01\n把目光放长远一点\n第一，如果你的工作年限不长，尤其是渴望在技术方面有一定的造诣，那么你首先考虑的应该是新的单位是否能有利于你技术上的成长，而不是两份同样的工作，薪资上的上下相差的三五千、五六千。如果想转行的同学（比如从客户端转服务器，从C++转JAVA），不要因为薪资突然变低而拒绝这种阵痛，要把目光放长远一点。\n02\n可能最终会因为薪资达不到不被录取","title":"我面试后端开发经理的经历"},{"content":"技术面试与HR谈薪资技巧 作为“生在红旗下，长在春风里”的“四有新人”（现在90后00后还有知道这个词的吗？^_^），张小方同志从毕业至今，与各路HR、HRD斗智斗勇，再加上自己的不懈努力，历尽千辛万苦终于将毕业时的1500每月的薪资提高了二十几倍。本文就和大家唠唠这些年风里来雨里去无数次铩羽而归、兢兢业业、如履薄冰、诚惶诚恐、夜不能寐、枕戈待旦、惴惴不安、临盆一脚，最终守得云开见月明的谈薪经历。当然，本文说的主要是技术面试中谈薪的经历，主要针对的是一些社会人士求职，当然一些通用的原则同样适用于应届生求职。\n面试官的级别 一般技术面试的模式是 n + 1 或者是 1 + n + 1，什么意思呢？其中 n 指的是你见到的不同级别的面试官的个数，1 指的你见到的hr。\n两种模式 模式一：一般技术面试有两种情形，你进入公司以后，会让你填写一些个人资料，如果有笔试题，也会做一些笔试题，接着HR会先找你简单地聊几句了解一下你的情况，然后通知技术面试官过来面试，如果一轮或者多轮技术面试后，面试官觉得你还不错，HR会接着详细地了解一下你的情况，如之前做什么工作的、是否已经离职、是否成家有小孩，当然最最关键的是询问你期望的薪资。这就是所谓的“1 + n + 1”模式，即开始由HR面试，中间是技术面试，最后还是HR面试。\n模式二： 在登记个人信息和笔试（如果有的话）完以后，直接就是技术面试，技术面试结束后如果面试官觉得你还不错，HR会接着进行人事面试。这就是所谓的“n + 1”模式，即开始是技术面试，最后由HR面试。\n当然，可能在你去公司现场面试之前，会有一些电话或者远程视频的面试的形式，这类基本上也属于技术面试的范畴。这里就不再赘述了。\n面试官的级别和面试轮次 一般公司的的级别是按如下方式划分的：普通员工上面是部门经理（或技术主管），部分经理（或技术主管）上面是总监（即所谓的大领导）（规模小的公司或者扁平化的公司上面就是CTO、副总或者CEO了，因此到这一层就没有了），总监（大领导）上面一般是公司的CTO、副总或者老板了。\n如果是应聘初、中级的岗位，第一轮面试官一般是你的职位所在的部门的经理。一般经理觉得没问题，接着就是HR面试了，也就是说就这么两类人来面试你。\n如果你面试的是高级、资深岗位，第一轮面试官是所在部门的经理，只要面试表现不是太差，经理会让总监来继续第二轮面试你。如果总监觉得也没有问题，接着就是HR面试了。\n如果你面试的是经理或开发主管的职位，第一轮面试一般是相关部门与你职级差不多的部门经理来面试你，注意这一轮大多数一般只是简单地聊一聊（走过场），然后由上一级总监（大领导）来进行第二轮面试（这轮面试很关键），如果这一轮面试也OK的话，会由大领导的上一级，如公司CTO或副总甚至CEO进行第三轮面试甚至第四轮面试。如果以上都没问题，接着就是HR或HRD的人事面试了。\n注意，我这里面试的轮次是按职级划分的，而不是按次数划分的。实际上在大多数公司，会由搭配交叉部门的其他同事来面试。举个例子，例如你求职的是高级开发，除了部门经理 A1 和大领导 B 会面试你，部门经理 A1 或者大领导 B 可能会邀请其他部门的某个同事C或者领导A2来面试你，这里的职级按从低到高依次是C \u0026lt; A1 = A2 \u0026lt; B。也就是说，面试官 C 和 A1、A2 这种级别的面试官可能会出现多位。\n人事面试 说完了技术面试官的职级和面试次数，再来说说人事面试，一般人事面试是最后一轮面试。你需要注意的是——HR 一般没有决策权，也就是说 HR 没有权利决定你最终的去留，她们只是转达用人部门的意见。当然，也不排除有少数强势的 HR 或 HRD，大多数的HR都没有一票否决权。所以，如果HR和你详谈时，也说明你前面的面试结果不是太差。这个时候，你要做的就是尽量在公司可接受的范围内达到自己利益最大化就可以了。\n在我看来，大多数HR虽然看起来美丽大方，但是都是“妖精”，尤其是一些阅人无数的资深HR，那简直是“职场白骨精”（调侃一下，没有恶意，请各位HR勿怪）。\n首先，由于她们有自己的绩效考核，即最短时间、最低的成本招到最合适的人才。据我所知，举个例子，比如一个计划最高可以用25K招到的人，现在某个HR用20K就招到了，那节省下来的5K就会算作HR的绩效，所以这也是HR为什么会找你谈工资的目的了，其核心目的其实就是为了压工资。减少人力资源成本是负责招聘的HR的一项重要职责。\n其次，由于大多数HR没有否决权，只是忠实地转达用人部门的意见。所以你问她的一些问题，大多数情况下是得不到任何实质性的答案的，一般都是些场面上的官话。所以，你也不用问诸如“面试成绩如何”、“面试官对你的影响如何”、“什么时候给面试结果”之类的傻傻的问题。\n当然，HR与你谈论很多问题，其实是通过交流中了解你这个人的性格、反应能力、情商、经历和资历等信息，以最大化地为公司招到一个合适的人，排除一些人事隐患。比如，HR一般会问男同胞是否有女朋友、是否结婚、老家是哪里的等等，这些不是说HR要查你的户口（这个从身份证信息上就能看出来），而是看你这个人未来几年是否稳定，一般成家就意味着责任感，而不是要刺探你的婚姻状况。\n当然读者最关心的可能就是如何谈薪资。这里单独来开一节来详细讨论下这个问题。\n谈薪的基本要点与脱坑技巧 谈薪是一个与HR斗智斗勇的过程，在谈薪的过程中有很多坑。一般HR会问你期望的薪资，然后就你的报价（请原谅我用这个词，谈好薪确实就等于把自己卖了 - -！）进行讨价还价，当然不和你讨价还价的HR也有，一般有两种：第一种，你的报价实在太高，已经远远超过公司的预算，HR觉得没有谈下去的必要；第二种，天使。第二种，我反正是从来没遇到过。除了总监及以上职位，一般你求职的JD上都会有一个薪资范围，你报价时可以参考一下这个。其次就是，除非你能力特别优秀，面试效果特别好，否则 IT 行业一般的涨薪最大幅度是你前一份工作的百分之三十，也就是说如果你前一份工作月薪是20K，那么你这份工作你最多可以报价27K。\n一般与HR谈薪的过程中，即要展示自己对求职的职位有很大的兴趣，但又不要暴露自己想尽快找到工作的想法，尤其是在你手头上没有offer 、且已经离职的情况下，这样会让自己很被动，你迫切需要一份工作，而现在又无多余的选择，这样HR就会使劲压制你的薪资。\nHR与你谈论薪资经常有如下套路：\nHR: 您期望的薪资是多少？\r你: 25K。 OK，你已经被HR成功套路。这个时候你的最高价就是25K了，然后HR会顺着这个价往下砍，所以你最终的薪资一般都会低于25K。等你接到offer，你的心里肯定充满了各种“悔恨”：其实当时报价26、27甚至28、29也是可以的。\n正确的回答可以这样，并且还能够反套路一下HR：\nHR: 您期望的薪资是多少？\r你: 就我的面试表现，贵公司最高可以给多少薪水？ 哈哈，如果经验不够老道的HR可能就真会说出一个报价（如25K）来，然后，你就可以很开心地顺着这个价慢慢地往上谈了。所以这种情况下，你最终的薪资肯定是大于25K的。当然，经验老道的HR会给你一句很官方的套话：\nHR: 您期望的薪资是多少？\r你: 就我的面试表现，贵公司最高可以给多少薪水？\rHR: 这个暂且没法确定，要结合您几轮面试结果和用人部门的意见来综合评定。 如果HR这么回答你，我的建议是这样的：\n虽然薪资很重要，但是我个人觉得这不是最重要的。我有以下建议：\n如果你觉得你技术面试效果很好，可以报一个高一点的薪资，这样如果HR想要你，会找你商量的。 如果你觉得技术面试效果一般，但是你比较想进这家公司，可以报一个折中的薪资。 如果你觉得面试效果很好，但是你不想进这家公司，你可以适当“漫天要价”一下。 如果你觉得面试效果不好，但是你想进这家公司，你可以开一个稍微低一点的工资。 需要注意的是，面试求职是一个双向选择的过程。面试应该做到不卑不亢，千万不要因为面试结果不好，就低声下气地乞求工作，每个人的工作经历和经验都是不一样的，技术面试不好，知道自己的短板针对性地补缺补差就行，而不是在人事关系上动歪脑筋。当然也不要盲目自信，把自己的无知当理所当然，谦虚一点。笔者曾经面试Intel时，因为单词“cache”的读音和面试官争论了很久，面试官读“cash”，我坚持认为读“cake”，这里就闹了一个笑话。\n除了和HR谈薪有陷阱，和技术面试官谈薪也一般存在一些陷阱。大多数公司都要求总监级别以下的面试官不得询问面试者期望薪资，但是也不排除一些面试官的个人好奇心，”无意中“向面试者询问该问题。除了级别高的领导，一般面试官是无权询问薪资的，此时面试者就要留心了。如果被问到，可以委婉地回答一下，如可以说：现在还不确定，会按招聘信息的薪资范围和结合自己的面试结果来提出一个期望薪资。如果实在绕不过去这个问题，可以把薪资说的低一点（口头上只是说说而已），实际薪资还是由高层领导决定并最终和HR谈的。原因是因为，在信息不对称的情况下，如果你报的薪资过高，超过当前面试官的薪资，很可能引起当前面试官的不愉快，造成对自己非技术上的差评，造成失去入职该公司的机会。\n谈薪资还有一个坑，你一定要搞清楚公司的薪资构成，就是尽量把月薪或者基础薪资谈高一点。说说我之前的两段经历：\n经历一：我之前有份工作，HR和我谈的时候，说是月薪14K。但是我实际进去以后，发现14K分为基础工资和绩效工资，这其中6K是基本工资，剩下的8K是绩效工资，而每个月会有一个绩效系数，系数范围是从0.8～1.5，也就是说当你某个月绩效系数是1时，你拿到完整的8K；如果你系数是0.8时，你只能拿到6400，也就是辛辛苦苦干了一个月实际拿到手的只有6000 + 6400 = 12400，平白无故地少了1600。而公司对外宣称你的月薪是14K，还有就是基本上绩效系数在1以上的都没有。\n经历二：我后来还有一份工作，我当时要月薪30K * 13，公司坚持要给我26K * 15（年薪都是39W），也就是说前者是一个月的年终奖，后者是3个月的年终奖。等我入职以后也发现是个大坑，首先，所谓的年终奖并不会写到劳动合同中去，所以公司发不发、发多少就要看公司的良心了。大多数公司，至少会发一个月的年终奖。但是多于一个月就很难说了，一般就按所谓的绩效系数，这里15薪的系数就是从1到3，但是实际上大多数人年底系数也就是1。其次，很多公司年终奖还有其他的一些规定，比如年终奖的比例按你当年在公司工作的实际天数来算，也就是说，假设你是6月1日入职的，正好是半年，你的年终奖只能拿一半，这就是所谓的年终奖 = 预先设定的金额 * n / 365，n 是你当年实际工作的自然日。如此一比，相信读者应该能看出30K * 13 与 26K * 15的巨大差别了吧。\n所以，不要被HR以少交税、年薪、期权等各种\u0026quot;诡计\u0026quot;所迷惑，在同等水平下，尽量把写到合同里面薪资谈高一点。多交税也不一定是坏事，以上海这边为例，税交多一点，对上海市的社会贡献就高一点，很多政策就会对你倾斜一点。\n职业发展与薪资 对于工作年限不长的读者，我个人建议是，如果两份工作月薪相差八千以内，我会优先选择更利于个人发展到人工作机会，而不是工资高一点的。对于努力的人来说，早些年每个月多几千或者少几千块钱，对以后的生活基本上没多大影响的，尤其是现在普遍存不住钱的职场新人。你更在乎的应该是你的平台、职业发展机会。这点尤其适用于求职的应届生。\n因作者个人经历和经验也有限，文中言论属一家之言，难免有失偏颇，请各位读者斟酌，欢迎温和地提出建议和批评。\n原创不易，写了这么多，打个小广告。\n如果读者在技术学习或者职业发展上有任何困惑，可以加入我的知识星球【小方说服务器开发】寻求帮助，在这里你不仅可以获得认真的问题解答，还能获得很多内部学习资料和不定期的内部免费技术分享。在这里，你将看到别人看不到的内部经验！\n有兴趣的读者，长按下图，微信扫码即可加入：\n往期推荐\n求如何成为一名合格的C/C++开发者？ C++高性能服务器网络框架设计细节 写给那些傻傻想做服务器开发的朋友 我的github开源软件列表 后台开发面试会问哪些问题？ 后台开发应该读的书 ","permalink":"https://haokiu.com/blog/d949dd8f005d45c7b6c71ea9a87a0712/","summary":"技术面试与HR谈薪资技巧 作为“生在红旗下，长在春风里”的“四有新人”（现在90后00后还有知道这个词的吗？^_^），张小方同志从毕业至今，与各路HR、HRD斗智斗勇，再加上自己的不懈努力，历尽千辛万苦终于将毕业时的1500每月的薪资提高了二十几倍。本文就和大家唠唠这些年风里来雨里去无数次铩羽而归、兢兢业业、如履薄冰、诚惶诚恐、夜不能寐、枕戈待旦、惴惴不安、临盆一脚，最终守得云开见月明的谈薪经历。当然，本文说的主要是技术面试中谈薪的经历，主要针对的是一些社会人士求职，当然一些通用的原则同样适用于应届生求职。\n面试官的级别 一般技术面试的模式是 n + 1 或者是 1 + n + 1，什么意思呢？其中 n 指的是你见到的不同级别的面试官的个数，1 指的你见到的hr。\n两种模式 模式一：一般技术面试有两种情形，你进入公司以后，会让你填写一些个人资料，如果有笔试题，也会做一些笔试题，接着HR会先找你简单地聊几句了解一下你的情况，然后通知技术面试官过来面试，如果一轮或者多轮技术面试后，面试官觉得你还不错，HR会接着详细地了解一下你的情况，如之前做什么工作的、是否已经离职、是否成家有小孩，当然最最关键的是询问你期望的薪资。这就是所谓的“1 + n + 1”模式，即开始由HR面试，中间是技术面试，最后还是HR面试。\n模式二： 在登记个人信息和笔试（如果有的话）完以后，直接就是技术面试，技术面试结束后如果面试官觉得你还不错，HR会接着进行人事面试。这就是所谓的“n + 1”模式，即开始是技术面试，最后由HR面试。\n当然，可能在你去公司现场面试之前，会有一些电话或者远程视频的面试的形式，这类基本上也属于技术面试的范畴。这里就不再赘述了。\n面试官的级别和面试轮次 一般公司的的级别是按如下方式划分的：普通员工上面是部门经理（或技术主管），部分经理（或技术主管）上面是总监（即所谓的大领导）（规模小的公司或者扁平化的公司上面就是CTO、副总或者CEO了，因此到这一层就没有了），总监（大领导）上面一般是公司的CTO、副总或者老板了。\n如果是应聘初、中级的岗位，第一轮面试官一般是你的职位所在的部门的经理。一般经理觉得没问题，接着就是HR面试了，也就是说就这么两类人来面试你。\n如果你面试的是高级、资深岗位，第一轮面试官是所在部门的经理，只要面试表现不是太差，经理会让总监来继续第二轮面试你。如果总监觉得也没有问题，接着就是HR面试了。\n如果你面试的是经理或开发主管的职位，第一轮面试一般是相关部门与你职级差不多的部门经理来面试你，注意这一轮大多数一般只是简单地聊一聊（走过场），然后由上一级总监（大领导）来进行第二轮面试（这轮面试很关键），如果这一轮面试也OK的话，会由大领导的上一级，如公司CTO或副总甚至CEO进行第三轮面试甚至第四轮面试。如果以上都没问题，接着就是HR或HRD的人事面试了。\n注意，我这里面试的轮次是按职级划分的，而不是按次数划分的。实际上在大多数公司，会由搭配交叉部门的其他同事来面试。举个例子，例如你求职的是高级开发，除了部门经理 A1 和大领导 B 会面试你，部门经理 A1 或者大领导 B 可能会邀请其他部门的某个同事C或者领导A2来面试你，这里的职级按从低到高依次是C \u0026lt; A1 = A2 \u0026lt; B。也就是说，面试官 C 和 A1、A2 这种级别的面试官可能会出现多位。\n人事面试 说完了技术面试官的职级和面试次数，再来说说人事面试，一般人事面试是最后一轮面试。你需要注意的是——HR 一般没有决策权，也就是说 HR 没有权利决定你最终的去留，她们只是转达用人部门的意见。当然，也不排除有少数强势的 HR 或 HRD，大多数的HR都没有一票否决权。所以，如果HR和你详谈时，也说明你前面的面试结果不是太差。这个时候，你要做的就是尽量在公司可接受的范围内达到自己利益最大化就可以了。\n在我看来，大多数HR虽然看起来美丽大方，但是都是“妖精”，尤其是一些阅人无数的资深HR，那简直是“职场白骨精”（调侃一下，没有恶意，请各位HR勿怪）。\n首先，由于她们有自己的绩效考核，即最短时间、最低的成本招到最合适的人才。据我所知，举个例子，比如一个计划最高可以用25K招到的人，现在某个HR用20K就招到了，那节省下来的5K就会算作HR的绩效，所以这也是HR为什么会找你谈工资的目的了，其核心目的其实就是为了压工资。减少人力资源成本是负责招聘的HR的一项重要职责。\n其次，由于大多数HR没有否决权，只是忠实地转达用人部门的意见。所以你问她的一些问题，大多数情况下是得不到任何实质性的答案的，一般都是些场面上的官话。所以，你也不用问诸如“面试成绩如何”、“面试官对你的影响如何”、“什么时候给面试结果”之类的傻傻的问题。\n当然，HR与你谈论很多问题，其实是通过交流中了解你这个人的性格、反应能力、情商、经历和资历等信息，以最大化地为公司招到一个合适的人，排除一些人事隐患。比如，HR一般会问男同胞是否有女朋友、是否结婚、老家是哪里的等等，这些不是说HR要查你的户口（这个从身份证信息上就能看出来），而是看你这个人未来几年是否稳定，一般成家就意味着责任感，而不是要刺探你的婚姻状况。\n当然读者最关心的可能就是如何谈薪资。这里单独来开一节来详细讨论下这个问题。\n谈薪的基本要点与脱坑技巧 谈薪是一个与HR斗智斗勇的过程，在谈薪的过程中有很多坑。一般HR会问你期望的薪资，然后就你的报价（请原谅我用这个词，谈好薪确实就等于把自己卖了 - -！）进行讨价还价，当然不和你讨价还价的HR也有，一般有两种：第一种，你的报价实在太高，已经远远超过公司的预算，HR觉得没有谈下去的必要；第二种，天使。第二种，我反正是从来没遇到过。除了总监及以上职位，一般你求职的JD上都会有一个薪资范围，你报价时可以参考一下这个。其次就是，除非你能力特别优秀，面试效果特别好，否则 IT 行业一般的涨薪最大幅度是你前一份工作的百分之三十，也就是说如果你前一份工作月薪是20K，那么你这份工作你最多可以报价27K。\n一般与HR谈薪的过程中，即要展示自己对求职的职位有很大的兴趣，但又不要暴露自己想尽快找到工作的想法，尤其是在你手头上没有offer 、且已经离职的情况下，这样会让自己很被动，你迫切需要一份工作，而现在又无多余的选择，这样HR就会使劲压制你的薪资。\nHR与你谈论薪资经常有如下套路：\nHR: 您期望的薪资是多少？\r你: 25K。 OK，你已经被HR成功套路。这个时候你的最高价就是25K了，然后HR会顺着这个价往下砍，所以你最终的薪资一般都会低于25K。等你接到offer，你的心里肯定充满了各种“悔恨”：其实当时报价26、27甚至28、29也是可以的。\n正确的回答可以这样，并且还能够反套路一下HR：\nHR: 您期望的薪资是多少？\r你: 就我的面试表现，贵公司最高可以给多少薪水？ 哈哈，如果经验不够老道的HR可能就真会说出一个报价（如25K）来，然后，你就可以很开心地顺着这个价慢慢地往上谈了。所以这种情况下，你最终的薪资肯定是大于25K的。当然，经验老道的HR会给你一句很官方的套话：\nHR: 您期望的薪资是多少？\r你: 就我的面试表现，贵公司最高可以给多少薪水？\rHR: 这个暂且没法确定，要结合您几轮面试结果和用人部门的意见来综合评定。 如果HR这么回答你，我的建议是这样的：\n虽然薪资很重要，但是我个人觉得这不是最重要的。我有以下建议：\n如果你觉得你技术面试效果很好，可以报一个高一点的薪资，这样如果HR想要你，会找你商量的。 如果你觉得技术面试效果一般，但是你比较想进这家公司，可以报一个折中的薪资。 如果你觉得面试效果很好，但是你不想进这家公司，你可以适当“漫天要价”一下。 如果你觉得面试效果不好，但是你想进这家公司，你可以开一个稍微低一点的工资。 需要注意的是，面试求职是一个双向选择的过程。面试应该做到不卑不亢，千万不要因为面试结果不好，就低声下气地乞求工作，每个人的工作经历和经验都是不一样的，技术面试不好，知道自己的短板针对性地补缺补差就行，而不是在人事关系上动歪脑筋。当然也不要盲目自信，把自己的无知当理所当然，谦虚一点。笔者曾经面试Intel时，因为单词“cache”的读音和面试官争论了很久，面试官读“cash”，我坚持认为读“cake”，这里就闹了一个笑话。\n除了和HR谈薪有陷阱，和技术面试官谈薪也一般存在一些陷阱。大多数公司都要求总监级别以下的面试官不得询问面试者期望薪资，但是也不排除一些面试官的个人好奇心，”无意中“向面试者询问该问题。除了级别高的领导，一般面试官是无权询问薪资的，此时面试者就要留心了。如果被问到，可以委婉地回答一下，如可以说：现在还不确定，会按招聘信息的薪资范围和结合自己的面试结果来提出一个期望薪资。如果实在绕不过去这个问题，可以把薪资说的低一点（口头上只是说说而已），实际薪资还是由高层领导决定并最终和HR谈的。原因是因为，在信息不对称的情况下，如果你报的薪资过高，超过当前面试官的薪资，很可能引起当前面试官的不愉快，造成对自己非技术上的差评，造成失去入职该公司的机会。\n谈薪资还有一个坑，你一定要搞清楚公司的薪资构成，就是尽量把月薪或者基础薪资谈高一点。说说我之前的两段经历：\n经历一：我之前有份工作，HR和我谈的时候，说是月薪14K。但是我实际进去以后，发现14K分为基础工资和绩效工资，这其中6K是基本工资，剩下的8K是绩效工资，而每个月会有一个绩效系数，系数范围是从0.8～1.5，也就是说当你某个月绩效系数是1时，你拿到完整的8K；如果你系数是0.8时，你只能拿到6400，也就是辛辛苦苦干了一个月实际拿到手的只有6000 + 6400 = 12400，平白无故地少了1600。而公司对外宣称你的月薪是14K，还有就是基本上绩效系数在1以上的都没有。","title":"技术面试与HR谈薪资技巧"},{"content":"拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？ 网友提问：\n拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？\n面试的时候双方都感觉还可以，一面后hr开始压价，比预期低了3K，我拒绝。\n然后邀请我去复试，跟经理交流后，觉得我可以，然而hr又压价，比预期低了1K，我拒绝，因为我对他们提出的期望薪资是我的最低底线。\n然而过去不到1小时，hr说可以给到我期望薪资，并发了offer，但是试用期6个月打8折这个条件我不是很满意，而且offer居然没说明具体薪资组成部分，感觉他们很没诚意，然后思前想后决定发邮件拒绝了。\n然而过去三天后，接到他们副总的电话，询问我拒绝原因，说自己公司管理制度如何如何人性化，还说条件可以再谈，非常诚恳也非常谦逊，感觉不好意思拒绝。然后我说自己再考虑考虑。随后hr再次电话来谈条件，说试用期不打折，并把薪资组成部分说的很详细，邀请我加入。\n我犹豫了，现在有点纠结，手里还有另一家offer，待遇差不多，但是这家录用我很爽快，感觉我合适就直接发offer了，并说清楚了具体待遇。但是考虑这家公司目前规模和发展趋势不是符合自己预期的，所以也在犹豫中。\n反正个人感觉第一家公司想要我但是却各种理由为难我，被我拒绝后又放低标准极力邀请我，这是不是一个坑啊，这么着急招人估计这个岗位肯定是个大坑啊。\n现在很纠结，跳槽需要慎重考虑啊，真怕自己跳入一个更大的坑爬不出来。\n小方老师建议：\n先说结论：现在拿到offer的话，如果比较纠结就都不去，哪怕一家公司都去不了。再找就是了。\n说两段我的经验吧，第一段，几年前，在A公司和B公司之间两家公司的offer纠结，A公司离我住的地方太远不想去，B公司感觉氛围不太喜欢，最后在各种纠结中去了B公司，没干三个月受不了离职了。\n某年年底找工作时，有个猎头，给我推荐了一个公司，我开始不太想去，因为这家公司我并不了解，所以我和猎头说，除非月薪可以给到30k，否则我不想去，后来猎头反复和对方公司沟通，最终满足了我的要求，但是，猎头说由于对方公司有一定的涨薪限制，所以不能给到月薪30k，但是由于我要求的是30k*13薪，对方公司换了种方式，给26k*15薪，这样一年下来也是39万。我开始是很不愿意这种所谓的变通方法，于是猎头就和他的领导那段时间反复做我的思想工作。我当时也非常纠结要不要去，因为相对于我当前的薪资确实翻了一番，但是我隐约觉得当初面试我的面试官(也就是我进去后我的直系领导)是个\u0026quot;不好相处\u0026quot;的人。后来猎头又反复和我说，面试我的面试官是和乐于传道受业解惑的和蔼可亲的技术大神最终在各种纠结中我还是去入职了。但是没过多久，我就干的很不开心。那个领导的代码风格稀烂，例如写C++代码，没有任何注释文档，甚至所有的实现文件都写在*.h文件中;其次，与人交流非常没耐心，下面的同事问他问题说不到三句可能就不耐烦，所以隔壁组的同事也都不太喜欢他，但是由于这个项目一直是他一个人做也没商业化，所以公司也没多管他。等到他带团队，与其他同事打交道时就暴露各种问题了。更让人受不了的是，他经常在项目要发版本时修改代码，也不通知其他同事，直到我们发现不对劲，排查很久发现问题，他才说。最让我们受不了的是，有次周六周日加了两天班，周六晚上到夜里十二点，周日到凌晨三点，他还冲团队成员发火。所以那天夜里，我四点钟半到家，直接给CTO写了封投诉他的信。\n后来的情况不用说了，我当初面试的时顾虑都一一应验了，和我一起来的几个同事，年后都陆续离职了。\n我想说的是，不管是薪资还是公司面试的时候面试官和人事的种种举动，如果你有顾虑或者觉得不适合你，千万不要为了钱本身就去了。\n小方老师联系方式：微信 easy_coder。\n","permalink":"https://haokiu.com/blog/40c71c6aa54540abb1c141d82ca0cd49/","summary":"拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？ 网友提问：\n拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？\n面试的时候双方都感觉还可以，一面后hr开始压价，比预期低了3K，我拒绝。\n然后邀请我去复试，跟经理交流后，觉得我可以，然而hr又压价，比预期低了1K，我拒绝，因为我对他们提出的期望薪资是我的最低底线。\n然而过去不到1小时，hr说可以给到我期望薪资，并发了offer，但是试用期6个月打8折这个条件我不是很满意，而且offer居然没说明具体薪资组成部分，感觉他们很没诚意，然后思前想后决定发邮件拒绝了。\n然而过去三天后，接到他们副总的电话，询问我拒绝原因，说自己公司管理制度如何如何人性化，还说条件可以再谈，非常诚恳也非常谦逊，感觉不好意思拒绝。然后我说自己再考虑考虑。随后hr再次电话来谈条件，说试用期不打折，并把薪资组成部分说的很详细，邀请我加入。\n我犹豫了，现在有点纠结，手里还有另一家offer，待遇差不多，但是这家录用我很爽快，感觉我合适就直接发offer了，并说清楚了具体待遇。但是考虑这家公司目前规模和发展趋势不是符合自己预期的，所以也在犹豫中。\n反正个人感觉第一家公司想要我但是却各种理由为难我，被我拒绝后又放低标准极力邀请我，这是不是一个坑啊，这么着急招人估计这个岗位肯定是个大坑啊。\n现在很纠结，跳槽需要慎重考虑啊，真怕自己跳入一个更大的坑爬不出来。\n小方老师建议：\n先说结论：现在拿到offer的话，如果比较纠结就都不去，哪怕一家公司都去不了。再找就是了。\n说两段我的经验吧，第一段，几年前，在A公司和B公司之间两家公司的offer纠结，A公司离我住的地方太远不想去，B公司感觉氛围不太喜欢，最后在各种纠结中去了B公司，没干三个月受不了离职了。\n某年年底找工作时，有个猎头，给我推荐了一个公司，我开始不太想去，因为这家公司我并不了解，所以我和猎头说，除非月薪可以给到30k，否则我不想去，后来猎头反复和对方公司沟通，最终满足了我的要求，但是，猎头说由于对方公司有一定的涨薪限制，所以不能给到月薪30k，但是由于我要求的是30k*13薪，对方公司换了种方式，给26k*15薪，这样一年下来也是39万。我开始是很不愿意这种所谓的变通方法，于是猎头就和他的领导那段时间反复做我的思想工作。我当时也非常纠结要不要去，因为相对于我当前的薪资确实翻了一番，但是我隐约觉得当初面试我的面试官(也就是我进去后我的直系领导)是个\u0026quot;不好相处\u0026quot;的人。后来猎头又反复和我说，面试我的面试官是和乐于传道受业解惑的和蔼可亲的技术大神最终在各种纠结中我还是去入职了。但是没过多久，我就干的很不开心。那个领导的代码风格稀烂，例如写C++代码，没有任何注释文档，甚至所有的实现文件都写在*.h文件中;其次，与人交流非常没耐心，下面的同事问他问题说不到三句可能就不耐烦，所以隔壁组的同事也都不太喜欢他，但是由于这个项目一直是他一个人做也没商业化，所以公司也没多管他。等到他带团队，与其他同事打交道时就暴露各种问题了。更让人受不了的是，他经常在项目要发版本时修改代码，也不通知其他同事，直到我们发现不对劲，排查很久发现问题，他才说。最让我们受不了的是，有次周六周日加了两天班，周六晚上到夜里十二点，周日到凌晨三点，他还冲团队成员发火。所以那天夜里，我四点钟半到家，直接给CTO写了封投诉他的信。\n后来的情况不用说了，我当初面试的时顾虑都一一应验了，和我一起来的几个同事，年后都陆续离职了。\n我想说的是，不管是薪资还是公司面试的时候面试官和人事的种种举动，如果你有顾虑或者觉得不适合你，千万不要为了钱本身就去了。\n小方老师联系方式：微信 easy_coder。","title":"拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？"},{"content":"整型变量赋值是原子操作吗？ 整型变量赋值操作不是原子操作 那么为什么整型变量的操作不是原子性的呢？常见的整型变量操作有如下几种情况：\n给整型变量赋值一个确定的值，如\nint a = 1; 这条指令操作一般是原子的，因为对应着一条计算机指令，cpu将立即数1搬运到变量a的内存地址中即可，汇编指令如下：\nmov dword ptr [a], 2 然后这确是最不常见的情形，由于现代编译器一般有优化策略，如果变量a的值在编译期间就可以计算出来（例如这里的例子中a的值就是1），那么a这个变量本身在正式版本的软件中（release版）就很有可能被编译器优化掉，使用a的地方，直接使用常量1来代替。所以实际的执行指令中，这样的指令存在的可能性比较低。\n变量自身增加或者减去一个值，如\na ++; 从C/C++语法的级别来看，这是一条语句，是原子的；但是从实际执行的二进制指令来看，也不是原子的，其一般对应三条指令，首先将变量a对应的内存值搬运到某个寄存器（如eax）中，然后将该寄存器中的值自增1，再将该寄存器中的值搬运回a的内存中：\nmov eax, dword ptr [a] inc eax mov dword ptr [a], eax 现在假设a的值是0，有两个线程，每个线程对变量a的值递增1，我们预想的结果应该是2，可实际运行的结果可能是1！是不是很奇怪？分析如下：\nint a = 0; //线程1 void thread_func1() { a ++; } //线程2 void thread_func2() { a ++; } 我们预想的结果是线程1和线程2的三条指令各自执行，最终a的值为2，但是由于操作系统线程调度的不确定性，线程1执行完指令①和②后，eax寄存器中的值为1，此时操作系统切换到线程2执行，执行指令③④⑤，此时eax的值变为1；接着操作系统切回线程1继续执行，执行指令⑦，得到a的最终结果1。\n把一个变量的值赋值给另外一个变量，或者把一个表达式的值赋值给另外一个变量，如\nint a = b; 从C/C++语法的级别来看，这是也是一条语句，是原子的；但是从实际执行的二进制指令来看，由于现代计算机CPU架构体系的限制，数据不可以直接从内存搬运到另外一块内存，必须借助寄存器中断，这条语句一般对应两条计算机指令，即将变量b的值搬运到某个寄存器（如eax）中，再从该寄存器搬运到变量a的内存地址：\nmov eax, dword ptr [b] mov dword ptr [a], eax 既然是两条指令，那么多个线程在执行这两条指令时，某个线程可能会在第一条指令执行完毕后被剥夺CPU时间片，切换到另外一个线程而产生不确定的情况。这和上一种情况类似，就不再详细分析了。\n说点题外话，网上很多人强调某些特殊的整型数值类型（如bool类型）的操作是原子的，这是由于，某些CPU生产商开始有意识地从硬件平台保证这一类操作的原子性，但这并不是每一种类型的CPU架构都支持，在这一事实成为标准之前，我们在多线程操作整型时还是老老实实使用下文介绍的原子操作或线程同步技术来对这些数据类型进行保护。\n","permalink":"https://haokiu.com/blog/c5ae7c2ab16046b2b12deffde01da947/","summary":"整型变量赋值是原子操作吗？ 整型变量赋值操作不是原子操作 那么为什么整型变量的操作不是原子性的呢？常见的整型变量操作有如下几种情况：\n给整型变量赋值一个确定的值，如\nint a = 1; 这条指令操作一般是原子的，因为对应着一条计算机指令，cpu将立即数1搬运到变量a的内存地址中即可，汇编指令如下：\nmov dword ptr [a], 2 然后这确是最不常见的情形，由于现代编译器一般有优化策略，如果变量a的值在编译期间就可以计算出来（例如这里的例子中a的值就是1），那么a这个变量本身在正式版本的软件中（release版）就很有可能被编译器优化掉，使用a的地方，直接使用常量1来代替。所以实际的执行指令中，这样的指令存在的可能性比较低。\n变量自身增加或者减去一个值，如\na ++; 从C/C++语法的级别来看，这是一条语句，是原子的；但是从实际执行的二进制指令来看，也不是原子的，其一般对应三条指令，首先将变量a对应的内存值搬运到某个寄存器（如eax）中，然后将该寄存器中的值自增1，再将该寄存器中的值搬运回a的内存中：\nmov eax, dword ptr [a] inc eax mov dword ptr [a], eax 现在假设a的值是0，有两个线程，每个线程对变量a的值递增1，我们预想的结果应该是2，可实际运行的结果可能是1！是不是很奇怪？分析如下：\nint a = 0; //线程1 void thread_func1() { a ++; } //线程2 void thread_func2() { a ++; } 我们预想的结果是线程1和线程2的三条指令各自执行，最终a的值为2，但是由于操作系统线程调度的不确定性，线程1执行完指令①和②后，eax寄存器中的值为1，此时操作系统切换到线程2执行，执行指令③④⑤，此时eax的值变为1；接着操作系统切回线程1继续执行，执行指令⑦，得到a的最终结果1。\n把一个变量的值赋值给另外一个变量，或者把一个表达式的值赋值给另外一个变量，如\nint a = b; 从C/C++语法的级别来看，这是也是一条语句，是原子的；但是从实际执行的二进制指令来看，由于现代计算机CPU架构体系的限制，数据不可以直接从内存搬运到另外一块内存，必须借助寄存器中断，这条语句一般对应两条计算机指令，即将变量b的值搬运到某个寄存器（如eax）中，再从该寄存器搬运到变量a的内存地址：\nmov eax, dword ptr [b] mov dword ptr [a], eax 既然是两条指令，那么多个线程在执行这两条指令时，某个线程可能会在第一条指令执行完毕后被剥夺CPU时间片，切换到另外一个线程而产生不确定的情况。这和上一种情况类似，就不再详细分析了。\n说点题外话，网上很多人强调某些特殊的整型数值类型（如bool类型）的操作是原子的，这是由于，某些CPU生产商开始有意识地从硬件平台保证这一类操作的原子性，但这并不是每一种类型的CPU架构都支持，在这一事实成为标准之前，我们在多线程操作整型时还是老老实实使用下文介绍的原子操作或线程同步技术来对这些数据类型进行保护。","title":"整型变量赋值是原子操作吗？"},{"content":"服务器开发中网络数据分析与故障排查经验漫谈 ​\n一、 操作系统提供的网络接口\n为了能更好的排查网络通信问题，我们需要熟悉操作系统提供的以下网络接口函数，列表如下：\n接口函数名称 接口函数描述 接口函数签名 socket 创建套接字 int socket(int domain, int type, int protocol); connect 连接一个服务器地址 int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); send 发送数据 ssize_t send(int sockfd, const void *buf, size_t len, int flags); recv 收取数据 ssize_t recv(int sockfd, void *buf, size_t len, int flags); accept 接收连接 int accept4(int sockfd, struct sockaddr *addr, socklen_t *addrlen, int flags); shutdown 关闭收发链路 int shutdown(int sockfd, int how); close 关闭套接字 int close(int fd); setsockopt 设置套接字选项 int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); 注意：这里以bekeley提供的标准为例，不包括特定操作系统上特有的接口函数（如Windows平台的WSASend，linux的accept4），也不包括实际与网络数据来往不相关的函数（如select、linux的epoll），这里只讨论与tcp相关的接口函数，像与udp相关的函数sendto/recvfrom等函数与此类似。\n下面讨论一下以上函数的一些使用注意事项：\n1 以上函数如果调用出错后，返回值均为-1；但是返回值是-1，不一定代表出错，这还得根据对应的套接字模式（阻塞与非阻塞模式）。\n2 默认使用的socket函数创建的套接字是阻塞模式的，可以调用相关接口函数将其设置为非阻塞模式（Windows平台可以使用ioctlsocket函数，linux平台可以使用fcntl函数，具体设置方法可以参考这里。）。阻塞模式和非阻塞模式的套接字，对服务器的连接服务器和网络数据的收发行为影响很大。详情如下：\n阻塞模式下，connect函数如果不能立刻连上服务器，会导致执行流阻塞在那里一会儿，直到connect连接成功或失败或网络超时；而非阻塞模式下，无论是否连接成功connect将立即返回，此时如果未连接成功，返回值将是-1，错误码是EINPROGRESS，表示连接操作仍然在进行中。Linux平台后续可以通过使用select/poll等函数检测该socket是否可写来判断连接是否成功。\n阻塞套接字模式下，send函数如果由于对端tcp窗口太小，不足以将全部数据发送出去，将阻塞执行流，直到出错或超时或者全部发送出去为止；同理recv函数如果当前协议栈系统缓冲区中无数据可读，也会阻塞执行流，直到出错或者超时或者读取到数据。send和recv函数的超时时间可以参考下文关于常用socket选项的介绍。\n非阻塞套接字模式下，如果由于对端tcp窗口太小，不足以将数据发出去，它将立刻返回，不会阻塞执行流，此时返回值为-1，错误码是EAGAIN或EWOULDBLOCK，表示当前数据发不出去，希望你下次再试。但是返回值如果是-1，也可能是真正的出错了，也可能得到错误码EINTR，表示被linux信号中断了，这点需要注意一下。recv函数与send函数情形一样。\n3 send函数虽然名称叫“send”，但是其并不是将数据发送到网络上去，只是将数据从应用层缓冲区中拷贝到协议栈内核缓冲区中，具体什么时候发送到网络上去，与协议栈本身行为有关系（socket选项nagle算法与这个有关系，下文介绍常见套接字选项时会介绍），这点需要特别注意，所以即使send函数返回一个大于0的值n，也不能表明已经有n个字节发送到网络上去了。同样的道理，recv函数也不是从网络上收取数据，只是从协议栈内核缓冲区拷贝数据至应用层缓冲区，并不是真正地从网络上收数据，所以，调用recv时，操作系统的协议栈已经将数据从网络上收到自己的内核缓冲区中了，recv仅仅是一次数据拷贝操作而已。\n4 由于套接字实现是收发全双工的，收和发通道相互独立，不会相互影响，shutdown函数是用来选择关闭socket收发通道中某一路（当然，也可以两路都关闭），其how参数取值一般有三个：SHUT_RD/SHUT_WR/SHUT_RDWR，SHUT_RD表示关闭收消息链路，即该套接字不能再收取数据，同理SHUT_WR表示关闭套接字发消息链路，但是这里有个问题，有时候我们需要等待缓冲区中数据发送完后再关闭连接怎么办？这里就要用到套接字选项LINGER，关于这个选项请参考下文常见的套接字选项介绍。最后，SHUT_RDWR同时关闭收消息链路和发消息链路。通过上面的分析，我们得出结论，shutdown函数并不会要求操作系统底层回收套接字等资源，真正会回收资源是close函数，这个函数会要求操作系统回收相关套接字资源，并释放对ip地址与端口号二元组的占用，但是由于tcp四次挥手最后一个阶段有个TIME_WAIT状态（关于这个状态下文介绍tcp三次握手和四次回收时会详细介绍），导致与该socket相关的端口号资源不会被立即释放，有时候为了达到释放端口用来复用，我们会设置套接字选项SOL_REUSEPORT（关于这个选项，下文会介绍）。综合起来，我们关闭一个套接字，一般会先调用shutdown函数再调用close函数，这就是所谓的优雅关闭：\n5 常见的套接字选项\n严格意义上说套接字选项是有不同层级的（level），如socket级别、TCP级别、IP级别，这里我们不区分具体的级别。\nSO_SNDTIMEO与SO_RCVTIMEO 这两个选项用于设置阻塞模式下套接字，SO_SNDTIMEO用于在send数据由于对端tcp窗口太小，发不出去而最大的阻塞时长；SO_RCVTIMEO用于recv函数因接受缓冲区无数据而阻塞的最大阻塞时长。如果你需要获取它们的默认值，请使用getsockopt函数。\nTCP_NODELAY 操作系统底层协议栈默认有这样一个机制，为了减少网络通信次数，会将send等函数提交给tcp协议栈的多个小的数据包合并成一个大的数据包，最后再一次性发出去，也就是说，如果你调用send函数往内核协议栈缓冲区拷贝了一个数据，这个数据也许不会马上发到网络上去，而是要等到协议栈缓冲区积累到一定量的数据后才会一次性发出去，我们把这种机制叫做nagle算法。默认打开了这个机制，有时候我们希望关闭这种机制，让send的数据能够立刻发出去，我们可以选择关闭这个算法，这就可以通过设置套接字选项TCP_NODELAY，即关闭nagle算法。\nSO_LINGER linger这个单词本身的意思，是“暂停、逗留”。这个选项的用处是用于解决，当需要关闭套接字时，协议栈发送缓冲区中尚有未发送出去的数据，等待这些数据发完的最长等待时间。\nSO_REUSEADDR/SO_REUSEPORT 一个端口，尤其是作为服务器端端口在四次挥手的最后一步，有一个为TIME_WAIT的状态，这个状态一般持续2MSL（MSL，maximum segment life， 最大生存周期，RFC上建议是2分钟）。这个状态存在原因如下：1. 保证发出去的ack能被送达（超时会重发ack）2. 让迟来的报文有足够的时间被丢弃，反过来说，如果不存在这个状态，那么可以立刻复用这个地址和端口号，那么可能会收到老的连接迟来的数据，这显然是不好的。为了立即回收复用端口号，我们可以通过开启套接字SO_REUSEADDR/SO_REUSEPORT。\nSO_KEEPALIVE 默认情况下，当一个连接长时间没有数据来往，会被系统防火墙之类的服务关闭。为了避免这种现象，尤其是一些需要长连接的应用场景下，我们需要使用心跳包机制，即定时从两端定时发一点数据，这种行为叫做“保活”。而tcp协议栈本身也提供了这种机制，那就是设置套接字SO_KEEPALIVE选项，开启这个选项后，tcp协议栈会定时发送心跳包探针，但是这个默认时间比较长（2个小时），我们可以继续通过相关选项改变这个默认值。\n​\n二、常用的网络故障排查工具 1.ping\nping命令可用于测试网络是否连通。\n2.telnet\n命令使用格式：\ntelnet ip或域名 port 例如：\ntelnet 120.55.94.78 8888 telnet www.baidu.com 80 结合ping和telnet命令我们就可以判断一个服务器地址上的某个端口号是否可以对外提供服务。\n由于我们使用的开发机器以windows居多，默认情况下，windows系统的telnet命令是没有打开的，我们可以在【控制面板】- 【程序】- 【程序和功能】- 【打开或关闭Windows功能】中打开telnet功能。\n3.host命令\nhost 命令可以解析域名得到对应的ip地址。例如，我们要得到www.baidu.com这个域名的ip地址，可以输入：\n得到www.google.com的ip地址可以输入：\n4 .netstat命令\n常见的选项有：\n-a (all)显示所有选项，netstat默认不显示LISTEN相关\n-t (tcp)仅显示tcp相关选项\n-u (udp)仅显示udp相关选项\n-n 拒绝显示别名，能显示数字的全部转化成数字。(重要)\n-l 仅列出有在 Listen (监听) 的服務状态\n-p 显示建立相关链接的程序名(macOS中表示协议 -p protocol)\n-r 显示路由信息，路由表\n-e 显示扩展信息，例如uid等\n-s 按各个协议进行统计 (重要)\n-c 每隔一个固定时间，执行该netstat命令。\n5. lsof命令\nlsof，即list opened filedescriptor，即列出当前操作系统中打开的所有文件描述符，socket也是一种file descriptor，常见的选项是:\n-i 列出系统打开的socket fd\n-P 不要显示端口号别名\n-n 不要显示ip地址别名（如localhost会用127.0.0.1来代替）\n+c w 程序列名称最大可以显示到w个字符。\n常见的选项组合为lsof –i –Pn：\n可以看到列出了当前侦听的socket，和连接socket的tcp状态。\n6.pstack\n严格意义上来说，这个不算网络排查故障和调试命令，但是我们可以利用这个命令来查看某个进程的线程数量和线程调用堆栈是否运行正常。指令使用格式：\npstack pid 即，pstack 进程号，如：\n7.nc命令\n即netcat命令，这个工具在排查网络故障时非常有用，因而被业绩称为网络界的“瑞士军刀”。常见的用法如下：\n模拟服务器端在指定ip地址和端口号上侦听 nc –l 0.0.0.0 8888 模拟客户端连接到指定ip地址和端口号 nc 0.0.0.0 8888 我们知道客户端连接服务器一般都是操作系统随机分配一个可用的端口号连接到服务器上去，这个指令甚至可以指定使用哪个端口号连接，如：\nnc –p 12345 127.0.0.1 8888 客户端使用端口12345去连接服务器127.0.0.1::8888。\n使用nc命令发消息和发文件 客户端\n服务器\n8 .tcpdump\n这个是linux系统自带的抓包工具，功能非常强大，默认需要开启root权限才能使用。\n其常见的选项有：\n-i 指定网卡\n-X –XX 打印十六进制的网络数据包\n-n –nn 不显示ip地址和端口的别名\n-S 以绝对值显示包的ISN号（包序列号）\n常用的过滤条件有如下形式：\ntcpdump –i any ‘port 8888’ tcpdump –i any ‘tcp port 8888’ tcpdump –i any ‘tcp src port 8888’ tcpdump –i any ‘tcp src port 8888 and udp dst port 9999’ tcpdump -i any \u0026#39;src host 127.0.0.1 and tcp src port 12345\u0026#39; -XX -nn -vv 关于tcpdump命令接下来将会以对tcp三次握手和四次挥手的包数据进行抓包来分析。\n三、 tcp三次握手和四次挥手过程解析 熟练地掌握tcp三次握手和四次挥手过程的每一个细节是我们排查网络问题的基础。\n下面我们来通过tcpdump抓包能实战一下三次握手的过程，假设我的服务器端的地址是 127.0.0.0.1 : 12345，使用nc命令创建一个服务器程序并在这个地址上进行侦听：\nnc –v -l 127.0.0.0.112345 然后在客户端机器上开启tcpdump工具：\n然后在客户端使用nc命令创建一个客户端去连接服务器：\n我们抓到的包如下：\n图片看不清，可以放大来看。上面我们需要注意的是：\n三次握手过程是客户端先给服务器发送一个SYN，然后服务器应答一个SYN+ACK，应答的序列号是递增1的，表示应答哪个请求，即从4004096087递增到4004096088，接着客户端再应答一个ACK。这个时候，我们发现发包序列号和应答序列号都变成1了，这是tcpdump使用相对序号，我们加上-S选项后就变成绝对序列号了。\n这是正常的tcp三次握手，假如我们连接的服务器ip地址存在，但监听端口号并不存在，我们看下tcpdump抓包结果：\n这个时候客户端发送SYN，服务器应答ACK+RST：\n这个应答包会导致客户端的connect连接失败。\n还有一种情况就是客户端访问一个很遥远的ip，或者网络繁忙，服务器对客户端发送的网络SYN报文没有应答，会出现什么情况呢？\n我们先将防火墙的已有规则都清理掉: iptables -F\n然后给防火墙的INPUT链上增加一个规则，丢弃本地网卡lo（也就是127.0.0.1这个回环地址）上的所有SYN包。\n接着，我们看到tcpdump抓到的数据包如下：\n连接不上，一共重试了5次，重试的时间间隔是1秒，2秒，4秒，8秒，16秒，最后返回失败。这个重试次数在/proc/sys/net/ipv4/tcp_syn_retries 内核参数中设置，默认为6。\n四次挥手与三次握手基本上类似，这里就不贴出tcpdump抓包的详情了。实际的网络开发中，尤其是高QPS的服务器程序，可能在在服务器程序所在的系统上留下大量非ESTABLISHED的中间状态，如CLOSE_WAIT/TIME_WAIT，我们可以使用以下指令来统计这些状态信息：\nnetstat -n | awk \u0026lsquo;/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}\u0026rsquo;\n得到结果可能类似：\n让我们再贴一张tcp三次握手和四次挥手更清晰的图吧。\n下面看下一般比较关心的三种TCP状态\nSYN_RECV 服务端收到建立连接的SYN没有收到ACK包的时候处在SYN_RECV状态。有两个相关系统配置：\n1 net.ipv4.tcp_synack_retries，整形，默认值是5\n对于远端的连接请求SYN，内核会发送SYN ＋ ACK数据报，以确认收到上一个 SYN连接请求包。这是三次握手机制的第二个步骤。这里决定内核在放弃连接之前所送出的 SYN+ACK 数目。不应该大于255，默认值是5，对应于180秒左右时间。通常我们不对这个值进行修改，因为我们希望TCP连接不要因为偶尔的丢包而无法建立。\n2 net.ipv4.tcp_syncookies\n一般服务器都会设置net.ipv4.tcp_syncookies=1来防止SYN Flood攻击。假设一个用户向服务器发送了SYN报文后突然死机或掉线，那么服务器在发出SYN+ACK应答报文后是无法收到客户端的ACK报文的（第三次握手无法完成），这种情况下服务器端一般会重试（再次发送SYN+ACK给客户端）并等待一段时间后丢弃这个未完成的连接，这段时间的长度我们称为SYN Timeout，一般来说这个时间是分钟的数量级（大约为30秒-2分钟）。这些处在SYNC_RECV的TCP连接称为半连接，并存储在内核的半连接队列中，在内核收到对端发送的ack包时会查找半连接队列，并将符合的requst_sock信息存储到完成三次握手的连接的队列中，然后删除此半连接。大量SYNC_RECV的TCP连接会导致半连接队列溢出，这样后续的连接建立请求会被内核直接丢弃，这就是SYN Flood攻击。能够有效防范SYN Flood攻击的手段之一，就是SYN Cookie。SYN Cookie原理由D. J. Bernstain和 Eric Schenk发明。SYN Cookie是对TCP服务器端的三次握手协议作一些修改，专门用来防范SYN Flood攻击的一种手段。它的原理是，在TCP服务器收到SYN包并返回SYN+ACK包时，不分配一个专门的数据区，而是根据这个SYN包计算出一个cookie值。在收到ACK包时，TCP服务器在根据那个cookie值检查这个TCP ACK包的合法性。如果合法，再分配专门的数据区进行处理未来的TCP连接。观测服务上SYN_RECV连接个数为：7314，对于一个高并发连接的通讯服务器，这个数字比较正常。\nCLOSE_WAIT 发起TCP连接关闭的一方称为client，被动关闭的一方称为server。被动关闭的server收到FIN后，但未发出ACK的TCP状态是CLOSE_WAIT。出现这种状况一般都是由于server端代码的问题，如果你的服务器上出现大量CLOSE_WAIT，应该要考虑检查代码。\nTIME_WAIT 根据三次握手断开连接规定，发起socket主动关闭的一方 socket将进入TIME_WAIT状态。TIME_WAIT状态将持续2MSL。TIME_WAIT状态下的socket不能被回收使用。 具体现象是对于一个处理大量短连接的服务器，如果是由服务器主动关闭客户端的连接，将导致服务器端存在大量的处于TIME_WAIT状态的socket， 甚至比处于Established状态下的socket多的多，严重影响服务器的处理能力，甚至耗尽可用的socket，停止服务。TIME_WAIT是TCP协议用以保证被重新分配的socket不会受到之前残留的延迟重发报文影响的机制,是必要的逻辑保证。和TIME_WAIT状态有关的系统参数有一般由3个，本机设置如下：\nnet.ipv4.tcp_tw_recycle = 1 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_fin_timeout = 30 net.ipv4.tcp_fin_timeout，默认60s，减小fin_timeout，减少TIME_WAIT连接数量。 net.ipv4.tcp_tw_reuse = 1表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭； net.ipv4.tcp_tw_recycle = 1表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。 我们这里总结一下这些与tcp状态的选项：\nnet.ipv4.tcp_syncookies=1 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookie来处理，可防范少量的SYN攻击。默认为0，表示关闭。\nnet.ipv4.tcp_tw_reuse=1 表示开启重用。允许将TIME-WAIT套接字重新用于新的TCP连接。默认为0，表示关闭。\nnet.ipv4.tcp_tw_recycle=1 表示开启TCP连接中TIME-WAIT套接字的快速回收。默认为0，表示关闭。**\nnet.ipv4.tcp_fin_timeout=30 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。\nnet.ipv4.tcp_keepalive_time=1200 表示当keepalive启用时，TCP发送keepalive消息的频度。默认是2小时，这里改为20分钟。\nnet.ipv4.ip_local_port_range=1024 65000 表示向外连接的端口范围。默认值很小：32768～61000，改为1024～65000。\nnet.ipv4.tcp_max_syn_backlog=8192 表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。\nnet.ipv4.tcp_max_tw_buckets=5000 表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数 字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为5000。\n注意\n上文中用红色字体标识出来的两个参数：\nnet.ipv4.tcp_tw_recycle net.ipv4.tcp_tw_reuse 在实际linux内核参数调优时并不建议开启。至于原因，我会单独用一篇文章来介绍。\n四、 关于跨系统与跨语言之间的网络通信连通问题 如何在Java语言中去解析C++的网络数据包，如何在C++中解析Java的网络数据包，对于很多人来说是一件很困难的事情，所以只能变着法子使用第三方的库。其实使用tcpdump工具可以很容易解决与分析。\n首先，我们需要明确字节序列这样一个概念，即我们说的大端编码(big endian)和小端编码(little endian)，x86和x64系列的cpu使用小端编码，而数据在网络上传输，以及Java语言中，使用的是大端编码。那么这是什么意思呢？\n我们举个例子，看一个x64机器上的32位数值在内存中的存储方式：\ni 在内存中的地址序列是0x003CF7C4~ 0x003CF7C8，值为40 e2 01 00。\n十六进制0001e240正好等于10进制123456，也就是说小端编码中权重高的的字节值存储在内存地址高（地址值较大）的位置，权重值低的字节值存储在内存地址低（地址值较小）的位置，也就是所谓的高高低低。\n相反，大端编码的规则应该是高低低高，也就是说权值高字节存储在内存地址低的位置，权值低的字节存储在内存地址高的位置。\n所以，如果我们一个C++程序的int32值123456不作转换地传给Java程序，那么Java按照大端编码的形式读出来的值是：十六进制40E20100 = 十进制1088553216。\n所以，我们要么在发送方将数据转换成网络字节序（大端编码），要么在接收端再进行转换。\n下面看一下如果C++端传送一个如下数据结构，Java端该如何解析（由于Java中是没有指针的，也无法操作内存地址，导致很多人无从下手），下面利用tcpdump来解决这个问题的思路。\n我们客户端发送的数据包：\n其结构体定义如下：\n利用tcpdump抓到的包如下：\n放大一点：\n我们白色标识出来就是我们收到的数据包。这里我想说明两点：\n如果我们知道发送端发送的字节流，再比照接收端收到的字节流，我们就能检测数据包的完整性，或者利用这个来排查一些问题； 对于Java程序只要按照这个顺序，先利用java.net.Socket的输出流java.io.DataOutputStream对象readByte、readInt32、readInt32、readBytes、readBytes方法依次读出一个char、int32、int32、16个字节的字节数组、63个字节数组即可，为了还原像int32这样的整形值，我们需要做一些小端编码向大端编码的转换。 参考资料：\n《TCP/IP详解卷一：协议》 《TCP/IP详解卷二：实现》 游双《Linux高性能服务器编程》 https://man.cx/?page=iptables(8) https://vincent.bernat.im/en/blog/2014-tcp-time-wait-state-linux https://blog.csdn.net/chinalinuxzend/article/details/1792184 https://www.zhihu.com/question/29212769 https://blog.csdn.net/launch_225/article/details/9211731 https://www.cnblogs.com/splenday/articles/7668589.html http://man.linuxde.net/ss http://www.cnxct.com/coping-with-the-tcp-time_wait-state-on-busy-linux-servers-in-chinese-and-dont-enable-tcp_tw_recycle/ https://www.cnblogs.com/xkus/p/7463135.html ","permalink":"https://haokiu.com/blog/b7d459605e1d4d46adba41bdb0c66b78/","summary":"服务器开发中网络数据分析与故障排查经验漫谈 ​\n一、 操作系统提供的网络接口\n为了能更好的排查网络通信问题，我们需要熟悉操作系统提供的以下网络接口函数，列表如下：\n接口函数名称 接口函数描述 接口函数签名 socket 创建套接字 int socket(int domain, int type, int protocol); connect 连接一个服务器地址 int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); send 发送数据 ssize_t send(int sockfd, const void *buf, size_t len, int flags); recv 收取数据 ssize_t recv(int sockfd, void *buf, size_t len, int flags); accept 接收连接 int accept4(int sockfd, struct sockaddr *addr, socklen_t *addrlen, int flags); shutdown 关闭收发链路 int shutdown(int sockfd, int how); close 关闭套接字 int close(int fd); setsockopt 设置套接字选项 int setsockopt(int sockfd, int level, int optname, const void *optval, socklen_t optlen); 注意：这里以bekeley提供的标准为例，不包括特定操作系统上特有的接口函数（如Windows平台的WSASend，linux的accept4），也不包括实际与网络数据来往不相关的函数（如select、linux的epoll），这里只讨论与tcp相关的接口函数，像与udp相关的函数sendto/recvfrom等函数与此类似。\n下面讨论一下以上函数的一些使用注意事项：\n1 以上函数如果调用出错后，返回值均为-1；但是返回值是-1，不一定代表出错，这还得根据对应的套接字模式（阻塞与非阻塞模式）。\n2 默认使用的socket函数创建的套接字是阻塞模式的，可以调用相关接口函数将其设置为非阻塞模式（Windows平台可以使用ioctlsocket函数，linux平台可以使用fcntl函数，具体设置方法可以参考这里。）。阻塞模式和非阻塞模式的套接字，对服务器的连接服务器和网络数据的收发行为影响很大。详情如下：\n阻塞模式下，connect函数如果不能立刻连上服务器，会导致执行流阻塞在那里一会儿，直到connect连接成功或失败或网络超时；而非阻塞模式下，无论是否连接成功connect将立即返回，此时如果未连接成功，返回值将是-1，错误码是EINPROGRESS，表示连接操作仍然在进行中。Linux平台后续可以通过使用select/poll等函数检测该socket是否可写来判断连接是否成功。\n阻塞套接字模式下，send函数如果由于对端tcp窗口太小，不足以将全部数据发送出去，将阻塞执行流，直到出错或超时或者全部发送出去为止；同理recv函数如果当前协议栈系统缓冲区中无数据可读，也会阻塞执行流，直到出错或者超时或者读取到数据。send和recv函数的超时时间可以参考下文关于常用socket选项的介绍。\n非阻塞套接字模式下，如果由于对端tcp窗口太小，不足以将数据发出去，它将立刻返回，不会阻塞执行流，此时返回值为-1，错误码是EAGAIN或EWOULDBLOCK，表示当前数据发不出去，希望你下次再试。但是返回值如果是-1，也可能是真正的出错了，也可能得到错误码EINTR，表示被linux信号中断了，这点需要注意一下。recv函数与send函数情形一样。\n3 send函数虽然名称叫“send”，但是其并不是将数据发送到网络上去，只是将数据从应用层缓冲区中拷贝到协议栈内核缓冲区中，具体什么时候发送到网络上去，与协议栈本身行为有关系（socket选项nagle算法与这个有关系，下文介绍常见套接字选项时会介绍），这点需要特别注意，所以即使send函数返回一个大于0的值n，也不能表明已经有n个字节发送到网络上去了。同样的道理，recv函数也不是从网络上收取数据，只是从协议栈内核缓冲区拷贝数据至应用层缓冲区，并不是真正地从网络上收数据，所以，调用recv时，操作系统的协议栈已经将数据从网络上收到自己的内核缓冲区中了，recv仅仅是一次数据拷贝操作而已。","title":"服务器开发中网络数据分析与故障排查经验漫谈"},{"content":"服务器开发案例实战 从零实现一个http服务器\n从零实现一款12306刷票软件\n从零实现一个邮件收发客户端\n从零开发一个WebSocket服务器\n从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始\n从零学习开源项目系列（二） 最后一战概况\n从零学习开源项目系列（三） CSBattleMgr服务源码研究\n从零学习开源项目系列（四）LogServer源码探究\n","permalink":"https://haokiu.com/blog/5d978400ccba478eaaa6a166b4ffba8d/","summary":"服务器开发案例实战 从零实现一个http服务器\n从零实现一款12306刷票软件\n从零实现一个邮件收发客户端\n从零开发一个WebSocket服务器\n从零学习开源项目系列（一） 从一款多人联机实时对战游戏开始\n从零学习开源项目系列（二） 最后一战概况\n从零学习开源项目系列（三） CSBattleMgr服务源码研究\n从零学习开源项目系列（四）LogServer源码探究","title":"服务器开发案例实战"},{"content":"服务器开发通信协议设计介绍 一、选择TCP还是UDP协议 由于我们的即时通讯软件的用户存在用户状态问题，即用户登录成功以后可以在他的好友列表中看到哪些好友在线，所以客户端和服务器需要保持长连接状态。另外即时通讯软件一般要求信息准确、有序、完整地到达对端，而这也是TCP协议的特点之一。综合这两个所以这里我们选择TCP协议，而不是UDP协议。\n二、协议的结构 由于TCP协议是流式协议，所谓流式协议即通讯的内容是无边界的字节流：如A给B连续发送了三个数据包，每个包的大小都是100个字节，那么B可能会一次性收到300个字节；也可能先收到100个字节，再收到200个字节；也可能先收到100个字节，再收到50个字节，再收到150个字节；或者先收到50个字节，再收到50个字节，再收到50个字节，最后收到150个字节。也就是说，B可能以任何组合形式收到这300个字节。即像水流一样无明确的边界。为了能让对端知道如何给包分界，目前一般有三种做法：\n以固定大小字节数目来分界，上文所说的就是属于这种类型，如每个包100个字节，对端每收齐100个字节，就当成一个包来解析； 以特定符号来分界，如每个包都以特定的字符来结尾（如\\n），当在字节流中读取到该字符时，则表明上一个包到此为止。 固定包头+包体结构，这种结构中一般包头部分是一个固定字节长度的结构，并且包头中会有一个特定的字段指定包体的大小。这是目前各种网络应用用的最多的一种包格式。 上面三种分包方式各有优缺点，方法1和方法2简单易操作，但是缺点也很明显，就是很不灵活，如方法一当包数据不足指定长度，只能使用占位符如0来凑，比较浪费；方法2中包中不能有包界定符，否则就会引起歧义，也就是要求包内容中不能有某些特殊符号。而方法3虽然解决了方法1和方法2的缺点，但是操作起来就比较麻烦。我们的即时通讯协议就采用第三种分包方式。所以我们的协议包的包头看起来像这样：\nstruct package_header { int32_t bodysize; }; 一个应用中，有许多的应用数据，拿我们这里的即时通讯来说，有注册、登录、获取好友列表、好友消息等各种各样的协议数据包，而每个包因为业务内容不一样可能数据内容也不一样，所以各个包可能看起来像下面这样：\nstruct package_header { int32_t bodysize; }; //登录数据包 struct register_package { package_header header; //命令号 int32_t cmd; //注册用户名 char username[16]; //注册密码 char password[16]; //注册昵称 char nickname[16]; //注册手机号 char mobileno[16]; }; //登录数据包 struct login_package { package_header header; //命令号 int32_t cmd; //登录用户名 char username[16]; //密码 char password[16]; //客户端类型 int32_t clienttype; //上线类型，如在线、隐身、忙碌、离开等 int32_t onlinetype; }; //获取好友列表 struct getfriend_package { package_header header; //命令号 int32_t cmd; }; //聊天内容 struct chat_package { package_header header; //命令号 int32_t cmd; //发送人userid int32_t senderid; //接收人userid int32_t targetid; //消息内容 char chatcontent[8192]; }; 看到没有？由于每一个业务的内容不一样，定义的结构体也不一样。如果业务比较多的话，我们需要定义各种各样的这种结构体，这简直是一场噩梦。那么有没有什么方法可以避免这个问题呢？有，我受jdk中的流对象的WriteInt32、WriteByte、WriteInt64、WriteString，这样的接口的启发，也发明了一套这样的协议，而且这套协议基本上是通用协议，可用于任何场景。我们的包还是分为包头和包体两部分，包头和上文所说的一样，包体是一个不固定大小的二进制流，其长度由包头中的指定包体长度的字段决定。\nstruct package_protocol { int32_t bodysize; //注意：C/C++语法不能这么定义结构体， //这里只是为了说明含义的伪代码 //bodycontent即为一个不固定大小的二进制流 char binarystream[bodysize]; }; 接下来的核心部分就是如何操作这个二进制流，我们将流分为二进制读和二进制写两种流，下面给出接口定义：\n//写 class BinaryWriteStream { public: BinaryWriteStream(string* data); const char* GetData() const; size_t GetSize() const; bool WriteCString(const char* str, size_t len); bool WriteString(const string\u0026amp; str); bool WriteDouble(double value, bool isNULL = false); bool WriteInt64(int64_t value, bool isNULL = false); bool WriteInt32(int32_t i, bool isNULL = false); bool WriteShort(short i, bool isNULL = false); bool WriteChar(char c, bool isNULL = false); size_t GetCurrentPos() const{ return m_data-\u0026gt;length(); } void Flush(); void Clear(); private: string* m_data; }; //读 class BinaryReadStream : public IReadStream { private: const char* const ptr; const size_t len; const char* cur; BinaryReadStream(const BinaryReadStream\u0026amp;); BinaryReadStream\u0026amp; operator=(const BinaryReadStream\u0026amp;); public: BinaryReadStream(const char* ptr, size_t len); const char* GetData() const; size_t GetSize() const; bool IsEmpty() const; bool ReadString(string* str, size_t maxlen, size_t\u0026amp; outlen); bool ReadCString(char* str, size_t strlen, size_t\u0026amp; len); bool ReadCCString(const char** str, size_t maxlen, size_t\u0026amp; outlen); bool ReadInt32(int32_t\u0026amp; i); bool ReadInt64(int64_t\u0026amp; i); bool ReadShort(short\u0026amp; i); bool ReadChar(char\u0026amp; c); size_t ReadAll(char* szBuffer, size_t iLen) const; bool IsEnd() const; const char* GetCurrent() const{ return cur; } public: bool ReadLength(size_t \u0026amp; len); bool ReadLengthWithoutOffset(size_t \u0026amp;headlen, size_t \u0026amp; outlen); }; 这样如果是上文的一个登录数据包，我们只要写成如下形式就可以了：\nstd::string outbuf; BinaryWriteStream stream(\u0026amp;outbuf); stream.WriteInt32(cmd); stream.WriteCString(username, 16); stream.WriteCString(password, 16); stream.WriteInt32(clienttype); stream.WriteInt32(onlinetype); //最终数据就存储到outbuf中去了 stream.Flush(); 接着我们再对端，解得正确的包体后，我们只要按写入的顺序依次读出来即可：\nBinaryWriteStream stream(outbuf.c_str(), outbuf.length()); int32_t cmd; stream.WriteInt32(cmd); char username[16]; stream.ReadCString(username, 16, NULL); char password[16]; stream.WriteCString(password, 16, NULL); int32_t clienttype; stream.WriteInt32(clienttype); int32_t onlinetype; stream.WriteInt32(onlinetype); 这里给出BinaryReadStream和BinaryWriteStream的完整实现：\n//计算校验和 unsigned short checksum(const unsigned short *buffer, int size) { unsigned int cksum = 0; while (size \u0026gt; 1) { cksum += *buffer++; size -= sizeof(unsigned short); } if (size) { cksum += *(unsigned char*)buffer; } //将32位数转换成16 while (cksum \u0026gt;\u0026gt; 16) cksum = (cksum \u0026gt;\u0026gt; 16) + (cksum \u0026amp; 0xffff); return (unsigned short)(~cksum); } bool compress_(unsigned int i, char *buf, size_t \u0026amp;len) { len = 0; for (int a = 4; a \u0026gt;= 0; a--) { char c; c = i \u0026gt;\u0026gt; (a * 7) \u0026amp; 0x7f; if (c == 0x00 \u0026amp;\u0026amp; len == 0) continue; if (a == 0) c \u0026amp;= 0x7f; else c |= 0x80; buf[len] = c; len++; } if (len == 0) { len++; buf[0] = 0; } //cout \u0026lt;\u0026lt; \u0026#34;compress:\u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; //cout \u0026lt;\u0026lt; \u0026#34;compress len:\u0026#34; \u0026lt;\u0026lt; len \u0026lt;\u0026lt; endl; return true; } bool uncompress_(char *buf, size_t len, unsigned int \u0026amp;i) { i = 0; for (int index = 0; index \u0026lt; (int)len; index++) { char c = *(buf + index); i = i \u0026lt;\u0026lt; 7; c \u0026amp;= 0x7f; i |= c; } //cout \u0026lt;\u0026lt; \u0026#34;uncompress:\u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; return true; } BinaryReadStream::BinaryReadStream(const char* ptr_, size_t len_) : ptr(ptr_), len(len_), cur(ptr_) { cur += BINARY_PACKLEN_LEN_2 + CHECKSUM_LEN; } bool BinaryReadStream::IsEmpty() const { return len \u0026lt;= BINARY_PACKLEN_LEN_2; } size_t BinaryReadStream::GetSize() const { return len; } bool BinaryReadStream::ReadCString(char* str, size_t strlen, /* out */ size_t\u0026amp; outlen) { size_t fieldlen; size_t headlen; if (!ReadLengthWithoutOffset(headlen, fieldlen)) { return false; } // user buffer is not enough if (fieldlen \u0026gt; strlen) { return false; } // 偏移到数据的位置 //cur += BINARY_PACKLEN_LEN_2; cur += headlen; if (cur + fieldlen \u0026gt; ptr + len) { outlen = 0; return false; } memcpy(str, cur, fieldlen); outlen = fieldlen; cur += outlen; return true; } bool BinaryReadStream::ReadString(string* str, size_t maxlen, size_t\u0026amp; outlen) { size_t headlen; size_t fieldlen; if (!ReadLengthWithoutOffset(headlen, fieldlen)) { return false; } // user buffer is not enough if (maxlen != 0 \u0026amp;\u0026amp; fieldlen \u0026gt; maxlen) { return false; } // 偏移到数据的位置 //cur += BINARY_PACKLEN_LEN_2; cur += headlen; if (cur + fieldlen \u0026gt; ptr + len) { outlen = 0; return false; } str-\u0026gt;assign(cur, fieldlen); outlen = fieldlen; cur += outlen; return true; } bool BinaryReadStream::ReadCCString(const char** str, size_t maxlen, size_t\u0026amp; outlen) { size_t headlen; size_t fieldlen; if (!ReadLengthWithoutOffset(headlen, fieldlen)) { return false; } // user buffer is not enough if (maxlen != 0 \u0026amp;\u0026amp; fieldlen \u0026gt; maxlen) { return false; } // 偏移到数据的位置 //cur += BINARY_PACKLEN_LEN_2; cur += headlen; //memcpy(str, cur, fieldlen); if (cur + fieldlen \u0026gt; ptr + len) { outlen = 0; return false; } *str = cur; outlen = fieldlen; cur += outlen; return true; } bool BinaryReadStream::ReadInt32(int32_t\u0026amp; i) { const int VALUE_SIZE = sizeof(int32_t); if (cur + VALUE_SIZE \u0026gt; ptr + len) return false; memcpy(\u0026amp;i, cur, VALUE_SIZE); i = ntohl(i); cur += VALUE_SIZE; return true; } bool BinaryReadStream::ReadInt64(int64_t\u0026amp; i) { char int64str[128]; size_t length; if (!ReadCString(int64str, 128, length)) return false; i = atoll(int64str); return true; } bool BinaryReadStream::ReadShort(short\u0026amp; i) { const int VALUE_SIZE = sizeof(short); if (cur + VALUE_SIZE \u0026gt; ptr + len) { return false; } memcpy(\u0026amp;i, cur, VALUE_SIZE); i = ntohs(i); cur += VALUE_SIZE; return true; } bool BinaryReadStream::ReadChar(char\u0026amp; c) { const int VALUE_SIZE = sizeof(char); if (cur + VALUE_SIZE \u0026gt; ptr + len) { return false; } memcpy(\u0026amp;c, cur, VALUE_SIZE); cur += VALUE_SIZE; return true; } bool BinaryReadStream::ReadLength(size_t \u0026amp; outlen) { size_t headlen; if (!ReadLengthWithoutOffset(headlen, outlen)) { return false; } //cur += BINARY_PACKLEN_LEN_2; cur += headlen; return true; } bool BinaryReadStream::ReadLengthWithoutOffset(size_t\u0026amp; headlen, size_t \u0026amp; outlen) { headlen = 0; const char *temp = cur; char buf[5]; for (size_t i = 0; i\u0026lt;sizeof(buf); i++) { memcpy(buf + i, temp, sizeof(char)); temp++; headlen++; //if ((buf[i] \u0026gt;\u0026gt; 7 | 0x0) == 0x0) if ((buf[i] \u0026amp; 0x80) == 0x00) break; } if (cur + headlen \u0026gt; ptr + len) return false; unsigned int value; uncompress_(buf, headlen, value); outlen = value; /*if ( cur + BINARY_PACKLEN_LEN_2 \u0026gt; ptr + len ) { return false; } unsigned int tmp; memcpy(\u0026amp;tmp, cur, sizeof(tmp)); outlen = ntohl(tmp);*/ return true; } bool BinaryReadStream::IsEnd() const { assert(cur \u0026lt;= ptr + len); return cur == ptr + len; } const char* BinaryReadStream::GetData() const { return ptr; } size_t BinaryReadStream::ReadAll(char * szBuffer, size_t iLen) const { size_t iRealLen = min(iLen, len); memcpy(szBuffer, ptr, iRealLen); return iRealLen; } //=================class BinaryWriteStream implementation============// BinaryWriteStream::BinaryWriteStream(string *data) : m_data(data) { m_data-\u0026gt;clear(); char str[BINARY_PACKLEN_LEN_2 + CHECKSUM_LEN]; m_data-\u0026gt;append(str, sizeof(str)); } bool BinaryWriteStream::WriteCString(const char* str, size_t len) { char buf[5]; size_t buflen; compress_(len, buf, buflen); m_data-\u0026gt;append(buf, sizeof(char)*buflen); m_data-\u0026gt;append(str, len); //unsigned int ulen = htonl(len); //m_data-\u0026gt;append((char*)\u0026amp;ulen,sizeof(ulen)); //m_data-\u0026gt;append(str,len); return true; } bool BinaryWriteStream::WriteString(const string\u0026amp; str) { return WriteCString(str.c_str(), str.length()); } const char* BinaryWriteStream::GetData() const { return m_data-\u0026gt;data(); } size_t BinaryWriteStream::GetSize() const { return m_data-\u0026gt;length(); } bool BinaryWriteStream::WriteInt32(int32_t i, bool isNULL) { int32_t i2 = 999999999; if (isNULL == false) i2 = htonl(i); m_data-\u0026gt;append((char*)\u0026amp;i2, sizeof(i2)); return true; } bool BinaryWriteStream::WriteInt64(int64_t value, bool isNULL) { char int64str[128]; if (isNULL == false) { #ifndef _WIN32 sprintf(int64str, \u0026#34;%ld\u0026#34;, value); #else sprintf(int64str, \u0026#34;%lld\u0026#34;, value); #endif WriteCString(int64str, strlen(int64str)); } else WriteCString(int64str, 0); return true; } bool BinaryWriteStream::WriteShort(short i, bool isNULL) { short i2 = 0; if (isNULL == false) i2 = htons(i); m_data-\u0026gt;append((char*)\u0026amp;i2, sizeof(i2)); return true; } bool BinaryWriteStream::WriteChar(char c, bool isNULL) { char c2 = 0; if (isNULL == false) c2 = c; (*m_data) += c2; return true; } bool BinaryWriteStream::WriteDouble(double value, bool isNULL) { char doublestr[128]; if (isNULL == false) { sprintf(doublestr, \u0026#34;%f\u0026#34;, value); WriteCString(doublestr, strlen(doublestr)); } else WriteCString(doublestr, 0); return true; } void BinaryWriteStream::Flush() { char *ptr = \u0026amp;(*m_data)[0]; unsigned int ulen = htonl(m_data-\u0026gt;length()); memcpy(ptr, \u0026amp;ulen, sizeof(ulen)); } void BinaryWriteStream::Clear() { m_data-\u0026gt;clear(); char str[BINARY_PACKLEN_LEN_2 + CHECKSUM_LEN]; m_data-\u0026gt;append(str, sizeof(str)); } 这里详细解释一下上面的实现原理，即如何把各种类型的字段写入这种所谓的流中，或者怎么从这种流中读出各种类型的数据。上文的字段在流中的格式如下图：\n这里最简便的方式就是每个字段的长度域都是固定字节数目，如4个字节。但是这里我们并没有这么做，而是使用了一个小小技巧去对字段长度进行了一点压缩。对于字符串类型的字段，我们将表示其字段长度域的整型值（int32类型，4字节）按照其数值的大小压缩成1～5个字节，对于每一个字节，如果我们只用其低7位。最高位为标志位，为1时，表示其左边的还有下一个字节，反之到此结束。例如，对于数字127，我们二进制表示成01111111，由于最高位是0，那么如果字段长度是127及以下，一个字节就可以存储下了。如果一个字段长度大于127，如等于256，对应二进制100000000，那么我们按照刚才的规则，先填充最低字节（从左往右依次是从低到高），由于最低的7位放不下，还有后续高位字节，所以我们在最低字节的最高位上填1，即10000000，接着次高位为00000100，由于次高位后面没有更高位的字节了，所以其最高位为0，组合起来两个字节就是10000000 0000100。对于数字50000，其二进制是1100001101010000，根据每7个一拆的原则是：11 0000110 1010000再加上标志位就是：10000011 10000110 01010000。采用这样一种策略将原来占4个字节的整型值根据数值大小压缩成了1～5个字节（由于我们对数据包最大长度有限制，所以不会出现长度需要占5个字节的情形）。反过来，解析每个字段的长度，就是先取出一个字节，看其最高位是否有标志位，如果有继续取下一个字节当字段长度的一部分继续解析，直到遇到某个字节最高位不为1为止。\n对一个整形压缩和解压缩的部分从上面的代码中摘录如下：\n压缩：\n1 //将一个四字节的整形数值压缩成1~5个字节 2 bool compress_(unsigned int i, char *buf, size_t \u0026amp;len) 3 { 4 len = 0; 5 for (int a = 4; a \u0026gt;= 0; a--) 6 { 7 char c; 8 c = i \u0026gt;\u0026gt; (a * 7) \u0026amp; 0x7f; 9 if (c == 0x00 \u0026amp;\u0026amp; len == 0) 10 continue; 11 if (a == 0) 12 c \u0026amp;= 0x7f; 13 else 14 c |= 0x80; 15 buf[len] = c; 16 len++; 17 } 18 if (len == 0) 19 { 20 len++; 21 buf[0] = 0; 22 } 23 //cout \u0026lt;\u0026lt; \u0026#34;compress:\u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; 24 //cout \u0026lt;\u0026lt; \u0026#34;compress len:\u0026#34; \u0026lt;\u0026lt; len \u0026lt;\u0026lt; endl; 25 return true; 26 } 解压\n1 //将一个1~5个字节的值还原成四字节的整形值 2 bool uncompress_(char *buf, size_t len, unsigned int \u0026amp;i) 3 { 4 i = 0; 5 for (int index = 0; index \u0026lt; (int)len; index++) 6 { 7 char c = *(buf + index); 8 i = i \u0026lt;\u0026lt; 7; 9 c \u0026amp;= 0x7f; 10 i |= c; 11 } 12 //cout \u0026lt;\u0026lt; \u0026#34;uncompress:\u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; endl; 13 return true; 14 } 三、关于跨系统与跨语言之间的网络通信协议解析与识别问题 由于我们的即时通讯同时涉及到Java和C++两种编程语言，且有windows、linux、安卓三个平台，而我们为了保障学习的质量和效果，所以我们不用第三跨平台库（其实我们也是在学习如何编写这些跨平台库的原理），所以我们需要学习以下如何在Java语言中去解析C++的网络数据包或者反过来。安卓端发送的数据使用Java语言编写，pc与服务器发送的数据使用C++编写，这里以在Java中解析C++网络数据包为例。 这对于很多人来说是一件很困难的事情，所以只能变着法子使用第三方的库。其实只要你掌握了一定的基础知识，利用一些现成的字节流抓包工具（如tcpdump、wireshark）很容易解决这个问题。我们这里使用tcpdump工具来尝试分析和解决这个问题。 首先，我们需要明确字节序列这样一个概念，即我们说的大端编码(big endian)和小端编码(little endian)，x86和x64系列的cpu使用小端编码，而数据在网络上传输，以及Java语言中，使用的是大端编码。那么这是什么意思呢？ 我们举个例子，看一个x64机器上的32位数值在内存中的存储方式：\ni在内存中的地址序列是0x003CF7C4~0x003CF7C8，值为40 e2 01 00。\n十六进制0001e240正好等于10进制123456，也就是说小端编码中权重高的的字节值存储在内存地址高（地址值较大）的位置，权重值低的字节值存储在内存地址低（地址值较小）的位置，也就是所谓的高高低低。 相反，大端编码的规则应该是高低低高，也就是说权值高字节存储在内存地址低的位置，权值低的字节存储在内存地址高的位置。 所以，如果我们一个C++程序的int32值123456不作转换地传给Java程序，那么Java按照大端编码的形式读出来的值是：十六进制40E20100 = 十进制1088553216。 所以，我们要么在发送方将数据转换成网络字节序（大端编码），要么在接收端再进行转换。\n下面看一下如果C++端传送一个如下数据结构，Java端该如何解析（由于Java中是没有指针的，也无法操作内存地址，导致很多人无从下手），下面利用tcpdump来解决这个问题的思路。 我们客户端发送的数据包：\n其结构体定义如下：\n利用tcpdump抓到的包如下：\n放大一点：\n我们白色标识出来就是我们收到的数据包。这里我想说明两点：\n如果我们知道发送端发送的字节流，再比照接收端收到的字节流，我们就能检测数据包的完整性，或者利用这个来排查一些问题；\n对于Java程序只要按照这个顺序，先利用java.net.Socket的输出流java.io.DataOutputStream对象readByte、readInt32、readInt32、readBytes、readBytes方法依次读出一个char、int32、int32、16个字节的字节数组、63个字节数组即可，为了还原像int32这样的整形值，我们需要做一些小端编码向大端编码的转换。\n","permalink":"https://haokiu.com/blog/27166845330344e4bf4f9a385e69fc94/","summary":"服务器开发通信协议设计介绍 一、选择TCP还是UDP协议 由于我们的即时通讯软件的用户存在用户状态问题，即用户登录成功以后可以在他的好友列表中看到哪些好友在线，所以客户端和服务器需要保持长连接状态。另外即时通讯软件一般要求信息准确、有序、完整地到达对端，而这也是TCP协议的特点之一。综合这两个所以这里我们选择TCP协议，而不是UDP协议。\n二、协议的结构 由于TCP协议是流式协议，所谓流式协议即通讯的内容是无边界的字节流：如A给B连续发送了三个数据包，每个包的大小都是100个字节，那么B可能会一次性收到300个字节；也可能先收到100个字节，再收到200个字节；也可能先收到100个字节，再收到50个字节，再收到150个字节；或者先收到50个字节，再收到50个字节，再收到50个字节，最后收到150个字节。也就是说，B可能以任何组合形式收到这300个字节。即像水流一样无明确的边界。为了能让对端知道如何给包分界，目前一般有三种做法：\n以固定大小字节数目来分界，上文所说的就是属于这种类型，如每个包100个字节，对端每收齐100个字节，就当成一个包来解析； 以特定符号来分界，如每个包都以特定的字符来结尾（如\\n），当在字节流中读取到该字符时，则表明上一个包到此为止。 固定包头+包体结构，这种结构中一般包头部分是一个固定字节长度的结构，并且包头中会有一个特定的字段指定包体的大小。这是目前各种网络应用用的最多的一种包格式。 上面三种分包方式各有优缺点，方法1和方法2简单易操作，但是缺点也很明显，就是很不灵活，如方法一当包数据不足指定长度，只能使用占位符如0来凑，比较浪费；方法2中包中不能有包界定符，否则就会引起歧义，也就是要求包内容中不能有某些特殊符号。而方法3虽然解决了方法1和方法2的缺点，但是操作起来就比较麻烦。我们的即时通讯协议就采用第三种分包方式。所以我们的协议包的包头看起来像这样：\nstruct package_header { int32_t bodysize; }; 一个应用中，有许多的应用数据，拿我们这里的即时通讯来说，有注册、登录、获取好友列表、好友消息等各种各样的协议数据包，而每个包因为业务内容不一样可能数据内容也不一样，所以各个包可能看起来像下面这样：\nstruct package_header { int32_t bodysize; }; //登录数据包 struct register_package { package_header header; //命令号 int32_t cmd; //注册用户名 char username[16]; //注册密码 char password[16]; //注册昵称 char nickname[16]; //注册手机号 char mobileno[16]; }; //登录数据包 struct login_package { package_header header; //命令号 int32_t cmd; //登录用户名 char username[16]; //密码 char password[16]; //客户端类型 int32_t clienttype; //上线类型，如在线、隐身、忙碌、离开等 int32_t onlinetype; }; //获取好友列表 struct getfriend_package { package_header header; //命令号 int32_t cmd; }; //聊天内容 struct chat_package { package_header header; //命令号 int32_t cmd; //发送人userid int32_t senderid; //接收人userid int32_t targetid; //消息内容 char chatcontent[8192]; }; 看到没有？由于每一个业务的内容不一样，定义的结构体也不一样。如果业务比较多的话，我们需要定义各种各样的这种结构体，这简直是一场噩梦。那么有没有什么方法可以避免这个问题呢？有，我受jdk中的流对象的WriteInt32、WriteByte、WriteInt64、WriteString，这样的接口的启发，也发明了一套这样的协议，而且这套协议基本上是通用协议，可用于任何场景。我们的包还是分为包头和包体两部分，包头和上文所说的一样，包体是一个不固定大小的二进制流，其长度由包头中的指定包体长度的字段决定。\nstruct package_protocol { int32_t bodysize; //注意：C/C++语法不能这么定义结构体， //这里只是为了说明含义的伪代码 //bodycontent即为一个不固定大小的二进制流 char binarystream[bodysize]; }; 接下来的核心部分就是如何操作这个二进制流，我们将流分为二进制读和二进制写两种流，下面给出接口定义：","title":"服务器开发通信协议设计介绍"},{"content":"服务器端发数据时，如果对端一直不收，怎么办？ 这类问题一般出现在跨部门尤其是与外部开发人员合作的时候。假设现在有这样一种情况，我们的服务器提供对外的服务，指定好了协议，然后对外提供服务，客户端由外部人员去开发，由于存在太多的不确定性，如果我们在给对端（客户端）发送数据时，对端因为一些问题（可能是逻辑 bug 或者其他的一些问题）一直不从 socket 系统缓冲区中收取数据，而服务器端可能定期产生一些数据需要发送给客户端，再发了一段时间后，由于 TCP 窗口太小，导致数据发送不出去，这样待发送的数据会在服务器端对应的连接的发送缓冲区中积压，如果我们不做任何处理，很快系统就会因为缓冲区过大内存耗尽，导致服务被系统杀死。\n对于这种情况，我们一般建议从以下几个方面来增加一些防御措施：\n设置每路发送连接的发送缓冲区大小上限（如 2 M，或者小于这个值），当某路连接上的数据发送不出去的时候，即将数据存入发送缓冲区时，先判断一下缓冲区最大剩余空间，如果剩余空间已经小于我们要放入的数据大小，也就是说缓冲区中数据大小会超过了我们规定的上限，则认为该连接出现了问题，关闭该路连接并回收相应的资源（如清空缓冲区、回收套接字资源等）。示例代码如下：\n//outputBuffer_为发送缓冲区对象 size_t remainingLen = outputBuffer_.remainingBytes(); //如果加入到缓冲区中的数据长度超出了发送缓冲区最大剩余量 if (remainingLen \u0026lt; dataToAppend.length()) { forceClose() return } outputBuffer_.append(static_cast\u0026lt;const char*\u0026gt;(dataToAppend.c_str()), dataToAppend.length()); 还有另外一种场景，当有一部分数据已经积压在发送缓冲区了，此后服务器端未产生新的待发送的数据，此时如果不做任何处理，发送缓冲区的数据会一直积压，但是发送缓冲区的数据容量也不会超过上限。如果不做任何处理的话，该数据会一直在缓冲区中积压，白白浪费系统资源。对于这种情况一般我们会设置一个定时器，每隔一段时间（如 3 秒）去检查一下各路连接的发送缓冲区中是否还有数据未发送出去，也就是说如果一个连接超过一定时间内还存在未发送出去的数据，我们也认为该连接出现了问题，我们可以关闭该路连接并回收相应的资源（如清空缓冲区、回收套接字资源等）。示例代码如下：\n//每3秒检测一次 const int SESSION_CHECK_INTERVAL = 3000; SetTimer(SESSION_CHECK_TIMER_ID, SESSION_CHECK_INTERVAL); void CSessionManager::OnTimer() { for (auto iter = m_mapSession.begin(); iter != m_mapSession.end(); ++iter) { if (!CheckSession(iter-\u0026gt;value)) { //关闭session，回收相关的资源 iter-\u0026gt;value-\u0026gt;ForceClose(); iter = m_mapSession.erase(iter); } } } void CSessionManager::CheckSession(CSession* pSession) { if (!pSession-\u0026gt;GetConnection().OutputBuffer.IsEmpty()) return false; return true; } 上述代码，每隔 3 秒检测所有的 Session 的对应的 Connection 对象，如果发现发送缓冲区非空，说明该连接中发送缓冲区中数据已经驻留 3 秒了，将该连接关闭并清理资源。\n","permalink":"https://haokiu.com/blog/bb7da7e0bc524808b2a072fb43da3a8e/","summary":"服务器端发数据时，如果对端一直不收，怎么办？ 这类问题一般出现在跨部门尤其是与外部开发人员合作的时候。假设现在有这样一种情况，我们的服务器提供对外的服务，指定好了协议，然后对外提供服务，客户端由外部人员去开发，由于存在太多的不确定性，如果我们在给对端（客户端）发送数据时，对端因为一些问题（可能是逻辑 bug 或者其他的一些问题）一直不从 socket 系统缓冲区中收取数据，而服务器端可能定期产生一些数据需要发送给客户端，再发了一段时间后，由于 TCP 窗口太小，导致数据发送不出去，这样待发送的数据会在服务器端对应的连接的发送缓冲区中积压，如果我们不做任何处理，很快系统就会因为缓冲区过大内存耗尽，导致服务被系统杀死。\n对于这种情况，我们一般建议从以下几个方面来增加一些防御措施：\n设置每路发送连接的发送缓冲区大小上限（如 2 M，或者小于这个值），当某路连接上的数据发送不出去的时候，即将数据存入发送缓冲区时，先判断一下缓冲区最大剩余空间，如果剩余空间已经小于我们要放入的数据大小，也就是说缓冲区中数据大小会超过了我们规定的上限，则认为该连接出现了问题，关闭该路连接并回收相应的资源（如清空缓冲区、回收套接字资源等）。示例代码如下：\n//outputBuffer_为发送缓冲区对象 size_t remainingLen = outputBuffer_.remainingBytes(); //如果加入到缓冲区中的数据长度超出了发送缓冲区最大剩余量 if (remainingLen \u0026lt; dataToAppend.length()) { forceClose() return } outputBuffer_.append(static_cast\u0026lt;const char*\u0026gt;(dataToAppend.c_str()), dataToAppend.length()); 还有另外一种场景，当有一部分数据已经积压在发送缓冲区了，此后服务器端未产生新的待发送的数据，此时如果不做任何处理，发送缓冲区的数据会一直积压，但是发送缓冲区的数据容量也不会超过上限。如果不做任何处理的话，该数据会一直在缓冲区中积压，白白浪费系统资源。对于这种情况一般我们会设置一个定时器，每隔一段时间（如 3 秒）去检查一下各路连接的发送缓冲区中是否还有数据未发送出去，也就是说如果一个连接超过一定时间内还存在未发送出去的数据，我们也认为该连接出现了问题，我们可以关闭该路连接并回收相应的资源（如清空缓冲区、回收套接字资源等）。示例代码如下：\n//每3秒检测一次 const int SESSION_CHECK_INTERVAL = 3000; SetTimer(SESSION_CHECK_TIMER_ID, SESSION_CHECK_INTERVAL); void CSessionManager::OnTimer() { for (auto iter = m_mapSession.begin(); iter != m_mapSession.end(); ++iter) { if (!CheckSession(iter-\u0026gt;value)) { //关闭session，回收相关的资源 iter-\u0026gt;value-\u0026gt;ForceClose(); iter = m_mapSession.erase(iter); } } } void CSessionManager::CheckSession(CSession* pSession) { if (!pSession-\u0026gt;GetConnection().OutputBuffer.IsEmpty()) return false; return true; } 上述代码，每隔 3 秒检测所有的 Session 的对应的 Connection 对象，如果发现发送缓冲区非空，说明该连接中发送缓冲区中数据已经驻留 3 秒了，将该连接关闭并清理资源。","title":"服务器端发数据时，如果对端一直不收，怎么办？"},{"content":"深入理解C/C++中的指针 C和C++中最强大的功能莫过于指针了（pointer），但是对于大多数人尤其是新手来说，指针是一个最容易出错、也最难掌握的概念了。本文将从指针的方方面面来讲述指针的概念和用法，希望对大家有所帮助。\n内存模型 为了更好地理解指针，让我们来看一下计算机的内存模型。\n内存分为物理内存和虚拟内存，物理内存对应计算机中的内存条，虚拟内存是操作系统内存管理系统假象出来的。由于这些不是我们本文的重点，下面不做区分。有不清楚这些概念的同学，可以给我留言或者在线询问。\n在不考虑cpu缓存的情况下，计算机运行程序本质上就是对内存中的数据的操作，通俗地来说，就是将内存条某些部分的数据搬进搬出或者搬来搬去，其中“搬进搬出”是指将内存中的二进制数据搬入cpu寄存器及运算器中进行相应的加减运算或者将寄存器中的数据搬回内存单元中，而“搬来搬去”是指将内存中的数据由这个位置搬到另外一个位置（当然，一般不是直接搬，而是借助寄存器作为中间存储区）。如下图所示：\n计算机为了方便管理内存，将内存的每个单元用一个数字编号，如下图所以：\n图中所示，是一个大小为128个字节的内存空间，其中每一个空格代表一个字节，所以内存编号是0~127。\n对于一个32位的操作系统来说，内存空间中每一个字节的编号是一个32位二进制数，所以内存编号从0000 0000 0000 0000 0000 0000 0000 0000至1111 1111 1111 1111 1111 1111 1111 1111，转换成16进制也就是0x00000000至0xFFFFFFFF，由于是从0开始的，所以化成10机制就是从0至2的32次方减1；对于64位操作系统，内存编号也就是从64个0至64个1。\n大家需要注意的是，从上面两个图我们可以发现，我们一般将编号小的内存单元画在上面，编号大的画在下面，也就是说从上至下，内存编号越来越大。\n指针与指针变量 指针的本意就是内存地址，我们可以通俗地理解成内存编号，既然计算机通过编号来操作内存单元，这就造就了指针的高效率。\n那么什么是指针变量呢？指针变量可通俗地理解成存储指针的变量，也就是存储内存地址（内存编号）的变量。首先指针变量和整型变量、字符型变量以及其他数据类型的变量一样都是变量类型；但是，反过来，我们不应该按这样的方式来分类，即：整型指针变量、字符型指针变量、浮点型指针变量等等。为什么不推荐这样的分类方法呢？首先，指针变量就是一个数据类型，指针数据类型，这种数据类型首先是一个变量数据类型，那么它的大小是多少呢？很多同学理所当然地认为整型指针变量和一个字符指针变量的大小是不一样的，这种认识是错的。指针变量也是一个变量，它是一个用来存储其他变量的内存地址的，更准确地说，指针变量时用来存储其他变量的内存首地址的，因为不同的数据类型所占的内存大小不一样。举个例子，在32位机器上，假如a是int型变量，pa是指向a的指针变量，b是一个double型变量，pb是指向b的指针变量，那么a在内存中占四个字节，b在内存中占8个字节，假如a在内存中分布是从0x11111110~0x11111113，而b在内存中分布是0x11112221至0x11112228，那么指针变量pa中存储的内容是0x11111110，而pb中存储就是0x11112221，看到了吧，也就是说，pa和pb中存储的都是地址，而且都是32位的二进制地址；再者，因为存储这样的地址需要4个字节，所以无论是int型指针变量pa或者是double型指针变量pb，它们所占的内存大小都是四个字节，从这点来说，不管什么类型的指针都是一样的，所以不论按整型指针变量、字符型指针变量、浮点型指针变量等等来区分指针变量。总结起来，指针变量和int、float、char等类型一样同属变量类型，指针变量类型占四个字节（32位机器下），存储的是32位的内存地址。下面的代码证明这一点：\n上面介绍的是指针变量的一个方面，指针变量还有另外一层含义：在C/C++中星号（*）被定义成取内容符号，虽然所有指针变量占的内存大小和存储的内存地址大小都是一样的，但是由于存储的只是数据的内存首地址，所以指针变量存储的内存地址所指向的数据类型决定着如何解析这个首地址，也就是说对于int型指针变量，我们需要从该指针变量存储的（首）地址开始向后一直搜索4个字节的内存空间，以图中的变量a为例就是从0x12ff60~0x12ff63，对于变量b就是0x12ff44~0x12ff4b。所以从这个意义来上讲，当我们使用*pa，必须先知道pa是一个整型的指针，这里强调“整型”，而a的值1也就存储在从0x12ff60~0x12ff63这四个字节里面，当我们使用*pb，必须先知道pb是一个double型指针，这里强调\u0026quot;double\u0026quot;,也就是说值2.0000存储在0x12ff44~0x12ff4b这八个字节里面。因此，我们对指针变量进行算术运算，比如pa + 2,pb + +之类的操作，是以数据类型大小为单位的，也就是说pa + 2,相当于0x12ff60 + sizeof(int) * 2 = 0x12ff60 + 4 * 2 = 0x12ff68,不是0x12ff60 + 2哦；而pb - -相当于0x12ff44 + sizeof(double) * 1 = 0x12ff44 + 8 * 1 = 0x12ff4c。理解这一点很重要。 同理\u0026amp;a + 2和\u0026amp;b - 1也是一样（注意由于\u0026amp;b是一个指针常量，所以写成\u0026amp;b - -是错误的）。\n指针变量和指针常量 指针变量首先是一个变量，由于指针变量存储了某个变量的内存首地址，我们通常认为**”指针变量指向了该变量“，但是在这个时刻指针变量pa指向变量a，下个时候可能不存储变量a的首地址，而是存储变量c的首地址，那么我们可以认为这个时候，pa不再指向a，而是指向c。请别嫌我啰嗦，为了帮助你理解，我是故意说得这么细的，后面我们讨论高级主题的时候，当你觉得迷糊，请回来反复咀嚼一下这段话。也就是说指针变量是一个变量，它的值可以变动**的。\n相反，指针常量可通俗地理解为存储固定的内存单元地址编号的”量“，它一旦存储了某个内存地址以后，不可再改存储其他的内存地址了。所以指针常量是坚韧，因为它”咬定青山不放松“；说是”痴情“，因为它”曾经沧海难为水“。我这里讲的指针常量对应的是const关键字定义的量，而不是指针字面量。像\u0026amp;a, \u0026amp;b, \u0026amp;a + 2等是指针字面量，而const int *p = \u0026amp;a;中的p才算是真正的指针常量，指针常量一般用在函数的参数中，表示该函数不可改变实参的内容。来看一个例子吧：\n上面的函数由于修改了一个常指针（多数情况下等同指针常量），因而会编译出错：error C3892: “x”: 不能给常量赋值。\n指针变量与数组 记得多年以前，我在学生会给电子技术部和地理信息系统专业的同学进行C语言培训时，这是一个最让他们头疼和感到一头雾水的话题，尤其是指针变量与二维数组的结合，我永远忘不了胡永月那一脸迷惑与无助的表情。今天我这里给大家深入地分析一下。先看一个例子：\n如果你能得出下面这样的结果，说明你已经基本上对数组与指针的概念理解清楚了：\n通过上图，我们可以知道*(a + 1) = 2, *(ptr - 1) = 5。\n且不说很多同学根本得不到这样的结果，他们看到int ptr = (int)(\u0026amp;a+1);这样的语句就已经懵了，首先，我们知道C语言中规定数组名表示这个数组的首地址，而这里竟然出现了\u0026amp;a这样的符号，本来a就是一个指针常量了，这里对\u0026amp;a再次取地址难道不是非法操作吗？哈哈，当你有这样的疑问的时候，说明你对二维数组相关知识理解不深入。我这里先给你补充下知识点吧：\n看这样一个二维数组：int arr[3][4],这个数组布局如下：\n这是一个3行4列的数组，它在内存中的分布如下：\n这里每一个数组元素占4字节空间，我们知道C语言规定，数组名arr是整个数组元素的首地址，比如是0x0012ff08,而像arr[0]、arr[1]、arr[2]分别是数组第一行、第二行、第三行的首地址，也就是0x0012ff08、0x0012ff18、0x0012ff28。\n我们把arr、arr[0]和\u0026amp;arr[0][0]单独拿出来分析，因为数组的首地址也是第一列的首地址，同时也是第一个元素的首地址，所以arr和arr[0]和\u0026amp;arr[0][0]表示的都是同一个地址，但是这三个首地址在进行算术运算时是有区别的。如果\u0026amp;arr[0][0] + 1，这里的相当于跳一个元素的内存字节数，也就是4个；但是arr[0] + 1，移动的内存字节数是一列元素所占的字节数，也就是4 * 4 = 16个；最后，也是最让人迷惑的的就是arr + 1,这个时候移动的内存数目是整个数组占的内存字节数，也就是48个字节数，所以a + 1所表示的内存地址已经不属于这个数组了，这个地址位于数组最后一个元素所占内存空间的下一个字节空间。\n光有这些知识还是不能解决上面的问题，我们再补充一个知识点。\nC++是一种强类型的语言，其中有一种类型叫void类型，从本质上说void不是一种类型，因为变量都是”有类型“的，就好像人的性别，不是男人就是女人，不存在无性别的人，所以void更多是一种抽象。在程序中，void类型更多是用来**”修饰“和”限制“**一个函数的：例如一个函数如果不返回任何类型的值，可以用void作返回类型；如果一个函数无参数列表，可以用void作为参数列表。\n跟void类型”修饰“作用不同，void型指针作为指向抽象数据的指针，它本质上表示一段内存块。如果两个指针类型不同，在进行指针类型赋值时必须进行强制类型转换，看下面的例子：\n但是可以将任何指针类型赋值给void类型而无须进行强制类型转换：\n当然，如果把void型指针转换成并不是它实际指向的数据类型，其结果是不可预测的。试想，如果把一个int型指针赋给void型，然后再把这个void型指针强制转换成double型指针，这样的结果是不可预测的。因为不同数据类型所占内存大小不一样，这样做可能或截断内存数据或者会增加一些未知的额外数据。所以，最好是将void类型指针转换成它实际数据类型指针。\n有了上面的说明，你应该能看懂C函数库中下面这个函数的签名含义了吧？\nvoid *memcpy(void *dest,const void *src,size_t len); 在这里，任何数据类型的指针都可以传给这个函数，所以这个函数成为了一个通用的内存复制函数。\n好了，说了这么多，回答最初的那个问题上：\n我们来分析一下。首先，我们可以将这个数组看成是一个特殊的二维数组，也就是1行5列的二维数组，现在a表示的是第一个元素的首地址，那么a + 1指向的就是下一个元素的内存首地址，所以*(a + 1) = 2；而\u0026amp;a则是表示整个数组的首地址，那么\u0026amp;a + 1移动的内存数目就是整个数组所占字节数，假如这里我们量化来说明，假如原先数组中第一个元素的首地址是1,那么\u0026amp;a + 1表示的就是21，而这个地址已经不属于数组了，接着通过(int*)(\u0026amp;a + 1)将数组指针转换成整型指针，这样原先\u0026amp;a + 1表示的数据范围是21~40一下缩小到21~24,正好是一个int型的大小，所以ptr - 1的存储的地址就是17了，表示的数据内存范围是17~20,这样*(ptr - 1)正好就是最后一个元素5了。\n但是话说回来，首先这样的转换安全与否尚有争议，再次，这样的程序晦涩难懂，难于理解，所以建议不要写出这样的程序。\n上面的例子，只是通过一些简单的数据类型来说明内存分布，但是实际对于一些复杂的数据类型，尤其是一些自定义的类或者结构体类型，内存分布必须还要充分考虑到字节对齐。比如下面的代码：\n这是输出结果：\n由于结构体s1中存在字节对齐现象（以sizeof(double) = 8个字节对齐），所以s1占据24字节内存，而s2只占16个字节。知道这点，我们平常在设计结构体字段的时候，就可以合理安排字段顺序来使用更少的内存空间了。\n函数指针 函数指针是指向函数的指针变量。 因而“函数指针”本身首先应是指针变量，只不过该指针变量指向函数。这正如用指针变量可指向整型变量、字符型、数组一样，这里是指向函数。C/C++程序在编译时，每一个函数都有一个入口地址，该入口地址就是函数指针所指向的地址。有了指向函数的指针变量后，可用该指针变量调用函数，就如同用指针变量可引用其他类型变量一样，在这些概念上是一致的。函数指针有两个用途：调用函数和做函数的参数。\n我们先来先使用函数指针调用函数。如下图所示：\n上面的代码首先是定义了一个函数f，然后是定义一个函数指针pf，接着在主函数里面将函数f的地址赋值给函数指针，这样pf就指向了函数f，这样使用*pf就可以直接调用函数了。但是上面的例子定义函数指针的方法在某些编译器中是无法通过的，最好通过typedef关键字定义函数指针，推荐的写法如下：\n通过上面的例子，我们来总结下函数指针的定义和使用方法：\n首先，通过typedef关键字定义一个函数指针类型，然后定义一个该函数指针类型变量，接着将函数的入口地址赋值给该函数指针类型变量，这样就可以通过这个函数指针变量调用函数了。\n需要注意的是，定义函数指针类型时的函数签名（包括函数返回值和函数参数列表的类型、个数、顺序）要将赋值给该类型变量的函数签名保持一致，不然可能会发生很多无法预料的情况。还有一点，就是C/C++规定函数名就表示函数入口地址，所以，函数名赋值时函数名前面加不加取地址符\u0026amp;都一样，也就是说PF pf = f等价于PF pf = \u0026amp;f。这个**\u0026amp;是可以省略**的。但是这是单个函数的情况，在C++中取类的方法函数的地址时，这个\u0026amp;符号式不能省略的，见下面的例子：\n函数指针的另外一个用处，而且是用的最多的，就是作为一个函数的参数。也就是说某个函数的某个参数类型是一个函数，这在windows编程中作为回调函数(callback)尤其常见。我们来看一个例子：\n上图中，函数f2第一个参数类型是一个函数，我们传入函数f1作为参数。这种函数参数是函数类型的用法很重要，建议大家掌握。\n指针变量的定义方法 先插播一段广告，说下main函数的返回值问题，如下图：\n这种main函数无返回值的写法，在国内各大C/C++教材上屡见不鲜，这种写法是错误的！\n有一点你必须明确：C/C++标准中从来没有定义过void main()这样的代码形式。C++之父Bjarne Stroustrup在他的主页FAQ中明确地写了这样一句话：\n在C++中绝对没有出现过void main(){ /* \u0026hellip; */ } 这样的函数定义，在C语言中也是。\nmain函数的返回值应该定义为int型，在C/C++标准中都是这样规定的。在C99标准规定，只有以下两种定义方式是正确的的：\n1 int main(void); 2 int main(int argc,char *argv[]); 虽然在C和C++标准中并不支持void main()，但是在部分编译器中void main()依旧是可以通过编译并执行的，比如微软的VC++。由于微软产品的市场占有率和影响力很大，因为在某种程度上加剧了这种不良习惯的蔓延。不过，并非所有犯人编译器都支持void main()，gcc就站在VC++的对立面，它是这一不良习气的坚定抵制者，它会在编译时明确地给出一个错误。\n广告播完，我们回到正题上来。我们来看下如何定义一个指针，首先看一个例子：\n我来替你回答吧，你肯定认为a是一个指针变量，b是一个整型变量，c和d都是一个指针变量。好吧，恭喜你，答错了！\n其实定义指针变量的时候，星号(*)无论是与数据类型结合还是与变量名结合在一起都是一样的！但是，为了便于理解，还是推荐大家写成第一种形式，第二种形式容易误导人，不是吗？而且第一种形式还有一个好处，我们可以这样看：\nint *a; //将*a看成一个整体，它是一个int型数据，那么a自然就是指向*a的指针了。 说完定义指针的方法，下面我们来看下如何初始化一个指针变量，看下面的代码：\n上面的代码有错误吗？\n错误在于我们不能这样写：int *p = 1; 由于p是一个匿名指针，也就是说p没有正确的初始化，它可能指向一个不确定的内存地址，而这个内存地址可能是系统程序内存所在，我们将数值1装入那个不确定的内存单元中是很危险的，因为可能会破坏系统那个内存原来的数据，引发异常。换另一个方面来看，将整型数值1直接赋值给指针型变量p是非法的。\n这样的指针我们称为匿名指针或者野指针。和其他变量类型一样，为了防止发生意料之外的错误，我们应该给新定义的指针变量一个初始值。但是有时候，我们又没有合适的初始值给这个指针，怎么办？我们可以使用NULL关键字或者C++中的nullptr。代码如下：\n通过上面的写法就告诉编译器，这两个指针现在不会指向不确定的内存单元了，但是目前暂时不需要使用它们。　C++中的引用 C++中不仅有指针的概念，而且还存在一个引用的概念，看下面的代码：\n我开始在接触这个概念的时候，老是弄错。当时这么想的，既然b是a的引用，那么\u0026amp;b应该等于a吧?也就是说，在需要使用变量a的时候，可以使用\u0026amp;b来代替。\n上面的这种认识是错误的！所谓引用，使用另外一个变量名来代表某一块内存，也就是说a和b完全是一样，所以任何地方，可以使用a的，换成b也可以，而不是使用\u0026amp;b，这就相当于同一个人有不同的名字，但是不管哪个名字，指的都是同一个人。\n新手在刚接触引用的使用，还有一个地方容易出错，就是忘记给引用及时初始化，注意这里的“及时”两个字，C++规定，定义一个引用时，必须马上初始化。看下面的代码：\n传值还是传引用(by value or by reference) 看下面的伪代码：\n在涉及到利用一个已有初值的变量给另外一个变量赋值时，必须考虑这样的情况。图中变量a已经有了初值，然后利用a来给b赋初值，那么最后改变b的值，a的值会不会受影响呢？这就取决于b到底是a的副本还是和a同时指向同一内存区域，这就是我们常说的赋值时是传值还是传引用。各大语言都是这样规定的，也就是说不局限于C/C++，同时Java、C#、php、javascript等都一样：\n如果变量类型是基元数据类型（基础数据类型），比如int、float、bool、char等小数据类型被称为基元数据类型(primitive data type)，那么赋值时传的是值。也就是说，这个时候b的值是a的拷贝，那么更改b不会影响到a，同理更改a也不会影响到b。\n但是，如果变量类型是复杂数据类型(complex data type)，不如数组、类对象，那么赋值时传的就是引用，这个时候，a和b指向的都是同一块内存区域，那么无论更改a或者b都会相互影响。\n让我们来深入地分析下，为什么各大语言都采取这种机制。对于那些基元数据类型，由于数据本身占用的内存空间就小，这样复制起来不仅速度快，即使这样的变量数目很多，总共也不会占多大空间。但是对于复杂数据类型，比如一些类对象，它们包含的属性字段就很多，占用的空间就大，如果赋值时，也是复制数据，那么一个两个对象还好，一旦多一点比如10个、100个，会占很大的内存单元的，这就导致效率的下降。\n最后，提醒一点，在利用C++中拷贝构造函数复制对象时需要注意，基元数据类型可以直接复制，但是对于引用类型数据，我们需要自己实现引用型数据的真正复制。\nC/C++中的new关键字与Java、C#中的关键字对比 我大学毕业的时候痴迷于于网页游戏开发，使用的语言是flash平台的actionscript 3.0（简称as3，唉，如今已经没落），我刚开始由as3转行至C/C++，对于C/C++中new出来的对象必须通过指针对象来引用它非常不习惯。上图中,Object是一个类(class)，在Java或者C#等语言中，通过new关键字定义一个对象，直接得到Object的实例，也就是说后续引用这个对象，我们可以直接使用obj.property或者obj.method()等形式，但是在C++中不行，比如用一个指针去接受这个new出来的对象，我们引用这个对象必须使用指针引用运算符-\u0026gt;，也就是我们需要这样写：pObj-\u0026gt;property或pObject-\u0026gt;method()。代码如下：\n当然C++中还有一种不需要使用指针就可以实例化出来类对象的方法，从Java、C#等转向C++的程序员容易误解为未初始化对象变量的定义，看下列代码：\n这是C++中利用Object类实例化两个对象obj1和obj2，obj2因为调用构造函数传了两个参数param1,param2还好理解一点，对于obj1很多Java或者C#的程序员开始很难接受这种写法，因为如果放在Java或者C#中，obj1根本就没有被实例化嘛，在他们看来，obj1只是一个简单的类型申明。希望Java、C#等程序员要转换过思维来看待C++中的这种写法。\n还有一点也容易出错，在C++中，this关键字是一个指针，而不是像在Java、C#中是一个类实例。也就是说，在C++中*this才等价于Java、C#中的this。所以写法也就不一样了：\nWindows编程中的指针 Windows是操作系统是用C语言写出来的，所以尽管你在Windows中看到很多不认识的数据类型，但是这些数据类型也是通过基本的C语言类型组装起来的。我们这里只介绍Windows中指针型数据。\n定义指针数据类型必须使用星号(*)，但是Windows为了开发的方便，通过宏定义将指针“隐藏起来”，严格地说应该是将星号隐藏起来了，下面给出一些例子：\nC++中的智能指针 为了保持内容的完整性，暂且列一个标题放在这里，这个话题请参考本专题相关文章。\n我能想到的关于C/C++中指针的内容就这么多了，希望本文对你有用。文中如果有不当或者纰漏的地方欢迎批评指正。\n","permalink":"https://haokiu.com/blog/ec8d1fd1cfc24923bdb71accca3fc1e4/","summary":"深入理解C/C++中的指针 C和C++中最强大的功能莫过于指针了（pointer），但是对于大多数人尤其是新手来说，指针是一个最容易出错、也最难掌握的概念了。本文将从指针的方方面面来讲述指针的概念和用法，希望对大家有所帮助。\n内存模型 为了更好地理解指针，让我们来看一下计算机的内存模型。\n内存分为物理内存和虚拟内存，物理内存对应计算机中的内存条，虚拟内存是操作系统内存管理系统假象出来的。由于这些不是我们本文的重点，下面不做区分。有不清楚这些概念的同学，可以给我留言或者在线询问。\n在不考虑cpu缓存的情况下，计算机运行程序本质上就是对内存中的数据的操作，通俗地来说，就是将内存条某些部分的数据搬进搬出或者搬来搬去，其中“搬进搬出”是指将内存中的二进制数据搬入cpu寄存器及运算器中进行相应的加减运算或者将寄存器中的数据搬回内存单元中，而“搬来搬去”是指将内存中的数据由这个位置搬到另外一个位置（当然，一般不是直接搬，而是借助寄存器作为中间存储区）。如下图所示：\n计算机为了方便管理内存，将内存的每个单元用一个数字编号，如下图所以：\n图中所示，是一个大小为128个字节的内存空间，其中每一个空格代表一个字节，所以内存编号是0~127。\n对于一个32位的操作系统来说，内存空间中每一个字节的编号是一个32位二进制数，所以内存编号从0000 0000 0000 0000 0000 0000 0000 0000至1111 1111 1111 1111 1111 1111 1111 1111，转换成16进制也就是0x00000000至0xFFFFFFFF，由于是从0开始的，所以化成10机制就是从0至2的32次方减1；对于64位操作系统，内存编号也就是从64个0至64个1。\n大家需要注意的是，从上面两个图我们可以发现，我们一般将编号小的内存单元画在上面，编号大的画在下面，也就是说从上至下，内存编号越来越大。\n指针与指针变量 指针的本意就是内存地址，我们可以通俗地理解成内存编号，既然计算机通过编号来操作内存单元，这就造就了指针的高效率。\n那么什么是指针变量呢？指针变量可通俗地理解成存储指针的变量，也就是存储内存地址（内存编号）的变量。首先指针变量和整型变量、字符型变量以及其他数据类型的变量一样都是变量类型；但是，反过来，我们不应该按这样的方式来分类，即：整型指针变量、字符型指针变量、浮点型指针变量等等。为什么不推荐这样的分类方法呢？首先，指针变量就是一个数据类型，指针数据类型，这种数据类型首先是一个变量数据类型，那么它的大小是多少呢？很多同学理所当然地认为整型指针变量和一个字符指针变量的大小是不一样的，这种认识是错的。指针变量也是一个变量，它是一个用来存储其他变量的内存地址的，更准确地说，指针变量时用来存储其他变量的内存首地址的，因为不同的数据类型所占的内存大小不一样。举个例子，在32位机器上，假如a是int型变量，pa是指向a的指针变量，b是一个double型变量，pb是指向b的指针变量，那么a在内存中占四个字节，b在内存中占8个字节，假如a在内存中分布是从0x11111110~0x11111113，而b在内存中分布是0x11112221至0x11112228，那么指针变量pa中存储的内容是0x11111110，而pb中存储就是0x11112221，看到了吧，也就是说，pa和pb中存储的都是地址，而且都是32位的二进制地址；再者，因为存储这样的地址需要4个字节，所以无论是int型指针变量pa或者是double型指针变量pb，它们所占的内存大小都是四个字节，从这点来说，不管什么类型的指针都是一样的，所以不论按整型指针变量、字符型指针变量、浮点型指针变量等等来区分指针变量。总结起来，指针变量和int、float、char等类型一样同属变量类型，指针变量类型占四个字节（32位机器下），存储的是32位的内存地址。下面的代码证明这一点：\n上面介绍的是指针变量的一个方面，指针变量还有另外一层含义：在C/C++中星号（*）被定义成取内容符号，虽然所有指针变量占的内存大小和存储的内存地址大小都是一样的，但是由于存储的只是数据的内存首地址，所以指针变量存储的内存地址所指向的数据类型决定着如何解析这个首地址，也就是说对于int型指针变量，我们需要从该指针变量存储的（首）地址开始向后一直搜索4个字节的内存空间，以图中的变量a为例就是从0x12ff60~0x12ff63，对于变量b就是0x12ff44~0x12ff4b。所以从这个意义来上讲，当我们使用*pa，必须先知道pa是一个整型的指针，这里强调“整型”，而a的值1也就存储在从0x12ff60~0x12ff63这四个字节里面，当我们使用*pb，必须先知道pb是一个double型指针，这里强调\u0026quot;double\u0026quot;,也就是说值2.0000存储在0x12ff44~0x12ff4b这八个字节里面。因此，我们对指针变量进行算术运算，比如pa + 2,pb + +之类的操作，是以数据类型大小为单位的，也就是说pa + 2,相当于0x12ff60 + sizeof(int) * 2 = 0x12ff60 + 4 * 2 = 0x12ff68,不是0x12ff60 + 2哦；而pb - -相当于0x12ff44 + sizeof(double) * 1 = 0x12ff44 + 8 * 1 = 0x12ff4c。理解这一点很重要。 同理\u0026amp;a + 2和\u0026amp;b - 1也是一样（注意由于\u0026amp;b是一个指针常量，所以写成\u0026amp;b - -是错误的）。\n指针变量和指针常量 指针变量首先是一个变量，由于指针变量存储了某个变量的内存首地址，我们通常认为**”指针变量指向了该变量“，但是在这个时刻指针变量pa指向变量a，下个时候可能不存储变量a的首地址，而是存储变量c的首地址，那么我们可以认为这个时候，pa不再指向a，而是指向c。请别嫌我啰嗦，为了帮助你理解，我是故意说得这么细的，后面我们讨论高级主题的时候，当你觉得迷糊，请回来反复咀嚼一下这段话。也就是说指针变量是一个变量，它的值可以变动**的。\n相反，指针常量可通俗地理解为存储固定的内存单元地址编号的”量“，它一旦存储了某个内存地址以后，不可再改存储其他的内存地址了。所以指针常量是坚韧，因为它”咬定青山不放松“；说是”痴情“，因为它”曾经沧海难为水“。我这里讲的指针常量对应的是const关键字定义的量，而不是指针字面量。像\u0026amp;a, \u0026amp;b, \u0026amp;a + 2等是指针字面量，而const int *p = \u0026amp;a;中的p才算是真正的指针常量，指针常量一般用在函数的参数中，表示该函数不可改变实参的内容。来看一个例子吧：\n上面的函数由于修改了一个常指针（多数情况下等同指针常量），因而会编译出错：error C3892: “x”: 不能给常量赋值。\n指针变量与数组 记得多年以前，我在学生会给电子技术部和地理信息系统专业的同学进行C语言培训时，这是一个最让他们头疼和感到一头雾水的话题，尤其是指针变量与二维数组的结合，我永远忘不了胡永月那一脸迷惑与无助的表情。今天我这里给大家深入地分析一下。先看一个例子：\n如果你能得出下面这样的结果，说明你已经基本上对数组与指针的概念理解清楚了：\n通过上图，我们可以知道*(a + 1) = 2, *(ptr - 1) = 5。\n且不说很多同学根本得不到这样的结果，他们看到int ptr = (int)(\u0026amp;a+1);这样的语句就已经懵了，首先，我们知道C语言中规定数组名表示这个数组的首地址，而这里竟然出现了\u0026amp;a这样的符号，本来a就是一个指针常量了，这里对\u0026amp;a再次取地址难道不是非法操作吗？哈哈，当你有这样的疑问的时候，说明你对二维数组相关知识理解不深入。我这里先给你补充下知识点吧：","title":"深入理解C/C++中的指针"},{"content":"游戏开发专题 1 游戏服务器开发的基本体系与服务器端开发的一些建议\n2 网络游戏服务器开发框架设计介绍\n3 游戏后端开发需要掌握的知识\n4 关于游戏服务端架构的整理\n5 各类游戏对应的服务端架构\n6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则\n7 QQ游戏百万人同时在线服务器架构实现\n8 大型多人在线游戏服务器架构设计\n9 百万用户级游戏服务器架构设计\n10 十万在线的WebGame的数据库设计思路\n11 一种高性能网络游戏服务器架构设计\n12 经典游戏服务器端架构概述\n13 游戏跨服架构进化之路\n","permalink":"https://haokiu.com/blog/c1e71fdf335346f5aadad6e1d1dc3e55/","summary":"游戏开发专题 1 游戏服务器开发的基本体系与服务器端开发的一些建议\n2 网络游戏服务器开发框架设计介绍\n3 游戏后端开发需要掌握的知识\n4 关于游戏服务端架构的整理\n5 各类游戏对应的服务端架构\n6 从腾讯QQgame高性能服务器集群架构看“分而治之”与“自治”等分布式架构设计原则\n7 QQ游戏百万人同时在线服务器架构实现\n8 大型多人在线游戏服务器架构设计\n9 百万用户级游戏服务器架构设计\n10 十万在线的WebGame的数据库设计思路\n11 一种高性能网络游戏服务器架构设计\n12 经典游戏服务器端架构概述\n13 游戏跨服架构进化之路","title":"游戏开发专题"},{"content":"用Visual Studio调试Linux程序 用Visual Studio调试Linux程序？你真的没看错，这个是真的，不是标题党。当然如果你说VS2015及以上版本自带的Linux调试插件，那就算了。这些自带的插件调试一个有简单的main函数程序还凑合，稍微复杂点的程序，根本无法编译调试。\n而本文介绍的主角是VS的另外一款插件Visual GDB，让我们欢迎主角登场，下面是正文。\n使用Visual Studio+VisualGDB调试远程Linux程序 需要工具：\nVisual Studio 2013或以上版本（以下简称VS） VisualGDB（一款VS插件，官网为：http://visualgdb.com/） 含有调试符号的Linux程序文件（该程序文件为调试目标） Visual Assistant（番茄助手，另外一款VS插件） 在VS上安装完VisualGDB插件以后，有如下几种方式来对远程Linux机器上的程序进行调试：\n**方法一、**如果该程序已经启动，则可以使用VS菜单【Debug】-\u0026gt;【Attach to Process\u0026hellip;】。 这种方法有个缺点是，不能从开始启动的main函数处添加断点，自始至终地调试程序，查看完整程序运行脉络，所以下面推荐方法二。\n方法二、利用VS启动远程Linux机器上一个Linux程序文件进行调试。选择VS菜单【Debug】 -\u0026gt;【Quick Debugwith GDB】。 需要注意的地方，已经在上图中标红框。这里简单地解释一下：\n如果你安装了交叉编译环境Target可以选择MinGW/Cygwin，否则就选择远程Linux系统。这里如果不存在一个ssh连接，则需要创建一个。\nDebugged program是需要设置的被调试程序的路径，位于远程Linux机器上。\nArguments是该调试程序需要设置的命令行参数，如果被调试程序不需要命令行参数可以不设置。\nWorking directory是被调试程序运行的工作目录。\n另外建议勾选上Initial breakpoint in main，这样启动调试时，程序就会停在程序入口处。\n这样，我们就可以利用VS强大的功能去查看程序的各种状态了，常用的面板，如【内存】【线程】【观察】【堆栈】【GDB Session】【断点】等窗口位于VS 菜单【Debug】-\u0026gt;【Windows】菜单下，注意，有些窗口只有在调试状态下才可见。这里有两个值得强调一下的功能是：\nGDB Session****窗口，在这个窗口里面可以像原来直接使用gdb调试一样输入gdb指令来进行调试。 SSH console****窗口，这个窗口类似一个远程操作Linux系统的应用程序如xshell、SecureCRT。 现在还剩下一个问题，就是我们虽然在调试时可视化地远程查看一个Linux进程的状态信息，但很多类型的定义和什么却无法看到。解决这个问题的方法就是你可以先在VS里面建立一个工程，导入你要调试的程序的源代码目录。然后利用方法一或者方法二去启动调试程序。这个时候你想查看某个类型的定义或什么只要利用Visual Assit的查看源码功能即可，快捷键是Alt + G。\n需要注意的时：同时安装了Visual Assist和VisualGDB后，后者也会提供一个go按钮去查找源码定义，但这个功能远不如Visual Assist按钮好用，我们可以禁用掉它来使用Visual Assist的Go功能。禁用方法，打开菜单：【Tools】-\u0026gt;【Option\u0026hellip;】:\n然后重启VS即可。\n到这里，既可以查看源码，也可以调试程序了。\nVisualGDB 下载地址：\n链接：https://share.weiyun.com/57aGHLM 密码：kj9ahs\n","permalink":"https://haokiu.com/blog/f64c601f237d4cac97445aa4b0e07369/","summary":"用Visual Studio调试Linux程序 用Visual Studio调试Linux程序？你真的没看错，这个是真的，不是标题党。当然如果你说VS2015及以上版本自带的Linux调试插件，那就算了。这些自带的插件调试一个有简单的main函数程序还凑合，稍微复杂点的程序，根本无法编译调试。\n而本文介绍的主角是VS的另外一款插件Visual GDB，让我们欢迎主角登场，下面是正文。\n使用Visual Studio+VisualGDB调试远程Linux程序 需要工具：\nVisual Studio 2013或以上版本（以下简称VS） VisualGDB（一款VS插件，官网为：http://visualgdb.com/） 含有调试符号的Linux程序文件（该程序文件为调试目标） Visual Assistant（番茄助手，另外一款VS插件） 在VS上安装完VisualGDB插件以后，有如下几种方式来对远程Linux机器上的程序进行调试：\n**方法一、**如果该程序已经启动，则可以使用VS菜单【Debug】-\u0026gt;【Attach to Process\u0026hellip;】。 这种方法有个缺点是，不能从开始启动的main函数处添加断点，自始至终地调试程序，查看完整程序运行脉络，所以下面推荐方法二。\n方法二、利用VS启动远程Linux机器上一个Linux程序文件进行调试。选择VS菜单【Debug】 -\u0026gt;【Quick Debugwith GDB】。 需要注意的地方，已经在上图中标红框。这里简单地解释一下：\n如果你安装了交叉编译环境Target可以选择MinGW/Cygwin，否则就选择远程Linux系统。这里如果不存在一个ssh连接，则需要创建一个。\nDebugged program是需要设置的被调试程序的路径，位于远程Linux机器上。\nArguments是该调试程序需要设置的命令行参数，如果被调试程序不需要命令行参数可以不设置。\nWorking directory是被调试程序运行的工作目录。\n另外建议勾选上Initial breakpoint in main，这样启动调试时，程序就会停在程序入口处。\n这样，我们就可以利用VS强大的功能去查看程序的各种状态了，常用的面板，如【内存】【线程】【观察】【堆栈】【GDB Session】【断点】等窗口位于VS 菜单【Debug】-\u0026gt;【Windows】菜单下，注意，有些窗口只有在调试状态下才可见。这里有两个值得强调一下的功能是：\nGDB Session****窗口，在这个窗口里面可以像原来直接使用gdb调试一样输入gdb指令来进行调试。 SSH console****窗口，这个窗口类似一个远程操作Linux系统的应用程序如xshell、SecureCRT。 现在还剩下一个问题，就是我们虽然在调试时可视化地远程查看一个Linux进程的状态信息，但很多类型的定义和什么却无法看到。解决这个问题的方法就是你可以先在VS里面建立一个工程，导入你要调试的程序的源代码目录。然后利用方法一或者方法二去启动调试程序。这个时候你想查看某个类型的定义或什么只要利用Visual Assit的查看源码功能即可，快捷键是Alt + G。\n需要注意的时：同时安装了Visual Assist和VisualGDB后，后者也会提供一个go按钮去查找源码定义，但这个功能远不如Visual Assist按钮好用，我们可以禁用掉它来使用Visual Assist的Go功能。禁用方法，打开菜单：【Tools】-\u0026gt;【Option\u0026hellip;】:\n然后重启VS即可。\n到这里，既可以查看源码，也可以调试程序了。\nVisualGDB 下载地址：\n链接：https://share.weiyun.com/57aGHLM 密码：kj9ahs","title":"用Visual Studio调试Linux程序"},{"content":"程序员如何写简历 笔者工作多年后面试了很多公司，例如 2018 年年初横扫各大互联网公司，也作为面试官面试了很多人，看过不少的简历。现在疫情快过去了，很多小伙伴开始准备简历看新机会了，但是不少小伙伴遇到以下两种情况：\n投了很多公司，邀请面试的寥寥无几； 面试的时候被面试官问的哑口无言。 造成以上原因很大一部分是因为简历的问题，本文将结合自身的面试和被面试的经历和大家聊一聊简历怎么写。我们先来分析一些简历素材。\n简历一 这是一位毕业生的简历，大家看下这个简历存在什么问题？\n分析：\n简历中写了自己做的一个项目，项目描述中将该项目描述成 RPC、分布式网络框架，试问从项目描述来看，哪里体现出该项目使用了 RPC 框架和分布式？且不说没用到，就算用了，一般按大多数应届生的经验水平是很难在面试时经得住面试官在分布式等问题上的追问的，这非常容易给自己面试挖坑，一般校招或者对应届生的项目要求并不会太高，但是自己在简历中写上这些“分布式”、“RPC”等高大上的术语，如果实际并未掌握，只能是给自己埋雷。\n另外，求职者的项目是一个网络通信库，但是通信协议不是自己的（Protobuf），网络库也是别人的（Muduo），那这个项目有自己的东西吗？一般作为面试官对应届生没有多少项目经验是可以理解的，但是如果把别人的东西拿来自己加个壳，并写在简历中，这就没多大意义了。如果该同学尝试自己设计了一种通信协议，哪怕最终实现的不是很好，面试官也可能非常喜欢，因为融入了自己的创作和思考；退一步说，用 protobuf 也是可以的，如果面试时能说得清楚 protobuf 的序列化和反序列化的原理和该库的结构，也是 OK 的。\n面试结果：\n该同学在面试时因这个项目被面试官死怼，铩羽而归。\n简历二 分析：\n这个简历我第一眼看到之后，我猜想应该很少有 HR 或者猎头联系该同学面试吧，后来和当事人确认下，果不其然。该简历的问题有以下几点：\n简历中列举的技术栈非常多，如 Linux 、Shell、Python、C++、Golang、Django、Flask、Bootstrap、JQuery\u0026hellip;\u0026hellip;面试者真的掌握了这么多技术吗？另外，求职目标写的是“后端开发”，虽然 HR 可能不知道 Bootstrap、vue 等是前端技术，但技术面试官不知道吗？你一个求职后端职位的，你写许多前端技术干嘛？体现自己全栈吗？按作者的年龄和工作经历，很多技术只是了解或者使用过，并不一定掌握，且不说面试容易被问到而答不出来，最主要的是这份简历让人一看就觉得求职者没有自己专精的领域。说白了，啥可能都知道，但啥都没掌握好。所以大多数公司看到这样一份简历直接就 pass 掉了。 求职目标写的是“后端开发”，位置不够显眼，其次求职目标后端开发一词描述太泛，这位同学本意是求职 C++ 后台开发，但是这样一写，php、Java、golang、python 等不算后端开发吗？所以建议把求职的职位稍微缩小点范围。 面试结果：\n基本无面试邀请。\n简历三 分析\n同学醒醒，你已经毕业工作三年了，还把毕业的硕士论文贴到简历中。。。。。。问题是，你这个毕业论文中还有 “ demo” 字样，可能你的毕业论文获过奖，但是大多数 HR 和 面试官都看不懂里面的行业术语，但是一定能看懂 “demo” 这个词，demo 给大家的感觉好像高大上不起来吧。。。。。。 这位同学作为一个非科班（动物科学）转计算机行业的人，已经成功入行三年了，为啥还要把自己本科的专业放在这么明显的位置，是强调自己转行不易、很努力吗？- -! 如果你不是科班出身，或者不是名牌大学（清华、北大、复旦、武大等）毕业，尤其是毕业几年了，就不要把学历和毕业院校放在这么显眼的位置吧，可以放在“兴趣爱好”之前。 求职意向也是一样的问题； 技术专长描述的也不好，一般我们看用人单位的招聘信息，也都是先写通用技术后写专业领域的技术，所以通用技术指的是算法数据结构、操作系统原理、网络编程等等；专业的技术，指的是 C++、Java、golang、python 等语言、各种框架、开源软件等。 另外，如果长得不是特别帅的话，就不建议放自己的照片了。。。。。。 简历四 分析\n这个简历看完我是真的醉了。\n大哥，我知道你没有拿得出手的项目经历和技术，可是你求职的是开发岗位，你也不至于把饲养猪的经历写进简历吧，虽然有些大厂自己给员工养猪吃，但是程序开发和养猪毕竟是两码事吧。。。。。。\n简历五 分析\n这份简历的项目描述也得太详细了，尤其是业务部分，感觉像项目招标书或者项目售前方案。。如果你求职的是技术开发类岗位，且你求职的下家公司与你简历中的项目不是同一个类型，那就把项目业务内容写得简略点，描述项目经历时多写一些技术内容。。。。。。说实话这份简历适合去应聘项目经理，尤其是公路局的项目经理。。。。。。\n简历六 分析\n这是一位大哥的简历，大哥已经工作十三年了，请读者看看这个项目经历描述是否有 13 年的水平？这项目描述实在太细了，首先可能把之前公司的商业技术机密全部泄露了。。。。。其次，和上面的简历六一样，多写点技术内容少写点业务内容不行吗，简历六可以应聘项目经理，这份简历可以应聘产品经理。。。。。。需求写的太细了，你确定是要找后端开发吗。。。。。。\n简历七 分析\n人常说，一份文案的整洁程度可以反映一个人的细致程度。这份简历存在两个问题：\n个人技能这一块分类很混乱，例如“掌握 C++ 应用，理解底层原理,部分 c11 特性”中底层原理和 C++ 应用有什么关系，完全可以分开写嘛，另外 C++11已经目前已经被广泛使用，如果你不熟悉就不要写，写熟悉部分是熟悉多少？是告诉面试官自己这方面掌握的不好吗？原本面试时面试官可能不会问，看到这个可能说不定忍不住问几个 C++11 的东西；“多线程，同步，ipc通信等”中的“同步”难道不是针对多线程讲的吗？“熟悉设计模式、策略模式、单例模式、工厂模式”中策略模式、单例模式、工厂模式难道不是设计模式的一种吗？为何和设计模式一起用顿号并列起来？ 简历中标点符号一会儿中文的逗号，一会儿英文的逗号，像 C++、Linux 这样的专用名词一会儿首字母大写，一会儿小写，导致整个排版脏乱不堪。 总结 成功的方法都差不多，错误的情形千奇百怪。因文章篇幅，就不贴更多的简历了，看完上面七份简历，你是否也有类似的情形呢？下面给大家总结一下投递简历注意事项和如何写技术简历。\n**一、**投递简历时，如果投递到企业或者 HR 的邮箱，一定要在邮件主题中写清楚来意，一般是【XXX 求职或者应聘 XXX 职位】，例如【张小方应聘后端 C++ 开发岗位】，不然邮件很容易被忽略或者被邮件垃圾过滤系统所过滤，简历根本到不了 HR 或者面试官手里；简历附件的文件名尽量写清楚附件的内容，如 【XXX 求职 XXX 岗位】.pdf/doc/docx 的简历，如【张小方应聘字节跳动资深开发的简历】.pdf。切记文件不要出现类似“新建文件夹.pdf”、“新建压缩包.zip”、“1111.doc”、“简历.pdf”这样的文件命名，被 HR 下载后放在电脑上难以寻找，给别人阅读你的简历造成不便。\n**二、**如果你是通过微信、QQ 等 IM 工具发给别人的简历，在求职期间为了方便交流，一定不要把自己的微信昵称、QQ 名、头像设置成不易识别的非主流名，如微信名设置成一片空白或者一片空白的头像或者根本很难搜索或者 at 出来的名字。举个例子，笔者曾见过一个面试者把自己的头像设置成一张母猪头，我原本计划和这位求职者多聊几句，看到这种头像实感不适，只好放弃。大家都很忙，尤其是在候选人众多的情况下，没人愿意在你身上因为这种问题花过多的时间。当然，如果你对那些特别的 IM 昵称有特殊的嗜好，建议在求职期间改成正常的，等找到工作后再改回去。\n成年人的世界，没人会刻意迁就你，方便别人等于给自己机会。\n**三、**简历中不要出现病句、错误的标点符号，尤其不要把一些重要的技术名词写错，非行首非行末的英文单词或者数字左右各一个空格。\n**四、**简历的首部把自己的联系信息写清楚，不要写许多非重要信息，一般写上自己的姓名、电话、邮箱、性别、年龄、求职意向即可，像身高、体重啥的就别写了，没人对你身高、体重感兴趣。。。。。。另外不要留一些让人产生分裂印象的联系方式，如姓名和邮箱明显感觉不是一个人，如你的姓名是你自己，你的邮箱联系地址像你的老婆的\u0026hellip;..\n**五、**如果你不是科班出身或者不是名校出身，尤其是非应届生，就不要把你的教育经历放在简历醒目位置，一般建议把教育经历放到简历尾部。教育经历一定不要作假哦。\n**六、**定位清楚自己求职的职位，如一般不要写求职“软件开发”、“后端开发”这样的字眼，这样的求职意向描述范围太宽泛了，既不利于企业筛选，也降低了你的获得面试邀请的机会。建议写成“C++ 软件开发”、“JAVA 后端开发”、“Linux C++ 后端开发 ”等具体职位描述。\n**七、**写自己的技术栈的时候，要根据技术类型分清楚，尽量把不相关的技术分成不同的条目，先写通用技术再写专业的技术，最后写业务技术，下面是一份样例：\n1. 熟悉常用的算法和数据结构； 2. 熟悉多线程编程技术，熟悉常见的线程同步、进程通信技术； 3. 熟悉网络编程，熟悉 TCP/IP 通信原理，熟悉 HTTP、FTP 等常用协议； 4. 熟悉 C/C++，熟悉 C++11，良好的面向对象思维和编码风格； 5. 熟悉 Linux 系统常用操作，熟练使用 gcc/gdb 等 Linux 下开发工具； 6. 熟悉 mysql、redis 等数据库原理，熟悉常见数据库调优技术； 7. 熟悉 kafka、RabbitMQ 等消息中间件； 8. 熟悉金融交易系统，有大宗交易系统开发经验。 **八、**从业经历建议分成工作经历和项目经历，工作经历写清楚从某年某月到某年某月你在哪家公司担任某某职位即可，项目经历介绍你的具体项目经历，如果你投递的下家公司和你的项目的业务是同行或者类似行业，可以多写一点项目业务介绍，反之粗略的交代下项目的背景、业务内容即可，多写点技术描述，写清楚你在这个项目中利用何种技术解决了或者达到了或者实现了什么效果，或者给公司或团队带来了什么收益，或者写你在该项目中遇到技术难题的攻关过程，千万不要写类似“通过该项目，我学习到了XXX”，企业招你来是干活的不是专门给你学习的，你给企业干活企业给你付工资，你这样写，是想不拿工资还给企业交学费吗？\n项目中的技术描述要根据求职职位做一些收敛，尽量写自己掌握的或者熟悉的技术术语，这样一定程度上可以在面试时把面试话题往自己熟悉的技术栈上引；少出现自己不熟悉的技术栈或者技术术语，这样面试时容易出错，甚至出现不知所措的场景。\n如果你的工作经历不长，你在项目中的角色可能是负责单个服务或者单个服务中的部分模块，此时写项目经历时可以多写点技术细节，如网络通信的协议细节、队列数据交换的设计细节、程序对数据加工的细节等等；但是如果你已经工作三年及以上的高级开发者，描写项目经历时，要侧重写一点对项目整体的框架或者架构的认知，如消息在各个服务中的流转过程、每个服务的作用、核心服务的结构、技术重难点等等。千万不要再像记流水账一样交代每个技术细节。\n描述技术栈时针对自己求职的公司职位或者求职意向来写，例如求职开发职位，就弱化一些自己曾经做过的一些测试、运维或者项目经理的工作描述；求职后端开发，就不要写类似于 MFC、QT、VUE 等技术术语了；求职 Java 开发，就不要在简历中大写特写 C++、Python 等其他语种的项目或模块经历。尤其不要写与职位无关的经历，如果存在的话可以一笔带过。\n项目描述中不要泄露之前公司的机密信息。\n针对自己心仪的公司，要准备专门的简历，不要一份简历到处投递。\n**九、**如果你有一些出色的开源项目或者已经发布的、可以被公众看到的产品展示，可以在简历中附上 GitHub 地址、技术博客地址或者项目上线地址。有的求职者博客少有高质量原创，或者 GitHub 的项目工程组织、代码风格混乱，甚至只有一个 README.md，这种就不要往简历中写了。大凡面试官看到求职者贴了技术博客或者 GitHub 地址都会要打开看一下的。\n**十、**自我描述或者自我评价建议写一些积极的、与工作、学习相关的，例如乐观好学、沟通能力、组织能力、团队合作能力，不要写一些无关紧要的，或者自曝短处的描述，如喜欢玩英雄联盟，有强迫症，爱与人较真等。\n限于笔者经验水平有限，文中一家之言难免有失偏颇，欢迎读者友善的提出自己的建议和意见，另外感谢文中提供简历精彩出演的各位知识星球小伙伴。\n","permalink":"https://haokiu.com/blog/9c853d8576774df7ad52d79d740d95f1/","summary":"程序员如何写简历 笔者工作多年后面试了很多公司，例如 2018 年年初横扫各大互联网公司，也作为面试官面试了很多人，看过不少的简历。现在疫情快过去了，很多小伙伴开始准备简历看新机会了，但是不少小伙伴遇到以下两种情况：\n投了很多公司，邀请面试的寥寥无几； 面试的时候被面试官问的哑口无言。 造成以上原因很大一部分是因为简历的问题，本文将结合自身的面试和被面试的经历和大家聊一聊简历怎么写。我们先来分析一些简历素材。\n简历一 这是一位毕业生的简历，大家看下这个简历存在什么问题？\n分析：\n简历中写了自己做的一个项目，项目描述中将该项目描述成 RPC、分布式网络框架，试问从项目描述来看，哪里体现出该项目使用了 RPC 框架和分布式？且不说没用到，就算用了，一般按大多数应届生的经验水平是很难在面试时经得住面试官在分布式等问题上的追问的，这非常容易给自己面试挖坑，一般校招或者对应届生的项目要求并不会太高，但是自己在简历中写上这些“分布式”、“RPC”等高大上的术语，如果实际并未掌握，只能是给自己埋雷。\n另外，求职者的项目是一个网络通信库，但是通信协议不是自己的（Protobuf），网络库也是别人的（Muduo），那这个项目有自己的东西吗？一般作为面试官对应届生没有多少项目经验是可以理解的，但是如果把别人的东西拿来自己加个壳，并写在简历中，这就没多大意义了。如果该同学尝试自己设计了一种通信协议，哪怕最终实现的不是很好，面试官也可能非常喜欢，因为融入了自己的创作和思考；退一步说，用 protobuf 也是可以的，如果面试时能说得清楚 protobuf 的序列化和反序列化的原理和该库的结构，也是 OK 的。\n面试结果：\n该同学在面试时因这个项目被面试官死怼，铩羽而归。\n简历二 分析：\n这个简历我第一眼看到之后，我猜想应该很少有 HR 或者猎头联系该同学面试吧，后来和当事人确认下，果不其然。该简历的问题有以下几点：\n简历中列举的技术栈非常多，如 Linux 、Shell、Python、C++、Golang、Django、Flask、Bootstrap、JQuery\u0026hellip;\u0026hellip;面试者真的掌握了这么多技术吗？另外，求职目标写的是“后端开发”，虽然 HR 可能不知道 Bootstrap、vue 等是前端技术，但技术面试官不知道吗？你一个求职后端职位的，你写许多前端技术干嘛？体现自己全栈吗？按作者的年龄和工作经历，很多技术只是了解或者使用过，并不一定掌握，且不说面试容易被问到而答不出来，最主要的是这份简历让人一看就觉得求职者没有自己专精的领域。说白了，啥可能都知道，但啥都没掌握好。所以大多数公司看到这样一份简历直接就 pass 掉了。 求职目标写的是“后端开发”，位置不够显眼，其次求职目标后端开发一词描述太泛，这位同学本意是求职 C++ 后台开发，但是这样一写，php、Java、golang、python 等不算后端开发吗？所以建议把求职的职位稍微缩小点范围。 面试结果：\n基本无面试邀请。\n简历三 分析\n同学醒醒，你已经毕业工作三年了，还把毕业的硕士论文贴到简历中。。。。。。问题是，你这个毕业论文中还有 “ demo” 字样，可能你的毕业论文获过奖，但是大多数 HR 和 面试官都看不懂里面的行业术语，但是一定能看懂 “demo” 这个词，demo 给大家的感觉好像高大上不起来吧。。。。。。 这位同学作为一个非科班（动物科学）转计算机行业的人，已经成功入行三年了，为啥还要把自己本科的专业放在这么明显的位置，是强调自己转行不易、很努力吗？- -! 如果你不是科班出身，或者不是名牌大学（清华、北大、复旦、武大等）毕业，尤其是毕业几年了，就不要把学历和毕业院校放在这么显眼的位置吧，可以放在“兴趣爱好”之前。 求职意向也是一样的问题； 技术专长描述的也不好，一般我们看用人单位的招聘信息，也都是先写通用技术后写专业领域的技术，所以通用技术指的是算法数据结构、操作系统原理、网络编程等等；专业的技术，指的是 C++、Java、golang、python 等语言、各种框架、开源软件等。 另外，如果长得不是特别帅的话，就不建议放自己的照片了。。。。。。 简历四 分析\n这个简历看完我是真的醉了。\n大哥，我知道你没有拿得出手的项目经历和技术，可是你求职的是开发岗位，你也不至于把饲养猪的经历写进简历吧，虽然有些大厂自己给员工养猪吃，但是程序开发和养猪毕竟是两码事吧。。。。。。\n简历五 分析\n这份简历的项目描述也得太详细了，尤其是业务部分，感觉像项目招标书或者项目售前方案。。如果你求职的是技术开发类岗位，且你求职的下家公司与你简历中的项目不是同一个类型，那就把项目业务内容写得简略点，描述项目经历时多写一些技术内容。。。。。。说实话这份简历适合去应聘项目经理，尤其是公路局的项目经理。。。。。。\n简历六 分析\n这是一位大哥的简历，大哥已经工作十三年了，请读者看看这个项目经历描述是否有 13 年的水平？这项目描述实在太细了，首先可能把之前公司的商业技术机密全部泄露了。。。。。其次，和上面的简历六一样，多写点技术内容少写点业务内容不行吗，简历六可以应聘项目经理，这份简历可以应聘产品经理。。。。。。需求写的太细了，你确定是要找后端开发吗。。。。。。\n简历七 分析\n人常说，一份文案的整洁程度可以反映一个人的细致程度。这份简历存在两个问题：\n个人技能这一块分类很混乱，例如“掌握 C++ 应用，理解底层原理,部分 c11 特性”中底层原理和 C++ 应用有什么关系，完全可以分开写嘛，另外 C++11已经目前已经被广泛使用，如果你不熟悉就不要写，写熟悉部分是熟悉多少？是告诉面试官自己这方面掌握的不好吗？原本面试时面试官可能不会问，看到这个可能说不定忍不住问几个 C++11 的东西；“多线程，同步，ipc通信等”中的“同步”难道不是针对多线程讲的吗？“熟悉设计模式、策略模式、单例模式、工厂模式”中策略模式、单例模式、工厂模式难道不是设计模式的一种吗？为何和设计模式一起用顿号并列起来？ 简历中标点符号一会儿中文的逗号，一会儿英文的逗号，像 C++、Linux 这样的专用名词一会儿首字母大写，一会儿小写，导致整个排版脏乱不堪。 总结 成功的方法都差不多，错误的情形千奇百怪。因文章篇幅，就不贴更多的简历了，看完上面七份简历，你是否也有类似的情形呢？下面给大家总结一下投递简历注意事项和如何写技术简历。\n**一、**投递简历时，如果投递到企业或者 HR 的邮箱，一定要在邮件主题中写清楚来意，一般是【XXX 求职或者应聘 XXX 职位】，例如【张小方应聘后端 C++ 开发岗位】，不然邮件很容易被忽略或者被邮件垃圾过滤系统所过滤，简历根本到不了 HR 或者面试官手里；简历附件的文件名尽量写清楚附件的内容，如 【XXX 求职 XXX 岗位】.","title":"程序员如何写简历"},{"content":"程序员必知必会的网络命令 利用telnet命令发电子邮件\n做Java或者C++开发都应该知道的lsof命令\nLinux网络故障排查的瑞士军刀nc命令\nLinux tcpdump使用详解\n从抓包的角度分析connect函数的连接过程\n服务器开发中网络数据分析与故障排查经验漫谈\n","permalink":"https://haokiu.com/blog/2137687badbe411cac56094071bcc338/","summary":"程序员必知必会的网络命令 利用telnet命令发电子邮件\n做Java或者C++开发都应该知道的lsof命令\nLinux网络故障排查的瑞士军刀nc命令\nLinux tcpdump使用详解\n从抓包的角度分析connect函数的连接过程\n服务器开发中网络数据分析与故障排查经验漫谈","title":"程序员必知必会的网络命令"},{"content":"程序员的烦心事 拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？\n我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？\n","permalink":"https://haokiu.com/blog/e11a027d307841d9b515ac4b1670037c/","summary":"程序员的烦心事 拒绝了一家公司的offer后，他们的副总和hr总监同时打电话来询问拒绝原因并极力要求加入，我该不该去？\n我是一名程序员，结婚时女友要求我用两年的工资作为彩礼，我该不该答应？","title":"程序员的烦心事"},{"content":"程序员的薪资与年终奖那些事儿 技术面试与HR谈薪资技巧\n聊一聊程序员如何增加收入\n谈一谈年终奖\n","permalink":"https://haokiu.com/blog/18d3e73501ef4be092520d6f5991517f/","summary":"程序员的薪资与年终奖那些事儿 技术面试与HR谈薪资技巧\n聊一聊程序员如何增加收入\n谈一谈年终奖","title":"程序员的薪资与年终奖那些事儿"},{"content":"程序员面试题精讲 腾讯后台开发实习生技能要求\n聊聊如何拿大厂的 offer\n网络通信题目集锦\n我面试后端开发经理的经历\nLinux C/C++后端开发面试问哪些问题\n","permalink":"https://haokiu.com/blog/c092595334ac4b29914e418b3aae0648/","summary":"程序员面试题精讲 腾讯后台开发实习生技能要求\n聊聊如何拿大厂的 offer\n网络通信题目集锦\n我面试后端开发经理的经历\nLinux C/C++后端开发面试问哪些问题","title":"程序员面试题精讲"},{"content":"网络编程 bind 函数重难点解析\nconnect 函数在阻塞和非阻塞模式下的行为\nselect 函数重难点解析\nLinux epoll 模型（含LT 模式和 ET 模式详解）\nsocket 的阻塞模式和非阻塞模式\n非阻塞模式下 send 和 recv 函数的返回值\n服务器开发通信协议设计介绍\nTCP 协议如何解决粘包、半包问题\n网络通信中收发数据的正确姿势\n服务器端发数据时，如果对端一直不收，怎么办？\n","permalink":"https://haokiu.com/blog/6e60982d515240e4b34e2f0e22647f58/","summary":"网络编程 bind 函数重难点解析\nconnect 函数在阻塞和非阻塞模式下的行为\nselect 函数重难点解析\nLinux epoll 模型（含LT 模式和 ET 模式详解）\nsocket 的阻塞模式和非阻塞模式\n非阻塞模式下 send 和 recv 函数的返回值\n服务器开发通信协议设计介绍\nTCP 协议如何解决粘包、半包问题\n网络通信中收发数据的正确姿势\n服务器端发数据时，如果对端一直不收，怎么办？","title":"网络编程"},{"content":"网络通信中收发数据的正确姿势 在网络通信中，我们可能既要通过 socket 去发送数据也要通过 socket 来收取数据。那么一般的网络通信框架是如何收发数据的呢？注意，这里讨论的范围是基于各种 IO 复用函数（select、poll、epoll 等）来判断 socket 读写来收发数据，其他情形比较简单，这里就不提了。\n我们这里以服务器端为例。服务器端接受客户端连接后，产生一个与客户端连接对应的 socket（Linux 下也叫 fd，为了叙述方便，以后称之为 clientfd），我们可以通过这个 clientfd 收取从客户端发来的数据，也可以通过这个 clientfd 将数据发往客户端。但是收与发在操作流程上是有明显的区别的。\n收数据的正确姿势 对于收数据，当接受连接成功得到 clientfd 后，我们会将该 clientfd 绑定到相应的 IO 复用函数上并监听其可读事件。不同的 IO 复用函数可读事件标志不一样，例如对于 poll 模型，可读标志是 POLLIN，对于 epoll 模型，可读事件标志是 EPOLLIN。当可读事件触发后，我们调用 recv 函数从 clientfd 上收取数据（这里不考虑出错的情况），根据不同的网络模式我们可能会收取部分，或一次性收完。收取到的数据我们会放入接收缓冲区内，然后做解包操作。这就是收数据的全部“姿势”。对于使用 epoll 的 LT 模式（水平触发模式），我们每次可以只收取部分数据；但是对于 ET 模式（边缘触发模式），我们必须将本次收到的数据全部收完。\nET 模式收完的标志是 recv 或者 read 函数的返回值是 -1，错误码是 EWOULDBLOCK，针对 Windows 和 Linux 下区别，前面章节已经详细地说过了。\n这就是读数据的全部姿势。流程图如下：\n发数据的正确姿势 对于发数据，除了 epoll 模型的 ET 模式外，epoll 的 LT 模式或者其他 IO 复用函数，我们通常都不会去注册监听该 clientfd 的可写事件。这是因为，只要对端正常收数据，一般不会出现 TCP 窗口太小导致 send 或 write 函数无法写的问题。因此大多数情况下，clientfd 都是可写的，如果注册了可写事件，会导致一直触发可写事件，而此时不一定有数据需要发送。故而，如果有数据要发送一般都是调用 send 或者 write 函数直接发送，如果发送过程中， send 函数返回 -1，并且错误码是 EWOULDBLOCK 表明由于 TCP 窗口太小数据已经无法写入时，而仍然还剩下部分数据未发送，此时我们才注册监听可写事件，并将剩余的服务存入自定义的发送缓冲区中，等可写事件触发后再接着将发送缓冲区中剩余的数据发送出去，如果仍然有部分数据不能发出去，继续注册可写事件，当已经无数据需要发送时应该立即移除对可写事件的监听。这是目前主流网络库的做法。\n流程图如下：\n上述逻辑示例如下：\n直接尝试发送消息处理逻辑：\n/** *@param data 待发送的数据 *@param len 待发送数据长度 */ void TcpConnection::sendMessage(const void* data, size_t len) { int32_t nwrote = 0; size_t remaining = len; bool faultError = false; if (state_ == kDisconnected) { LOGW(\u0026#34;disconnected, give up writing\u0026#34;); return; } // 当前未监听可写事件，且发送缓冲区中没有遗留数据 if (!channel_-\u0026gt;isWriting() \u0026amp;\u0026amp; outputBuffer_.readableBytes() == 0) { //直接发送数据 nwrote = sockets::write(channel_-\u0026gt;fd(), data, len); if (nwrote \u0026gt;= 0) { remaining = len - nwrote; } else // nwrote \u0026lt; 0 { nwrote = 0; //错误码不等于EWOULDBLOCK说明发送出错了 if (errno != EWOULDBLOCK) { LOGSYSE(\u0026#34;TcpConnection::sendInLoop\u0026#34;); if (errno == EPIPE || errno == ECONNRESET) { faultError = true; } } } } //发送未出错且还有剩余字节未发出去 if (!faultError \u0026amp;\u0026amp; remaining \u0026gt; 0) { //将剩余部分加入发送缓冲区 outputBuffer_.append(static_cast\u0026lt;const char*\u0026gt;(data) + nwrote, remaining); if (!channel_-\u0026gt;isWriting()) { //注册可写事件 channel_-\u0026gt;enableWriting(); } } } 不能全部发出去监听可写事件后，可写事件触发后处理逻辑：\n//可写事件触发后会调用handleWrite()函数 void TcpConnection::handleWrite() { //将发送缓冲区中的数据发送出去 int32_t n = sockets::write(channel_-\u0026gt;fd(), outputBuffer_.peek(), outputBuffer_.readableBytes()); if (n \u0026gt; 0) { //发送多少从发送缓冲区移除多少 outputBuffer_.retrieve(n); //如果发送缓冲区中已经没有剩余，则移除监听可写事件 if (outputBuffer_.readableBytes() == 0) { //移除监听可写事件 channel_-\u0026gt;disableWriting(); if (state_ == kDisconnecting) { shutdown(); } } } else { //发数据出错处理 LOGSYSE(\u0026#34;TcpConnection::handleWrite\u0026#34;); handleClose(); } } 对于 epoll LT 模式注册监听一次可写事件后，可写事件触发后，尝试发送数据，如果数据此时还不能全部发送完，不用再次注册可写事件；如果是 epoll 的 ET 模式，注册监听可写事件后，可写事件触发后，尝试发送数据，如果数据此时还不能全部发送完，需要再次注册可写事件以便让可写事件下次再次触发（给予再次发数据的机会）。当然，这只是理论上的情况，实际开发中，如果一段数据反复发送都不能完全发送完（例如对端先不收，后面每隔很长时间再收一个字节），我们可以设置一个最大发送次数或最大发送总时间，超过这些限定，我们可以认为对端出了问题，应该立即清空发送缓冲区并关闭连接。\n本节的标题是“收发数据的正确姿势”，其实还可以换一种说法，即“检测网络事件的正确姿势”，这里意指检测一个 fd 的读写事件的区别（对于侦听 fd，只检测可读事件）：\n在 select、poll 和 epoll 的 LT 模式下，可以直接设置检测 fd 的可读事件； 在 select、poll 和 epoll 的 LT 模式下不要直接设置检测 fd 的可写事件，应该先尝试发送数据，因为 TCP 窗口太小发不出去再设置检测 fd 的可写事件，一旦数据发出去应立即取消对可写事件的检测。 在 epoll 的 ET 模式下，需要发送数据时，每次都要设置检测可写事件。 ","permalink":"https://haokiu.com/blog/ec34cfea56f74c0d9a622ef5cbc4f812/","summary":"网络通信中收发数据的正确姿势 在网络通信中，我们可能既要通过 socket 去发送数据也要通过 socket 来收取数据。那么一般的网络通信框架是如何收发数据的呢？注意，这里讨论的范围是基于各种 IO 复用函数（select、poll、epoll 等）来判断 socket 读写来收发数据，其他情形比较简单，这里就不提了。\n我们这里以服务器端为例。服务器端接受客户端连接后，产生一个与客户端连接对应的 socket（Linux 下也叫 fd，为了叙述方便，以后称之为 clientfd），我们可以通过这个 clientfd 收取从客户端发来的数据，也可以通过这个 clientfd 将数据发往客户端。但是收与发在操作流程上是有明显的区别的。\n收数据的正确姿势 对于收数据，当接受连接成功得到 clientfd 后，我们会将该 clientfd 绑定到相应的 IO 复用函数上并监听其可读事件。不同的 IO 复用函数可读事件标志不一样，例如对于 poll 模型，可读标志是 POLLIN，对于 epoll 模型，可读事件标志是 EPOLLIN。当可读事件触发后，我们调用 recv 函数从 clientfd 上收取数据（这里不考虑出错的情况），根据不同的网络模式我们可能会收取部分，或一次性收完。收取到的数据我们会放入接收缓冲区内，然后做解包操作。这就是收数据的全部“姿势”。对于使用 epoll 的 LT 模式（水平触发模式），我们每次可以只收取部分数据；但是对于 ET 模式（边缘触发模式），我们必须将本次收到的数据全部收完。\nET 模式收完的标志是 recv 或者 read 函数的返回值是 -1，错误码是 EWOULDBLOCK，针对 Windows 和 Linux 下区别，前面章节已经详细地说过了。\n这就是读数据的全部姿势。流程图如下：\n发数据的正确姿势 对于发数据，除了 epoll 模型的 ET 模式外，epoll 的 LT 模式或者其他 IO 复用函数，我们通常都不会去注册监听该 clientfd 的可写事件。这是因为，只要对端正常收数据，一般不会出现 TCP 窗口太小导致 send 或 write 函数无法写的问题。因此大多数情况下，clientfd 都是可写的，如果注册了可写事件，会导致一直触发可写事件，而此时不一定有数据需要发送。故而，如果有数据要发送一般都是调用 send 或者 write 函数直接发送，如果发送过程中， send 函数返回 -1，并且错误码是 EWOULDBLOCK 表明由于 TCP 窗口太小数据已经无法写入时，而仍然还剩下部分数据未发送，此时我们才注册监听可写事件，并将剩余的服务存入自定义的发送缓冲区中，等可写事件触发后再接着将发送缓冲区中剩余的数据发送出去，如果仍然有部分数据不能发出去，继续注册可写事件，当已经无数据需要发送时应该立即移除对可写事件的监听。这是目前主流网络库的做法。\n流程图如下：\n上述逻辑示例如下：\n直接尝试发送消息处理逻辑：\n/** *@param data 待发送的数据 *@param len 待发送数据长度 */ void TcpConnection::sendMessage(const void* data, size_t len) { int32_t nwrote = 0; size_t remaining = len; bool faultError = false; if (state_ == kDisconnected) { LOGW(\u0026#34;disconnected, give up writing\u0026#34;); return; } // 当前未监听可写事件，且发送缓冲区中没有遗留数据 if (!","title":"网络通信中收发数据的正确姿势"},{"content":"网络通信面试题集锦 TCP/IP协议栈层次结构\nTCP三次握手需要知道的细节点\nTCP四次挥手需要知道的细节点(CLOSE_WAIT、TIME_WAIT、MSL)\nTCP与UDP的区别与适用场景\nlinux常见网络模型详解(select、poll与epoll)\nepoll_event结构中的epoll_data_t的fd与ptr的使用场景\nWindows常见的网络模型详解(select、WSAEventSelect、WSAAsyncSelect)\nWindows上的完成端口模型(IOCP)\n异步的connect函数如何编写\nselect函数可以检测网络异常吗？\nepoll的水平模式和边缘模式\n如何将socket设置成非阻塞的(创建时设置与创建完成后设置)，非阻塞socket与阻塞的socket在收发数据上的区别\nsend/recv(read/write)返回值大于0、等于0、小于0的区别\n如何编写正确的收数据代码与发数据代码\n发送数据缓冲区与接收数据缓冲区如何设计\nsocket选项SO_SNDTIMEO和SO_RCVTIMEO\nsocket选项TCP_NODELAY\nsocket选项SO_REUSEADDR和SO_REUSEPORT（Windows平台与linux平台的区别）\nsocket选项SO_LINGER\nshutdown与优雅关闭\nsocket选项SO_KEEPALIVE\n关于错误码EINTR\n如何解决tcp粘包问题\n信号SIGPIPE与EPIPE错误码\ngethostbyname阻塞与错误码获取问题\n心跳包的设计技巧（保活心跳包与业务心跳包）\n断线重连机制如何设计\n如何检测对端已经关闭\n如何清除无效的死链（端与端之间的线路故障）\n定时器的不同实现及优缺点\nhttp协议的具体格式\nhttp head、get与post方法的细节\nhttp代理、socks4代理与socks5代理如何编码实现\nping\ntelnet\n关于以上问题的答案，有兴趣可以参考我的知乎live：https://www.zhihu.com/lives/922110858308485120\n或者如果你有任何不明白的地方，可以加我微信 easy_coder 交流。\n","permalink":"https://haokiu.com/blog/eb4b0ccb7b2942b989b3655d832bb0e0/","summary":"网络通信面试题集锦 TCP/IP协议栈层次结构\nTCP三次握手需要知道的细节点\nTCP四次挥手需要知道的细节点(CLOSE_WAIT、TIME_WAIT、MSL)\nTCP与UDP的区别与适用场景\nlinux常见网络模型详解(select、poll与epoll)\nepoll_event结构中的epoll_data_t的fd与ptr的使用场景\nWindows常见的网络模型详解(select、WSAEventSelect、WSAAsyncSelect)\nWindows上的完成端口模型(IOCP)\n异步的connect函数如何编写\nselect函数可以检测网络异常吗？\nepoll的水平模式和边缘模式\n如何将socket设置成非阻塞的(创建时设置与创建完成后设置)，非阻塞socket与阻塞的socket在收发数据上的区别\nsend/recv(read/write)返回值大于0、等于0、小于0的区别\n如何编写正确的收数据代码与发数据代码\n发送数据缓冲区与接收数据缓冲区如何设计\nsocket选项SO_SNDTIMEO和SO_RCVTIMEO\nsocket选项TCP_NODELAY\nsocket选项SO_REUSEADDR和SO_REUSEPORT（Windows平台与linux平台的区别）\nsocket选项SO_LINGER\nshutdown与优雅关闭\nsocket选项SO_KEEPALIVE\n关于错误码EINTR\n如何解决tcp粘包问题\n信号SIGPIPE与EPIPE错误码\ngethostbyname阻塞与错误码获取问题\n心跳包的设计技巧（保活心跳包与业务心跳包）\n断线重连机制如何设计\n如何检测对端已经关闭\n如何清除无效的死链（端与端之间的线路故障）\n定时器的不同实现及优缺点\nhttp协议的具体格式\nhttp head、get与post方法的细节\nhttp代理、socks4代理与socks5代理如何编码实现\nping\ntelnet\n关于以上问题的答案，有兴趣可以参考我的知乎live：https://www.zhihu.com/lives/922110858308485120\n或者如果你有任何不明白的地方，可以加我微信 easy_coder 交流。","title":"网络通信面试题集锦"},{"content":"聊一聊程序员如何增加收入 亲爱的读者朋友，你好。我是高性能服务器开发公众号的作者，范蠡。一些老的读者应该知道，我有个同名 QQ 群叫高性能服务器开发（研究）群，目前两个群加在一起，也快五千人了吧。很多群友不止一次的想了解我的收入情况，粗略的算了一下，今年一年到目前为止，大概有一百万。然而，这种程度的收入在上海这样的城市，依旧是买不起房，解决不了生活的大问题，比上不足比下有余吧。\n咱公众号的大多数读者应该都是从事程序开发或者相关的，你或许在北京上海深圳，或许在南京武汉广州，或许在郑州合肥，或许在其他一些二线三线城市。大多数程序员其实是单纯而又朴实的，晚上可能在骂老板抠门、产品经理SB，但明天早上依然会早起去挤地铁，认真写每一行代码，因为高堂明镜悲白发，朝如青丝暮成雪，一天天老去的父母，需要我们赡养；\u0026ldquo;笑看妻子愁何在，漫卷诗书喜欲狂”，一天天长大的孩子，需要我们去养育。哪个程序员曾经不是不为五斗米而折腰的男子，如今却不得过着李白洗尿布一样的生活？所以，尽管有时候我们有千万种不愿意，但还是不得说这言不由衷的话，做着自己不想做的事情——因为我们缺钱。\n今天，我们就和大家讨论一下程序员如何提高收入，当然，由于个人经历经验有限，难免是一家之言，文中内容仅供参考，欢迎温和地提出意见和建议。\n程序员们的主要收入来源 这个标题其实不言自明的，程序员们，当然对于大多数上班族，工作是收入的主要来源。看到群里很多学生讨论 offer 薪资的时候，动辄就月薪 30 k 甚至如 45 k以及更高的，虽然不排除确实存在这一类的 SP 或者 SSP offer。但是大多数人会是这类高收入者或者幸运儿吗？月薪 30 k 意味着什么？意味着在一个小城市两口之家半年多的生活费，意味着在中国广大农村一家两三年的生活成本。老板都不是傻子，你能干多少活才会给你多少钱，那么 30 k 需要干多少活呢？其他的城市我不熟悉，以我所在的上海为例吧，对于一般学校毕业的应届毕业生月薪 5 k 起步，硕士会稍微高上 3～5 k，工作两年月薪在 12k～16k 之间，工作四五年月薪在 20 k ～26 k 之间，达到 30 k 及以上，一般需要工作七八年以上。如果较短工作年限，需要达到较高收入水平的，都是技术非常好或者能力特别强的。我工作三多年时，在一家做公司做音视频实时通讯技术，月薪 26 k。但是工作内容和工作量就很大，当时负责 pc 、安卓、iOS、mac 四个端的 C++ sdk 开发和维护，同时负责这几个端的 Java sdk 开发，每天需要处理多家客户使用这些 sdk 报的各种问题。每天晚上九点下班，被项目经理看到，她会说，你今天下班真早啊。我印象深刻的是，那一年春节，从年二十五到正月初六每天早上九点，我需要准时参加公司的项目会议，汇报项目状况和进度，每天二十四小时要随时响应。\n我们大多人毕业学校一般、学历也一般，而且也不是特别努力，本身存在\u0026quot;先天不足”。高中或者大学不努力，毕业后本来起点就比名校或者努力的同学差上一截，这一截可能不是 0.1 到 0.11 的距离，可能是 0.1 到 10 的距离。哈佛大学有句校训是这样写的：今天不走，明天要跑。这句话是很有道理的，你从前不努力的阿喀琉斯之踵，可能在短期内对你没多少影响，但是有一天生活的压力，会逼着你补救之，补救的日子里你会觉得异常辛苦。例如人到中年，上有老小，加班加点为了那点微薄的薪资，在行业或者公司不景气时，被公司无情的降薪或者裁员。然后偷偷地抹掉眼泪，整理简历，为下一份微不足道的薪水继续努力。\n中国有句老话叫，失之东隅，收之桑榆。意思是说，如果你失去了早上的朝阳，那么你一定要及时抓住晚上的夕阳，它是你最后弥补的机会。既然工资是主要收入来源，那么提高职场竞争力是加薪升职的唯一途径。而对于程序员来说就是提高技术能力和开阔视野。不管你是什么原因入了此行，既然选择了这一行，凑合或者破罐子破摔在这一行是行不通的，互联网行业的特点就是变化迅速，你需要不断学习去适应新的变化。你可能并不喜欢这份职业，这就如同一场婚姻一样，你可能对你的对象不满意，但是大多数人都没有推倒重来（离婚）的勇气和资本。如果你不尝试去与你这个不满意的爱人去培养感情，你的心情只会更加恶心，生活只会更糟。所以，从现在努力，好好培养对技术的热情还来得及，这就是所谓的先结婚再恋爱。不要盲目相信网上所谓程序员 35 岁危机，真正的技术大神是不会有啥危机的。我个人的经历告诉我，30 岁之前的每个月工资多几千块少几千块，对后来的生活真的没多大影响。对于开发人员来说，影响你后期收入却是人到中年的技术实力。我自做公众号以来，因为我的号（高性能服务器开发）是以技术为主，也认识了许许多多的技术号主，但是很多号的号主其实并不是做技术的，因为我本人是个技术痴迷者，所以我对那些技术实力一般的号主都不怎么感冒，反之我会主动约一些技术实力非常好的号主线下见面。在我的了解中，这些坚持做好技术的号主，工资收入都不低，年薪基本都在 50 W+，甚至有到 150 W。当然，技术实力好的，还有许多其他的优势，例如不用担心被裁员、不用担心找不到好工作，而且可能利用自己的技术去轻松地赚一些钱（下文会详细介绍）。\n说了这么多，我建议亲爱的读者，你，如果是从事开发的，那么一定要热爱技术，并努力把它学好，因为它是你吃饭的家伙。吃饭的家伙都不重视，那还能指望你有多大的提高？虽然一些人从技术成功转型了，也赚了不少钱，但是这些都是个例，不具有普适性，你觉得你会成为那个幸运的个例吗？\n有读者可能会问，那如何学好技术呢？我个人觉得是肯对自己投资。很多人会愿意为自己一趟旅游、一顿大餐花许多钱，却为自己买本书、买个课程、报个学习班的几十或几百块钱而纠结半天。消费行为分为投资型消费和纯消费型消费，工作的早些年，你一定要肯为自己多一些投资型消费。例如，我月薪不过万的时候，我会为见一个技术前辈一面，从上海跑到北京，转好几次车；会在得到 App 上花 1500 块钱约某个技术大神去咖啡店聊上两个小时。很多高人或行业前辈，我们在现实生活中可能永远都没机会与他们接触，但是现在的知识付费平台，给我们提供了很多机会。或许高人前辈的一句话，一个建议或者思路就能让你受益无穷。这样的例子自古有之，我这里就不举例了。\n**要对自己负责，学习和提高是自己的事情。**我发现现在很多的人，出了社会之后还是学生时代被老师教的思维。学校里面老师教你是因为你交了并不便宜的学费给学校，学校给老师发工资和补助。但是到了社会上，大家都很忙，别人凭什么要给你无偿提供帮助或者解决问题；别人提供了一份学习资料，你自己没保存，过几天别人删掉了，你又腆着脸让别人再分享一次；别人给你解决问题，你却说你不方便，让别人等一会儿。或者是你觉得工作太忙、孩子吵得太凶没时间学习等等。这些都是理由和借口，都没把自己的学习和提高当自己的事情。\n提高技术，先解决思想上的问题，再解决行动上的问题，这样就容易的多了。其实现实生活中大多数人都不努力，或者貌似很努力，所以你只要稍微真努力一点，你就能超过 90% 的人了。不信你可以试一试。两年前加入高性能服务器开发群的，并认真听我的建议付诸行动的群友，现在年薪都 50 W 了吧。\n程序员的副业 程序员有哪些副业？很多人说去接外包，但是我并不建议你去接各种外包，尤其是那些需求不是很明确或者金额达到上千的外包项目。由于外包项目一般很难有明确的需求，尤其是和非技术出身的甲方人员对接时，很多功能的界限和定义都是不明确的，例如为一个即时通讯软件做一个\u0026quot;发送消息功能”，这个\u0026quot;发送消息功能\u0026quot;可多可少，可轻可重。发文字发表情比较简单，发图片就不容易做了，而发语音视频尤其是发实时的语音和视频的工作的量是需要一个专门的专业团队至少花上好几个月的。需求不明确的结果就导致容易出现反复沟通和返工，这会耗费你大量的时间和精力，必然会影响你正常的工作和生活，尤其是对于本职工作本来就忙碌的程序员们来说。而最后可能因为甲方的不满意，必然导致不会按期按量付款。当然，现在很多外包平台正在改善这一状况，如码云、开源中国社区、程序员客栈，不过还是存在不少问题。\n除了外包，我们再来聊一聊知识付费，知识付费主要是程序员给各大知识付费站点或平台录制或者写作技术教程。文字系列的知识付费课程，国内做的比较好的有极客时间、GitChat 和 掘金社区。由于商业的运作，很多课程的标题和内容比较容易吸引用户购买，当然内容质量也是有保证的。如果你在某些技术方面有积累或者独到之处，可以尝试在这些平台上写一些专栏课程。但是，很多人看到别人的专栏动辄几千甚至上万的购买量，加上定价都在两位数，觉得作者一定通过课程赚到一笔不少的收入。其实也未必，一般的课程在开售前都有一定的基础数量，比如某个课程可能还没开始出售，就有 100 的购买量，这类纯粹是为了吸引用户去购买的。另外，很多课程都会被平台拿去做一些商业活动，如打折优惠、会员免费学习等等，通过这个形式购买的收入，平台会拿去不少一部分，分到每个作者的并不多。最后，剩下的的终于结算给作者了，平台又会为作者缴纳不少的个人所得税（纳税光荣！纳税光荣！纳税光荣！），最后到作者这里就剩下十之三四了。\n视频型的知识付费平台，以慕课网和网易云课堂为例，当然由于平台对你录制的课程有一定的质量要求，你需要花费不少时间和精力去撰写课程教案和 PPT，提前练习，保证录制的视频讲解流畅、技术娴熟、知识专业。这类对一般的程序员属于比较重量级的副业了，有一定的难度。\n再来说语音型的知识付费平台，例如得到、知乎 live。这里以知乎 live 为例，在知乎举办一场 live，为了保证质量，平台需要你进行资格认证，例如你说你在某某大公司任职，那需要你提交在该公司的工牌、身份证件或者劳动合同；你说你是某方面的专家，你需要有那一方面的相关证书，另外需要缴纳 500 块钱的保证金，这个用途是，如果你不能按期按质举办你的 live，那么这个保证金将不会退还给你。知乎 live 是我比较喜欢的一种形式，主要是比较省事，举办一次，每个月都会一点收入（同样需要缴税），我在知乎上举办过三场开发方面的 live，一年多时间，所有收入加起来大概有一万块钱左右。如果你在大城市生活和工作，可能觉得这没多少钱（我就是），但是如果你在像郑州、合肥这样的二三线城市做 IT，由于这类城市程序员的收入本身就不高，一万块钱绝对至少抵得上一两个月的收入，可以让生活负担小一点。所以建议在这类城市工作的读者可以尝试一下。\n再来说做公众号。做公众号赚钱吗？这不能一概而论。公众号的收入主要有三个来源，来源一是公众号的流量主，来源二是原创文章的打赏，来源三是公众号的广告收入。腾讯微信公众号是一个非常不错重视和保护原创作者权益的平台。新注册的公众号，现在只要粉丝达到 500 就可以开通流量主，流量主开通之后微信会在公众号文章的中间（文中）或者底部插入广告，当用户看到这个广告或者点击这些广告，公众号主就会有一点收入，收入多少与用户阅读这个广告的次数（曝光量）和点击量有关。我一般不开公众号文中广告，那样对读者阅读体验不好。当然，这种流量主的收入基本很少，不过如果你坚持原创的话，每天利用流量主的收入用餐时给自己加个鸡蛋或者鸡腿还是可以的。原创文章的打赏是公众号的收入的第二个来源，这类收入比较少，尤其是技术类公众号，一般很少有读者会为你打赏的。也就是说公众号的广告收入是公众号的主要来源，因为流量主和打赏实在太少了。辛辛苦苦每天写文章和排版，其实也不容易，所以希望读者在看到一些公众号发广告时可以多一点理解，少一点抨击。经常有一些号主反映只要一发广告就有读者在后台开骂。每天发文章，你也没怎么打赏，号主也要吃饭，不喜欢就取关，没必要骂的。当你的公众号平均阅读量达到一定数量时，会有广告商主动联系你，给你投放广告。按目前的市场行情，广告文的单价是根据文章平均阅读量来算的，平均下来是 0.7～1.2 元/阅读量。也就是说一篇广告文阅读量如果在四五千，那么一篇广告收入也会有四五千。当然，平均阅读量达到四五千也不容易，一般可能是十万粉丝。我个人觉得月薪三万容易，公众号三万粉丝却不容易。当然，就技术圈号主来说，大多数号还是比较良心的，不是每种广告都会接，一般理财类、美容类、保健类等等都不会接。目前不少大号的（粉丝量超过 10 W）的号主，都辞去了工作，全职做公众号。他们的理由是：既然副业收入已经超过主业（上班）了，在公司继续上班就是亏钱，不如辞职全身心做副业。当然，**我自己不会走这条路的，我还想在技术上继续精进，所以会去更多公司挑战对系统要求更高的业务。**所以，读者不用担心，此号会继续给大家分享高质量的后台开发技术，但是由于我有正常的全职工作，做不到每天都推送一篇高质量的原创，希望读者能理解。\n基于公众号，很多号主会做一些付费增值服务，如付费知识群、专栏课程、知识星球、线下付费活动等等，这个读者可以按需选取。以知识星球为例，有些知识星球只需花少许费用，的确能让人耳目一新。\n与公众号类似的平台还有很多，一些全职做自媒体的个人或者公司，他们除了运营公众号以外，还有今日头条号、百度的百家号、抖音号、简书、知乎、新浪微博等等。如果有兴趣的读者也可以试试。\n另外一些就是提供一些付费咨询，例如知乎、分答的付费的咨询。\n还有一类是出书，书的编写方式有\u0026quot;著\u0026rdquo;、\u0026ldquo;编写\u0026quot;和\u0026quot;译\u0026rdquo;，其中\u0026quot;著\u0026quot;是完全原创，要求比较高；\u0026ldquo;编写\u0026quot;一般是原创一部分，整理撰写一部分；\u0026ldquo;译\u0026quot;就是翻译国外的书籍。你可以主动联系出版社沟通出书计划。大多数时候，当你在某个平台上的某个领域有一定的影响之后，会有出版社的编辑或者图书策划公司的工作人员主动联系你写书。我就是在知乎上发过一些列高性能服务器开发专题的文章，被出版社主动联系的。当然，写书是一件非常磨人的事情，写书的过程是一个很痛苦的过程，和写博客不同，作者需要小心翼翼，为自己的每句话负责，以免出现技术性错误或者造成误解（以免误人子弟）。同时需要规划书籍整体内容，要根据出版社编辑的意见反复修改，字句要反复斟酌，版面要反复优化。不过，写书也是很锻炼人的事情，你不仅可以系统性地梳理一下你在那个领域的知识体系，在和出版社老师沟通的过程中学到很多写作和排版的技巧；而且写书会让你在某个领域增加一点名气和\u0026quot;光环\u0026rdquo;，对你将来的求职和谈薪都有一定的加成作用。很多人的可能会说写书也能得到一大笔稿费，实际情况是靠写书真赚不了多少钱。出版一本书，一般的作者只能拿到 8% 的分成，名气大一点的或者销量好一点的可以拿到 10%，也就是说一本定价 100 元的书，每卖出去一本你可以拿 8 块钱，卖出去三千本（可能很难），是 24000，然后再缴去一部分个人所得税，到手其实也不没多少。\n以上介绍了一些常见的程序员的一些副业。但是我还想提醒一下读者，不要光看到别人搞公众号和在知识付费平台写专栏赚钱了，尤其是做公众号，如果你是一名初入职场或者技术不是特别好的开发人员，一定不要把重心放在这上面，一定要把学习和积累技术作为中心，否则可能会捡了芝麻丢了西瓜。我在 GitChat 上写《C/C++ 多线程编程》时，我已经使用 C++ 快 10 年了，这 10 年了利用 C/C++ 开发过大大小小的系统，有客户端也有服务器程序，所以该课程总结了是我这 10 年中 C/C++ 多线程编程最常用和实用的技术的重难点。举个例子，课程中我介绍了条件变量时只介绍了 Linux 系统上的条件变量，而没有介绍 Windows 系统上的条件变量，不是因为 Windows 系统上不存在条件变量，而是在 Windows 上使用它的场景我基本没见过，为此我翻阅过大量的源码，如金山卫士、电驴、filezilla 等。\n最后，希望本文对身为开发者的你有一点启发，那就善莫大焉了。感谢阅读～\n","permalink":"https://haokiu.com/blog/cbd700214d4e4bc691c5f33f6e905343/","summary":"聊一聊程序员如何增加收入 亲爱的读者朋友，你好。我是高性能服务器开发公众号的作者，范蠡。一些老的读者应该知道，我有个同名 QQ 群叫高性能服务器开发（研究）群，目前两个群加在一起，也快五千人了吧。很多群友不止一次的想了解我的收入情况，粗略的算了一下，今年一年到目前为止，大概有一百万。然而，这种程度的收入在上海这样的城市，依旧是买不起房，解决不了生活的大问题，比上不足比下有余吧。\n咱公众号的大多数读者应该都是从事程序开发或者相关的，你或许在北京上海深圳，或许在南京武汉广州，或许在郑州合肥，或许在其他一些二线三线城市。大多数程序员其实是单纯而又朴实的，晚上可能在骂老板抠门、产品经理SB，但明天早上依然会早起去挤地铁，认真写每一行代码，因为高堂明镜悲白发，朝如青丝暮成雪，一天天老去的父母，需要我们赡养；\u0026ldquo;笑看妻子愁何在，漫卷诗书喜欲狂”，一天天长大的孩子，需要我们去养育。哪个程序员曾经不是不为五斗米而折腰的男子，如今却不得过着李白洗尿布一样的生活？所以，尽管有时候我们有千万种不愿意，但还是不得说这言不由衷的话，做着自己不想做的事情——因为我们缺钱。\n今天，我们就和大家讨论一下程序员如何提高收入，当然，由于个人经历经验有限，难免是一家之言，文中内容仅供参考，欢迎温和地提出意见和建议。\n程序员们的主要收入来源 这个标题其实不言自明的，程序员们，当然对于大多数上班族，工作是收入的主要来源。看到群里很多学生讨论 offer 薪资的时候，动辄就月薪 30 k 甚至如 45 k以及更高的，虽然不排除确实存在这一类的 SP 或者 SSP offer。但是大多数人会是这类高收入者或者幸运儿吗？月薪 30 k 意味着什么？意味着在一个小城市两口之家半年多的生活费，意味着在中国广大农村一家两三年的生活成本。老板都不是傻子，你能干多少活才会给你多少钱，那么 30 k 需要干多少活呢？其他的城市我不熟悉，以我所在的上海为例吧，对于一般学校毕业的应届毕业生月薪 5 k 起步，硕士会稍微高上 3～5 k，工作两年月薪在 12k～16k 之间，工作四五年月薪在 20 k ～26 k 之间，达到 30 k 及以上，一般需要工作七八年以上。如果较短工作年限，需要达到较高收入水平的，都是技术非常好或者能力特别强的。我工作三多年时，在一家做公司做音视频实时通讯技术，月薪 26 k。但是工作内容和工作量就很大，当时负责 pc 、安卓、iOS、mac 四个端的 C++ sdk 开发和维护，同时负责这几个端的 Java sdk 开发，每天需要处理多家客户使用这些 sdk 报的各种问题。每天晚上九点下班，被项目经理看到，她会说，你今天下班真早啊。我印象深刻的是，那一年春节，从年二十五到正月初六每天早上九点，我需要准时参加公司的项目会议，汇报项目状况和进度，每天二十四小时要随时响应。\n我们大多人毕业学校一般、学历也一般，而且也不是特别努力，本身存在\u0026quot;先天不足”。高中或者大学不努力，毕业后本来起点就比名校或者努力的同学差上一截，这一截可能不是 0.1 到 0.11 的距离，可能是 0.1 到 10 的距离。哈佛大学有句校训是这样写的：今天不走，明天要跑。这句话是很有道理的，你从前不努力的阿喀琉斯之踵，可能在短期内对你没多少影响，但是有一天生活的压力，会逼着你补救之，补救的日子里你会觉得异常辛苦。例如人到中年，上有老小，加班加点为了那点微薄的薪资，在行业或者公司不景气时，被公司无情的降薪或者裁员。然后偷偷地抹掉眼泪，整理简历，为下一份微不足道的薪水继续努力。\n中国有句老话叫，失之东隅，收之桑榆。意思是说，如果你失去了早上的朝阳，那么你一定要及时抓住晚上的夕阳，它是你最后弥补的机会。既然工资是主要收入来源，那么提高职场竞争力是加薪升职的唯一途径。而对于程序员来说就是提高技术能力和开阔视野。不管你是什么原因入了此行，既然选择了这一行，凑合或者破罐子破摔在这一行是行不通的，互联网行业的特点就是变化迅速，你需要不断学习去适应新的变化。你可能并不喜欢这份职业，这就如同一场婚姻一样，你可能对你的对象不满意，但是大多数人都没有推倒重来（离婚）的勇气和资本。如果你不尝试去与你这个不满意的爱人去培养感情，你的心情只会更加恶心，生活只会更糟。所以，从现在努力，好好培养对技术的热情还来得及，这就是所谓的先结婚再恋爱。不要盲目相信网上所谓程序员 35 岁危机，真正的技术大神是不会有啥危机的。我个人的经历告诉我，30 岁之前的每个月工资多几千块少几千块，对后来的生活真的没多大影响。对于开发人员来说，影响你后期收入却是人到中年的技术实力。我自做公众号以来，因为我的号（高性能服务器开发）是以技术为主，也认识了许许多多的技术号主，但是很多号的号主其实并不是做技术的，因为我本人是个技术痴迷者，所以我对那些技术实力一般的号主都不怎么感冒，反之我会主动约一些技术实力非常好的号主线下见面。在我的了解中，这些坚持做好技术的号主，工资收入都不低，年薪基本都在 50 W+，甚至有到 150 W。当然，技术实力好的，还有许多其他的优势，例如不用担心被裁员、不用担心找不到好工作，而且可能利用自己的技术去轻松地赚一些钱（下文会详细介绍）。\n说了这么多，我建议亲爱的读者，你，如果是从事开发的，那么一定要热爱技术，并努力把它学好，因为它是你吃饭的家伙。吃饭的家伙都不重视，那还能指望你有多大的提高？虽然一些人从技术成功转型了，也赚了不少钱，但是这些都是个例，不具有普适性，你觉得你会成为那个幸运的个例吗？\n有读者可能会问，那如何学好技术呢？我个人觉得是肯对自己投资。很多人会愿意为自己一趟旅游、一顿大餐花许多钱，却为自己买本书、买个课程、报个学习班的几十或几百块钱而纠结半天。消费行为分为投资型消费和纯消费型消费，工作的早些年，你一定要肯为自己多一些投资型消费。例如，我月薪不过万的时候，我会为见一个技术前辈一面，从上海跑到北京，转好几次车；会在得到 App 上花 1500 块钱约某个技术大神去咖啡店聊上两个小时。很多高人或行业前辈，我们在现实生活中可能永远都没机会与他们接触，但是现在的知识付费平台，给我们提供了很多机会。或许高人前辈的一句话，一个建议或者思路就能让你受益无穷。这样的例子自古有之，我这里就不举例了。\n**要对自己负责，学习和提高是自己的事情。**我发现现在很多的人，出了社会之后还是学生时代被老师教的思维。学校里面老师教你是因为你交了并不便宜的学费给学校，学校给老师发工资和补助。但是到了社会上，大家都很忙，别人凭什么要给你无偿提供帮助或者解决问题；别人提供了一份学习资料，你自己没保存，过几天别人删掉了，你又腆着脸让别人再分享一次；别人给你解决问题，你却说你不方便，让别人等一会儿。或者是你觉得工作太忙、孩子吵得太凶没时间学习等等。这些都是理由和借口，都没把自己的学习和提高当自己的事情。\n提高技术，先解决思想上的问题，再解决行动上的问题，这样就容易的多了。其实现实生活中大多数人都不努力，或者貌似很努力，所以你只要稍微真努力一点，你就能超过 90% 的人了。不信你可以试一试。两年前加入高性能服务器开发群的，并认真听我的建议付诸行动的群友，现在年薪都 50 W 了吧。\n程序员的副业 程序员有哪些副业？很多人说去接外包，但是我并不建议你去接各种外包，尤其是那些需求不是很明确或者金额达到上千的外包项目。由于外包项目一般很难有明确的需求，尤其是和非技术出身的甲方人员对接时，很多功能的界限和定义都是不明确的，例如为一个即时通讯软件做一个\u0026quot;发送消息功能”，这个\u0026quot;发送消息功能\u0026quot;可多可少，可轻可重。发文字发表情比较简单，发图片就不容易做了，而发语音视频尤其是发实时的语音和视频的工作的量是需要一个专门的专业团队至少花上好几个月的。需求不明确的结果就导致容易出现反复沟通和返工，这会耗费你大量的时间和精力，必然会影响你正常的工作和生活，尤其是对于本职工作本来就忙碌的程序员们来说。而最后可能因为甲方的不满意，必然导致不会按期按量付款。当然，现在很多外包平台正在改善这一状况，如码云、开源中国社区、程序员客栈，不过还是存在不少问题。\n除了外包，我们再来聊一聊知识付费，知识付费主要是程序员给各大知识付费站点或平台录制或者写作技术教程。文字系列的知识付费课程，国内做的比较好的有极客时间、GitChat 和 掘金社区。由于商业的运作，很多课程的标题和内容比较容易吸引用户购买，当然内容质量也是有保证的。如果你在某些技术方面有积累或者独到之处，可以尝试在这些平台上写一些专栏课程。但是，很多人看到别人的专栏动辄几千甚至上万的购买量，加上定价都在两位数，觉得作者一定通过课程赚到一笔不少的收入。其实也未必，一般的课程在开售前都有一定的基础数量，比如某个课程可能还没开始出售，就有 100 的购买量，这类纯粹是为了吸引用户去购买的。另外，很多课程都会被平台拿去做一些商业活动，如打折优惠、会员免费学习等等，通过这个形式购买的收入，平台会拿去不少一部分，分到每个作者的并不多。最后，剩下的的终于结算给作者了，平台又会为作者缴纳不少的个人所得税（纳税光荣！纳税光荣！纳税光荣！），最后到作者这里就剩下十之三四了。\n视频型的知识付费平台，以慕课网和网易云课堂为例，当然由于平台对你录制的课程有一定的质量要求，你需要花费不少时间和精力去撰写课程教案和 PPT，提前练习，保证录制的视频讲解流畅、技术娴熟、知识专业。这类对一般的程序员属于比较重量级的副业了，有一定的难度。\n再来说语音型的知识付费平台，例如得到、知乎 live。这里以知乎 live 为例，在知乎举办一场 live，为了保证质量，平台需要你进行资格认证，例如你说你在某某大公司任职，那需要你提交在该公司的工牌、身份证件或者劳动合同；你说你是某方面的专家，你需要有那一方面的相关证书，另外需要缴纳 500 块钱的保证金，这个用途是，如果你不能按期按质举办你的 live，那么这个保证金将不会退还给你。知乎 live 是我比较喜欢的一种形式，主要是比较省事，举办一次，每个月都会一点收入（同样需要缴税），我在知乎上举办过三场开发方面的 live，一年多时间，所有收入加起来大概有一万块钱左右。如果你在大城市生活和工作，可能觉得这没多少钱（我就是），但是如果你在像郑州、合肥这样的二三线城市做 IT，由于这类城市程序员的收入本身就不高，一万块钱绝对至少抵得上一两个月的收入，可以让生活负担小一点。所以建议在这类城市工作的读者可以尝试一下。","title":"聊一聊程序员如何增加收入"},{"content":"聊聊如何拿大厂的 offer 为什么要进大厂 许多读者，尤其是一些学生朋友在找我聊职业规划和职场困惑时，我给的建议就是，如果你是应届生或者工作年限较短（五年以下），那一定要找个机会去大厂工作几年。\n无论是出于所谓的“镀镀金”的心理，还是想去大厂挑战大业务量、接触高并发、提高技术、开阔视野，都是非常值得的。\n虽然很多大厂都加班，但是作为工薪阶层的一员，哪里不加班呢？再者大厂的各项规章制度和福利待遇都比较完善，你可以见识到很多成熟的系统和优秀的做法和理念。\n就福利待遇来说，大厂给的薪资待遇比一般的小公司给的要高上一截。就算你从大厂离职，你也可以很容易的涨薪去另外一家大厂。这些都是小公司的没有的优势（我这里并不是说小公司不好）。\n由于刚毕业的时候，没有能够进大厂，导致起点和平台都比同时间进大厂的同学低许多。虽然最终通过自己的努力，从刚毕业时的月薪 5 千到现在的年薪 50 W+。\n这期间我走了很多弯路和吃了很多苦头。以工资收入来说，未进大厂的，可能在社会上摸爬滚打好多年才勉强达到月薪 2~3 万，而进大厂可能工作一两年就够了，甚至有些大厂开出的 SSP 直接就有三五十万。\n因此，如果你一毕业就进入了大厂，那么你的第一份工作的收入、起点和视野就会比同龄人高很多。这也是我苦口婆心地劝毕业生们在毕业前夕的那段日子里面咬咬牙，努力去拿个大厂的 Offer 的原因。\n进入大厂的难点在哪里 虽然大厂很好，但是进大厂对个人资质、个人素养和技术水平都有一定的要求，并不是每个人都有机会的。这里说的个人资质，如学历和毕业院校的层次。\n一般大厂都只接收本科及本科以上的学历，对于本科以下的学历的应届生一般都不会考虑。而且会优先选择学校层次还不错的毕业生。\n也就是说对于应届生，学校和学历成了硬性要求。即使你的能力再强，HR 筛选简历时就已经把你给 pass 掉了，你根本没有面试的机会。\n高考已经没考好了，这个已经成为既成事实了。那对于学历和学校不好的人，还有机会补救吗？\n有的，通过社招。\n也就是说，你可以先工作几年，再尝试去大厂面试。因为社招更多的是看重的是你的技术水平、工作经验等，对学历要求没那么高了。\n如何进入大厂 无论是应届生还是工作几年的人，一般都需要通过技术面试才能进入大厂。\n那么大厂技术面试一般会哪些问题呢？除了少部分相关的技术外，重头戏都是算法与数据结构。\n说到算法和数据结构这门学科，很多人尤其是已经工作了几年的社会人士，用范玮琪的一句歌词来形容，那真是“那一些是非题，总让人伤透脑筋”。\n大家常学常忘，但为了面试，尤其是大厂面试，所以不得不学。\n很多人对算法和数据结构这门课，甚至存在这样一个误解：实际工作中根本用不到算法，只有面试才会用到。产生这种错觉的原理，莫外乎此人技术不够资深、水平不够好，无缘参与核心开发而已。\n学好算法和数据结构，无论对从技术水平长远的发展来说，还是对个人逻辑思维锻炼都是大有裨益的。\n国内的大厂面试，基本上大多数问题都是各种算法和数据结构题，而国外的大厂，像 Google、Facebook、微软等等，基本上百分之百是算法和数据结构题目。\n很多应届毕业生横扫各大大厂 Offer，很大一部分原因是因为算法和数据结构掌握的好，当然薪资也非常可观。社会人士虽然在面试大厂时对相关的项目有一定的工作经验，没有像应届生要求那么高，但是最基础最常用的算法和数据结构还是要熟悉的。\n说了这么多，那么大厂面试到底要求哪些算法和数据结构知识？我根据我面试的经验，给大家整理了一个清单：\n**排序（常考的排序按频率排序为：**快速排序 \u0026gt; 冒泡排序 \u0026gt; 归并排序 \u0026gt; 桶排序）\n一般对于对算法基础有要求的公司，如果你是应届生或者工作经验在一至三年内，以上算法如果写不出来，给面试官的印象会非常不好，甚至直接被 pass 掉。\n对于工作三年以上的社会人士，如果写不出来，但是能分析出其算法平均、最好和最坏的情况下的复杂度，说出算法大致原理，在多数面试官面前也可以过的。注意，如果你是学生，写不出来或者写的不对，基本上面试就过不了。\n二分查找\n二分查找的算法尽量要求写出来。当然，大多数面试官并不会直接问你二分查找，而是结合具体的场景，例如如何求一个数的平方根，这个时候你要能想到是二分查找。\n我在 2017 年年底，面试 agora 时，面试官问了一个问题：如何从所有很多的 ip 地址中快速找个某个 ip 地址。\n链表\n无论是应届生还是工作年限不长的社会人士，琏表常见的操作一定要熟练写出来，如链表的查找、定位、反转、连接等等。还有一些经典的问题也经常被问到，如两个链表如何判断有环（我在 2017 年面试饿了么二面、上海黄金交易所一面被问过）。\n链表的问题一般不难，但是链表的问题存在非常多的“坑”，如很多人不注意边界检查、空链表、返回一个链表的函数应该返回链表的头指针等等。\n队列与栈\n对于应届生来说一般这一类问的比较少，但是对于社会人士尤其是中高级岗位开发，会结合相关的问题问的比较多，例如让面试者利用队列写一个多线程下的生产者和消费者程序，全面考察的多线程的资源同步与竞态问题（下文介绍多线程面试题时详细地介绍）。\n栈一般对于基础要求高的面试，会结合函数调用实现来问。即函数如何实现的，包括函数的调用的几种常见调用方式、参数的入栈顺序、内存栈在地址从高向低扩展、栈帧指针和栈顶指针的位置、函数内局部变量在栈中的内存分布、函数调用结束后，调用者和被调用者谁和如何清理栈等等\n某年面试京东一基础部门，面试官让写从 0 加到 100 这样一个求和算法，然后写其汇编代码。\n哈希表\n哈希表是考察最多的数据结构之一。常见的问题有哈希冲突的检测、让面试者写一个哈希插入函数等等。基本上一场面试下来不考察红黑树基本上就会问哈希表，而且问题可浅可深。\n我印象比较深刻的是，当年面试百度广告推荐部门时，二面问的一些关于哈希表的问题。\n当时面试官时先问的链表，接着问的哈希冲突的解决方案，后来让写一个哈希插入算法，这里需要注意的是，你的算法中插入的元素一定要是通用元素，所以对于 C++ 或者 Java 语言，一定要使用模板这一类参数作为哈希插入算法的对象。\n然后，就是哈希表中多个元素冲突时，某个位置的元素使用链表往后穿成一串的方案。\n最终考察 Linux 下 malloc（下面的 ptmalloc） 函数在频繁调用造成的内存碎片问题，以及开源方案解决方案 tcmalloc 和 jemalloc。\n总体下来，面试官是一步步引导你深入。（有兴趣的读者可以自行搜索，网上有很多相关资料）\n树 面试高频的树是红黑树，也有一部分是 B 树（B+ 树）。\n红黑树一般的问的深浅不一，大多数面试官只要能说出红黑树的概念、左旋右旋的方式、分析出查找和插入的平均算法复杂度和最好最坏时的算法复杂度，并不要写面试者写出具体代码实现。\n一般 C++ 面试问 stl 的 map，java 面试问 TreeMap 基本上就等于开始问你红黑树了，要有心里准备。笔者曾经面试爱奇艺被问过红黑树。\nB树一般不会直接问，问的最多的形式是通过问 MySQL 索引实现原理。笔者面试腾讯看点部门二面被问到过。\n图\n图的问题我在面试三星电子时就有一道面试题就是深度优先和广度优先问题。\n其他的一些算法\n如 A* 寻路、霍夫曼编码也偶尔会在某一个领域的公司的面试中被问到，我在面试宝开（《植物大战僵尸》的母公司）就被问到过。\n","permalink":"https://haokiu.com/blog/61401d1e68344e7b94c634f9b00cdbe4/","summary":"聊聊如何拿大厂的 offer 为什么要进大厂 许多读者，尤其是一些学生朋友在找我聊职业规划和职场困惑时，我给的建议就是，如果你是应届生或者工作年限较短（五年以下），那一定要找个机会去大厂工作几年。\n无论是出于所谓的“镀镀金”的心理，还是想去大厂挑战大业务量、接触高并发、提高技术、开阔视野，都是非常值得的。\n虽然很多大厂都加班，但是作为工薪阶层的一员，哪里不加班呢？再者大厂的各项规章制度和福利待遇都比较完善，你可以见识到很多成熟的系统和优秀的做法和理念。\n就福利待遇来说，大厂给的薪资待遇比一般的小公司给的要高上一截。就算你从大厂离职，你也可以很容易的涨薪去另外一家大厂。这些都是小公司的没有的优势（我这里并不是说小公司不好）。\n由于刚毕业的时候，没有能够进大厂，导致起点和平台都比同时间进大厂的同学低许多。虽然最终通过自己的努力，从刚毕业时的月薪 5 千到现在的年薪 50 W+。\n这期间我走了很多弯路和吃了很多苦头。以工资收入来说，未进大厂的，可能在社会上摸爬滚打好多年才勉强达到月薪 2~3 万，而进大厂可能工作一两年就够了，甚至有些大厂开出的 SSP 直接就有三五十万。\n因此，如果你一毕业就进入了大厂，那么你的第一份工作的收入、起点和视野就会比同龄人高很多。这也是我苦口婆心地劝毕业生们在毕业前夕的那段日子里面咬咬牙，努力去拿个大厂的 Offer 的原因。\n进入大厂的难点在哪里 虽然大厂很好，但是进大厂对个人资质、个人素养和技术水平都有一定的要求，并不是每个人都有机会的。这里说的个人资质，如学历和毕业院校的层次。\n一般大厂都只接收本科及本科以上的学历，对于本科以下的学历的应届生一般都不会考虑。而且会优先选择学校层次还不错的毕业生。\n也就是说对于应届生，学校和学历成了硬性要求。即使你的能力再强，HR 筛选简历时就已经把你给 pass 掉了，你根本没有面试的机会。\n高考已经没考好了，这个已经成为既成事实了。那对于学历和学校不好的人，还有机会补救吗？\n有的，通过社招。\n也就是说，你可以先工作几年，再尝试去大厂面试。因为社招更多的是看重的是你的技术水平、工作经验等，对学历要求没那么高了。\n如何进入大厂 无论是应届生还是工作几年的人，一般都需要通过技术面试才能进入大厂。\n那么大厂技术面试一般会哪些问题呢？除了少部分相关的技术外，重头戏都是算法与数据结构。\n说到算法和数据结构这门学科，很多人尤其是已经工作了几年的社会人士，用范玮琪的一句歌词来形容，那真是“那一些是非题，总让人伤透脑筋”。\n大家常学常忘，但为了面试，尤其是大厂面试，所以不得不学。\n很多人对算法和数据结构这门课，甚至存在这样一个误解：实际工作中根本用不到算法，只有面试才会用到。产生这种错觉的原理，莫外乎此人技术不够资深、水平不够好，无缘参与核心开发而已。\n学好算法和数据结构，无论对从技术水平长远的发展来说，还是对个人逻辑思维锻炼都是大有裨益的。\n国内的大厂面试，基本上大多数问题都是各种算法和数据结构题，而国外的大厂，像 Google、Facebook、微软等等，基本上百分之百是算法和数据结构题目。\n很多应届毕业生横扫各大大厂 Offer，很大一部分原因是因为算法和数据结构掌握的好，当然薪资也非常可观。社会人士虽然在面试大厂时对相关的项目有一定的工作经验，没有像应届生要求那么高，但是最基础最常用的算法和数据结构还是要熟悉的。\n说了这么多，那么大厂面试到底要求哪些算法和数据结构知识？我根据我面试的经验，给大家整理了一个清单：\n**排序（常考的排序按频率排序为：**快速排序 \u0026gt; 冒泡排序 \u0026gt; 归并排序 \u0026gt; 桶排序）\n一般对于对算法基础有要求的公司，如果你是应届生或者工作经验在一至三年内，以上算法如果写不出来，给面试官的印象会非常不好，甚至直接被 pass 掉。\n对于工作三年以上的社会人士，如果写不出来，但是能分析出其算法平均、最好和最坏的情况下的复杂度，说出算法大致原理，在多数面试官面前也可以过的。注意，如果你是学生，写不出来或者写的不对，基本上面试就过不了。\n二分查找\n二分查找的算法尽量要求写出来。当然，大多数面试官并不会直接问你二分查找，而是结合具体的场景，例如如何求一个数的平方根，这个时候你要能想到是二分查找。\n我在 2017 年年底，面试 agora 时，面试官问了一个问题：如何从所有很多的 ip 地址中快速找个某个 ip 地址。\n链表\n无论是应届生还是工作年限不长的社会人士，琏表常见的操作一定要熟练写出来，如链表的查找、定位、反转、连接等等。还有一些经典的问题也经常被问到，如两个链表如何判断有环（我在 2017 年面试饿了么二面、上海黄金交易所一面被问过）。\n链表的问题一般不难，但是链表的问题存在非常多的“坑”，如很多人不注意边界检查、空链表、返回一个链表的函数应该返回链表的头指针等等。\n队列与栈\n对于应届生来说一般这一类问的比较少，但是对于社会人士尤其是中高级岗位开发，会结合相关的问题问的比较多，例如让面试者利用队列写一个多线程下的生产者和消费者程序，全面考察的多线程的资源同步与竞态问题（下文介绍多线程面试题时详细地介绍）。\n栈一般对于基础要求高的面试，会结合函数调用实现来问。即函数如何实现的，包括函数的调用的几种常见调用方式、参数的入栈顺序、内存栈在地址从高向低扩展、栈帧指针和栈顶指针的位置、函数内局部变量在栈中的内存分布、函数调用结束后，调用者和被调用者谁和如何清理栈等等\n某年面试京东一基础部门，面试官让写从 0 加到 100 这样一个求和算法，然后写其汇编代码。\n哈希表\n哈希表是考察最多的数据结构之一。常见的问题有哈希冲突的检测、让面试者写一个哈希插入函数等等。基本上一场面试下来不考察红黑树基本上就会问哈希表，而且问题可浅可深。\n我印象比较深刻的是，当年面试百度广告推荐部门时，二面问的一些关于哈希表的问题。\n当时面试官时先问的链表，接着问的哈希冲突的解决方案，后来让写一个哈希插入算法，这里需要注意的是，你的算法中插入的元素一定要是通用元素，所以对于 C++ 或者 Java 语言，一定要使用模板这一类参数作为哈希插入算法的对象。\n然后，就是哈希表中多个元素冲突时，某个位置的元素使用链表往后穿成一串的方案。\n最终考察 Linux 下 malloc（下面的 ptmalloc） 函数在频繁调用造成的内存碎片问题，以及开源方案解决方案 tcmalloc 和 jemalloc。\n总体下来，面试官是一步步引导你深入。（有兴趣的读者可以自行搜索，网上有很多相关资料）\n树 面试高频的树是红黑树，也有一部分是 B 树（B+ 树）。","title":"聊聊如何拿大厂的 offer"},{"content":"腾讯后台开发实习生技能要求 如题，应届生除了要良好地掌握算法和数据结构以外，以下一些技能点列表希望对大家有帮助，有兴趣的朋友可以参考这个针对性地补缺补差。文章列出的技能点有的要求熟悉，有的了解即可，注意技能点前面的修饰词。如果没有明确给出“熟悉”“了解”等字眼，要求均为熟悉。\n一、操作系统方面 多线程相关与线程之间同步技术 熟练使用（但不局限于）以下linux API\nlinux下的线程创建、等待、获取线程id\nint pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); int pthread_join(pthread_t thread, void **retval); pthread_t pthread_self(void); 常见线程之间的同步技术（何时该用那种技术）\n互斥体\nint pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *mutexattr); int pthread_mutex_destroy(pthread_mutex_t *mutex); int pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); 信号量\nint sem_init(sem_t *sem, int pshared, unsigned int value); int sem_destroy(sem_t *sem); int sem_wait(sem_t *sem); int sem_post(sem_t *sem); int sem_getvalue(sem_t *sem, int *valp); 条件变量\nint pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr); int pthread_cond_destroy(pthread_cond_t *cond); int pthread_cond_signal(pthread_cond_t *cond); int pthread_cond_broadcast(pthread_cond_t *cond); int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex); int pthread_cond_timedwait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex, const struct timespec *restrict abstime); 读写/自旋锁\nint pthread_rwlock_init(pthread_rwlock_t *restrict rwlock, const pthread_rwlockattr_t *restrict attr); int pthread_rwlock_destroy(pthread_rwlock_t *rwlock); int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock); int pthread_rwlock_tryrdlock(pthread_rwlock_t *rwlock); int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock); int pthread_rwlock_trywrlock(pthread_rwlock_t *rwlock); int pthread_rwlock_unlock(pthread_rwlock_t *rwlock); //这两个函数在Linux和Mac的man文档里都没有，新版的pthread.h里面也没有，旧版的能找到 int pthread_rwlock_timedrdlock_np(pthread_rwlock_t *rwlock, const struct timespec *deltatime); int pthread_rwlock_timedwrlock_np(pthread_rwlock_t *rwlock, const struct timespec *deltatime); int pthread_spin_init (__pthread_spinlock_t *__lock, int __pshared); int pthread_spin_destroy (__pthread_spinlock_t *__lock); int pthread_spin_trylock (__pthread_spinlock_t *__lock); int pthread_spin_unlock (__pthread_spinlock_t *__lock); int pthread_spin_lock (__pthread_spinlock_t *__lock); 熟悉守护进程的创建、原理 了解计划作业crontab 熟悉进程、线程状态查看命令（top、strace、pstack） 熟悉内存状态查看命令memstat、free 熟悉IO状态查看命令iostat、df、du 了解linux文件的权限、用户、时间（ctime、mtime、atime）、inode等文件基本属性，熟练使用chmod、chown、chgrp等基本命令。 熟悉文件传输命令scp、rz、sz命令、 熟悉文件定位命令find、whereis命令。 熟悉软链接，熟悉ln命令。 熟悉lsof命令。 二、网络 熟悉tcp状态机（三次握手、四次挥手）。 熟悉tcpdump命令。 熟悉网络状态和防火墙状态查看命令：netstat、ifconfig、iptables 熟悉socket API，包括但不限于（connect、accept、bind、listen、send/sendto、recv/recvfrom、select、gethostbyname） int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); int bind(int socket, const struct sockaddr *address, socklen_t address_len); int listen(int sockfd, int backlog); ssize_t send(int sockfd, const void *buf, size_t len, int flags); ssize_t sendto(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen); ssize_t recv(int sockfd, void *buf, size_t len, int flags); ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); void FD_CLR(int fd, fd_set *set); int FD_ISSET(int fd, fd_set *set); void FD_SET(int fd, fd_set *set); void FD_ZERO(fd_set *set); struct hostent *gethostbyname(const char *name); 熟悉epoll，熟悉水平触发与边缘触发。 int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 熟悉阻塞socket和非阻塞socket在connect、send、recv等行为上的区别，如何将socket设置为非阻塞的。 三、脚本工具 了解shell基本语法、变量操作、函数、循环/条件判断等程序结构。 熟练使用文本编辑工具vi/vim。 了解使用文本处理命令grep、sed、cut。 了解awk命令。 四、数据库 熟悉数据表结构设计（三范式、字段属性）。 了解查询优化（索引的概念与创建、sql优化）。 熟悉常见的mysql API函数： mysql_real_connect mysql_select_db mysql_query mysql_store_result mysql_free_result mysql_num_rows mysql_close mysql_errno 五、编程语言 C/C++方面\n熟悉内存分布（堆、栈、静态/全局/局部变量、虚指针…） 熟悉Makefile。 熟悉gdb调试（断点、查看内存、执行跟踪、了解CPU主要寄存器作用…）。 熟悉性能分析工具(gprof)。 熟悉C-Runtime常用函数（如字符串格式化函数printf、scanf，字符串比较连接函数、内存分配函数、文件与目录操作函数等）。 熟悉stl库。 熟悉OO思想、常见设计模式（如单例模式、工厂设计模式、装饰者模式、Builder模式、生产者消费者模式、策略模式等）。 熟悉RAII、pimpl惯用法。 有一定的代码质量和重构能力。 文章版权所有，转载请保留文章末尾版权信息和公众号信息。\n","permalink":"https://haokiu.com/blog/5f118ee0e1be49a8a754072ecb9b441a/","summary":"腾讯后台开发实习生技能要求 如题，应届生除了要良好地掌握算法和数据结构以外，以下一些技能点列表希望对大家有帮助，有兴趣的朋友可以参考这个针对性地补缺补差。文章列出的技能点有的要求熟悉，有的了解即可，注意技能点前面的修饰词。如果没有明确给出“熟悉”“了解”等字眼，要求均为熟悉。\n一、操作系统方面 多线程相关与线程之间同步技术 熟练使用（但不局限于）以下linux API\nlinux下的线程创建、等待、获取线程id\nint pthread_create(pthread_t *thread, const pthread_attr_t *attr, void *(*start_routine) (void *), void *arg); int pthread_join(pthread_t thread, void **retval); pthread_t pthread_self(void); 常见线程之间的同步技术（何时该用那种技术）\n互斥体\nint pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *mutexattr); int pthread_mutex_destroy(pthread_mutex_t *mutex); int pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); 信号量\nint sem_init(sem_t *sem, int pshared, unsigned int value); int sem_destroy(sem_t *sem); int sem_wait(sem_t *sem); int sem_post(sem_t *sem); int sem_getvalue(sem_t *sem, int *valp); 条件变量\nint pthread_cond_init(pthread_cond_t *restrict cond, const pthread_condattr_t *restrict attr); int pthread_cond_destroy(pthread_cond_t *cond); int pthread_cond_signal(pthread_cond_t *cond); int pthread_cond_broadcast(pthread_cond_t *cond); int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex); int pthread_cond_timedwait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex, const struct timespec *restrict abstime); 读写/自旋锁","title":"腾讯后台开发实习生技能要求"},{"content":"详解 C++ 11 中的智能指针 C/C++ 语言最为人所诟病的特性之一就是存在内存泄露问题，因此后来的大多数语言都提供了内置内存分配与释放功能，有的甚至干脆对语言的使用者屏蔽了内存指针这一概念。这里不置贬褒，手动分配内存与手动释放内存有利也有弊，自动分配内存和自动释放内存亦如此，这是两种不同的设计哲学。有人认为，内存如此重要的东西怎么能放心交给用户去管理呢？而另外一些人则认为，内存如此重要的东西怎么能放心交给系统去管理呢？在 C/C++ 语言中，内存泄露的问题一直困扰着广大的开发者，因此各类库和工具的一直在努力尝试各种方法去检测和避免内存泄露，如 boost，智能指针技术应运而生。\nC++ 98/03 的尝试——std::auto_ptr 在 2019 年讨论 std::auto_ptr 不免有点让人怀疑是不是有点过时了，确实如此，随着 C++11 标准的出现（最新标准是 C++20），std::auto_ptr 已经被彻底废弃了，取而代之是 std::unique_ptr。然而，我之所以还向你介绍一下 std::auto_ptr 的用法以及它的设计不足之处是想让你了解 C++ 语言中智能指针的发展过程，一项技术如果我们了解它过去的样子和发展的轨迹，我们就能更好地掌握它，不是吗？\nstd::auto_ptr 的基本用法如下代码所示：\n#include \u0026lt;memory\u0026gt; int main() { //初始化方式1 std::auto_ptr\u0026lt;int\u0026gt; sp1(new int(8)); //初始化方式2 std::auto_ptr\u0026lt;int\u0026gt; sp2; sp2.reset(new int(8)); return 0; } 智能指针对象 sp1 和 sp2 均持有一个在堆上分配 int 对象，其值均是 8，这两块堆内存均可以在 sp1 和 sp2 释放时得到释放。这是 std::auto_ptr 的基本用法。\nsp 是 smart pointer（智能指针）的简写。\nstd::auto_ptr 真正让人容易误用的地方是其不常用的复制语义，即当复制一个 std::auto_ptr 对象时（拷贝复制或 operator = 复制），原对象所持有的堆内存对象也会转移给复制出来的对象。示例代码如下：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; int main() { //测试拷贝构造 std::auto_ptr\u0026lt;int\u0026gt; sp1(new int(8)); std::auto_ptr\u0026lt;int\u0026gt; sp2(sp1); if (sp1.get() != NULL) { std::cout \u0026lt;\u0026lt; \u0026#34;sp1 is not empty.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;sp1 is empty.\u0026#34; \u0026lt;\u0026lt; std::endl; } if (sp2.get() != NULL) { std::cout \u0026lt;\u0026lt; \u0026#34;sp2 is not empty.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;sp2 is empty.\u0026#34; \u0026lt;\u0026lt; std::endl; } //测试赋值构造 std::auto_ptr\u0026lt;int\u0026gt; sp3(new int(8)); std::auto_ptr\u0026lt;int\u0026gt; sp4; sp4 = sp3; if (sp3.get() != NULL) { std::cout \u0026lt;\u0026lt; \u0026#34;sp3 is not empty.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;sp3 is empty.\u0026#34; \u0026lt;\u0026lt; std::endl; } if (sp4.get() != NULL) { std::cout \u0026lt;\u0026lt; \u0026#34;sp4 is not empty.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;sp4 is empty.\u0026#34; \u0026lt;\u0026lt; std::endl; } return 0; } 上述代码中分别利用拷贝构造（sp1 =\u0026gt; sp2）和 赋值构造（sp3 =\u0026gt; sp4）来创建新的 std::auto_ptr 对象，因此 sp1 持有的堆对象被转移给 sp2，sp3 持有的堆对象被转移给 sp4。我们得到程序执行结果如下：\n[root@iZ238vnojlyZ testx]# g++ -g -o test_auto_ptr test_auto_ptr.cpp [root@iZ238vnojlyZ testx]# ./test_auto_ptr sp1 is empty. sp2 is not empty. sp3 is empty. sp4 is not empty. 由于 std::auto_ptr 这种不常用的复制语义，我们应该避免在 stl 容器中使用 std::auto_ptr，例如我们绝不应该写出如下代码：\nstd::vector\u0026lt;std::auto_ptr\u0026lt;int\u0026gt;\u0026gt; myvectors; 当用算法对容器操作的时候（如最常见的容器元素遍历），很难避免不对容器中的元素实现赋值传递，这样便会使容器中多个元素被置为空指针，这不是我们想看到的，会造成很多意想不到的错误。\n以史为鉴，作为 std::auto_ptr 的替代者 std::unique_ptr 吸取了这个经验教训。下文会来详细介绍。\n正因为 std::auto_ptr 的设计存在如此重大缺陷，C++11 标准在充分借鉴和吸收了 boost 库中智能指针的设计思想，引入了三种类型的智能指针，即 std::unique_ptr、std::shared_ptr 和 std::weak_ptr。\nboost 还有 scoped_ptr，C++11 并没有全部照搬，而是选择了三个最实用的指针类型。在 C++11 中可以通过 std::unique_ptr 达到与 boost::scoped_ptr 一样的效果。\n所有的智能指针类（包括 std::unique_ptr）均包含于头文件 **** 中。\n正因为存在上述设计上的缺陷，在 C++11及后续语言规范中 std::auto_ptr 已经被废弃，你的代码不应该再使用它。\nstd::unique_ptr std::unique_ptr 对其持有的堆内存具有唯一拥有权，也就是说引用计数永远是 1，std::unique_ptr 对象销毁时会释放其持有的堆内存。可以使用以下方式初始化一个 std::unique_ptr 对象：\n//初始化方式1 std::unique_ptr\u0026lt;int\u0026gt; sp1(new int(123)); //初始化方式2 std::unique_ptr\u0026lt;int\u0026gt; sp2; sp2.reset(new int(123)); //初始化方式3 std::unique_ptr\u0026lt;int\u0026gt; sp3 = std::make_unique\u0026lt;int\u0026gt;(123); 你应该尽量使用初始化方式 3 的方式去创建一个 std::unique_ptr 而不是方式 1 和 2，因为形式 3 更安全，原因 Scott Meyers 在其《Effective Modern C++》中已经解释过了，有兴趣的读者可以阅读此书相关章节。\n令很多人对 C++11 规范不满的地方是，C++11 新增了 std::make_shared() 方法创建一个 std::shared_ptr 对象，却没有提供相应的 std::make_unique() 方法创建一个 std::unique_ptr 对象，这个方法直到 C++14 才被添加进来。当然，在 C++11 中你很容易实现出这样一个方法来：\ntemplate\u0026lt;typename T, typename... Ts\u0026gt; std::unique_ptr\u0026lt;T\u0026gt; make_unique(Ts\u0026amp;\u0026amp; ...params) { return std::unique_ptr\u0026lt;T\u0026gt;(new T(std::forward\u0026lt;Ts\u0026gt;(params)...)); } 鉴于 std::auto_ptr 的前车之鉴，std::unique_ptr 禁止复制语义，为了达到这个效果，std::unique_ptr 类的拷贝构造函数和赋值运算符（operator =）被标记为 delete。\ntemplate \u0026lt;class T\u0026gt; class unique_ptr { //省略其他代码... //拷贝构造函数和赋值运算符被标记为delete unique_ptr(const unique_ptr\u0026amp;) = delete; unique_ptr\u0026amp; operator=(const unique_ptr\u0026amp;) = delete; }; 因此，下列代码是无法通过编译的：\nstd::unique_ptr\u0026lt;int\u0026gt; sp1(std::make_unique\u0026lt;int\u0026gt;(123));; //以下代码无法通过编译 //std::unique_ptr\u0026lt;int\u0026gt; sp2(sp1); std::unique_ptr\u0026lt;int\u0026gt; sp3; //以下代码无法通过编译 //sp3 = sp1; 禁止复制语义也存在特例，即可以通过一个函数返回一个 std::unique_ptr：\n#include \u0026lt;memory\u0026gt; std::unique_ptr\u0026lt;int\u0026gt; func(int val) { std::unique_ptr\u0026lt;int\u0026gt; up(new int(val)); return up; } int main() { std::unique_ptr\u0026lt;int\u0026gt; sp1 = func(123); return 0; } 上述代码从 func 函数中得到一个 std::unique_ptr 对象，然后返回给 sp1。\n既然 std::unique_ptr 不能复制，那么如何将一个 std::unique_ptr 对象持有的堆内存转移给另外一个呢？答案是使用移动构造，示例代码如下：\n#include \u0026lt;memory\u0026gt; int main() { std::unique_ptr\u0026lt;int\u0026gt; sp1(std::make_unique\u0026lt;int\u0026gt;(123)); std::unique_ptr\u0026lt;int\u0026gt; sp2(std::move(sp1)); std::unique_ptr\u0026lt;int\u0026gt; sp3; sp3 = std::move(sp2); return 0; } 以上代码利用 std::move 将 sp1 持有的堆内存（值为 123）转移给 sp2，再把 sp2 转移给 sp3。最后，sp1 和 sp2 不再持有堆内存的引用，变成一个空的智能指针对象。并不是所有的对象的 std::move 操作都有意义，只有实现了移动构造函数（Move Constructor）或移动赋值运算符（operator =）的类才行，而 std::unique_ptr 正好实现了这二者，以下是实现伪码：\ntemplate\u0026lt;typename T, typename Deletor\u0026gt; class unique_ptr { //其他函数省略... public: unique_ptr(unique_ptr\u0026amp;\u0026amp; rhs) { this-\u0026gt;m_pT = rhs.m_pT; //源对象释放 rhs.m_pT = nullptr; } unique_ptr\u0026amp; operator=(unique_ptr\u0026amp;\u0026amp; rhs) { this-\u0026gt;m_pT = rhs.m_pT; //源对象释放 rhs.m_pT = nullptr; return *this; } private: T* m_pT; }; 这是 std::unique_ptr 具有移动语义的原因，希望读者可以理解之。关于移动构造和 std::move，我们将在后面章节详细介绍。\nstd::unique_ptr 不仅可以持有一个堆对象，也可以持有一组堆对象，示例如下：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; int main() { //创建10个int类型的堆对象 //形式1 std::unique_ptr\u0026lt;int[]\u0026gt; sp1(new int[10]); //形式2 std::unique_ptr\u0026lt;int[]\u0026gt; sp2; sp2.reset(new int[10]); //形式3 std::unique_ptr\u0026lt;int[]\u0026gt; sp3(std::make_unique\u0026lt;int[]\u0026gt;(10)); for (int i = 0; i \u0026lt; 10; ++i) { sp1[i] = i; sp2[i] = i; sp3[i] = i; } for (int i = 0; i \u0026lt; 10; ++i) { std::cout \u0026lt;\u0026lt; sp1[i] \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; sp2[i] \u0026lt;\u0026lt; \u0026#34;, \u0026#34; \u0026lt;\u0026lt; sp3[i] \u0026lt;\u0026lt; std::endl; } return 0; } 程序执行结果如下：\n[root@myaliyun testmybook]# g++ -g -o test_unique_ptr_with_array test_unique_ptr_with_array.cpp -std=c++17 [root@myaliyun testmybook]# ./test_unique_ptr_with_array 0, 0, 0 1, 1, 1 2, 2, 2 3, 3, 3 4, 4, 4 5, 5, 5 6, 6, 6 7, 7, 7 8, 8, 8 9, 9, 9 std::shared_ptr 和 std::weak_ptr 也可以持有一组堆对象，用法与 std::unique_ptr 相同，下文不再赘述。\n自定义智能指针对象持有的资源的释放函数\n默认情况下，智能指针对象在析构时只会释放其持有的堆内存（调用 delete 或者 delete[]），但是假设这块堆内存代表的对象还对应一种需要回收的资源（如操作系统的套接字句柄、文件句柄等），我们可以通过自定义智能指针的资源释放函数。假设现在有一个 Socket 类，对应着操作系统的套接字句柄，在回收时需要关闭该对象，我们可以如下自定义智能指针对象的资源析构函数，这里以 std::unique_ptr 为例：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; class Socket { public: Socket() { } ~Socket() { } //关闭资源句柄 void close() { } }; int main() { auto deletor = [](Socket* pSocket) { //关闭句柄 pSocket-\u0026gt;close(); //TODO: 你甚至可以在这里打印一行日志... delete pSocket; }; std::unique_ptr\u0026lt;Socket, void(*)(Socket * pSocket)\u0026gt; spSocket(new Socket(), deletor); return 0; } 自定义 std::unique_ptr 的资源释放函数其规则是：\nstd::unique_ptr\u0026lt;T, DeletorFuncPtr\u0026gt; 其中 T 是你要释放的对象类型，DeletorPtr 是一个自定义函数指针。上述代码 33 行表示 DeletorPtr 有点复杂，我们可以使用 decltype(deletor) 让编译器自己推导 deletor 的类型，因此可以将 33 行代码修改为：\nstd::unique_ptr\u0026lt;Socket, decltype(deletor)\u0026gt; spSocket(new Socket(), deletor); std::shared_ptr std::unique_ptr 对其持有的资源具有独占性，而 std::shared_ptr 持有的资源可以在多个 std::shared_ptr 之间共享，每多一个 std::shared_ptr 对资源的引用，资源引用计数将增加 1，每一个指向该资源的 std::shared_ptr 对象析构时，资源引用计数减 1，最后一个 std::shared_ptr 对象析构时，发现资源计数为 0，将释放其持有的资源。多个线程之间，递增和减少资源的引用计数是安全的。（注意：这不意味着多个线程同时操作 std::shared_ptr 引用的对象是安全的）。std::shared_ptr 提供了一个 use_count() 方法来获取当前持有资源的引用计数。除了上面描述的，std::shared_ptr 用法和 std::unique_ptr 基本相同。\n下面是一个初始化 std::shared_ptr 的示例：\n//初始化方式1 std::shared_ptr\u0026lt;int\u0026gt; sp1(new int(123)); //初始化方式2 std::shared_ptr\u0026lt;int\u0026gt; sp2; sp2.reset(new int(123)); //初始化方式3 std::shared_ptr\u0026lt;int\u0026gt; sp3; sp3 = std::make_shared\u0026lt;int\u0026gt;(123); 和 std::unique_ptr 一样，你应该优先使用 std::make_shared 去初始化一个 std::shared_ptr 对象。\n再来看另外一段代码：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; class A { public: A() { std::cout \u0026lt;\u0026lt; \u0026#34;A constructor\u0026#34; \u0026lt;\u0026lt; std::endl; } ~A() { std::cout \u0026lt;\u0026lt; \u0026#34;A destructor\u0026#34; \u0026lt;\u0026lt; std::endl; } }; int main() { { //初始化方式1 std::shared_ptr\u0026lt;A\u0026gt; sp1(new A()); std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; //初始化方式2 std::shared_ptr\u0026lt;A\u0026gt; sp2(sp1); std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; sp2.reset(); std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; { std::shared_ptr\u0026lt;A\u0026gt; sp3 = sp1; std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; } std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; } return 0; } 上述代码 22 行 sp1 构造时，同时触发对象 A 的构造，因此 A 的构造函数会执行； 此时只有一个 sp1 对象引用 22 行 new 出来的 A 对象（为了叙述方便，下文统一称之为资源对象 A），因此代码 24 行打印出来的引用计数值为 1； 代码 27 行，利用 sp1 拷贝一份 sp2，导致代码 28 行打印出来的引用计数为 2； 代码 30 行调用 sp2 的 reset() 方法，sp2 释放对资源对象 A 的引用，因此代码 31 行打印的引用计数值再次变为 1； 代码 34 行 利用 sp1 再次 创建 sp3，因此代码 35 行打印的引用计数变为 2； 程序执行到 36 行以后，sp3 出了其作用域被析构，资源 A 的引用计数递减 1，因此 代码 38 行打印的引用计数为 1； 程序执行到 39 行以后，sp1 出了其作用域被析构，在其析构时递减资源 A 的引用计数至 0，并析构资源 A 对象，因此类 A 的析构函数被调用。 所以整个程序的执行结果如下：\n[root@myaliyun testmybook]# ./test_shared_ptr_use_count A constructor use count: 1 use count: 2 use count: 1 use count: 2 use count: 1 A destructor std::enable_shared_from_this\n实际开发中，有时候需要在类中返回包裹当前对象（this）的一个 std::shared_ptr 对象给外部使用，C++ 新标准也为我们考虑到了这一点，有如此需求的类只要继承自 std::enable_shared_from_this 模板对象即可。用法如下：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; class A : public std::enable_shared_from_this\u0026lt;A\u0026gt; { public: A() { std::cout \u0026lt;\u0026lt; \u0026#34;A constructor\u0026#34; \u0026lt;\u0026lt; std::endl; } ~A() { std::cout \u0026lt;\u0026lt; \u0026#34;A destructor\u0026#34; \u0026lt;\u0026lt; std::endl; } std::shared_ptr\u0026lt;A\u0026gt; getSelf() { return shared_from_this(); } }; int main() { std::shared_ptr\u0026lt;A\u0026gt; sp1(new A()); std::shared_ptr\u0026lt;A\u0026gt; sp2 = sp1-\u0026gt;getSelf(); std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; return 0; } 上述代码中，类 A 的继承 std::enable_shared_from_this 并提供一个 getSelf() 方法返回自身的 std::shared_ptr 对象，在 getSelf() 中调用 shared_from_this() 即可。\nstd::enable_shared_from_this 用起来比较方便，但是也存在很多不易察觉的陷阱。\n陷阱一：不应该共享栈对象的 this 给智能指针对象\n假设我们将上面代码 main 函数 25 行生成 A 对象的方式改成一个栈变量，即：\n//其他相同代码省略... int main() { A a; std::shared_ptr\u0026lt;A\u0026gt; sp2 = a.getSelf(); std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp2.use_count() \u0026lt;\u0026lt; std::endl; return 0; } 运行修改后的代码会发现程序在 std::shared_ptr sp2 = a.getSelf(); 产生崩溃。这是因为，智能指针管理的是堆对象，栈对象会在函数调用结束后自行销毁，因此不能通过 shared_from_this() 将该对象交由智能指针对象管理。切记：智能指针最初设计的目的就是为了管理堆对象的（即那些不会自动释放的资源）。\n陷阱二：避免 std::enable_shared_from_this 的循环引用问题\n再来看另外一段代码：\n// test_std_enable_shared_from_this.cpp : This file contains the \u0026#39;main\u0026#39; function. Program execution begins and ends there. // #include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; class A : public std::enable_shared_from_this\u0026lt;A\u0026gt; { public: A() { m_i = 9; //注意: //比较好的做法是在构造函数里面调用shared_from_this()给m_SelfPtr赋值 //但是很遗憾不能这么做,如果写在构造函数里面程序会直接崩溃 std::cout \u0026lt;\u0026lt; \u0026#34;A constructor\u0026#34; \u0026lt;\u0026lt; std::endl; } ~A() { m_i = 0; std::cout \u0026lt;\u0026lt; \u0026#34;A destructor\u0026#34; \u0026lt;\u0026lt; std::endl; } void func() { m_SelfPtr = shared_from_this(); } public: int m_i; std::shared_ptr\u0026lt;A\u0026gt; m_SelfPtr; }; int main() { { std::shared_ptr\u0026lt;A\u0026gt; spa(new A()); spa-\u0026gt;func(); } return 0; } 乍一看上面的代码好像看不出什么问题，让我们来实际运行一下看看输出结果：\n[root@myaliyun testmybook]# g++ -g -o test_std_enable_shared_from_this_problem test_std_enable_shared_from_this_problem.cpp [root@myaliyun testmybook]# ./test_std_enable_shared_from_this_problem A constructor 我们发现在程序的整个生命周期内，只有 A 类构造函数的调用输出，没有 A 类析构函数的调用输出，这意味着 new 出来的 A 对象产生了内存泄漏了！\n我们来分析一下为什么 new 出来的 A 对象得不到释放。当程序执行到 42 行后，spa 出了其作用域准备析构，在析构时其发现仍然有另外的一个 std::shared_ptr 对象即 A::m_SelfPtr 引用了 A，因此 spa 只会将 A 的引用计数递减为 1，然后就销毁自身了。现在留下一个矛盾的处境：必须销毁 A 才能销毁其成员变量 m_SelfPtr，而销毁 m_SelfPtr 必须先销毁 A。这就是所谓的 std::enable_shared_from_this 的循环引用问题。我们在实际开发中应该避免做出这样的逻辑设计，这种情形下即使使用了智能指针也会造成内存泄漏。也就是说一个资源的生命周期可以交给一个智能指针对象，但是该智能指针的生命周期不可以再交给整个资源来管理。\nstd::weak_ptr std::weak_ptr 是一个不控制资源生命周期的智能指针，是对对象的一种弱引用，只是提供了对其管理的资源的一个访问手段，引入它的目的为协助 std::shared_ptr 工作。\nstd::weak_ptr 可以从一个 std::shared_ptr 或另一个 std::weak_ptr 对象构造，std::shared_ptr 可以直接赋值给 std::weak_ptr ，也可以通过 std::weak_ptr 的 lock() 函数来获得 std::shared_ptr。它的构造和析构不会引起引用计数的增加或减少。std::weak_ptr 可用来解决 std::shared_ptr 相互引用时的死锁问题（即两个std::shared_ptr 相互引用，那么这两个指针的引用计数永远不可能下降为 0， 资源永远不会释放）。\n示例代码如下：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; int main() { //创建一个std::shared_ptr对象 std::shared_ptr\u0026lt;int\u0026gt; sp1(new int(123)); std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; //通过构造函数得到一个std::weak_ptr对象 std::weak_ptr\u0026lt;int\u0026gt; sp2(sp1); std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; //通过赋值运算符得到一个std::weak_ptr对象 std::weak_ptr\u0026lt;int\u0026gt; sp3 = sp1; std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; //通过一个std::weak_ptr对象得到另外一个std::weak_ptr对象 std::weak_ptr\u0026lt;int\u0026gt; sp4 = sp2; std::cout \u0026lt;\u0026lt; \u0026#34;use count: \u0026#34; \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; return 0; } 程序执行结果如下：\n[root@myaliyun testmybook]# g++ -g -o test_weak_ptr test_weak_ptr.cpp [root@myaliyun testmybook]# ./test_weak_ptr use count: 1 use count: 1 use count: 1 use count: 1 无论通过何种方式创建 std::weak_ptr 都不会增加资源的引用计数，因此每次输出引用计数的值都是 1。\n既然，std::weak_ptr 不管理对象的生命周期，那么其引用的对象可能在某个时刻被销毁了，如何得知呢？std::weak_ptr 提供了一个 expired() 方法来做这一项检测，返回 true，说明其引用的资源已经不存在了；返回 false，说明该资源仍然存在，这个时候可以使用 std::weak_ptr 的 lock() 方法得到一个 std::shared_ptr 对象然后继续操作资源，以下代码演示了该用法：\n//tmpConn_ 是一个 std::weak_ptr\u0026lt;TcpConnection\u0026gt; 对象 //tmpConn_引用的TcpConnection已经销毁，直接返回 if (tmpConn_.expired()) return; std::shared_ptr\u0026lt;TcpConnection\u0026gt; conn = tmpConn_.lock(); if (conn) { //对conn进行操作，省略... } 有读者可能对上述代码产生疑问，既然使用了 std::weak_ptr 的 expired() 方法判断了对象是否存在，为什么不直接使用 std::weak_ptr 对象对引用资源进行操作呢？实际上这是行不通的，std::weak_ptr 类没有重写 operator-\u0026gt; 和 operator* 方法，因此不能像 std::shared_ptr 或 std::unique_ptr 一样直接操作对象，同时 std::weak_ptr 类也没有重写 operator! 操作，因此也不能通过 std::weak_ptr 对象直接判断其引用的资源是否存在：\n#include \u0026lt;memory\u0026gt; class A { public: void doSomething() { } }; int main() { std::shared_ptr\u0026lt;A\u0026gt; sp1(new A()); std::weak_ptr\u0026lt;A\u0026gt; sp2(sp1); //正确代码 if (sp1) { //正确代码 sp1-\u0026gt;doSomething(); (*sp1).doSomething(); } //正确代码 if (!sp1) { } //错误代码，无法编译通过 //if (sp2) //{ // //错误代码，无法编译通过 // sp2-\u0026gt;doSomething(); // (*sp2).doSomething(); //} //错误代码，无法编译通过 //if (!sp2) //{ //} return 0; } 之所以 std::weak_ptr 不增加引用资源的引用计数不管理资源的生命周期，是因为，即使它实现了以上说的几个方法，调用它们也是不安全的，因为在调用期间，引用的资源可能恰好被销毁了，这会造成棘手的错误和麻烦。\n因此，std::weak_ptr 的正确使用场景是那些资源如果可能就使用，如果不可使用则不用的场景，它不参与资源的生命周期管理。例如，网络分层结构中，Session 对象（会话对象）利用 Connection 对象（连接对象）提供的服务工作，但是 Session 对象不管理 Connection 对象的生命周期，Session 管理 Connection 的生命周期是不合理的，因为网络底层出错会导致 Connection 对象被销毁，此时 Session 对象如果强行持有 Connection 对象与事实矛盾。\nstd::weak_ptr 的应用场景，经典的例子是订阅者模式或者观察者模式中。这里以订阅者为例来说明，消息发布器只有在某个订阅者存在的情况下才会向其发布消息，而不能管理订阅者的生命周期。\nclass Subscriber { }; class SubscribeManager { public: void publish() { for (const auto\u0026amp; iter : m_subscribers) { if (!iter.expired()) { //TODO：给订阅者发送消息 } } } private: std::vector\u0026lt;std::weak_ptr\u0026lt;Subscriber\u0026gt;\u0026gt; m_subscribers; }; 智能指针对象的大小 一个 std::unique_ptr 对象大小与裸指针大小相同（即 sizeof(std::unique_ptr) == sizeof(void*)），而 std::shared_ptr 的大小是 std::unique_ptr 的一倍。以下是我分别在 Visual Studio 2019 和 gcc/g++ 4.8 上（二者都编译成 x64 程序）的测试结果：\n测试代码\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; #include \u0026lt;string\u0026gt; int main() { std::shared_ptr\u0026lt;int\u0026gt; sp0; std::shared_ptr\u0026lt;std::string\u0026gt; sp1; sp1.reset(new std::string()); std::unique_ptr\u0026lt;int\u0026gt; sp2; std::weak_ptr\u0026lt;int\u0026gt; sp3; std::cout \u0026lt;\u0026lt; \u0026#34;sp0 size: \u0026#34; \u0026lt;\u0026lt; sizeof(sp0) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;sp1 size: \u0026#34; \u0026lt;\u0026lt; sizeof(sp1) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;sp2 size: \u0026#34; \u0026lt;\u0026lt; sizeof(sp2) \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; \u0026#34;sp3 size: \u0026#34; \u0026lt;\u0026lt; sizeof(sp3) \u0026lt;\u0026lt; std::endl; return 0; } Visual Studio 2019 运行结果：\ngcc/g++ 运行结果：\n在 32 位机器上，std_unique_ptr 占 4 字节，std::shared_ptr 和 std::weak_ptr 占 8 字节；在 64 位机器上，std_unique_ptr 占 8 字节，std::shared_ptr 和 std::weak_ptr 占 16 字节。也就是说，std_unique_ptr 的大小总是和原始指针大小一样，std::shared_ptr 和 std::weak_ptr 大小是原始指针的一倍。\n智能指针使用注意事项 C++ 新标准提倡的理念之一是不应该再手动调用 delete 或者 free 函数去释放内存了，而应该把它们交给新标准提供的各种智能指针对象。C++ 新标准中的各种智能指针是如此的实用与强大，在现代 C++ 项目开发中，读者应该尽量去使用它们。智能指针虽然好用，但稍不注意，也可能存在许多难以发现的 bug，这里我根据经验总结了几条：\n一旦一个对象使用智能指针管理后，就不该再使用原始裸指针去操作；\n看一段代码：\n#include \u0026lt;memory\u0026gt; class Subscriber { }; int main() { Subscriber* pSubscriber = new Subscriber(); std::unique_ptr\u0026lt;Subscriber\u0026gt; spSubscriber(pSubscriber); delete pSubscriber; return 0; } 这段代码利用创建了一个堆对象 Subscriber，然后利用智能指针 spSubscriber 去管理之，可以却私下利用原始指针销毁了该对象，这让智能指针对象 spSubscriber 情何以堪啊？\n记住，一旦智能指针对象接管了你的资源，所有对资源的操作都应该通过智能指针对象进行，不建议再通过原始指针进行操作了。当然，除了 std::weak_ptr，std::unique_ptr 和 std::shared_ptr 都提供了获取原始指针的方法——get() 函数。\nint main() { Subscriber* pSubscriber = new Subscriber(); std::unique_ptr\u0026lt;Subscriber\u0026gt; spSubscriber(pSubscriber); //pTheSameSubscriber和pSubscriber指向同一个对象 Subscriber* pTheSameSubscriber= spSubscriber.get(); return 0; } 分清楚场合应该使用哪种类型的智能指针；\n通常情况下，如果你的资源不需要在其他地方共享，那么应该优先使用 std::unique_ptr，反之使用 std::shared_ptr，当然这是在该智能指针需要管理资源的生命周期的情况下；如果不需要管理对象的生命周期，请使用 std::weak_ptr。\n认真考虑，避免操作某个引用资源已经释放的智能指针；\n前面的例子，一定让你觉得非常容易知道一个智能指针的持有的资源是否还有效，但是还是建议在不同场景谨慎一点，有些场景是很容易造成误判。例如下面的代码：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; class T { public: void doSomething() { std::cout \u0026lt;\u0026lt; \u0026#34;T do something...\u0026#34; \u0026lt;\u0026lt; m_i \u0026lt;\u0026lt; std::endl; } private: int m_i; }; int main() { std::shared_ptr\u0026lt;T\u0026gt; sp1(new T()); const auto\u0026amp; sp2 = sp1; sp1.reset(); //由于sp2已经不再持有对象的引用，程序会在这里出现意外的行为 sp2-\u0026gt;doSomething(); return 0; } 上述代码中，sp2 是 sp1 的引用，sp1 被置空后，sp2 也一同为空。这时候调用 sp2-\u0026gt;doSomething()，sp2-\u0026gt;（即 operator-\u0026gt;）在内部会调用 get() 方法获取原始指针对象，这时会得到一个空指针（地址为 0），继续调用 doSomething() 导致程序崩溃。\n你一定仍然觉得这个例子也能很明显地看出问题，ok，让我们把这个例子放到实际开发中再来看一下：\n//连接断开 void MonitorServer::OnClose(const std::shared_ptr\u0026lt;TcpConnection\u0026gt;\u0026amp; conn) { std::lock_guard\u0026lt;std::mutex\u0026gt; guard(m_sessionMutex); for (auto iter = m_sessions.begin(); iter != m_sessions.end(); ++iter) { //通过比对connection对象找到对应的session if ((*iter)-\u0026gt;GetConnectionPtr() == conn) { m_sessions.erase(iter); //注意这里：程序在此处崩溃 LOGI(\u0026#34;monitor client disconnected: %s\u0026#34;, conn-\u0026gt;peerAddress().toIpPort().c_str()); break; } } } 这段代码不是我杜撰的，而是来自于我实际的一个商业项目中。注意代码中我提醒注意的地方，该段程序会在代码 12 行处崩溃，崩溃原因是调用了 conn-\u0026gt;peerAddress() 方法。为什么这个方法的调用可能会引起崩溃？现在可以一目了然地看出了吗？\n崩溃原因是传入的 conn 对象和上一个例子中的 sp2 一样都是另外一个 std::shared_ptr 的引用，当连接断开时，对应的 TcpConnection 对象可能早已被销毁，而 conn 引用就会变成空指针（严格来说是不再拥有一个 TcpConnection 对象），此时调用 TcpConnection 的 peerAddress() 方法就会产生和上一个示例一样的错误。\n作为类成员变量时，应该优先使用前置声明（forward declarations）\n我们知道，为了减小编译依赖加快编译速度和生成二进制文件的大小，C/C++ 项目中一般在 *.h 文件对于指针类型尽量使用前置声明，而不是直接包含对应类的头文件。例如：\n//Test.h //在这里使用A的前置声明，而不是直接包含A.h文件 class A; class Test { public: Test(); ~Test(); private: A* m_pA; }; 同样的道理，在头文件中当使用智能指针对象作为类成员变量时，也应该优先使用前置声明去引用智能指针对象的包裹类，而不是直接包含包裹类的头文件。\n//Test.h #include \u0026lt;memory\u0026gt; //智能指针包裹类A，这里优先使用A的前置声明，而不是直接包含A.h class A; class Test { public: Test(); ~Test(); private: std::unique_ptr\u0026lt;A\u0026gt; m_spA; }; C++ 新标准中的智能指针我想介绍的就这么多了，Modern C/C++ 已经变为 C/C++ 开发的趋势，希望读者能善用和熟练使用本节介绍的后三种智能指针对象。\n","permalink":"https://haokiu.com/blog/913fb3f31d024baf871726b2f22cdfde/","summary":"详解 C++ 11 中的智能指针 C/C++ 语言最为人所诟病的特性之一就是存在内存泄露问题，因此后来的大多数语言都提供了内置内存分配与释放功能，有的甚至干脆对语言的使用者屏蔽了内存指针这一概念。这里不置贬褒，手动分配内存与手动释放内存有利也有弊，自动分配内存和自动释放内存亦如此，这是两种不同的设计哲学。有人认为，内存如此重要的东西怎么能放心交给用户去管理呢？而另外一些人则认为，内存如此重要的东西怎么能放心交给系统去管理呢？在 C/C++ 语言中，内存泄露的问题一直困扰着广大的开发者，因此各类库和工具的一直在努力尝试各种方法去检测和避免内存泄露，如 boost，智能指针技术应运而生。\nC++ 98/03 的尝试——std::auto_ptr 在 2019 年讨论 std::auto_ptr 不免有点让人怀疑是不是有点过时了，确实如此，随着 C++11 标准的出现（最新标准是 C++20），std::auto_ptr 已经被彻底废弃了，取而代之是 std::unique_ptr。然而，我之所以还向你介绍一下 std::auto_ptr 的用法以及它的设计不足之处是想让你了解 C++ 语言中智能指针的发展过程，一项技术如果我们了解它过去的样子和发展的轨迹，我们就能更好地掌握它，不是吗？\nstd::auto_ptr 的基本用法如下代码所示：\n#include \u0026lt;memory\u0026gt; int main() { //初始化方式1 std::auto_ptr\u0026lt;int\u0026gt; sp1(new int(8)); //初始化方式2 std::auto_ptr\u0026lt;int\u0026gt; sp2; sp2.reset(new int(8)); return 0; } 智能指针对象 sp1 和 sp2 均持有一个在堆上分配 int 对象，其值均是 8，这两块堆内存均可以在 sp1 和 sp2 释放时得到释放。这是 std::auto_ptr 的基本用法。\nsp 是 smart pointer（智能指针）的简写。\nstd::auto_ptr 真正让人容易误用的地方是其不常用的复制语义，即当复制一个 std::auto_ptr 对象时（拷贝复制或 operator = 复制），原对象所持有的堆内存对象也会转移给复制出来的对象。示例代码如下：\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;memory\u0026gt; int main() { //测试拷贝构造 std::auto_ptr\u0026lt;int\u0026gt; sp1(new int(8)); std::auto_ptr\u0026lt;int\u0026gt; sp2(sp1); if (sp1.get() != NULL) { std::cout \u0026lt;\u0026lt; \u0026#34;sp1 is not empty.\u0026#34; \u0026lt;\u0026lt; std::endl; } else { std::cout \u0026lt;\u0026lt; \u0026#34;sp1 is empty.","title":"详解 C++ 11 中的智能指针"},{"content":"谈一谈年终奖 转眼 2019 年就快过完了，对于广大程序员读者来说，重要的事情除了关心能不能买到回老家的车票以外，剩下的事情应该就属年终奖了。\n对于 IT 行业来说，所谓年终奖其实就是公司在当年的月底基于你工资的数额发一定的比例的奖金，这也是很多企业的 HR 和猎头向求职者“许诺”的待遇之一。关于年终奖，一般是求职者在应聘时和 HR 谈好，再结合所在的公司的规定在年终兑现给求职者。但是，城市的套路太深了，本文就和大家讨论一下关于年终奖的那些坑，希望对读者朋友有一定启发意义。\n年终奖的计算套路 先来说通用规则吧。IT 行业默认的不成文的规定，大多数公司，对于普通员工的年终奖一般是月底多发一个月工资，也就是所谓的 13 薪，这个基本上是保底的。对于从事开发的小伙伴来说，这个规则适用于初中高级，对于技术专家或者开发经理及以上级别一般保底工资会大于 13 薪，常见的是 14 ~ 16 薪不等，总结起来，就是所谓 12 + n，n 的可能取值是 1 ~ 5，它们就是所谓的年终奖，这是大多数公司的通用做法。但是在这些规定的基础之上不同的公司也有一些特殊的规定，常见的有如下几种形式：\n年终奖的数量是 n 个月的月薪，但是要根据员工在当年在公司实际工作的天数来定，也就是说员工实际拿到的年终奖数目是 年终奖数目 = 月薪 * n * （员工当年实际工作的天数 / 365）\n举个例子，员工小明在某公司当年工作半年，其月薪是 20k， 当时和 HR 谈好是 2 个月年终奖（n = 2），那么小明当年拿到的年终奖是数额是：20000 * 2 * 0.5 = 20000。\nok，有读者看到这里可能美滋滋，他可能会想，今年 12 月 1 日入职现在的公司，按这个规则年终奖是 2 个月，那么我今年的年终奖可以拿到 20000 * 2 * （1 / 12） = 3333，3333 元也不少啦，过年回家给长辈或者小朋友包个红包，或者给女朋友买几件衣服也是戳戳有余的啦。我只能说，这位读者想多了。因为某些公司还有第 2 条规定。\n计算年终奖系数时虽然按员工当年实际工作的天数 / 365，但是如果员工当年实际工作的天数小于某个数值（例如 2 个月），则系数为 0。也就是说，很多 12 月份入职该公司的小伙伴在当年大概率是没有年终奖的。\n除了上述两个规定外，企业对于年终奖还有一个比较常见的规定，就是年终奖绩效正态分布制。啥意思呢？举个例子，我在求职某大型旅游互联网公司时，HR 告诉我待遇是 16 薪，于是我就相信了。等到当年年底的时候发现，果然是 16 薪啊，但是每个员工都需要进行绩效考评，绩效分为 ABCD 四个等级，A 最优，D 最差，且 ABCD 四个等级的比例是 20%、30%、30%、20%，也就是说一个部门 10 个人，实际上只有 2 个人能拿到 16 薪，剩下的依次是 15 薪、14 薪和 13 薪。到此时，我也只能无奈的接受现实。\n这也是为什么同等的年薪，HR 在和你谈薪时，会尽量压低你的月薪，而承诺多给你月薪次数。举个例子，同样的年薪 39 W，你要求按 30k * 13 来发，但是 HR 会找你谈判希望是以 26k * 15 来发。HR 会“站在你的角度苦口婆心“的劝说你，员工上班不容易， 26k * 15 相比 30k * 13 的方式，每个月可以少交很多税等理由。但是请读者注意：这里感觉好像总额是一样的，但是差别其实非常大，30k * 13 虽然多交了一点税（纳税光荣），但是比 26k * 15 更有保障一些。首先，30k 是实实在在每个月的月薪，发 13 个月（多发一个月的年终奖）基本也不成问题；但是对于 26k * 15 这个 15 薪多出来的 3 个月属于年终奖部分，由于年终奖具体是多少一般不会明确的写到劳动合同中去的，根据上文介绍的公司对于年终奖的数额发放比例和计算规则来说，你最终实际上能拿到 26k * 13 已经算不错的了。\n另外一种绩效规则就是，根据员工的当年表现，给员工一个绩效值，例如我曾经的一个公司，绩效值范围 0.5 ~ 1.5，如果满额的年终奖是 2 万（月薪），你年底的绩效值是 0.5，你的年终奖拿 20000 * 0.5 = 10000 元，如果你年终的绩效值是 1.5，你的年终奖是 20000 * 1.5 = 30000 元。这里不得不吐槽一些公司的一些拿着鸡毛当令箭的领导，有些公司的某些部门的领导（开发经理或者主管级别），在公司没有规定某个绩效值不少于或者不多于某个值的情况，年年给部门下面的任劳任怨的某些员工的绩效系数都评为 1.0。我的言外之意就是，部门员工认认真真干好本职工作，在公司干了三五年，薪资基本不涨。\n另外，也有一些公司将年终奖一分为二，分为年中奖和年终奖部分，为这类公司点个赞。例如某公司某员工的是 14 薪，其中额外的 2 个月分两次在当年的 6 月份和 12 月份发放，每次多发 1 个月。当然这类发放方式中具体年中和年终部分是多少也可能按绩效来评比，但员工能尽快拿到手，离职损失最少。\n当然，上面说的是一些普遍的计算年终奖的规则和套路，对于那些以高绩效来确定员工年终奖不在此列。例如游戏公司，某年的腾讯的王者荣耀开发团队的年终奖。\n年终奖的发放时间套路 对于大多数良心企业，发放年终奖的时间，会在次年 1 月份随着上一年的 12 月份工资一起发放，当然不一定是一次到账，可能是 12 月份工资先到账，然后过几天年终奖到账，或者反过来。对于一些员工人数比较多，考核流程比较长，年终奖的发放数额需要一段较长的时间才会统计出来，这类企业年终奖一般会在次年的三四月发放。这两类公司的年终奖发放时间，都可以让人接受。但是下面一些公司发放年终奖的方式就让人非常鄙视：\n我们知道每年过完年的三四月份是离职求职的高峰期，很多公司为了防止员工离职，故意拖延前一年的年终奖，甚至有拖到第二年的七八月份的，且规定在这之前离职年终奖就没有了。大多数员工针对这种 情况都只能默默的接受现实：要不选择熬到年终奖发放的那一天之后再离职，可能因此也错过了一些更好的工作机会；要不就是壮士断腕，选择放弃年终奖。后者，对于工作没几年的人来说，年终奖数额不大，没多大影响，但是对于已经工作不少年了，年龄偏大，养活一家老小，这一笔年终奖金额会比较大，放弃很可惜，不放弃又错失新的工作机会，就比较可惜。\n我曾经有一份工作，老板故意拖着年终奖不发，直到第二年五六月都没有发，同事们议论纷纷，HR 竟然在群里和大家说，据她了解大多数公司在第二年下半年发放前一年的年终奖是非常普遍的现象。\n公司业绩不好的情况下，高级员工年终奖减半，普通员工可能没有年终奖。我遇到过这样一类公司，那一年公司先是在快到年底时裁掉了一批员工，剩下的的员工公司不再裁员，但是当年年终奖大大折扣了。这样的举动也会变相导致员工大批离职。\n离职到底有没有年终奖？ 我相信很多读者很关心这个问题，毕竟和月薪相比，年终奖可能是大头部分。除去上文介绍的无良公司离职时没有年终奖的情况，一般公司会有一个明文规定，规定在当年的某月某日之前（例如元旦之前）的离职是没有年终奖的，所以如果有读者要离职但有关心年终奖能否拿的到可以查询下公司的相关规章制度。这个日期，一般是当年结束之前的某一天就是合理的，但是倘若在次年的某月某日就不太合理了。建议大家离职之前和 HR 核实清楚。\n上面说的是主动离职，倘若你被公司裁员了，年终奖也应该算在赔偿款之内。\n年终奖避坑建议 相对于企业，员工一般是弱势群体，尤其是一些大型企业，普通人没有那么多的时间、精力和金钱去公司的法务部门耗。所以，相对于离职之后出现经济纠纷，更多的建议读者在入职前和 HR 关于一些福利待遇方面谈好。事前风险控制比事后风险控制收益更大一些。谈钱不羞耻，千万不要碍于面子，不好意思在一些细节上问。HR 是代表公司，有义务把各项福利待遇和入职者交代清楚。\n关于程序员如何与 HR 谈薪，我公众号曾专门写过这样一篇文章，可以参考这里《技术面试与 HR 谈薪技巧》。本文的重点是年终奖，由于大多数人都是普通员工，年终奖等福利的具体数额都不会写到劳动合同里面去的，所以到了年终的时候，企业给不给你发年终奖、发多少年终奖、什么时候发就要看公司的实际处理了，此时个人是很被动的，遇到企业效益不好的时候不发年终奖的也是很常见的。但是呢，HR 或者主管在面试你的时候，会以最大比例的年终奖和股票来作为条件压你的月薪。月薪是有保障的，因为实实在在的写到劳动合同里面去的，所以我的第一个建议是，谈薪时尽量把月薪谈高。如果你是应聘某些核心职位，可以直接和 HR 商量，不要或者少要年终奖和股票期权，但把月薪要的高一点。读者可以想想上文中的 30k * 13 与 26k * 15 的例子。\n第二个建议是，离职之前，把年终奖的发放规定打探清楚，衡量清楚选择继续留下来等到发年终奖还是去下一家公司这二者的收益哪个大。当然，一些不错的领导，会在你离职时为你尽量争取一部分年终奖。\n有些人会在离职时利用年假褥公司的羊毛，举个例子，某公司规定12 月 1日之前离职的员工没有年终奖，某员工可能需要提前离职，但距离 12 月 1 日还有几天，他可能会在不能来的几天里请掉自己未休完的年假以让离职日超过 12 月 1 日。大多数公司，对这种做法会睁一只眼闭一只眼，但有些公司会有专门的规定，已申请离职的员工，不能连续请年假超过一定的天数（例如 3 天），以此来杜绝这种现象。读者如果离职时要进行此类操作建议查清楚公司在这方面的相关规定。\n第三个建议，关于离职日的日期选择。这个也很有讲究，我经历的有些公司喜欢玩双标。所谓双标就是当月未满工作的天数在计算支付给员工的工资时按两个标准来算，向尽量支付少的工资的方向来计算。举个例子，一种常用的套路就是所谓的国家规定的月工作出勤天数。假设你的月薪是 30k，你最后一个月离职，如果那个月没有较长的节假日，那么计算你离职当月的实际收入是 30k * 你最后一个月的实际出勤日 / 当月的天数，反过来如果你离职的当月有长假，例如 10 月份，而你是在国庆长假后离职的，那么计算你离职当月的实际收入不会算上这法定七天假日的。这是很多公司套路，请假或离职扣薪资时算日薪按按你的月薪 / 21.75，21.75 是所谓的法定月出勤天数，计算绩效或者支付你工资日薪按你的月薪 / 当月天数来算。对于这一类，很多人都无可奈何，尤其是已经从公司离职了。大家了解了这一套规则后，可以根据自己的情况选择离职日期，减少一些自己的损失。\n最后，无论大环境好与不好，作为开发人员，应该踏踏实实把技术学好。核心职位被裁员或者在考评年终奖时，都不会吃亏。\n以上观点，因笔者的经验、经历有限，难免存在个人观点偏颇的问题，欢迎温和的提出意见和建议。『高性能服务器开发』公众号与你同在。\n====== END =====\n欢迎关注公众号『高性能服务器开发』，如果你在学习的过程中有任何疑问可以加入高性能服务器开发交流群：578019391 一起交流，本群汇集 BAT 各类大佬，也欢迎各大互联网公司猎头、HR 进群寻觅人才。\n","permalink":"https://haokiu.com/blog/0f72f7a83bbb4b4fb76a05dc63f5480c/","summary":"谈一谈年终奖 转眼 2019 年就快过完了，对于广大程序员读者来说，重要的事情除了关心能不能买到回老家的车票以外，剩下的事情应该就属年终奖了。\n对于 IT 行业来说，所谓年终奖其实就是公司在当年的月底基于你工资的数额发一定的比例的奖金，这也是很多企业的 HR 和猎头向求职者“许诺”的待遇之一。关于年终奖，一般是求职者在应聘时和 HR 谈好，再结合所在的公司的规定在年终兑现给求职者。但是，城市的套路太深了，本文就和大家讨论一下关于年终奖的那些坑，希望对读者朋友有一定启发意义。\n年终奖的计算套路 先来说通用规则吧。IT 行业默认的不成文的规定，大多数公司，对于普通员工的年终奖一般是月底多发一个月工资，也就是所谓的 13 薪，这个基本上是保底的。对于从事开发的小伙伴来说，这个规则适用于初中高级，对于技术专家或者开发经理及以上级别一般保底工资会大于 13 薪，常见的是 14 ~ 16 薪不等，总结起来，就是所谓 12 + n，n 的可能取值是 1 ~ 5，它们就是所谓的年终奖，这是大多数公司的通用做法。但是在这些规定的基础之上不同的公司也有一些特殊的规定，常见的有如下几种形式：\n年终奖的数量是 n 个月的月薪，但是要根据员工在当年在公司实际工作的天数来定，也就是说员工实际拿到的年终奖数目是 年终奖数目 = 月薪 * n * （员工当年实际工作的天数 / 365）\n举个例子，员工小明在某公司当年工作半年，其月薪是 20k， 当时和 HR 谈好是 2 个月年终奖（n = 2），那么小明当年拿到的年终奖是数额是：20000 * 2 * 0.5 = 20000。\nok，有读者看到这里可能美滋滋，他可能会想，今年 12 月 1 日入职现在的公司，按这个规则年终奖是 2 个月，那么我今年的年终奖可以拿到 20000 * 2 * （1 / 12） = 3333，3333 元也不少啦，过年回家给长辈或者小朋友包个红包，或者给女朋友买几件衣服也是戳戳有余的啦。我只能说，这位读者想多了。因为某些公司还有第 2 条规定。\n计算年终奖系数时虽然按员工当年实际工作的天数 / 365，但是如果员工当年实际工作的天数小于某个数值（例如 2 个月），则系数为 0。也就是说，很多 12 月份入职该公司的小伙伴在当年大概率是没有年终奖的。\n除了上述两个规定外，企业对于年终奖还有一个比较常见的规定，就是年终奖绩效正态分布制。啥意思呢？举个例子，我在求职某大型旅游互联网公司时，HR 告诉我待遇是 16 薪，于是我就相信了。等到当年年底的时候发现，果然是 16 薪啊，但是每个员工都需要进行绩效考评，绩效分为 ABCD 四个等级，A 最优，D 最差，且 ABCD 四个等级的比例是 20%、30%、30%、20%，也就是说一个部门 10 个人，实际上只有 2 个人能拿到 16 薪，剩下的依次是 15 薪、14 薪和 13 薪。到此时，我也只能无奈的接受现实。","title":"谈一谈年终奖"},{"content":"为了节省空间，docker 容器里面有很多命令是没有安装的，提示： Reading package lists\u0026hellip; Done Building dependency tree Reading state information\u0026hellip; Done E: Unable to locate package vim\n更新apt-get源 这时候需要敲：apt-get update\n这个命令的作用是：同步 /etc/apt/sources.list 和 /etc/apt/sources.list.d 中列出的源的索引，这样才能获取到最新的软件包。\n安装vim apt-get install vim\n安装telnet apt-get install telnet\n安装ifconfig apt-get install net-tools\n","permalink":"https://haokiu.com/blog/d5nhvK/","summary":"为了节省空间，docker 容器里面有很多命令是没有安装的，提示： Reading package lists\u0026hellip; Done Building dependency tree Reading state information\u0026hellip; Done E: Unable to locate package vim\n更新apt-get源 这时候需要敲：apt-get update\n这个命令的作用是：同步 /etc/apt/sources.list 和 /etc/apt/sources.list.d 中列出的源的索引，这样才能获取到最新的软件包。\n安装vim apt-get install vim\n安装telnet apt-get install telnet\n安装ifconfig apt-get install net-tools","title":"docker apt-get"},{"content":"golang 的数组与切片有两大区别：\n初始化：数组需要明确指定大小，切片不需要 函数传递：数组是值传递，切片是地址传递 初始化 数组 a := [...]int{1,2,3} a := [3]int{1,2,3} 切片 a:= []int{1,2,3} a := make([]int, 5) a := make([]int, 5, 10) slice的数据结构： go源码slice的数据结构定义：\ntype slice struct { array unsafe.Pointer len int cap int } slice 有三个字段：\n指向真实 array 地址的指针 ptr slice 的长度 len 容量 cap 特性 通过例子说明 slice 和 array 的一些特性。\n函数传递 数组需要明确指定大小，切片不需要。数组是值传递，切片是地址传递\na := [...]int{1, 2, 3, 4, 5, 6} fmt.Println(\u0026#34;star deal array, orginal data is:\u0026#34;) fmt.Println(a) aMaxIndex := len(a) - 1 fmt.Printf(\u0026#34;aMaxIndex:%d\\r\u0026#34;, aMaxIndex) for i, e := range a { if i == aMaxIndex { a[0] += e fmt.Printf(\u0026#34;index is 0, val is :%d\\r\u0026#34;, a[0]) } else { a[i+1] += e fmt.Printf(\u0026#34;index is:%d ,val is :%d\\r\u0026#34;, i+1, a[i+1]) } } fmt.Println(\u0026#34;deal result is:\u0026#34;) fmt.Println(a) s := []int{1, 2, 3, 4, 5, 6} fmt.Println(\u0026#34;star deal slice, orginal data is:\u0026#34;) fmt.Println(s) sMaxIndex := len(s) - 1 fmt.Printf(\u0026#34;aMaxIndex:%d\\r\u0026#34;, sMaxIndex) for i, e := range s { if i == sMaxIndex { s[0] += e fmt.Printf(\u0026#34;index is 0, val is :%d\\r\u0026#34;, s[0]) } else { s[i+1] += e fmt.Printf(\u0026#34;index is:%d ,val is :%d\\r\u0026#34;, i+1, s[i+1]) } } fmt.Println(\u0026#34;deal result is:\u0026#34;) fmt.Println(s) 输出：\nstar deal array, orginal data is: [1 2 3 4 5 6] aMaxIndex:5 index is:1 ,val is :3 index is:2 ,val is :5 index is:3 ,val is :7 index is:4 ,val is :9 index is:5 ,val is :11 index is 0, val is :7 deal result is: [7 3 5 7 9 11] star deal slice, orginal data is: [1 2 3 4 5 6] aMaxIndex:5 index is:1 ,val is :3 index is:2 ,val is :6 index is:3 ,val is :10 index is:4 ,val is :15 index is:5 ,val is :21 index is 0, val is :22 deal result is: [22 3 6 10 15 21] 这个是比较复杂的值传递和地址传递的例子，可以看到：\narray在循环时每次拿到的值（e）是传递数组的值 slice在循环时每次拿到的值（e）是传递地址的值 所以最后a 和 s 的值会不一样。\nslice append的时候内存地址的改变情况 通过一个例子：\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { //说先定义一个切片，只限定长度为1 s := make([]int, 1) //打印出slice的长度，容量以及内存地址 fmt.Printf(\u0026#34;len :%d cap:%d array ptr :%v \\n\u0026#34;, len(s), cap(s), *(*unsafe.Pointer)(unsafe.Pointer(\u0026amp;s))) for i := 0; i \u0026lt; 5; i++ { s = append(s, i) fmt.Printf(\u0026#34;len :%d cap:%d array ptr :%v \\n\u0026#34;, len(s), cap(s), *(*unsafe.Pointer)(unsafe.Pointer(\u0026amp;s))) } //打印出slice fmt.Println(\u0026#34;array:\u0026#34;, s) } 输出：\nlen :1 cap:1 array ptr :0xc042062080 len :2 cap:2 array ptr :0xc0420620c0 len :3 cap:4 array ptr :0xc0420600e0 len :4 cap:4 array ptr :0xc0420600e0 len :5 cap:8 array ptr :0xc0420880c0 len :6 cap:8 array ptr :0xc0420880c0 array: [0 0 1 2 3 4] 可以看出来在append的过程中，内存地址有些是一样的，有些是不一样的，容量也是如此。\n每次cap改变的时候指向array内存的指针都在变化。因为当在使用 append 的时候，如果 cap==len ，这个时候就会新开辟一块更大内存，然后把之前的数据复制过去。\n最后一句输出slice元素的时候为什么会多了一个0呢？是因为make初始化时，都会初始化成对应数据类型的原值。\ncap的扩大规律 go 在 append 的时候放大 cap 是有规律的。在 cap 小于1024的情况下是每次扩大到 2 * cap ，当大于1024之后就每次扩大到 1.25 * cap 。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { //说先定义一个切片，只限定长度为1 s := make([]int, 1) //打印出slice的长度，容量以及内存地址 fmt.Printf(\u0026#34;len :%d cap:%d array ptr :%v \\n\u0026#34;, len(s), cap(s), *(*unsafe.Pointer)(unsafe.Pointer(\u0026amp;s))) for i := 1; i \u0026lt; 1024*2; i++ { s = append(s, i) fmt.Printf(\u0026#34;len :%d cap:%d array ptr :%v \\n\u0026#34;, len(s), cap(s), *(*unsafe.Pointer)(unsafe.Pointer(\u0026amp;s))) } //打印出slice fmt.Println(\u0026#34;array:\u0026#34;, s) } 输出太多，截一部分：\n... len :1019 cap:1024 array ptr :0xc000184000 len :1020 cap:1024 array ptr :0xc000184000 len :1021 cap:1024 array ptr :0xc000184000 len :1022 cap:1024 array ptr :0xc000184000 len :1023 cap:1024 array ptr :0xc000184000 len :1024 cap:1024 array ptr :0xc000184000 len :1025 cap:1280 array ptr :0xc000188000 len :1026 cap:1280 array ptr :0xc000188000 len :1027 cap:1280 array ptr :0xc000188000 len :1028 cap:1280 array ptr :0xc000188000 ... ","permalink":"https://haokiu.com/blog/gnNp9N/","summary":"golang 的数组与切片有两大区别：\n初始化：数组需要明确指定大小，切片不需要 函数传递：数组是值传递，切片是地址传递 初始化 数组 a := [...]int{1,2,3} a := [3]int{1,2,3} 切片 a:= []int{1,2,3} a := make([]int, 5) a := make([]int, 5, 10) slice的数据结构： go源码slice的数据结构定义：\ntype slice struct { array unsafe.Pointer len int cap int } slice 有三个字段：\n指向真实 array 地址的指针 ptr slice 的长度 len 容量 cap 特性 通过例子说明 slice 和 array 的一些特性。\n函数传递 数组需要明确指定大小，切片不需要。数组是值传递，切片是地址传递\na := [...]int{1, 2, 3, 4, 5, 6} fmt.Println(\u0026#34;star deal array, orginal data is:\u0026#34;) fmt.Println(a) aMaxIndex := len(a) - 1 fmt.Printf(\u0026#34;aMaxIndex:%d\\r\u0026#34;, aMaxIndex) for i, e := range a { if i == aMaxIndex { a[0] += e fmt.Printf(\u0026#34;index is 0, val is :%d\\r\u0026#34;, a[0]) } else { a[i+1] += e fmt.","title":"golang 数组与切片的区别"},{"content":"在用 vscode 生成测试用例的时候，生成了测试的匿名数组，没怎么用过，这里展示了 go 匿名结构体数组示例\nimport \u0026#34;testing\u0026#34; func TestGetRandomString(t *testing.T) { type args struct { lens int } tests := []struct { name string args args want string }{ { name: \u0026#34;test\u0026#34;, args: args{ lens: 6, }, want: \u0026#34;hi\u0026#34;, }, { name: \u0026#34;test\u0026#34;, args: args{ lens: 6, }, want: \u0026#34;hi\u0026#34;, }, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := GetRandomString(tt.args.lens); got != tt.want { t.Logf(\u0026#34;GetRandomString() = %v, want %v\u0026#34;, got, tt.want) } }) } } 需要注意的是各个结构体后面有个逗号。\n","permalink":"https://haokiu.com/blog/XVVOUE/","summary":"在用 vscode 生成测试用例的时候，生成了测试的匿名数组，没怎么用过，这里展示了 go 匿名结构体数组示例\nimport \u0026#34;testing\u0026#34; func TestGetRandomString(t *testing.T) { type args struct { lens int } tests := []struct { name string args args want string }{ { name: \u0026#34;test\u0026#34;, args: args{ lens: 6, }, want: \u0026#34;hi\u0026#34;, }, { name: \u0026#34;test\u0026#34;, args: args{ lens: 6, }, want: \u0026#34;hi\u0026#34;, }, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := GetRandomString(tt.args.lens); got != tt.want { t.Logf(\u0026#34;GetRandomString() = %v, want %v\u0026#34;, got, tt.want) } }) } } 需要注意的是各个结构体后面有个逗号。","title":"go 匿名结构体 数组 示例"},{"content":"有时需要查看本地开发的git项目的远程仓库地址\ngit remote -v 可以方便的查看远程仓库的地址\ngit remote -v origin https://gitee.com/leonardodacn/pixiublog.git (fetch) origin https://gitee.com/leonardodacn/pixiublog.git (push) -v : verbose，冗余的意思\n","permalink":"https://haokiu.com/blog/ss9sfI/","summary":"有时需要查看本地开发的git项目的远程仓库地址\ngit remote -v 可以方便的查看远程仓库的地址\ngit remote -v origin https://gitee.com/leonardodacn/pixiublog.git (fetch) origin https://gitee.com/leonardodacn/pixiublog.git (push) -v : verbose，冗余的意思","title":"git 查看远程地址"},{"content":"OLAP 在数据仓库一章中我们讨论了数据仓库及其模型的概念，而数据库与数据仓库的区别实际讲的是 OLTP 与 OLAP 的区别。操作型处理，叫联机事务处理 OLTP（On-Line Transaction Processing），也可以称面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。用户较为关心操作的响应时间、数据的安全性、完整性和并发的支持用户数等问题。传统的数据库系统作为数据管理的主要手段，主要用于操作型处理。分析型处理，叫联机分析处理 OLAP（On-Line Analytical Processing）一般针对某些主题历史数据进行分析，支持管理决策。\nOLAP 与 OLTP 在互联网浪潮出现之前，企业的数据量普遍不大，特别是核心的业务数据，通常一个单机的数据库就可以保存。那时候的存储并不需要复杂的架构，所有的线上请求(OLTP, Online Transactional Processing) 和后台分析 (OLAP, Online Analytical Processing) 都跑在同一个数据库实例上。后来渐渐的业务越来越复杂，数据量越来越大，DBA 们再也优化不动 SQL 了。其中一个显著问题是：单机数据库支持线上的 TP 请求已经非常吃力，没办法再跑比较重的 AP 分析型任务。跑起来要么 OOM，要么影响线上业务，要么做了主从分离、分库分表之后很难实现业务需求。\n在这样的背景下，以 Hadoop 为代表的大数据技术开始蓬勃发展，它用许多相对廉价的 x86 机器构建了一个数据分析平台，用并行的能力破解大数据集的计算问题。所以从某种程度上说，大数据技术可以算是传统关系型数据库技术发展过程的一个分支。当然在过程中大数据领域也发展出了属于自己的全新场景，诞生了许多新的技术，这个不深入提了。\n由此，架构师把存储划分成线上业务和数据分析两个模块。如下图所示，业务库的数据通过 ETL 工具抽取出来，导入专用的分析平台。业务数据库专注提供 TP 能力，分析平台提供 AP 能力，各施其职，看起来已经很完美了。但其实这个架构也有自己的不足。\nHTAP 首先是复杂性问题。本身 ETL 过程就是一个很繁琐的过程，一个例证是 ETL 做的好，可以成为一个商业模式。因为是两个系统，必然带来更高的学习成本、维护成本和整合成本。如果你使用的是开源的大数据工具搭建的分析平台，那么肯定会遇到各种工具之间的磨合的问题，还有由于各种工具良莠不齐所导致的质量问题。\n其次是实时性问题。通常我们认为越接近实时的数据，它的价值越大。很多业务场景，对实时性有很高的要求，比如风控系统，它需要对数据不停的分析，并且在险情出现之后尽快响应。而通常的 ETL 是一个周期性的操作，比如一天或者一个小时导一次数据，数据实时性是没有办法保证的。最后是一致性问题。一致性在数据库里面是很重要的概念，数据库的事务就是用来保证一致性的。如果把数据分表存储在两个不同的系统内，那么很难保证一致性，即 AP 系统的查询结果没有办法与线上业务正确对应。那么这两个系统的联动效应就会受到限制，比如用户没办法在一个事务里面，同时访问两个系统的数据。\n由于现有的数据平台存在的以上局限性，我们认为开发一个HTAP（Hybrid Transactional/Analytical Processing）融合型数据库产品可以缓解大家在 TP or AP 抉择上的焦虑，或者说，让数据库的使用者不用考虑过度复杂的架构，在一套数据库中既能满足 OLTP 类需求，也能满足 OLAP 类需求。\n","permalink":"https://haokiu.com/blog/OLAP/","summary":"OLAP 在数据仓库一章中我们讨论了数据仓库及其模型的概念，而数据库与数据仓库的区别实际讲的是 OLTP 与 OLAP 的区别。操作型处理，叫联机事务处理 OLTP（On-Line Transaction Processing），也可以称面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。用户较为关心操作的响应时间、数据的安全性、完整性和并发的支持用户数等问题。传统的数据库系统作为数据管理的主要手段，主要用于操作型处理。分析型处理，叫联机分析处理 OLAP（On-Line Analytical Processing）一般针对某些主题历史数据进行分析，支持管理决策。\nOLAP 与 OLTP 在互联网浪潮出现之前，企业的数据量普遍不大，特别是核心的业务数据，通常一个单机的数据库就可以保存。那时候的存储并不需要复杂的架构，所有的线上请求(OLTP, Online Transactional Processing) 和后台分析 (OLAP, Online Analytical Processing) 都跑在同一个数据库实例上。后来渐渐的业务越来越复杂，数据量越来越大，DBA 们再也优化不动 SQL 了。其中一个显著问题是：单机数据库支持线上的 TP 请求已经非常吃力，没办法再跑比较重的 AP 分析型任务。跑起来要么 OOM，要么影响线上业务，要么做了主从分离、分库分表之后很难实现业务需求。\n在这样的背景下，以 Hadoop 为代表的大数据技术开始蓬勃发展，它用许多相对廉价的 x86 机器构建了一个数据分析平台，用并行的能力破解大数据集的计算问题。所以从某种程度上说，大数据技术可以算是传统关系型数据库技术发展过程的一个分支。当然在过程中大数据领域也发展出了属于自己的全新场景，诞生了许多新的技术，这个不深入提了。\n由此，架构师把存储划分成线上业务和数据分析两个模块。如下图所示，业务库的数据通过 ETL 工具抽取出来，导入专用的分析平台。业务数据库专注提供 TP 能力，分析平台提供 AP 能力，各施其职，看起来已经很完美了。但其实这个架构也有自己的不足。\nHTAP 首先是复杂性问题。本身 ETL 过程就是一个很繁琐的过程，一个例证是 ETL 做的好，可以成为一个商业模式。因为是两个系统，必然带来更高的学习成本、维护成本和整合成本。如果你使用的是开源的大数据工具搭建的分析平台，那么肯定会遇到各种工具之间的磨合的问题，还有由于各种工具良莠不齐所导致的质量问题。\n其次是实时性问题。通常我们认为越接近实时的数据，它的价值越大。很多业务场景，对实时性有很高的要求，比如风控系统，它需要对数据不停的分析，并且在险情出现之后尽快响应。而通常的 ETL 是一个周期性的操作，比如一天或者一个小时导一次数据，数据实时性是没有办法保证的。最后是一致性问题。一致性在数据库里面是很重要的概念，数据库的事务就是用来保证一致性的。如果把数据分表存储在两个不同的系统内，那么很难保证一致性，即 AP 系统的查询结果没有办法与线上业务正确对应。那么这两个系统的联动效应就会受到限制，比如用户没办法在一个事务里面，同时访问两个系统的数据。\n由于现有的数据平台存在的以上局限性，我们认为开发一个HTAP（Hybrid Transactional/Analytical Processing）融合型数据库产品可以缓解大家在 TP or AP 抉择上的焦虑，或者说，让数据库的使用者不用考虑过度复杂的架构，在一套数据库中既能满足 OLTP 类需求，也能满足 OLAP 类需求。","title":"OLAP"},{"content":"数据中台 阿里在 2018 年提出了所谓“数据中台”的概念：即数据被统一采集，规范数据语义和业务口径形成企业基础数据模型，提供统一的分析查询和新业务的数据对接能力。数据中台并不是新的颠覆式技术，而是一种企业数据资产管理和应用方法学，涵盖了数据集成、数据质量管理、元数据与主数据管理、数仓建模、支持高并发访问的数据服务接口层开发等内容。\n在数据中台建设中，结合企业自身的业务需求特点，架构和功能可能各不相同，但其中一个最基本的需求是数据采集的实时性和完整性。数据从源端产生，到被采集到数据汇集层的时间要尽可能短，至少应做到秒级延迟，这样中台的数据模型更新才可能做到近实时，构建在中台之上依赖实时数据流驱动的应用（例如商品推荐、欺诈检测等）才能够满足业务的需求。\n以阿里双十一为例，在极高的并发情况下，订单产生到大屏统计数据更新延迟不能超过 5s，一般在 2s 内。中台对外提供的数据应该是完整的，源端数据的 Create、Update 和 Delete 都要能够被捕获，不能少也不能多，即数据需要有端到端一致性的能力（Exactly Once Semantic，EOS）。当然，EOS 并非在任何业务场景下都需要，但从平台角度必须具备这种能力，并且允许用户根据业务需求灵活开启和关闭。\n数据中台的产生背景 起初，企业只有一个主营业务，比如电商，但随着公司战略和发展需要，会新增多支业务线，由于存在负责业务线开发的团队不一致，随之而来的就是风格迥异的代码风格和数据烟囱问题。\n数据中台的产生就是为了解决数据烟囱的问题，打通数据孤岛，让数据活起来，让数据产生价值，结合前台能力，达到快速响应用户的目标。\n中台只会同步能服务于超过两个业务线的数据，如果仅仅带有自身业务属性(不存在共性)的数据，不在中台的考虑范围内。例如:电商的产品产地信息，对于金融业务来说，其实是没有价值的，但电商的用户收货地址对金融业务来说是有价值的。所以不要简单的认为数据中台会汇集企业的所有数据，还是有侧重点的。导致这个结果的原因还包括数据中台建设本身是一个长周期的事，如果数据仅仅作用于一方，由业务方(前台)自行开发，更符合敏捷开发的特性。\n关于何时应该建立数据中台这个问题，我的思考是这样的。复杂的业务线、丰富的数据维度和公司上层领导主推。三者缺一，都没有实行的必要。 一只手都能数的过来的业务线量，跨多个项目的需求相对还是比较少的，取数也比较方便，直接走接口方式基本就能满足。反而，通过数据中台流转，将问题复杂化了。\n数据的维度越丰富，数据的价值越大。只知道性别数据，与知道性别和年龄，所得到的用户画像，肯定是维度丰富的准确性高。维度不丰富的情况下，没有计算的价值。\n可能会很奇怪为什么一定需要公司上层的同意。这里就可能涉及到动了谁的奶酪的问题，数据是每个业务线最重要的资源，在推行中台过程中，势必会遇到阻力，只有成为全公司的战略任务，才有可能把事情做好。\n中台如果没有考虑通用的业务能力，也会导致无法更专注于对中台技术的深入研究。中台如果不从抽象度、共性等角度出发，很有可能局限于某单一业务，导致中台无法很好地适应其他相关业务的要求，从而不能很好地应对业务的变化。如果中台的抽象程度低、扩展性差，则会导致中台无法满足前台业务需求。这时前台应用又因为业务本身的发展目标和压力不得不自行组织团队完成这部分功能，由此可能发生本应由中台提供的能力却最终实现在业务应用中，失去了中台存在的价值。\n","permalink":"https://haokiu.com/blog/3OKmkr/","summary":"数据中台 阿里在 2018 年提出了所谓“数据中台”的概念：即数据被统一采集，规范数据语义和业务口径形成企业基础数据模型，提供统一的分析查询和新业务的数据对接能力。数据中台并不是新的颠覆式技术，而是一种企业数据资产管理和应用方法学，涵盖了数据集成、数据质量管理、元数据与主数据管理、数仓建模、支持高并发访问的数据服务接口层开发等内容。\n在数据中台建设中，结合企业自身的业务需求特点，架构和功能可能各不相同，但其中一个最基本的需求是数据采集的实时性和完整性。数据从源端产生，到被采集到数据汇集层的时间要尽可能短，至少应做到秒级延迟，这样中台的数据模型更新才可能做到近实时，构建在中台之上依赖实时数据流驱动的应用（例如商品推荐、欺诈检测等）才能够满足业务的需求。\n以阿里双十一为例，在极高的并发情况下，订单产生到大屏统计数据更新延迟不能超过 5s，一般在 2s 内。中台对外提供的数据应该是完整的，源端数据的 Create、Update 和 Delete 都要能够被捕获，不能少也不能多，即数据需要有端到端一致性的能力（Exactly Once Semantic，EOS）。当然，EOS 并非在任何业务场景下都需要，但从平台角度必须具备这种能力，并且允许用户根据业务需求灵活开启和关闭。\n数据中台的产生背景 起初，企业只有一个主营业务，比如电商，但随着公司战略和发展需要，会新增多支业务线，由于存在负责业务线开发的团队不一致，随之而来的就是风格迥异的代码风格和数据烟囱问题。\n数据中台的产生就是为了解决数据烟囱的问题，打通数据孤岛，让数据活起来，让数据产生价值，结合前台能力，达到快速响应用户的目标。\n中台只会同步能服务于超过两个业务线的数据，如果仅仅带有自身业务属性(不存在共性)的数据，不在中台的考虑范围内。例如:电商的产品产地信息，对于金融业务来说，其实是没有价值的，但电商的用户收货地址对金融业务来说是有价值的。所以不要简单的认为数据中台会汇集企业的所有数据，还是有侧重点的。导致这个结果的原因还包括数据中台建设本身是一个长周期的事，如果数据仅仅作用于一方，由业务方(前台)自行开发，更符合敏捷开发的特性。\n关于何时应该建立数据中台这个问题，我的思考是这样的。复杂的业务线、丰富的数据维度和公司上层领导主推。三者缺一，都没有实行的必要。 一只手都能数的过来的业务线量，跨多个项目的需求相对还是比较少的，取数也比较方便，直接走接口方式基本就能满足。反而，通过数据中台流转，将问题复杂化了。\n数据的维度越丰富，数据的价值越大。只知道性别数据，与知道性别和年龄，所得到的用户画像，肯定是维度丰富的准确性高。维度不丰富的情况下，没有计算的价值。\n可能会很奇怪为什么一定需要公司上层的同意。这里就可能涉及到动了谁的奶酪的问题，数据是每个业务线最重要的资源，在推行中台过程中，势必会遇到阻力，只有成为全公司的战略任务，才有可能把事情做好。\n中台如果没有考虑通用的业务能力，也会导致无法更专注于对中台技术的深入研究。中台如果不从抽象度、共性等角度出发，很有可能局限于某单一业务，导致中台无法很好地适应其他相关业务的要求，从而不能很好地应对业务的变化。如果中台的抽象程度低、扩展性差，则会导致中台无法满足前台业务需求。这时前台应用又因为业务本身的发展目标和压力不得不自行组织团队完成这部分功能，由此可能发生本应由中台提供的能力却最终实现在业务应用中，失去了中台存在的价值。","title":"数据中台"},{"content":"用 acme.sh 生产了 Let\u0026rsquo;s Encrypt 的https 证书，在浏览器访问没有问题，但在服务器访问出现下面的异常：\ncurl: (60) SSL certificate problem: unable to get local issuer certificate More details here: https://curl.haxx.se/docs/sslcerts.html curl failed to verify the legitimacy of the server and therefore could not establish a secure connection to it. To learn more about this situation and how to fix it, please visit the web page mentioned above. 网站用了beego，用 acme.sh 生成的证书。配置：\nEnableHTTPS = true HTTPSPort = 443 HTTPSCertFile = \u0026#34;/home/blog/cert/cert.pem\u0026#34; HTTPSKeyFile = \u0026#34;/home/blog/cert/key.pem\u0026#34; 要将 cert.pem 替换为：fullchain.pem\nEnableHTTPS = true HTTPSPort = 443 HTTPSCertFile = \u0026#34;/home/blog/cert/fullchain.pem\u0026#34; HTTPSKeyFile = \u0026#34;/home/blog/cert/key.pem\u0026#34; ","permalink":"https://haokiu.com/blog/KsbUyb/","summary":"用 acme.sh 生产了 Let\u0026rsquo;s Encrypt 的https 证书，在浏览器访问没有问题，但在服务器访问出现下面的异常：\ncurl: (60) SSL certificate problem: unable to get local issuer certificate More details here: https://curl.haxx.se/docs/sslcerts.html curl failed to verify the legitimacy of the server and therefore could not establish a secure connection to it. To learn more about this situation and how to fix it, please visit the web page mentioned above. 网站用了beego，用 acme.sh 生成的证书。配置：\nEnableHTTPS = true HTTPSPort = 443 HTTPSCertFile = \u0026#34;/home/blog/cert/cert.pem\u0026#34; HTTPSKeyFile = \u0026#34;/home/blog/cert/key.pem\u0026#34; 要将 cert.pem 替换为：fullchain.pem\nEnableHTTPS = true HTTPSPort = 443 HTTPSCertFile = \u0026#34;/home/blog/cert/fullchain.pem\u0026#34; HTTPSKeyFile = \u0026#34;/home/blog/cert/key.pem\u0026#34; ","title":"curl https 地址报异常"},{"content":"服务经常会重启失败，写了个简单的shell叫脚本，可以发现服务端口是否起来，没有发现监听端口会重启服务\n1.监控脚本 if [ -z \u0026#34;`lsof -i:443 | grep LISTEN`\u0026#34; ];then echo -e \u0026#34;restart $(date +\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;)\u0026#34; systemctl restart pixiublog fi 2.系统定时任务 */3 * * * * /usr/local/pixiublog/monitor.sh \u0026gt;\u0026gt; /usr/local/pixiublog/monitor.log 2\u0026gt;\u0026amp;1 ","permalink":"https://haokiu.com/blog/5XKHkb/","summary":"服务经常会重启失败，写了个简单的shell叫脚本，可以发现服务端口是否起来，没有发现监听端口会重启服务\n1.监控脚本 if [ -z \u0026#34;`lsof -i:443 | grep LISTEN`\u0026#34; ];then echo -e \u0026#34;restart $(date +\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;)\u0026#34; systemctl restart pixiublog fi 2.系统定时任务 */3 * * * * /usr/local/pixiublog/monitor.sh \u0026gt;\u0026gt; /usr/local/pixiublog/monitor.log 2\u0026gt;\u0026amp;1 ","title":"简单脚本实现服务监控"},{"content":"haokiu 的启动脚本，配置 https 可以参考beego 通过acms.sh 使用 https\n#!/bin/sh siteDir=\u0026#39;/usr/local/pixiublog\u0026#39; appName=\u0026#39;pixiublogMain\u0026#39; echo \u0026#34;kill the running program\u0026#34; ps -ef | grep $appName | grep -v grep | awk \u0026#39;{print $2}\u0026#39; | xargs kill -9 echo \u0026#34;sleep 3 secons for app to shutdown\u0026#34; sleep 3 echo \u0026#34;start program\u0026#34; cd $siteDir nohup $siteDir/$appName \u0026gt;\u0026gt; $siteDir/console.log 2\u0026gt;\u0026amp;1 \u0026amp; ","permalink":"https://haokiu.com/blog/v3yn45/","summary":"haokiu 的启动脚本，配置 https 可以参考beego 通过acms.sh 使用 https\n#!/bin/sh siteDir=\u0026#39;/usr/local/pixiublog\u0026#39; appName=\u0026#39;pixiublogMain\u0026#39; echo \u0026#34;kill the running program\u0026#34; ps -ef | grep $appName | grep -v grep | awk \u0026#39;{print $2}\u0026#39; | xargs kill -9 echo \u0026#34;sleep 3 secons for app to shutdown\u0026#34; sleep 3 echo \u0026#34;start program\u0026#34; cd $siteDir nohup $siteDir/$appName \u0026gt;\u0026gt; $siteDir/console.log 2\u0026gt;\u0026amp;1 \u0026amp; ","title":"haokiu网站启动脚本"},{"content":"如果beego配置了https，那么可以让 让http请求跳转到 https，怎样配置 beego 的https，可以参考beego 通过acms.sh 使用 https\n//siteUrl 是网站地址，比如:https://haokiu.com if \u0026#34;HTTP/1.1\u0026#34; == self.Ctx.Request.Proto \u0026amp;\u0026amp; siteUrl != \u0026#34;\u0026#34; \u0026amp;\u0026amp; strings.HasPrefix(siteUrl, \u0026#34;https\u0026#34;) { //如果支持https，则所有http请求跳转到https self.redirect(siteUrl + self.Ctx.Request.URL.Path) } ","permalink":"https://haokiu.com/blog/ZSf4yF/","summary":"如果beego配置了https，那么可以让 让http请求跳转到 https，怎样配置 beego 的https，可以参考beego 通过acms.sh 使用 https\n//siteUrl 是网站地址，比如:https://haokiu.com if \u0026#34;HTTP/1.1\u0026#34; == self.Ctx.Request.Proto \u0026amp;\u0026amp; siteUrl != \u0026#34;\u0026#34; \u0026amp;\u0026amp; strings.HasPrefix(siteUrl, \u0026#34;https\u0026#34;) { //如果支持https，则所有http请求跳转到https self.redirect(siteUrl + self.Ctx.Request.URL.Path) } ","title":"beego 让http请求跳转到 https"},{"content":"beego 通过 acme.sh 使用 https\n安装acms.sh curl https://get.acme.sh | sh 生成证书 如果使用的是 beego 框架，需添加可访问的静态文件目录：\n//acme.sh 自动验证网站目录，不使用https可以忽略 beego.SetStaticPath(\u0026#34;/.well-known\u0026#34;, \u0026#34;.well-known\u0026#34;) acme.sh --issue -d haokiu.com -d www.haokiu.com --webroot /usr/local/pixiublog/ 设置pixiublog开机启动 1. 编写开机启动脚本 vim /usr/lib/systemd/system/pixiublog.service\n[Unit] Description=The pixiublog Process Manager After=syslog.target network.target [Service] Type=forking ExecStart=sh /usr/local/pixiublog/start.sh ExecReload=/bin/kill -USR2 $MAINPID ExecStop=/bin/kill -SIGINT $MAINPID [Install] WantedBy=multi-user.target 2. 设置开机启动 systemctl enable pixiublog 安装证书 acme.sh --install-cert -d haokiu.com \\ --cert-file /home/blog/cert/cert.pem \\ --key-file /home/blog/cert/key.pem \\ --fullchain-file /home/blog/cert/fullchain.pem \\ --reloadcmd \u0026#34;systemctl restart pixiublog\u0026#34; beego app.conf 配置 EnableHTTPS = true HTTPSPort = 443 HTTPSCertFile = \u0026#34;/home/blog/cert/fullchain.pem\u0026#34; HTTPSKeyFile = \u0026#34;/home/blog/cert/key.pem\u0026#34; 参考 acme.sh 使用\n","permalink":"https://haokiu.com/blog/qP3u4V/","summary":"beego 通过 acme.sh 使用 https\n安装acms.sh curl https://get.acme.sh | sh 生成证书 如果使用的是 beego 框架，需添加可访问的静态文件目录：\n//acme.sh 自动验证网站目录，不使用https可以忽略 beego.SetStaticPath(\u0026#34;/.well-known\u0026#34;, \u0026#34;.well-known\u0026#34;) acme.sh --issue -d haokiu.com -d www.haokiu.com --webroot /usr/local/pixiublog/ 设置pixiublog开机启动 1. 编写开机启动脚本 vim /usr/lib/systemd/system/pixiublog.service\n[Unit] Description=The pixiublog Process Manager After=syslog.target network.target [Service] Type=forking ExecStart=sh /usr/local/pixiublog/start.sh ExecReload=/bin/kill -USR2 $MAINPID ExecStop=/bin/kill -SIGINT $MAINPID [Install] WantedBy=multi-user.target 2. 设置开机启动 systemctl enable pixiublog 安装证书 acme.sh --install-cert -d haokiu.com \\ --cert-file /home/blog/cert/cert.pem \\ --key-file /home/blog/cert/key.pem \\ --fullchain-file /home/blog/cert/fullchain.pem \\ --reloadcmd \u0026#34;systemctl restart pixiublog\u0026#34; beego app.conf 配置 EnableHTTPS = true HTTPSPort = 443 HTTPSCertFile = \u0026#34;/home/blog/cert/fullchain.pem\u0026#34; HTTPSKeyFile = \u0026#34;/home/blog/cert/key.pem\u0026#34; 参考 acme.sh 使用","title":"beego 通过acme.sh 使用 https"},{"content":"acme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书。这个脚本可以非常方便的管理 letsencrypt 的证书，省去很多繁琐操作。有了这个脚本就可以方便地给网站使用 https 了\n主要步骤:\n安装 acme.sh 生成证书 copy 证书到 nginx/apache 或者其他服务 更新证书 更新 acme.sh 出错怎么办, 如何调试 下面详细介绍.\n1. 安装 acme.sh 安装很简单, 一个命令:\ncurl https://get.acme.sh | sh 普通用户和 root 用户都可以安装使用. 安装过程进行了以下几步:\n把 acme.sh 安装到你的 home 目录下: ~/.acme.sh/ 并创建 一个 bash 的 alias, 方便你的使用: alias acme.sh=~/.acme.sh/acme.sh\n2). 自动为你创建 cronjob, 每天 0:00 点自动检测所有的证书, 如果快过期了, 需要更新, 则会自动更新证书.\n更高级的安装选项请参考: https://github.com/Neilpang/acme.sh/wiki/How-to-install\n安装过程不会污染已有的系统任何功能和文件, 所有的修改都限制在安装目录中: ~/.acme.sh/\n2. 生成证书 acme.sh 实现了 acme 协议支持的所有验证协议. 一般有两种方式验证: http 和 dns 验证.\n1. http 方式需要在你的网站根目录下放置一个文件, 来验证你的域名所有权,完成验证. 然后就可以生成证书了. acme.sh --issue -d mydomain.com -d www.mydomain.com --webroot /home/wwwroot/mydomain.com/ 只需要指定域名, 并指定域名所在的网站根目录. acme.sh 会全自动的生成验证文件, 并放到网站的根目录, 然后自动完成验证. 最后会聪明的删除验证文件. 整个过程没有任何副作用.\n如果你用的 apache服务器, acme.sh 还可以智能的从 apache的配置中自动完成验证, 你不需要指定网站根目录:\nacme.sh --issue -d mydomain.com --apache 如果你用的 nginx服务器, 或者反代, acme.sh 还可以智能的从 nginx的配置中自动完成验证, 你不需要指定网站根目录:\nacme.sh --issue -d mydomain.com --nginx 注意, 无论是 apache 还是 nginx 模式, acme.sh在完成验证之后, 会恢复到之前的状态, 都不会私自更改你本身的配置. 好处是你不用担心配置被搞坏, 也有一个缺点, 你需要自己配置 ssl 的配置, 否则只能成功生成证书, 你的网站还是无法访问https. 但是为了安全, 你还是自己手动改配置吧.\n如果你还没有运行任何 web 服务, 80 端口是空闲的, 那么 acme.sh 还能假装自己是一个webserver, 临时听在80 端口, 完成验证:\nacme.sh --issue -d mydomain.com --standalone 更高级的用法请参考: https://github.com/Neilpang/acme.sh/wiki/How-to-issue-a-cert\n2. 手动 dns 方式, 手动在域名上添加一条 txt 解析记录, 验证域名所有权. 这种方式的好处是, 你不需要任何服务器, 不需要任何公网 ip, 只需要 dns 的解析记录即可完成验证. 坏处是，如果不同时配置 Automatic DNS API，使用这种方式 acme.sh 将无法自动更新证书，每次都需要手动再次重新解析验证域名所有权。\nacme.sh --issue --dns -d mydomain.com 然后, acme.sh 会生成相应的解析记录显示出来, 你只需要在你的域名管理面板中添加这条 txt 记录即可.\n等待解析完成之后, 重新生成证书:\nacme.sh --renew -d mydomain.com 注意第二次这里用的是 --renew\ndns 方式的真正强大之处在于可以使用域名解析商提供的 api 自动添加 txt 记录完成验证.\nacme.sh 目前支持 cloudflare, dnspod, cloudxns, godaddy 以及 ovh 等数十种解析商的自动集成.\n以 dnspod 为例, 你需要先登录到 dnspod 账号, 生成你的 api id 和 api key, 都是免费的. 然后:\nexport DP_Id=\u0026#34;1234\u0026#34; export DP_Key=\u0026#34;sADDsdasdgdsf\u0026#34; acme.sh --issue --dns dns_dp -d aa.com -d www.aa.com 证书就会自动生成了. 这里给出的 api id 和 api key 会被自动记录下来, 将来你在使用 dnspod api 的时候, 就不需要再次指定了. 直接生成就好了:\nacme.sh --issue -d mydomain2.com --dns dns_dp 更详细的 api 用法: https://github.com/Neilpang/acme.sh/blob/master/dnsapi/README.md\n3. copy/安装 证书 前面证书生成以后, 接下来需要把证书 copy 到真正需要用它的地方.\n注意, 默认生成的证书都放在安装目录下: ~/.acme.sh/, 请不要直接使用此目录下的文件, 例如: 不要直接让 nginx/apache 的配置文件使用这下面的文件. 这里面的文件都是内部使用, 而且目录结构可能会变化.\n正确的使用方法是使用 --install-cert 命令,并指定目标位置, 然后证书文件会被copy到相应的位置, 例如:\nApache example: acme.sh --install-cert -d example.com \\ --cert-file /path/to/certfile/in/apache/cert.pem \\ --key-file /path/to/keyfile/in/apache/key.pem \\ --fullchain-file /path/to/fullchain/certfile/apache/fullchain.pem \\ --reloadcmd \u0026#34;service apache2 force-reload\u0026#34; Nginx example: acme.sh --install-cert -d example.com \\ --key-file /path/to/keyfile/in/nginx/key.pem \\ --fullchain-file /path/to/fullchain/nginx/cert.pem \\ --reloadcmd \u0026#34;service nginx force-reload\u0026#34; (一个小提醒, 这里用的是 service nginx force-reload, 不是 service nginx reload, 据测试, reload 并不会重新加载证书, 所以用的 force-reload)\nNginx 的配置 ssl_certificate 使用 /etc/nginx/ssl/fullchain.cer ，而非 /etc/nginx/ssl/\u0026lt;domain\u0026gt;.cer ，否则 SSL Labs 的测试会报 Chain issues Incomplete 错误。\n--install-cert命令可以携带很多参数, 来指定目标文件. 并且可以指定 reloadcmd, 当证书更新以后, reloadcmd会被自动调用,让服务器生效.\n详细参数请参考: https://github.com/Neilpang/acme.sh#3-install-the-issued-cert-to-apachenginx-etc\n值得注意的是, 这里指定的所有参数都会被自动记录下来, 并在将来证书自动更新以后, 被再次自动调用.\n4. 更新证书 目前证书在 60 天以后会自动更新, 你无需任何操作. 今后有可能会缩短这个时间, 不过都是自动的, 你不用关心.\n5. 更新 acme.sh 目前由于 acme 协议和 letsencrypt CA 都在频繁的更新, 因此 acme.sh 也经常更新以保持同步.\n升级 acme.sh 到最新版 :\nacme.sh --upgrade 如果你不想手动升级, 可以开启自动升级:\nacme.sh --upgrade --auto-upgrade 之后, acme.sh 就会自动保持更新了.\n你也可以随时关闭自动更新:\nacme.sh --upgrade --auto-upgrade 0 6. 出错怎么办： 如果出错, 请添加 debug log：\nacme.sh --issue ..... --debug 或者：\nacme.sh --issue ..... --debug 2 请参考： https://github.com/Neilpang/acme.sh/wiki/How-to-debug-acme.sh\n最后, 本文并非完全的使用说明, 还有很多高级的功能, 更高级的用法请参看其他 wiki 页面.\nhttps://github.com/Neilpang/acme.sh/wiki\n","permalink":"https://haokiu.com/blog/6D0DBH/","summary":"acme.sh 实现了 acme 协议, 可以从 letsencrypt 生成免费的证书。这个脚本可以非常方便的管理 letsencrypt 的证书，省去很多繁琐操作。有了这个脚本就可以方便地给网站使用 https 了\n主要步骤:\n安装 acme.sh 生成证书 copy 证书到 nginx/apache 或者其他服务 更新证书 更新 acme.sh 出错怎么办, 如何调试 下面详细介绍.\n1. 安装 acme.sh 安装很简单, 一个命令:\ncurl https://get.acme.sh | sh 普通用户和 root 用户都可以安装使用. 安装过程进行了以下几步:\n把 acme.sh 安装到你的 home 目录下: ~/.acme.sh/ 并创建 一个 bash 的 alias, 方便你的使用: alias acme.sh=~/.acme.sh/acme.sh\n2). 自动为你创建 cronjob, 每天 0:00 点自动检测所有的证书, 如果快过期了, 需要更新, 则会自动更新证书.\n更高级的安装选项请参考: https://github.com/Neilpang/acme.sh/wiki/How-to-install\n安装过程不会污染已有的系统任何功能和文件, 所有的修改都限制在安装目录中: ~/.acme.sh/\n2. 生成证书 acme.sh 实现了 acme 协议支持的所有验证协议. 一般有两种方式验证: http 和 dns 验证.\n1. http 方式需要在你的网站根目录下放置一个文件, 来验证你的域名所有权,完成验证. 然后就可以生成证书了. acme.sh --issue -d mydomain.com -d www.mydomain.com --webroot /home/wwwroot/mydomain.com/ 只需要指定域名, 并指定域名所在的网站根目录. acme.sh 会全自动的生成验证文件, 并放到网站的根目录, 然后自动完成验证. 最后会聪明的删除验证文件. 整个过程没有任何副作用.\n如果你用的 apache服务器, acme.","title":"acme.sh 方便管理 letsencrypt "},{"content":"… 是go的一种语法糖。\n作用 用于函数有多个不定参数的情况，可以接受多个不确定数量的参数 打散slice进行传递 例子 一、接受多个不确定数量的参数 func println(args ...string) { //可以接受任意个string参数 for _, v:= range args{ fmt.Println(v) } } func main(){ var strss= []string{ \u0026#34;qwr\u0026#34;, \u0026#34;234\u0026#34;, \u0026#34;yui\u0026#34;, \u0026#34;cvbc\u0026#34;, } println(strss...) //切片被打散传入 } 结果：\nqwr 234 yui cvbc 二、打散slice进行传递 var strss= []string{ \u0026#34;qwr\u0026#34;, \u0026#34;234\u0026#34;, \u0026#34;yui\u0026#34;, } var strss2= []string{ \u0026#34;qqq\u0026#34;, \u0026#34;aaa\u0026#34;, \u0026#34;zzz\u0026#34;, \u0026#34;zzz\u0026#34;, } strss=append(strss,strss2...) //strss2的元素被打散一个个append进strss fmt.Println(strss) 结果：\n[qwr 234 yui qqq aaa zzz zzz] 最后 如果没有’…’，面对上面的情况，无疑会增加代码量。\n","permalink":"https://haokiu.com/blog/hiUuGO/","summary":"… 是go的一种语法糖。\n作用 用于函数有多个不定参数的情况，可以接受多个不确定数量的参数 打散slice进行传递 例子 一、接受多个不确定数量的参数 func println(args ...string) { //可以接受任意个string参数 for _, v:= range args{ fmt.Println(v) } } func main(){ var strss= []string{ \u0026#34;qwr\u0026#34;, \u0026#34;234\u0026#34;, \u0026#34;yui\u0026#34;, \u0026#34;cvbc\u0026#34;, } println(strss...) //切片被打散传入 } 结果：\nqwr 234 yui cvbc 二、打散slice进行传递 var strss= []string{ \u0026#34;qwr\u0026#34;, \u0026#34;234\u0026#34;, \u0026#34;yui\u0026#34;, } var strss2= []string{ \u0026#34;qqq\u0026#34;, \u0026#34;aaa\u0026#34;, \u0026#34;zzz\u0026#34;, \u0026#34;zzz\u0026#34;, } strss=append(strss,strss2...) //strss2的元素被打散一个个append进strss fmt.Println(strss) 结果：\n[qwr 234 yui qqq aaa zzz zzz] 最后 如果没有’…’，面对上面的情况，无疑会增加代码量。","title":"go ... 作用"},{"content":"1. 获取当前时间 时间戳(秒)：time.Now().Unix 日期：time.Now().Format(\u0026#34;2006-01-02 15:04:05\u0026#34;) 注意：参数必须是 2006-01-02 15:04:05 而不能是自定义的年月日时间 2. 字符串与int转换 i,_ := strconv.Atoi(\u0026#34;3\u0026#34;) a := strconv.Itoa(32) 3.结构体json序列化 chatMsg := \u0026amp;ChatMsg{} err := json.Unmarshal([]byte(msg), chatMsg) //json转结构体 buf, _ := json.Marshal(chatMsg) //结构体转json return string(buf) 4.删除切片元素 mySlice := make([]int, 5) //创建一个初始元素个数为5的数组切片，元素初始值为0 mySlice = append(mySlice[:i], mySlice[i+1:]...) //删除下标为i的元素 mySlice = append(mySlice[:0], mySlice[1:]...) //删除第1个元素 5. url encode/decode encodeUrl:= url.QueryEscape(urltest) decodeUrl,err := url.QueryUnescape(encodeUrl) 6. base64编码 encodeString := base64.StdEncoding.EncodeToString(input) decodeBytes, err := base64.StdEncoding.DecodeString(encodeString) 7. 获取字符串长度 tips := \u0026#34;忍者\u0026#34; len := len(tips) //len=6 len := utf8.RuneCountInString(tips) //len=2 8. SubString func SubString(str string, start int32, end int32) string { result := []rune(str) length := int32(len(result)) if start \u0026lt; 0 || start \u0026gt; length { return str } if end \u0026lt; 0 || end \u0026gt; length { return str } return string(result[start:end]) } result = SubString(result, 0, int32(len([]rune(result)))-1)//注意end参数的取值 9. 结构体类型断言 logger := \u0026amp;log.Logger{} fl, ok := interface{}(logger).(*FileLogger) 类型断言变量一定要是一个接口变量，否则报错 invalid type assertion: xxx (non-interface type xxx on left);\n使用类型断言的思路，应该是接收到一个接口值，但不确定这个值具体的类型，然后通过类型断言来判断。\n10. os常用函数 import ( \u0026#34;os\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; \u0026#34;strings\u0026#34; ) //os包中的一些常用函数 func main() { //获取主机名 fmt.Println(os.Hostname()); //获取当前目录 fmt.Println(os.Getwd()); //获取用户ID fmt.Println(os.Getuid()); //获取有效用户ID fmt.Println(os.Geteuid()); //获取组ID fmt.Println(os.Getgid()); //获取有效组ID fmt.Println(os.Getegid()); //获取进程ID fmt.Println(os.Getpid()); //获取父进程ID fmt.Println(os.Getppid()); //获取环境变量的值 fmt.Println(os.Getenv(\u0026#34;GOPATH\u0026#34;)); //设置环境变量的值 os.Setenv(\u0026#34;TEST\u0026#34;, \u0026#34;test\u0026#34;); //改变当前工作目录 os.Chdir(\u0026#34;C:/\u0026#34;); fmt.Println(os.Getwd()); //创建文件 f1, _ := os.Create(\u0026#34;./1.txt\u0026#34;); defer f1.Close(); //修改文件权限 if err := os.Chmod(\u0026#34;./1.txt\u0026#34;, 0777); err != nil { fmt.Println(err); } //修改文件所有者 if err := os.Chown(\u0026#34;./1.txt\u0026#34;, 0, 0); err != nil { fmt.Println(err); } //修改文件的访问时间和修改时间 os.Chtimes(\u0026#34;./1.txt\u0026#34;, time.Now().Add(time.Hour), time.Now().Add(time.Hour)); //获取所有环境变量 fmt.Println(strings.Join(os.Environ(), \u0026#34;\\r\\n\u0026#34;)); //把字符串中带NULL或$var替换成指定指符串 fmt.Println(os.Expand(\u0026#34;NULL NULL NULL\u0026#34;, func(k string) string { mapp := map[string]string{ \u0026#34;1\u0026#34;: \u0026#34;111\u0026#34;, \u0026#34;2\u0026#34;: \u0026#34;222\u0026#34;, \u0026#34;3\u0026#34;: \u0026#34;333\u0026#34;, }; return mapp[k]; })); //创建目录 os.Mkdir(\u0026#34;abc\u0026#34;, os.ModePerm); //创建多级目录 os.MkdirAll(\u0026#34;abc/d/e/f\u0026#34;, os.ModePerm); //删除文件或目录 os.Remove(\u0026#34;abc/d/e/f\u0026#34;); //删除指定目录下所有文件 os.RemoveAll(\u0026#34;abc\u0026#34;); //重命名文件 os.Rename(\u0026#34;./2.txt\u0026#34;, \u0026#34;./2_new.txt\u0026#34;); //判断是否为同一文件 //unix下通过底层结构的设备和索引节点是否相同来判断 //其他系统可能是通过文件绝对路径来判断 fs1, _ := f1.Stat(); f2, _ := os.Open(\u0026#34;./1.txt\u0026#34;); fs2, _ := f2.Stat(); fmt.Println(os.SameFile(fs1, fs2)); //返回临时目录 fmt.Println(os.TempDir()); } 11. 文件常用函数 import ( \u0026#34;os\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) //os包中关于文件的操作函数 func main() { //创建文件，返回一个文件指针 f3, _ := os.Create(\u0026#34;./3.txt\u0026#34;); defer f3.Close(); //以读写方式打开文件，如果不存在则创建文件，等同于上面os.Create f4, _ := os.OpenFile(\u0026#34;./4.txt\u0026#34;, os.O_RDWR|os.O_CREATE|os.O_TRUNC, 0666); defer f4.Close(); //打开文件，返回文件指针 f1, _ := os.Open(\u0026#34;./1.txt\u0026#34;); defer f1.Close(); //修改文件权限，类似os.chmod f1.Chmod(0777); //修改文件所有者，类似os.chown f1.Chown(0, 0); //返回文件的句柄，通过NewFile创建文件需要文件句柄 fmt.Println(f1.Fd()); //从文件中读取数据 buf := make([]byte, 128); //read每次读取数据到buf中 for n, _ := f1.Read(buf); n != 0; n, _ = f1.Read(buf) { fmt.Println(string(buf[:n])); } //向文件中写入数据 for i := 0; i \u0026lt; 5; i++ { f3.Write([]byte(\u0026#34;写入数据\u0026#34; + strconv.Itoa(i) + \u0026#34;\\r\\n\u0026#34;)); } //返回一对关联的文件对象 //从r中可以读取到从w写入的数据 r, w, _ := os.Pipe(); //向w中写入字符串 w.WriteString(\u0026#34;写入w\u0026#34;); buf2 := make([]byte, 128); //从r中读取数据 n, _ := r.Read(buf); fmt.Println(string(buf2[:n])); //改变工作目录 os.Mkdir(\u0026#34;a\u0026#34;, os.ModePerm); dir, _ := os.Open(\u0026#34;a\u0026#34;); //改变工作目录到dir，dir必须为一个目录 dir.Chdir(); fmt.Println(os.Getwd()); //读取目录的内容，返回一个FileInfo的slice //参数大于0，最多返回n个FileInfo //参数小于等于0，返回所有FileInfo fi, _ := dir.Readdir(-1); for _, v := range fi { fmt.Println(v.Name()); } //读取目录中文件对象的名字 names, _ := dir.Readdirnames(-1); fmt.Println(names); //获取文件的详细信息，返回FileInfo结构 fi3, _ := f3.Stat(); //文件名 fmt.Println(fi3.Name()); //文件大小 fmt.Println(fi3.Size()); //文件权限 fmt.Println(fi3.Mode()); //文件修改时间 fmt.Println(fi3.ModTime()); //是否是目录 fmt.Println(fi3.IsDir()); } 12. os中关于进程的操作 import ( \u0026#34;os\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) //os包中关于进程的操作函数 func main() { //设置新进程的属性 attr := \u0026amp;os.ProcAttr{ //files指定新进程继承的活动文件对象 //前三个分别为，标准输入、标准输出、标准错误输出 Files: []*os.File{os.Stdin, os.Stdout, os.Stderr}, //新进程的环境变量 Env: os.Environ(), } //win下通过记事本打开1.txt //开始一个新进程 p, err := os.StartProcess(\u0026#34;C:\\\\Windows\\\\System32\\\\notepad.exe\u0026#34;, []string{\u0026#34;C:\\\\Windows\\\\System32\\\\notepad.exe\u0026#34;, \u0026#34;D:\\\\1.txt\u0026#34;}, attr); if err != nil { fmt.Println(err); } fmt.Println(p); fmt.Println(\u0026#34;进程ID：\u0026#34;, p.Pid); //通过进程ID查找进程 p2, _ := os.FindProcess(p.Pid); fmt.Println(p2); //等待10秒，执行函数 time.AfterFunc(time.Second*10, func() { //向p进程发送退出信号 p.Signal(os.Kill); }); //等待进程p的退出，返回进程状态 ps, _ := p.Wait(); fmt.Println(ps.String()); } ","permalink":"https://haokiu.com/blog/XtwuYL/","summary":"1. 获取当前时间 时间戳(秒)：time.Now().Unix 日期：time.Now().Format(\u0026#34;2006-01-02 15:04:05\u0026#34;) 注意：参数必须是 2006-01-02 15:04:05 而不能是自定义的年月日时间 2. 字符串与int转换 i,_ := strconv.Atoi(\u0026#34;3\u0026#34;) a := strconv.Itoa(32) 3.结构体json序列化 chatMsg := \u0026amp;ChatMsg{} err := json.Unmarshal([]byte(msg), chatMsg) //json转结构体 buf, _ := json.Marshal(chatMsg) //结构体转json return string(buf) 4.删除切片元素 mySlice := make([]int, 5) //创建一个初始元素个数为5的数组切片，元素初始值为0 mySlice = append(mySlice[:i], mySlice[i+1:]...) //删除下标为i的元素 mySlice = append(mySlice[:0], mySlice[1:]...) //删除第1个元素 5. url encode/decode encodeUrl:= url.QueryEscape(urltest) decodeUrl,err := url.QueryUnescape(encodeUrl) 6. base64编码 encodeString := base64.StdEncoding.EncodeToString(input) decodeBytes, err := base64.StdEncoding.DecodeString(encodeString) 7. 获取字符串长度 tips := \u0026#34;忍者\u0026#34; len := len(tips) //len=6 len := utf8.RuneCountInString(tips) //len=2 8. SubString func SubString(str string, start int32, end int32) string { result := []rune(str) length := int32(len(result)) if start \u0026lt; 0 || start \u0026gt; length { return str } if end \u0026lt; 0 || end \u0026gt; length { return str } return string(result[start:end]) } result = SubString(result, 0, int32(len([]rune(result)))-1)//注意end参数的取值 9.","title":"golang 常用函数"},{"content":"现在 presto 有两个官网：\n旧presto官网 新presto官网 ","permalink":"https://haokiu.com/blog/FhpG3z/","summary":"现在 presto 有两个官网：\n旧presto官网 新presto官网 ","title":"presto 官网"},{"content":"presto 有很多连接器以支持不同的数据源：\nAccumulo BigQuery Black Hole Cassandra Druid Elasticsearch Google Sheets Iceberg Hive JMX Kafka Kinesis Kudu Local File Memory MemSQL MongoDB MySQL Oracle Phoenix Pinot PostgreSQL Prometheus Redis Redshift SQL Server System Thrift TPCDS TPCH ","permalink":"https://haokiu.com/blog/7mlwkW/","summary":"presto 有很多连接器以支持不同的数据源：\nAccumulo BigQuery Black Hole Cassandra Druid Elasticsearch Google Sheets Iceberg Hive JMX Kafka Kinesis Kudu Local File Memory MemSQL MongoDB MySQL Oracle Phoenix Pinot PostgreSQL Prometheus Redis Redshift SQL Server System Thrift TPCDS TPCH ","title":"presto 支持的数据源"},{"content":"MyBatis 提供的强大机制，使用插件是非常简单的，只需实现 Interceptor 接口，并指定想要拦截的方法签名即可。\n拦截器 import java.text.DateFormat; import java.util.Date; import java.util.List; import java.util.Locale; import java.util.Properties; import org.apache.ibatis.executor.Executor; import org.apache.ibatis.mapping.BoundSql; import org.apache.ibatis.mapping.MappedStatement; import org.apache.ibatis.mapping.ParameterMapping; import org.apache.ibatis.plugin.Interceptor; import org.apache.ibatis.plugin.Intercepts; import org.apache.ibatis.plugin.Invocation; import org.apache.ibatis.plugin.Plugin; import org.apache.ibatis.plugin.Signature; import org.apache.ibatis.reflection.MetaObject; import org.apache.ibatis.session.Configuration; import org.apache.ibatis.session.ResultHandler; import org.apache.ibatis.session.RowBounds; import org.apache.ibatis.type.TypeHandlerRegistry; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Intercepts({ @Signature(type = Executor.class, method = \u0026#34;update\u0026#34;, args = { MappedStatement.class, Object.class }), @Signature(type = Executor.class, method = \u0026#34;query\u0026#34;, args = { MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class }) }) public class MybatisInterceptor implements Interceptor { private static final Logger log = LoggerFactory.getLogger(MybatisInterceptor.class); @Override public Object intercept(Invocation invocation) throws Throwable { MappedStatement mappedStatement = (MappedStatement) invocation.getArgs()[0]; Object parameter = null; if (invocation.getArgs().length \u0026gt; 1) { parameter = invocation.getArgs()[1]; } BoundSql boundSql = mappedStatement.getBoundSql(parameter); Configuration configuration = mappedStatement.getConfiguration(); Object returnVal = invocation.proceed(); //获取sql语句 String sql = getSql(configuration, boundSql); log.info(\u0026#34;Mybatis 拦截器获取SQL:{}\u0026#34;,sql); return returnVal; } @Override public Object plugin(Object target) { return Plugin.wrap(target, this); } @Override public void setProperties(Properties arg0) { } /** * 获取SQL */ private String getSql(Configuration configuration, BoundSql boundSql) { Object parameterObject = boundSql.getParameterObject(); List\u0026lt;ParameterMapping\u0026gt; parameterMappings = boundSql.getParameterMappings(); String sql = boundSql.getSql().replaceAll(\u0026#34;[\\\\s]+\u0026#34;, \u0026#34; \u0026#34;); if (parameterObject == null || parameterMappings.size() == 0) { return sql; } TypeHandlerRegistry typeHandlerRegistry = configuration.getTypeHandlerRegistry(); if (typeHandlerRegistry.hasTypeHandler(parameterObject.getClass())) { sql = sql.replaceFirst(\u0026#34;\\\\?\u0026#34;, getParameterValue(parameterObject)); } else { MetaObject metaObject = configuration.newMetaObject(parameterObject); for (ParameterMapping parameterMapping : parameterMappings) { String propertyName = parameterMapping.getProperty(); if (metaObject.hasGetter(propertyName)) { Object obj = metaObject.getValue(propertyName); sql = sql.replaceFirst(\u0026#34;\\\\?\u0026#34;, getParameterValue(obj)); } else if (boundSql.hasAdditionalParameter(propertyName)) { Object obj = boundSql.getAdditionalParameter(propertyName); sql = sql.replaceFirst(\u0026#34;\\\\?\u0026#34;, getParameterValue(obj)); } } } return sql; } private String getParameterValue(Object obj) { String value = null; if (obj instanceof String) { value = \u0026#34;\u0026#39;\u0026#34; + obj.toString() + \u0026#34;\u0026#39;\u0026#34;; } else if (obj instanceof Date) { DateFormat formatter = DateFormat.getDateTimeInstance(DateFormat.DEFAULT, DateFormat.DEFAULT, Locale.CHINA); value = \u0026#34;\u0026#39;\u0026#34; + formatter.format(obj) + \u0026#34;\u0026#39;\u0026#34;; } else { if (obj != null) { value = obj.toString(); } else { value = \u0026#34;\u0026#34;; } } return value; } } 配置 mybatis: type-aliases-package: me.zingon.pagehelper.model mapper-locations: classpath:mapper/*.xml configuration: map-underscore-to-camel-case: true default-fetch-size: 100 default-statement-timeout: 30 在springboot中要给mybatis加上这个拦截器，有三种方法，前两种方法在启动项目时不会自动调用自定义拦截器的setProperties方法。\n第一种 直接给自定义拦截器添加一个 @Component注解，当调用sql时结果如下，可以看到拦截器生效了，但是启动时候并没有自动调用setProperties方法。\n第二种 在配置类里添加拦截器，这种方法结果同上，也不会自动调用setProperties方法。\n@Configuration public class MybatisConfig { @Bean ConfigurationCustomizer mybatisConfigurationCustomizer() { return new ConfigurationCustomizer() { @Override public void customize(org.apache.ibatis.session.Configuration configuration) { configuration.addInterceptor(new MyPageInterceptor()); } }; } } 第三种 这种方法就是跟以前的配置方法类似，在yml配置文件中指定mybatis的xml配置文件,注意config-location属性和configuration属性不能同时指定\nmybatis: config-location: classpath:mybatis.xml type-aliases-package: com.haokiu.model mapper-locations: classpath:mapper/*.xml mybatis.xml\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE configuration PUBLIC \u0026#34;-//mybatis.org//DTD Config 3.0//EN\u0026#34; \u0026#34;http://mybatis.org/dtd/mybatis-3-config.dtd\u0026#34;\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;typeAliases\u0026gt; \u0026lt;package name=\u0026#34;com.haokiu.model\u0026#34;/\u0026gt; \u0026lt;/typeAliases\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin interceptor=\u0026#34;com.haokiu.interceptor.MyInterceptor\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;dialect\u0026#34; value=\u0026#34;oracle\u0026#34;/\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/configuration\u0026gt; 可以看到，在启动项目的时候setProperties被自动调用了\n总结 前两种方法可以在初始化自定义拦截器的时候通过 @Value 注解直接初始化需要的参数。\n","permalink":"https://haokiu.com/blog/bGqNiH/","summary":"MyBatis 提供的强大机制，使用插件是非常简单的，只需实现 Interceptor 接口，并指定想要拦截的方法签名即可。\n拦截器 import java.text.DateFormat; import java.util.Date; import java.util.List; import java.util.Locale; import java.util.Properties; import org.apache.ibatis.executor.Executor; import org.apache.ibatis.mapping.BoundSql; import org.apache.ibatis.mapping.MappedStatement; import org.apache.ibatis.mapping.ParameterMapping; import org.apache.ibatis.plugin.Interceptor; import org.apache.ibatis.plugin.Intercepts; import org.apache.ibatis.plugin.Invocation; import org.apache.ibatis.plugin.Plugin; import org.apache.ibatis.plugin.Signature; import org.apache.ibatis.reflection.MetaObject; import org.apache.ibatis.session.Configuration; import org.apache.ibatis.session.ResultHandler; import org.apache.ibatis.session.RowBounds; import org.apache.ibatis.type.TypeHandlerRegistry; import org.slf4j.Logger; import org.slf4j.LoggerFactory; @Intercepts({ @Signature(type = Executor.class, method = \u0026#34;update\u0026#34;, args = { MappedStatement.class, Object.class }), @Signature(type = Executor.class, method = \u0026#34;query\u0026#34;, args = { MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class }) }) public class MybatisInterceptor implements Interceptor { private static final Logger log = LoggerFactory.getLogger(MybatisInterceptor.class); @Override public Object intercept(Invocation invocation) throws Throwable { MappedStatement mappedStatement = (MappedStatement) invocation.","title":"mybatis 增加自定义拦截器"},{"content":"idea 付费版和免费版的区别 IntelliJ IDEA Ultimate IntelliJ IDEA Community Edition Java, Kotlin, Groovy, Scala + + Android + + Maven, Gradle, sbt + + Git, SVN, Mercurial + + Debugger + + Profiling tools + - Spring, Java EE, Micronaut, Quarkus, Helidon, and more + - Swagger, Open API Specifications + - JavaScript, TypeScript + - Database Tools, SQL + - ","permalink":"https://haokiu.com/blog/oqQib8/","summary":"idea 付费版和免费版的区别 IntelliJ IDEA Ultimate IntelliJ IDEA Community Edition Java, Kotlin, Groovy, Scala + + Android + + Maven, Gradle, sbt + + Git, SVN, Mercurial + + Debugger + + Profiling tools + - Spring, Java EE, Micronaut, Quarkus, Helidon, and more + - Swagger, Open API Specifications + - JavaScript, TypeScript + - Database Tools, SQL + - ","title":"idea 付费版和免费版的区别"},{"content":"okex 是一个老牌的数字货币交易所，我一直在用OKEx安全简便地交易数字货币。\n用我的邀请链接注册OKEx可以免费获得比特币奖励！点击这里 或者 使用这个地址： https://www.ouyi.fit/join/1841513\nokex 是全球著名的数字资产交易平台之一，主要面向全球用户提供比特币、莱特币、以太币等数字资产的币币和衍生品交易服务。\n","permalink":"https://haokiu.com/blog/4Li9s1/","summary":"okex 是一个老牌的数字货币交易所，我一直在用OKEx安全简便地交易数字货币。\n用我的邀请链接注册OKEx可以免费获得比特币奖励！点击这里 或者 使用这个地址： https://www.ouyi.fit/join/1841513\nokex 是全球著名的数字资产交易平台之一，主要面向全球用户提供比特币、莱特币、以太币等数字资产的币币和衍生品交易服务。","title":"okex"},{"content":"SQL 优化已经成为衡量程序猿优秀与否的硬性指标，甚至在各大厂招聘岗位职能上都有明码标注。\n有朋友疑问到，SQL 优化真的有这么重要么？如下图所示，SQL 优化在提升系统性能中是：成本最低和优化效果最明显的途径。\n**优化成本：**硬件\u0026gt;系统配置\u0026gt;数据库表结构\u0026gt;SQL 及索引。\n**优化效果：**硬件\u0026lt;系统配置\u0026lt;数据库表结构\u0026lt;SQL 及索引。\n对于MySQL层优化我一般遵从五个原则：\n**减少数据访问：**设置合理的字段类型，启用压缩，通过索引访问等减少磁盘 IO。 **返回更少的数据：**只返回需要的字段和数据分页处理，减少磁盘 IO 及网络 IO。 **减少交互次数：**批量 DML 操作，函数存储等减少数据连接次数。 **减少服务器 CPU 开销：**尽量减少数据库排序操作以及全表查询，减少 CPU 内存占用。 **利用更多资源：**使用表分区，可以增加并行操作，更大限度利用 CPU 资源。 总结到 SQL 优化中，就如下三点：\n最大化利用索引。 尽可能避免全表扫描。 减少无效数据的查询。 理解 SQL 优化原理 ，首先要搞清楚 SQL 执行顺序。\nSELECT 语句，语法顺序如下：\n1. SELECT 2. DISTINCT \u0026lt;select_list\u0026gt; 3. FROM \u0026lt;left_table\u0026gt; 4. \u0026lt;join_type\u0026gt; JOIN \u0026lt;right_table\u0026gt; 5. ON \u0026lt;join_condition\u0026gt; 6. WHERE \u0026lt;where_condition\u0026gt; 7. GROUP BY \u0026lt;group_by_list\u0026gt; 8. HAVING \u0026lt;having_condition\u0026gt; 9. ORDER BY \u0026lt;order_by_condition\u0026gt; 10.LIMIT \u0026lt;limit_number\u0026gt; SELECT 语句，执行顺序如下：\nFROM \u0026lt;表名\u0026gt; # 选取表，将多个表数据通过笛卡尔积变成一个表。 ON \u0026lt;筛选条件\u0026gt; # 对笛卡尔积的虚表进行筛选 JOIN \u0026lt;join, left join, right join...\u0026gt; \u0026lt;join表\u0026gt; # 指定join，用于添加数据到on之后的虚表中，例如left join会将左表的剩余数据添加到虚表中 WHERE \u0026lt;where条件\u0026gt; # 对上述虚表进行筛选 GROUP BY \u0026lt;分组条件\u0026gt; # 分组 \u0026lt;SUM()等聚合函数\u0026gt; # 用于having子句进行判断，在书写上这类聚合函数是写在having判断里面的 HAVING \u0026lt;分组筛选\u0026gt; # 对分组后的结果进行聚合筛选 SELECT \u0026lt;返回数据列表\u0026gt; # 返回的单列必须在group by子句中，聚合函数除外 DISTINCT # 数据除重 ORDER BY \u0026lt;排序条件\u0026gt; # 排序 LIMIT \u0026lt;行数限制\u0026gt; 以下 SQL 优化策略适用于数据量较大的场景下，如果数据量较小，没必要以此为准，以免画蛇添足。\n避免不走索引的场景\n①尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描\n如下：\nSELECT * FROM t WHERE username LIKE \u0026#39;%陈%\u0026#39; **优化方式：**尽量在字段后面使用模糊查询。\n如下：\nSELECT * FROM t WHERE username LIKE \u0026#39;陈%\u0026#39; 如果需求是要在前面使用模糊查询：\n使用 MySQL 内置函数 INSTR（str，substr）来匹配，作用类似于 Java 中的 indexOf()，查询字符串出现的角标位置。\n使用 FullText 全文索引，用 match against 检索。\n数据量较大的情况，建议引用 ElasticSearch、Solr，亿级数据量检索速度秒级。 当表数据量较少（几千条儿那种），别整花里胡哨的，直接用 like \u0026lsquo;%xx%\u0026rsquo;。\n②尽量避免使用 in 和 not in，会导致引擎走全表扫描\n如下：\nSELECT * FROM t WHERE id IN (2,3) **优化方式：**如果是连续数值，可以用 between 代替。\n如下：\nSELECT * FROM t WHERE id BETWEEN 2 AND 3 如果是子查询，可以用 exists 代替。\n如下：\n-- 不走索引 select * from A where A.id in (select id from B); -- 走索引 select * from A where exists (select * from B where B.id = A.id); ③尽量避免使用 or，会导致数据库引擎放弃索引进行全表扫描\n如下：\nSELECT * FROM t WHERE id = 1 OR id = 3 **优化方式：**可以用 union 代替 or。\n如下：\nSELECT * FROM t WHERE id = 1 UNION SELECT * FROM t WHERE id = 3 ④尽量避免进行 null 值的判断，会导致数据库引擎放弃索引进行全表扫描\n如下：\nSELECT * FROM t WHERE score IS NULL **优化方式：**可以给字段添加默认值 0，对 0 值进行判断。\n如下：\nSELECT * FROM t WHERE score = 0 ⑤尽量避免在 where 条件中等号的左侧进行表达式、函数操作，会导致数据库引擎放弃索引进行全表扫描\n可以将表达式、函数操作移动到等号右侧，如下：\n-- 全表扫描 SELECT * FROM T WHERE score/10 = 9 -- 走索引 SELECT * FROM T WHERE score = 10*9 ⑥当数据量大时，避免使用 where 1=1 的条件\n通常为了方便拼装查询条件，我们会默认使用该条件，数据库引擎会放弃索引进行全表扫描。\n如下：\nSELECT username, age, sex FROM T WHERE 1=1 **优化方式：**用代码拼装 SQL 时进行判断，没 where 条件就去掉 where，有 where 条件就加 and。\n⑦查询条件不能用 \u0026lt;\u0026gt; 或者 !=\n使用索引列作为条件进行查询时，需要避免使用\u0026lt;\u0026gt;或者!=等判断条件。\n如确实业务需要，使用到不等于符号，需要在重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替。\n⑧where 条件仅包含复合索引非前置列\n如下：复合（联合）索引包含 key_part1，key_part2，key_part3 三列，但 SQL 语句没有包含索引前置列\u0026quot;key_part1\u0026quot;，按照 MySQL 联合索引的最左匹配原则，不会走联合索引。\nselect col1 from table where key_part2=1 and key_part3=2 ⑨隐式类型转换造成不使用索引\n如下 SQL 语句由于索引对列类型为 varchar，但给定的值为数值，涉及隐式类型转换，造成不能正确走索引。\nselect col1 from table where col_varchar=123; ⑩order by 条件要与 where 中条件一致，否则 order by 不会利用索引进行排序\n如下：\n-- 不走age索引 SELECT * FROM t order by age; -- 走age索引 SELECT * FROM t where age \u0026gt; 0 order by age; 对于上面的语句，数据库的处理顺序是：\n**第一步：**根据 where 条件和统计信息生成执行计划，得到数据。 **第二步：**将得到的数据排序。当执行处理数据（order by）时，数据库会先查看第一步的执行计划，看 order by 的字段是否在执行计划中利用了索引。如果是，则可以利用索引顺序而直接取得已经排好序的数据。如果不是，则重新进行排序操作。 **第三步：**返回排序后的数据。 当 order by 中的字段出现在 where 条件中时，才会利用索引而不再二次排序，更准确的说，order by 中的字段在执行计划中利用了索引时，不用排序操作。\n这个结论不仅对 order by 有效，对其他需要排序的操作也有效。比如 group by 、union 、distinct 等。\n⑪正确使用 hint 优化语句\nMySQL 中可以使用 hint 指定优化器在执行时选择或忽略特定的索引。\n一般而言，处于版本变更带来的表结构索引变化，更建议避免使用 hint，而是通过 Analyze table 多收集统计信息。\n但在特定场合下，指定 hint 可以排除其他索引干扰而指定更优的执行计划：\nUSE INDEX 在你查询语句中表名的后面，添加 USE INDEX 来提供希望 MySQL 去参考的索引列表，就可以让 MySQL 不再考虑其他可用的索引。\n例子: SELECT col1 FROM table USE INDEX (mod_time, name)\u0026hellip;\nIGNORE INDEX 如果只是单纯的想让 MySQL 忽略一个或者多个索引，可以使用 IGNORE INDEX 作为 Hint。\n例子: SELECT col1 FROM table IGNORE INDEX (priority) \u0026hellip;\nFORCE INDEX 为强制 MySQL 使用一个特定的索引，可在查询中使用FORCE INDEX 作为 Hint。\n例子: SELECT col1 FROM table FORCE INDEX (mod_time) \u0026hellip;\n在查询的时候，数据库系统会自动分析查询语句，并选择一个最合适的索引。但是很多时候，数据库系统的查询优化器并不一定总是能使用最优索引。\n如果我们知道如何选择索引，可以使用 FORCE INDEX 强制查询使用指定的索引。\n例如：\nSELECT * FROM students FORCE INDEX (idx_class_id) WHERE class_id = 1 ORDER BY id DESC; SELECT 语句其他优化\n①避免出现 select *\n首先，select * 操作在任何类型数据库中都不是一个好的 SQL 编写习惯。\n使用 select * 取出全部列，会让优化器无法完成索引覆盖扫描这类优化，会影响优化器对执行计划的选择，也会增加网络带宽消耗，更会带来额外的 I/O，内存和 CPU 消耗。\n建议提出业务实际需要的列数，将指定列名以取代 select *。具体详情见《为什么大家都说SELECT * 效率低》\n②避免出现不确定结果的函数\n特定针对主从复制这类业务场景。由于原理上从库复制的是主库执行的语句，使用如 now()、rand()、sysdate()、current_user() 等不确定结果的函数很容易导致主库与从库相应的数据不一致。\n另外不确定值的函数，产生的 SQL 语句无法利用 query cache。\n③多表关联查询时，小表在前，大表在后\n在 MySQL 中，执行 from 后的表关联查询是从左往右执行的（Oracle 相反），第一张表会涉及到全表扫描。\n所以将小表放在前面，先扫小表，扫描快效率较高，在扫描后面的大表，或许只扫描大表的前 100 行就符合返回条件并 return 了。\n例如：表 1 有 50 条数据，表 2 有 30 亿条数据；如果全表扫描表 2，你品，那就先去吃个饭再说吧是吧。\n④使用表的别名\n当在 SQL 语句中连接多个表时，请使用表的别名并把别名前缀于每个列名上。这样就可以减少解析的时间并减少哪些友列名歧义引起的语法错误。\n⑤用 where 字句替换 HAVING 字句\n避免使用 HAVING 字句，因为 HAVING 只会在检索出所有记录之后才对结果集进行过滤，而 where 则是在聚合前刷选记录，如果能通过 where 字句限制记录的数目，那就能减少这方面的开销。\nHAVING 中的条件一般用于聚合函数的过滤，除此之外，应该将条件写在 where 字句中。\nwhere 和 having 的区别：where 后面不能使用组函数。\n⑥调整 Where 字句中的连接顺序\nMySQL 采用从左往右，自上而下的顺序解析 where 子句。根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集。\n增删改 DML 语句优化\n①大批量插入数据\n如果同时执行大量的插入，建议使用多个值的 INSERT 语句（方法二）。这比使用分开 INSERT 语句快（方法一），一般情况下批量插入效率有几倍的差别。\n方法一：\ninsert into T values(1,2); insert into T values(1,3); insert into T values(1,4); 方法二：\nInsert into T values(1,2),(1,3),(1,4); 选择后一种方法的原因有三：\n减少 SQL 语句解析的操作，MySQL 没有类似 Oracle 的 share pool，采用方法二，只需要解析一次就能进行数据的插入操作。 在特定场景可以减少对 DB 连接次数。 SQL 语句较短，可以减少网络传输的 IO。 ②适当使用 commit\n适当使用 commit 可以释放事务占用的资源而减少消耗，commit 后能释放的资源如下：\n事务占用的 undo 数据块。\n事务在 redo log 中记录的数据块。\n释放事务施加的，减少锁争用影响性能。特别是在需要使用 delete 删除大量数据的时候，必须分解删除量并定期 commit。 ③避免重复查询更新的数据\n针对业务中经常出现的更新行同时又希望获得改行信息的需求，MySQL 并不支持 PostgreSQL 那样的 UPDATE RETURNING 语法，在 MySQL 中可以通过变量实现。\n例如，更新一行记录的时间戳，同时希望查询当前记录中存放的时间戳是什么？\n简单方法实现：\nUpdate t1 set time=now() where col1=1; Select time from t1 where id =1; 使用变量，可以重写为以下方式：\nUpdate t1 set time=now () where col1=1 and @now: = now (); Select @now; 前后二者都需要两次网络来回，但使用变量避免了再次访问数据表，特别是当 t1 表数据量较大时，后者比前者快很多。\n④查询优先还是更新（insert、update、delete）优先\nMySQL 还允许改变语句调度的优先级，它可以使来自多个客户端的查询更好地协作，这样单个客户端就不会由于锁定而等待很长时间。改变优先级还可以确保特定类型的查询被处理得更快。\n我们首先应该确定应用的类型，判断应用是以查询为主还是以更新为主的，是确保查询效率还是确保更新的效率，决定是查询优先还是更新优先。\n下面我们提到的改变调度策略的方法主要是针对只存在表锁的存储引擎，比如 MyISAM 、MEMROY、MERGE，对于 Innodb 存储引擎，语句的执行是由获得行锁的顺序决定的。\nMySQL 的默认的调度策略可用总结如下：\n写入操作优先于读取操作。 对某张数据表的写入操作某一时刻只能发生一次，写入请求按照它们到达的次序来处理。 对某张数据表的多个读取操作可以同时地进行。 MySQL 提供了几个语句调节符，允许你修改它的调度策略：\nLOW_PRIORITY 关键字应用于 DELETE、INSERT、LOAD DATA、REPLACE 和 UPDATE。\nHIGH_PRIORITY 关键字应用于 SELECT 和 INSERT 语句。\nDELAYED 关键字应用于 INSERT 和 REPLACE 语句。 如果写入操作是一个 LOW_PRIORITY（低优先级）请求，那么系统就不会认为它的优先级高于读取操作。\n在这种情况下，如果写入者在等待的时候，第二个读取者到达了，那么就允许第二个读取者插到写入者之前。\n只有在没有其它的读取者的时候，才允许写入者开始操作。这种调度修改可能存在 LOW_PRIORITY 写入操作永远被阻塞的情况。\nSELECT 查询的 HIGH_PRIORITY（高优先级）关键字也类似。它允许 SELECT 插入正在等待的写入操作之前，即使在正常情况下写入操作的优先级更高。\n另外一种影响是，高优先级的 SELECT 在正常的 SELECT 语句之前执行，因为这些语句会被写入操作阻塞。\n如果希望所有支持 LOW_PRIORITY 选项的语句都默认地按照低优先级来处理，那么请使用\u0026ndash;low-priority-updates 选项来启动服务器。\n通过使用 INSERTHIGH_PRIORITY 来把 INSERT 语句提高到正常的写入优先级，可以消除该选项对单个 INSERT 语句的影响。\n查询条件优化\n①对于复杂的查询，可以使用中间临时表暂存数据\n②优化 group by 语句\n默认情况下，MySQL 会对 GROUP BY 分组的所有值进行排序，如 “GROUP BY col1，col2，\u0026hellip;.;” 查询的方法如同在查询中指定 “ORDER BY col1，col2，\u0026hellip;;” 。\n如果显式包括一个包含相同的列的 ORDER BY 子句，MySQL 可以毫不减速地对它进行优化，尽管仍然进行排序。\n因此，如果查询包括 GROUP BY 但你并不想对分组的值进行排序，你可以指定 ORDER BY NULL 禁止排序。\n例如：\nSELECT col1, col2, COUNT(*) FROM table GROUP BY col1, col2 ORDER BY NULL ; ③优化 join 语句\nMySQL 中可以通过子查询来使用 SELECT 语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。\n使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的 SQL 操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接（JOIN）..替代。\n例子：假设要将所有没有订单记录的用户取出来，可以用下面这个查询完成：\nSELECT col1 FROM customerinfo WHERE CustomerID NOT in (SELECT CustomerID FROM salesinfo ) 如果使用连接（JOIN）..来完成这个查询工作，速度将会有所提升。\n尤其是当 salesinfo 表中对 CustomerID 建有索引的话，性能将会更好，查询如下：\nSELECT col1 FROM customerinfo LEFT JOIN salesinfoON customerinfo.CustomerID=salesinfo.CustomerID WHERE salesinfo.CustomerID IS NULL 连接（JOIN）..之所以更有效率一些，是因为 MySQL 不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作。\n④优化 union 查询\nMySQL 通过创建并填充临时表的方式来执行 union 查询。除非确实要消除重复的行，否则建议使用 union all。\n原因在于如果没有 all 这个关键词，MySQL 会给临时表加上 distinct 选项，这会导致对整个临时表的数据做唯一性校验，这样做的消耗相当高。\n高效：\nSELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 UNION ALL SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3= \u0026#39;TEST\u0026#39;; 低效：\nSELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 UNION SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3= \u0026#39;TEST\u0026#39;; ⑤拆分复杂 SQL 为多个小 SQL，避免大事务\n如下：\n简单的 SQL 容易使用到 MySQL 的 QUERY CACHE。 减少锁表时间特别是使用 MyISAM 存储引擎的表。 可以使用多核 CPU。 ⑥使用 truncate 代替 delete\n当删除全表中记录时，使用 delete 语句的操作会被记录到 undo 块中，删除记录也记录 binlog。\n当确认需要删除全表时，会产生很大量的 binlog 并占用大量的 undo 数据块，此时既没有很好的效率也占用了大量的资源。\n使用 truncate 替代，不会记录可恢复的信息，数据不能被恢复。也因此使用 truncate 操作有其极少的资源占用与极快的时间。另外，使用 truncate 可以回收表的水位，使自增字段值归零。\n⑦使用合理的分页方式以提高分页效率\n使用合理的分页方式以提高分页效率 针对展现等分页需求，合适的分页方式能够提高分页的效率。\n案例 1：\nselect * from t where thread_id = 10000 and deleted = 0 order by gmt_create asc limit 0, 15; 上述例子通过一次性根据过滤条件取出所有字段进行排序返回。数据访问开销=索引 IO+索引全部记录结果对应的表数据 IO。\n因此，该种写法越翻到后面执行效率越差，时间越长，尤其表数据量很大的时候。\n适用场景：当中间结果集很小（10000 行以下）或者查询条件复杂（指涉及多个不同查询字段或者多表连接）时适用。\n案例 2：\nselect t.* from (select id from t where thread_id = 10000 and deleted = 0 order by gmt_create asc limit 0, 15) a, t where a.id = t.id; 上述例子必须满足 t 表主键是 id 列，且有覆盖索引 secondary key：（thread_id, deleted, gmt_create）。\n通过先根据过滤条件利用覆盖索引取出主键 id 进行排序，再进行 join 操作取出其他字段。\n数据访问开销=索引 IO+索引分页后结果（例子中是 15 行）对应的表数据 IO。因此，该写法每次翻页消耗的资源和时间都基本相同，就像翻第一页一样。\n**适用场景：**当查询和排序字段（即 where 子句和 order by 子句涉及的字段）有对应覆盖索引时，且中间结果集很大的情况时适用。\n建表优化\n①在表中建立索引，优先考虑 where、order by 使用到的字段。\n②尽量使用数字型字段（如性别，男：1 女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。\n这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。\n③查询数据量大的表 会造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段分页进行查询，循环遍历，将结果合并处理进行展示。\n要查询 100000 到 100050 的数据，如下：\nSELECT * FROM (SELECT ROW_NUMBER() OVER(ORDER BY ID ASC) AS rowid,* FROM infoTab)t WHERE t.rowid \u0026gt; 100000 AND t.rowid \u0026lt;= 100050 ④用 varchar/nvarchar 代替 char/nchar。\n尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。\n不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL 也包含在内），都是占用 100 个字符的空间的，如果是 varchar 这样的变长字段， null 不占用空间\n","permalink":"https://haokiu.com/blog/XEhpYv/","summary":"SQL 优化已经成为衡量程序猿优秀与否的硬性指标，甚至在各大厂招聘岗位职能上都有明码标注。\n有朋友疑问到，SQL 优化真的有这么重要么？如下图所示，SQL 优化在提升系统性能中是：成本最低和优化效果最明显的途径。\n**优化成本：**硬件\u0026gt;系统配置\u0026gt;数据库表结构\u0026gt;SQL 及索引。\n**优化效果：**硬件\u0026lt;系统配置\u0026lt;数据库表结构\u0026lt;SQL 及索引。\n对于MySQL层优化我一般遵从五个原则：\n**减少数据访问：**设置合理的字段类型，启用压缩，通过索引访问等减少磁盘 IO。 **返回更少的数据：**只返回需要的字段和数据分页处理，减少磁盘 IO 及网络 IO。 **减少交互次数：**批量 DML 操作，函数存储等减少数据连接次数。 **减少服务器 CPU 开销：**尽量减少数据库排序操作以及全表查询，减少 CPU 内存占用。 **利用更多资源：**使用表分区，可以增加并行操作，更大限度利用 CPU 资源。 总结到 SQL 优化中，就如下三点：\n最大化利用索引。 尽可能避免全表扫描。 减少无效数据的查询。 理解 SQL 优化原理 ，首先要搞清楚 SQL 执行顺序。\nSELECT 语句，语法顺序如下：\n1. SELECT 2. DISTINCT \u0026lt;select_list\u0026gt; 3. FROM \u0026lt;left_table\u0026gt; 4. \u0026lt;join_type\u0026gt; JOIN \u0026lt;right_table\u0026gt; 5. ON \u0026lt;join_condition\u0026gt; 6. WHERE \u0026lt;where_condition\u0026gt; 7. GROUP BY \u0026lt;group_by_list\u0026gt; 8. HAVING \u0026lt;having_condition\u0026gt; 9. ORDER BY \u0026lt;order_by_condition\u0026gt; 10.LIMIT \u0026lt;limit_number\u0026gt; SELECT 语句，执行顺序如下：\nFROM \u0026lt;表名\u0026gt; # 选取表，将多个表数据通过笛卡尔积变成一个表。 ON \u0026lt;筛选条件\u0026gt; # 对笛卡尔积的虚表进行筛选 JOIN \u0026lt;join, left join, right join...\u0026gt; \u0026lt;join表\u0026gt; # 指定join，用于添加数据到on之后的虚表中，例如left join会将左表的剩余数据添加到虚表中 WHERE \u0026lt;where条件\u0026gt; # 对上述虚表进行筛选 GROUP BY \u0026lt;分组条件\u0026gt; # 分组 \u0026lt;SUM()等聚合函数\u0026gt; # 用于having子句进行判断，在书写上这类聚合函数是写在having判断里面的 HAVING \u0026lt;分组筛选\u0026gt; # 对分组后的结果进行聚合筛选 SELECT \u0026lt;返回数据列表\u0026gt; # 返回的单列必须在group by子句中，聚合函数除外 DISTINCT # 数据除重 ORDER BY \u0026lt;排序条件\u0026gt; # 排序 LIMIT \u0026lt;行数限制\u0026gt; 以下 SQL 优化策略适用于数据量较大的场景下，如果数据量较小，没必要以此为准，以免画蛇添足。","title":"sql 优化"},{"content":"基本概念 Node 与 Cluster Elastic 本质上是一个分布式数据库，允许多台服务器协同工作，每台服务器可以运行多个 Elastic 实例。\n单个 Elastic 实例称为一个节点（node）。一组节点构成一个集群（cluster）。\nIndex Elastic 会索引所有字段，经过处理后写入一个反向索引（Inverted Index）。查找数据的时候，直接查找该索引。\n所以，Elastic 数据管理的顶层单位就叫做 Index（索引）。它是单个数据库的同义词。每个 Index （即数据库）的名字必须是小写。\nDocument Index 里面单条的记录称为 Document（文档）。许多条 Document 构成了一个 Index。Document 使用 JSON 格式表示。同一个 Index 里面的 Document，不要求有相同的结构（scheme），但是最好保持相同，这样有利于提高搜索效率。\nType Document 可以分组，比如weather这个 Index 里面，可以按城市分组（北京和上海），也可以按气候分组（晴天和雨天）。这种分组就叫做 Type，它是虚拟的逻辑分组，用来过滤 Document。\n不同的 Type 应该有相似的结构（schema），举例来说，id字段不能在这个组是字符串，在另一个组是数值。这是与关系型数据库的表的一个区别。性质完全不同的数据（比如products和logs）应该存成两个 Index，而不是一个 Index 里面的两个 Type（虽然可以做到）。\n在6.0之前的版本，一个ElasticSearch索引中，可以有多个类型；从6.0版本开始，，一个ElasticSearch索引中，只有1个类型。一个类型是索引的一个逻辑上的分类，通常具有一组相同字段的文档组成。ElasticSearch的类型概念相当于关系数据库的数据表。\nshard 当数据量较大时，索引的存储空间需求超出单个节点磁盘容量的限制，或者出现单个节点处理速度较慢。为了解决这些问题，ElasticSearch将索引中的数据进行切分成多个分片（shard），每个分片存储这个索引的一部分数据，分布在不同节点上。当需要查询索引时，ElasticSearch将查询发送到每个相关分片，之后将查询结果合并，这个过程对ElasticSearch应用来说是透明的，用户感知不到分片的存在。 一个索引的分片一旦指定，不再修改。\n副本 其实，分片全称是主分片，简称为分片。主分片是相对于副本来说的，副本是对主分片的一个或多个复制版本（或称拷贝），这些复制版本（拷贝）可以称为复制分片，可以直接称之为副本。当主分片丢失时，集群可以将一个副本升级为新的主分片。\n对比 ElasticSearch RDBMS 索引（index） 数据库（database） 类型（type） 表（table） 文档（document） 行（row） 字段（field） 列（column） 映射（mapping） 表结构（schema） 全文索引 索引 查询DSL SQL GET select PUT/POST update DELETE delete 节点信息 查看节点信息 curl localhost:9200 查看节点健康度 curl localhost:9200/_cat/health?v\u0026amp;pretty=true 查看集群状况 curl localhost:9200/_cat/nodes?v\u0026amp;pretty=true index(索引)操作 查看当前节点的所有 Index。 curl -X GET \u0026#39;http://localhost:9200/_cat/indices?v\u0026#39; 可以列出每个 Index 所包含的 Type curl \u0026#39;localhost:9200/_mapping?pretty=true\u0026#39; 新建一个名叫weather的 Index。 curl -X PUT \u0026#39;localhost:9200/weather\u0026#39; 删除这个 Index。 curl -X DELETE \u0026#39;localhost:9200/weather\u0026#39; 文档操作 获取 GET /website/blog/123?pretty { \u0026#34;_index\u0026#34; : \u0026#34;website\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;blog\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;123\u0026#34;, \u0026#34;_version\u0026#34; : 1, \u0026#34;found\u0026#34; : true, \u0026#34;_source\u0026#34; : { \u0026#34;title\u0026#34;: \u0026#34;My first blog entry\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;Just trying this out...\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2014/01/01\u0026#34; } } 检索文档的一部分\nGET /website/blog/123?_source=title,text { \u0026#34;_index\u0026#34; : \u0026#34;website\u0026#34;, \u0026#34;_type\u0026#34; : \u0026#34;blog\u0026#34;, \u0026#34;_id\u0026#34; : \u0026#34;123\u0026#34;, \u0026#34;_version\u0026#34; : 1, \u0026#34;exists\u0026#34; : true, \u0026#34;_source\u0026#34; : { \u0026#34;title\u0026#34;: \u0026#34;My first blog entry\u0026#34; , \u0026#34;text\u0026#34;: \u0026#34;Just trying this out...\u0026#34; } } 只想得到_source字段而不要其他的元数据\nGET /website/blog/123/_source { \u0026#34;title\u0026#34;: \u0026#34;My first blog entry\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;Just trying this out...\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2014/01/01\u0026#34; } 存在 如果你想做的只是检查文档是否存在——你对内容完全不感兴趣——使用HEAD方法来代替GET。HEAD请求不会返回响应体，只有HTTP头：\ncurl -i -XHEAD http://localhost:9200/website/blog/123 Elasticsearch将会返回200 OK状态如果你的文档存在：\nHTTP/1.1 200 OK Content-Type: text/plain; charset=UTF-8 Content-Length: 0 如果不存在返回404 Not Found：\nHTTP/1.1 404 Not Found Content-Type: text/plain; charset=UTF-8 Content-Length: 0 更新整个文档 PUT /website/blog/123 { \u0026#34;title\u0026#34;: \u0026#34;My first blog entry\u0026#34;, \u0026#34;text\u0026#34;: \u0026#34;I am starting to get the hang of this...\u0026#34;, \u0026#34;date\u0026#34;: \u0026#34;2014/01/02\u0026#34; } 新建文档 PUT /website/blog/123 { ... } 删除文档 DELETE /website/blog/123 配置 elasticsearch的config文件夹里面有两个配置文件：elasticsearch.yml和log4j2.properties，第一个是es的基本配置文件，第二个是日志配置文件，es也是使用log4j2来记录日志的，所以log4j2.properties里的设置按普通log4j2配置文件来设置就行了。\ncluster.name Elasticsearch 默认启动的集群名字叫 elasticsearch 。 你最好给你的生产环境的集群改个名字，改名字的目的很简单， 就是防止某人的笔记本电脑加入了集群这种意外。简单修改成 elasticsearch_production 会很省心。\n你可以在你的 elasticsearch.yml 文件中修改：\ncluster.name: elasticsearch_production\nnode.name 建议给每个节点设置一个有意义的、清楚的、描述性的名字，同样你可以在 elasticsearch.yml 中配置：\nnode.name: elasticsearch_005_data\nMaster节点 （主节点） node.master: true node.data: false 这样配置的节点为master节点。主节点的主要职责是和集群操作相关的内容，如创建或删除索引，跟踪哪些节点是群集的一部分，并决定哪些分片分配给相关的节点。稳定的主节点对集群的健康是非常重要的。\ndiscovery.zen.minimum_master_nodes 为了防止数据丢失，配置discovery.zen.minimum_master_nodes设置是至关重要的（默认为1），每个主节点应该知道形成一个集群的最小数量的主资格节点的数量。\n假设我们有一个集群。有3个主资格节点，当网络发生故障的时候，有可能其中一个节点不能和其他节点进行通信了。这个时候，当discovery.zen.minimum_master_nodes设置为1的时候，就会分成两个小的独立集群，当网络好的时候，就会出现数据错误或者丢失数据的情况。当discovery.zen.minimum_master_nodes设置为2的时候，一个网络中有两个主资格节点，可以继续工作，另一部分，由于只有一个主资格节点，则不会形成一个独立的集群，这个时候当网络回复的时候，节点又会从新加入集群。\n设置这个值的原则是：（master_eligible_nodes / 2）+ 1\ndiscovery.zen.ping.unicast.hosts Elasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。\n虽然组播仍然作为插件提供， 但它应该永远不被使用在生产环境了，否则你得到的结果就是一个节点意外的加入到了你的生产环境，仅仅是因为他们收到了一个错误的组播信号。 对于组播本身并没有错，组播会导致一些愚蠢的问题，并且导致集群变的脆弱（比如，一个网络工程师正在捣鼓网络，而没有告诉你，你会发现所有的节点突然发现不了对方了）。\n使用单播，你可以为 Elasticsearch 提供一些它应该去尝试连接的节点列表。 当一个节点联系到单播列表中的成员时，它就会得到整个集群所有节点的状态，然后它会联系 master 节点，并加入集群。\n这意味着你的单播列表不需要包含你的集群中的所有节点， 它只是需要足够的节点，当一个新节点联系上其中一个并且说上话就可以了。如果你使用 master 候选节点作为单播列表，你只要列出三个就可以了。 这个配置在 elasticsearch.yml 文件中：\ndiscovery.zen.ping.unicast.hosts: [\u0026quot;host1\u0026quot;, \u0026quot;host2:port\u0026quot;]\n注：端口非9200的节点， ip后需加端口号， 因 es 默认识别端口是9200\nData节点（数据节点） node.master: false node.data: true 数据节点主要是存储索引数据的节点，主要对文档进行增删改查操作，聚合操作等。数据节点对cpu，内存，io要求较高，在优化的时候需要监控数据节点的状态，当资源不够的时候，需要在集群中添加新的节点。\nClient节点 (客户端节点) node.master: false node.data: false 当主节点和数据节点配置都设置为false的时候，该节点只能处理路由请求，处理搜索，分发索引操作等，从本质上来说该客户节点表现为智能负载平衡器。独立的客户端节点在一个比较大的集群中是非常有用的，他协调主节点和数据节点，客户端节点加入集群可以得到集群的状态，根据集群的状态可以直接路由请求。 警告：添加太多的客户端节点对集群是一种负担，因为主节点必须等待每一个节点集群状态的更新确认！客户节点的作用不应被夸大，数据节点也可以起到类似的作用。\n安全 search-guard是elastcisearch的一款插件，提供加密，身份验证和授权，基于search guard SSL，另外提供可插入的身份验证/授权模块，search-guard是shield的替代品，可免费提供所有的基本安全功能。\n参考 阮一蜂的博客\n","permalink":"https://haokiu.com/blog/3XTrh1/","summary":"基本概念 Node 与 Cluster Elastic 本质上是一个分布式数据库，允许多台服务器协同工作，每台服务器可以运行多个 Elastic 实例。\n单个 Elastic 实例称为一个节点（node）。一组节点构成一个集群（cluster）。\nIndex Elastic 会索引所有字段，经过处理后写入一个反向索引（Inverted Index）。查找数据的时候，直接查找该索引。\n所以，Elastic 数据管理的顶层单位就叫做 Index（索引）。它是单个数据库的同义词。每个 Index （即数据库）的名字必须是小写。\nDocument Index 里面单条的记录称为 Document（文档）。许多条 Document 构成了一个 Index。Document 使用 JSON 格式表示。同一个 Index 里面的 Document，不要求有相同的结构（scheme），但是最好保持相同，这样有利于提高搜索效率。\nType Document 可以分组，比如weather这个 Index 里面，可以按城市分组（北京和上海），也可以按气候分组（晴天和雨天）。这种分组就叫做 Type，它是虚拟的逻辑分组，用来过滤 Document。\n不同的 Type 应该有相似的结构（schema），举例来说，id字段不能在这个组是字符串，在另一个组是数值。这是与关系型数据库的表的一个区别。性质完全不同的数据（比如products和logs）应该存成两个 Index，而不是一个 Index 里面的两个 Type（虽然可以做到）。\n在6.0之前的版本，一个ElasticSearch索引中，可以有多个类型；从6.0版本开始，，一个ElasticSearch索引中，只有1个类型。一个类型是索引的一个逻辑上的分类，通常具有一组相同字段的文档组成。ElasticSearch的类型概念相当于关系数据库的数据表。\nshard 当数据量较大时，索引的存储空间需求超出单个节点磁盘容量的限制，或者出现单个节点处理速度较慢。为了解决这些问题，ElasticSearch将索引中的数据进行切分成多个分片（shard），每个分片存储这个索引的一部分数据，分布在不同节点上。当需要查询索引时，ElasticSearch将查询发送到每个相关分片，之后将查询结果合并，这个过程对ElasticSearch应用来说是透明的，用户感知不到分片的存在。 一个索引的分片一旦指定，不再修改。\n副本 其实，分片全称是主分片，简称为分片。主分片是相对于副本来说的，副本是对主分片的一个或多个复制版本（或称拷贝），这些复制版本（拷贝）可以称为复制分片，可以直接称之为副本。当主分片丢失时，集群可以将一个副本升级为新的主分片。\n对比 ElasticSearch RDBMS 索引（index） 数据库（database） 类型（type） 表（table） 文档（document） 行（row） 字段（field） 列（column） 映射（mapping） 表结构（schema） 全文索引 索引 查询DSL SQL GET select PUT/POST update DELETE delete 节点信息 查看节点信息 curl localhost:9200 查看节点健康度 curl localhost:9200/_cat/health?v\u0026amp;pretty=true 查看集群状况 curl localhost:9200/_cat/nodes?v\u0026amp;pretty=true index(索引)操作 查看当前节点的所有 Index。 curl -X GET \u0026#39;http://localhost:9200/_cat/indices?v\u0026#39; 可以列出每个 Index 所包含的 Type curl \u0026#39;localhost:9200/_mapping?pretty=true\u0026#39; 新建一个名叫weather的 Index。 curl -X PUT \u0026#39;localhost:9200/weather\u0026#39; 删除这个 Index。 curl -X DELETE \u0026#39;localhost:9200/weather\u0026#39; 文档操作 获取 GET /website/blog/123?","title":"elasticsearch"},{"content":"搜索引擎是对数据的检索，所以我们先从生活中的数据说起。我们生活中的数据总体分为两种：\n结构化数据 非结构化数据 **结构化数据：**也称作行数据，是由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。指具有固定格式或有限长度的数据，如数据库，元数据等。\n**非结构化数据：**又可称为全文数据，不定长或无固定格式，不适于由数据库二维表来表现，包括所有格式的办公文档、XML、HTML、Word 文档，邮件，各类报表、图片和咅频、视频信息等。\n**说明：**如果要更细致的区分的话，XML、HTML 可划分为半结构化数据。因为它们也具有自己特定的标签格式，所以既可以根据需要按结构化数据来处理，也可抽取出纯文本按非结构化数据来处理。\n根据两种数据分类，搜索也相应的分为两种：\n结构化数据搜索 非结构化数据搜索 **对于结构化数据，**因为它们具有特定的结构，所以我们一般都是可以通过关系型数据库（MySQL，Oracle 等）的二维表（Table）的方式存储和搜索，也可以建立索引。\n对于非结构化数据，也即对全文数据的搜索主要有两种方法：\n顺序扫描 全文检索 **顺序扫描：**通过文字名称也可了解到它的大概搜索方式，即按照顺序扫描的方式查询特定的关键字。\n例如给你一张报纸，让你找到该报纸中“平安”的文字在哪些地方出现过。你肯定需要从头到尾把报纸阅读扫描一遍然后标记出关键字在哪些版块出现过以及它的出现位置。\n这种方式无疑是最耗时的最低效的，如果报纸排版字体小，而且版块较多甚至有多份报纸，等你扫描完你的眼睛也差不多了。\n**全文搜索：**对非结构化数据顺序扫描很慢，我们是否可以进行优化？把我们的非结构化数据想办法弄得有一定结构不就行了吗？\n将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。\n这种方式就构成了全文检索的基本思路。这部分从非结构化数据中提取出的然后重新组织的信息，我们称之为索引。\n这种方式的主要工作量在前期索引的创建，但是对于后期搜索却是快速高效的。\n先说说 Lucene\n通过对生活中数据的类型作了一个简短了解之后，我们知道关系型数据库的 SQL 检索是处理不了这种非结构化数据的。\n这种非结构化数据的处理需要依赖全文搜索，而目前市场上开放源代码的最好全文检索引擎工具包就属于 Apache 的 Lucene了。\n但是 Lucene 只是一个工具包，它不是一个完整的全文检索引擎。Lucene 的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。\n目前以 Lucene 为基础建立的开源可用全文搜索引擎主要是 Solr 和 Elasticsearch。\nSolr 和 Elasticsearch 都是比较成熟的全文搜索引擎，能完成的功能和性能也基本一样。\n但是 ES 本身就具有分布式的特性和易安装使用的特点，而 Solr 的分布式需要借助第三方来实现，例如通过使用 ZooKeeper 来达到分布式协调管理。\n不管是 Solr 还是 Elasticsearch 底层都是依赖于 Lucene，而 Lucene 能实现全文搜索主要是因为它实现了倒排索引的查询结构。\n如何理解倒排索引呢？假如现有三份数据文档，文档的内容如下分别是：\nJava is the best programming language. PHP is the best programming language. Javascript is the best programming language. 为了创建倒排索引，我们通过分词器将每个文档的内容域拆分成单独的词（我们称它为词条或 Term），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。\n结果如下所示：\nTerm Doc_1 Doc_2 Doc_3 ------------------------------------- Java | X | | is | X | X | X the | X | X | X best | X | X | X programming | x | X | X language | X | X | X PHP | | X | Javascript | | | X ------------------------------------- 这种结构由文档中所有不重复词的列表构成，对于其中每个词都有一个文档列表与之关联。\n这种由属性值来确定记录的位置的结构就是倒排索引。带有倒排索引的文件我们称为倒排文件。\n我们将上面的内容转换为图的形式来说明倒排索引的结构信息，如下图所示：\n其中主要有如下几个核心术语需要理解：\n**词条（Term）：**索引里面最小的存储和查询单元，对于英文来说是一个单词，对于中文来说一般指分词后的一个词。\n**词典（Term Dictionary）：**或字典，是词条 Term 的集合。搜索引擎的通常索引单位是单词，单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。\n**倒排表（Post list）：**一个文档通常由多个词组成，倒排表记录的是某个词在哪些文档里出现过以及出现的位置。\n每条记录称为一个倒排项（Posting）。倒排表记录的不单是文档编号，还存储了词频等信息。\n**倒排文件（Inverted File）：**所有单词的倒排列表往往顺序地存储在磁盘的某个文件里，这个文件被称之为倒排文件，倒排文件是存储倒排索引的物理文件。\n从上图我们可以了解到倒排索引主要由两个部分组成：\n词典 倒排文件 词典和倒排表是 Lucene 中很重要的两种数据结构，是实现快速检索的重要基石。词典和倒排文件是分两部分存储的，词典在内存中而倒排文件存储在磁盘上。\nES 核心概念\n一些基础知识的铺垫之后我们正式进入今天的主角 Elasticsearch 的介绍。\nES 是使用 Java 编写的一种开源搜索引擎，它在内部使用 Lucene 做索引与搜索，通过对 Lucene 的封装，隐藏了 Lucene 的复杂性，取而代之的提供一套简单一致的 RESTful API。\n然而，Elasticsearch 不仅仅是 Lucene，并且也不仅仅只是一个全文搜索引擎。\n它可以被下面这样准确的形容：\n一个分布式的实时文档存储，每个字段可以被索引与搜索。 一个分布式实时分析搜索引擎。 能胜任上百个服务节点的扩展，并支持 PB 级别的结构化或者非结构化数据。 官网对 Elasticsearch 的介绍是 Elasticsearch 是一个分布式、可扩展、近实时的搜索与数据分析引擎。\n我们通过一些核心概念来看下 Elasticsearch 是如何做到分布式，可扩展和近实时搜索的。\n集群（Cluster）\nES 的集群搭建很简单，不需要依赖第三方协调管理组件，自身内部就实现了集群的管理功能。\nES 集群由一个或多个 Elasticsearch 节点组成，每个节点配置相同的 cluster.name 即可加入集群，默认值为 “elasticsearch”。\n确保不同的环境中使用不同的集群名称，否则最终会导致节点加入错误的集群。\n一个 Elasticsearch 服务启动实例就是一个节点（Node）。节点通过 node.name 来设置节点名称，如果不设置则在启动时给节点分配一个随机通用唯一标识符作为名称。\n①发现机制 那么有一个问题，ES 内部是如何通过一个相同的设置 cluster.name 就能将不同的节点连接到同一个集群的？答案是 Zen Discovery。\nZen Discovery 是 Elasticsearch 的内置默认发现模块（发现模块的职责是发现集群中的节点以及选举 Master 节点）。\n它提供单播和基于文件的发现，并且可以扩展为通过插件支持云环境和其他形式的发现。\nZen Discovery 与其他模块集成，例如，节点之间的所有通信都使用 Transport 模块完成。节点使用发现机制通过 Ping 的方式查找其他节点。\nElasticsearch 默认被配置为使用单播发现，以防止节点无意中加入集群。只有在同一台机器上运行的节点才会自动组成集群。\n如果集群的节点运行在不同的机器上，使用单播，你可以为 Elasticsearch 提供一些它应该去尝试连接的节点列表。\n当一个节点联系到单播列表中的成员时，它就会得到整个集群所有节点的状态，然后它会联系 Master 节点，并加入集群。\n这意味着单播列表不需要包含集群中的所有节点， 它只是需要足够的节点，当一个新节点联系上其中一个并且说上话就可以了。\n如果你使用 Master 候选节点作为单播列表，你只要列出三个就可以了。这个配置在 elasticsearch.yml 文件中：\ndiscovery.zen.ping.unicast.hosts: [\u0026#34;host1\u0026#34;, \u0026#34;host2:port\u0026#34;] 节点启动后先 Ping ，如果 discovery.zen.ping.unicast.hosts 有设置，则 Ping 设置中的 Host ，否则尝试 ping localhost 的几个端口。\nElasticsearch 支持同一个主机启动多个节点，Ping 的 Response 会包含该节点的基本信息以及该节点认为的 Master 节点。\n选举开始，先从各节点认为的 Master 中选，规则很简单，按照 ID 的字典序排序，取第一个。如果各节点都没有认为的 Master ，则从所有节点中选择，规则同上。\n这里有个限制条件就是 discovery.zen.minimum_master_nodes ，如果节点数达不到最小值的限制，则循环上述过程，直到节点数足够可以开始选举。\n最后选举结果是肯定能选举出一个 Master ，如果只有一个 Local 节点那就选出的是自己。\n如果当前节点是 Master ，则开始等待节点数达到 discovery.zen.minimum_master_nodes，然后提供服务。\n如果当前节点不是 Master ，则尝试加入 Master 。Elasticsearch 将以上服务发现以及选主的流程叫做 Zen Discovery 。\n由于它支持任意数目的集群（ 1- N ），所以不能像 Zookeeper 那样限制节点必须是奇数，也就无法用投票的机制来选主，而是通过一个规则。\n只要所有的节点都遵循同样的规则，得到的信息都是对等的，选出来的主节点肯定是一致的。\n但分布式系统的问题就出在信息不对等的情况，这时候很容易出现脑裂（Split-Brain）的问题。\n大多数解决方案就是设置一个 Quorum 值，要求可用节点必须大于 Quorum（一般是超过半数节点），才能对外提供服务。\n而 Elasticsearch 中，这个 Quorum 的配置就是 discovery.zen.minimum_master_nodes 。\n②节点的角色 每个节点既可以是候选主节点也可以是数据节点，通过在配置文件 ../config/elasticsearch.yml 中设置即可，默认都为 true。\nnode.master: true //是否候选主节点 node.data: true //是否数据节点 数据节点负责数据的存储和相关的操作，例如对数据进行增、删、改、查和聚合等操作，所以数据节点（Data 节点）对机器配置要求比较高，对 CPU、内存和 I/O 的消耗很大。\n通常随着集群的扩大，需要增加更多的数据节点来提高性能和可用性。\n候选主节点可以被选举为主节点（Master 节点），集群中只有候选主节点才有选举权和被选举权，其他节点不参与选举的工作。\n主节点负责创建索引、删除索引、跟踪哪些节点是群集的一部分，并决定哪些分片分配给相关的节点、追踪集群中节点的状态等，稳定的主节点对集群的健康是非常重要的。\n一个节点既可以是候选主节点也可以是数据节点，但是由于数据节点对 CPU、内存核 I/O 消耗都很大。\n所以如果某个节点既是数据节点又是主节点，那么可能会对主节点产生影响从而对整个集群的状态产生影响。\n因此为了提高集群的健康性，我们应该对 Elasticsearch 集群中的节点做好角色上的划分和隔离。可以使用几个配置较低的机器群作为候选主节点群。\n主节点和其他节点之间通过 Ping 的方式互检查，主节点负责 Ping 所有其他节点，判断是否有节点已经挂掉。其他节点也通过 Ping 的方式判断主节点是否处于可用状态。\n虽然对节点做了角色区分，但是用户的请求可以发往任何一个节点，并由该节点负责分发请求、收集结果等操作，而不需要主节点转发。\n这种节点可称之为协调节点，协调节点是不需要指定和配置的，集群中的任何节点都可以充当协调节点的角色。\n③脑裂现象 同时如果由于网络或其他原因导致集群中选举出多个 Master 节点，使得数据更新时出现不一致，这种现象称之为脑裂，即集群中不同的节点对于 Master 的选择出现了分歧，出现了多个 Master 竞争。\n“脑裂”问题可能有以下几个原因造成：\n**网络问题：**集群间的网络延迟导致一些节点访问不到 Master，认为 Master 挂掉了从而选举出新的 Master，并对 Master 上的分片和副本标红，分配新的主分片。 **节点负载：**主节点的角色既为 Master 又为 Data，访问量较大时可能会导致 ES 停止响应（假死状态）造成大面积延迟，此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点。 **内存回收：**主节点的角色既为 Master 又为 Data，当 Data 节点上的 ES 进程占用的内存较大，引发 JVM 的大规模内存回收，造成 ES 进程失去响应。 为了避免脑裂现象的发生，我们可以从原因着手通过以下几个方面来做出优化措施：\n**适当调大响应时间，减少误判。**通过参数 discovery.zen.ping_timeout 设置节点状态的响应时间，默认为 3s，可以适当调大。\n如果 Master 在该响应时间的范围内没有做出响应应答，判断该节点已经挂掉了。调大参数（如 6s，discovery.zen.ping_timeout:6），可适当减少误判。\n**选举触发。**我们需要在候选集群中的节点的配置文件中设置参数 discovery.zen.munimum_master_nodes 的值。\n这个参数表示在选举主节点时需要参与选举的候选主节点的节点数，默认值是 1，官方建议取值(master_eligibel_nodes/2)+1，其中 master_eligibel_nodes 为候选主节点的个数。\n这样做既能防止脑裂现象的发生，也能最大限度地提升集群的高可用性，因为只要不少于 discovery.zen.munimum_master_nodes 个候选节点存活，选举工作就能正常进行。\n当小于这个值的时候，无法触发选举行为，集群无法使用，不会造成分片混乱的情况。\n**角色分离。**即是上面我们提到的候选主节点和数据节点进行角色分离，这样可以减轻主节点的负担，防止主节点的假死状态发生，减少对主节点“已死”的误判。\n分片（Shards）\nES 支持 PB 级全文搜索，当索引上的数据量太大的时候，ES 通过水平拆分的方式将一个索引上的数据拆分出来分配到不同的数据块上，拆分出来的数据库块称之为一个分片。\n这类似于 MySQL 的分库分表，只不过 MySQL 分库分表需要借助第三方组件而 ES 内部自身实现了此功能。\n在一个多分片的索引中写入数据时，通过路由来确定具体写入哪一个分片中，所以在创建索引的时候需要指定分片的数量，并且分片的数量一旦确定就不能修改。\n分片的数量和下面介绍的副本数量都是可以通过创建索引时的 Settings 来配置，ES 默认为一个索引创建 5 个主分片, 并分别为每个分片创建一个副本。\nPUT /myIndex { \u0026#34;settings\u0026#34; : { \u0026#34;number_of_shards\u0026#34; : 5, \u0026#34;number_of_replicas\u0026#34; : 1 } } ES 通过分片的功能使得索引在规模上和性能上都得到提升，每个分片都是 Lucene 中的一个索引文件，每个分片必须有一个主分片和零到多个副本。\n副本（Replicas）\n副本就是对分片的 Copy，每个主分片都有一个或多个副本分片，当主分片异常时，副本可以提供数据的查询等操作。\n主分片和对应的副本分片是不会在同一个节点上的，所以副本分片数的最大值是 N-1（其中 N 为节点数）。\n对文档的新建、索引和删除请求都是写操作，必须在主分片上面完成之后才能被复制到相关的副本分片。\nES 为了提高写入的能力这个过程是并发写的，同时为了解决并发写的过程中数据冲突的问题，ES 通过乐观锁的方式控制，每个文档都有一个 _version （版本）号，当文档被修改时版本号递增。\n一旦所有的副本分片都报告写成功才会向协调节点报告成功，协调节点向客户端报告成功。\n从上图可以看出为了达到高可用，Master 节点会避免将主分片和副本分片放在同一个节点上。\n假设这时节点 Node1 服务宕机了或者网络不可用了，那么主节点上主分片 S0 也就不可用了。\n幸运的是还存在另外两个节点能正常工作，这时 ES 会重新选举新的主节点，而且这两个节点上存在我们所需要的 S0 的所有数据。\n我们会将 S0 的副本分片提升为主分片，这个提升主分片的过程是瞬间发生的。此时集群的状态将会为 Yellow。\n为什么我们集群状态是 Yellow 而不是 Green 呢？虽然我们拥有所有的 2 个主分片，但是同时设置了每个主分片需要对应两份副本分片，而此时只存在一份副本分片。所以集群不能为 Green 的状态。\n如果我们同样关闭了 Node2 ，我们的程序依然可以保持在不丢失任何数据的情况下运行，因为 Node3 为每一个分片都保留着一份副本。\n如果我们重新启动 Node1 ，集群可以将缺失的副本分片再次进行分配，那么集群的状态又将恢复到原来的正常状态。\n如果 Node1 依然拥有着之前的分片，它将尝试去重用它们，只不过这时 Node1 节点上的分片不再是主分片而是副本分片了，如果期间有更改的数据只需要从主分片上复制修改的数据文件即可。\n小结：\n将数据分片是为了提高可处理数据的容量和易于进行水平扩展，为分片做副本是为了提高集群的稳定性和提高并发量。\n副本是乘法，越多消耗越大，但也越保险。分片是除法，分片越多，单分片数据就越少也越分散。\n副本越多，集群的可用性就越高，但是由于每个分片都相当于一个 Lucene 的索引文件，会占用一定的文件句柄、内存及 CPU。\n并且分片间的数据同步也会占用一定的网络带宽，所以索引的分片数和副本数也不是越多越好。\n映射（Mapping）\n映射是用于定义 ES 对索引中字段的存储类型、分词方式和是否存储等信息，就像数据库中的 Schema ，描述了文档可能具有的字段或属性、每个字段的数据类型。\n只不过关系型数据库建表时必须指定字段类型，而 ES 对于字段类型可以不指定然后动态对字段类型猜测，也可以在创建索引时具体指定字段的类型。\n对字段类型根据数据格式自动识别的映射称之为动态映射（Dynamic Mapping），我们创建索引时具体定义字段类型的映射称之为静态映射或显示映射（Explicit Mapping）。\n在讲解动态映射和静态映射的使用前，我们先来了解下 ES 中的数据有哪些字段类型？之后我们再讲解为什么我们创建索引时需要建立静态映射而不使用动态映射。\nES（v6.8）中字段数据类型主要有以下几类：\nText 用于索引全文值的字段，例如电子邮件正文或产品说明。这些字段是被分词的，它们通过分词器传递 ，以在被索引之前将字符串转换为单个术语的列表。\n分析过程允许 Elasticsearch 搜索单个单词中每个完整的文本字段。文本字段不用于排序，很少用于聚合。\nKeyword 用于索引结构化内容的字段，例如电子邮件地址，主机名，状态代码，邮政编码或标签。它们通常用于过滤，排序，和聚合。Keyword 字段只能按其确切值进行搜索。\n通过对字段类型的了解我们知道有些字段需要明确定义的，例如某个字段是 Text 类型还是 Keyword 类型差别是很大的，时间字段也许我们需要指定它的时间格式，还有一些字段我们需要指定特定的分词器等等。\n如果采用动态映射是不能精确做到这些的，自动识别常常会与我们期望的有些差异。\n所以创建索引的时候一个完整的格式应该是指定分片和副本数以及 Mapping 的定义，如下：\nPUT my_index { \u0026#34;settings\u0026#34; : { \u0026#34;number_of_shards\u0026#34; : 5, \u0026#34;number_of_replicas\u0026#34; : 1 } \u0026#34;mappings\u0026#34;: { \u0026#34;_doc\u0026#34;: { \u0026#34;properties\u0026#34;: { \u0026#34;title\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;name\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;text\u0026#34; }, \u0026#34;age\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34; }, \u0026#34;created\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;date\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;strict_date_optional_time||epoch_millis\u0026#34; } } } } } ES 的基本使用\n在决定使用 Elasticsearch 的时候首先要考虑的是版本问题，Elasticsearch （排除 0.x 和 1.x）目前有如下常用的稳定的主版本：2.x，5.x，6.x，7.x（current）。\n你可能会发现没有 3.x 和 4.x，ES 从 2.4.6 直接跳到了 5.0.0。其实是为了 ELK（ElasticSearch，Logstash，Kibana）技术栈的版本统一，免的给用户带来混乱。\n在 Elasticsearch 是 2.x （2.x 的最后一版 2.4.6 的发布时间是 July 25, 2017） 的情况下，Kibana 已经是 4.x（Kibana 4.6.5 的发布时间是 July 25, 2017）。\n那么在 Kibana 的下一主版本肯定是 5.x 了，所以 Elasticsearch 直接将自己的主版本发布为 5.0.0 了。\n统一之后，我们选版本就不会犹豫困惑了，我们选定 Elasticsearch 的版本后再选择相同版本的 Kibana 就行了，不用担忧版本不兼容的问题。\nElasticsearch 是使用 Java 构建，所以除了注意 ELK 技术的版本统一，我们在选择 Elasticsearch 的版本的时候还需要注意 JDK 的版本。\n因为每个大版本所依赖的 JDK 版本也不同，目前 7.2 版本已经可以支持 JDK11。\n安装使用\n①下载和解压 Elasticsearch，无需安装解压后即可用，解压后目录如上图：\n**bin：**二进制系统指令目录，包含启动命令和安装插件命令等。 **config：**配置文件目录。 **data：**数据存储目录。 **lib：**依赖包目录。 **logs：**日志文件目录。 **modules：**模块库，例如 x-pack 的模块。 **plugins：**插件目录。 ②安装目录下运行 bin/elasticsearch 来启动 ES。\n③默认在 9200 端口运行，请求 curl http://localhost:9200/ 或者浏览器输入 http://localhost:9200，得到一个 JSON 对象，其中包含当前节点、集群、版本等信息。\n{ \u0026#34;name\u0026#34; : \u0026#34;U7fp3O9\u0026#34;, \u0026#34;cluster_name\u0026#34; : \u0026#34;elasticsearch\u0026#34;, \u0026#34;cluster_uuid\u0026#34; : \u0026#34;-Rj8jGQvRIelGd9ckicUOA\u0026#34;, \u0026#34;version\u0026#34; : { \u0026#34;number\u0026#34; : \u0026#34;6.8.1\u0026#34;, \u0026#34;build_flavor\u0026#34; : \u0026#34;default\u0026#34;, \u0026#34;build_type\u0026#34; : \u0026#34;zip\u0026#34;, \u0026#34;build_hash\u0026#34; : \u0026#34;1fad4e1\u0026#34;, \u0026#34;build_date\u0026#34; : \u0026#34;2019-06-18T13:16:52.517138Z\u0026#34;, \u0026#34;build_snapshot\u0026#34; : false, \u0026#34;lucene_version\u0026#34; : \u0026#34;7.7.0\u0026#34;, \u0026#34;minimum_wire_compatibility_version\u0026#34; : \u0026#34;5.6.0\u0026#34;, \u0026#34;minimum_index_compatibility_version\u0026#34; : \u0026#34;5.0.0\u0026#34; }, \u0026#34;tagline\u0026#34; : \u0026#34;You Know, for Search\u0026#34; } 集群健康状态\n要检查群集运行状况，我们可以在 Kibana 控制台中运行以下命令 GET /_cluster/health，得到如下信息：\n{ \u0026#34;cluster_name\u0026#34; : \u0026#34;wujiajian\u0026#34;, \u0026#34;status\u0026#34; : \u0026#34;yellow\u0026#34;, \u0026#34;timed_out\u0026#34; : false, \u0026#34;number_of_nodes\u0026#34; : 1, \u0026#34;number_of_data_nodes\u0026#34; : 1, \u0026#34;active_primary_shards\u0026#34; : 9, \u0026#34;active_shards\u0026#34; : 9, \u0026#34;relocating_shards\u0026#34; : 0, \u0026#34;initializing_shards\u0026#34; : 0, \u0026#34;unassigned_shards\u0026#34; : 5, \u0026#34;delayed_unassigned_shards\u0026#34; : 0, \u0026#34;number_of_pending_tasks\u0026#34; : 0, \u0026#34;number_of_in_flight_fetch\u0026#34; : 0, \u0026#34;task_max_waiting_in_queue_millis\u0026#34; : 0, \u0026#34;active_shards_percent_as_number\u0026#34; : 64.28571428571429 } 集群状态通过 绿，黄，红 来标识：\n**绿色：**集群健康完好，一切功能齐全正常，所有分片和副本都可以正常工作。 **黄色：**预警状态，所有主分片功能正常，但至少有一个副本是不能正常工作的。此时集群是可以正常工作的，但是高可用性在某种程度上会受影响。 **红色：**集群不可正常使用。某个或某些分片及其副本异常不可用，这时集群的查询操作还能执行，但是返回的结果会不准确。对于分配到这个分片的写入请求将会报错，最终会导致数据的丢失。 当集群状态为红色时，它将会继续从可用的分片提供搜索请求服务，但是你需要尽快修复那些未分配的分片。\nES 机制原理\nES 的基本概念和基本操作介绍完了之后，我们可能还有很多疑惑：\n它们内部是如何运行的？ 主分片和副本分片是如何同步的？ 创建索引的流程是什么样的？ ES 如何将索引数据分配到不同的分片上的？以及这些索引数据是如何存储的？ 为什么说 ES 是近实时搜索引擎而文档的 CRUD (创建-读取-更新-删除) 操作是实时的？ 以及 Elasticsearch 是怎样保证更新被持久化在断电时也不丢失数据？ 还有为什么删除文档不会立刻释放空间？ 带着这些疑问我们进入接下来的内容。\n写索引原理\n下图描述了 3 个节点的集群，共拥有 12 个分片，其中有 4 个主分片（S0、S1、S2、S3）和 8 个副本分片（R0、R1、R2、R3），每个主分片对应两个副本分片，节点 1 是主节点（Master 节点）负责整个集群的状态。\n写索引是只能写在主分片上，然后同步到副本分片。这里有四个主分片，一条数据 ES 是根据什么规则写到特定分片上的呢？\n这条索引数据为什么被写到 S0 上而不写到 S1 或 S2 上？那条数据为什么又被写到 S3 上而不写到 S0 上了？\n首先这肯定不会是随机的，否则将来要获取文档的时候我们就不知道从何处寻找了。\n实际上，这个过程是根据下面这个公式决定的：\nshard = hash(routing) % number_of_primary_shards Routing 是一个可变值，默认是文档的 _id ，也可以设置成一个自定义的值。\nRouting 通过 Hash 函数生成一个数字，然后这个数字再除以 number_of_primary_shards （主分片的数量）后得到余数。\n这个在 0 到 number_of_primary_shards-1 之间的余数，就是我们所寻求的文档所在分片的位置。\n这就解释了为什么我们要在创建索引的时候就确定好主分片的数量并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。\n由于在 ES 集群中每个节点通过上面的计算公式都知道集群中的文档的存放位置，所以每个节点都有处理读写请求的能力。\n在一个写请求被发送到某个节点后，该节点即为前面说过的协调节点，协调节点会根据路由公式计算出需要写到哪个分片上，再将请求转发到该分片的主分片节点上。\n假如此时数据通过路由计算公式取余后得到的值是 shard=hash(routing)%4=0。\n则具体流程如下：\n客户端向 ES1 节点（协调节点）发送写请求，通过路由计算公式得到值为 0，则当前数据应被写到主分片 S0 上。 ES1 节点将请求转发到 S0 主分片所在的节点 ES3，ES3 接受请求并写入到磁盘。 并发将数据复制到两个副本分片 R0 上，其中通过乐观并发控制数据的冲突。一旦所有的副本分片都报告成功，则节点 ES3 将向协调节点报告成功，协调节点向客户端报告成功。 存储原理\n上面介绍了在 ES 内部索引的写处理流程，这个流程是在 ES 的内存中执行的，数据被分配到特定的分片和副本上之后，最终是存储到磁盘上的，这样在断电的时候就不会丢失数据。\n具体的存储路径可在配置文件 ../config/elasticsearch.yml 中进行设置，默认存储在安装目录的 Data 文件夹下。\n建议不要使用默认值，因为若 ES 进行了升级，则有可能导致数据全部丢失：\npath.data: /path/to/data //索引数据 path.logs: /path/to/logs //日志记录 ①分段存储 索引文档以段的形式存储在磁盘上，何为段？索引文件被拆分为多个子文件，则每个子文件叫作段，每一个段本身都是一个倒排索引，并且段具有不变性，一旦索引的数据被写入硬盘，就不可再修改。\n在底层采用了分段的存储模式，使它在读写时几乎完全避免了锁的出现，大大提升了读写性能。\n段被写入到磁盘后会生成一个提交点，提交点是一个用来记录所有提交后段信息的文件。\n一个段一旦拥有了提交点，就说明这个段只有读的权限，失去了写的权限。相反，当段在内存中时，就只有写的权限，而不具备读数据的权限，意味着不能被检索。\n段的概念提出主要是因为：在早期全文检索中为整个文档集合建立了一个很大的倒排索引，并将其写入磁盘中。\n如果索引有更新，就需要重新全量创建一个索引来替换原来的索引。这种方式在数据量很大时效率很低，并且由于创建一次索引的成本很高，所以对数据的更新不能过于频繁，也就不能保证时效性。\n索引文件分段存储并且不可修改，那么新增、更新和删除如何处理呢？\n**新增，**新增很好处理，由于数据是新的，所以只需要对当前文档新增一个段就可以了。\n**删除，**由于不可修改，所以对于删除操作，不会把文档从旧的段中移除而是通过新增一个 .del 文件，文件中会列出这些被删除文档的段信息。\n这个被标记删除的文档仍然可以被查询匹配到， 但它会在最终结果被返回前从结果集中移除。\n**更新，**不能修改旧的段来进行反映文档的更新，其实更新相当于是删除和新增这两个动作组成。会将旧的文档在 .del 文件中标记删除，然后文档的新版本被索引到一个新的段中。\n可能两个版本的文档都会被一个查询匹配到，但被删除的那个旧版本文档在结果集返回前就会被移除。\n段被设定为不可修改具有一定的优势也有一定的缺点，优势主要表现在：\n不需要锁。如果你从来不更新索引，你就不需要担心多进程同时修改数据的问题。 一旦索引被读入内核的文件系统缓存，便会留在哪里，由于其不变性。只要文件系统缓存中还有足够的空间，那么大部分读请求会直接请求内存，而不会命中磁盘。这提供了很大的性能提升。 其它缓存(像 Filter 缓存)，在索引的生命周期内始终有效。它们不需要在每次数据改变时被重建，因为数据不会变化。 写入单个大的倒排索引允许数据被压缩，减少磁盘 I/O 和需要被缓存到内存的索引的使用量。 段的不变性的缺点如下：\n当对旧数据进行删除时，旧数据不会马上被删除，而是在 .del 文件中被标记为删除。而旧数据只能等到段更新时才能被移除，这样会造成大量的空间浪费。 若有一条数据频繁的更新，每次更新都是新增新的标记旧的，则会有大量的空间浪费。 每次新增数据时都需要新增一个段来存储数据。当段的数量太多时，对服务器的资源例如文件句柄的消耗会非常大。 在查询的结果中包含所有的结果集，需要排除被标记删除的旧数据，这增加了查询的负担。 ②延迟写策略 介绍完了存储的形式，那么索引写入到磁盘的过程是怎样的？是否是直接调 Fsync 物理性地写入磁盘？\n答案是显而易见的，如果是直接写入到磁盘上，磁盘的 I/O 消耗上会严重影响性能。\n那么当写数据量大的时候会造成 ES 停顿卡死，查询也无法做到快速响应。如果真是这样 ES 也就不会称之为近实时全文搜索引擎了。\n为了提升写的性能，ES 并没有每新增一条数据就增加一个段到磁盘上，而是采用延迟写的策略。\n每当有新增的数据时，就将其先写入到内存中，在内存和磁盘之间是文件系统缓存。\n当达到默认的时间（1 秒钟）或者内存的数据达到一定量时，会触发一次刷新（Refresh），将内存中的数据生成到一个新的段上并缓存到文件缓存系统 上，稍后再被刷新到磁盘中并生成提交点。\n这里的内存使用的是 ES 的 JVM 内存，而文件缓存系统使用的是操作系统的内存。\n新的数据会继续的被写入内存，但内存中的数据并不是以段的形式存储的，因此不能提供检索功能。\n由内存刷新到文件缓存系统的时候会生成新的段，并将段打开以供搜索使用，而不需要等到被刷新到磁盘。\n在 Elasticsearch 中，写入和打开一个新段的轻量的过程叫做 Refresh （即内存刷新到文件缓存系统）。\n默认情况下每个分片会每秒自动刷新一次。这就是为什么我们说 Elasticsearch 是近实时搜索，因为文档的变化并不是立即对搜索可见，但会在一秒之内变为可见。\n我们也可以手动触发 Refresh，POST /_refresh 刷新所有索引，POST /nba/_refresh 刷新指定的索引。\n**Tips：**尽管刷新是比提交轻量很多的操作，它还是会有性能开销。当写测试的时候， 手动刷新很有用，但是不要在生产\u0026gt;环境下每次索引一个文档都去手动刷新。而且并不是所有的情况都需要每秒刷新。\n可能你正在使用 Elasticsearch 索引大量的日志文件， 你可能想优化索引速度而不是\u0026gt;近实时搜索。\n这时可以在创建索引时在 Settings 中通过调大 refresh_interval = \u0026ldquo;30s\u0026rdquo; 的值 ， 降低每个索引的刷新频率，设值时需要注意后面带上时间单位，否则默认是毫秒。当 refresh_interval=-1 时表示关闭索引的自动刷新。\n虽然通过延时写的策略可以减少数据往磁盘上写的次数提升了整体的写入能力，但是我们知道文件缓存系统也是内存空间，属于操作系统的内存，只要是内存都存在断电或异常情况下丢失数据的危险。\n为了避免丢失数据，Elasticsearch 添加了事务日志（Translog），事务日志记录了所有还没有持久化到磁盘的数据。\n添加了事务日志后整个写索引的流程如上图所示：\n一个新文档被索引之后，先被写入到内存中，但是为了防止数据的丢失，会追加一份数据到事务日志中。\n不断有新的文档被写入到内存，同时也都会记录到事务日志中。这时新数据还不能被检索和查询。\n当达到默认的刷新时间或内存中的数据达到一定量后，会触发一次 Refresh，将内存中的数据以一个新段形式刷新到文件缓存系统中并清空内存。这时虽然新段未被提交到磁盘，但是可以提供文档的检索功能且不能被修改。\n随着新文档索引不断被写入，当日志数据大小超过 512M 或者时间超过 30 分钟时，会触发一次 Flush。\n内存中的数据被写入到一个新段同时被写入到文件缓存系统，文件系统缓存中数据通过 Fsync 刷新到磁盘中，生成提交点，日志文件被删除，创建一个空的新日志。\n通过这种方式当断电或需要重启时，ES 不仅要根据提交点去加载已经持久化过的段，还需要工具 Translog 里的记录，把未持久化的数据重新持久化到磁盘上，避免了数据丢失的可能。\n③段合并 由于自动刷新流程每秒会创建一个新的段 ，这样会导致短时间内的段数量暴增。而段数目太多会带来较大的麻烦。\n每一个段都会消耗文件句柄、内存和 CPU 运行周期。更重要的是，每个搜索请求都必须轮流检查每个段然后合并查询结果，所以段越多，搜索也就越慢。\nElasticsearch 通过在后台定期进行段合并来解决这个问题。小的段被合并到大的段，然后这些大的段再被合并到更大的段。\n段合并的时候会将那些旧的已删除文档从文件系统中清除。被删除的文档不会被拷贝到新的大段中。合并的过程中不会中断索引和搜索。\n段合并在进行索引和搜索时会自动进行，合并进程选择一小部分大小相似的段，并且在后台将它们合并到更大的段中，这些段既可以是未提交的也可以是已提交的。\n合并结束后老的段会被删除，新的段被 Flush 到磁盘，同时写入一个包含新段且排除旧的和较小的段的新提交点，新的段被打开可以用来搜索。\n段合并的计算量庞大， 而且还要吃掉大量磁盘 I/O，段合并会拖累写入速率，如果任其发展会影响搜索性能。\nElasticsearch 在默认情况下会对合并流程进行资源限制，所以搜索仍然有足够的资源很好地执行。\n性能优化\n存储设备\n磁盘在现代服务器上通常都是瓶颈。Elasticsearch 重度使用磁盘，你的磁盘能处理的吞吐量越大，你的节点就越稳定。\n这里有一些优化磁盘 I/O 的技巧：\n**使用 SSD。**就像其他地方提过的， 他们比机械磁盘优秀多了。 **使用 RAID 0。**条带化 RAID 会提高磁盘 I/O，代价显然就是当一块硬盘故障时整个就故障了。不要使用镜像或者奇偶校验 RAID 因为副本已经提供了这个功能。 **另外，使用多块硬盘，**并允许 Elasticsearch 通过多个 path.data 目录配置把数据条带化分配到它们上面。 **不要使用远程挂载的存储，**比如 NFS 或者 SMB/CIFS。这个引入的延迟对性能来说完全是背道而驰的。 **如果你用的是 EC2，当心 EBS。**即便是基于 SSD 的 EBS，通常也比本地实例的存储要慢。 内部索引优化\nElasticsearch 为了能快速找到某个 Term，先将所有的 Term 排个序，然后根据二分法查找 Term，时间复杂度为 logN，就像通过字典查找一样，这就是 Term Dictionary。\n现在再看起来，似乎和传统数据库通过 B-Tree 的方式类似。但是如果 Term 太多，Term Dictionary 也会很大，放内存不现实，于是有了 Term Index。\n就像字典里的索引页一样，A 开头的有哪些 Term，分别在哪页，可以理解 Term Index是一棵树。\n这棵树不会包含所有的 Term，它包含的是 Term 的一些前缀。通过 Term Index 可以快速地定位到 Term Dictionary 的某个 Offset，然后从这个位置再往后顺序查找。\n在内存中用 FST 方式压缩 Term Index，FST 以字节的方式存储所有的 Term，这种压缩方式可以有效的缩减存储空间，使得 Term Index 足以放进内存，但这种方式也会导致查找时需要更多的 CPU 资源。\n对于存储在磁盘上的倒排表同样也采用了压缩技术减少存储所占用的空间。\n调整配置参数\n调整配置参数建议如下：\n给每个文档指定有序的具有压缩良好的序列模式 ID，避免随机的 UUID-4 这样的 ID，这样的 ID 压缩比很低，会明显拖慢 Lucene。\n对于那些不需要聚合和排序的索引字段禁用 Doc values。Doc Values 是有序的基于 document=\u0026gt;field value 的映射列表。\n不需要做模糊检索的字段使用 Keyword 类型代替 Text 类型，这样可以避免在建立索引前对这些文本进行分词。\n如果你的搜索结果不需要近实时的准确度，考虑把每个索引的 index.refresh_interval 改到 30s 。\n如果你是在做大批量导入，导入期间你可以通过设置这个值为 -1 关掉刷新，还可以通过设置 index.number_of_replicas: 0 关闭副本。别忘记在完工的时候重新开启它。\n避免深度分页查询建议使用 Scroll 进行分页查询。普通分页查询时，会创建一个 from+size 的空优先队列，每个分片会返回 from+size 条数据，默认只包含文档 ID 和得分 Score 给协调节点。\n如果有 N 个分片，则协调节点再对（from+size）×n 条数据进行二次排序，然后选择需要被取回的文档。当 from 很大时，排序过程会变得很沉重，占用 CPU 资源严重。\n减少映射字段，只提供需要检索，聚合或排序的字段。其他字段可存在其他存储设备上，例如 Hbase，在 ES 中得到结果后再去 Hbase 查询这些字段。\n创建索引和查询时指定路由 Routing 值，这样可以精确到具体的分片查询，提升查询效率。路由的选择需要注意数据的分布均衡。\nJVM 调优\nJVM 调优建议如下：\n确保堆内存最小值（ Xms ）与最大值（ Xmx ）的大小是相同的，防止程序在运行时改变堆内存大小。\nElasticsearch 默认安装后设置的堆内存是 1GB。可通过 ../config/jvm.option 文件进行配置，但是最好不要超过物理内存的50%和超过 32GB。\nGC 默认采用 CMS 的方式，并发但是有 STW 的问题，可以考虑使用 G1 收集器。\nES 非常依赖文件系统缓存（Filesystem Cache），快速搜索。一般来说，应该至少确保物理上有一半的可用内存分配到文件系统缓存。\n","permalink":"https://haokiu.com/blog/oaXyUa/","summary":"搜索引擎是对数据的检索，所以我们先从生活中的数据说起。我们生活中的数据总体分为两种：\n结构化数据 非结构化数据 **结构化数据：**也称作行数据，是由二维表结构来逻辑表达和实现的数据，严格地遵循数据格式与长度规范，主要通过关系型数据库进行存储和管理。指具有固定格式或有限长度的数据，如数据库，元数据等。\n**非结构化数据：**又可称为全文数据，不定长或无固定格式，不适于由数据库二维表来表现，包括所有格式的办公文档、XML、HTML、Word 文档，邮件，各类报表、图片和咅频、视频信息等。\n**说明：**如果要更细致的区分的话，XML、HTML 可划分为半结构化数据。因为它们也具有自己特定的标签格式，所以既可以根据需要按结构化数据来处理，也可抽取出纯文本按非结构化数据来处理。\n根据两种数据分类，搜索也相应的分为两种：\n结构化数据搜索 非结构化数据搜索 **对于结构化数据，**因为它们具有特定的结构，所以我们一般都是可以通过关系型数据库（MySQL，Oracle 等）的二维表（Table）的方式存储和搜索，也可以建立索引。\n对于非结构化数据，也即对全文数据的搜索主要有两种方法：\n顺序扫描 全文检索 **顺序扫描：**通过文字名称也可了解到它的大概搜索方式，即按照顺序扫描的方式查询特定的关键字。\n例如给你一张报纸，让你找到该报纸中“平安”的文字在哪些地方出现过。你肯定需要从头到尾把报纸阅读扫描一遍然后标记出关键字在哪些版块出现过以及它的出现位置。\n这种方式无疑是最耗时的最低效的，如果报纸排版字体小，而且版块较多甚至有多份报纸，等你扫描完你的眼睛也差不多了。\n**全文搜索：**对非结构化数据顺序扫描很慢，我们是否可以进行优化？把我们的非结构化数据想办法弄得有一定结构不就行了吗？\n将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。\n这种方式就构成了全文检索的基本思路。这部分从非结构化数据中提取出的然后重新组织的信息，我们称之为索引。\n这种方式的主要工作量在前期索引的创建，但是对于后期搜索却是快速高效的。\n先说说 Lucene\n通过对生活中数据的类型作了一个简短了解之后，我们知道关系型数据库的 SQL 检索是处理不了这种非结构化数据的。\n这种非结构化数据的处理需要依赖全文搜索，而目前市场上开放源代码的最好全文检索引擎工具包就属于 Apache 的 Lucene了。\n但是 Lucene 只是一个工具包，它不是一个完整的全文检索引擎。Lucene 的目的是为软件开发人员提供一个简单易用的工具包，以方便的在目标系统中实现全文检索的功能，或者是以此为基础建立起完整的全文检索引擎。\n目前以 Lucene 为基础建立的开源可用全文搜索引擎主要是 Solr 和 Elasticsearch。\nSolr 和 Elasticsearch 都是比较成熟的全文搜索引擎，能完成的功能和性能也基本一样。\n但是 ES 本身就具有分布式的特性和易安装使用的特点，而 Solr 的分布式需要借助第三方来实现，例如通过使用 ZooKeeper 来达到分布式协调管理。\n不管是 Solr 还是 Elasticsearch 底层都是依赖于 Lucene，而 Lucene 能实现全文搜索主要是因为它实现了倒排索引的查询结构。\n如何理解倒排索引呢？假如现有三份数据文档，文档的内容如下分别是：\nJava is the best programming language. PHP is the best programming language. Javascript is the best programming language. 为了创建倒排索引，我们通过分词器将每个文档的内容域拆分成单独的词（我们称它为词条或 Term），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。\n结果如下所示：\nTerm Doc_1 Doc_2 Doc_3 ------------------------------------- Java | X | | is | X | X | X the | X | X | X best | X | X | X programming | x | X | X language | X | X | X PHP | | X | Javascript | | | X ------------------------------------- 这种结构由文档中所有不重复词的列表构成，对于其中每个词都有一个文档列表与之关联。","title":"搜索引擎 及 elastic search "},{"content":" HTTPS 的整个通信过程可以分为两大阶段：证书验证和数据传输阶段，数据传输阶段又可以分为非对称加密和对称加密两个阶段。具体流程按图中的序号讲解。\n客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。\n采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书，证书是需要申请的，并由专门的数字证书认证机构(CA)通过非常严格的审核之后颁发的电子证书 (当然了是要钱的，安全级别越高价格越贵)。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。\n服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。Chrome 浏览器点击地址栏的锁标志再点击证书就可以看到证书详细信息。\n客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。\n客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。\n服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。\n服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。\n双方使用对称加密愉快地传输所有数据。\n","permalink":"https://haokiu.com/blog/3TSsuC/","summary":"HTTPS 的整个通信过程可以分为两大阶段：证书验证和数据传输阶段，数据传输阶段又可以分为非对称加密和对称加密两个阶段。具体流程按图中的序号讲解。\n客户端请求 HTTPS 网址，然后连接到 server 的 443 端口 (HTTPS 默认端口，类似于 HTTP 的80端口)。\n采用 HTTPS 协议的服务器必须要有一套数字 CA (Certification Authority)证书，证书是需要申请的，并由专门的数字证书认证机构(CA)通过非常严格的审核之后颁发的电子证书 (当然了是要钱的，安全级别越高价格越贵)。颁发证书的同时会产生一个私钥和公钥。私钥由服务端自己保存，不可泄漏。公钥则是附带在证书的信息中，可以公开的。证书本身也附带一个证书电子签名，这个签名用来验证证书的完整性和真实性，可以防止证书被篡改。\n服务器响应客户端请求，将证书传递给客户端，证书包含公钥和大量其他信息，比如证书颁发机构信息，公司信息和证书有效期等。Chrome 浏览器点击地址栏的锁标志再点击证书就可以看到证书详细信息。\n客户端解析证书并对其进行验证。如果证书不是可信机构颁布，或者证书中的域名与实际域名不一致，或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。如果证书没有问题，客户端就会从服务器证书中取出服务器的公钥A。然后客户端还会生成一个随机码 KEY，并使用公钥A将其加密。\n客户端把加密后的随机码 KEY 发送给服务器，作为后面对称加密的密钥。\n服务器在收到随机码 KEY 之后会使用私钥B将其解密。经过以上这些步骤，客户端和服务器终于建立了安全连接，完美解决了对称加密的密钥泄露问题，接下来就可以用对称加密愉快地进行通信了。\n服务器使用密钥 (随机码 KEY)对数据进行对称加密并发送给客户端，客户端使用相同的密钥 (随机码 KEY)解密数据。\n双方使用对称加密愉快地传输所有数据。","title":"https 原理简介"},{"content":"从今年 10 月 1 日起，GitHub 在该平台上创建的所有新的源代码仓库将默认被命名为 \u0026ldquo;main\u0026rdquo;，而不是原先的\u0026quot;master\u0026quot;。值得注意的是，现有的存储库不会受到此更改影响。\n早在今年 6 月份，受美国大规模的 “Black Lives Matter”运动影响，为了安抚愈演愈烈的民众情绪，GitHub 就宣布将替换掉 master 等术语，以避免联想奴隶制。现如今，在外界一些声音的催促下，这一举措则终于要正式落地了。\n除 GitHub 外，为了避免带有所谓的“种族歧视色彩”，许多科技巨头或知名软件也都调整了自己的业务和产品，以平息社会舆论。包括有：MySQL 宣布删除 master、黑名单白名单等术语；Linus Torvalds 通过了 Linux 中避免 master/slave 等术语的提案；还有 Twitter 、GitHub、微软、LinkedIn、Ansible、Splunk、OpenZFS、OpenSSL、JP Morgan、 Android 移动操作系统、Go 编程语言、PHPUnit 和 Curl 等宣布要对此类术语进行删除或更改。同时，IBM、亚马逊、微软也都接连调整面部识别平台业务，以防加深歧视或遭受指责。\n且最初在 Git 中写下“master”一词的开发者 Petr Baudis 也于 6 月份在社交网站上表明立场称，自己当年不该使用“master”这个可能给别人造成伤害的词语。并表示，他曾多次希望可以将“master”改成“main”(和“upstream”）。不过直到现在，才由 GitHub 开始主导替换工作。\n而对于为何选择“main”而不是其他替换词汇，Github 方面给出的解释为，main 是他们在平台上看到的最受欢迎的 master 替代品。并且 main 这个词汇很短，可以帮助用户形成良好的肌肉记忆；在很多种语言中翻译起来也都很容易。\n此外，Github 还透露，截至今年年底，他们将使现有存储库无缝重命名其默认分支。当用户重命名分支机构时，他们将重新定位打开的 PR 和草稿版本、移动分支机构保护策略等，且所有的这些都将自动完成。\n事实上，计算机术语政治正确性早已不是新鲜话题。2004 年，“master/slave”曾被全球语言检测机构评为年度最不政治正确的十大词汇之一，时任主席称这是政治渗透到计算机技术控制中的表现。2008 年，开源软件 Drupal 在社区发布消息，高调站队，将“master/slave”重命名为“client/server”。2018年，IETF 也在草案当中指出，要求开源软件更改“master/slave”和“blacklist/whitelist”两项表述。\n但是值得思考的是，在计算机源码领域中，“master/slave”和“blacklist/whitelist”之类的技术用语有错吗？一味的“一刀切”的话，会不会导致所谓的矫枉过正呢\n","permalink":"https://haokiu.com/blog/LcW9jL/","summary":"从今年 10 月 1 日起，GitHub 在该平台上创建的所有新的源代码仓库将默认被命名为 \u0026ldquo;main\u0026rdquo;，而不是原先的\u0026quot;master\u0026quot;。值得注意的是，现有的存储库不会受到此更改影响。\n早在今年 6 月份，受美国大规模的 “Black Lives Matter”运动影响，为了安抚愈演愈烈的民众情绪，GitHub 就宣布将替换掉 master 等术语，以避免联想奴隶制。现如今，在外界一些声音的催促下，这一举措则终于要正式落地了。\n除 GitHub 外，为了避免带有所谓的“种族歧视色彩”，许多科技巨头或知名软件也都调整了自己的业务和产品，以平息社会舆论。包括有：MySQL 宣布删除 master、黑名单白名单等术语；Linus Torvalds 通过了 Linux 中避免 master/slave 等术语的提案；还有 Twitter 、GitHub、微软、LinkedIn、Ansible、Splunk、OpenZFS、OpenSSL、JP Morgan、 Android 移动操作系统、Go 编程语言、PHPUnit 和 Curl 等宣布要对此类术语进行删除或更改。同时，IBM、亚马逊、微软也都接连调整面部识别平台业务，以防加深歧视或遭受指责。\n且最初在 Git 中写下“master”一词的开发者 Petr Baudis 也于 6 月份在社交网站上表明立场称，自己当年不该使用“master”这个可能给别人造成伤害的词语。并表示，他曾多次希望可以将“master”改成“main”(和“upstream”）。不过直到现在，才由 GitHub 开始主导替换工作。\n而对于为何选择“main”而不是其他替换词汇，Github 方面给出的解释为，main 是他们在平台上看到的最受欢迎的 master 替代品。并且 main 这个词汇很短，可以帮助用户形成良好的肌肉记忆；在很多种语言中翻译起来也都很容易。\n此外，Github 还透露，截至今年年底，他们将使现有存储库无缝重命名其默认分支。当用户重命名分支机构时，他们将重新定位打开的 PR 和草稿版本、移动分支机构保护策略等，且所有的这些都将自动完成。\n事实上，计算机术语政治正确性早已不是新鲜话题。2004 年，“master/slave”曾被全球语言检测机构评为年度最不政治正确的十大词汇之一，时任主席称这是政治渗透到计算机技术控制中的表现。2008 年，开源软件 Drupal 在社区发布消息，高调站队，将“master/slave”重命名为“client/server”。2018年，IETF 也在草案当中指出，要求开源软件更改“master/slave”和“blacklist/whitelist”两项表述。\n但是值得思考的是，在计算机源码领域中，“master/slave”和“blacklist/whitelist”之类的技术用语有错吗？一味的“一刀切”的话，会不会导致所谓的矫枉过正呢","title":"github 的 master 分支将更改为 main"},{"content":"ECMAScript 6.0（以下简称 ES6）是 JavaScript 语言的下一代标准，已经在 2015 年 6 月正式发布了。它的目标，是使得 JavaScript 语言可以用来编写复杂的大型应用程序，成为企业级开发语言。\nECMAScript 和 JavaScript 的关系 一个常见的问题是，ECMAScript 和 JavaScript 到底是什么关系？\n要讲清楚这个问题，需要回顾历史。1996 年 11 月，JavaScript 的创造者 Netscape 公司，决定将 JavaScript 提交给标准化组织 ECMA，希望这种语言能够成为国际标准。次年，ECMA 发布 262 号标准文件（ECMA-262）的第一版，规定了浏览器脚本语言的标准，并将这种语言称为 ECMAScript，这个版本就是 1.0 版。\n该标准从一开始就是针对 JavaScript 语言制定的，但是之所以不叫 JavaScript，有两个原因。一是商标，Java 是 Sun 公司的商标，根据授权协议，只有 Netscape 公司可以合法地使用 JavaScript 这个名字，且 JavaScript 本身也已经被 Netscape 公司注册为商标。二是想体现这门语言的制定者是 ECMA，不是 Netscape，这样有利于保证这门语言的开放性和中立性。\n因此，ECMAScript 和 JavaScript 的关系是，前者是后者的规格，后者是前者的一种实现（另外的 ECMAScript 方言还有 JScript 和 ActionScript）。日常场合，这两个词是可以互换的。\nBabel 转码器 Babel 是一个广泛使用的 ES6 转码器，可以将 ES6 代码转为 ES5 代码，从而在现有环境执行。这意味着，你可以用 ES6 的方式编写程序，又不用担心现有环境是否支持。下面是一个例子。\n// 转码前 input.map(item =\u0026gt; item + 1); // 转码后 input.map(function (item) { return item + 1; }); 上面的原始代码用了箭头函数，Babel 将其转为普通函数，就能在不支持箭头函数的 JavaScript 环境执行了。\n","permalink":"https://haokiu.com/blog/Cqhoxc/","summary":"ECMAScript 6.0（以下简称 ES6）是 JavaScript 语言的下一代标准，已经在 2015 年 6 月正式发布了。它的目标，是使得 JavaScript 语言可以用来编写复杂的大型应用程序，成为企业级开发语言。\nECMAScript 和 JavaScript 的关系 一个常见的问题是，ECMAScript 和 JavaScript 到底是什么关系？\n要讲清楚这个问题，需要回顾历史。1996 年 11 月，JavaScript 的创造者 Netscape 公司，决定将 JavaScript 提交给标准化组织 ECMA，希望这种语言能够成为国际标准。次年，ECMA 发布 262 号标准文件（ECMA-262）的第一版，规定了浏览器脚本语言的标准，并将这种语言称为 ECMAScript，这个版本就是 1.0 版。\n该标准从一开始就是针对 JavaScript 语言制定的，但是之所以不叫 JavaScript，有两个原因。一是商标，Java 是 Sun 公司的商标，根据授权协议，只有 Netscape 公司可以合法地使用 JavaScript 这个名字，且 JavaScript 本身也已经被 Netscape 公司注册为商标。二是想体现这门语言的制定者是 ECMA，不是 Netscape，这样有利于保证这门语言的开放性和中立性。\n因此，ECMAScript 和 JavaScript 的关系是，前者是后者的规格，后者是前者的一种实现（另外的 ECMAScript 方言还有 JScript 和 ActionScript）。日常场合，这两个词是可以互换的。\nBabel 转码器 Babel 是一个广泛使用的 ES6 转码器，可以将 ES6 代码转为 ES5 代码，从而在现有环境执行。这意味着，你可以用 ES6 的方式编写程序，又不用担心现有环境是否支持。下面是一个例子。\n// 转码前 input.map(item =\u0026gt; item + 1); // 转码后 input.map(function (item) { return item + 1; }); 上面的原始代码用了箭头函数，Babel 将其转为普通函数，就能在不支持箭头函数的 JavaScript 环境执行了。","title":"es6 简介"},{"content":"go MD5 所需要的包在”crypto/md5”包中，需要先实例化一个MD5对象，然后在此基础上调用sum方法即可\n文件的MD5 md5 := md5.New() io.Copy(md5,file) MD5Str := hex.EncodeToString(md5.Sum(nil)) 上面的代码实现了计算了文件MD5，其中file是multipart.File类型的，也可以是其他的已打开的其他文件类型。 当然也可以不使用io.copy，而是直接使用sum函数来计算：\nmd5 := md5.New() MD5Str := hex.EncodeToString(md5.Sum(file)) 这样是直接调用了sum函数来计算文件的值可能要比io.copy稍微慢一些。\n字符串的MD5 有时候需要将已知的一段字符串加密，其实和文件加密大概是类似的，只需要调用write方法将字符串写入hash中：\nmd5 := md5.New() md5.Write([]byte(\u0026#34;hello,world!\u0026#34;)) MD5Str := hex.EncodeToString(md5.Sum(nil)) ","permalink":"https://haokiu.com/blog/dpoeTs/","summary":"go MD5 所需要的包在”crypto/md5”包中，需要先实例化一个MD5对象，然后在此基础上调用sum方法即可\n文件的MD5 md5 := md5.New() io.Copy(md5,file) MD5Str := hex.EncodeToString(md5.Sum(nil)) 上面的代码实现了计算了文件MD5，其中file是multipart.File类型的，也可以是其他的已打开的其他文件类型。 当然也可以不使用io.copy，而是直接使用sum函数来计算：\nmd5 := md5.New() MD5Str := hex.EncodeToString(md5.Sum(file)) 这样是直接调用了sum函数来计算文件的值可能要比io.copy稍微慢一些。\n字符串的MD5 有时候需要将已知的一段字符串加密，其实和文件加密大概是类似的，只需要调用write方法将字符串写入hash中：\nmd5 := md5.New() md5.Write([]byte(\u0026#34;hello,world!\u0026#34;)) MD5Str := hex.EncodeToString(md5.Sum(nil)) ","title":"golang 计算文件和字符串的 md5 值"},{"content":"S3是Simple Storage Service的缩写，即简单存储服务。亚马逊的名词缩写也都遵循这个习惯，例如Elastic Compute Cloud缩写为EC2等等。\nS3说的玄乎一点可以叫云存储，通俗一点就是大网盘。其概念类似于分布式文家系统，同Google的GFS应该在一个层面。\n目前的阿里的oss，腾讯的cos，七牛云存储都兼容aws的S3，所以要更换这些服务商之间提供的云存储非常容易，只需要简单的修改Access Key, Secrect Key等就行。\nS3的定义如下 Amazon S3 is a web service that enables you to store data in the cloud. You can then download the data or use the data with other AWS services, such as Amazon Elastic Cloud Computer (EC2).\n看来除了做网盘只用，S3存储的数据还可以被其他的亚马逊高层服务直接引用，这一点比国内的简单的网盘提供商高不少，亚马逊大网盘是其整体Solution中的有机组成部分。\n基本概念 1. bucket – 类比于文件系统的目录 A bucket is a Container for objects stored in Amazon S3. Every object is contained in a bucket. For example, if the object named photos/puppy.jpg is stored in the johnsmith bucket, then it is addressable using the URL http://johnsmith.s3.amazonaws.com/photos/puppy.jpg\n似乎目录不能嵌套，也就是不能有子目录，官方的说法是起到namespace的作用，是访问控制的基本单位，其实丫还是个目录。\n2. Object – 类比文件系统的文件 对象中带有对象名名，对象属性，对象本身最大5G，其实也还是个文件。\n目前object有Versioning的属性（即对象不同历史版本的cache概念），这个是文件系统不具备的，在早期看到的S3资料中没有这一概念，应该是演进的结果，其面对的应该是有版本控制的需求的用户。\n3. Keys – 类比文件名 key的样式也是URL，记住亚马逊的服务都是使用Web Service或REST方式访问的。\n例如，http://doc.s3.amazonaws.com/2006-03-01/AmazonS3.wsdl\n其中‘doc’就是目录名（桶名），”2006-03-01/AmazonS3.wsdl”是文件名（对象名）。\n如果引入了version则bucket + key + version唯一标示一个版本的文件。\n4. Versioning – 类比CVS中的一个版本 同名文件的写入，并不覆盖已有文件而是增加了一个最新的文件版本。\n同样的删除也不真正删除，而是mark了删除标记。\n当最新版本mark为deleted之后，对该对象的get操作返回404错误，除非明确指定一个历史版本。\n当然也可以指定版本永久删除其中一个拷贝。\n5. Regions – 文件存储的地理位置 这个也是文件系统中不存在的，就是不同的地理区域，用户可以指定将文件存在某个国家的服务器。我个人认为，这不是一个很好的概念，作为云的提供商，应该对于应用屏蔽这些部署细节。工程实现同技术理想还是有差距。目前其可以指定的server位置有美国、爱尔兰、新加坡等地。\n接口API 常用的API就是读、写、增、删、改、查等等。使用标准的SOAP和REST定义。\n尤其一提的是对于对象的获取，除了用http直接按照C/S方式获取之外，亚马逊支持BT协议，也就是说提供种子。从用户角度想，亚马逊会 charge更少的钱，但同时亚马逊自身也会减负。bt下载的速度就不太稳定了，基本取决于种子“质量”也就是取决于对文件感兴趣的人的多寡。例如命名为 “XX门”估计文件下载能够快很多。\n参考 http://aws.amazon.com/s3/#functionality\nhttp://docs.amazonwebservices.com/AmazonS3/2006-03-01/\nhttp://developer.amazonwebservices.com/connect/forum.jspa?forumID=24\n","permalink":"https://haokiu.com/blog/d0DCeH/","summary":"S3是Simple Storage Service的缩写，即简单存储服务。亚马逊的名词缩写也都遵循这个习惯，例如Elastic Compute Cloud缩写为EC2等等。\nS3说的玄乎一点可以叫云存储，通俗一点就是大网盘。其概念类似于分布式文家系统，同Google的GFS应该在一个层面。\n目前的阿里的oss，腾讯的cos，七牛云存储都兼容aws的S3，所以要更换这些服务商之间提供的云存储非常容易，只需要简单的修改Access Key, Secrect Key等就行。\nS3的定义如下 Amazon S3 is a web service that enables you to store data in the cloud. You can then download the data or use the data with other AWS services, such as Amazon Elastic Cloud Computer (EC2).\n看来除了做网盘只用，S3存储的数据还可以被其他的亚马逊高层服务直接引用，这一点比国内的简单的网盘提供商高不少，亚马逊大网盘是其整体Solution中的有机组成部分。\n基本概念 1. bucket – 类比于文件系统的目录 A bucket is a Container for objects stored in Amazon S3. Every object is contained in a bucket. For example, if the object named photos/puppy.jpg is stored in the johnsmith bucket, then it is addressable using the URL http://johnsmith.s3.amazonaws.com/photos/puppy.jpg\n似乎目录不能嵌套，也就是不能有子目录，官方的说法是起到namespace的作用，是访问控制的基本单位，其实丫还是个目录。\n2. Object – 类比文件系统的文件 对象中带有对象名名，对象属性，对象本身最大5G，其实也还是个文件。\n目前object有Versioning的属性（即对象不同历史版本的cache概念），这个是文件系统不具备的，在早期看到的S3资料中没有这一概念，应该是演进的结果，其面对的应该是有版本控制的需求的用户。\n3. Keys – 类比文件名 key的样式也是URL，记住亚马逊的服务都是使用Web Service或REST方式访问的。","title":"S3协议"},{"content":"七牛云存储 提供了每月10G的免费存储，一般的网站已经够用，如果超额了，费用也很低，可以考虑将网站的图片存在七牛，安全可靠。\n","permalink":"https://haokiu.com/blog/0K1gzu/","summary":"七牛云存储 提供了每月10G的免费存储，一般的网站已经够用，如果超额了，费用也很低，可以考虑将网站的图片存在七牛，安全可靠。","title":"免费的云存储"},{"content":"网站的部署脚本\n#!/bin/sh #部署目录 siteDir=\u0026#39;/usr/local/pixiublog\u0026#39; # 源代码目录 cd /root/pixiublog echo \u0026#34;update code\u0026#34; git pull echo \u0026#34;build pixiublog\u0026#34; go build main.go echo \u0026#34;remove old\u0026#34; rm -rf $siteDir/views rm -rf $siteDir/static rm -rf $siteDir/pixiublog echo \u0026#34;mv new program to $siteDir\u0026#34; cp main $siteDir/pixiublog cp -rf views $siteDir/ cp -rf static $siteDir/ echo \u0026#34;kill the running program\u0026#34; ps -ef | grep \u0026#39;pixiublog\u0026#39; | grep -v grep | awk \u0026#39;{print $2}\u0026#39; | xargs kill -9 echo \u0026#34;start program\u0026#34; cd $siteDir nohup $siteDir/pixiublog \u0026gt;\u0026gt; $siteDir/console.log 2\u0026gt;\u0026amp;1 \u0026amp; ","permalink":"https://haokiu.com/blog/1gTd1h/","summary":"网站的部署脚本\n#!/bin/sh #部署目录 siteDir=\u0026#39;/usr/local/pixiublog\u0026#39; # 源代码目录 cd /root/pixiublog echo \u0026#34;update code\u0026#34; git pull echo \u0026#34;build pixiublog\u0026#34; go build main.go echo \u0026#34;remove old\u0026#34; rm -rf $siteDir/views rm -rf $siteDir/static rm -rf $siteDir/pixiublog echo \u0026#34;mv new program to $siteDir\u0026#34; cp main $siteDir/pixiublog cp -rf views $siteDir/ cp -rf static $siteDir/ echo \u0026#34;kill the running program\u0026#34; ps -ef | grep \u0026#39;pixiublog\u0026#39; | grep -v grep | awk \u0026#39;{print $2}\u0026#39; | xargs kill -9 echo \u0026#34;start program\u0026#34; cd $siteDir nohup $siteDir/pixiublog \u0026gt;\u0026gt; $siteDir/console.log 2\u0026gt;\u0026amp;1 \u0026amp; ","title":"网站部署脚本"},{"content":"golang 判断目录或文件是否存在：\nfunc Exist(path string) bool { _, err := os.Stat(path) return err == nil || os.IsExist(err) } ","permalink":"https://haokiu.com/blog/Cd6WaZ/","summary":"golang 判断目录或文件是否存在：\nfunc Exist(path string) bool { _, err := os.Stat(path) return err == nil || os.IsExist(err) } ","title":"golang 判断目录或文件是否存在"},{"content":"katacoda is Interactive Learning and Training Platform for Software Engineers Helping Developers Learn and Companies Increase Adoption\n可以交互式的学习各种前沿技术：k8s linux docker 机器学习等\n","permalink":"https://haokiu.com/blog/baIB8x/","summary":"katacoda is Interactive Learning and Training Platform for Software Engineers Helping Developers Learn and Companies Increase Adoption\n可以交互式的学习各种前沿技术：k8s linux docker 机器学习等","title":"在线交互式学习k8s/docker/linux"},{"content":"bee 工具是一个为了协助快速开发 beego 项目而创建的项目，通过 bee 您可以很容易的进行 beego 项目的创建、热编译、开发、测试、和部署。\nbee 工具的安装 您可以通过如下的方式安装 bee 工具：\ngo get github.com/beego/bee 安装完之后，bee 可执行文件默认存放在 $GOPATH/bin 里面，所以您需要把 $GOPATH/bin 添加到您的环境变量中，才可以进行下一步。\n如何添加环境变量，请自行搜索 如果你本机设置了 GOBIN，那么上面的命令就会安装到 GOBIN 下，请添加 GOBIN 到你的环境变量中\nbee 工具命令详解 我们在命令行输入 bee，可以看到如下的信息：\nBee is a Fast and Flexible tool for managing your Beego Web Application. Usage: bee command [arguments] The commands are: version show the bee \u0026amp; beego version migrate run database migrations api create an api application base on beego framework bale packs non-Go files to Go source files new create an application base on beego framework run run the app which can hot compile pack compress an beego project fix Fixes your application by making it compatible with newer versions of Beego dlv Start a debugging session using Delve dockerize Generates a Dockerfile for your Beego application generate Source code generator hprose Creates an RPC application based on Hprose and Beego frameworks pack Compresses a Beego application into a single file rs Run customized scripts run Run the application by starting a local development server server serving static content over HTTP on port Use bee help [command] for more information about a command. new 命令 new 命令是新建一个 Web 项目，我们在命令行下执行 bee new \u0026lt;项目名\u0026gt; 就可以创建一个新的项目。但是注意该命令必须在 $GOPATH/src 下执行。最后会在 $GOPATH/src 相应目录下生成如下目录结构的项目：\nbee new myproject [INFO] Creating application... /gopath/src/myproject/ /gopath/src/myproject/conf/ /gopath/src/myproject/controllers/ /gopath/src/myproject/models/ /gopath/src/myproject/static/ /gopath/src/myproject/static/js/ /gopath/src/myproject/static/css/ /gopath/src/myproject/static/img/ /gopath/src/myproject/views/ /gopath/src/myproject/conf/app.conf /gopath/src/myproject/controllers/default.go /gopath/src/myproject/views/index.tpl /gopath/src/myproject/main.go 13-11-25 09:50:39 [SUCC] New application successfully created! myproject ├── conf │ └── app.conf ├── controllers │ └── default.go ├── main.go ├── models ├── routers │ └── router.go ├── static │ ├── css │ ├── img │ └── js ├── tests │ └── default_test.go └── views └── index.tpl 8 directories, 4 files api 命令 上面的 new 命令是用来新建 Web 项目，不过很多用户使用 beego 来开发 API 应用。所以这个 api 命令就是用来创建 API 应用的，执行命令之后如下所示：\nbee api apiproject create app folder: /gopath/src/apiproject create conf: /gopath/src/apiproject/conf create controllers: /gopath/src/apiproject/controllers create models: /gopath/src/apiproject/models create tests: /gopath/src/apiproject/tests create conf app.conf: /gopath/src/apiproject/conf/app.conf create controllers default.go: /gopath/src/apiproject/controllers/default.go create tests default.go: /gopath/src/apiproject/tests/default_test.go create models object.go: /gopath/src/apiproject/models/object.go create main.go: /gopath/src/apiproject/main.go 这个项目的目录结构如下：\napiproject ├── conf │ └── app.conf ├── controllers │ └── object.go │ └── user.go ├── docs │ └── doc.go ├── main.go ├── models │ └── object.go │ └── user.go ├── routers │ └── router.go └── tests └── default_test.go 从上面的目录我们可以看到和 Web 项目相比，少了 static 和 views 目录，多了一个 test 模块，用来做单元测试的。\n同时，该命令还支持一些自定义参数自动连接数据库创建相关 model 和 controller: bee api [appname] [-tables=\u0026quot;\u0026quot;] [-driver=mysql] [-conn=\u0026quot;root:\u0026lt;password\u0026gt;@tcp(127.0.0.1:3306)/test\u0026quot;] 如果 conn 参数为空则创建一个示例项目，否则将基于链接信息链接数据库创建项目。\nrun 命令 我们在开发 Go 项目的时候最大的问题是经常需要自己手动去编译再运行，bee run 命令是监控 beego 的项目，通过 fsnotify监控文件系统。但是注意该命令必须在 $GOPATH/src/appname 下执行。 这样我们在开发过程中就可以实时的看到项目修改之后的效果：\nbee run 13-11-25 09:53:04 [INFO] Uses \u0026#39;myproject\u0026#39; as \u0026#39;appname\u0026#39; 13-11-25 09:53:04 [INFO] Initializing watcher... 13-11-25 09:53:04 [TRAC] Directory(/gopath/src/myproject/controllers) 13-11-25 09:53:04 [TRAC] Directory(/gopath/src/myproject/models) 13-11-25 09:53:04 [TRAC] Directory(/gopath/src/myproject) 13-11-25 09:53:04 [INFO] Start building... 13-11-25 09:53:16 [SUCC] Build was successful 13-11-25 09:53:16 [INFO] Restarting myproject ... 13-11-25 09:53:16 [INFO] ./myproject is running... 我们打开浏览器就可以看到效果 http://localhost:8080/:\n如果我们修改了 Controller 下面的 default.go 文件，我们就可以看到命令行输出：\n13-11-25 10:11:20 [EVEN] \u0026#34;/gopath/src/myproject/controllers/default.go\u0026#34;: DELETE|MODIFY 13-11-25 10:11:20 [INFO] Start building... 13-11-25 10:11:20 [SKIP] \u0026#34;/gopath/src/myproject/controllers/default.go\u0026#34;: CREATE 13-11-25 10:11:23 [SKIP] \u0026#34;/gopath/src/myproject/controllers/default.go\u0026#34;: MODIFY 13-11-25 10:11:23 [SUCC] Build was successful 13-11-25 10:11:23 [INFO] Restarting myproject ... 13-11-25 10:11:23 [INFO] ./myproject is running... 刷新浏览器我们看到新的修改内容已经输出。\npack 命令 pack 目录用来发布应用的时候打包，会把项目打包成 zip 包，这样我们部署的时候直接把打包之后的项目上传，解压就可以部署了：\nbee pack app path: /gopath/src/apiproject GOOS darwin GOARCH amd64 build apiproject build success exclude prefix: exclude suffix: .go:.DS_Store:.tmp file write to `/gopath/src/apiproject/apiproject.tar.gz` 我们可以看到目录下有如下的压缩文件：\nrwxr-xr-x 1 astaxie staff 8995376 11 25 22:46 apiproject -rw-r--r-- 1 astaxie staff 2240288 11 25 22:58 apiproject.tar.gz drwxr-xr-x 3 astaxie staff 102 11 25 22:31 conf drwxr-xr-x 3 astaxie staff 102 11 25 22:31 controllers -rw-r--r-- 1 astaxie staff 509 11 25 22:31 main.go drwxr-xr-x 3 astaxie staff 102 11 25 22:31 models drwxr-xr-x 3 astaxie staff 102 11 25 22:31 tests bale 命令 这个命令目前仅限内部使用，具体实现方案未完善，主要用来压缩所有的静态文件变成一个变量申明文件，全部编译到二进制文件里面，用户发布的时候携带静态文件，包括 js、css、img 和 views。最后在启动运行时进行非覆盖式的自解压。\nversion 命令 这个命令是动态获取 bee、beego 和 Go 的版本，这样一旦用户出现错误，可以通过该命令来查看当前的版本\n$ bee version bee :1.2.2 beego :1.4.2 Go :go version go1.3.3 darwin/amd64 generate 命令 这个命令是用来自动化的生成代码的，包含了从数据库一键生成 model，还包含了 scaffold 的，通过这个命令，让大家开发代码不再慢\nbee generate scaffold [scaffoldname] [-fields=\u0026#34;\u0026#34;] [-driver=mysql] [-conn=\u0026#34;root:@tcp(127.0.0.1:3306)/test\u0026#34;] The generate scaffold command will do a number of things for you. -fields: a list of table fields. Format: field:type, ... -driver: [mysql | postgres | sqlite], the default is mysql -conn: the connection string used by the driver, the default is root:@tcp(127.0.0.1:3306)/test example: bee generate scaffold post -fields=\u0026#34;title:string,body:text\u0026#34; bee generate model [modelname] [-fields=\u0026#34;\u0026#34;] generate RESTful model based on fields -fields: a list of table fields. Format: field:type, ... bee generate controller [controllerfile] generate RESTful controllers bee generate view [viewpath] generate CRUD view in viewpath bee generate migration [migrationfile] [-fields=\u0026#34;\u0026#34;] generate migration file for making database schema update -fields: a list of table fields. Format: field:type, ... bee generate docs generate swagger doc file bee generate test [routerfile] generate testcase bee generate appcode [-tables=\u0026#34;\u0026#34;] [-driver=mysql] [-conn=\u0026#34;root:@tcp(127.0.0.1:3306)/test\u0026#34;] [-level=3] generate appcode based on an existing database -tables: a list of table names separated by \u0026#39;,\u0026#39;, default is empty, indicating all tables -driver: [mysql | postgres | sqlite], the default is mysql -conn: the connection string used by the driver. default for mysql: root:@tcp(127.0.0.1:3306)/test default for postgres: postgres://postgres:postgres@127.0.0.1:5432/postgres -level: [1 | 2 | 3], 1 = models; 2 = models,controllers; 3 = models,controllers,router migrate 命令 这个命令是应用的数据库迁移命令，主要是用来每次应用升级，降级的SQL管理。\nbee migrate [-driver=mysql] [-conn=\u0026#34;root:@tcp(127.0.0.1:3306)/test\u0026#34;] run all outstanding migrations -driver: [mysql | postgresql | sqlite], the default is mysql -conn: the connection string used by the driver, the default is root:@tcp(127.0.0.1:3306)/test bee migrate rollback [-driver=mysql] [-conn=\u0026#34;root:@tcp(127.0.0.1:3306)/test\u0026#34;] rollback the last migration operation -driver: [mysql | postgresql | sqlite], the default is mysql -conn: the connection string used by the driver, the default is root:@tcp(127.0.0.1:3306)/test bee migrate reset [-driver=mysql] [-conn=\u0026#34;root:@tcp(127.0.0.1:3306)/test\u0026#34;] rollback all migrations -driver: [mysql | postgresql | sqlite], the default is mysql -conn: the connection string used by the driver, the default is root:@tcp(127.0.0.1:3306)/test bee migrate refresh [-driver=mysql] [-conn=\u0026#34;root:@tcp(127.0.0.1:3306)/test\u0026#34;] rollback all migrations and run them all again -driver: [mysql | postgresql | sqlite], the default is mysql -conn: the connection string used by the driver, the default is root:@tcp(127.0.0.1:3306)/test dockerize 命令 这个命令可以通过生成Dockerfile文件来实现docker化你的应用。\n例子: 生成一个以1.6.4版本Go环境为基础镜像的Dockerfile,并暴露9000端口:\n$ bee dockerize -image=\u0026#34;library/golang:1.6.4\u0026#34; -expose=9000 ______ | ___ \\ | |_/ / ___ ___ | ___ \\ / _ \\ / _ \\ | |_/ /| __/| __/ \\____/ \\___| \\___| v1.6.2 2016/12/26 22:34:54 INFO ▶ 0001 Generating Dockerfile... 2016/12/26 22:34:54 SUCCESS ▶ 0002 Dockerfile generated. 更多帮助信息可执行bee help dockerize.\nbee 工具配置文件 您可能已经注意到，在 bee 工具的源码目录下有一个 bee.json 文件，这个文件是针对 bee 工具的一些行为进行配置。该功能还未完全开发完成，不过其中的一些选项已经可以使用：\n\u0026quot;version\u0026quot;: 0：配置文件版本，用于对比是否发生不兼容的配置格式版本。 \u0026quot;go_install\u0026quot;: false：如果您的包均使用完整的导入路径（例如：github.com/user/repo/subpkg）,则可以启用该选项来进行 go install 操作，加快构建操作。 \u0026quot;watch_ext\u0026quot;: []：用于监控其它类型的文件（默认只监控后缀为 .go 的文件）。 \u0026quot;dir_structure\u0026quot;:{}：如果您的目录名与默认的 MVC 架构的不同，则可以使用该选项进行修改。 \u0026quot;cmd_args\u0026quot;: []：如果您需要在每次启动时加入启动参数，则可以使用该选项。 \u0026quot;envs\u0026quot;: []：如果您需要在每次启动时设置临时环境变量参数，则可以使用该选项。 ","permalink":"https://haokiu.com/blog/xVaucl/","summary":"bee 工具是一个为了协助快速开发 beego 项目而创建的项目，通过 bee 您可以很容易的进行 beego 项目的创建、热编译、开发、测试、和部署。\nbee 工具的安装 您可以通过如下的方式安装 bee 工具：\ngo get github.com/beego/bee 安装完之后，bee 可执行文件默认存放在 $GOPATH/bin 里面，所以您需要把 $GOPATH/bin 添加到您的环境变量中，才可以进行下一步。\n如何添加环境变量，请自行搜索 如果你本机设置了 GOBIN，那么上面的命令就会安装到 GOBIN 下，请添加 GOBIN 到你的环境变量中\nbee 工具命令详解 我们在命令行输入 bee，可以看到如下的信息：\nBee is a Fast and Flexible tool for managing your Beego Web Application. Usage: bee command [arguments] The commands are: version show the bee \u0026amp; beego version migrate run database migrations api create an api application base on beego framework bale packs non-Go files to Go source files new create an application base on beego framework run run the app which can hot compile pack compress an beego project fix Fixes your application by making it compatible with newer versions of Beego dlv Start a debugging session using Delve dockerize Generates a Dockerfile for your Beego application generate Source code generator hprose Creates an RPC application based on Hprose and Beego frameworks pack Compresses a Beego application into a single file rs Run customized scripts run Run the application by starting a local development server server serving static content over HTTP on port Use bee help [command] for more information about a command.","title":"beego bee 工具使用简介"},{"content":"beego logs 的设计思路来自于 database/sql，目前支持的引擎有 file、console、net、smtp，可以通过如下方式进行安装：\ngo get github.com/astaxie/beego/logs 如何使用 通用方式 首先引入包：\nimport ( \u0026#34;github.com/astaxie/beego/logs\u0026#34; ) 然后添加输出引擎（log 支持同时输出到多个引擎），这里我们以 console 为例，第一个参数是引擎名（包括：console、file、conn、smtp、es、multifile）\nlogs.SetLogger(\u0026#34;console\u0026#34;) 添加输出引擎也支持第二个参数,用来表示配置信息，详细的配置请看下面介绍：\nlogs.SetLogger(logs.AdapterFile,`{\u0026#34;filename\u0026#34;:\u0026#34;project.log\u0026#34;,\u0026#34;level\u0026#34;:7,\u0026#34;maxlines\u0026#34;:0,\u0026#34;maxsize\u0026#34;:0,\u0026#34;daily\u0026#34;:true,\u0026#34;maxdays\u0026#34;:10,\u0026#34;color\u0026#34;:true}`) 然后我们就可以在我们的逻辑中开始任意的使用了：\npackage main import ( \u0026#34;github.com/astaxie/beego/logs\u0026#34; ) func main() { //an official log.Logger l := logs.GetLogger() l.Println(\u0026#34;this is a message of http\u0026#34;) //an official log.Logger with prefix ORM logs.GetLogger(\u0026#34;ORM\u0026#34;).Println(\u0026#34;this is a message of orm\u0026#34;) logs.Debug(\u0026#34;my book is bought in the year of \u0026#34;, 2016) logs.Info(\u0026#34;this %s cat is %v years old\u0026#34;, \u0026#34;yellow\u0026#34;, 3) logs.Warn(\u0026#34;json is a type of kv like\u0026#34;, map[string]int{\u0026#34;key\u0026#34;: 2016}) logs.Error(1024, \u0026#34;is a very\u0026#34;, \u0026#34;good game\u0026#34;) logs.Critical(\u0026#34;oh,crash\u0026#34;) } 多个实例 一般推荐使用通用方式进行日志，但依然支持单独声明来使用独立的日志\npackage main import ( \u0026#34;github.com/astaxie/beego/logs\u0026#34; ) func main() { log := logs.NewLogger() log.SetLogger(logs.AdapterConsole) log.Debug(\u0026#34;this is a debug message\u0026#34;) } 输出文件名和行号 日志默认不输出调用的文件名和文件行号,如果你期望输出调用的文件名和文件行号,可以如下设置\nlogs.EnableFuncCallDepth(true) 开启传入参数 true,关闭传入参数 false,默认是关闭的.\n如果你的应用自己封装了调用 log 包,那么需要设置 SetLogFuncCallDepth,默认是 2,也就是直接调用的层级,如果你封装了多层,那么需要根据自己的需求进行调整.\nlogs.SetLogFuncCallDepth(3) 异步输出日志 为了提升性能, 可以设置异步输出:\nlogs.Async() 异步输出允许设置缓冲 chan 的大小\nlogs.Async(1e3) 引擎配置设置 console\n命令行输出，默认输出到`os.Stdout`： logs.SetLogger(logs.AdapterConsole, `{\u0026#34;level\u0026#34;:1,\u0026#34;color\u0026#34;:true}`) 主要的参数如下说明：\nlevel 输出的日志级别 color 是否开启打印日志彩色打印(需环境支持彩色输出) file\n设置的例子如下所示：\nlogs.SetLogger(logs.AdapterFile, `{\u0026#34;filename\u0026#34;:\u0026#34;test.log\u0026#34;}`) 主要的参数如下说明：\nfilename 保存的文件名 maxlines 每个文件保存的最大行数，默认值 1000000 maxsize 每个文件保存的最大尺寸，默认值是 1 \u0026laquo; 28, //256 MB daily 是否按照每天 logrotate，默认是 true maxdays 文件最多保存多少天，默认保存 7 天 rotate 是否开启 logrotate，默认是 true level 日志保存的时候的级别，默认是 Trace 级别 perm 日志文件权限 multifile\n设置的例子如下所示：\nlogs.SetLogger(logs.AdapterMultiFile, `{\u0026#34;filename\u0026#34;:\u0026#34;test.log\u0026#34;,\u0026#34;separate\u0026#34;:[\u0026#34;emergency\u0026#34;, \u0026#34;alert\u0026#34;, \u0026#34;critical\u0026#34;, \u0026#34;error\u0026#34;, \u0026#34;warning\u0026#34;, \u0026#34;notice\u0026#34;, \u0026#34;info\u0026#34;, \u0026#34;debug\u0026#34;]}`) 主要的参数如下说明(除 separate 外,均与file相同)：\nfilename 保存的文件名 maxlines 每个文件保存的最大行数，默认值 1000000 maxsize 每个文件保存的最大尺寸，默认值是 1 \u0026laquo; 28, //256 MB daily 是否按照每天 logrotate，默认是 true maxdays 文件最多保存多少天，默认保存 7 天 rotate 是否开启 logrotate，默认是 true level 日志保存的时候的级别，默认是 Trace 级别 perm 日志文件权限 separate 需要单独写入文件的日志级别,设置后命名类似 test.error.log conn\n网络输出，设置的例子如下所示：\nlogs.SetLogger(logs.AdapterConn, `{\u0026#34;net\u0026#34;:\u0026#34;tcp\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;:7020\u0026#34;}`) 主要的参数说明如下：\nreconnectOnMsg 是否每次链接都重新打开链接，默认是 false reconnect 是否自动重新链接地址，默认是 false net 发开网络链接的方式，可以使用 tcp、unix、udp 等 addr 网络链接的地址 level 日志保存的时候的级别，默认是 Trace 级别 smtp\n邮件发送，设置的例子如下所示：\nlogs.SetLogger(logs.AdapterMail, `{\u0026#34;username\u0026#34;:\u0026#34;beegotest@gmail.com\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;xxxxxxxx\u0026#34;,\u0026#34;host\u0026#34;:\u0026#34;smtp.gmail.com:587\u0026#34;,\u0026#34;sendTos\u0026#34;:[\u0026#34;xiemengjun@gmail.com\u0026#34;]}`) 主要的参数说明如下：\nusername smtp 验证的用户名 password smtp 验证密码 host 发送的邮箱地址 sendTos 邮件需要发送的人，支持多个 subject 发送邮件的标题，默认是 Diagnostic message from server level 日志发送的级别，默认是 Trace 级别 ElasticSearch\n输出到 ElasticSearch:\nlogs.SetLogger(logs.AdapterEs, `{\u0026#34;dsn\u0026#34;:\u0026#34;http://localhost:9200/\u0026#34;,\u0026#34;level\u0026#34;:1}`) 简聊\n输出到简聊：\nlogs.SetLogger(logs.AdapterJianLiao, `{\u0026#34;authorname\u0026#34;:\u0026#34;xxx\u0026#34;,\u0026#34;title\u0026#34;:\u0026#34;beego\u0026#34;, \u0026#34;webhookurl\u0026#34;:\u0026#34;https://jianliao.com/xxx\u0026#34;, \u0026#34;redirecturl\u0026#34;:\u0026#34;https://jianliao.com/xxx\u0026#34;,\u0026#34;imageurl\u0026#34;:\u0026#34;https://jianliao.com/xxx\u0026#34;,\u0026#34;level\u0026#34;:1}`) slack\n输出到slack:\nlogs.SetLogger(logs.AdapterSlack, `{\u0026#34;webhookurl\u0026#34;:\u0026#34;https://slack.com/xxx\u0026#34;,\u0026#34;level\u0026#34;:1}`) ","permalink":"https://haokiu.com/blog/gq7FUH/","summary":"beego logs 的设计思路来自于 database/sql，目前支持的引擎有 file、console、net、smtp，可以通过如下方式进行安装：\ngo get github.com/astaxie/beego/logs 如何使用 通用方式 首先引入包：\nimport ( \u0026#34;github.com/astaxie/beego/logs\u0026#34; ) 然后添加输出引擎（log 支持同时输出到多个引擎），这里我们以 console 为例，第一个参数是引擎名（包括：console、file、conn、smtp、es、multifile）\nlogs.SetLogger(\u0026#34;console\u0026#34;) 添加输出引擎也支持第二个参数,用来表示配置信息，详细的配置请看下面介绍：\nlogs.SetLogger(logs.AdapterFile,`{\u0026#34;filename\u0026#34;:\u0026#34;project.log\u0026#34;,\u0026#34;level\u0026#34;:7,\u0026#34;maxlines\u0026#34;:0,\u0026#34;maxsize\u0026#34;:0,\u0026#34;daily\u0026#34;:true,\u0026#34;maxdays\u0026#34;:10,\u0026#34;color\u0026#34;:true}`) 然后我们就可以在我们的逻辑中开始任意的使用了：\npackage main import ( \u0026#34;github.com/astaxie/beego/logs\u0026#34; ) func main() { //an official log.Logger l := logs.GetLogger() l.Println(\u0026#34;this is a message of http\u0026#34;) //an official log.Logger with prefix ORM logs.GetLogger(\u0026#34;ORM\u0026#34;).Println(\u0026#34;this is a message of orm\u0026#34;) logs.Debug(\u0026#34;my book is bought in the year of \u0026#34;, 2016) logs.Info(\u0026#34;this %s cat is %v years old\u0026#34;, \u0026#34;yellow\u0026#34;, 3) logs.Warn(\u0026#34;json is a type of kv like\u0026#34;, map[string]int{\u0026#34;key\u0026#34;: 2016}) logs.Error(1024, \u0026#34;is a very\u0026#34;, \u0026#34;good game\u0026#34;) logs.Critical(\u0026#34;oh,crash\u0026#34;) } 多个实例 一般推荐使用通用方式进行日志，但依然支持单独声明来使用独立的日志\npackage main import ( \u0026#34;github.com/astaxie/beego/logs\u0026#34; ) func main() { log := logs.","title":"beego 日志配置"},{"content":"beego 的日志处理是基于 logs 模块搭建的，内置了一个变量 BeeLogger，默认已经是 logs.BeeLogger 类型，初始化了 console，也就是默认输出到 console。\n使用入门 一般在程序中我们使用如下的方式进行输出：\nbeego.Emergency(\u0026#34;this is emergency\u0026#34;) beego.Alert(\u0026#34;this is alert\u0026#34;) beego.Critical(\u0026#34;this is critical\u0026#34;) beego.Error(\u0026#34;this is error\u0026#34;) beego.Warning(\u0026#34;this is warning\u0026#34;) beego.Notice(\u0026#34;this is notice\u0026#34;) beego.Informational(\u0026#34;this is informational\u0026#34;) beego.Debug(\u0026#34;this is debug\u0026#34;) 设置输出 我们的程序往往期望把信息输出到 log 中，现在设置输出到文件很方便，如下所示：\nbeego.SetLogger(\u0026#34;file\u0026#34;, `{\u0026#34;filename\u0026#34;:\u0026#34;logs/test.log\u0026#34;}`) 更多详细的日志配置请查看 beego 日志配置\n这个默认情况就会同时输出到两个地方，一个 console，一个 file，如果只想输出到文件，就需要调用删除操作：\nbeego.BeeLogger.DelLogger(\u0026#34;console\u0026#34;) 设置级别 日志的级别如上所示的代码这样分为八个级别：\nLevelEmergency LevelAlert LevelCritical LevelError LevelWarning LevelNotice LevelInformational LevelDebug 级别依次降低，默认全部打印，但是一般我们在部署环境，可以通过设置级别设置日志级别：\nbeego.SetLevel(beego.LevelInformational) 输出文件名和行号 日志默认不输出调用的文件名和文件行号,如果你期望输出调用的文件名和文件行号,可以如下设置\nbeego.SetLogFuncCall(true) 开启传入参数 true, 关闭传入参数 false, 默认是关闭的.\n完整示例 func internalCalculationFunc(x, y int) (result int, err error) { beego.Debug(\u0026#34;calculating z. x:\u0026#34;, x, \u0026#34; y:\u0026#34;, y) z := y switch { case x == 3: beego.Debug(\u0026#34;x == 3\u0026#34;) panic(\u0026#34;Failure.\u0026#34;) case y == 1: beego.Debug(\u0026#34;y == 1\u0026#34;) return 0, errors.New(\u0026#34;Error!\u0026#34;) case y == 2: beego.Debug(\u0026#34;y == 2\u0026#34;) z = x default: beego.Debug(\u0026#34;default\u0026#34;) z += x } retVal := z - 3 beego.Debug(\u0026#34;Returning \u0026#34;, retVal) return retVal, nil } func processInput(input inputData) { defer func() { if r := recover(); r != nil { beego.Error(\u0026#34;Unexpected error occurred: \u0026#34;, r) outputs \u0026lt;- outputData{result: 0, error: true} } }() beego.Informational(\u0026#34;Received input signal. x:\u0026#34;, input.x, \u0026#34; y:\u0026#34;, input.y) res, err := internalCalculationFunc(input.x, input.y) if err != nil { beego.Warning(\u0026#34;Error in calculation:\u0026#34;, err.Error()) } beego.Informational(\u0026#34;Returning result: \u0026#34;, res, \u0026#34; error: \u0026#34;, err) outputs \u0026lt;- outputData{result: res, error: err != nil} } func main() { inputs = make(chan inputData) outputs = make(chan outputData) criticalChan = make(chan int) beego.Informational(\u0026#34;App started.\u0026#34;) go consumeResults(outputs) beego.Informational(\u0026#34;Started receiving results.\u0026#34;) go generateInputs(inputs) beego.Informational(\u0026#34;Started sending signals.\u0026#34;) for { select { case input := \u0026lt;-inputs: processInput(input) case \u0026lt;-criticalChan: beego.Critical(\u0026#34;Caught value from criticalChan: Go shut down.\u0026#34;) panic(\u0026#34;Shut down due to critical fault.\u0026#34;) } } } 日志级别 beego 日志级别对应的数值可参考：beego 的日志级别\n","permalink":"https://haokiu.com/blog/YAotkP/","summary":"beego 的日志处理是基于 logs 模块搭建的，内置了一个变量 BeeLogger，默认已经是 logs.BeeLogger 类型，初始化了 console，也就是默认输出到 console。\n使用入门 一般在程序中我们使用如下的方式进行输出：\nbeego.Emergency(\u0026#34;this is emergency\u0026#34;) beego.Alert(\u0026#34;this is alert\u0026#34;) beego.Critical(\u0026#34;this is critical\u0026#34;) beego.Error(\u0026#34;this is error\u0026#34;) beego.Warning(\u0026#34;this is warning\u0026#34;) beego.Notice(\u0026#34;this is notice\u0026#34;) beego.Informational(\u0026#34;this is informational\u0026#34;) beego.Debug(\u0026#34;this is debug\u0026#34;) 设置输出 我们的程序往往期望把信息输出到 log 中，现在设置输出到文件很方便，如下所示：\nbeego.SetLogger(\u0026#34;file\u0026#34;, `{\u0026#34;filename\u0026#34;:\u0026#34;logs/test.log\u0026#34;}`) 更多详细的日志配置请查看 beego 日志配置\n这个默认情况就会同时输出到两个地方，一个 console，一个 file，如果只想输出到文件，就需要调用删除操作：\nbeego.BeeLogger.DelLogger(\u0026#34;console\u0026#34;) 设置级别 日志的级别如上所示的代码这样分为八个级别：\nLevelEmergency LevelAlert LevelCritical LevelError LevelWarning LevelNotice LevelInformational LevelDebug 级别依次降低，默认全部打印，但是一般我们在部署环境，可以通过设置级别设置日志级别：\nbeego.SetLevel(beego.LevelInformational) 输出文件名和行号 日志默认不输出调用的文件名和文件行号,如果你期望输出调用的文件名和文件行号,可以如下设置\nbeego.SetLogFuncCall(true) 开启传入参数 true, 关闭传入参数 false, 默认是关闭的.\n完整示例 func internalCalculationFunc(x, y int) (result int, err error) { beego.Debug(\u0026#34;calculating z. x:\u0026#34;, x, \u0026#34; y:\u0026#34;, y) z := y switch { case x == 3: beego.Debug(\u0026#34;x == 3\u0026#34;) panic(\u0026#34;Failure.\u0026#34;) case y == 1: beego.","title":"beego 日志处理"},{"content":"这篇博客对数组的理解很深入，特别转发，原文地址：https://jiang-hao.com/articles/2020/backend-data-struct-array.html\n定义 数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。\n这个定义里有几个关键词，理解了这几个关键词，我想你就能彻底掌握数组的概念了。\n首先是线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。\n而与它相对立的概念是非线性表，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。\n第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“随机访问”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。\n随机访问 我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10]来举例。在下面这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。\n我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：\na[i]_address=base_address+i∗data_type_sizea[i]_address=base_address+i∗data_type_size\n其中 data_type_size 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。\n这里要特别纠正一个“错误”。在面试的时候，常常会问数组和链表的区别，很多人都回答说，“链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)”。\n实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。\n低效的“插入”和“删除” 前面概念部分我们提到，数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效。现在我们就来详细说一下，究竟为什么会导致低效？又有哪些改进方法呢？\n插入操作 设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。\n如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。\n如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。\n为了更好地理解，我们举一个例子。假设数组 a[10]中存储了如下 5 个元素：a，b，c，d，e。\n我们现在需要将元素 x 插入到第 3 个位置。我们只需要将 c 放入到 a[5]，将 a[2]赋值为 x 即可。最后，数组中的元素如下： a，b，x，d，e，c。\n利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。这个处理思想在快排中也会用到。\n删除操作 跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。\n和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。\n实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？\n我们继续来看例子。数组 a[10]中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。\n为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。\n如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的。如果你细心留意，不管是在软件开发还是架构设计中，总能找到某些算法和数据结构的影子。\n警惕数组的访问越界问题 首先，我请你来分析一下这段 C 语言代码的运行结果：\nint main(int argc, char* argv[]){ int i = 0; int arr[3] = {0}; for(; i\u0026lt;=3; i++){ arr[i] = 0; printf(\u0026#34;hello world\\n\u0026#34;); } return 0; } 这段代码的运行结果并非是打印三行“hello word”，而是会无限打印“hello world”，这是为什么呢？\n因为，数组大小为 3，a[0]，a[1]，a[2]，而我们的代码因为书写错误，导致 for 循环的结束条件错写为了 i\u0026lt;=3 而非 i\u0026lt;3，所以当 i=3 时，数组 a[3]访问越界。\n我们知道，在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据我们前面讲的数组寻址公式，a[3]也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。\n对此处的无限循环有疑问的话，可以去查函数调用的栈桢结构细节（操作系统或计算机体系结构的教材应该会讲到）。函数体内的局部变量存在栈上，且是连续压栈。在Linux进程的内存布局中，栈区在高地址空间，从高向低增长。变量i和arr在相邻地址，且i比arr的地址大，所以arr越界正好访问到i。当然，前提是i和arr元素同类型，否则那段代码仍是未决行为。\n数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。\n这种情况下，一般都会出现莫名其妙的逻辑错误，就像我们刚刚举的那个例子，debug 的难度非常的大。而且，很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统，所以写代码的时候一定要警惕数组越界。\n但并非所有的语言都像 C 一样，把数组越界检查的工作丢给程序员来做，像 Java 本身就会做越界检查，比如下面这几行 Java 代码，就会抛出 java.lang.ArrayIndexOutOfBoundsException。\nint[] a = new int[3]; a[3] = 10; 容器能否完全替代数组？ 针对数组类型，很多语言都提供了容器类，比如 Java 中的 ArrayList、C++ STL 中的 vector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？\nArrayList 最大的优势就是可以将很多数组操作的细节封装起来。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是支持动态扩容。\n数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为 10 的数组，当第 11 个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。\n如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。\n不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。\n比如我们要从数据库中取出 10000 条数据放入 ArrayList。我们看下面这几行代码，你会发现，相比之下，事先指定数据大小可以省掉很多次内存申请和数据搬移操作。\nArrayList\u0026lt;User\u0026gt; users = new ArrayList(10000); for (int i = 0; i \u0026lt; 10000; ++i) { users.add(xxx); } 作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，在以下场景，用数组可能会更合适些：\nJava ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。 当要表示多维数组时，用数组往往会更加直观。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList \u0026gt; array。 总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。\n为什么数组要从 0 开始编号，而不是从 1 开始？ 从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也讲到，如果用 a 来表示数组的首地址，a[0]就是偏移为 0 的位置，也就是首地址，a[k]就表示偏移 k 个 type_size 的位置，所以计算 a[k]的内存地址只需要用这个公式：\na[k]_address=base_address+k∗type_sizea[k]_address=base_address+k∗type_size\n但是，如果数组从 1 开始计数，那我们计算数组元素 a[k]的内存地址就会变为：\na[k]_address=base_address+(k−1)∗type_sizea[k]_address=base_address+(k−1)∗type_size\n对比两个公式，我们不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。\n数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。\n除此之外，更主要的原因可能是历史原因。\nC 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。实际上，很多语言中数组也并不是从 0 开始计数的，比如 Matlab。甚至还有一些语言支持负数下标，比如 Python。\n内容小结 数组可以说是最基础、最简单的数据结构了。数组用一块连续的内存空间，来存储相同类型的一组数据，最大的特点就是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为 O(n)。在平时的业务开发中，我们可以直接使用编程语言提供的容器类，但是，如果是特别底层的开发，直接使用数组可能会更合适。\n","permalink":"https://haokiu.com/blog/OOuDn6/","summary":"这篇博客对数组的理解很深入，特别转发，原文地址：https://jiang-hao.com/articles/2020/backend-data-struct-array.html\n定义 数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。\n这个定义里有几个关键词，理解了这几个关键词，我想你就能彻底掌握数组的概念了。\n首先是线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。\n而与它相对立的概念是非线性表，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。\n第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“随机访问”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。\n随机访问 我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10]来举例。在下面这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。\n我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：\na[i]_address=base_address+i∗data_type_sizea[i]_address=base_address+i∗data_type_size\n其中 data_type_size 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。\n这里要特别纠正一个“错误”。在面试的时候，常常会问数组和链表的区别，很多人都回答说，“链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)”。\n实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。\n低效的“插入”和“删除” 前面概念部分我们提到，数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效。现在我们就来详细说一下，究竟为什么会导致低效？又有哪些改进方法呢？\n插入操作 设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。\n如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。\n如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数据插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。\n为了更好地理解，我们举一个例子。假设数组 a[10]中存储了如下 5 个元素：a，b，c，d，e。\n我们现在需要将元素 x 插入到第 3 个位置。我们只需要将 c 放入到 a[5]，将 a[2]赋值为 x 即可。最后，数组中的元素如下： a，b，x，d，e，c。\n利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。这个处理思想在快排中也会用到。\n删除操作 跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。\n和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。\n实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？\n我们继续来看例子。数组 a[10]中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。","title":"计算机 数组"},{"content":"vscode 列选择 快捷键: shift + alt + 鼠标左键\n","permalink":"https://haokiu.com/blog/QCpYff/","summary":"vscode 列选择 快捷键: shift + alt + 鼠标左键","title":"vscode 列选择 快捷键"},{"content":"interface Go语言里面设计最精妙的应该算interface，它让面向对象，内容组织实现非常的方便，当你看完这一章，你就会被interface的巧妙设计所折服。\n什么是interface 简单的说，interface是一组method签名的组合，我们通过interface来定义对象的一组行为。\n我们前面一章最后一个例子中Student和Employee都能SayHi，虽然他们的内部实现不一样，但是那不重要，重要的是他们都能say hi\n让我们来继续做更多的扩展，Student和Employee实现另一个方法Sing，然后Student实现方法BorrowMoney而Employee实现SpendSalary。\n这样Student实现了三个方法：SayHi、Sing、BorrowMoney；而Employee实现了SayHi、Sing、SpendSalary。\n上面这些方法的组合称为interface(被对象Student和Employee实现)。例如Student和Employee都实现了interface：SayHi和Sing，也就是这两个对象是该interface类型。而Employee没有实现这个interface：SayHi、Sing和BorrowMoney，因为Employee没有实现BorrowMoney这个方法。\ninterface类型 interface类型定义了一组方法，如果某个对象实现了某个接口的所有方法，则此对象就实现了此接口。详细的语法参考下面这个例子\ntype Human struct { name string age int phone string } type Student struct { Human //匿名字段Human school string loan float32 } type Employee struct { Human //匿名字段Human company string money float32 } //Human对象实现Sayhi方法 func (h *Human) SayHi() { fmt.Printf(\u0026#34;Hi, I am %s you can call me on %s\\n\u0026#34;, h.name, h.phone) } // Human对象实现Sing方法 func (h *Human) Sing(lyrics string) { fmt.Println(\u0026#34;La la, la la la, la la la la la...\u0026#34;, lyrics) } //Human对象实现Guzzle方法 func (h *Human) Guzzle(beerStein string) { fmt.Println(\u0026#34;Guzzle Guzzle Guzzle...\u0026#34;, beerStein) } // Employee重载Human的Sayhi方法 func (e *Employee) SayHi() { fmt.Printf(\u0026#34;Hi, I am %s, I work at %s. Call me on %s\\n\u0026#34;, e.name, e.company, e.phone) //此句可以分成多行 } //Student实现BorrowMoney方法 func (s *Student) BorrowMoney(amount float32) { s.loan += amount // (again and again and...) } //Employee实现SpendSalary方法 func (e *Employee) SpendSalary(amount float32) { e.money -= amount // More vodka please!!! Get me through the day! } // 定义interface type Men interface { SayHi() Sing(lyrics string) Guzzle(beerStein string) } type YoungChap interface { SayHi() Sing(song string) BorrowMoney(amount float32) } type ElderlyGent interface { SayHi() Sing(song string) SpendSalary(amount float32) } 通过上面的代码我们可以知道，interface可以被任意的对象实现。我们看到上面的Men interface被Human、Student和Employee实现。同理，一个对象可以实现任意多个interface，例如上面的Student实现了Men和YoungChap两个interface。\n最后，任意的类型都实现了空interface(我们这样定义：interface{})，也就是包含0个method的interface。\ninterface值 那么interface里面到底能存什么值呢？如果我们定义了一个interface的变量，那么这个变量里面可以存实现这个interface的任意类型的对象。例如上面例子中，我们定义了一个Men interface类型的变量m，那么m里面可以存Human、Student或者Employee值。\n因为m能够持有这三种类型的对象，所以我们可以定义一个包含Men类型元素的slice，这个slice可以被赋予实现了Men接口的任意结构的对象，这个和我们传统意义上面的slice有所不同。\n让我们来看一下下面这个例子:\npackage main import \u0026#34;fmt\u0026#34; type Human struct { name string age int phone string } type Student struct { Human //匿名字段 school string loan float32 } type Employee struct { Human //匿名字段 company string money float32 } //Human实现SayHi方法 func (h Human) SayHi() { fmt.Printf(\u0026#34;Hi, I am %s you can call me on %s\\n\u0026#34;, h.name, h.phone) } //Human实现Sing方法 func (h Human) Sing(lyrics string) { fmt.Println(\u0026#34;La la la la...\u0026#34;, lyrics) } //Employee重载Human的SayHi方法 func (e Employee) SayHi() { fmt.Printf(\u0026#34;Hi, I am %s, I work at %s. Call me on %s\\n\u0026#34;, e.name, e.company, e.phone) } // Interface Men被Human,Student和Employee实现 // 因为这三个类型都实现了这两个方法 type Men interface { SayHi() Sing(lyrics string) } func main() { mike := Student{Human{\u0026#34;Mike\u0026#34;, 25, \u0026#34;222-222-XXX\u0026#34;}, \u0026#34;MIT\u0026#34;, 0.00} paul := Student{Human{\u0026#34;Paul\u0026#34;, 26, \u0026#34;111-222-XXX\u0026#34;}, \u0026#34;Harvard\u0026#34;, 100} sam := Employee{Human{\u0026#34;Sam\u0026#34;, 36, \u0026#34;444-222-XXX\u0026#34;}, \u0026#34;Golang Inc.\u0026#34;, 1000} tom := Employee{Human{\u0026#34;Tom\u0026#34;, 37, \u0026#34;222-444-XXX\u0026#34;}, \u0026#34;Things Ltd.\u0026#34;, 5000} //定义Men类型的变量i var i Men //i能存储Student i = mike fmt.Println(\u0026#34;This is Mike, a Student:\u0026#34;) i.SayHi() i.Sing(\u0026#34;November rain\u0026#34;) //i也能存储Employee i = tom fmt.Println(\u0026#34;This is tom, an Employee:\u0026#34;) i.SayHi() i.Sing(\u0026#34;Born to be wild\u0026#34;) //定义了slice Men fmt.Println(\u0026#34;Let\u0026#39;s use a slice of Men and see what happens\u0026#34;) x := make([]Men, 3) //这三个都是不同类型的元素，但是他们实现了interface同一个接口 x[0], x[1], x[2] = paul, sam, mike for _, value := range x{ value.SayHi() } } 通过上面的代码，你会发现interface就是一组抽象方法的集合，它必须由其他非interface类型实现，而不能自我实现， Go通过interface实现了duck-typing:即\u0026quot;当看到一只鸟走起来像鸭子、游泳起来像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子\u0026quot;。\n空interface 空interface(interface{})不包含任何的method，正因为如此，所有的类型都实现了空interface。空interface对于描述起不到任何的作用(因为它不包含任何的method），但是空interface在我们需要存储任意类型的数值的时候相当有用，因为它可以存储任意类型的数值。它有点类似于C语言的void*类型。\n// 定义a为空接口 var a interface{} var i int = 5 s := \u0026#34;Hello world\u0026#34; // a可以存储任意类型的数值 a = i a = s 一个函数把interface{}作为参数，那么他可以接受任意类型的值作为参数，如果一个函数返回interface{},那么也就可以返回任意类型的值。是不是很有用啊！\ninterface函数参数 interface的变量可以持有任意实现该interface类型的对象，这给我们编写函数(包括method)提供了一些额外的思考，我们是不是可以通过定义interface参数，让函数接受各种类型的参数。\n举个例子：fmt.Println是我们常用的一个函数，但是你是否注意到它可以接受任意类型的数据。打开fmt的源码文件，你会看到这样一个定义:\ntype Stringer interface { String() string } 也就是说，任何实现了String方法的类型都能作为参数被fmt.Println调用,让我们来试一试\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) type Human struct { name string age int phone string } // 通过这个方法 Human 实现了 fmt.Stringer func (h Human) String() string { return \u0026#34;❰\u0026#34;+h.name+\u0026#34; - \u0026#34;+strconv.Itoa(h.age)+\u0026#34; years - ✆ \u0026#34; +h.phone+\u0026#34;❱\u0026#34; } func main() { Bob := Human{\u0026#34;Bob\u0026#34;, 39, \u0026#34;000-7777-XXX\u0026#34;} fmt.Println(\u0026#34;This Human is : \u0026#34;, Bob) } 现在我们再回顾一下前面的Box示例，你会发现Color结构也定义了一个method：String。其实这也是实现了fmt.Stringer这个interface，即如果需要某个类型能被fmt包以特殊的格式输出，你就必须实现Stringer这个接口。如果没有实现这个接口，fmt将以默认的方式输出。\n//实现同样的功能 fmt.Println(\u0026#34;The biggest one is\u0026#34;, boxes.BiggestsColor().String()) fmt.Println(\u0026#34;The biggest one is\u0026#34;, boxes.BiggestsColor()) 注：实现了error接口的对象（即实现了Error() string的对象），使用fmt输出时，会调用Error()方法，因此不必再定义String()方法了。\ninterface变量存储的类型 我们知道interface的变量里面可以存储任意类型的数值(该类型实现了interface)。那么我们怎么反向知道这个变量里面实际保存了的是哪个类型的对象呢？目前常用的有两种方法：\nComma-ok断言\nGo语言里面有一个语法，可以直接判断是否是该类型的变量： value, ok = element.(T)，这里value就是变量的值，ok是一个bool类型，element是interface变量，T是断言的类型。\n如果element里面确实存储了T类型的数值，那么ok返回true，否则返回false。\n让我们通过一个例子来更加深入的理解。\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) type Element interface{} type List [] Element type Person struct { name string age int } //定义了String方法，实现了fmt.Stringer func (p Person) String() string { return \u0026#34;(name: \u0026#34; + p.name + \u0026#34; - age: \u0026#34;+strconv.Itoa(p.age)+ \u0026#34; years)\u0026#34; } func main() { list := make(List, 3) list[0] = 1 // an int list[1] = \u0026#34;Hello\u0026#34; // a string list[2] = Person{\u0026#34;Dennis\u0026#34;, 70} for index, element := range list { if value, ok := element.(int); ok { fmt.Printf(\u0026#34;list[%d] is an int and its value is %d\\n\u0026#34;, index, value) } else if value, ok := element.(string); ok { fmt.Printf(\u0026#34;list[%d] is a string and its value is %s\\n\u0026#34;, index, value) } else if value, ok := element.(Person); ok { fmt.Printf(\u0026#34;list[%d] is a Person and its value is %s\\n\u0026#34;, index, value) } else { fmt.Printf(\u0026#34;list[%d] is of a different type\\n\u0026#34;, index) } } } 是不是很简单啊，同时你是否注意到了多个if里面，还记得我前面介绍流程时讲过，if里面允许初始化变量。 也许你注意到了，我们断言的类型越多，那么if else也就越多，所以才引出了下面要介绍的switch。 switch测试\n最好的讲解就是代码例子，现在让我们重写上面的这个实现\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; ) type Element interface{} type List [] Element type Person struct { name string age int } //打印 func (p Person) String() string { return \u0026#34;(name: \u0026#34; + p.name + \u0026#34; - age: \u0026#34;+strconv.Itoa(p.age)+ \u0026#34; years)\u0026#34; } func main() { list := make(List, 3) list[0] = 1 //an int list[1] = \u0026#34;Hello\u0026#34; //a string list[2] = Person{\u0026#34;Dennis\u0026#34;, 70} for index, element := range list{ switch value := element.(type) { case int: fmt.Printf(\u0026#34;list[%d] is an int and its value is %d\\n\u0026#34;, index, value) case string: fmt.Printf(\u0026#34;list[%d] is a string and its value is %s\\n\u0026#34;, index, value) case Person: fmt.Printf(\u0026#34;list[%d] is a Person and its value is %s\\n\u0026#34;, index, value) default: fmt.Println(\u0026#34;list[%d] is of a different type\u0026#34;, index) } } } 这里有一点需要强调的是：`element.(type)`语法不能在switch外的任何逻辑里面使用，如果你要在switch外面判断一个类型就使用`comma-ok`。 嵌入interface Go里面真正吸引人的是它内置的逻辑语法，就像我们在学习Struct时学习的匿名字段，多么的优雅啊，那么相同的逻辑引入到interface里面，那不是更加完美了。如果一个interface1作为interface2的一个嵌入字段，那么interface2隐式的包含了interface1里面的method。\n我们可以看到源码包container/heap里面有这样的一个定义\ntype Interface interface { sort.Interface //嵌入字段sort.Interface Push(x interface{}) //a Push method to push elements into the heap Pop() interface{} //a Pop elements that pops elements from the heap } 我们看到sort.Interface其实就是嵌入字段，把sort.Interface的所有method给隐式的包含进来了。也就是下面三个方法：\ntype Interface interface { // Len is the number of elements in the collection. Len() int // Less returns whether the element with index i should sort // before the element with index j. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int) } 另一个例子就是io包下面的 io.ReadWriter ，它包含了io包下面的Reader和Writer两个interface：\n// io.ReadWriter type ReadWriter interface { Reader Writer } 反射 Go语言实现了反射，所谓反射就是能检查程序在运行时的状态。我们一般用到的包是reflect包。如何运用reflect包，官方的这篇文章详细的讲解了reflect包的实现原理，laws of reflection\n使用reflect一般分成三步，下面简要的讲解一下：要去反射是一个类型的值(这些值都实现了空interface)，首先需要把它转化成reflect对象(reflect.Type或者reflect.Value，根据不同的情况调用不同的函数)。这两种获取方式如下：\nt := reflect.TypeOf(i) //得到类型的元数据,通过t我们能获取类型定义里面的所有元素 v := reflect.ValueOf(i) //得到实际的值，通过v我们获取存储在里面的值，还可以去改变值 转化为reflect对象之后我们就可以进行一些操作了，也就是将reflect对象转化成相应的值，例如\ntag := t.Elem().Field(0).Tag //获取定义在struct里面的标签 name := v.Elem().Field(0).String() //获取存储在第一个字段里面的值 获取反射值能返回相应的类型和数值\nvar x float64 = 3.4 v := reflect.ValueOf(x) fmt.Println(\u0026#34;type:\u0026#34;, v.Type()) fmt.Println(\u0026#34;kind is float64:\u0026#34;, v.Kind() == reflect.Float64) fmt.Println(\u0026#34;value:\u0026#34;, v.Float()) 最后，反射的话，那么反射的字段必须是可修改的，我们前面学习过传值和传引用，这个里面也是一样的道理。反射的字段必须是可读写的意思是，如果下面这样写，那么会发生错误\nvar x float64 = 3.4 v := reflect.ValueOf(x) v.SetFloat(7.1) 如果要修改相应的值，必须这样写\nvar x float64 = 3.4 p := reflect.ValueOf(\u0026amp;x) v := p.Elem() v.SetFloat(7.1) 上面只是对反射的简单介绍，更深入的理解还需要自己在编程中不断的实践。\n","permalink":"https://haokiu.com/blog/BmxATZ/","summary":"interface Go语言里面设计最精妙的应该算interface，它让面向对象，内容组织实现非常的方便，当你看完这一章，你就会被interface的巧妙设计所折服。\n什么是interface 简单的说，interface是一组method签名的组合，我们通过interface来定义对象的一组行为。\n我们前面一章最后一个例子中Student和Employee都能SayHi，虽然他们的内部实现不一样，但是那不重要，重要的是他们都能say hi\n让我们来继续做更多的扩展，Student和Employee实现另一个方法Sing，然后Student实现方法BorrowMoney而Employee实现SpendSalary。\n这样Student实现了三个方法：SayHi、Sing、BorrowMoney；而Employee实现了SayHi、Sing、SpendSalary。\n上面这些方法的组合称为interface(被对象Student和Employee实现)。例如Student和Employee都实现了interface：SayHi和Sing，也就是这两个对象是该interface类型。而Employee没有实现这个interface：SayHi、Sing和BorrowMoney，因为Employee没有实现BorrowMoney这个方法。\ninterface类型 interface类型定义了一组方法，如果某个对象实现了某个接口的所有方法，则此对象就实现了此接口。详细的语法参考下面这个例子\ntype Human struct { name string age int phone string } type Student struct { Human //匿名字段Human school string loan float32 } type Employee struct { Human //匿名字段Human company string money float32 } //Human对象实现Sayhi方法 func (h *Human) SayHi() { fmt.Printf(\u0026#34;Hi, I am %s you can call me on %s\\n\u0026#34;, h.name, h.phone) } // Human对象实现Sing方法 func (h *Human) Sing(lyrics string) { fmt.Println(\u0026#34;La la, la la la, la la la la la...\u0026#34;, lyrics) } //Human对象实现Guzzle方法 func (h *Human) Guzzle(beerStein string) { fmt.Println(\u0026#34;Guzzle Guzzle Guzzle...\u0026#34;, beerStein) } // Employee重载Human的Sayhi方法 func (e *Employee) SayHi() { fmt.","title":"golang interface"},{"content":"看 beego 的源码，beego 的日志分为7个级别：\nconst ( LevelEmergency = iota LevelAlert LevelCritical LevelError LevelWarning LevelNotice LevelInformational LevelDebug ) 转换为\nLevelEmergency = 0 LevelAlert = 1 LevelCritical = 2 LevelError = 3 LevelWarning = 4 LevelNotice = 5 LevelInformational = 6 LevelDebug = 7 ","permalink":"https://haokiu.com/blog/RAhBfF/","summary":"看 beego 的源码，beego 的日志分为7个级别：\nconst ( LevelEmergency = iota LevelAlert LevelCritical LevelError LevelWarning LevelNotice LevelInformational LevelDebug ) 转换为\nLevelEmergency = 0 LevelAlert = 1 LevelCritical = 2 LevelError = 3 LevelWarning = 4 LevelNotice = 5 LevelInformational = 6 LevelDebug = 7 ","title":"beego 的日志级别"},{"content":"设计模式主要分为三大类： 创建型模式 创建型模式关注对象的创建过程\n工厂模式（Factory Method） 抽象工厂模式 单例模式 建造者模式 原型模式 结构型模式 结构型模式关注对象和类的组织\n适配器模式 桥接模式 装饰模式 组合模式 外观模式 享元模式 代理模式 行为型模式 行为型模式关注系统中对象之间的相互交互，研究系统在运行时对象之间相互通信和协作，进一步明确对象的职责\n模板方法模式 命令模式 迭代器模式 观察者模式 中介者模式 备忘录模式 解释器模式 状态模式 策略模式 职责链模式 访问者模式 详细说明 创建型模式 创建型模式关注对象的创建过程\n1．抽象工厂模式\n为一个产品族提供了统一的创建接口。当需要这个产品族的某一系列的时候，可以从抽象工厂中选出相应的系列创建一个具体的工厂类。\n2．建造者模式\n将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。\n3．工厂方法模式\n定义一个接口用于创建对象，但是让子类决定初始化哪个类。工厂方法把一个类的初始化下放到子类。\n4．原型模式\n用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。\n5．单例模式\n确保一个类只有一个实例，并提供对该实例的全局访问。\n5．多例模式\n确保一个类只有命名的实例，并提供对这些实例的全局访问。\n对象池模式\n通过回收利用对象避免获取和释放资源所需的昂贵成本。\n惰性初始模式\n推迟对象的创建、数据的计算等需要耗费较多资源的操作，只有在第一次访问的时候才执行。\n资源获取为初始化\n通过绑定到合适对象的生命周期来确保资源被适当地释放。\n结构型模式 结构型模式关注对象和类的组织\n6．适配器模式\n将某个类的接口转换成客户端期望的另一个接口表示。适配器模式可以消除由于接口不匹配所造成的类兼容性问题。\n7．桥接模式\n将一个抽象与实现解耦，以便两者可以独立的变化。\n8．组合模式\n把多个对象组成树状结构来表示局部与整体，这样用户可以一样的对待单个对象和对象的组合。\n9．装饰模式\n向某个对象动态地添加更多的功能。修饰模式是除类继承外另一种扩展功能的方法。\n10．外观模式\n为子系统中的一组接口提供一个一致的界面， 外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。\n11．享元\n通过共享以便有效的支持大量小颗粒对象。\n12．代理\n为其他对象提供一个代理以控制对这个对象的访问。\n行为型模式 行为型模式关注系统中对象之间的相互交互，研究系统在运行时对象之间相互通信和协作，进一步明确对象的职责\n13．职责链\n为解除请求的发送者和接收者之间耦合，而使多个对象都有机会处理这个请求。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它。\n14．命令\n将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化；对请求排队或记录请求日志，以及支持可取消的操作。\n15．解释器\n给定一个语言, 定义它的文法的一种表示，并定义一个解释器, 该解释器使用该表示来解释语言中的句子。\n16．迭代器\n提供一种方法顺序访问一个聚合对象中各个元素, 而又不需暴露该对象的内部表示。\n17．中介者\n包装了一系列对象相互作用的方式，使得这些对象不必相互明显作用，从而使它们可以松散偶合。当某些对象之间的作用发生改变时，不会立即影响其他的一些对象之间的作用，保证这些作用可以彼此独立的变化。\n18．备忘录\n备忘录对象是一个用来存储另外一个对象内部状态的快照的对象。备忘录模式的用意是在不破坏封装的条件下，将一个对象的状态捉住，并外部化，存储起来，从而可以在将来合适的时候把这个对象还原到存储起来的状态。\n19．观察者模式\n在对象间定义一个一对多的联系性，由此当一个对象改变了状态，所有其他相关的对象会被通知并且自动刷新。\n20．状态\n让一个对象在其内部状态改变的时候，其行为也随之改变。状态模式需要对每一个系统可能取得的状态创立一个状态类的子类。当系统的状态变化时，系统便改变所选的子类。\n21．策略\n定义一个算法的系列，将其各个分装，并且使他们有交互性。策略模式使得算法在用户使用的时候能独立的改变。\n22．模板方法\n模板方法模式准备一个抽象类，将部分逻辑以具体方法及具体构造子类的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。先构建一个顶级逻辑框架，而将逻辑的细节留给具体的子类去实现。\n23．访问者\n封装一些施加于某种数据结构元素之上的操作。一旦这些操作需要修改，接受这个操作的数据结构可以保持不变。访问者模式适用于数据结构相对未定的系统，它把数据结构和作用于结构上的操作之间的耦合解脱开，使得操作集合可以相对自由的演化。\n","permalink":"https://haokiu.com/blog/nG4mC7/","summary":"设计模式主要分为三大类： 创建型模式 创建型模式关注对象的创建过程\n工厂模式（Factory Method） 抽象工厂模式 单例模式 建造者模式 原型模式 结构型模式 结构型模式关注对象和类的组织\n适配器模式 桥接模式 装饰模式 组合模式 外观模式 享元模式 代理模式 行为型模式 行为型模式关注系统中对象之间的相互交互，研究系统在运行时对象之间相互通信和协作，进一步明确对象的职责\n模板方法模式 命令模式 迭代器模式 观察者模式 中介者模式 备忘录模式 解释器模式 状态模式 策略模式 职责链模式 访问者模式 详细说明 创建型模式 创建型模式关注对象的创建过程\n1．抽象工厂模式\n为一个产品族提供了统一的创建接口。当需要这个产品族的某一系列的时候，可以从抽象工厂中选出相应的系列创建一个具体的工厂类。\n2．建造者模式\n将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。\n3．工厂方法模式\n定义一个接口用于创建对象，但是让子类决定初始化哪个类。工厂方法把一个类的初始化下放到子类。\n4．原型模式\n用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。\n5．单例模式\n确保一个类只有一个实例，并提供对该实例的全局访问。\n5．多例模式\n确保一个类只有命名的实例，并提供对这些实例的全局访问。\n对象池模式\n通过回收利用对象避免获取和释放资源所需的昂贵成本。\n惰性初始模式\n推迟对象的创建、数据的计算等需要耗费较多资源的操作，只有在第一次访问的时候才执行。\n资源获取为初始化\n通过绑定到合适对象的生命周期来确保资源被适当地释放。\n结构型模式 结构型模式关注对象和类的组织\n6．适配器模式\n将某个类的接口转换成客户端期望的另一个接口表示。适配器模式可以消除由于接口不匹配所造成的类兼容性问题。\n7．桥接模式\n将一个抽象与实现解耦，以便两者可以独立的变化。\n8．组合模式\n把多个对象组成树状结构来表示局部与整体，这样用户可以一样的对待单个对象和对象的组合。\n9．装饰模式\n向某个对象动态地添加更多的功能。修饰模式是除类继承外另一种扩展功能的方法。\n10．外观模式\n为子系统中的一组接口提供一个一致的界面， 外观模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。\n11．享元\n通过共享以便有效的支持大量小颗粒对象。\n12．代理\n为其他对象提供一个代理以控制对这个对象的访问。\n行为型模式 行为型模式关注系统中对象之间的相互交互，研究系统在运行时对象之间相互通信和协作，进一步明确对象的职责\n13．职责链\n为解除请求的发送者和接收者之间耦合，而使多个对象都有机会处理这个请求。将这些对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它。\n14．命令\n将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化；对请求排队或记录请求日志，以及支持可取消的操作。\n15．解释器\n给定一个语言, 定义它的文法的一种表示，并定义一个解释器, 该解释器使用该表示来解释语言中的句子。\n16．迭代器\n提供一种方法顺序访问一个聚合对象中各个元素, 而又不需暴露该对象的内部表示。\n17．中介者\n包装了一系列对象相互作用的方式，使得这些对象不必相互明显作用，从而使它们可以松散偶合。当某些对象之间的作用发生改变时，不会立即影响其他的一些对象之间的作用，保证这些作用可以彼此独立的变化。\n18．备忘录\n备忘录对象是一个用来存储另外一个对象内部状态的快照的对象。备忘录模式的用意是在不破坏封装的条件下，将一个对象的状态捉住，并外部化，存储起来，从而可以在将来合适的时候把这个对象还原到存储起来的状态。\n19．观察者模式\n在对象间定义一个一对多的联系性，由此当一个对象改变了状态，所有其他相关的对象会被通知并且自动刷新。\n20．状态\n让一个对象在其内部状态改变的时候，其行为也随之改变。状态模式需要对每一个系统可能取得的状态创立一个状态类的子类。当系统的状态变化时，系统便改变所选的子类。\n21．策略\n定义一个算法的系列，将其各个分装，并且使他们有交互性。策略模式使得算法在用户使用的时候能独立的改变。\n22．模板方法\n模板方法模式准备一个抽象类，将部分逻辑以具体方法及具体构造子类的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。先构建一个顶级逻辑框架，而将逻辑的细节留给具体的子类去实现。\n23．访问者\n封装一些施加于某种数据结构元素之上的操作。一旦这些操作需要修改，接受这个操作的数据结构可以保持不变。访问者模式适用于数据结构相对未定的系统，它把数据结构和作用于结构上的操作之间的耦合解脱开，使得操作集合可以相对自由的演化。","title":"23中设计模式简介"},{"content":"frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议。本文简单的介绍frp的配置使用。\n实现内网穿需要有一台公网服务器。本文将公网服务器称为服务端，内网服务器称为客户端。需要开启相关的端口。相关端口没开通，访问就会失败。\nfrp git地址:https://github.com/fatedier/frp 中文文档：https://github.com/fatedier/frp/blob/master/README_zh.md frp下载地址：https://github.com/fatedier/frp/releases 本文使用软件：frp_0.21.0_linux_amd64.tar.gz 本文使用系统：centos7（公网一台，内网一台）\n本文使用软件：frp_0.21.0_linux_amd64.tar.gz，frp的客户端和服务端都在同一个包里。\n文件说明 frps.ini: 服务端配置文件 frps: 服务端软件 frpc.ini: 客户端配置文件 frpc: 客户端软件\nfrps.ini配置 [common] bind_port = 7000 # auth token token = Qwert123 dashboard_port = 7500 # dashboard 用户名密码，默认都为 admin dashboard_user = admin dashboard_pwd = Qwert123 vhost_http_port = 7083 开启服务端服务 ./frps -c ./frps.ini\n可以用脚本来启动：\n#!/bin/sh nohup /usr/local/frp/frps -c /usr/local/frp/frps.ini \u0026amp; frpc.ini配置 [common] #服务器ip地址 server_addr = 121.199.2.XXX server_port = 7000 #开放api，提供reload服务 admin_addr = 127.0.0.1 admin_port = 7400 # auth token token = Qwert123 [ssh] type = tcp local_ip = 127.0.0.1 #ssh端口 local_port = 22 remote_port = 1022 可以使用脚本来启动(start.sh)\n#!/bin/sh sudo nohup /usr/local/frp/frpc -c /usr/local/frp/frpc.ini \u0026amp; 如果更改配置文件，可以使用重新加载来更新配置(reload.sh)\n#!/bin/sh /usr/local/frp/frpc reload -c /usr/local/frp/frpc.ini \u0026amp; 配置完后就可以通过 ssh 121.199.2.XXX 1022 来连接到内网服务器。\ncentos7开机启动 /usr/lib/systemd/system/frp.service\n[Unit] Description=the frp service After=syslog.target network.target [Service] Type=forking ExecStart=/usr/local/frp/start.sh ExecReload=/bin/kill -USR2 $MAINPID ExecStop=/bin/kill -SIGINT $MAINPID [Install] WantedBy=multi-user.target 执行：\nsystemctl enable frp systemctl start frp 转自：http://www.seaxiang.com/blog/frp\n","permalink":"https://haokiu.com/blog/HYawYY/","summary":"frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议。本文简单的介绍frp的配置使用。\n实现内网穿需要有一台公网服务器。本文将公网服务器称为服务端，内网服务器称为客户端。需要开启相关的端口。相关端口没开通，访问就会失败。\nfrp git地址:https://github.com/fatedier/frp 中文文档：https://github.com/fatedier/frp/blob/master/README_zh.md frp下载地址：https://github.com/fatedier/frp/releases 本文使用软件：frp_0.21.0_linux_amd64.tar.gz 本文使用系统：centos7（公网一台，内网一台）\n本文使用软件：frp_0.21.0_linux_amd64.tar.gz，frp的客户端和服务端都在同一个包里。\n文件说明 frps.ini: 服务端配置文件 frps: 服务端软件 frpc.ini: 客户端配置文件 frpc: 客户端软件\nfrps.ini配置 [common] bind_port = 7000 # auth token token = Qwert123 dashboard_port = 7500 # dashboard 用户名密码，默认都为 admin dashboard_user = admin dashboard_pwd = Qwert123 vhost_http_port = 7083 开启服务端服务 ./frps -c ./frps.ini\n可以用脚本来启动：\n#!/bin/sh nohup /usr/local/frp/frps -c /usr/local/frp/frps.ini \u0026amp; frpc.ini配置 [common] #服务器ip地址 server_addr = 121.199.2.XXX server_port = 7000 #开放api，提供reload服务 admin_addr = 127.0.0.1 admin_port = 7400 # auth token token = Qwert123 [ssh] type = tcp local_ip = 127.0.0.1 #ssh端口 local_port = 22 remote_port = 1022 可以使用脚本来启动(start.sh)\n#!/bin/sh sudo nohup /usr/local/frp/frpc -c /usr/local/frp/frpc.","title":"frp 使用"}]